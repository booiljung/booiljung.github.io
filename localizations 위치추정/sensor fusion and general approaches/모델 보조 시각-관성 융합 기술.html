<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:모델 보조 시각-관성 융합 기술</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>모델 보조 시각-관성 융합 기술</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">위치 추정 (Localization)</a> / <a href="index.html">센서 융합 및 일반 접근법 (Sensor Fusion & General Approaches)</a> / <span>모델 보조 시각-관성 융합 기술</span></nav>
                </div>
            </header>
            <article>
                <h1>모델 보조 시각-관성 융합 기술</h1>
<h2>1. 주행 거리 측정(Odometry)의 한계를 넘어서</h2>
<p>자율 시스템이 GPS와 같은 외부 참조 시스템 없이 미지의 환경에서 작동하기 위해서는 동시적 위치 추정 및 지도 작성(Simultaneous Localization and Mapping, SLAM) 기술이 필수적이다.1 SLAM의 핵심 구성 요소 중 하나는 시스템의 상대적인 움직임을 추정하는 주행 거리 측정(Odometry)이며, 시각-관성 주행 거리 측정(Visual-Inertial Odometry, VIO)은 이 분야에서 가장 발전된 기술 중 하나로 평가받는다.1 VIO는 저렴하고 보편적인 센서인 카메라와 관성 측정 장치(Inertial Measurement Unit, IMU)를 융합하여 높은 정확도의 단기적인 움직임 추정을 가능하게 한다.</p>
<p>그러나 VIO는 근본적으로 상대적인 움직임을 누적하여 위치를 계산하는 ‘데드 레코닝(dead-reckoning)’ 방식에 의존한다. 이는 아무리 작은 측정 오차라도 시간이 지남에 따라 계속해서 누적되어, 전역 위치 및 방향(yaw) 추정치에 심각한 드리프트(drift)를 유발한다는 치명적인 약점을 내포한다.1 이러한 누적 오차는 장시간 임무 수행이나 전역적 일관성이 요구되는 응용 분야에서 순수 VIO 기술을 사용하기 어렵게 만드는 주된 요인이다.</p>
<p>이 안내서의 핵심 명제는 견고하고 장기적이며 전역적으로 일관된 위치 추정을 달성하기 위해서는 VIO를 외부 모델 기반의 제약 조건으로 보강해야 한다는 것이다. 이 외부 모델은 VIO 추정치를 현실 세계에 고정시키는 앵커(anchor) 역할을 함으로써, VIO 자체만으로는 얻을 수 없는 전역 정보를 제공하고 누적 오차를 주기적으로 보정한다. 본 안내서는 이러한 모델 보조 기술을 체계적으로 분석하고, 모델의 종류에 따라 기술을 분류하여 심도 있게 고찰하고자 한다.</p>
<p>이 안내서에서 다룰 모델 보조 기술의 분류 체계는 다음과 같다. 이 분류는 기술의 발전 과정과 추상화 수준을 반영하며, 안내서의 전체적인 구조를 형성한다.</p>
<ul>
<li><strong>기하학적 사전 정보 (Geometric Priors):</strong> 환경에 대해 사전에 구축된 3차원 지도를 활용하는 방식이다. 이는 가장 확립된 형태의 모델 보조 기술이다.</li>
<li><strong>구조적 사전 정보 (Structured Priors):</strong> CAD(Computer-Aided Design) 도면이나 디지털 트윈(Digital Twin)과 같은 고정밀 모델을 활용하여 정밀도를 극대화하는 방식이다.</li>
<li><strong>의미론적 사전 정보 (Semantic Priors):</strong> 객체, 구조물 등 환경에 대한 고수준의 인지적 이해를 활용하여 강건성과 지능을 향상시키는 방식이다.</li>
</ul>
<p>이러한 모델의 개념은 단일한 아이디어가 아니라, VIO 기술 분야 자체의 발전을 반영하는 추상화의 스펙트럼으로 이해할 수 있다. 초기 접근 방식에서 ’모델’은 희소 특징점 클라우드나 밀집 라이다(LiDAR) 스캔과 같은 순수한 기하학적 데이터로 정의되었다.5 이때의 목표는 “이 지도 위에서 나의 위치는 어디인가?“라는 기하학적 정렬 문제에 국한되었다. 다음 단계에서는 CAD나 BIM(Building Information Modeling)과 같은 구조화된 모델이 등장했다.8 여기서 모델은 단순한 기하학적 데이터가 아니라, 객체나 건물의 완벽하고 이상적인 표현이다. 이는 더 높은 정밀도의 정렬을 가능하게 하지만, 알려진 객체에만 적용할 수 있다는 한계가 있다. 딥러닝의 발전은 ’의미론적 모델’이라는 새로운 패러다임을 열었다.10 이제 모델은 ‘의자’, ‘벽’, ’사람’과 같이 레이블이 지정된 개체들의 집합으로 정의된다. 이는 문제의 본질을 “나는 어디에 있는가?“에서 “내 주변에 무엇이 있으며, 이 사물들과의 관계 속에서 나는 어디에 있는가?“로 전환시켰다. 이는 훨씬 더 강건한 데이터 연관 및 상호작용을 가능하게 한다. 가장 최근의 발전은 NeRF(Neural Radiance Fields)나 3D 가우시안 스플래팅(Gaussian Splatting)과 같은 연구에서 나타나며, 여기서 모델은 장면의 외형과 기하학을 표현하는 암시적이고 학습된 함수로 취급된다.10 이러한 기술적 흐름은 VIO 분야의 목표가 순수한 위치 추정이라는 기하학적 문제에서, 전체적인 장면 이해라는 인지적 인식 문제로 근본적으로 이동하고 있음을 보여준다. 이는 로봇 공학이 단순한 내비게이션을 넘어 복잡하고 맥락을 인지하는 상호작용 및 임무 수행으로 나아가는 데 심오한 영향을 미친다.</p>
<p>아래 표는 본 안내서에서 다룰 모델 보조 VIO 패러다임의 분류를 요약한 것이다.</p>
<p><strong>표 1: 모델 보조 VIO 패러다임의 분류</strong></p>
<table><thead><tr><th>모델 유형</th><th>데이터 소스</th><th>핵심 과제</th><th>주요 응용 분야</th></tr></thead><tbody>
<tr><td><strong>기하학적 (Geometric)</strong></td><td>LiDAR 스캔, 특징점 지도, 시각적 포인트 클라우드</td><td>포인트 클라우드 정합, 2D-3D 매칭, 드리프트 보정</td><td>자율 주행, 대규모 AR, 드론 내비게이션</td></tr>
<tr><td><strong>구조적 (Structured)</strong></td><td>CAD 모델, BIM, 레벨-오브-디테일(LoD) 지도</td><td>고정밀 2D-3D 정렬, 모델-실물 불일치 처리</td><td>산업용 계측, 건축, 로봇 팔 제어</td></tr>
<tr><td><strong>의미론적 (Semantic)</strong></td><td>주석 달린 이미지, 객체 데이터베이스</td><td>의미론적 데이터 연관, 동적 객체 필터링, 장면 이해</td><td>지능형 로봇, 인간-로봇 상호작용, 증강 현실</td></tr>
</tbody></table>
<h2>2. 시각-관성 주행 거리 측정(VIO)의 기초</h2>
<p>모델 보조 기술의 효과를 이해하기 위해서는 먼저 VIO의 기본 원리, 핵심 방법론, 그리고 내재된 한계를 명확히 파악해야 한다. 이 섹션에서는 VIO의 기술적 토대를 상세히 설명한다.</p>
<h3>2.1 센서 융합의 원리</h3>
<p>VIO의 핵심은 서로 다른 특성을 가진 두 센서, 즉 카메라와 IMU의 상보적인 결합에 있다.3</p>
<ul>
<li><strong>카메라 (Visual Sensor):</strong> 카메라는 주변 환경에 대한 풍부한 외부 정보를 제공한다. 이미지로부터 특징점, 선, 면과 같은 기하학적 구조를 추출하여 움직임을 추정할 수 있다. 일반적으로 30-60Hz 정도의 비교적 낮은 주기로 데이터를 제공하며, 조명 변화에 민감하고 빠른 움직임에서는 모션 블러(motion blur)가 발생하기 쉽다는 단점이 있다.3</li>
<li><strong>관성 측정 장치 (IMU, Inertial Measurement Unit):</strong> IMU는 가속도계와 자이로스코프로 구성되어, 시스템의 선형 가속도와 각속도를 측정하는 고유 수용성 센서이다.16 100Hz에서 1000Hz에 이르는 매우 높은 주기로 데이터를 출력하여 빠른 움직임을 놓치지 않고 측정할 수 있다.3 하지만 측정값에 노이즈가 포함되어 있으며, 이를 적분하여 자세와 위치를 계산하는 과정에서 오차가 빠르게 누적된다. 특히, 정지 상태나 등속 운동 시에는 드리프트가 심각해진다.3</li>
</ul>
<p>이 두 센서의 융합은 각자의 단점을 보완하고 장점을 극대화한다. IMU는 카메라 프레임 사이의 짧은 시간 동안의 움직임을 높은 빈도로 추정하여 전체적인 움직임 추정의 연속성을 보장한다. 반면, 카메라는 외부 환경을 직접 관찰하여 IMU의 누적되는 드리프트를 주기적으로 보정하는 역할을 한다.3 특히, 단안 카메라(monocular camera) 사용 시 발생하는 스케일 모호성(scale ambiguity) 문제, 즉 장면의 실제 크기를 알 수 없는 문제를 해결하는 데 IMU가 결정적인 역할을 한다. IMU가 측정한 가속도 값은 미터(m) 단위의 물리량을 제공하므로, 시스템이 충분한 가속 운동을 할 경우, VIO 시스템은 실제 세계의 스케일을 복원할 수 있다.3</p>
<h3>2.2 핵심 방법론: 필터링 대 최적화</h3>
<p>VIO에서 센서 데이터를 융합하여 상태(자세, 위치, 속도 등)를 추정하는 방식은 크게 필터링 기반 접근법과 최적화 기반 접근법으로 나뉜다.17</p>
<ul>
<li><strong>필터링 기반 접근법 (Filtering Approaches):</strong> 확장 칼만 필터(Extended Kalman Filter, EKF)가 대표적인 예이다. 이 방식은 오직 <em>현재</em> 시점의 상태만을 추정한다. 예측(prediction) 단계에서 IMU 측정값을 이용해 상태를 전파하고, 업데이트(update) 단계에서 새로운 카메라 측정값이 들어오면 예측된 상태를 보정하는 과정을 재귀적으로 반복한다.18 필터링 방식의 가장 큰 장점은 연산량이 적어 매우 빠르다는 것이다.17 하지만 치명적인 단점은 과거의 상태 정보를 선형화하여 요약하고 폐기한다는 점이다. 이로 인해 선형화 오차가 누적될 수 있으며, 한번 발생한 추정 오차는 이후의 상태에 계속해서 영향을 미쳐 일관성(consistency)을 잃기 쉽다.17</li>
<li><strong>최적화 기반 접근법 (Optimization-Based Approaches):</strong> 평활화(smoothing)라고도 불리는 이 방식은 일정 시간 동안의 과거 상태들을 모두 고려하여, 모든 측정값을 가장 잘 만족시키는 최적의 궤적을 찾는다. 이는 보통 비선형 최소 제곱법(non-linear least-squares) 문제로 공식화되며, 인수 그래프(factor graph)를 통해 표현되고 번들 조정(Bundle Adjustment, BA)과 같은 기법으로 해결된다.17 이 방식은 과거 정보를 버리지 않고 공동으로 최적화하기 때문에 필터링 방식보다 훨씬 높은 정확도를 제공한다. 하지만 모든 과거 상태와 측정값을 고려해야 하므로 연산 복잡도가 매우 높다는 단점이 있다.17</li>
</ul>
<p>이러한 연산 부담을 줄이기 위해 현대의 많은 고성능 VIO 시스템들은 ’슬라이딩 윈도우 최적화(sliding-window optimization)’라는 하이브리드 방식을 채택한다. 이는 전체 궤적이 아닌, 최근의 일정 개수 키프레임(keyframe)으로 구성된 윈도우 내에서만 최적화를 수행하는 방식이다. 윈도우에서 가장 오래된 상태는 주변화(marginalization)를 통해 제거하여 계산량을 관리하면서도, 순수 필터링 방식보다 높은 정확도를 유지한다.3</p>
<p>역사적으로 필터링과 최적화는 뚜렷하게 구분되는 두 개의 패러다임이었지만, 최근에는 이 둘의 경계가 허물어지고 있다. 최신 시스템들은 어느 한쪽에 치우치기보다는 두 방식의 장점을 결합한 하이브리드 아키텍처를 지향한다. 이는 VIO/SLAM 분야의 추정 이론이 단순한 속도 대 정확도의 트레이드오프를 넘어, 정보 행렬을 어떻게 가장 효율적이고 일관성 있게 관리할 것인가라는 더 근본적인 문제로 발전하고 있음을 시사한다. 예를 들어, VINS-Mono와 같은 시스템은 슬라이딩 윈도우 최적화를 통해 필터의 실시간성과 최적화의 정확성 사이의 균형을 맞춘다.3 반대로, Schmidt-Kalman Filter(SKF)와 같은 진보된 필터링 기법은 상태 변수를 ‘활성(active)’ 상태와 ‘방해(nuisance)’ 상태(예: 지도)로 분할하여, 전통적으로 최적화 기반 SLAM의 영역이었던 영구적인 지도 관리를 효율적으로 수행하도록 설계되었다.19 이는 미래의 VIO 시스템이 필터와 최적화 중 하나를 선택하는 것이 아니라, 어떤 정보를 최적화하고 어떤 정보를 주변화하며, 이를 계산적으로 어떻게 효율적으로 수행할 것인가에 대한 정교한 하이브리드 추정기를 설계하는 방향으로 나아갈 것임을 보여준다.</p>
<h3>2.3 결합 전략: 약결합 대 강결합</h3>
<p>센서 데이터를 융합하는 구체적인 방식에 따라 VIO 시스템은 약결합(Loosely-Coupled)과 강결합(Tightly-Coupled)으로 구분된다.</p>
<ul>
<li><strong>약결합 (Loosely-Coupled):</strong> 카메라와 IMU 하위 시스템이 각각 독립적으로 움직임(자세, 위치 등)을 추정한다. 이후, 이렇게 개별적으로 계산된 두 개의 추정치를 또 다른 필터를 이용해 결합하는 방식이다.20 구현이 비교적 간단하지만, 각 센서의 원시 측정값(raw measurement)이 서로를 직접적으로 보정해주지 못하기 때문에 성능이 제한적이다. 각 센서가 가진 고유의 드리프트와 같은 한계가 융합 단계까지 그대로 남아있게 되어, 근본적인 오차 보상이 어렵다.17</li>
<li><strong>강결합 (Tightly-Coupled):</strong> 카메라의 원시 측정값(예: 이미지 특징점의 픽셀 위치)과 IMU의 원시 측정값(각속도, 가속도)을 하나의 통합된 상태 추정 프레임워크(필터 또는 최적화)에 직접 입력하여 모든 관련 상태 변수(카메라 자세, IMU 바이어스, 3D 특징점 위치 등)를 공동으로 추정하는 방식이다.3 이 방식에서는 IMU 측정값이 시각 정보 추정을 제약하고, 반대로 시각 정보가 IMU 바이어스 추정을 제약하는 등, 센서 간의 상호작용이 극대화된다. 예를 들어, IMU 측정값으로 다음 카메라 프레임에서의 특징점 위치를 예측하여 특징점 추적(tracking)의 강건성을 높일 수 있다.17 이처럼 강결합 방식은 훨씬 더 높은 정확도와 강건성을 제공하기 때문에, 현재 고성능 VIO 시스템의 표준으로 자리 잡고 있다.</li>
</ul>
<h3>2.4 VIO의 근본적인 도전 과제</h3>
<p>이론적으로 강력함에도 불구하고, 실제 VIO 시스템을 구현하고 운영하는 데에는 여러 근본적인 어려움이 따른다.</p>
<ul>
<li><strong>초기화 (Initialization):</strong> 시스템이 처음 시작될 때, 정확한 상태 추정을 위해 몇 가지 초기값을 결정해야 한다. 여기에는 초기 속도, 중력 벡터의 방향, 그리고 IMU 센서의 바이어스(bias) 추정이 포함된다. 이 과정은 종종 사용자가 특정 움직임(예: 위아래, 좌우로 흔들기)을 수행하도록 요구하며, 이 과정이 제대로 수행되지 않으면 전체 시스템의 성능이 저하되거나 실패할 수 있다.3 정지 상태에서 시작하는 것이 일반적인 전략이지만, 이는 실제 사용 환경에서 제약이 될 수 있다.</li>
<li><strong>스케일 모호성 (Scale Ambiguity):</strong> 앞서 언급했듯이, 단안 카메라만으로는 환경의 절대적인 크기를 알 수 없다. IMU가 이 문제를 해결할 수 있지만, 이를 위해서는 시스템이 충분한 가속 운동을 경험해야만 스케일이 관측 가능(observable)해진다.</li>
<li><strong>연산 복잡도 (Computational Complexity):</strong> 특히 최적화 기반 방식에서 수많은 상태 변수와 특징점을 실시간으로 처리하는 것은 상당한 계산 부하를 유발한다.17 이 때문에 키프레임 기반 처리, 슬라이딩 윈도우, 특징점 관리 등 연산량을 줄이기 위한 다양한 기법이 필수적이다.</li>
<li><strong>강건성 (Robustness):</strong> VIO 시스템의 성능은 특정 환경이나 움직임에 따라 크게 저하될 수 있다. 텍스처가 부족한 벽이나 심한 조명 변화가 있는 환경에서는 카메라 특징점 추적이 실패할 수 있다.3 반대로, 느리고 일정한 속도로 움직일 때는 IMU의 드리프트가 심해져 오차가 커지며, 너무 격렬하게 움직이면 모션 블러로 인해 이미지 품질이 저하되어 추적이 실패할 수 있다.15</li>
</ul>
<p>아래 표는 VIO의 핵심 방법론인 필터링과 최적화 방식을 비교 분석한 것이다.</p>
<p><strong>표 2: VIO 방법론 비교 분석</strong></p>
<table><thead><tr><th>구분</th><th>필터링 기반 (예: EKF)</th><th>최적화 기반 (예: Smoothing)</th></tr></thead><tbody>
<tr><td><strong>핵심 원리</strong></td><td>현재 상태만을 재귀적으로 예측 및 업데이트</td><td>과거 상태들의 윈도우를 공동으로 최적화</td></tr>
<tr><td><strong>주요 장점</strong></td><td>빠르고 연산 효율이 높음, 실시간성에 유리</td><td>정확도가 높고, 과거 정보를 활용하여 일관성 유지</td></tr>
<tr><td><strong>주요 단점</strong></td><td>과거 정보 폐기로 인한 선형화 오차 누적 및 불일관성</td><td>연산 복잡도가 높고, 상태가 많아지면 계산량 급증</td></tr>
<tr><td><strong>연산 복잡도</strong></td><td>상태 벡터 크기에 대해 제곱(O(n2))</td><td>상태 및 측정값 수에 따라 다항식으로 증가</td></tr>
<tr><td><strong>일관성</strong></td><td>선형화 지점 고정 시 불일관성 문제 발생 가능</td><td>재선형화를 통해 일관성 유지에 더 유리</td></tr>
<tr><td><strong>대표적 사용 사례</strong></td><td>빠른 응답이 중요한 실시간 시스템, 저사양 하드웨어</td><td>높은 정확도가 요구되는 오프라인 처리, SLAM 백엔드</td></tr>
</tbody></table>
<hr />
<h2>3. 기하학적 모델 보조: 알려진 세계 내에서의 위치 추정</h2>
<p>모델 보조 VIO의 첫 번째 주요 범주는 환경의 기하학적 표현을 사전 정보로 활용하는 것이다. 이는 가장 오래 연구되었고 상업적으로도 널리 배포된 방식으로, VIO를 미지의 환경을 탐험하는 SLAM의 일부가 아닌, 이미 알려진 지도 내에서 자신의 위치를 찾는 순수 측위(localization) 문제로 변환시킨다.</p>
<h3>3.1 사전 지도를 이용한 위치 추정</h3>
<ul>
<li><strong>개념:</strong> 이 접근법의 핵심은 처음부터 지도를 생성하는 대신, 사전에 정밀하게 제작된 지도를 기준으로 VIO를 구동하는 것이다.7 VIO는 지도 기반의 전역 위치 보정 업데이트 사이의 고주파 상대 움직임을 추정하는 역할을 담당한다. 즉, VIO는 부드러운 단기 궤적을 제공하고, 사전 지도는 이 궤적이 전역적으로 표류하지 않도록 주기적으로 절대 좌표계에 고정시키는 앵커 역할을 한다. 이로써 VIO의 가장 큰 약점인 누적 오차 문제를 근본적으로 해결할 수 있다.</li>
<li><strong>지도의 종류:</strong> 사전 지도는 다양한 형태로 존재할 수 있다. 스테레오 카메라로 생성된 밀집 시각적 포인트 클라우드 7, 특징점과 그 디스크립터로 구성된 희소 특징점 지도 19, LiDAR 센서로 스캔한 정밀 포인트 클라우드 5, 혹은 환경의 구조적 특징을 담은 선과 평면 지도 25 등이 모두 활용될 수 있다.</li>
<li><strong>방법론:</strong> VIO 시스템을 사전 지도에 정렬하는 방법은 지도의 종류와 센서 구성에 따라 달라진다.</li>
<li><strong>2D-3D 매칭:</strong> 현재 카메라 이미지에서 추출한 2D 특징점을 사전 지도의 3D 랜드마크와 매칭하는 방식이다.19 이는 특징점 기술자(descriptor) 데이터베이스를 필요로 하지만, 매우 효과적이고 널리 사용되는 기법이다.</li>
<li><strong>3D-3D 정렬:</strong> VIO나 스테레오 비전을 통해 실시간으로 생성된 지역 3D 포인트 클라우드를 전역 사전 지도와 정합하는 방식이다. 주로 ICP(Iterative Closest Point)나 NDT(Normal Distributions Transform)와 같은 알고리즘이 사용되며, LiDAR 기반 지도에 효과적이다.7</li>
<li><strong>교차 모달 위치 추정 (Cross-Modal Localization):</strong> 지도 제작에 사용된 센서와 위치 추정에 사용되는 센서가 다른 경우를 말한다. 예를 들어, 사전에 LiDAR로 제작된 지도 내에서 카메라의 위치를 추정하는 것은 매우 도전적이면서도 강력한 접근법이다.5 이를 위해 LiDAR 데이터로부터 카메라와 유사한 가상 이미지를 합성하거나, 두 센서 양쪽에서 모두 강건하게 검출될 수 있는 교차 모달 특징을 찾아야 한다.</li>
</ul>
<h3>3.2 사례 연구: 전 지구적 시각 위치 확인 시스템 (VPS)</h3>
<p>기하학적 모델 보조 기술의 정점은 구글의 ARCore 지오스페이셜 API(Geospatial API)나 애플의 ARKit 지오트래킹(Geotracking)과 같은 상용 VPS(Visual Positioning System)에서 찾아볼 수 있다.26 이 시스템들은 전 지구적 규모의 위치 추정을 서비스 형태로 제공한다.</p>
<ul>
<li><strong>기반 기술:</strong> 이 서비스들의 근간에는 구글 스트리트 뷰(Street View)와 같은 대규모 데이터 수집 프로젝트를 통해 구축된 방대한 시각적 지도가 있다.26 딥러닝 신경망이 수십억 장의 이미지에서 추출한 수조 개의 특징점을 분석하여 전 지구적인 3D 포인트 클라우드, 즉 ’측위 모델(localization model)’을 생성한다.26</li>
<li><strong>위치 추정 과정:</strong> 사용자의 기기가 VPS 서비스에 위치를 요청하면, 기기의 카메라 영상이 신경망에 의해 처리되어 인식 가능한 특징점을 찾는다. 이 특징점들은 클라우드에 저장된 전역 VPS 모델과 매칭되며, 컴퓨터 비전 알고리즘이 이를 바탕으로 GPS 단독으로는 불가능했던 매우 정확한 6자유도(6-DoF) 자세(위치 및 방향)를 계산해낸다.26</li>
<li><strong>VIO와의 통합:</strong> 기기에 내장된 VIO(ARCore/ARKit 문서에서는 SLAM 또는 모션 트래킹으로 지칭됨 30)는 이러한 전역 VPS 위치 보정 사이의 고주파 상대 자세 추적을 담당한다. 즉, VPS가 드리프트 없는 절대적인 전역 자세를 제공하면, VIO는 그 사이를 부드럽고 실시간으로 연결하는 역할을 한다.</li>
<li><strong>VPS의 도전 과제:</strong></li>
<li><strong>적용 범위 (Coverage):</strong> VPS는 사전 이미지 데이터가 존재하는 지역(주로 공공 도로)에서만 작동하며, 실내나 지도화되지 않은 지역에서는 사용할 수 없다.27</li>
<li><strong>환경 변화:</strong> 시스템은 지도 제작 시점과 실제 사용 시점 사이의 환경 변화(계절, 날씨, 공사, 조명 등)에 강건해야 한다. 이를 위해 머신러닝을 통해 나무와 같은 일시적인 요소보다는 건물 외곽선처럼 영구적인 구조물에 집중한다.29</li>
<li><strong>하드웨어 및 연결성:</strong> VPS 서비스를 이용하기 위해서는 네트워크 연결이 필수적이며, 기기의 센서(카메라, GPS, IMU) 성능에 따라 측위 결과의 품질이 달라질 수 있다.27</li>
<li><strong>확장성 및 유지보수:</strong> 전 지구적 지도를 구축하고 최신 상태로 유지하는 것은 막대한 비용과 노력이 드는 작업이다. 특히 실내 공간은 그 규모가 방대하고 사생활 보호 문제, 수동 데이터 수집의 필요성 등으로 인해 지도화가 훨씬 더 어렵다.33</li>
</ul>
<p>이러한 VPS의 등장은 지도에 대한 패러다임의 근본적인 전환을 의미한다. 과거 클래식 SLAM에서 지도는 단일 에이전트가 자신의 위치 추정을 위해 생성하는 지역적이고 일회성인 ’산출물(artifact)’이었다.1 반면, ARCore의 지오스페이셜 API와 같은 시스템에서 지도는 클라우드에 호스팅되는 영구적이고 중앙 집중화된 ’유틸리티(utility)’이며, 최종 사용자는 API를 통해 이 ’서비스’를 소비하는 씬 클라이언트(thin client)가 된다.26 이 패러다임 전환은 적용 범위 내에서 드리프트 문제를 결정적으로 해결하지만, 지도 제작, 데이터 연관, 장기 유지보수와 같은 SLAM의 가장 어려운 부분을 서비스 제공자에게 외부화한다. 이는 기술적 문제를 해결하는 동시에 새로운 생태계적 과제를 낳는다. 즉, 특정 업체에 대한 종속성(vendor lock-in) 35, 사생활 보호 문제 35, 상시 네트워크 연결의 필요성 27, 그리고 지도화된 지역과 그렇지 않은 지역 간의 디지털 격차와 같은 시스템 수준 및 경제적 문제가 새로운 연구의 장을 열고 있다.</p>
<h3>3.3 구조화된 3D 모델(CAD/BIM)과의 정렬</h3>
<p>제조, 건축, 산업 검사 등 특정 분야에서는 대상 물체나 환경에 대한 완벽한 CAD 또는 BIM 모델이 존재하는 경우가 많다. VIO를 이러한 이상적인 모델과 융합하면 극도로 높은 정밀도의 위치 추정이 가능하다.</p>
<ul>
<li><strong>개념:</strong> 이 문제는 주로 카메라 이미지의 2D 특징점과 3D 모델을 정렬하는 2D-3D 정렬 문제로 귀결된다. VIO는 이 정렬 과정에서 안정적인 초기 자세 추정치를 제공하거나, 정렬 결과와 함께 통합적으로 최적화된다.</li>
<li><strong>방법론:</strong></li>
<li><strong>하이브리드 번들 조정 (Hybrid Bundle Adjustment, HBA):</strong> 여러 대의 카메라 자세와 CAD 모델 자체의 6자유도 자세를 공동으로 최적화하는 강력한 기법이다.36 HBA는 이상적인 CAD 모델과 실제 물체 간의 불일치(예: 제조 공차)를 강건하게 처리할 수 있다. 이는 신뢰도가 높은 2D-3D(이미지-모델) 대응 관계와 2D-2D(다중 뷰 간) 대응 관계를 유연하게 전환하며 사용하기 때문이다.36</li>
<li><strong>학습 기반 정렬:</strong> 최신 접근법들은 데이터 기반 방식을 사용하여 스캔 데이터와 CAD 모델 간의 강건한 대응 관계를 학습함으로써 기하학적 불일치를 극복한다.37</li>
<li><strong>와이어프레임 정렬:</strong> 드론(UAV) 위치 추정의 경우, LoD-Loc과 같은 방법은 이미지에서 신경망이 예측한 건물의 와이어프레임과 경량 LoD(Level-of-Detail) 3D 지도에서 투영된 와이어프레임을 정렬한다. 이는 상세한 텍스처 정보 없이도 위치 추정을 가능하게 한다.8</li>
</ul>
<hr />
<h2>4. 의미론적 모델 보조: 인지적 인식을 향하여</h2>
<p>VIO 기술의 다음 단계는 순수한 기하학적 추론을 넘어, 인간이 이해할 수 있는 고수준의 의미론적(semantic) 정보를 융합하는 것이다. 이는 시스템이 단순히 공간을 측정하는 것을 넘어 환경을 ’이해’하게 함으로써, 더 강건하고 지능적인 행동을 가능하게 하는 인지적 인식으로의 전환을 의미한다.</p>
<h3>4.1 의미론적 SLAM 및 VIO의 원리</h3>
<ul>
<li><strong>정의:</strong> 의미론적 SLAM/VIO는 전통적인 기하학적 접근법에 객체의 정체성, 범주, 속성과 같은 의미론적 정보를 통합하여 매핑 및 위치 추정 프로세스를 향상시키는 기술이다.10 이제 지도는 더 이상 점과 평면의 집합이 아니라, ‘의자’, ‘문’, ’벽’과 같이 의미 있는 개체들로 구성된 구조화된 표현이 된다.39</li>
<li><strong>장점:</strong></li>
<li><strong>향상된 강건성:</strong> 의미론적 정보는 데이터 연관(data association)에 강력한 사전 정보를 제공한다. 모호한 두 개의 특징점 군집을 구별하는 것보다 두 개의 다른 의자를 구별하는 것이 훨씬 쉽다. 이는 동적인 환경에서 사람과 같은 움직이는 객체를 식별하고 필터링함으로써 추적의 안정성을 크게 높인다.11</li>
<li><strong>향상된 위치 추정 정확도:</strong> “문은 벽에 붙어있다” 또는 “의자는 바닥에 있다“와 같은 의미론적 제약 조건을 백엔드 최적화에 추가하여 위치 추정의 정확도를 높일 수 있다.12</li>
<li><strong>고급 기능 구현:</strong> 의미론적 지도는 “부엌 식탁으로 가“와 같은 더 높은 추상화 수준에서의 인간-로봇 상호작용과 지능적인 임무 계획을 가능하게 한다.10</li>
<li><strong>맥락 인지:</strong> 시스템은 자신이 <em>어디에</em> 있는지를 아는 것을 넘어, <em>무엇을</em> 보고 있는지를 이해하게 되어 더 지능적인 의사결정을 내릴 수 있다.10</li>
</ul>
<h3>4.2 의미론적 정보 추출</h3>
<p>의미론적 SLAM의 부상은 컴퓨터 비전 분야, 특히 딥러닝의 발전과 불가분의 관계에 있다.11 VIO 시스템은 딥러닝 모델을 통해 이미지로부터 의미론적 정보를 실시간으로 추출한다.</p>
<ul>
<li>주요 기술 11:</li>
<li><strong>객체 탐지 (Object Detection):</strong> YOLO, SSD와 같은 모델들은 실시간으로 이미지 내 객체의 경계 상자(bounding box)와 클래스를 식별한다. 이는 잠재적으로 움직이는 객체를 걸러내거나, 정적인 객체를 안정적인 랜드마크로 활용하는 데 사용된다.43</li>
<li><strong>의미론적 분할 (Semantic Segmentation):</strong> SegNet, PSPNet과 같은 모델은 이미지의 모든 픽셀을 ‘도로’, ‘건물’, ’식물’과 같은 의미론적 범주로 분류한다. 이는 밀집된 의미론적 정보를 제공한다.38</li>
<li><strong>인스턴스 분할 (Instance Segmentation):</strong> Mask R-CNN과 같은 모델은 한 단계 더 나아가, 각 객체 <em>인스턴스</em>를 개별적으로 탐지, 분류하고 픽셀 단위의 완벽한 마스크를 제공한다. 이는 나란히 있는 두 개의 의자를 구별하는 것과 같이 개별 객체를 식별하는 데 매우 중요하다.11</li>
</ul>
<h3>4.3 기하학적 및 의미론적 제약의 융합</h3>
<p>추출된 의미론적 정보는 최적화 프레임워크 내에서 수학적 제약 조건으로 변환되어 기하학적 정보와 융합된다.</p>
<ul>
<li><strong>객체 기반 SLAM (Object-Based SLAM):</strong> 점(point)이 아닌 객체(object)를 지도의 주요 랜드마크로 사용하는 핵심 패러다임이다.46 객체는 타원체나 직육면체와 같은 간단한 기하학적 형태로 표현되거나 48, 핵심 특징점들의 집합으로 표현될 수 있다.49</li>
<li><strong>제약 조건 공식화:</strong> 의미론적 정보는 인수 그래프(factor graph) 내에서 다음과 같은 제약(factor)으로 공식화된다.</li>
<li>객체의 자세는 인수 그래프에서 하나의 변수 노드(variable node)가 될 수 있다.50</li>
<li>객체에 대한 관측(예: 경계 상자, 분할 마스크)은 카메라 자세와 객체 자세를 연결하는 인수(factor)를 생성한다.48</li>
<li>객체 간의 관계나 객체와 환경(예: 평면) 간의 관계 또한 인수로 모델링될 수 있다.53</li>
<li><strong>도전 과제:</strong> 이러한 융합은 간단하지 않다. 부정확한 의미론적 예측에 대한 강건성 확보 53 및 객체의 부분적이거나 불완전한 관측 처리 54 등이 주요 도전 과제이다.</li>
</ul>
<p>의미론적 제약의 도입은 강력한 성능 향상을 가져오지만, 동시에 새로운 종류의 위험을 내포하는 ’양날의 검’과 같다. 의미론적 정보는 강건성과 정확성을 극적으로 향상시킬 수 있는 고수준의 제약을 제공하지만, 잘못된 해석에 뿌리를 둔 치명적인 실패 모드를 야기하며 상당한 계산 병목 현상을 초래한다. 전체 시스템의 강건성이 외부 인식 모듈(딥러닝 모델)의 신뢰성에 의존하게 되는 것이다. 만약 딥러닝 모델이 움직이는 객체를 정적이라고 잘못 분류하거나 객체를 오인하면, SLAM 백엔드는 강력하지만 <em>틀린</em> 사전 정보를 받게 된다. 의미론적 제약은 고수준 정보이기 때문에, 단 하나의 잘못된 데이터 연관이 몇 개의 잘못된 특징점 매칭보다 훨씬 더 크고 치명적인 최적화 실패를 유발할 수 있다.53 이는 VIO 정확도가 최적화에 의존하고, 최적화는 의미론적 제약에, 다시 의미론적 제약은 인식 모델의 정확성에 의존하는 새로운 의존성 사슬을 만든다. 인식 모델의 오류가 전체 추정 파이프라인을 오염시킬 수 있는 것이다. 게다가, 이러한 대규모 딥러닝 모델을 실행하는 것은 계산 비용이 많이 들어, 특히 임베디드 시스템에서 VIO/SLAM의 실시간 요구 사항과 직접적으로 충돌한다.10 이는 중요한 트레이드오프 관계이다. 이러한 문제점은 두 가지 중요한 연구 방향을 제시한다. 첫째, 로보틱스에 특화된 경량화되고 효율적인 딥러닝 모델의 개발이다.44 둘째, 그리고 더 근본적으로, 의미론적 입력을 맹목적으로 신뢰하지 않는 강건한 백엔드 최적화 기술의 개발이다. 여기에는 의미론적 이상치(outlier) 제거, 불확실성을 고려한 의미론적 융합, 그리고 최적화기가 기하학 정보와 일치하지 않는다고 판단하는 의미론적 정보를 폐기할 수 있도록 하는 스위처블 제약(switchable constraints) 56과 같은 기술이 포함된다. 즉, 시스템은 자신의 의미론적 이해의</p>
<p><em>신뢰도</em>에 대해 추론할 수 있어야 한다.</p>
<h3>4.4 사례 연구: Kimera 아키텍처</h3>
<p>Kimera는 실시간 미터법-의미론적(metric-semantic) VIO/SLAM을 위한 대표적인 오픈소스 C++ 라이브러리로, 최첨단 VIO와 의미론적 메시 재구성을 긴밀하게 통합한 시스템의 대표적인 예이다.39</p>
<ul>
<li>모듈식 아키텍처 39:</li>
</ul>
<p>Kimera는 독립적으로 또는 조합하여 실행할 수 있는 네 가지 주요 모듈로 구성된다.</p>
<ol>
<li><strong>Kimera-VIO:</strong> 빠르고 정확한 상태 추정을 위한 고성능 스테레오 VIO 프론트엔드.</li>
<li><strong>Kimera-RPGO:</strong> 루프 폐쇄 및 전역 궤적 보정을 위한 강건한 자세 그래프 최적화(pose-graph optimization) 백엔드.</li>
<li><strong>Kimera-Mesher:</strong> 장애물 회피와 같은 응용을 위한 경량의 지역 3D 메시 생성 모듈.</li>
<li><strong>Kimera-Semantics:</strong> 밀집되고 전역적이며 의미론적으로 주석이 달린 3D 메시를 생성하는 모듈.</li>
</ol>
<ul>
<li>미터법-의미론적 융합 과정 39:</li>
</ul>
<ol>
<li>Kimera-VIO가 정확하고 높은 빈도의 자세 추정치라는 기하학적 뼈대를 제공한다.</li>
<li>입력 이미지에 대해 기성(off-the-shelf) 2D 의미론적 분할이 수행된다.</li>
<li>Kimera-Semantics는 VIO 자세와 스테레오 깊이 정보를 사용하여 2D 의미론적 레이블을 3D 볼륨 표현(TSDF, Truncated Signed Distance Field)으로 투영한다.</li>
<li>베이즈 업데이트 규칙을 사용하여 각 복셀(voxel)에서 시간 경과에 따른 의미론적 확률을 융합하여, 강건하고 전역적으로 일관된 3D 의미론적 메시를 생성한다.</li>
</ol>
<ul>
<li><strong>의의:</strong> Kimera는 기하학적 SLAM(VIO + PGO)과 의미론적 이해를 성공적으로 결합하여, 풍부하고 다층적인 세계 표현을 생성하는 완전한 실시간 시스템을 어떻게 구축할 수 있는지를 보여주는 중요한 사례이다.39</li>
</ul>
<hr />
<h2>5. 통합 프레임워크: 인수 그래프 최적화</h2>
<p>이 섹션에서는 대부분의 현대 모델 보조 VIO 및 SLAM 시스템의 근간을 이루는 수학적 프레임워크를 심도 있게 다룬다. 인수 그래프(Factor Graph)는 이종의 정보 소스를 유연하게 융합하는 핵심 기술이다.</p>
<h3>5.1 SLAM을 인수 그래프로 표현하기</h3>
<ul>
<li>
<p><strong>개념:</strong> 인수 그래프는 함수의 인수분해를 나타내는 이분 그래프(bipartite graph)로, 확률적 추정 문제를 모델링하는 데 이상적이다.60 SLAM 문제에서 인수 그래프는 다음 두 종류의 노드로 구성된다.</p>
</li>
<li>
<p><strong>변수 노드 (Variable Nodes):</strong> 추정하고자 하는 미지의 확률 변수를 나타낸다. 예를 들어, 시간 t에서의 로봇 자세 xt, 3D 랜드마크 위치 lj, 객체 자세 ok 등이 해당된다.</p>
</li>
<li>
<p><strong>인수 노드 (Factor Nodes):</strong> 센서 측정이나 사전 지식으로부터 파생된 변수들 간의 확률적 제약 조건을 나타낸다.61</p>
</li>
<li>
<p><strong>최적화 문제:</strong> SLAM 문제를 푸는 것은 모든 제약 조건을 가장 잘 만족시키는 변수 노드의 구성을 찾는 것과 같다. 이는 일반적으로 비선형 최소 제곱법 문제로 공식화되며, 목표는 상태의 최대 사후 확률(Maximum a Posteriori, MAP) 추정치를 찾는 것이다.2 즉, 모든 인수</p>
</li>
</ul>
<p>fi의 곱으로 표현되는 확률을 최대화하는 변수 X의 집합 <span class="math math-inline">X^*</span>를 찾는 것이다.</p>
<p>X∗=Xargmaxi∏fi(Xi)</p>
<h3>5.2 제약 조건을 인수(Factor)로 공식화하기</h3>
<p>다양한 종류의 측정과 사전 정보는 인수 그래프에서 특정 형태의 인수 노드로 표현된다.</p>
<ul>
<li>
<p><strong>사전 인수 (Prior Factor):</strong> 단일 변수 노드에 연결되는 단항(unary) 인수로, 해당 변수에 대한 사전 지식을 나타낸다. 예를 들어, 첫 번째 자세 x0에 대한 인수는 전체 그래프를 좌표계에 고정시키는 역할을 한다.62</p>
</li>
<li>
<p><strong>주행 거리 측정 인수 (Odometry Factors):</strong> 연속적인 두 자세(xi,xi+1)를 연결하는 이진(binary) 인수이다. VIO에서는 IMU 측정값이 이 인수를 통해 복잡하게 모델링된다.</p>
</li>
<li>
<p>IMU 사전 통합 (IMU Pre-integration) 3:</p>
</li>
</ul>
<p>IMU 데이터는 카메라 프레임에 비해 매우 높은 빈도로 수신되므로, 모든 개별 IMU 측정값을 그래프에 직접 추가하는 것은 계산적으로 불가능하다. IMU 사전 통합은 두 키프레임 사이의 모든 IMU 측정값들을 단일 상대 운동 제약, 즉 ’IMU 인수’로 요약하는 핵심 기술이다. 이 인수는 두 키프레임의 자세, 속도, 바이어스를 연관시키며, 귀중한 IMU 정보를 유지하면서도 계산량을 극적으로 줄여준다.3</p>
<ul>
<li>
<p><strong>시각 재투영 인수 (Visual Reprojection Factors):</strong> 카메라 자세 xi, 랜드마크 lj, 그리고 해당하는 2D 측정값 <span class="math math-inline">z_{ij}</span>를 연결한다. 이 인수는 재투영 오차, 즉 3D 랜드마크 lj를 카메라 xi의 프레임으로 투영하여 얻은 예측 픽셀 위치와 실제 관측된 픽셀 위치 zij 간의 차이를 인코딩한다.18</p>
</li>
<li>
<p><strong>루프 폐쇄 인수 (Loop Closure Factors):</strong> 로봇이 이전에 지도화했던 영역을 다시 방문했을 때, 루프 폐쇄가 감지된다. 이는 연속적이지 않은 두 자세(xi,xj)를 연결하는 인수를 생성하며, 누적된 드리프트를 수정하는 매우 강력한 제약 조건이 된다.2</p>
</li>
<li>
<p><strong>모델 기반 인수 (기하학적 및 의미론적):</strong> 모델 보조 기술이 수학적으로 통합되는 부분이다.</p>
</li>
<li>
<p><strong>사전 지도 제약:</strong> 사전 지도 내에서 위치를 추정할 때, VIO 상태의 랜드마크 lj가 전역 지도의 랜드마크 Lj와 연관될 수 있다. 이는 lj에 대한 단항 인수로 공식화될 수 있으며, 평균은 Lj, 공분산은 지도의 불확실성을 나타낸다.63</p>
</li>
<li>
<p><strong>평면 인수:</strong> 평면이 감지되면, 이를 그래프의 변수로 추가할 수 있다. 3D 점 랜드마크가 특정 평면 위에 존재해야 한다는 제약이나, 평면 관측을 기반으로 카메라 자세를 제약하는 인수를 추가할 수 있다.52</p>
</li>
<li>
<p><strong>객체 인수:</strong> 객체의 자세 ok가 변수가 된다. 2D 경계 상자 탐지에 기반하여 카메라 자세 xi와 객체 자세 ok를 연결하는 인수를 만들 수 있다. 이때 오차 함수는 투영된 3D 객체 모델이 2D 경계 상자 내에 얼마나 잘 맞는지를 측정한다.48</p>
</li>
</ul>
<h3>5.3 고급 최적화 전략</h3>
<ul>
<li><strong>완전 공동 추정 대 Schmidt-Kalman 필터 (SKF):</strong> 사전 지도를 사용할 때, 지도 랜드마크를 어떻게 처리할지는 중요한 문제이다.</li>
<li><strong>완전 공동 추정 (Full Joint Estimation):</strong> 지도 랜드마크를 상태 벡터에 변수로 포함시켜 로봇의 자세와 함께 완전히 최적화한다. 가장 정확하지만 계산 비용이 가장 많이 든다.19</li>
<li><strong>Schmidt-Kalman 필터 (SKF):</strong> 더 효율적이고 일관성 있는 대안이다. 지도 랜드마크를 ‘방해(nuisance)’ 매개변수로 취급한다. 즉, 이들은 활성 상태(로봇 자세)를 업데이트하는 데 사용되지만, 랜드마크 자체의 추정치와 공분산은 업데이트되지 않는다. 이는 랜드마크와 활성 상태 간의 상호 상관 관계를 올바르게 고려하면서도, 완전한 업데이트 단계의 계산 비용을 피할 수 있게 해준다. 결과적으로 연산 비용이 지도 상태의 수에 선형적으로 비례하게 된다.19 연구 19에 따르면 SKF는 작은 작업 공간에서 정확도와 효율성 간의 뛰어난 균형을 제공한다.</li>
<li><strong>강건성을 위한 스위처블 제약 (Switchable Constraints):</strong> 잘못된 루프 폐쇄나 거짓된 의미론적 탐지와 같은 이상치(outlier)를 제거하는 것은 매우 중요하다. 스위처블 제약은 이에 대한 우아한 해결책을 제공한다.56 잠재적으로 잘못될 수 있는 각 제약(예: 루프 폐쇄 인수)에 추가적인 ‘스위치’ 변수를 도입한다. 이 스위치 변수는 해당 제약이 그래프의 나머지 부분과 일치하지 않을 경우, 최적화 과정에서 제약을 효과적으로 ‘끌’ 수 있다. 스위치 변수에 대한 사전 확률은 제약을 끄는 것에 페널티를 부여하므로, 심각한 이상치에 대해서만 작동한다. 이는 그래프의 위상(topology) 자체를 최적화의 대상으로 만들어, 훨씬 더 강건한 백엔드를 구현할 수 있게 한다.</li>
</ul>
<hr />
<h2>6. 시스템 수준의 도전 과제와 실제적 개척 분야</h2>
<p>이 섹션에서는 이론과 알고리즘을 넘어, 모델 보조 VIO 시스템을 실제 세계에 배포할 때 직면하는 실질적인 문제들, 즉 계산 비용, 장기 운용, 확장성 등을 다룬다.</p>
<h3>6.1 계산 부담: 자원 제약 시스템에서의 실시간성</h3>
<ul>
<li><strong>의미론적 정보의 비용:</strong> 의미론적 정보는 강력하지만, 이를 추출하는 딥러닝 모델(분할, 탐지 등)은 계산 집약적이다.43 Mask R-CNN과 같은 네트워크를 매 프레임마다 실행하는 것은 모바일 CPU에서 실시간으로 처리하기에는 너무 느릴 수 있다.43 이는 의미론적 이해의 풍부함과 실시간 성능 사이에 근본적인 트레이드오프를 발생시킨다.10</li>
<li><strong>임베디드 시스템(예: NVIDIA Jetson)에서의 성능:</strong> 드론이나 모바일 로봇과 같은 자원 제약 플랫폼에 배포하는 것은 주요 도전 과제이다. 한 비교 연구에 따르면 10:</li>
<li><strong>기하학적 SLAM:</strong> 현재 임베디드 시스템에서 계산 비용과 정확도 간의 최상의 균형을 제공한다.</li>
<li><strong>NeRF/가우시안 스플래팅 SLAM:</strong> 높은 수준의 의미론적 디테일을 달성하지만, 상당한 컴퓨팅 자원(GPU 메모리, 전력)을 요구하여 현재로서는 실시간 임베디드 사용에 대체로 부적합하다.10</li>
<li><strong>완화 전략:</strong></li>
<li><strong>경량 네트워크:</strong> YOLOv7-tiny 44나 임베디드 GPU용으로 설계된 JetSeg 66와 같은 더 효율적인 네트워크 아키텍처에 대한 연구가 활발하다. 예를 들어, GY-SLAM은 경량화된 YOLOv5를 사용하여 파라미터 수와 계산 비용을 줄인다.55</li>
<li><strong>비동기 처리:</strong> 계산량이 많은 의미론적 분석을 주 VIO 추적 스레드와는 별개의 병렬 스레드에서 더 낮은 빈도로 실행하는 방식이다.41 이는 인식 모듈이 실시간 상태 추정을 방해하지 않도록 한다.</li>
<li><strong>하드웨어-소프트웨어 공동 설계:</strong> 효율성을 최적화하기 위해 알고리즘과 하드웨어를 함께 설계하는 것이 핵심적인 미래 방향이다.10</li>
</ul>
<p>아래 표는 임베디드 플랫폼에서 다양한 의미론적 SLAM 아키텍처의 성능을 분석한 것이다.</p>
<p><strong>표 3: 임베디드 플랫폼(NVIDIA Jetson)에서의 의미론적 SLAM 아키텍처 분석</strong></p>
<table><thead><tr><th>아키텍처 유형</th><th>대표 알고리즘 예시</th><th>위치 추정 정확도 (ATE)</th><th>GPU 메모리 사용량</th><th>에너지 소비량</th><th></th></tr></thead><tbody>
<tr><td><strong>의미론적 기하학 SLAM</strong></td><td>ORB-SLAM3 기반 시스템</td><td>양호 (실용적 수준)</td><td>낮음 - 중간</td><td>낮음 - 중간</td><td></td></tr>
<tr><td><strong>의미론적 NeRF SLAM</strong></td><td>iMAP, FR-Fusion</td><td>높음</td><td>매우 높음</td><td>매우 높음</td><td></td></tr>
<tr><td><strong>의미론적 3D 가우시안 SLAM</strong></td><td>SGS-SLAM, GS-SLAM</td><td>매우 높음</td><td>높음</td><td>높음</td><td></td></tr>
<tr><td>참고: 데이터는 10의 정성적 분석 결과를 기반으로 함.</td><td></td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<h3>6.2 장기 자율성: 지도 유지보수의 과제</h3>
<ul>
<li><strong>정적 세계 가정의 한계:</strong> 대부분의 SLAM 시스템은 환경이 정적이라고 가정한다. 이 가정은 객체가 끊임없이 움직이는 실제 인간 중심의 공간에서는 근본적으로 유효하지 않다.54 월요일에 만든 지도는 화요일에는 부정확해져 장기적인 위치 추정에 신뢰할 수 없게 될 수 있다.</li>
<li>장기 매핑의 주요 과제 67:</li>
<li><strong>인스턴스 중복:</strong> 부분적인 관측이나 시점 변화로 인해, 실제 세계의 단일 객체가 지도상에 여러 개의 개별 객체로 잘못 생성될 수 있다.67 이는 강건한 데이터 연관 기술을 필요로 한다.</li>
<li><strong>동적 변화 처리:</strong> 시스템은 객체가 이동했거나 환경에서 제거되었을 때 이를 감지할 수 있어야 한다. 이는 단순히 탐지된 것을 처리하는 것뿐만 아니라, 객체가 있어야 할 곳에서 보이지 않는 *비탐지(non-detection)*에 대해 추론하는 것을 포함한다.67</li>
<li><strong>의미론적 정보 업데이트:</strong> 기반이 되는 기하학적 지도가 업데이트될 때(예: 새로운 센서 데이터로 인해), 의미론적 계층도 일관성 있게 업데이트되어야 한다. “문은 벽에 붙어있다“와 같은 의미론적 제약 조건이 유지되어야 하므로 이는 복잡할 수 있다.68</li>
<li><strong>제안된 해결책:</strong></li>
<li><strong>생애주기 매핑 프레임워크 (Lifelong Mapping Frameworks):</strong> 이러한 시스템들은 여러 세션이나 실행에 걸쳐 지도를 명시적으로 모델링한다. 새로운 정보로 지도를 업데이트하고, 업데이트된 기하학에 의미론적 정보를 전파하며, 새로운 의미론적 요소를 발견하는 메커니즘을 포함한다.68</li>
<li><strong>메타-의미론 (Meta-Semantics):</strong> 지도가 변경될 때 의미론적 제약의 불일치를 관리하고 해결하기 위해 ’메타-의미론’이라는 계층을 도입한다.68</li>
</ul>
<h3>6.3 확장성 및 배포: 전역 VPS의 사례</h3>
<ul>
<li><strong>실내 대 실외:</strong> 구글과 같은 전역 VPS는 실외 위치 추정에서 상당한 진전을 이루었지만, 이를 실내 환경으로 확장하는 것은 엄청난 도전이다. 실내 공간의 총량은 방대하며, 위성이나 차량 기반 시스템으로 지도화할 수 없다.35</li>
<li><strong>데이터 수집 및 사생활:</strong> 실내 공간을 지도화하려면 수동 데이터 수집이 필요하며, 이는 시간이 많이 걸리고 특히 개인 주택이나 보안이 요구되는 사무실에서는 심각한 사생활 문제를 야기한다.33</li>
<li><strong>인프라 및 유지보수:</strong> 전역 위치 추정 서비스는 지도를 저장하고 측위 요청을 처리하기 위한 대규모 클라우드 인프라를 필요로 한다. 이 지도를 환경 변화에 맞춰 최신 상태로 유지하는 것은 지속적이고 비용이 많이 드는 노력이다.29</li>
<li><strong>연합 및 분산 접근법:</strong> 중앙 집중식 서비스의 한계를 해결하기 위해, 연구자들은 연합 위치 추정 시스템(예: OpenFLAME 35)을 탐구하고 있다. 이러한 시스템에서는 여러 조직이 자체 지역 지도를 호스팅하고, DNS와 같은 검색 서비스가 사용자의 대략적인 위치에 따라 적절한 지도 서버로 안내한다. 이는 사생활 및 확장성 문제를 완화할 수 있지만, 지도 검색 및 지도 간 일관성 유지라는 새로운 과제를 도입한다.35</li>
</ul>
<hr />
<h2>7. 결론 및 향후 전망</h2>
<h3>7.1 종합: 주행 거리 측정에서 인식으로의 진화</h3>
<p>본 안내서는 VIO 기술이 단순한 주행 거리 측정 기술에서 정교한 인식 시스템으로 진화해 온 과정을 종합적으로 분석했다. 이 기술의 여정은 다음과 같이 요약할 수 있다. 첫째, 순수 기하학 기반의 VIO는 “나는 어떻게 움직이고 있는가?“라는 질문에 답하며, 상대적인 움직임을 추정하는 데 탁월한 성능을 보였다. 그러나 누적 오차라는 근본적인 한계에 직면했다. 둘째, 모델 보조 VIO는 사전 구축된 기하학적 지도를 활용하여 “이 알려진 지도에서 나의 위치는 어디인가?“라는 질문에 답함으로써 드리프트 문제를 해결했다. 이는 대규모 상용화의 문을 열었다. 셋째, 최근의 미터법-의미론적 시스템으로의 진화는 “이 환경은 무엇이며, 나는 이 환경과 어떻게 관계를 맺고 있는가?“라는 더 높은 수준의 질문에 답하며, 인지적 인식으로의 도약을 상징한다. 이러한 발전은 고전적인 기하학적 추정 이론과 현대 딥러닝 기술의 융합을 통해 가능했으며, 인수 그래프와 같은 강력한 백엔드 프레임워크에 의해 통합되었다.</p>
<h3>7.2 미해결 문제와 연구의 지평</h3>
<p>모델 보조 VIO 기술은 상당한 발전을 이루었지만, 완전한 자율성을 향한 길에는 여전히 많은 미해결 문제와 흥미로운 연구 주제들이 남아있다.</p>
<ul>
<li><strong>장기 자율성 및 생애주기 매핑:</strong> 동적인 환경에서 장기간에 걸쳐 적응하고 유지될 수 있는 지도를 만드는 것은 여전히 주요 미해결 문제이다. 이는 변화 탐지, 지도 업데이트, 메모리 관리 기술의 발전을 요구한다.12</li>
<li><strong>도전적인 환경에서의 강건성:</strong> 특징이 희박하거나, 극심한 조명 변화가 있거나, 매우 동적인 요소가 많은 환경에서의 성능을 향상시키는 것은 지속적인 과제이다. 이는 열화상 또는 이벤트 카메라와 같은 새로운 센서와의 융합 및 더 강건한 알고리즘 개발을 포함한다.15</li>
<li><strong>기하학과 의미론의 심층 통합:</strong> 현재 시스템들은 종종 의미론을 기하학 위에 추가된 계층으로 취급한다. 향후 연구는 기하학적 불확실성이 의미론적 추론에 정보를 제공하고, 그 반대도 가능한, 보다 깊고 양방향적인 통합을 탐구하여 총체적인 장면 이해를 추구할 것이다.71</li>
<li><strong>일반화 및 개방형 집합 인식:</strong> 대부분의 의미론적 시스템은 고정된 수의 객체 클래스에 대해 훈련된다. 새로운, 본 적 없는 객체(open-set)를 처리하고, 광범위한 재훈련 없이 새로운 환경에 지속적으로 학습하고 적응할 수 있는 시스템을 개발하는 것이 핵심 과제이다.73</li>
<li><strong>임베디드 및 엣지 장치를 위한 효율성:</strong> 알고리즘이 복잡해짐에 따라, 저전력, 자원 제약 하드웨어에서 실행될 수 있는 효율적인 구현의 필요성이 그 어느 때보다 중요해지고 있다. 이는 알고리즘-하드웨어 공동 설계, 모델 양자화, 특수 프로세서 분야의 연구를 촉진할 것이다.10</li>
<li><strong>인식에서 행동으로 (상황 인식):</strong> 궁극적인 목표는 단순히 지도를 만드는 것이 아니라, 지능적인 행동을 가능하게 하는 것이다. 미래의 시스템은 인식을 넘어 ’상황 인식(situational awareness)’으로 나아가야 한다. 이는 현재 상태를 이해하고, 정보에 입각한 결정을 내리기 위해 미래를 <em>예측</em>하는 것을 포함한다.15 이는 SLAM을 계획(planning) 및 제어(control) 분야와 직접적으로 연결하는 중요한 연구 방향이다.</li>
</ul>
<h2>8. 참고 자료</h2>
<ol>
<li>SLAM-past-present-future.pdf - cs.wisc.edu, accessed July 16, 2025, https://pages.cs.wisc.edu/~jphanna/teaching/25spring_cs639/resources/SLAM-past-present-future.pdf</li>
<li>(PDF) A tutorial on graph-based SLAM - ResearchGate, accessed July 16, 2025, https://www.researchgate.net/publication/231575337_A_tutorial_on_graph-based_SLAM</li>
<li>[SLAM] 23. Visual-Inertial Odometry (VIO)의 역사 - velog, accessed July 16, 2025, <a href="https://velog.io/@happy_quokka/SLAM-23.-Visual-Inertial-Odometry-VIO%EC%9D%98-%EC%97%AD%EC%82%AC">https://velog.io/@happy_quokka/SLAM-23.-Visual-Inertial-Odometry-VIO%EC%9D%98-%EC%97%AD%EC%82%AC</a></li>
<li>Visual-Inertial Odometry and SLAM - Robotics and Perception Group, accessed July 16, 2025, https://rpg.ifi.uzh.ch/research_vo.html</li>
<li>Laser Map Aided Visual Inertial Localization in … - Li Tang’s Site, accessed July 16, 2025, https://tangli.site/assets/pdfs/ding2018laser.pdf</li>
<li>(PDF) Map-Based Probabilistic Visual Self-Localization - ResearchGate, accessed July 16, 2025, https://www.researchgate.net/publication/282499551_Map-Based_Probabilistic_Visual_Self-Localization</li>
<li>Autonomous Vehicle Localization with Prior Visual Point Cloud Map Constraints in GNSS-Challenged Environments - MDPI, accessed July 16, 2025, https://www.mdpi.com/2072-4292/13/3/506</li>
<li>LoD-Loc: Aerial Visual Localization using LoD 3D Map with Neural Wireframe Alignment - NIPS, accessed July 16, 2025, https://proceedings.neurips.cc/paper_files/paper/2024/file/d78ece6613953f46501b958b7bb4582f-Paper-Conference.pdf</li>
<li>MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices - CVF Open Access, accessed July 16, 2025, https://openaccess.thecvf.com/content/CVPR2023/papers/Li_MobileBrick_Building_LEGO_for_3D_Reconstruction_on_Mobile_Devices_CVPR_2023_paper.pdf</li>
<li>Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey - arXiv, accessed July 16, 2025, https://arxiv.org/html/2505.12384v1</li>
<li>Semantic Visual Simultaneous Localization and Mapping: A … - arXiv, accessed July 16, 2025, https://arxiv.org/pdf/2209.06428</li>
<li>Semantic Visual Simultaneous Localization and Mapping: A Survey - arXiv, accessed July 16, 2025, https://arxiv.org/html/2209.06428v2</li>
<li>Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey - ResearchGate, accessed July 16, 2025, https://www.researchgate.net/publication/391878292_Is_Semantic_SLAM_Ready_for_Embedded_Systems_A_Comparative_Survey</li>
<li>[Literature Review] Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey - Moonlight | AI Colleague for Research Papers, accessed July 16, 2025, https://www.themoonlight.io/en/review/is-semantic-slam-ready-for-embedded-systems-a-comparative-survey</li>
<li>From SLAM to Situational Awareness: Challenges and Survey - MDPI, accessed July 16, 2025, https://www.mdpi.com/1424-8220/23/10/4849</li>
<li>VIO, IMU, INS - has,me - 티스토리, accessed July 16, 2025, https://hasme.tistory.com/3</li>
<li>Visual Inertial Odometry Review | OnGoing, accessed July 16, 2025, https://youngguncho.github.io/2020/01/06/Visual_Inertial_Odometry/</li>
<li>희희 - cdc wiki - 서울시립대학교, accessed July 16, 2025, <a href="https://capstone.uos.ac.kr/cdc/index.php/%ED%9D%AC%ED%9D%AC">https://capstone.uos.ac.kr/cdc/index.php/%ED%9D%AC%ED%9D%AC</a></li>
<li>Map-based Visual-Inertial Localization: A … - Patrick Geneva, accessed July 16, 2025, https://pgeneva.com/downloads/papers/Geneva2022ICRA.pdf</li>
<li>“정보처리” 태그로 연결된 21개 게시물개의 게시물이 있습니다. - gracefullight.dev, accessed July 16, 2025, <a href="https://gracefullight.dev/tags/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC/page/2/">https://gracefullight.dev/tags/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC/page/2/</a></li>
<li>3차원 입체 격자 체계기반 국토 통합관리 지원 기술 개발 최종안내서, accessed July 16, 2025, https://www.codil.or.kr/filebank/original/RK/OTKCRK200031/OTKCRK200031.pdf</li>
<li>e-비즈니스의확산과산업혁신과정의변화 화학산업, accessed July 16, 2025, https://www.stepi.re.kr/common/report/Download.do?reIdx=264&amp;cateCont=A0201&amp;streFileNm=A0201_264&amp;downCont=0</li>
<li>작업 환경의 은유적 매핑을 이용한 실제와 가상세계의 암시적 융합 - Korea Science, accessed July 16, 2025, https://koreascience.kr/article/JAKO200935736658061.pdf</li>
<li>A Probabilistic Feature Map-Based Localization System Using a Monocular Camera - PMC, accessed July 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC4610567/</li>
<li>Structure PLP-SLAM: Efficient Sparse Mapping and Localization using Point, Line and Plane for Monocular, RGB-D and Stereo Camera, accessed July 16, 2025, https://www.dfki.de/fileadmin/user_upload/import/13017_ICRA_2023__PLP_SLAM_camera_ready.pdf</li>
<li>Build global-scale, immersive, location-based AR experiences with …, accessed July 16, 2025, https://developers.google.com/ar/develop/geospatial</li>
<li>Tracking geographic locations in AR | Apple Developer Documentation, accessed July 16, 2025, https://developer.apple.com/documentation/arkit/tracking-geographic-locations-in-ar</li>
<li>Build location-based augmented reality with ARCore geospatial API - YouTube, accessed July 16, 2025, https://www.youtube.com/watch?v=pFn11hYZM2E</li>
<li>Using Global Localization to Improve Navigation - Google Research, accessed July 16, 2025, https://research.google/blog/using-global-localization-to-improve-navigation/</li>
<li>Fundamental concepts | ARCore - Google for Developers, accessed July 16, 2025, https://developers.google.com/ar/develop/fundamentals</li>
<li>Visual Localization - Wemap, accessed July 16, 2025, https://blog.getwemap.com/visual-localization-70da58f034c</li>
<li>What challenges are faced when implementing indoor AR navigation? - Milvus, accessed July 16, 2025, https://milvus.io/ai-quick-reference/what-challenges-are-faced-when-implementing-indoor-ar-navigation</li>
<li>A Guide to Developing Augmented Reality Indoor Navigation Applications - MobiDev, accessed July 16, 2025, https://mobidev.biz/blog/augmented-reality-indoor-navigation-app-development</li>
<li>Geospatial localization has very different performance depending on the device. / Issue #180 / google-ar/arcore-unity-extensions - GitHub, accessed July 16, 2025, https://github.com/google-ar/arcore-unity-extensions/issues/180</li>
<li>Building a large scale federated localization and mapping service https://openflam.github.io - arXiv, accessed July 16, 2025, https://arxiv.org/html/2411.04271v1</li>
<li>Multi-view 2D–3D alignment with hybrid bundle adjustment for …, accessed July 16, 2025, https://www.researchgate.net/publication/349920981_Multi-view_2D-3D_alignment_with_hybrid_bundle_adjustment_for_visual_metrology</li>
<li>CAD Model Retrieval and Alignment in 3D Scans - mediaTUM, accessed July 16, 2025, https://mediatum.ub.tum.de/doc/1640133/affku0bdtasmq6ha4ts21a8t9.Dissertation_Armen_Avetisyan_Scan2CAD.pdf</li>
<li>Design and analysis of different semantic SLAM algorithms - DiVA portal, accessed July 16, 2025, https://www.diva-portal.org/smash/get/diva2:1415843/FULLTEXT01.pdf</li>
<li>Kimera: an Open-Source Library for Real-Time Metric … - MIT, accessed July 16, 2025, https://www.mit.edu/~arosinol/papers/Rosinol20icra-Kimera.pdf</li>
<li>(PDF) A Computationally Efficient Semantic SLAM Solution for Dynamic Scenes, accessed July 16, 2025, https://www.researchgate.net/publication/345445057_A_Computationally_Efficient_Semantic_SLAM_Solution_for_Dynamic_Scenes</li>
<li>SOLO-SLAM: A Parallel Semantic SLAM Algorithm for Dynamic Scenes - PMC, accessed July 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC9501329/</li>
<li>Semantic SLAM - AMS Tesi di Dottorato, accessed July 16, 2025, https://amsdottorato.unibo.it/id/eprint/7954/1/Cavallari_Tommaso_Tesi.pdf</li>
<li>A Computationally Efficient Semantic SLAM Solution for Dynamic Scenes - MDPI, accessed July 16, 2025, https://www.mdpi.com/2072-4292/11/11/1363</li>
<li>(PDF) Real-time visual SLAM based on semantic information and geometric information in dynamic environment - ResearchGate, accessed July 16, 2025, https://www.researchgate.net/publication/380969977_Real-time_visual_SLAM_based_on_semantic_information_and_geometric_information_in_dynamic_environment</li>
<li>A Monocular-Visual SLAM System with Semantic and Optical-Flow Fusion for Indoor Dynamic Environments, accessed July 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC9695233/</li>
<li>Towards Object-based SLAM - DSpace@MIT, accessed July 16, 2025, https://dspace.mit.edu/bitstream/handle/1721.1/158310/zhang-yihaozh-phd-meche-2024-thesis.pdf?sequence=1&amp;isAllowed=y</li>
<li>Higher or Lower: Challenges in Object based SLAM - arXiv, accessed July 16, 2025, https://arxiv.org/pdf/2310.13256</li>
<li>Robust Object-Based SLAM for High-Speed Autonomous Navigation - Research, accessed July 16, 2025, https://groups.csail.mit.edu/rrg/papers/OkLiu19icra.pdf</li>
<li>Robust and Efficient Semantic SLAM with Semantic Keypoints - Y-Prize - University of Pennsylvania, accessed July 16, 2025, https://yprize.upenn.edu/wp-content/uploads/2021/01/Semantic-SLAM-paper.pdf</li>
<li>DJPETE-SLAM: Object-Level SLAM System Based on Distributed Joint Pose Estimation and Texture Editing - MDPI, accessed July 16, 2025, https://www.mdpi.com/2079-9292/14/6/1181</li>
<li>Factor Graphs for Robot Perception - CMU School of Computer Science, accessed July 16, 2025, https://www.cs.cmu.edu/~kaess/pub/Dellaert17fnt.pdf</li>
<li>The factor graph of our Semantic SLAM system demonstrating all types of… - ResearchGate, accessed July 16, 2025, https://www.researchgate.net/figure/The-factor-graph-of-our-Semantic-SLAM-system-demonstrating-all-types-of-our-landmark_fig1_324745171</li>
<li>Leveraging Semantic Graphs for Efficient and Robust LiDAR SLAM - arXiv, accessed July 16, 2025, https://arxiv.org/html/2503.11145v1</li>
<li>Semantically Constrained SLAM Using Reliable Object Landmarks in Dynamic Vehicle Environments - ResearchGate, accessed July 16, 2025, https://www.researchgate.net/publication/393211923_Semantically_Constrained_SLAM_Using_Reliable_Object_Landmarks_in_Dynamic_Vehicle_Environments</li>
<li>GY-SLAM: A Dense Semantic SLAM System for Plant Factory Transport Robots - PMC, accessed July 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC10934148/</li>
<li>Switchable Constraints for Robust Pose Graph SLAM - CiteSeerX, accessed July 16, 2025, https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=8a937906e2a4235a6509926322f3de88340fd4dc</li>
<li>MIT-SPARK/Kimera: Index repo for Kimera code - GitHub, accessed July 16, 2025, https://github.com/MIT-SPARK/Kimera</li>
<li>Kimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping, accessed July 16, 2025, https://www.researchgate.net/publication/344982175_Kimera_an_Open-Source_Library_for_Real-Time_Metric-Semantic_Localization_and_Mapping</li>
<li>Kimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping (1910.02490v3) - Emergent Mind, accessed July 16, 2025, https://www.emergentmind.com/articles/1910.02490</li>
<li>A Tutorial on Graph-Based SLAM, accessed July 16, 2025, http://www2.informatik.uni-freiburg.de/~stachnis/pdf/grisetti10titsmag.pdf</li>
<li>Factor Graphs and GTSAM, accessed July 16, 2025, https://gtsam.org/tutorials/intro.html</li>
<li>Factor Graphs for Navigation Applications: A Tutorial, accessed July 16, 2025, https://navi.ion.org/content/71/3/navi.653</li>
<li>lio / GitHub Topics, accessed July 16, 2025, https://github.com/topics/lio</li>
<li>PGD-VIO: An Accurate Plane-Aided Visual-Inertial Odometry with Graph-Based Drift Suppression - arXiv, accessed July 16, 2025, https://arxiv.org/html/2407.17709v1</li>
<li>A Unified Framework for Mutual Improvement of SLAM and Semantic Segmentation - arXiv, accessed July 16, 2025, https://arxiv.org/pdf/1812.10016</li>
<li>[2305.11419] JetSeg: Efficient Real-Time Semantic Segmentation Model for Low-Power GPU-Embedded Systems - arXiv, accessed July 16, 2025, https://arxiv.org/abs/2305.11419</li>
<li>LTC-Mapping, Enhancing Long-Term Consistency of Object-Oriented Semantic Maps in Robotics - MDPI, accessed July 16, 2025, https://www.mdpi.com/1424-8220/22/14/5308</li>
<li>Lifelong update of semantic maps in dynamic environments - arXiv, accessed July 16, 2025, https://arxiv.org/pdf/2010.08846</li>
<li>[2010.08846] Lifelong update of semantic maps in dynamic environments - arXiv, accessed July 16, 2025, https://arxiv.org/abs/2010.08846</li>
<li>From SLAM to Situational Awareness: Challenges and Survey - ORBilu, accessed July 16, 2025, https://orbilu.uni.lu/bitstream/10993/50749/1/2110.00273.pdf</li>
<li>Understanding while Exploring: Semantics-driven Active Mapping - arXiv, accessed July 16, 2025, https://arxiv.org/html/2506.00225v1</li>
<li>Survey of simultaneous localization and mapping based on environmental semantic information - ResearchGate, accessed July 16, 2025, https://www.researchgate.net/publication/355719818_Survey_of_simultaneous_localization_and_mapping_based_on_environmental_semantic_information</li>
<li>Open-Set Dense Semantic SLAM with 3D Gaussian Splatting for Object-Level Scene Understanding - arXiv, accessed July 16, 2025, https://arxiv.org/html/2503.01646v1</li>
<li>Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey | AI Research Paper Details - AIModels.fyi, accessed July 16, 2025, https://www.aimodels.fyi/papers/arxiv/is-semantic-slam-ready-embedded-systems-comparative</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>