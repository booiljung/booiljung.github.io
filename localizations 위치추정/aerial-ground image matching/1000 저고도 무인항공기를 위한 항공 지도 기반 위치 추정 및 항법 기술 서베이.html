<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:저고도 무인항공기를 위한 항공 지도 기반 위치 추정 및 항법 기술 서베이</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>저고도 무인항공기를 위한 항공 지도 기반 위치 추정 및 항법 기술 서베이</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">위치 추정 (Localization)</a> / <a href="index.html">항공-지상 이미지 매칭 (Aerial-Ground Image Matching)</a> / <span>저고도 무인항공기를 위한 항공 지도 기반 위치 추정 및 항법 기술 서베이</span></nav>
                </div>
            </header>
            <article>
                <h1>저고도 무인항공기를 위한 항공 지도 기반 위치 추정 및 항법 기술 서베이</h1>
<p><strong>초록:</strong> 저고도 무인항공기(UAV)의 활용 분야가 국방, 물류, 인프라 점검 등 다방면으로 확대되면서, 자율 비행의 핵심인 강건하고 정밀한 항법 기술의 중요성이 그 어느 때보다 부각되고 있다. 기존의 항법 시스템은 주로 위성항법시스템(GNSS)에 의존하고 있으나, 도심 협곡, 실내, 혹은 적대적 전파 방해 환경에서는 신호가 차단되거나 조작될 위험이 크다. 이러한 GNSS 음영 환경에서 저가의 관성항법장치(INS)는 누적 오차로 인해 단독 사용이 불가능하다. 본 논문은 이러한 한계를 극복하기 위한 대안으로, 전 세계적으로 표준화되어 있으며 신뢰도 높은 정보를 담고 있는 항공 지도를 핵심 참조 데이터로 활용하는 위치 추정 및 항법 기술에 대한 포괄적인 서베이를 제공한다. 본 논문에서는 먼저 저고도 UAV의 복잡한 운용 환경과 그에 따른 항법 시스템의 요구사항을 정의하고, 항공 지도가 어떻게 기계가독형(machine-readable) 참조 레이어로 변환될 수 있는지 탐구한다. 이어서 항공 지도 정보를 활용하는 핵심적인 두 가지 위치 추정 방법론인 영상 기반 절대 위치 추정(Vision-Based Absolute Localization)과 지형 참조 항법(Terrain Referenced Navigation, TRN)에 대해 심도 있게 분석한다. 특히, 딥러닝 기반의 계층적 영상 정합, 지형 고도 프로파일 매칭 등 최신 기술 동향을 상세히 다룬다. 또한, 다양한 센서로부터의 비정기적이고 노이즈가 포함된 측정치를 통합하여 강건한 상태 추정치를 생성하기 위한 확장 칼만 필터(EKF), 입자 필터(PF)와 같은 전통적 필터링 기법부터 인공지능(AI) 기반의 하이브리드 융합 아키텍처까지의 발전 과정을 체계적으로 검토한다. 마지막으로, 추정된 위치 정보를 활용한 경로 계획 및 장애물 회피 적용 사례를 살펴보고, 실시간 동적 지도 업데이트, 디지털 트윈과의 연동, 설명가능 인공지능(XAI) 도입 등 현재의 기술적 난제와 미래 연구 방향을 제시한다. 본 서베이는 항공 지도를 기반으로 한 UAV 항법 기술의 현주소를 조망하고, 미래 도심 항공 모빌리티(UAM) 시대의 안전하고 신뢰성 있는 자율 비행을 위한 기술적 토대를 마련하는 데 기여하고자 한다.</p>
<h2>1.  서론</h2>
<h3>1.1  자율 저고도 UAV의 부상과 항법 기술의 필요성</h3>
<p>무인항공기(Unmanned Aerial Vehicle, UAV), 즉 드론은 4차 산업혁명의 핵심 기술 중 하나로 부상하며, 그 활용 범위가 폭발적으로 확장되고 있다. 초기에는 취미용이나 단순 촬영에 국한되었던 UAV는 이제 물류 배송, 정밀 농업, 사회 기반 시설의 감시 및 점검, 재난 구조, 그리고 국방 분야에 이르기까지 다양한 산업에서 핵심적인 역할을 수행하고 있다.1 특히 군사 분야에서는 네트워크 중심전(NCW)의 핵심 자산으로 활용되며 전쟁의 패러다임을 바꾸고 있고 3, 민간 분야에서는 유연한 공간 이동성을 바탕으로 기존 시스템의 효율성을 획기적으로 개선하고 있다.4 이러한 응용 분야의 성공적인 확장은 UAV가 주어진 임무를 인간의 개입 없이 완수할 수 있는 고도의 자율성에 달려 있으며, 그 자율성의 근간에는 바로 강건하고(robust) 정밀한 항법(navigation) 기술이 자리 잡고 있다.5</p>
<h3>1.2  복잡한 운용 환경에서의 GNSS 음영 문제</h3>
<p>현대의 항법 시스템은 대부분 위성항법시스템(Global Navigation Satellite System, GNSS)과 관성항법장치(Inertial Navigation System, INS)의 통합에 크게 의존한다.6 GNSS는 전 지구적인 위치 정보를 제공하며 장기적인 정확성을 보장하고, INS는 가속도계와 자이로스코프 센서를 통해 단기적으로 높은 주기의 자세 및 위치 변화 정보를 제공한다.7 그러나 UAV의 운용 환경이 개활지에서 벗어나 고층 빌딩이 밀집한 도심 협곡(urban canyon), 깊은 계곡, 실내 공간으로 확장되면서 GNSS의 근본적인 취약성이 드러나고 있다.</p>
<p>고층 건물이나 지형지물은 GNSS 위성 신호를 직접적으로 차단(blockage)하거나, 신호가 여러 경로를 통해 수신기에 도달하는 다중경로(multipath) 현상을 유발하여 위치 오차를 급격히 증가시킨다.6 더욱 심각한 문제는 의도적인 전파 방해, 즉 재밍(jamming)과 스푸핑(spoofing) 공격이다. 재밍은 강력한 방해 전파로 GNSS 수신을 마비시키며, 스푸핑은 위조된 GNSS 신호를 송출하여 수신기가 자신의 위치를 완전히 잘못 계산하도록 속인다.11 이러한 위협은 특히 군사 작전이나 국가 중요 시설 주변에서 현실적인 문제로 대두되고 있으며 3, 민간 영역에서도 저렴한 재머의 확산으로 인해 그 위험성이 점차 커지고 있다.11</p>
<p>GNSS 신호가 두절되면 항법 시스템은 INS에만 의존하게 되는데, 소형 UAV에 탑재되는 저가의 MEMS(Micro-Electro-Mechanical Systems) 기반 INS는 내재된 오차(bias, noise)가 시간에 따라 빠르게 누적되는 드리프트(drift) 현상을 보인다.14 이로 인해 GNSS의 보정 없이는 수십 초 내에 수십 미터 이상의 위치 오차가 발생하여 단독으로는 신뢰성 있는 항법 정보를 제공할 수 없다.6 이러한 현상은 GNSS에 대한 과도한 의존이 자율 시스템의 치명적인 취약점이 될 수 있음을 시사한다. 이는 단순히 ‘백업’ 시스템의 필요성을 넘어, GNSS와 동등한 수준에서 독립적으로 임무 연속성을 보장할 수 있는 ‘공동-주(co-primary)’ 항법 체계의 필요성으로 이어진다.</p>
<h3>1.3  논지: 강건한 대안 항법을 위한 기초 데이터 소스로서의 항공 지도</h3>
<p>본 논문은 GNSS의 취약성을 극복하기 위한 강력한 대안으로, 수십 년간 항공 분야에서 축적되고 표준화된 **항공 지도(Aeronautical Chart)**를 핵심적인 사전 참조 정보(a priori map)로 활용하는 항법 패러다임을 제시한다. 항공 지도는 지형, 장애물, 공역, 항로 등 항법에 필수적인 정보를 담고 있는 공인된 데이터 소스로, 전 세계적으로 일관된 형식과 높은 신뢰도를 자랑한다.16 이 지도를 디지털화하고 기계가독형 데이터로 변환함으로써, UAV는 GNSS 신호와 무관하게 자신의 절대 위치를 추정할 수 있는 안정적인 기준점을 확보하게 된다. 즉, 항공 지도는 변화하지 않는 환경 정보를 제공하여, 드리프트가 누적되는 상대 위치 추정 방식의 한계를 극복하고 강건한 절대 위치 추정을 가능하게 하는 근간이 된다.</p>
<h3>1.4  서베이의 구성</h3>
<p>본 서베이는 항공 지도 기반 UAV 항법 기술을 체계적으로 조망하기 위해 다음과 같은 구조로 구성된다. 2장에서는 저고도 UAV의 독특한 운용 환경과 항법 시스템에 요구되는 성능을 정의한다. 3장에서는 전통적인 항공 지도의 구성 요소를 분석하고, 이를 자율 시스템을 위한 디지털 참조 레이어로 변환하는 과정을 논의한다. 4장에서는 항공 지도를 활용하는 핵심 위치 추정 방법론인 영상 기반 절대 위치 추정과 지형 참조 항법을 심도 있게 다룬다. 5장에서는 다양한 센서 데이터를 융합하여 최적의 상태 추정치를 생성하는 고급 센서 융합 프레임워크를 검토한다. 6장에서는 추정된 위치 정보를 실제 자율 비행에 적용하는 경로 계획 및 장애물 회피 기술을 살펴본다. 7장에서는 현재 기술이 직면한 난제와 미래 연구 방향을 제시하며, 마지막으로 8장에서 전체 내용을 종합하고 결론을 맺는다.</p>
<h2>2.  저고도 운용 환경과 항법 요구사항</h2>
<h3>2.1  저고도 공역의 특성</h3>
<p>저고도 UAV의 운용 환경은 전통적인 항공기가 비행하는 고고도 환경과는 근본적으로 다른 특성을 가진다. 일반적으로 규제에 따라 지상고도(AGL) 150m (약 500피트) 미만의 공역으로 정의되는 이 공간은 매우 복잡하고 동적인 요소들로 가득 차 있다.18 도심 지역에서는 고층 빌딩, 타워크레인, 송전탑, 가로등과 같은 수많은 정적 장애물이 밀집해 있으며, 이는 비행 가능 공간을 극도로 제한한다.19 산악 지형에서는 급격한 지형 변화가 주요 위협 요인이 된다.19</p>
<p>정적 장애물뿐만 아니라 동적 요인들도 항법에 큰 어려움을 준다. 국지적인 돌풍, 빌딩풍과 같은 예측하기 어려운 미세 기상 변화, 갑작스러운 강우나 강설은 기체의 안정성을 위협한다.20 또한, 다른 UAV나 경량 항공기, 심지어 새떼와 같은 예측 불가능한 공중 트래픽과의 충돌 위험도 상존한다. 이러한 복잡성과 비예측성은 저고도 공역이 기존의 2차원적인 지상 도로보다 훨씬 더 강화된 안전 인프라와 정밀한 항법 능력을 요구하는 3차원 공간임을 의미한다.20</p>
<h3>2.2  규제 프레임워크와 가상 공중도로의 개념</h3>
<p>수백, 수천 대의 드론이 도심 상공을 자유롭게 비행하는 시나리오를 상상해보면, 그 혼란과 잠재적 위험은 명백하다. 이러한 문제를 해결하고 질서 있고 안전한 대규모 드론 운용을 실현하기 위해, 각국 정부와 연구 기관들은 저고도 공역을 체계적으로 관리하기 위한 새로운 규제 프레임워크와 교통 관리 시스템을 구상하고 있다. 대표적인 개념이 바로 ‘가상 공중도로(Virtual Aerial Roads)’ 또는 ’공중 회랑(Air Corridor)’이다.20</p>
<p>이는 저고도 공역에 지상의 도로망처럼 명확하게 정의된 3차원 경로와 교통 규칙을 설정하는 개념이다.20 각 공중도로는 특정 고도, 폭, 방향을 가지며, UAV는 이 약속된 경로를 따라서만 비행하도록 통제된다. 이 시스템은 기체 간의 충돌을 사전에 방지하고, 지상의 주요 장애물 및 인구 밀집 지역을 회피하며, 효율적인 교통 흐름을 유도하는 것을 목표로 한다.20 한국 정부 역시 ’한국형 도심항공교통(K-UAM) 로드맵’을 통해 이러한 개념을 적극적으로 추진하고 있으며, 이는 안전한 저고도 항공 교통 체계 구축의 핵심 요소로 간주된다.20</p>
<p>이러한 구조화된 공역 관리 패러다임의 등장은 항법 기술에 중요한 시사점을 던진다. 만약 하늘에 ’도로’가 생긴다면, 모든 운용자는 그 ’도로 지도’를 공유하고 준수해야 한다. 이는 곧, 공역의 구조, 장애물 정보, 비행 제한 구역 등을 담고 있는 표준화된 공통 지도의 중요성이 극도로 높아짐을 의미한다. 따라서, UAV가 이 공통 지도를 기준으로 자신의 위치를 정확히 인식하고 경로를 따라 비행하는 능력은 미래 도심 항공 모빌리티(UAM) 시스템에 참여하기 위한 필수 전제 조건이 된다.</p>
<h3>2.3  강건한 UAV 항법 시스템의 요구사항 정의</h3>
<p>저고도 운용 환경의 복잡성과 가상 공중도로와 같은 새로운 교통 체계의 등장은 UAV 항법 시스템에 다음과 같은 핵심적인 성능 요구사항을 부과한다.</p>
<ul>
<li><strong>정확성 (Accuracy):</strong> 좁은 공중도로를 이탈하지 않고, 건물이나 타워 같은 장애물로부터 안전거리를 확보하기 위해서는 수십 센티미터 수준의 높은 위치 정확도가 요구된다. 특히 착륙과 같은 정밀 기동 시에는 정확성이 임무 성공의 결정적인 요소가 된다.15</li>
<li><strong>강건성 (Robustness):</strong> 항법 시스템은 GNSS 신호가 두절되는 상황, 악천후나 야간과 같은 열악한 시각 조건, 그리고 의도적인 전파 방해 등 다양한 비정상적인 상황에서도 안정적으로 작동해야 한다.15 단일 센서의 고장에 시스템 전체가 마비되지 않도록 다중 센서 융합을 통한 강건성 확보가 필수적이다.</li>
<li><strong>실시간성 (Real-time Capability):</strong> 고속으로 비행하는 UAV가 동적 장애물을 회피하고 실시간으로 경로를 수정하기 위해서는 항법 정보가 지연 없이 매우 빠른 주기로 계산되어야 한다.22</li>
<li><strong>무결성 (Integrity):</strong> 시스템이 단순히 위치 추정치를 제공하는 것을 넘어, 그 추정치가 얼마나 신뢰할 수 있는지를 나타내는 ‘신뢰도’ 또는 ‘오차 경계’ 정보를 함께 제공하는 능력이다. 이는 안전이 최우선인 항공 분야에서 매우 중요한 요구사항으로, 시스템이 자신의 상태를 인지하고 위험한 상황을 스스로 판단할 수 있게 한다.</li>
</ul>
<p>이러한 요구사항들은 단일 기술만으로는 충족시키기 어려우며, 다양한 센서와 정교한 알고리즘, 그리고 신뢰할 수 있는 지도 정보가 결합될 때 비로소 달성될 수 있다.</p>
<h2>3.  항공 지도를 항법 참조 레이어로 활용</h2>
<h3>3.1  저고도 항공 지도의 구조</h3>
<p>자율 UAV 항법의 기반이 되는 지도 데이터는 신뢰할 수 있고, 표준화되어 있으며, 항법에 필요한 핵심 정보를 충분히 담고 있어야 한다. 이러한 조건을 가장 잘 만족시키는 것이 바로 항공 지도이다. 저고도 시계비행(VFR)을 하는 조종사들을 위해 제작된 이 지도들은 UAV 운용에 매우 유용한 정보를 제공한다. 주요 차트 유형은 다음과 같다.16</p>
<ul>
<li><strong>VFR Sectional Charts (항공 구역도):</strong> 1:500,000 축척으로 제작되며, 비교적 저속으로 비행하는 항공기를 위해 설계되었다.16 지형, 장애물, 공역, 항행안전시설 등 시각적 참조점(visual checkpoint)을 이용한 항법에 필요한 광범위한 정보를 포함하고 있어 UAV의 광역 비행 계획에 적합하다.17</li>
<li><strong>VFR Terminal Area Charts (TAC, 터미널 지역도):</strong> 1:250,000 축척으로, Class B와 같이 복잡하고 교통량이 많은 공역 주변을 더 상세하게 표현한다.16 건물, 지형, 장애물 등에 대한 더 자세한 정보를 제공하여 도심 지역과 같이 정밀한 항법이 요구되는 환경에서 필수적이다.</li>
<li><strong>En Route Low Altitude Charts:</strong> 계기비행(IFR)용 차트이지만, 18,000피트 미만의 저고도 항로, 통제 공역의 경계, 항행안전시설의 상세 정보(주파수, 좌표 등)를 포함하고 있어 디지털 지도 데이터베이스 구축 시 중요한 참조 자료가 될 수 있다.24</li>
</ul>
<h3>3.2  핵심 항법 데이터 추출</h3>
<p>UAV 자율 항법 시스템은 이 지도들로부터 기계가 해석할 수 있는 형태로 핵심 정보를 추출해야 한다. 미국 연방항공청(FAA)의 ’Aeronautical Chart User’s Guide’와 같은 문서는 이러한 정보 해석의 표준을 제공한다.27 UAV 항법에 특히 중요한 정보는 다음과 같다.</p>
<ul>
<li><strong>지형 및 장애물 (Terrain and Obstacles):</strong></li>
<li><strong>등고선 (Contour Lines):</strong> 지형의 높낮이를 나타내며, 3D 지형 모델(DEM) 생성의 기초 데이터가 된다.17</li>
<li><strong>최대고도지수 (Maximum Elevation Figure, MEF):</strong> 각 격자 사각형 내에서 가장 높은 지형지물이나 인공 장애물의 해발고도(MSL)를 표시하여, 해당 구역의 최소안전고도 설정을 돕는다.23</li>
<li><strong>장애물 기호:</strong> 송전탑, 빌딩, 안테나 등 인공 장애물은 특정 기호로 표시되며, 해발고도(MSL)와 지상고도(AGL)가 함께 명시된다. 야간 조명의 유무(lit/unlit) 또한 중요한 정보이다.30</li>
<li><strong>공역 (Airspace):</strong></li>
<li><strong>공역 등급:</strong> Class B, C, D, E 등의 공역은 각각 다른 색상(파란색, 자홍색)과 선 종류(실선, 파선)로 경계가 명확히 표시된다.23 각 공역의 수직 범위(상한 및 하한 고도)도 숫자로 명시되어 있어, UAV는 이 정보를 바탕으로 특정 공역의 진입 허가 필요 여부 및 비행 가능 고도를 판단해야 한다.</li>
<li><strong>특수목적공역 (Special Use Airspace, SUA):</strong></li>
<li><strong>비행금지구역 (Prohibited Area) 및 제한구역 (Restricted Area):</strong> 국가 안보나 공공 안전을 위해 비행이 금지되거나 엄격히 제한되는 구역으로, UAV 경로 계획 시 절대적으로 회피해야 할 영역이다.17</li>
<li><strong>군사작전구역 (Military Operations Area, MOA):</strong> 군사 훈련이 수행되는 구역으로, 비행 시 잠재적 위험이 있으므로 운용에 각별한 주의가 필요하다.31</li>
</ul>
<h3>3.3  자율 시스템을 위한 디지털 표현 및 통합</h3>
<p>전통적인 종이 지도는 인간 조종사가 시각적으로 해석하도록 설계되었다. 자율 UAV가 이를 활용하기 위해서는 지도의 정보를 구조화된 디지털 데이터로 변환하는 과정이 필수적이다. 이는 단순히 지도를 스캔하여 이미지 파일로 만드는 것을 넘어, 각 기호와 선이 가진 의미론적(semantic) 정보를 추출하는 것을 포함한다. 예를 들어, 지도 위의 파란색 실선은 ’Class B 공역의 경계’라는 속성과 함께 ’하한 고도 3000피트, 상한 고도 10000피트’라는 구체적인 데이터를 가진 객체로 변환되어야 한다.</p>
<p>이러한 변환 과정은 지도 제작과 로보틱스 기술의 융합을 요구한다. 최근에는 딥러닝 기반의 의미론적 분할(semantic segmentation) 기술을 사용하여 항공 지도 이미지로부터 자동으로 공역, 장애물, 지형 등의 객체를 인식하고 벡터 데이터로 추출하는 연구가 활발히 진행되고 있다.32</p>
<p>그러나 전통적인 항공 지도의 정적인 업데이트 주기(예: 56일)는 저고도 환경의 동적인 변화(예: 신규 건설 크레인, 임시 비행 제한 구역)를 실시간으로 반영하기 어렵다는 근본적인 한계를 가진다.27 이는 미래의 ’지도’가 정적인 파일이 아닌, 실시간으로 업데이트되는 동적 데이터베이스 서비스가 되어야 함을 시사한다. 이러한 서비스는 항공정보교환모델(Aeronautical Information Exchange Model, AIXM)과 같은 표준화된 데이터 형식을 기반으로 구축되어, 다양한 출처의 정보(고정 장애물, 임시 비행 제한, 실시간 교통 정보 등)를 통합하여 UAV에 제공하는 역할을 하게 될 것이다.34 결국, 항공 지도는 자율 항법을 위한 ’디지털 트윈’의 기초 레이어로 진화하게 될 것이다.</p>
<h2>4.  지도 기반 위치 추정 핵심 방법론</h2>
<p>UAV가 GNSS 없이 자신의 위치를 파악하기 위해 항공 지도 데이터를 활용하는 핵심 기술은 크게 영상 기반 절대 위치 추정과 지형 참조 항법으로 나눌 수 있다. 이 두 접근법은 서로 다른 원리와 센서를 사용하지만, 사전에 구축된 지도 정보와 실시간 센서 측정을 비교하여 위치를 결정한다는 공통점을 가진다.</p>
<h3>4.1  영상 기반 절대 위치 추정: 픽셀과 지도의 정합</h3>
<p>영상 기반 절대 위치 추정(Vision-Based Absolute Localization)은 UAV에 장착된 카메라로 촬영한 실시간 영상과, 지리 정보가 부여된 참조 지도(위성사진, 항공사진, 또는 디지털화된 항공 지도)를 비교하여 기체의 현재 위치와 자세를 추정하는 기술이다.35 이는 시각적 특징점(visual feature)을 기반으로 “내가 지금 보고 있는 이 장면이 지도의 어느 부분에 해당하는가?“라는 질문에 답하는 과정과 같다.37 초기에는 SIFT(Scale-Invariant Feature Transform)와 같은 전통적인 특징점 추출 및 정합 기법이 사용되었으나 8, UAV 영상(저고도, 사선 시점)과 참조 지도(고고도, 수직 시점) 간의 극심한 시점, 조명, 계절 변화로 인해 강건한 성능을 확보하기 어려웠다.36 이러한 문제를 해결하기 위해 최근 딥러닝 기반의 접근법들이 주류를 이루고 있다.</p>
<h4>4.1.1  계층적 정합과 의미론적 제약 조건</h4>
<p>최신 연구(arXiv:2506.09748)는 이 문제를 해결하기 위해 <strong>계층적 영상 정합(Hierarchical Image Matching)</strong> 방식을 제안한다.36 이 방식은 문제를 두 단계로 나누어 접근한다.</p>
<ol>
<li><strong>거친 정합 (Coarse Matching):</strong> 이 단계에서는 픽셀 수준의 저수준 특징 대신, DINOv2와 같은 강력한 비전 파운데이션 모델(Vision Foundation Model)을 사용하여 영상으로부터 ‘건물’, ‘도로’, ’숲’과 같은 고수준의 <strong>의미론적(semantic) 특징</strong>을 추출한다. 이러한 의미론적 정보는 시점이나 조명 변화에 상대적으로 둔감하여 매우 다른 두 영상 간에도 강건한 초기 대응 관계(영역 대 영역)를 설정할 수 있게 한다. 또한, 올바른 정합은 주변 이웃에서도 일관된 지지 정합을 가질 것이라는 **구조적 제약 조건(structural constraint)**을 4D 컨볼루션 레이어를 통해 적용하여, 유사한 의미를 가진 여러 후보 지역 사이의 모호성을 줄인다.36</li>
<li><strong>세밀한 정합 (Fine-grained Matching):</strong> 거친 정합을 통해 대략적인 위치 후보 영역이 식별되면, 이 좁혀진 영역 내에서 경량화된 컨볼루션 신경망(CNN)을 사용하여 정밀한 픽셀 수준의 특징점 정합을 수행한다. 이를 통해 최종 위치 추정의 정밀도를 수 미터 이내로 크게 향상시킨다.36</li>
</ol>
<p>이러한 계층적 접근법은 먼저 의미론적 이해를 통해 탐색 공간을 극적으로 줄이고, 그 후 정밀한 기하학적 정합을 수행함으로써, 기존 방식들이 겪었던 교차 소스(cross-source) 영상 정합의 근본적인 어려움을 효과적으로 해결한다.</p>
<h4>4.1.2  열악한 환경에서의 특징점 정합</h4>
<p>도심과 달리 특징점이 부족한 자연환경(“in the wild”)에서의 위치 추정은 또 다른 도전 과제이다. 연구(arXiv:2210.09727)에서는 이러한 환경에 대응하기 위해 딥러닝 기반의 특징점 추출기와 SuperGlue와 같은 그래프 신경망(GNN) 기반 정합기를 활용한다.38 SuperGlue는 극심한 시점 변화와 조명 조건에서도 특징점 간의 올바른 대응 관계를 찾아내는 데 탁월한 성능을 보여, 인공 구조물이 거의 없는 강, 숲 경계선 등의 자연 지형지물을 활용한 위치 추정을 가능하게 한다. 이 연구는 또한 드론의 방위각 정보를 이용해 실시간 영상을 참조 지도와 동일한 북쪽 방향으로 회전시켜 정합 성공률을 높이는 실용적인 기법도 제시한다.38 이는 전통적인 컴퓨터 비전 기법의 한계가 어떻게 딥러닝 기반의 새로운 패러다임으로 극복되고 있는지를 명확히 보여준다.</p>
<h3>4.2  지형 참조 항법 (Terrain Referenced Navigation, TRN)</h3>
<p>지형 참조 항법(TRN)은 영상 정보 대신 지형의 고도 정보를 활용하는 고전적이면서도 매우 강건한 항법 기술이다. 핵심 원리는 UAV에 장착된 고도계 센서로 비행 경로 하방의 지형 고도 프로파일을 실시간으로 측정한 후, 이 측정된 프로파일을 사전에 저장된 수치표고모델(Digital Elevation Model, DEM)과 비교하여 가장 일치하는 위치를 찾아내는 것이다.39 DEM은 현대 항공 정보 시스템의 핵심 데이터 레이어 중 하나로, 항공 지도의 등고선 정보를 기반으로 생성된다.</p>
<h4>4.2.1  TRN을 위한 센서 기술</h4>
<p>TRN의 성능은 지형 고도를 얼마나 정확하고 신뢰성 있게 측정하는지에 크게 좌우된다. 이를 위해 다양한 센서 기술이 활용된다.</p>
<ul>
<li><strong>밀리미터파(mmWave) 레이더:</strong> 최근 저가의 차량용 mmWave 레이더를 소형 드론에 적용한 TRN 연구가 주목받고 있다.39 레이더는 빛을 사용하지 않기 때문에 안개, 비, 어둠과 같은 악천후나 열악한 조명 조건에 거의 영향을 받지 않는다는 결정적인 장점을 가진다.39 또한, 지향성이 강한 빔을 사용하므로 재밍이나 스푸핑 공격에도 매우 강하다. 하지만, 호수나 빙원처럼 지형 변화가 거의 없는 평탄한 환경에서는 고도 프로파일의 특징이 사라져 성능이 급격히 저하되는 명확한 한계를 가진다.39</li>
<li><strong>영상 기반 TRN:</strong> 단안 카메라와 레이더 고도계를 결합하여 TRN을 구현하는 방식도 있다.43 연속된 두 영상 간의 호모그래피(homography) 관계를 분해하여 기체의 상대적인 이동 벡터를 추정하고, 이 이동 정보와 레이더 고도계로 측정한 지형 높이를 베이즈 필터(Bayesian filter)의 일종인 점질량 필터(Point-Mass Filter)를 통해 DEM과 융합하여 절대 위치를 추정한다.43</li>
<li><strong>라이다(LiDAR) 기반 TRN:</strong> 스캐닝 라이다를 사용하여 지상의 고해상도 3차원 점군(point cloud)을 직접 생성하고, 이를 참조 DEM과 정합하는 방식이다.8 매우 정밀한 지형 프로파일을 얻을 수 있지만, 라이다 센서 자체의 비용과 무게, 그리고 악천후에 대한 민감도가 고려되어야 한다.</li>
</ul>
<p>영상 기반 위치 추정과 TRN은 상호 보완적인 관계에 있다. 영상 기반 방식은 도로, 건물 등 2차원적인 시각적 특징이 풍부한 도심 환경에서 강점을 보이는 반면, TRN은 시각적 특징은 부족하지만 지형의 고저 변화가 뚜렷한 산악 지형에서 탁월한 성능을 발휘한다. 따라서 미래의 강건한 항법 시스템은 이 두 가지 방식을 상황에 따라 동적으로 전환하거나, 두 방식의 출력을 함께 융합하여 어떠한 환경에서도 안정적인 위치 정보를 제공하는 형태로 발전할 것이다.</p>
<h2>5.  상태 추정을 위한 고급 센서 융합 프레임워크</h2>
<p>4장에서 논의된 위치 추정 방법론들은 GNSS가 없는 환경에서 절대 위치를 제공할 수 있는 강력한 수단이지만, 각각의 한계를 지닌다. 영상 기반 위치 추정은 특정 질감이 없는(textureless) 표면 위에서는 실패할 수 있고, TRN은 평지에서 무력화된다. 또한, 이러한 기법들은 일반적으로 INS보다 낮은 주기(low frequency)로 위치 정보를 갱신한다. 따라서 단일 센서나 단일 알고리즘에 의존하는 대신, 여러 종류의 이종(heterogeneous) 센서 데이터를 융합하여 하나의 일관되고 강건한 상태 추정치를 생성하는 센서 융합(sensor fusion) 기술이 필수적이다.44</p>
<h3>5.1  이종 센서 데이터 융합의 필요성</h3>
<p>센서 융합의 핵심 철학은 각 센서의 장점을 취하고 단점을 보완하는 데 있다.</p>
<ul>
<li><strong>INS (관성항법장치):</strong> 수백 Hz의 높은 주기로 부드러운 움직임 정보를 제공하지만, 시간이 지남에 따라 오차가 누적된다.14</li>
<li><strong>기압계 (Barometer):</strong> 고도 정보를 제공하여 수직축의 드리프트를 억제하지만, 기압 변화에 민감하고 노이즈가 많다.44</li>
<li><strong>영상/TRN 기반 절대 위치:</strong> 낮은 주기로 갱신되지만, 드리프트가 누적되지 않는 절대 위치 정보를 제공하여 INS의 누적 오차를 주기적으로 보정(reset)하는 앵커(anchor) 역할을 한다.39</li>
</ul>
<p>이처럼 서로 다른 특성을 가진 센서 정보를 최적으로 결합함으로써, 시스템은 높은 갱신율과 장기적인 정확성을 동시에 달성하고, 일부 센서가 일시적으로 실패하더라도 안정적인 항법을 유지할 수 있다.</p>
<h3>5.2  확률적 필터링 기법 검토</h3>
<p>센서 융합은 주로 확률적 필터링(probabilistic filtering) 기법을 통해 구현된다. 이 기법들은 불확실성(uncertainty)을 수학적으로 모델링하고, 새로운 측정값이 들어올 때마다 확률적 추론을 통해 상태(위치, 속도, 자세 등)에 대한 믿음(belief)을 갱신한다.</p>
<ul>
<li><strong>확장 칼만 필터 (Extended Kalman Filter, EKF):</strong> EKF는 수십 년간 항법 분야의 표준 기술로 사용되어 온 강력한 필터이다.48 EKF는 ’예측(prediction)’과 ’수정(correction)’의 두 단계를 반복한다. 예측 단계에서는 INS 데이터를 이용해 현재 상태로부터 다음 시점의 상태를 예측한다. 수정 단계에서는 영상이나 TRN으로부터 얻은 절대 위치 측정값을 이용해 예측된 상태를 보정하고 불확실성을 줄인다.44 EKF는 계산적으로 효율적이지만, 비선형적인 시스템 모델을 선형화하여 근사하는 과정에서 오차가 발생할 수 있으며, 시스템의 비선형성이 매우 클 경우 필터가 발산(diverge)할 위험이 있다.50</li>
<li><strong>입자 필터 (Particle Filter, PF) / 몬테카를로 위치 추정 (MCL):</strong> 입자 필터는 비선형, 비가우시안(non-Gaussian) 문제에 대해 EKF보다 더 강건한 대안을 제공한다. 이 필터는 확률 분포를 여러 개의 가중치를 가진 ’입자(particle)’들의 집합으로 근사하여 표현한다.51 각 입자는 가능한 상태 가설(예: ‘드론은 A 지점에 있을 것이다’)을 나타낸다. 측정값이 들어오면, 각 입자는 그 측정값을 얼마나 잘 설명하는지에 따라 가중치가 재조정되고, 가중치가 높은 입자 주변으로 새로운 입자들이 재추출(resampling)된다. 이 과정은 UAV가 자신의 초기 위치를 전혀 모르는 전역 위치 추정(global localization) 문제나, 다중 경로가 심한 복잡한 환경에서 특히 효과적이다.39</li>
</ul>
<h3>5.3  하이브리드 및 AI 기반 융합 아키텍처</h3>
<p>최근 연구는 전통적인 필터링 기법의 한계를 극복하기 위해 인공지능(AI)을 결합한 하이브리드 아키텍처로 나아가고 있다. 이는 단순한 상태 추정을 넘어, 센서의 복잡한 오차 특성 자체를 학습하고 모델링하려는 시도이다.</p>
<ul>
<li><strong>연합 필터 아키텍처 (Federated Architecture):</strong> 여러 개의 독립적인 로컬 필터(local filter)가 병렬로 실행되고, 이들의 출력을 마스터 필터(master filter)가 융합하는 구조이다.46 예를 들어, 하나의 로컬 필터는 INS/GNSS를 융합하고, 다른 필터는 INS/Vision/Barometer를 융합할 수 있다. 이 구조는 모듈성이 뛰어나며, 하나의 센서 스트림(예: GNSS)이 완전히 실패하더라도 다른 필터가 계속 작동하여 전체 시스템의 강건성을 높인다.48</li>
<li><strong>AI 강화 필터링 (EKF+GRU):</strong> 연구(arXiv:2401.12784)에서 제안된 하이브리드 아키텍처는 EKF와 순환 신경망(RNN)의 일종인 GRU(Gated Recurrent Unit)를 결합한다.46 여기서 GRU 모델은 실제 비행 데이터를 통해 INS 센서의 복잡하고 시간에 따라 변하는 드리프트 패턴을 학습한다. 운용 중 GRU는 실시간 INS 데이터로부터 예측된 오차를 제거하여 ‘정화된(pre-cleaned)’ 움직임 정보를 EKF에 제공한다. 그 결과, GNSS 신호가 장시간 두절되더라도 시스템은 학습된 오차 모델에 기반하여 드리프트를 효과적으로 억제할 수 있다. 이는 단순한 물리 모델에 의존하는 고전적인 EKF에 비해 훨씬 뛰어난 복원력(resilience)을 보여준다.46</li>
<li><strong>LSTM-칼만 협력 구조:</strong> 유사한 접근법으로, LSTM(Long Short-Term Memory) 네트워크가 칼만 필터와 협력하여 비가우시안 노이즈에 적응적으로 대처하고 시스템 동역학을 더 정밀하게 모델링하는 연구도 있다.53 이는 물리 기반 모델(칼만 필터)과 데이터 기반 모델(AI)의 장점을 결합하여, 복잡하고 예측 불가능한 실제 환경에서 항법 성능을 극대화하려는 새로운 패러다임을 제시한다.</li>
</ul>
<p>다음 표는 본 장에서 논의된 내용을 바탕으로 주요 UAV 위치 추정 기술들의 특성을 종합적으로 비교 분석한 것이다.</p>
<p><strong>표 5.1: UAV 위치 추정 기술 비교 분석</strong></p>
<table><thead><tr><th>기술 분류</th><th>정확도</th><th>강건성 (날씨/조명/방해)</th><th>갱신율</th><th>최대 범위</th><th>비용/무게</th><th>전력 소모</th><th>핵심 강점</th><th>핵심 약점</th></tr></thead><tbody>
<tr><td><strong>GNSS</strong></td><td>높음 (수 m)</td><td>낮음 (차단, 다중경로, 재밍/스푸핑에 취약)</td><td>중간 (1-10 Hz)</td><td>전 지구</td><td>낮음</td><td>낮음</td><td>전역 절대 위치, 장기적 안정성</td><td>신호 음영 환경에서 사용 불가 9</td></tr>
<tr><td><strong>INS (저가형)</strong></td><td>낮음 (시간에 따라 누적 오차 급증)</td><td>매우 높음 (외부 영향 없음)</td><td>매우 높음 (100+ Hz)</td><td>제한 없음</td><td>매우 낮음</td><td>매우 낮음</td><td>고주파 단기 움직임 추정</td><td>단독 사용 시 드리프트 문제 14</td></tr>
<tr><td><strong>Vision-SLAM</strong></td><td>중간-높음</td><td>낮음 (조명, 날씨, 텍스처 부족에 민감)</td><td>높음 (30+ Hz)</td><td>제한적</td><td>낮음-중간</td><td>중간-높음</td><td>GNSS 없이 상대 경로 추적, 맵핑</td><td>누적 오차 발생, 루프 클로저 필요 54</td></tr>
<tr><td><strong>Vision-Absolute</strong></td><td>높음 (수 m 이내)</td><td>낮음 (조명, 날씨, 시점 변화에 민감)</td><td>낮음-중간</td><td>지도 범위 내</td><td>낮음-중간</td><td>중간-높음</td><td>드리프트 없는 절대 위치 제공</td><td>특징 없는 지역에서 실패, 계산량 많음 15</td></tr>
<tr><td><strong>TRN (레이더)</strong></td><td>중간-높음</td><td>매우 높음 (날씨, 조명, 방해에 강함)</td><td>중간</td><td>지도 범위 내</td><td>중간</td><td>중간</td><td>전천후 운용 가능, 높은 신뢰성</td><td>평지, 수면에서 성능 저하 39</td></tr>
<tr><td><strong>TRN (라이다)</strong></td><td>매우 높음</td><td>중간 (악천후에 민감)</td><td>높음</td><td>지도 범위 내</td><td>높음</td><td>높음</td><td>매우 정밀한 3D 지형 정보 획득</td><td>센서 비용 및 무게, 악천후 취약성 8</td></tr>
<tr><td><strong>UWB</strong></td><td>매우 높음 (수 cm)</td><td>높음 (다중경로에 강함)</td><td>높음</td><td>짧음 (&lt;100m)</td><td>중간</td><td>낮음</td><td>초정밀 단거리 상대 위치 측정</td><td>인프라(앵커) 필요, 범위 제한 15</td></tr>
</tbody></table>
<h2>6.  적용: 위치 추정에서 자율 항법으로</h2>
<p>정확하고 강건한 위치 추정은 자율 항법의 필요조건이지만, 충분조건은 아니다. UAV가 실제로 목표 지점까지 안전하게 비행하기 위해서는 추정된 위치 정보를 바탕으로 최적의 경로를 계획하고, 예기치 않은 장애물을 실시간으로 회피하는 고수준의 의사결정 기능이 필요하다. 항공 지도는 이러한 고수준 기능의 구현에도 핵심적인 역할을 수행한다.</p>
<h3>6.1  지도 정보를 활용한 경로 계획</h3>
<p>경로 계획(Path Planning)은 출발점에서 목표점까지 장애물과 비행 제한 구역을 피해 최적의 비행 경로를 생성하는 과정이다.2 항공 지도는 이 과정에 필요한 정적인 환경 정보를 제공하는 기본 지도가 된다.</p>
<h4>6.1.1  경로 계획 알고리즘</h4>
<p>UAV 경로 계획에는 다양한 알고리즘이 사용된다. 대표적인 알고리즘은 다음과 같다.</p>
<ul>
<li><strong>A* (A-star) 알고리즘:</strong> 환경을 격자(grid)로 나누고, 각 격자를 통과하는 비용을 계산하여 최단 경로를 탐색하는 그래프 탐색 알고리즘이다. 휴리스틱 함수를 사용하여 탐색 효율을 높인 것이 특징이다.34</li>
<li><strong>RRT (Rapidly-exploring Random Tree) 알고리즘:</strong> 복잡하고 고차원적인 공간에서 효율적으로 경로를 탐색하기 위해 사용되는 샘플링 기반 알고리즘이다. 무작위로 샘플점을 생성하고 기존 트리와 연결하는 방식으로 탐색 공간을 빠르게 확장한다. RRT*, DB-RRT* 등 다양한 변형 알고리즘이 존재한다.56</li>
</ul>
<h4>6.1.2  지도 기반 제약 조건 통합</h4>
<p>이러한 경로 계획 알고리즘의 성능은 얼마나 정확한 환경 정보를 입력받는지에 따라 결정된다. 디지털화된 항공 지도는 다음과 같은 핵심 제약 조건을 제공한다.</p>
<ul>
<li><strong>정적 장애물:</strong> 항공 지도에 표시된 건물, 송전탑, 산악 지형 등의 정보는 경로 계획 알고리즘의 탐색 공간에서 ‘통과 불가능한’ 또는 ‘매우 높은 비용을 가진’ 영역으로 설정된다.5 이를 통해 알고리즘은 물리적인 충돌을 원천적으로 회피하는 경로를 생성한다.</li>
<li><strong>비행금지구역 (No-Fly Zones, NFZs):</strong> 공항 주변, 원자력 발전소, 군사 시설 등 항공 지도에 명시된 비행금지구역 및 제한구역 정보는 경로 계획 시 반드시 회피해야 할 제약 조건으로 인코딩된다.61</li>
</ul>
<p>이러한 제약 조건의 효과적인 통합은 표준화된 데이터 형식에 크게 의존한다. 항공정보교환모델(Aeronautical Information Exchange Model, AIXM)은 공역, 장애물, 항로 등 모든 항공 정보를 구조화된 XML 형식으로 표현하기 위한 국제 표준이다.34 AIXM을 통해 UAV 시스템은 공식적인 출처로부터 제공된 안전 및 규제 정보를 일관된 방식으로 해석하고 경로 계획에 반영할 수 있다. 이는 개별 기업이 독자적인 데이터 파이프라인을 구축하는 비효율성을 제거하고, 상호운용성이 보장되는 안전한 자율 항법 생태계를 구축하는 데 필수적인 기반 기술이다.</p>
<h3>6.2  실시간 장애물 회피</h3>
<p>전역 경로 계획(global path planning)은 지도에 있는 정적 정보를 기반으로 최적의 경로를 생성하지만, 지도에 없는 동적 장애물(다른 드론, 새떼)이나 미처 파악되지 않은 장애물(최신 건설 구조물)에 대처할 수는 없다. 따라서 전역 경로를 따라 비행하면서 동시에 실시간으로 주변 환경을 감지하고 충돌을 회피하는 지역 장애물 회피(local obstacle avoidance) 기능이 반드시 필요하다.2</p>
<h4>6.2.1  전역 계획과 지역 감지의 융합</h4>
<p>일반적으로 자율 항법 시스템은 계층적 제어 구조를 가진다. 상위 레벨에서는 전역 경로 계획기가 지도 정보를 바탕으로 웨이포인트(waypoint)의 연속인 전역 경로를 생성한다. 하위 레벨의 지역 제어기는 이 전역 경로를 따라가되, 라이다나 심도 카메라(depth camera)와 같은 실시간 센서로 주변을 감지하여 임박한 충돌 위험이 발견되면 일시적으로 경로를 이탈하여 회피 기동을 수행한다. 안전이 확보되면 다시 원래의 전역 경로로 복귀하는 방식이다.5</p>
<h4>6.2.2  강화학습을 이용한 동적 회피</h4>
<p>최근에는 예측 불가능한 동적 환경에 더 효과적으로 대응하기 위해 강화학습(Reinforcement Learning)을 도입하는 연구가 활발하다. Q-러닝(Q-learning)과 같은 알고리즘을 사용하여 가상의 시뮬레이션 환경에서 드론 에이전트를 수없이 훈련시킨다.56 에이전트는 심도 카메라로부터 얻은 영상과 같은 상태(state) 정보를 입력받아, 회피를 위한 행동(action)을 출력하도록 학습된다. ’충돌 없이 목표 도달’과 같은 보상(reward)을 최대로 하는 방향으로 행동 정책(policy)이 최적화되므로, 훈련된 에이전트는 실제 비행 중에 마주치는 다양한 장애물에 대해 인간의 프로그래밍 없이도 효과적인 회피 기동을 수행할 수 있다.56</p>
<h2>7.  공개된 도전 과제 및 미래 연구 방향</h2>
<p>항공 지도 기반 항법 기술은 GNSS 음영 환경에서 UAV의 자율 비행을 위한 유망한 해결책을 제시하지만, 완전한 상용화와 대중화를 위해서는 여전히 해결해야 할 여러 도전 과제가 남아있다.</p>
<h3>7.1  동적 지도 문제: 실시간 업데이트와 데이터 동기화</h3>
<p>가장 근본적이고 시급한 도전 과제는 ’지도의 정적인 특성’을 극복하는 것이다. 전통적인 항공 지도는 56일과 같은 고정된 주기로 업데이트되지만 27, 저고도 도심 환경은 그보다 훨씬 빠르게 변한다. 갑자기 설치되는 건설 크레인, 주요 행사로 인해 임시로 설정되는 비행 제한 구역(TFR), 재난 현장 등은 정적 지도에 즉시 반영되지 않는다.66 한 달 전 지도를 보고 비행하는 드론은 지난주에 세워진 타워와 충돌할 수 있으며, 이는 용납할 수 없는 안전 위험이다.</p>
<p>따라서 미래의 항법 시스템은 다운로드 가능한 정적 파일을 참조하는 대신, 실시간으로 정보가 갱신되는 ‘살아있는 지도(live map)’ 서비스에 연결되어야 한다.67 이 서비스는 고정 장애물 데이터베이스, 항공고시보(NOTAM)와 TFR 피드, 심지어는 다른 UAV나 지상 인프라로부터 수집되는 실시간 교통 및 위험 정보를 통합해야 한다. 또한, 수많은 UAV가 이 동적 지도 데이터를 어떻게 일관성 있고 신뢰할 수 있게 동기화할 것인지에 대한 문제도 해결해야 할 중요한 기술적 과제이다.</p>
<h3>7.2  고도로 동적인 환경에서의 항법</h3>
<p>정적 지도를 넘어, 예측이 거의 불가능한 동적 객체들로 가득 찬 환경에서의 항법은 또 다른 차원의 문제이다. 갑자기 나타나는 새떼, 비협조적인 다른 항공기, 시시각각 변하는 돌풍 등은 현재의 경로 계획 및 회피 알고리즘으로는 완벽하게 대처하기 어렵다.68 이러한 환경에 대응하기 위해서는 다른 객체의 의도를 예측하는 고급 예측 모델링 기술과, 예측이 빗나갔을 때 즉각적으로 반응할 수 있는 초고속 반응형 계획(reactive planning) 알고리즘에 대한 심도 있는 연구가 필요하다.</p>
<h3>7.3  시뮬레이션 및 항법을 위한 디지털 트윈의 역할</h3>
<p>‘살아있는 지도’ 개념의 궁극적인 발전 형태는 바로 현실 세계를 매우 정밀하게 복제한 3차원 가상 공간, 즉 **디지털 트윈(Digital Twin)**이다.70 2차원적인 지도를 넘어, 건물과 지형의 3차원 형상, 재질, 실시간 환경 변화까지 모두 반영하는 디지털 트윈은 UAV 항법 기술 개발에 혁신적인 변화를 가져올 것이다.</p>
<ul>
<li><strong>시뮬레이션:</strong> AirSim, Gazebo와 같은 고충실도 시뮬레이터 내에 구축된 디지털 트윈은 항법 및 경로 계획 알고리즘을 개발하고 검증하기 위한 완벽한 테스트베드를 제공한다.65 수천, 수만 번의 가상 비행을 통해 실제 드론을 위험에 빠뜨리지 않고도 알고리즘의 성능을 극한까지 테스트하고 최적화할 수 있다.</li>
<li><strong>운용 참조 모델:</strong> 더 나아가, UAV는 비행 중에 이 디지털 트윈 자체를 기본 참조 지도로 사용할 수 있다. 2차원 지도보다 훨씬 풍부하고 정밀한 3차원 정보를 제공하므로, 영상 기반 위치 추정이나 TRN의 정확도를 획기적으로 향상시킬 수 있다.</li>
</ul>
<h3>7.4  신뢰성 있는 자율 항법을 위한 설명가능 인공지능 (XAI)</h3>
<p>항법 시스템이 딥러닝과 같은 복잡한 ‘블랙박스’ AI 모델에 점점 더 의존하게 되면서, 그 결정 과정을 이해하고 신뢰할 수 있는지의 문제가 중요하게 대두된다.72 특히 도심 상공에서 사람 위를 비행하기 위한 안전 인증을 획득하고 대중의 신뢰를 얻기 위해서는, 시스템이 “왜” 특정 경로를 선택했는지, 또는 “왜” 특정 회피 기동을 했는지를 인간이 이해할 수 있는 방식으로 설명할 수 있어야 한다.</p>
<p>설명가능 인공지능(Explainable AI, XAI)은 이러한 요구에 부응하는 기술이다.74 XAI 기술을 항법 시스템에 적용함으로써, 개발자는 모델의 오작동 원인을 파악하여 디버깅할 수 있고, 인증 기관은 시스템의 안전성을 검증할 수 있으며, 최종 사용자는 자율 시스템의 행동을 신뢰할 수 있게 된다.</p>
<p>이러한 미래 도전 과제들(동적 지도, 디지털 트윈, XAI)은 서로 분리된 것이 아니라 긴밀하게 연결되어 있다. 이는 미래의 항법 시스템이 기체에 탑재된 고립된 기능이 아니라, 실시간 데이터 네트워크에 지속적으로 연결되고, 고충실도 세계 모델을 기반으로 학습하며, 그 결정 과정을 투명하게 검증할 수 있는 하나의 거대한 ’인지 아키텍처(cognitive architecture)’로 진화할 것임을 시사한다.</p>
<h2>8.  결론</h2>
<h3>8.1  핵심 연구 결과 종합</h3>
<p>본 논문은 저고도 UAV의 안전하고 신뢰성 있는 자율 항법을 위해 항공 지도를 핵심 참조 데이터로 활용하는 다양한 기술들을 포괄적으로 검토했다. 분석 결과, GNSS는 도심 및 적대적 환경에서 명백한 취약성을 가지며, 이를 극복하기 위한 대안 항법 기술의 확보가 시급함을 확인했다. 항공 지도는 표준화되고 신뢰도 높은 정보를 담고 있어, GNSS에 의존하지 않는 절대 위치 추정을 위한 강력한 기반을 제공한다.</p>
<p>기술적 측면에서, 위치 추정 방법론은 전통적인 특징점 정합에서 벗어나, 시점과 환경 변화에 강건한 의미론적 특징을 활용하는 딥러닝 기반의 계층적 정합 방식으로 진화하고 있다. 또한, 영상 센서의 한계를 보완하는 레이더 및 라이다 기반의 지형 참조 항법(TRN) 기술이 전천후 운용을 위한 중요한 대안으로 부상하고 있다. 센서 융합 분야에서는 단순한 칼만 필터 구조를 넘어, 센서의 복잡한 오차 모델을 직접 학습하는 AI 기반 하이브리드 필터 아키텍처가 등장하여 항법 시스템의 강건성과 복원력을 한 차원 높은 수준으로 끌어올리고 있다. 이러한 기술적 진보는 정밀한 위치 추정을 가능하게 할 뿐만 아니라, 지도 정보를 제약 조건으로 활용하는 지능적인 경로 계획 및 실시간 장애물 회피를 통해 완전한 자율 항법으로 나아가는 길을 열어주고 있다.</p>
<h3>8.2  항공 지도 기반 항법의 효용성과 미래</h3>
<p>결론적으로, 항공 지도 기반 항법 기술은 GNSS의 대안을 넘어, 미래 도심 항공 모빌리티(UAM)와 무인 자율 시스템의 안전과 신뢰를 담보하는 핵심 요소 기술이다. 그러나 이 기술의 잠재력을 완전히 실현하기 위해서는 ’지도’의 개념 자체에 대한 패러다임 전환이 요구된다. 미래의 ’항공 지도’는 더 이상 정적인 인쇄물이나 파일이 아닐 것이다. 그것은 현실 세계의 물리적, 규제적, 동적 요소를 실시간으로 반영하는 고충실도의 <strong>디지털 트윈</strong>이 될 것이다.</p>
<p>UAV는 이 살아 숨 쉬는 디지털 트윈과 지속적으로 상호작용하며 자신의 위치를 파악하고, 최적의 행동을 계획하며, 예측하지 못한 위험에 대응하게 될 것이다. 이러한 비전을 실현하기 위해서는 실시간 데이터 처리, 고성능 컴퓨팅, 표준화된 데이터 교환 프로토콜, 그리고 무엇보다도 시스템의 결정을 신뢰하고 검증할 수 있게 하는 설명가능 AI(XAI) 기술에 대한 지속적인 연구와 투자가 필수적이다. 결국, 항공 지도를 기반으로 한 AI 기반 항법 시스템의 성숙도가 차세대 자율 항공 시스템의 성공을 결정짓는 척도가 될 것이다.</p>
<h2>9. 참고 자료</h2>
<ol>
<li>Improvement in the UAV position estimation with low-cost GPS, INS and vision-based system - arXiv, accessed July 1, 2025, https://arxiv.org/pdf/1807.06117</li>
<li>A Review of UAV Path-Planning Algorithms and Obstacle Avoidance Methods for Remote Sensing Applications - MDPI, accessed July 1, 2025, https://www.mdpi.com/2072-4292/16/21/4019</li>
<li>군사용 드론의 효과적 운용에 관한 연구, accessed July 1, 2025, https://koreascience.kr/article/JAKO202412757605795.pdf</li>
<li>UAVs Meet LLMs: Overviews and Perspectives Toward Agentic Low-Altitude Mobility - arXiv, accessed July 1, 2025, https://arxiv.org/html/2501.02341v1</li>
<li>An Obstacle Avoidance Approach for UAV Path Planning - GitHub, accessed July 1, 2025, https://raw.githubusercontent.com/Gabriel0010/l2ti/main/BashirN23a.pdf</li>
<li>An Autonomous Positioning Method for Drones in GNSS Denial Scenarios Driven by Real-Scene 3D Models - PubMed Central, accessed July 1, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC11722939/</li>
<li>드론 정밀 측위 기술 동향 - ETRI Electronics and Telecommunications Trends - 한국전자통신연구원, accessed July 1, 2025, <a href="https://ettrends.etri.re.kr/ettrends/202/0905202002/011-019.%20%EC%9D%B4%EC%A0%95%ED%98%B8_202%ED%98%B8.pdf">https://ettrends.etri.re.kr/ettrends/202/0905202002/011-019.%20%EC%9D%B4%EC%A0%95%ED%98%B8_202%ED%98%B8.pdf</a></li>
<li>Terrain Referenced Navigation Using SIFT Features in LiDAR Range-Based Data - DTIC, accessed July 1, 2025, https://apps.dtic.mil/sti/tr/pdf/ADA615027.pdf</li>
<li>Reliable GNSS Positioning in Urban Areas: A Key Technical Challenge for Drones and Self-Driving Cars - Spirent, accessed July 1, 2025, https://www.spirent.com/blogs/reliable-gnss-positioning-in-urban-areas-a-key-technical-challenge-for-drones-and-self-driving-cars</li>
<li>MAPPING GNSS RESTRICTED ENVIRONMENTS WITH A DRONE TANDEM AND INDIRECT POSITION CONTROL, accessed July 1, 2025, https://isprs-annals.copernicus.org/articles/IV-2-W3/1/2017/isprs-annals-IV-2-W3-1-2017.pdf</li>
<li>Resilient Navigation Alternatives for GNSS-Denied Environments - Inside GNSS - Global Navigation Satellite Systems Engineering, Policy, and Design, accessed July 1, 2025, https://insidegnss.com/resilient-navigation-alternatives-for-gnss-denied-environments/</li>
<li>UAV Navigation in GNSS-Denied Environment Using Radio Beacons and Onboard Sensor Fusion - DiVA portal, accessed July 1, 2025, http://www.diva-portal.org/smash/get/diva2:1893255/FULLTEXT01.pdf</li>
<li>GPS jamming &amp; interference map | Flightradar24, accessed July 1, 2025, https://www.flightradar24.com/data/gps-jamming</li>
<li>Enhanced Drone Navigation in GNSS Denied Environment Using VDM and Hall Effect Sensor - MDPI, accessed July 1, 2025, https://www.mdpi.com/2220-9964/8/4/169</li>
<li>A Comprehensive Survey on Short-Distance Localization of UAVs - MDPI, accessed July 1, 2025, https://www.mdpi.com/2504-446X/9/3/188</li>
<li>Aeronautical Charts - AOPA, accessed July 1, 2025, https://www.aopa.org/training-and-safety/students/crosscountry/special/aeronautical-charts</li>
<li>Sectional Symbols | Angle of Attack, accessed July 1, 2025, https://www.angleofattack.com/sectional-symbols/</li>
<li>무인/자율의 드론 운용을 위한 법적 과제와 전망, accessed July 1, 2025, https://repository.klri.re.kr/bitstream/2017.oak/9827/1/18079k.pdf</li>
<li>군사용 드론 현황 및 對드론대책 - BEMIL 군사세계, accessed July 1, 2025, https://bemil.chosun.com/nbrd/bbs/view.html?b_bbs_id=10008&amp;num=133</li>
<li>저고도 UAV를 위한 가상 공중도로 설계/제공/관리기술 개발 기획, accessed July 1, 2025, https://www.codil.or.kr/filebank/original/RK/OTKCRK210297/OTKCRK210297.pdf</li>
<li>무인비행장치의 안전운항을 위한 저고도 교통관리체계 개발 및 실증시험, accessed July 1, 2025, https://www.codil.or.kr/filebank/original/RK/OTKCRK230286/OTKCRK230286.pdf</li>
<li>A Comprehensive Survey on Short-Distance Localization of UAVs - ResearchGate, accessed July 1, 2025, https://www.researchgate.net/publication/389579861_A_Comprehensive_Survey_on_Short-Distance_Localization_of_UAVs</li>
<li>Understanding Sectional Charts for Remote Pilots - DroneTribe, accessed July 1, 2025, https://dronetribe.io/remote-pilot-sectional-charts/</li>
<li>En Route Low Altitude Chart - Sporty’s Pilot Shop, accessed July 1, 2025, https://www.sportys.com/en-route-low-altitude-chart.html</li>
<li>Section 1. Types of Charts Available - FAA, accessed July 1, 2025, https://www.faa.gov/air_traffic/publications/atpubs/aim_html/chap9_section_1.html</li>
<li>FAA IFR Enroute Low Altitude Charts | MG Pilot Shop - Marv Golden, accessed July 1, 2025, https://marvgolden.com/ifr-enroute-low-altitude-charts/</li>
<li>Aeronautical Chart Users’ Guide - FAA, accessed July 1, 2025, https://www.faa.gov/air_traffic/flight_info/aeronav/digital_products/aero_guide/</li>
<li>Faa Aeronautical Chart Users Guide - Free PDF Download, accessed July 1, 2025, https://www2.internationalinsurance.org/GR-8-08/Book?ID=dcv44-1468&amp;title=faa-aeronautical-chart-users-guide.pdf</li>
<li>Aeronautical Chart User’s Guide, Sixteenth Edition, accessed July 1, 2025, https://asa2fly.com/aeronautical-chart-users-guide-sixteenth-edition/</li>
<li>How To Read A VFR Sectional Chart | Cessna Chick, accessed July 1, 2025, https://cessnachick.files.wordpress.com/2013/10/howtoreadasectionalchart1.pdf</li>
<li>Aeronautical Chart Users’ Guide - Sheppard Air, accessed July 1, 2025, https://www.sheppardair.com/download/Aeronautical_Chart_Users_Guide_Oct23.pdf</li>
<li>SEMANTIC SEGMENTATION OF AERIAL IMAGES WITH AN ENSEMBLE OF CNNS, accessed July 1, 2025, https://ethz.ch/content/dam/ethz/special-interest/baug/igp/photogrammetry-remote-sensing-dam/documents/pdf/marmanis-isprs16.pdf</li>
<li>Deep semantic segmentation of unmanned aerial vehicle remote sensing images based on fully convolutional neural network - Frontiers, accessed July 1, 2025, https://www.frontiersin.org/journals/earth-science/articles/10.3389/feart.2023.1115805/epub</li>
<li>(PDF) A Helicopter Path Planning Method Based on AIXM Dataset - ResearchGate, accessed July 1, 2025, https://www.researchgate.net/publication/375569515_A_Helicopter_Path_Planning_Method_Based_on_AIXM_Dataset</li>
<li>Advanced Air Mobility를 위한 영상 기반 위치 추정 및 Geo-Referencing 기술 동향, accessed July 1, 2025, <a href="https://ettrends.etri.re.kr/ettrends/209/0905209001/001-009.%20%EC%B5%9C%EC%9D%98%ED%99%98_209%ED%98%B8%20%EC%B5%9C%EC%A2%85.pdf">https://ettrends.etri.re.kr/ettrends/209/0905209001/001-009.%20%EC%B5%9C%EC%9D%98%ED%99%98_209%ED%98%B8%20%EC%B5%9C%EC%A2%85.pdf</a></li>
<li>Hierarchical Image Matching for UAV Absolute Visual … - arXiv, accessed July 1, 2025, https://arxiv.org/abs/2506.09748</li>
<li>영상 기반 드론 식별 및 위치 표시 - AURIC, accessed July 1, 2025, http://journal.auric.kr/kiee/XmlViewer/f391084</li>
<li>Vision-based GNSS-Free Localization for UAVs in the Wild - arXiv, accessed July 1, 2025, https://arxiv.org/pdf/2210.09727</li>
<li>Drone-Based Radar Terrain-Referenced Navigation Using a Low-Cost Automotive-Class FMCW Radar to Enable GNSS-Denied Navigation - MDPI, accessed July 1, 2025, https://www.mdpi.com/2673-4591/88/1/11</li>
<li>Terrain referenced navigation | Download Scientific Diagram - ResearchGate, accessed July 1, 2025, https://www.researchgate.net/figure/Terrain-referenced-navigation_fig2_257581446</li>
<li>Terrain-Aided Navigation, accessed July 1, 2025, https://tangu.riotu-lab.org/</li>
<li>accessed January 1, 1970, <a href="http://docs.google.com/https.www.mdpi.com/2673-4591/88/1/11">https.www.mdpi.com/2673-4591/88/1/11</a></li>
<li>(PDF) Vision-based Terrain Referenced Navigation for Unmanned …, accessed July 1, 2025, https://www.researchgate.net/publication/257581446_Vision-based_Terrain_Referenced_Navigation_for_Unmanned_Aerial_Vehicles_using_Homography_Relationship</li>
<li>A method for UAV multi-sensor fusion 3D-localization under …, accessed July 1, 2025, https://cdnsciencepub.com/doi/10.1139/juvs-2018-0007</li>
<li>A Loosely Coupled Extended Kalman Filter Algorithm for … - Frontiers, accessed July 1, 2025, https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.849260/full</li>
<li>Resilient Multi-Sensor UAV Navigation with a Hybrid Federated …, accessed July 1, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC10857391/</li>
<li>Vision-Based Navigation Techniques for Unmanned Aerial Vehicles: Review and Challenges - City University of Hong Kong (Dongguan), accessed July 1, 2025, <a href="https://cityu-dg.primo.exlibrisgroup.com.cn/discovery/fulldisplay?docid=cdi_doaj_primary_oai_doaj_org_article_30b20524e1404efc80fd210aa739b5e9&amp;context=PC&amp;vid=86CITYU_DG:cityu_dg&amp;lang=en&amp;adaptor=Primo+Central&amp;tab=Everything&amp;query=sub,exact,+Hierarchies+,AND&amp;facet=citedby,exact,cdi_FETCH-LOGICAL-c3764-c9213de03351bd995ce0f9f21ec32e1b48bfcf402c684dbad7998529e07aa1fb3&amp;offset=0">https://cityu-dg.primo.exlibrisgroup.com.cn/discovery/fulldisplay?docid=cdi_doaj_primary_oai_doaj_org_article_30b20524e1404efc80fd210aa739b5e9&amp;context=PC&amp;vid=86CITYU_DG:cityu_dg&amp;lang=en&amp;adaptor=Primo%20Central&amp;tab=Everything&amp;query=sub%2Cexact%2C%20Hierarchies%20%2CAND&amp;facet=citedby%2Cexact%2Ccdi_FETCH-LOGICAL-c3764-c9213de03351bd995ce0f9f21ec32e1b48bfcf402c684dbad7998529e07aa1fb3&amp;offset=0</a></li>
<li>Enhanced UAV Tracking through Multi-Sensor Fusion and Extended Kalman Filtering - CEUR-WS, accessed July 1, 2025, https://ceur-ws.org/Vol-3900/Paper19.pdf</li>
<li>Extended Kalman Filter Sensor Fusion in Practice for Mobile Robot Localization - The Science and Information (SAI) Organization, accessed July 1, 2025, https://thesai.org/Downloads/Volume13No2/Paper_4-Extended_Kalman_Filter_Sensor_Fusion_in_Practice.pdf</li>
<li>(PDF) UAV Altitude Estimation Using Kalman Filter and Extended Kalman Filter, accessed July 1, 2025, https://www.researchgate.net/publication/377794988_UAV_Altitude_Estimation_Using_Kalman_Filter_and_Extended_Kalman_Filter</li>
<li>Multi-sensor fusion for robust indoor localization of industrial UAVs using particle filter, accessed July 1, 2025, https://www.researchgate.net/publication/383005052_Multi-sensor_fusion_for_robust_indoor_localization_of_industrial_UAVs_using_particle_filter</li>
<li>Performance Analysis of Localization Algorithms for Inspections in 2D and 3D Unstructured Environments Using 3D Laser Sensors and UAVs - MDPI, accessed July 1, 2025, https://www.mdpi.com/1424-8220/22/14/5122</li>
<li>LSTM-Kalman Filter-Based Multi-Sensor Signal Fusion for UAV Altitude Prediction in Non-Gaussian Environments | IIETA, accessed July 1, 2025, https://www.iieta.org/journals/ts/paper/10.18280/ts.420242</li>
<li>Exploring the best way for UAV visual localization under Low-altitude Multi-view Observation Condition: a Benchmark - arXiv, accessed July 1, 2025, https://arxiv.org/html/2503.10692v1</li>
<li>Path Planning for Autonomous Drones: Challenges and Future Directions - ResearchGate, accessed July 1, 2025, https://www.researchgate.net/publication/368944540_Path_Planning_for_Autonomous_Drones_Challenges_and_Future_Directions</li>
<li>Path Planning and Obstacle Avoidance of Formation Flight - PMC, accessed July 1, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC12030896/</li>
<li>(PDF) UAV Path Planning and Obstacle Avoidance Based on Reinforcement Learning in 3D Environments - ResearchGate, accessed July 1, 2025, https://www.researchgate.net/publication/367548783_UAV_Path_Planning_and_Obstacle_Avoidance_Based_on_Reinforcement_Learning_in_3D_Environments</li>
<li>Automated Flight Technology for Integral Path Planning and Trajectory Tracking of the UAV - MDPI, accessed July 1, 2025, https://www.mdpi.com/2504-446X/8/1/9</li>
<li>Flight Planning Tools - UgCS manual, accessed July 1, 2025, https://manuals-ugcs.sphengineering.com/docs/flight-planning-tools</li>
<li>Small UAV Flight Planning in Urban Environments, accessed July 1, 2025, https://ntrs.nasa.gov/api/citations/20210022208/downloads/20210022208_Xue_JAIS_manuscript_final.pdf</li>
<li>Ultimate Guide to Drone Flight Planning - From Concept to Execution - The Dronedesk Blog, accessed July 1, 2025, https://blog.dronedesk.io/drone-flight-planning/</li>
<li>GEO Zone Information - DJI FlySafe, accessed July 1, 2025, https://fly-safe.dji.com/nfz/nfz-query</li>
<li>Mission planning for complex structures - Helpdesk Portal, accessed July 1, 2025, https://agisoft.freshdesk.com/support/solutions/articles/31000157953-mission-planning-for-complex-structures</li>
<li>Coverage path planning for UAVs in search missions - DiVA portal, accessed July 1, 2025, http://www.diva-portal.org/smash/get/diva2:1880482/FULLTEXT01.pdf</li>
<li>UAV Path Planning and Obstacle Avoidance Based on Reinforcement Learning in 3D Environments - MDPI, accessed July 1, 2025, https://www.mdpi.com/2076-0825/12/2/57</li>
<li>Low-Signal Navigation for Drones - XRAY - GreyB, accessed July 1, 2025, https://xray.greyb.com/drones/drone-navigation-in-poor-signal-areas</li>
<li>Comprehensive Guide to the Latest UAS Regulatory Changes: Understanding and Adapting to New Rules - Datumate, accessed July 1, 2025, https://www.datumate.com/blog/new-regulatory-changes-for-us/</li>
<li>A Comprehensive Study of Recent Path-Planning Techniques in Dynamic Environments for Autonomous Robots - PMC - PubMed Central, accessed July 1, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC11679792/</li>
<li>Vision-Based Learning for Drones: A Survey - arXiv, accessed July 1, 2025, https://arxiv.org/html/2312.05019v2</li>
<li>Digital Twin Approaches and Strategies for Urban Planning - Esri Videos, accessed July 1, 2025, https://mediaspace.esri.com/media/t/1_7uu7uy62</li>
<li>A Survey of Open-Source UAV Autopilots - MDPI, accessed July 1, 2025, https://www.mdpi.com/2079-9292/13/23/4785</li>
<li>Explainable AI and monocular vision for enhanced UAV navigation in smart cities: prospects and challenges - Frontiers, accessed July 1, 2025, https://www.frontiersin.org/articles/10.3389/frsc.2025.1561404/full</li>
<li>Explainable Artificial Intelligence (XAI) 2.0 - arXiv, accessed July 1, 2025, https://arxiv.org/pdf/2310.19775</li>
<li>OD-XAI: Explainable AI-Based Semantic Object Detection for Autonomous Vehicles - MDPI, accessed July 1, 2025, https://www.mdpi.com/2076-3417/12/11/5310</li>
<li>What is XAI - Explainable AI and Visualization (Part 10) | by Parvez Kose - Medium, accessed July 1, 2025, https://medium.com/deepviz/what-is-xai-explainable-ai-and-visualization-part-10-da41c981c5fa</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>