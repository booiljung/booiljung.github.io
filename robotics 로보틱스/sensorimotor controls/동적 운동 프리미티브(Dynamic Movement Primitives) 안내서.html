<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:동적 운동 프리미티브(Dynamic Movement Primitives) 안내서</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>동적 운동 프리미티브(Dynamic Movement Primitives) 안내서</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">로봇공학 (Robotics)</a> / <a href="index.html">감각운동 제어(sensorimotor control)</a> / <span>동적 운동 프리미티브(Dynamic Movement Primitives) 안내서</span></nav>
                </div>
            </header>
            <article>
                <h1>동적 운동 프리미티브(Dynamic Movement Primitives) 안내서</h1>
<h2>1.  움직임의 원시(Primitive)를 찾아서</h2>
<h3>1.1  생물학적 운동 제어와 운동 프리미티브 이론</h3>
<p>인간을 포함한 생물학적 시스템은 놀라울 정도로 복잡하고 다양한 움직임을 민첩하고 유연하게 수행한다.1 우리는 걷거나, 물건을 잡거나, 글씨를 쓰는 등의 과업을 거의 무의식적으로 해낸다. 감각운동 제어(sensorimotor control) 분야의 연구자들은 오랫동안 이러한 능력의 근원을 이해하고 공식화하고자 노력해왔다.1 수많은 실험적 발견을 통해 지지되는 핵심적인 아이디어는, 생물학적 시스템이 ’운동 프리미티브(Motor Primitives)’라고 불리는 기본적인 운동 단위를 조합하고 변조하여 복잡한 과업을 수행한다는 이론이다.1 뇌가 모든 가능한 움직임을 개별적으로 저장하고 계획하는 것은 계산적으로 비효율적이기 때문에, 재사용 가능한 운동의 기본 구성 요소를 활용한다는 개념은 매우 설득력이 있다.4</p>
<p>운동 프리미티브 이론은 로봇 공학의 근본적인 질문, 즉 “어떻게 인공 시스템이 인간처럼 다재다능하고 창의적인 움직임을 수행할 수 있는가?“에 대한 중요한 실마리를 제공한다.1 이 이론의 핵심은 ’모듈성(modularity)’과 ’적응성(adaptability)’이다. 즉, 제한된 수의 기본 운동 모듈을 학습하고, 주어진 상황과 목표에 맞게 이 모듈들을 변형하고 조합하여 무한에 가까운 움직임을 생성해내는 원리이다. 동적 운동 프리미티브(DMP)는 바로 이 생물학적 제어의 원리를 공학적으로 재해석한 결과물이다. 이는 단순히 생물학적 현상을 표면적으로 모방하는 것을 넘어, 그 기저에 있는 원리를 안정적인 동역학계(dynamical system)라는 엄밀한 수학적 언어로 번역하려는 시도에서 출발한다. Ijspeert, Schaal 등의 선구적인 연구자들은 이 운동의 ’기본 블록’을 안정적인 비선형 동역학계로 정의함으로써, 생물학적 영감을 공학적으로 실현 가능하고 수학적으로 그 안정성이 보장되는 강력한 프레임워크로 구체화하였다.1</p>
<h3>1.2  동적 운동 프리미티브(DMP)의 개념과 로봇 공학에서의 중요성</h3>
<p>동적 운동 프리미티브(Dynamic Movement Primitives, DMP)는 운동 프리미티브 이론의 우아한 수학적 공식화(elegant mathematical formulation)로 정의할 수 있다.1 DMP는 특정 운동 궤적을 안정적인 비선형 미분 방정식의 집합으로 인코딩한다.1 이 동역학 시스템의 해(solution)가 바로 로봇이 따라야 할 운동 궤적이 된다. 지난 수십 년간 DMP는 모방 학습(Imitation Learning), 강화 학습(Reinforcement Learning), 최적 제어(Optimal Control), 물리적 상호작용(Physical Interaction), 그리고 인간-로봇 협업(Human-Robot Co-working)에 이르기까지 매우 광범위한 로봇 공학 분야에서 핵심적인 도구로 자리매김하였다.1</p>
<p>DMP가 이처럼 폭넓은 성공을 거둔 이유는 여러 가지 강력한 특성에서 기인한다. 첫째, 시스템의 구조상 주어진 목표점으로의 수렴이 수학적으로 보장된다. 둘째, 복잡하고 미묘한 인간의 움직임을 모사할 수 있을 만큼 충분한 표현력과 유연성을 갖추고 있다. 셋째, 동역학계의 특성상 예기치 않은 외부의 방해나 섭동(perturbation)에 실시간으로 반응하고 안정성을 유지할 수 있다. 마지막으로, 시연 데이터로부터 효율적인 알고리즘을 통해 학습될 수 있다.1 이러한 특성들은 DMP를 단순한 궤적 생성기를 넘어, 로봇이 환경과 상호작용하며 지능적인 행동을 학습하고 생성하기 위한 강력한 프레임워크로 만들었다.</p>
<h3>1.3  DMP 프레임워크의 핵심 철학: 안정성, 일반화, 강인성</h3>
<p>DMP의 설계 철학은 세 가지 핵심 키워드로 요약할 수 있다.</p>
<ul>
<li>
<p><strong>안정성(Stability):</strong> DMP가 생성하는 모든 움직임은 수학적으로 증명 가능한 동역학계의 끌개(attractor)로 수렴하도록 설계되었다.6 이는 로봇의 행동이 발산하거나 예측 불가능한 상태에 빠지지 않음을 보장하며, 특히 인간과 함께 작업하는 환경에서 안전성을 확보하는 데 매우 중요하다.8</p>
</li>
<li>
<p><strong>일반화(Generalization):</strong> DMP의 가장 강력한 특징 중 하나는 일반화 능력이다. 단 한 번의 시연으로부터 학습된 움직임의 고유한 ’형태(shape)’는 유지하면서, 새로운 시작점, 목표점, 또는 다른 실행 속도에 맞게 궤적을 즉시 변형하여 생성할 수 있다.9 이는 매번 새로운 상황에 대해 처음부터 다시 계획하거나 학습할 필요 없이, 기존의 지식을 새로운 과업에 유연하게 적용할 수 있게 해준다.</p>
</li>
<li>
<p><strong>강인성(Robustness):</strong> DMP는 내재된 끌개 동역학(attractor dynamics) 덕분에 외부 섭동에 대해 강인하다.12 로봇이 궤적을 따라 움직이는 도중 예기치 않은 외력에 의해 경로를 이탈하더라도, 시스템은 즉시 원래의 궤적과 목표점을 향해 복귀하려는 힘을 생성한다. 이는 정적으로 계획된 경로를 단순히 추종하는 방식에 비해 동적인 실제 환경에서 훨씬 더 신뢰성 높은 행동을 가능하게 한다.13</p>
</li>
</ul>
<h2>2.  DMP의 수학적 구조: 동역학계 해부</h2>
<p>DMP 프레임워크는 세 가지 핵심적인 수학적 구성 요소의 상호작용으로 이루어진다: (1) 변환 시스템(Transformation System), (2) 정규 시스템(Canonical System), (3) 비선형 강제항(Nonlinear Forcing Term). 이 세 요소가 결합하여 안정적이면서도 복잡한 궤적을 생성하는 동역학계를 형성한다.</p>
<h3>2.1  변환 시스템(Transformation System): 스프링-댐퍼 모델 기반의 목표점 수렴 동역학</h3>
<p>변환 시스템은 DMP의 근간을 이루는 동역학계로, 목표점 <span class="math math-inline">g</span>를 향해 안정적으로 수렴하는 2차 미분방정식으로 기술된다. 이 시스템은 물리적으로 임계 감쇠(critically damped) 상태의 스프링-댐퍼 시스템으로 해석될 수 있다.12 즉, 목표점을 향해 진동 없이 가장 빠르게 수렴하는 움직임을 기본 행동으로 정의한다. 1차 미분방정식 형태로 표현하면 다음과 같다.12</p>
<p><span class="math math-display">
\tau \dot{z} = K(g - y) - D z
\tau \dot{y} = z
</span><br />
여기서 <span class="math math-inline">y</span>는 시스템의 위치, <span class="math math-inline">z</span>는 시스템의 속도(시간에 대해 스케일링된), <span class="math math-inline">g</span>는 목표점(끌개), <span class="math math-inline">K</span>는 스프링 상수, <span class="math math-inline">D</span>는 감쇠 계수를 나타낸다. <span class="math math-inline">\tau</span>는 전체 시스템의 시간적 스케일을 조절하는 시간 상수이다.</p>
<p>이 변환 시스템은 DMP의 ’안전망’과 같은 역할을 수행한다. 로봇 제어에서 가장 중요한 요소 중 하나는 예측 가능성과 안정성인데, 스프링-댐퍼 시스템은 물리학적으로 안정성이 보장된 가장 단순한 목표점 수렴 모델이다. DMP는 이 안정적인 시스템을 기본값(default)으로 설정하고, 여기에 학습 가능한 비선형 항을 ‘덧붙이는’ 구조를 취한다.12 만약 학습된 비선형 항이 0이 되거나 예측 불가능한 값을 생성하더라도, 시스템의 기본 동역학은 항상 안정적인 목표점을 향해 회귀하려는 성질을 잃지 않는다. 이는 학습 기반 시스템이 가질 수 있는 예측 불가능성을 근본적으로 제어하는 강력한 귀납적 편향(inductive bias)으로 작용하여 ’안전한 학습’을 가능하게 하는 핵심적인 설계 철학이라 할 수 있다.</p>
<h3>2.2  정규 시스템(Canonical System): 시간 독립성을 위한 위상 변수(Phase Variable)</h3>
<p>DMP의 중요한 특징 중 하나는 시간에 직접적으로 의존하지 않는다는 점이다. 이는 정규 시스템이라는 별도의 동역학계를 통해 달성된다.9 정규 시스템은 실제 시간</p>
<p><span class="math math-inline">t</span>를 대체하여 시스템의 진행 상태를 나타내는 단조적으로 변화하는 ‘위상 변수(phase variable)’ <span class="math math-inline">s</span> (문헌에 따라 <span class="math math-inline">x</span> 또는 <span class="math math-inline">\theta</span>로 표기되기도 함)를 생성한다.</p>
<p>이산적(discrete) 운동을 위한 DMP에서 정규 시스템은 일반적으로 다음과 같은 간단한 1차 미분방정식으로 정의된다.9</p>
<p><span class="math math-display">
\tau \dot{s} = -\alpha_s s
</span><br />
이 방정식의 해는 초기값 <span class="math math-inline">s(0)=1</span>에서 시작하여 0으로 지수적으로 감쇠한다. <span class="math math-inline">\alpha_s</span>는 감쇠 속도를 결정하는 양의 상수이다. 이 위상 변수 <span class="math math-inline">s</span>는 움직임의 시작부터 끝까지의 ’진행률’을 나타내는 내부적인 시계 역할을 한다. 변환 시스템에 추가될 비선형 강제항은 이 위상 변수 <span class="math math-inline">s</span>의 함수로 정의됨으로써, 전체 시스템이 실제 시간 <span class="math math-inline">t</span>로부터 독립성을 갖게 된다. 이는 움직임의 속도를 조절하거나(시간적 스케일링) 외부 신호에 동기화하는 것을 매우 용이하게 만든다.12</p>
<h3>2.3  비선형 강제항(Nonlinear Forcing Term): 궤적 형태를 조각하는 학습 가능한 요소</h3>
<p>단순한 스프링-댐퍼 시스템은 직선 또는 부드러운 곡선 형태의 단조로운 움직임만을 생성할 수 있다. 인간의 움직임처럼 복잡하고 미묘한 형태의 궤적을 만들기 위해, 변환 시스템에 비선형 강제항 <span class="math math-inline">f(s)</span>가 추가된다.12 이 강제항은 기본 스프링-댐퍼 시스템을 ’방해(perturb)’하여 원하는 형태의 궤적을 ’조각(shape)’하는 역할을 한다.</p>
<p>강제항은 일반적으로 정규화된 가우시안 기저 함수(Gaussian Basis Functions)들의 선형 조합으로 모델링된다.12</p>
<p><span class="math math-display">
f(s) = \frac{\sum_{i=1}^{N} w_i \psi_i(s)}{\sum_{i=1}^{N} \psi_i(s)} s
</span><br />
여기서 <span class="math math-inline">w_i</span>는 학습을 통해 결정되는 조절 가능한 가중치(weight)이며, <span class="math math-inline">\psi_i(s)</span>는 가우시안 기저 함수이다.</p>
<p><span class="math math-display">
\psi_i(s) = \exp(-h_i(s - c_i)^2)
</span><br />
<span class="math math-inline">c_i</span>는 <span class="math math-inline">i</span>번째 기저 함수의 중심(center)이고 <span class="math math-inline">h_i</span>는 폭(width)을 결정하는 상수이다. 각 기저 함수는 위상 변수 <span class="math math-inline">s</span>가 특정 값(<span class="math math-inline">c_i</span>)을 지날 때 활성화되어, 해당 구간에서 궤적의 형태에 영향을 미친다. 이 구조의 가장 큰 장점은 복잡한 비선형 함수 <span class="math math-inline">f(s)</span>가 학습 파라미터인 가중치 <span class="math math-inline">w_i</span>에 대해 선형(linear in parameters)이라는 점이다. 이는 효율적인 선형 회귀 기법을 통해 가중치를 쉽게 학습할 수 있게 해준다.4</p>
<p>최종적으로 이 강제항을 변환 시스템에 통합하면, 이산적 DMP의 완전한 형태는 다음과 같이 표현된다.12</p>
<p><span class="math math-display">
\tau \dot{z} = K(g - y) - D z + (g - y_0) f(s)
</span><br />
여기서 <span class="math math-inline">(g - y_0)</span> 항은 시작점(<span class="math math-inline">y_0</span>)과 목표점(<span class="math math-inline">g</span>) 사이의 거리에 비례하여 강제항의 크기를 조절하는 공간 스케일링(spatial scaling) 역할을 한다. 위상 변수 <span class="math math-inline">s</span>가 0에 가까워지면 강제항 <span class="math math-inline">f(s)</span>도 0으로 수렴하므로, 움직임의 끝에서는 강제항의 영향이 사라지고 시스템은 다시 순수한 스프링-댐퍼 동역학에 따라 안정적으로 목표점 <span class="math math-inline">g</span>에 수렴하게 된다.</p>
<h2>3.  DMP의 유형별 공식과 특성</h2>
<p>DMP는 생성하고자 하는 움직임의 종류에 따라 크게 이산적(discrete) DMP와 율동적(rhythmic) DMP로 나뉜다. 두 유형은 변환 시스템의 기본 구조를 공유하지만, 정규 시스템과 강제항의 형태에서 결정적인 차이를 보인다.</p>
<h3>3.1  이산적 운동(Discrete Movements) DMP: 점대점 궤적 생성</h3>
<p>이산적 DMP는 시작점에서 목표점까지 한 번의 움직임으로 끝나는 과업, 즉 점대점(point-to-point) 운동을 모델링하는 데 사용된다.12 예를 들어, 로봇 팔이 특정 위치의 물체를 향해 뻗는 동작, 컵을 들어 다른 곳으로 옮기는 동작 등이 이에 해당한다.</p>
<p>이산적 DMP의 정규 시스템은 앞서 설명한 바와 같이 지수적으로 감쇠하는 모델을 사용한다.</p>
<p><span class="math math-display">
\tau \dot{s} = -\alpha_s s
</span><br />
위상 변수 <span class="math math-inline">s</span>가 1에서 시작하여 0으로 수렴함에 따라, <span class="math math-inline">s</span>에 비례하는 강제항 <span class="math math-inline">f(s)</span>의 영향력은 움직임이 진행될수록 점차 감소한다. 움직임의 종반부에 <span class="math math-inline">s \approx 0</span>이 되면 강제항의 효과는 거의 사라지고, 시스템은 변환 시스템의 기본 동역학에 의해 안정적으로 목표점 <span class="math math-inline">g</span>로 수렴하는 것이 보장된다.12</p>
<h3>3.2  율동적 운동(Rhythmic Movements) DMP: 주기적 궤적 생성</h3>
<p>율동적 DMP는 걷기, 북치기, 톱질, 표면 닦기 등과 같이 지속적으로 반복되는 주기적인 움직임을 모델링하는 데 적합하다.16</p>
<p>율동적 DMP의 가장 큰 특징은 정규 시스템에 있다. 지수적으로 소멸하는 위상 변수 대신, 율동적 DMP는 일정한 속도로 계속해서 순환하는 위상 발진기(phase oscillator)를 정규 시스템으로 사용한다.16</p>
<p><span class="math math-display">
\tau \dot{\phi} = 1
</span><br />
여기서 <span class="math math-inline">\phi \in [0, 2\pi]</span>는 주기적인 위상 각도를 나타낸다. 이 위상 <span class="math math-inline">\phi</span>는 결코 0으로 수렴하지 않고 계속해서 순환하기 때문에, 이에 의존하는 강제항 역시 주기적인 패턴을 반복적으로 생성하게 된다.</p>
<p>강제항 <span class="math math-inline">f</span>는 위상 <span class="math math-inline">\phi</span>에 의존하는 주기적인 기저 함수를 사용하며, 일반적으로 폰 미제스 기저 함수(Von Mises basis functions)가 사용된다. 또한, 진동의 진폭(amplitude) <span class="math math-inline">r</span>에 의해 그 크기가 조절된다.16</p>
<p><span class="math math-display">
f(\phi, r) = \frac{\sum_{i=1}^{N} w_i \Psi_i(\phi)}{\sum_{i=1}^{N} \Psi_i(\phi)} r
</span><br />
여기서 기저 함수 <span class="math math-inline">\Psi_i</span>는 다음과 같이 정의된다.</p>
<p><span class="math math-display">
\Psi_i = \exp(h_i(\cos(\phi - c_i) - 1))
</span><br />
이러한 구조 덕분에 율동적 DMP는 안정적인 극한 주기 궤도(limit cycle)를 형성하며, 진폭 <span class="math math-inline">r</span>과 주기 <span class="math math-inline">\tau</span>를 실시간으로 변경하여 움직임의 크기와 속도를 유연하게 조절할 수 있다.</p>
<h3>3.3  이산적 DMP와 율동적 DMP의 비교</h3>
<p>두 DMP 유형의 차이점을 명확히 이해하기 위해 핵심 공식을 비교하면 다음과 같다.</p>
<table><thead><tr><th>구성 요소</th><th>이산적(Discrete) DMP</th><th>율동적(Rhythmic) DMP</th><th>핵심 통찰</th></tr></thead><tbody>
<tr><td><strong>변환 시스템</strong></td><td><span class="math math-inline">\tau \dot{z} = K(g - y) - D z + (g - y_0) f(s)</span></td><td><span class="math math-inline">\tau \dot{z} = K(g - y) - D z + f(\phi, r)</span></td><td>기본 동역학은 동일하나, 강제항의 입력 소스가 다르다. <span class="math math-inline">g</span>는 각각 ’최종 목표점’과 ’진동 중심점’으로 해석된다.</td></tr>
<tr><td><strong>정규 시스템</strong></td><td><span class="math math-inline">\tau \dot{s} = -\alpha_s s</span></td><td><span class="math math-inline">\tau \dot{\phi} = 1</span></td><td><strong>소멸하는(decaying) 위상</strong> vs. <strong>순환하는(oscillating) 위상</strong>. 이것이 두 DMP 유형의 근본적인 행동 차이를 결정한다.</td></tr>
<tr><td><strong>강제항 <span class="math math-inline">f</span></strong></td><td><span class="math math-inline">f(s) = \frac{\sum w_i \psi_i(s)}{\sum \psi_i(s)} s</span></td><td><span class="math math-inline">f(\phi, r) = \frac{\sum w_i \Psi_i(\phi)}{\sum \Psi_i(\phi)} r</span></td><td>시간에 따라 소멸하는 가우시안 기저 함수 vs. 위상에 따라 반복되는 Von Mises 기저 함수.</td></tr>
<tr><td><strong>주요 목적</strong></td><td>점대점(Point-to-point) 운동</td><td>주기적(Periodic) 운동</td><td>시스템의 근본적인 구조(정규 시스템)가 생성되는 움직임의 종류(이산적/율동적)를 결정한다.</td></tr>
</tbody></table>
<p>이 비교를 통해 두 DMP 유형이 동일한 철학(안정적인 동역학계 + 학습 가능한 강제항)을 공유하면서도, 정규 시스템의 동역학적 특성을 다르게 설계함으로써 근본적으로 다른 종류의 움직임을 생성해냄을 알 수 있다. 이는 DMP 프레임워크의 모듈성과 확장성을 잘 보여주는 예이다.</p>
<h2>4.  시연으로부터 움직임 학습하기</h2>
<p>DMP의 가장 실용적인 측면 중 하나는 인간의 시연(demonstration)으로부터 복잡한 움직임을 쉽게 학습할 수 있다는 점이다. 학습의 목표는 시연된 궤적을 가장 잘 재현하는 비선형 강제항 <span class="math math-inline">f</span>의 가중치 벡터 <span class="math math-inline">w</span>를 찾는 것이다. 이를 위해 주로 지도 학습(Supervised Learning) 방식이 사용되지만, 특정 과업에 대한 성능을 최적화하기 위해 강화 학습(Reinforcement Learning) 방식도 활발히 적용된다.</p>
<h3>4.1  지도 학습 기반 접근: 국소 가중 회귀(LWR)를 이용한 강제항 가중치 추정</h3>
<p>지도 학습 기반의 접근법은 시연된 궤적 데이터를 이용하여 강제항의 목표 형태를 직접 계산하고, 이를 가장 잘 근사하는 가중치를 찾는 방식으로 이루어진다.</p>
<ol>
<li>
<p><strong>데이터 수집:</strong> 먼저, 인간 교사가 로봇을 직접 움직여주거나(kinesthetic teaching) 모션 캡처 시스템을 이용하여 시연 궤적 데이터(<span class="math math-inline">y_d(t)</span>)를 수집한다. 수치 미분을 통해 속도(<span class="math math-inline">\dot{y}_d(t)</span>)와 가속도(<span class="math math-inline">\ddot{y}_d(t)</span>) 데이터를 계산한다.12</p>
</li>
<li>
<p><strong>목표 강제항 계산:</strong> 수집된 궤적 데이터를 변환 시스템 방정식에 대입하여, 해당 궤적을 생성하기 위해 필요했던 목표 강제항 <span class="math math-inline">f_{target}</span>을 각 시간 스텝마다 역으로 계산한다.12 이산적 DMP의 경우, 식은 다음과 같이 정리된다.</p>
<p><span class="math math-display">
f_{target}(s) = \frac{\tau^2 \ddot{y}_d + D \tau \dot{y}_d - K(g - y_d)}{g - y_0}
</span><br />
여기서 <span class="math math-inline">g</span>는 시연 궤적의 최종점 <span class="math math-inline">y_d(T)</span>, <span class="math math-inline">y_0</span>는 시작점 <span class="math math-inline">y_d(0)</span>로 설정된다.12</p>
</li>
<li>
<p><strong>가중치 학습:</strong> 이제 <span class="math math-inline">f_{target}(s)</span>를 기저 함수의 가중합 <span class="math math-inline">\frac{\sum w_i \psi_i(s)}{\sum \psi_i(s)} s</span>로 근사하는 문제가 된다. 이는 가중치 <span class="math math-inline">w_i</span>에 대한 선형 회귀 문제이며, 국소 가중 회귀(Locally Weighted Regression, LWR)라는 효율적인 알고리즘을 통해 해결할 수 있다.17 LWR은 각 데이터 포인트에 대해 오차를 계산할 때, 해당 포인트 주변의 기저 함수 활성화 값(<span class="math math-inline">\psi_i(s)</span>)을 가중치로 사용하여 회귀를 수행한다. 즉, <span class="math math-inline">i</span>번째 기저 함수가 크게 활성화되는 구간의 데이터가 <span class="math math-inline">w_i</span>를 결정하는 데 더 큰 영향을 미치도록 하는 방식이다.8 이 방법은 단 한 번의 시연만으로도 비선형적인 궤적을 빠르고 안정적으로 학습할 수 있다는 큰 장점을 가진다.</p>
</li>
</ol>
<h3>4.2  강화 학습 기반 접근: 시행착오를 통한 파라미터 최적화</h3>
<p>지도 학습이 시연을 충실히 ’모방’하는 데 중점을 두는 반면, 강화 학습(RL)은 특정 과업의 성공 여부를 나타내는 보상 함수(reward function)를 최대화하도록 움직임을 ’개선’하고 최적화하는 데 사용된다.8</p>
<p>DMP 프레임워크는 강화 학습의 정책(policy)을 표현하는 데 매우 효과적인 구조를 제공한다. 고차원 로봇의 관절 토크나 속도를 매 시간 스텝마다 직접 결정하는 대신, RL 에이전트는 상대적으로 저차원인 DMP의 가중치 벡터 <span class="math math-inline">w</span>만을 학습하면 된다. <span class="math math-inline">w</span>가 결정되면 전체 궤적은 DMP 동역학 시스템에 의해 자동으로 생성된다.8</p>
<p>이러한 접근 방식은 강화 학습의 고질적인 문제인 ’탐색 공간의 저주(curse of dimensionality)’를 완화하는 데 매우 효과적이다. RL 에이전트가 탐색해야 할 파라미터의 수가 수천, 수만 개의 개별 행동 시퀀스에서 수십, 수백 개의 DMP 가중치로 급격히 줄어들기 때문이다. 또한, DMP가 생성하는 궤적은 기본적으로 부드럽고 안정적이며 목표점으로 수렴하는 특성을 가지므로, 에이전트는 물리적으로 불가능하거나 위험한 행동을 탐색할 가능성이 현저히 낮아진다. 즉, DMP는 강화 학습에 유용한 사전 지식(prior) 또는 구조적 편향(structural bias)을 제공하여, 학습의 효율성과 안정성을 극적으로 향상시키는 역할을 한다.4 이는 DMP가 단순한 궤적 생성기를 넘어, 강화 학습과 같은 고급 학습 알고리즘의 핵심 구성 요소로 활용될 수 있음을 보여준다.</p>
<h2>5.  DMP의 핵심 능력: 일반화와 변조</h2>
<p>DMP의 가장 강력한 장점은 한 번 학습된 움직임을 새로운 상황에 맞게 유연하게 변형하고 조절하는 능력, 즉 일반화(generalization)와 변조(modulation)에 있다. 이는 학습된 가중치 <span class="math math-inline">w</span>를 수정하지 않고도 가능하다.</p>
<h3>5.1  공간적 스케일링: 새로운 시작점과 목표점에 대한 궤적 변형</h3>
<p>학습된 DMP는 시작점 <span class="math math-inline">y_0</span>와 목표점 <span class="math math-inline">g</span>를 새로운 값으로 변경하는 것만으로 궤적의 전반적인 형태는 유지하면서 공간적으로 스케일링된 새로운 궤적을 즉시 생성할 수 있다.10 예를 들어, 시연보다 두 배 먼 목표점을 설정하면, 궤적의 형태는 비슷하지만 전체적으로 두 배 더 큰 움직임이 생성된다.10 이는 변환 시스템의 <span class="math math-inline">K(g - y)</span> 항이 새로운 목표점을 향한 끌개를 형성하고, 강제항의 <span class="math math-inline">(g - y_0)</span> 항이 움직임의 전체적인 진폭을 조절하기 때문에 가능하다.10</p>
<p>하지만 이 고전적인 스케일링 방식에는 몇 가지 문제점이 존재한다. 예를 들어, 시작점과 목표점이 같으면(<span class="math math-inline">g = y_0</span>) 강제항이 0이 되어 움직임이 시작되지 않거나, <span class="math math-inline">g - y_0</span>의 크기가 매우 작으면 강제항이 과도하게 증폭되어 비정상적인 가속도를 유발할 수 있다.12 이러한 문제를 해결하기 위해 다음과 같이 수정된 변환 시스템이 제안되었다.12</p>
<p><span class="math math-display">
\tau \dot{v} = K(g - x) - Dv - K(g - x_0)s + K f(s)
</span><br />
이 공식에서는 강제항 <span class="math math-inline">f(s)</span>가 더 이상 <span class="math math-inline">(g - y_0)</span>에 의해 직접 스케일링되지 않아 안정성이 향상되지만, 반대로 공간적 일반화 능력이 다소 저하될 수 있다는 단점이 있다.25</p>
<h3>5.2  시간적 스케일링: 움직임 속도 및 기간 조절</h3>
<p>DMP 궤적의 실행 속도는 시간 상수 <span class="math math-inline">\tau</span>를 조절하여 쉽게 변경할 수 있다.11</p>
<p><span class="math math-inline">\tau</span> 값을 증가시키면 정규 시스템과 변환 시스템의 진행 속도가 모두 느려져 전체 움직임이 더 오랜 시간에 걸쳐 수행되고, <span class="math math-inline">\tau</span> 값을 감소시키면 움직임이 더 빨라진다. 중요한 점은 <span class="math math-inline">\tau</span>의 변경이 궤적의 공간적 형태에는 영향을 주지 않는다는 것이다.10 이 특성은 로봇이 작업 환경의 속도에 맞춰 자신의 움직임을 조절해야 할 때 매우 유용하다.</p>
<h3>5.3  쿼터니언을 이용한 3차원 방향(Orientation) 제어</h3>
<p>기본적인 DMP 공식은 로봇 엔드 이펙터의 위치(position)와 같이 유클리드 공간(Euclidean space)에 정의된 변수를 다루는 데 적합하다. 그러나 로봇 조작 작업에서는 위치뿐만 아니라 3차원 공간에서의 방향(orientation)을 정밀하게 제어하는 것이 필수적이다. 방향은 오일러 각도(Euler angles)로 표현할 경우 짐벌 락(Gimbal lock)과 같은 특이점 문제가 발생할 수 있다.</p>
<p>이러한 문제를 해결하기 위해, 단위 쿼터니언(Unit Quaternions)을 사용하여 3차원 회전을 표현하고 이를 DMP 프레임워크에 통합하는 연구가 진행되었다.27 쿼터니언은 4차원 벡터로 표현되며 짐벌 락 문제가 없다. 쿼터니언 공간의 비유클리드 기하학적 특성을 고려하여 변환 시스템의 오차 항(<span class="math math-inline">g - y</span>)을 쿼터니언 곱셈을 이용한 로그 맵(logarithmic map)으로 정의하고, 속도 역시 쿼터니언의 미분으로 재정의한다. 이러한 방식을 통해 DMP는 3차원 공간에서 특이점 문제 없이 부드럽고 안정적인 방향 전환 궤적을 생성하고 학습할 수 있게 된다.27</p>
<h2>6.  고급 응용: 동적 환경과의 상호작용</h2>
<p>DMP의 진정한 힘은 미리 계획된 궤적을 단순히 재생하는 것을 넘어, 실시간으로 변화하는 동적 환경과 상호작용하는 능력을 갖출 때 발휘된다. 이는 ’커플링 텀(coupling term)’이라는 개념을 통해 구현된다.</p>
<h3>6.1  커플링 텀(Coupling Term)을 이용한 실시간 궤적 변조</h3>
<p>커플링 텀은 외부 센서 정보나 다른 시스템의 상태를 DMP의 동역학에 실시간으로 반영하기 위해 변환 시스템에 추가되는 항이다.14 이는 기존에 학습된 궤적에 동적인 변조를 가하는 역할을 한다. 커플링 텀 <span class="math math-inline">C</span>가 추가된 변환 시스템은 다음과 같다.</p>
<p><span class="math math-display">
\tau \dot{z} = K(g - y) - D z + f(s) + C
</span><br />
여기서 <span class="math math-inline">C</span>는 장애물의 위치, 인간이 가하는 힘, 다른 로봇의 움직임 등 외부 요인에 따라 계산되는 함수이다.28 커플링 텀은 DMP를 정적인 궤적 생성기에서 동적인 상호작용 정책으로 확장시키는 핵심적인 메커니즘이다. 초기 DMP가 주로 시스템의 ’내부 상태(위상 변수)’에 따라 궤적을 생성하는 자율 시스템(autonomous system)이었다면, 커플링 텀은 여기에 ’외부 세계(센서 정보)’와의 연결고리를 추가하여 DMP를 환경과 상호작용하는 반응형 시스템(reactive system)으로 진화시킨다.</p>
<p><span class="math math-inline">C</span>에 어떤 정보를 연결하느냐에 따라 DMP의 기능은 무한히 확장될 수 있다.</p>
<h3>6.2  응용 사례 1: 잠재장(Potential Field) 기반 장애물 회피</h3>
<p>로봇이 작업 공간에서 움직일 때 정적 또는 동적 장애물을 회피하는 것은 필수적인 기능이다. DMP에 잠재장(potential field) 기반의 장애물 회피 기능을 통합할 수 있다.13 이 접근법에서는 각 장애물 주변에 가상의 ’척력(repulsive force)’을 발생시키는 잠재장을 생성한다. 이 척력의 크기와 방향은 로봇과 장애물 간의 상대적인 위치와 속도에 따라 결정되며, 로봇이 장애물에 가까워질수록 더 강해진다.</p>
<p>이 계산된 척력 벡터가 바로 커플링 텀 <span class="math math-inline">C</span>가 되어 변환 시스템에 추가된다. 그 결과, 로봇은 원래의 목표를 향해 나아가려는 DMP의 기본 동역학을 따르면서도, 장애물 근처에서는 척력의 영향을 받아 자연스럽게 경로를 수정하여 충돌을 회피하게 된다.13 이 방식은 실시간으로 장애물 위치가 변하더라도 즉각적으로 반응할 수 있다는 장점이 있다.</p>
<h3>6.3  응용 사례 2: 힘 피드백 기반 인간-로봇 협동 조작</h3>
<p>인간과 로봇이 무거운 물체를 함께 옮기거나 조립 작업을 협력하여 수행하는 과업에서 DMP는 매우 효과적으로 사용될 수 있다.15 이 시나리오에서 로봇은 엔드 이펙터에 장착된 힘/토크(F/T) 센서를 통해 인간 파트너가 가하는 힘을 실시간으로 측정한다.</p>
<p>측정된 힘 벡터는 적절한 게인(gain) 조정을 거쳐 커플링 텀 <span class="math math-inline">C</span>로 변환되어 DMP 시스템에 입력된다.29 만약 인간이 로봇을 더 빨리 밀면, 로봇은 이 힘을 감지하고 <span class="math math-inline">\tau</span>를 줄여 움직임 속도를 높이거나, 경로를 수정하여 인간의 의도에 순응적으로 반응한다. 이를 통해 로봇은 단순히 정해진 경로를 고집하는 것이 아니라, 인간 파트너의 의도를 실시간으로 파악하고 그에 맞춰 자신의 행동을 조절하는 진정한 의미의 협업을 수행할 수 있게 된다. 이는 DMP가 정적인 궤적 생성기를 넘어, 인간과 물리적으로 소통하고 협력하는 동적인 상호작용 정책으로 기능할 수 있음을 보여주는 대표적인 사례이다.</p>
<h2>7.  고전적 DMP의 한계와 비판적 고찰</h2>
<p>DMP는 많은 장점에도 불구하고 몇 가지 근본적인 한계점을 가지고 있으며, 이는 실제 로봇 응용에서 문제점으로 작용할 수 있다. 이러한 한계에 대한 명확한 이해는 DMP를 효과적으로 사용하고 최신 확장 모델의 필요성을 파악하는 데 필수적이다.</p>
<h3>7.1  공간적 일반화 시 발생하는 과대/과소 스케일링 문제</h3>
<p>고전적 DMP의 공간적 일반화 메커니즘은 직관적이지만 때때로 예기치 않은 결과를 낳는다. 특히, 시연된 궤적의 진폭(최대 변위)이 시작점과 목표점 사이의 직선 거리보다 큰 경우(예: 장애물을 피하기 위해 크게 돌아가는 움직임), 새로운 목표점이 시연과 크게 다른 위치에 설정되면 궤적이 비정상적으로 과대하게(overscaling) 스케일링되는 문제가 발생할 수 있다.36 이는 로봇에 물리적으로 불가능하거나 위험한 수준의 과도한 속도와 가속도를 요구할 수 있다. 반대로, 이 문제를 해결하기 위해 제안된 수정된 DMP 공식에서는 강제항이 시작-목표점 벡터에 의해 직접 스케일링되지 않기 때문에, 새로운 목표점에 대한 궤적의 형태가 직관적으로 변형되지 않는 과소 스케일링(underscaling) 문제가 발생할 수 있다.25</p>
<h3>7.2  단일 시연 학습의 정보 부족 및 다중 시연 통합의 어려움</h3>
<p>DMP는 본질적으로 ‘원샷 학습(one-shot learning)’ 프레임워크로, 단 하나의 시연 궤적으로부터 운동 모델을 생성하도록 설계되었다.25 이는 학습이 매우 빠르다는 장점이 있지만, 동시에 심각한 단점을 내포한다. 단일 시연에는 교사의 의도치 않은 버릇이나 측정 노이즈와 같은 비본질적인 정보가 포함될 수 있으며, DMP는 이러한 정보까지 그대로 학습하여 과적합(overfitting)될 위험이 있다.</p>
<p>더 중요한 문제는, 인간이 동일한 과업을 수행할 때 나타나는 자연스러운 변화(variability)를 모델링하기 어렵다는 점이다. 여러 번의 시연을 통해 과업의 본질적인 특성과 허용 가능한 변화의 범위를 학습하는 것이 더 강인한 모델을 만드는 데 유리하지만, 고전적 DMP 프레임워크에서는 여러 시연 궤적을 평균 내거나 그 분포를 통합하는 직관적인 방법을 제공하지 않는다.37</p>
<h3>7.3  기저 함수 개수 등 하이퍼파라미터 설정의 민감성</h3>
<p>DMP의 성능은 여러 하이퍼파라미터의 설정에 매우 민감하다. 특히 비선형 강제항을 구성하는 기저 함수의 개수(<span class="math math-inline">N</span>)는 생성되는 궤적의 복잡도와 품질에 직접적인 영향을 미친다.36</p>
<p><span class="math math-inline">N</span>이 너무 작으면 복잡한 궤적을 충분히 표현할 수 없고, 너무 크면 과적합의 위험이 커진다. 또한, 기저 함수의 폭(<span class="math math-inline">h_i</span>), 변환 시스템의 시간 상수(<span class="math math-inline">\alpha, \beta</span>) 등 다른 하이퍼파라미터들도 궤적의 부드러움과 수렴 속도에 큰 영향을 미친다.36 이러한 하이퍼파라미터를 주어진 과업에 맞게 체계적으로 설정하는 명확한 방법론이 부족하며, 종종 전문가의 경험이나 반복적인 시행착오에 의존해야 하는 것은 DMP를 실제 문제에 적용하는 데 있어 실용적인 장벽으로 작용한다.</p>
<h2>8.  DMP의 진화: 최신 확장 모델</h2>
<p>고전적 DMP의 한계를 극복하고 표현력과 유연성을 확장하기 위해, 확률론 및 심층 학습과 같은 최신 기계 학습 기법을 접목한 다양한 확장 모델들이 제안되었다.</p>
<h3>8.1  확률론적 운동 프리미티브(ProMP &amp; ProDMP): 궤적의 불확실성과 분포 모델링</h3>
<p>고전적 DMP가 여러 시연의 ’평균’적인 단일 궤적을 학습하는 데 그쳤다면, 확률론적 운동 프리미티브(Probabilistic Movement Primitives, ProMP)는 한 걸음 더 나아가 궤적의 ‘분포(distribution over trajectories)’ 자체를 학습한다.38 이는 동일한 과업에 대한 여러 시연에서 나타나는 자연스러운 가변성(variability)과 자유도 간의 상관관계(correlation)를 통계적으로 모델링하는 것을 가능하게 한다.</p>
<p>ProMP는 DMP와 유사하게 궤적을 기저 함수의 선형 조합으로 표현하지만, 가중치 벡터 <span class="math math-inline">w</span>를 단일 값이 아닌 확률 분포, 일반적으로 다변수 가우시안 분포 <span class="math math-inline">p(w) = \mathcal{N}(\mu_w, \Sigma_w)</span>로 모델링한다.39 여기서 평균 벡터 <span class="math math-inline">\mu_w</span>는 평균적인 궤적의 형태를, 공분산 행렬 <span class="math math-inline">\Sigma_w</span>는 궤적의 가변성과 자유도 간의 상호작용을 인코딩한다. 이 확률적 표현 덕분에 베이즈 정리(Bayes’ theorem)를 이용한 조건부 확률(conditioning) 계산을 통해 새로운 목표점이나 경유점을 통과하는 궤적 분포를 유도하는 등, 보다 원리적인 방식으로 일반화를 수행할 수 있다.39</p>
<p>최근에는 ProMP의 확률론적 표현력과 DMP의 안정적인 동역학계 구조를 통합하려는 시도로 확률론적 동적 운동 프리미티브(Probabilistic Dynamic Movement Primitives, ProDMP)가 제안되었다.42 ProDMP는 DMP의 온라인 수치 적분 과정을 오프라인에서 미리 계산하여 궤적을 생성하는 기저 함수 형태로 변환한다. 이를 통해 ProMP처럼 궤적의 분포를 다루면서도, DMP 고유의 특성인 시작점 및 목표점에서의 동역학적 제약을 엄격하게 만족시킬 수 있어 두 프레임워크의 장점을 모두 취할 수 있다.45</p>
<p>이러한 DMP에서 ProDMP로의 발전은 로봇 학습의 패러다임이 ’결정론적 모방’에서 ’확률론적 추론’으로 이동하고 있음을 보여주는 중요한 흐름이다. 이는 로봇이 단순히 시연된 단일 경로를 따라하는 것을 넘어, 과업 수행에 내재된 본질적인 불확실성을 이해하고, 주어진 상황에서 가장 가능성이 높은 행동을 추론하여 생성하는 방향으로 진화하고 있음을 의미한다. 로봇은 이제 “이 궤적을 따라하라“는 명령을 넘어, “이러한 형태의 궤적들이 ‘좋은’ 궤적의 분포를 이루니, 이 분포 내에서 현재 상황에 가장 적합하고 동역학적으로 안정적인 궤적을 생성하라“는 더 정교하고 지능적인 명령을 수행할 수 있게 된 것이다.</p>
<h3>8.2  심층 학습과의 융합(Deep DMP): 시각 정보로부터 직접 운동을 생성하는 End-to-End 학습</h3>
<p>최근 인공지능 분야의 발전을 이끌고 있는 심층 학습(Deep Learning) 기술이 DMP와 융합되면서, 로봇이 고차원의 원시 센서 데이터(raw sensor data)로부터 직접 움직임을 학습하고 생성하는 것이 가능해지고 있다. 특히, 합성곱 신경망(Convolutional Neural Network, CNN)을 사용하여 이미지 입력으로부터 DMP의 핵심 파라미터(가중치 <span class="math math-inline">w</span>, 목표점 <span class="math math-inline">g</span> 등)를 직접 추론하는 연구들이 활발히 진행되고 있다.46</p>
<p>이러한 접근법(예: Deep-DMP, Neural Dynamic Policies)은 DMP의 동역학 구조를 신경망의 일부 레이어로 내장(embed)하여, 이미지 입력부터 로봇의 최종 행동 출력까지 전체 과정을 한 번에 학습하는 종단간 학습(end-to-end learning)을 가능하게 한다.24 예를 들어, CNN이 카메라 이미지에서 물체의 위치와 형태를 인식하면, 후속 완전 연결 계층(fully-connected layers)이 이 정보를 바탕으로 해당 물체를 조작하는 데 필요한 DMP 파라미터를 출력하는 방식이다.47 이를 통해 기존에는 전문가가 수동으로 정의해주어야 했던 ’작업 파라미터’를 시스템이 데이터로부터 스스로 학습하게 되어, 복잡하고 다양한 시각적 조건에 반응하는 유연한 움직임을 생성할 수 있다.</p>
<p>더 나아가, 최근에는 거대 언어 모델(LLM)과 비전 모델을 결합한 Vision-Language Model(VLM)을 DMP와 통합하려는 연구도 등장하고 있다. 이 접근법은 “테이블 위에 있는 빨간 컵을 들어서 파란색 그릇에 옮겨줘“와 같은 자연어 및 시각적 지시를 이해하고, 이를 수행하기 위한 일련의 DMP들을 순차적으로 생성하고 실행하는 것을 목표로 한다.46 이는 로봇 기술의 학습과 생성을 넘어, 인간과의 상호작용을 통해 로봇의 행동을 보다 직관적이고 의미론적인 수준에서 제어하는 새로운 가능성을 열어주고 있다.</p>
<h2>9.  실용적 구현 가이드</h2>
<p>DMP를 실제 로봇 시스템에 적용하기 위해서는 이론적 이해와 더불어 실용적인 구현 도구에 대한 지식이 필요하다. 다행히 DMP를 쉽게 사용할 수 있도록 도와주는 여러 오픈소스 라이브러리가 존재하며, 이를 로봇 운영체제(ROS)와 통합하여 활용할 수 있다.</p>
<h3>9.1  오픈소스 라이브러리 소개 및 활용법</h3>
<ul>
<li>
<p><strong>pydmps:</strong> Python으로 구현된 대표적인 DMP 라이브러리로, 설치와 사용이 간편하여 DMP를 처음 접하는 연구자나 개발자에게 적합하다. <code>pip</code>를 통해 쉽게 설치할 수 있으며, 시연 궤적 데이터를 입력하여 DMP를 학습시키고, 새로운 시작점과 목표점을 설정하여 새로운 궤적을 생성하는 기본적인 기능을 충실히 제공한다. 장애물 회피와 같은 고급 기능에 대한 예제 코드도 포함되어 있어 학습에 용이하다.51</p>
</li>
<li>
<p><strong>dmpbbo:</strong> C++과 Python 인터페이스를 모두 제공하는 다목적 라이브러리이다. 실시간 성능이 중요한 실제 로봇 제어에는 C++ 구현을, 빠른 프로토타이핑과 분석에는 Python 구현을 사용할 수 있다. 이 라이브러리는 DMP뿐만 아니라, 동역학 시스템, 함수 근사기, 블랙박스 최적화(BBO) 알고리즘 등 관련된 모듈들을 독립적으로 제공하여 유연성이 높다. 특히 강화 학습을 통해 DMP 파라미터를 최적화하는 기능이 통합되어 있어 고급 연구에 유용하다.54</p>
</li>
<li>
<p><strong>movement_primitives:</strong> 비교적 최신 라이브러리로, 고전적인 DMP뿐만 아니라 확률론적 운동 프리미티브(ProMP)까지 통합하여 제공한다. 특히 로봇 팔의 Cartesian 공간 제어와 양팔 조작(bimanual manipulation)을 위한 커플링 텀 구현에 중점을 두고 있어, 조작(manipulation) 연구에 특화된 기능을 제공한다.57</p>
</li>
</ul>
<h3>9.2  ROS(Robot Operating System) 환경에서의 통합 및 적용 방안</h3>
<p>로봇 운영체제(ROS)는 로봇 응용 프로그램 개발을 위한 사실상의 표준 플랫폼으로, 다양한 하드웨어와 소프트웨어 모듈을 통합하는 데 강력한 기능을 제공한다.58 위에서 소개된 DMP 라이브러리들을 ROS 환경에 통합하면 실제 로봇을 이용한 실험과 개발을 효율적으로 수행할 수 있다.</p>
<p>통합의 일반적인 과정은 다음과 같다.</p>
<ol>
<li>
<p><strong>ROS 노드 생성:</strong> DMP 기능을 수행하는 ROS 노드(node)를 생성한다. 이 노드는 Python 또는 C++로 작성될 수 있으며, 내부적으로는 <code>pydmps</code>나 <code>dmpbbo</code>와 같은 라이브러리를 호출하여 DMP 관련 계산을 수행한다.</p>
</li>
<li>
<p><strong>토픽(Topic) 통신:</strong> 생성된 DMP 노드는 ROS의 메시지 통신 시스템인 토픽을 통해 다른 노드들과 데이터를 주고받는다. 예를 들어, 카메라 드라이버 노드가 발행(publish)하는 이미지 토픽(<code>sensor_msgs/Image</code>)을 구독(subscribe)하여 시각 정보를 입력받을 수 있다.</p>
</li>
<li>
<p><strong>궤적 실행:</strong> DMP 노드가 계산한 궤적은 로봇의 컨트롤러가 이해할 수 있는 형태의 메시지, 예를 들어 <code>trajectory_msgs/JointTrajectory</code> 타입의 토픽으로 발행된다. 로봇의 드라이버 노드(예: <code>ros_control</code>)는 이 토픽을 구독하여 실제 로봇 관절을 해당 궤적에 따라 구동시킨다.60</p>
</li>
</ol>
<p>이러한 방식으로 DMP를 ROS 생태계에 통합하면, 시각, 힘 센서 등 다양한 센서 모듈과 경로 계획, 충돌 회피 등 다른 고급 기능 모듈들과의 유기적인 연동이 가능해져 복잡하고 지능적인 로봇 응용 프로그램을 손쉽게 개발할 수 있다.58</p>
<h2>10.  결론: 미래 로봇 지능을 위한 초석</h2>
<h3>10.1  DMP 연구의 현재 위치와 기여 요약</h3>
<p>동적 운동 프리미티브(DMP)는 지난 20여 년간 로봇 운동 생성 및 학습 분야에서 가장 영향력 있는 패러다임 중 하나로 자리 잡았다. 생물학적 운동 제어 원리에서 영감을 받아, 안정성, 일반화 능력, 그리고 학습 용이성을 하나의 통합된 수학적 프레임워크 안에 우아하게 담아냈다. DMP는 로봇이 단순히 정해진 경로를 추종하는 것을 넘어, 인간의 시연으로부터 움직임의 ’본질’을 학습하고 이를 새로운 상황에 유연하게 적용할 수 있는 길을 열었다.</p>
<p>DMP의 기여는 단순히 궤적을 인코딩하는 기술에 그치지 않는다. 이는 복잡한 로봇 기술을 모듈화하고, 조합하며, 점진적으로 개선해 나갈 수 있는 강력한 방법론을 제공했다. 강화 학습의 정책 표현법으로 사용되어 학습 효율을 높이고, 커플링 텀을 통해 동적인 환경과 실시간으로 상호작용하는 능력을 부여했으며, 확률론 및 심층 학습과의 융합을 통해 그 표현력과 적용 범위를 끊임없이 확장해왔다. 이처럼 DMP는 로봇 지능의 발전에 있어 중요한 이론적, 실용적 초석을 마련했다.</p>
<h3>10.2  향후 연구 방향 및 전망</h3>
<p>DMP와 그 파생 기술들은 여전히 활발한 연구 주제이며, 미래의 자율 로봇 기술을 향한 여러 도전적인 과제들을 해결하는 데 핵심적인 역할을 할 것으로 기대된다. 향후 연구는 다음과 같은 방향으로 전개될 것으로 전망된다.</p>
<ul>
<li>
<p><strong>데이터 효율성(Data Efficiency):</strong> 현재의 학습 기반 로봇 기술은 여전히 많은 양의 데이터를 필요로 한다. 메타 학습(Meta-Learning)이나 전이 학습(Transfer Learning)과 같은 기법을 DMP 프레임워크에 통합하여, 더 적은 시연 데이터로부터 더 빠르고 강인하게 새로운 기술을 학습하는 방법론에 대한 연구가 심화될 것이다.</p>
</li>
<li>
<p><strong>고차원 표현(High-Dimensional Representation):</strong> 인간형 로봇의 전신 운동이나 여러 로봇이 협업하는 다중 로봇 시스템과 같이 매우 높은 자유도를 갖는 복잡한 움직임을 효과적으로 표현하고 학습하는 것은 여전히 큰 도전이다. 계층적(hierarchical) DMP 구조나 텐서(tensor) 분해와 같은 기법을 활용하여 고차원 운동 공간을 효율적으로 다루는 연구가 필요하다.</p>
</li>
<li>
<p><strong>의미론적 이해(Semantic Understanding):</strong> 로봇이 “물건을 조심스럽게 내려놓아라” 또는 “더 빠르게 저어라“와 같은 추상적이고 부사적인 지시를 이해하고, 이를 실제 궤적의 동역학적 파라미터(예: 부드러움, 속도, 힘)로 변환하는 기술이 중요해질 것이다. 이는 거대 언어 모델(LLM)과 DMP의 더욱 깊이 있는 융합을 통해 이루어질 것이다.</p>
</li>
<li>
<p><strong>안전성 보장(Safety Guarantees):</strong> 학습 기반 접근법은 본질적으로 데이터에 의존하기 때문에 예측 불가능한 상황에서 안전을 보장하기 어렵다. 제어 배리어 함수(Control Barrier Functions, CBF)와 같은 형식적 검증(formal verification) 기법을 DMP와 결합하여, 학습된 정책이 어떠한 상황에서도 안전 경계를 위반하지 않음을 수학적으로 보장하는 연구가 더욱 중요해질 것이다.</p>
</li>
</ul>
<p>결론적으로, 동적 운동 프리미티브는 로봇이 구조화되지 않은 복잡한 세상 속에서 인간과 더 유사하고, 더 지능적이며, 더 안전하게 상호작용하는 미래를 여는 데 있어 계속해서 핵심적인 역할을 수행할 것이다. 이는 로봇 공학의 과거와 현재를 잇고 미래를 향한 길을 제시하는 강력하고 살아있는 프레임워크이다.</p>
<h2>11. 참고 자료</h2>
<ol>
<li>(PDF) Dynamic movement primitives in robotics: A tutorial survey, https://www.researchgate.net/publication/374150029_Dynamic_movement_primitives_in_robotics_A_tutorial_survey</li>
<li>Dynamic movement primitives in robotics: A tutorial survey - University of Southern Denmark, https://portal.findresearcher.sdu.dk/en/publications/dynamic-movement-primitives-in-robotics-a-tutorial-survey</li>
<li>Dynamic movement primitives in robotics: A tutorial survey - TU Delft Research Portal, https://pure.tudelft.nl/ws/portalfiles/portal/169612489/saveriano_et_al_2023_dynamic_movement_primitives_in_robotics_a_tutorial_survey.pdf</li>
<li>(PDF) Learning Movement Primitives - ResearchGate, https://www.researchgate.net/publication/220757258_Learning_Movement_Primitives</li>
<li>Dynamic movement primitives in robotics: A tutorial survey - NYU, https://nyuscholars.nyu.edu/en/publications/dynamic-movement-primitives-in-robotics-a-tutorial-survey</li>
<li>Dynamic Movement Primitives-A Framework for Motor Control in Humans and Humanoid Robotics - DTIC, https://apps.dtic.mil/sti/trecms/pdf/AD1154811.pdf</li>
<li>Dynamic Movement Primitives -A Framework for Motor Control in Humans and Humanoid Robotics - Semantic Scholar, https://www.semanticscholar.org/paper/Dynamic-Movement-Primitives-A-Framework-for-Motor-Schaal/2065d9eb28be0700a235afb78e4a073845bfb67d</li>
<li>Reinforcement Learning with Dynamic Movement Primitives - DMPs, https://cps.unileoben.ac.at/wp/theses/Kniewasser_MscProject_2013.pdf</li>
<li>Constrained Dynamic Movement Primitives for Collision Avoidance in Novel Environments - Brown Computer Science, https://cs.brown.edu/people/gdk/pubs/cdmps.pdf</li>
<li>Dynamic Movement Primitives for moving goals with temporal scaling adaptation - Zenodo, https://zenodo.org/records/3635299/files/ICRA_2020_DMP___moving_goal.pdf</li>
<li>Real-time temporal adaptation of dynamic movement primitives for moving targets - SINTEF Open, https://sintef.brage.unit.no/sintef-xmlui/bitstream/handle/11250/3013835/Real-time_temporal_adaptation_of_dynamic_movement_primitives_for_moving_targets.pdf?sequence=1</li>
<li>Learning and Generalization of Motor Skills by … - UTK-EECS, https://web.eecs.utk.edu/~leparker/Courses/CS494-529-fall14/Homeworks/Papers/12.pdf</li>
<li>Dynamic movement primitive - studywolf - WordPress.com, https://studywolf.wordpress.com/category/robotics/dynamic-movement-primitive/</li>
<li>Coupling Movement Primitives: Interaction With the Environment and Bimanual Tasks - SciSpace, https://scispace.com/pdf/coupling-movement-primitives-interaction-with-the-2altzkct4o.pdf</li>
<li>Coordinate Change Dynamic Movement Primitives – A Leader-Follower Approach - KIT, https://h2t.iar.kit.edu/pdf/Zhou2016a.pdf</li>
<li>Dynamic movement primitives - ini.rub.de, https://www.ini.rub.de/upload/file/1624536834_5459cf7b065170bfce2a/9_dynamic_movement_primitives.pdf</li>
<li>Task-Oriented Generalization of Dynamic Movement Primitive - KIT, https://h2t.iar.kit.edu/pdf/Zhou2017.pdf</li>
<li>Combining Movement Primitives with Contraction Theory - arXiv, https://arxiv.org/html/2501.09198v1</li>
<li>Dynamic movement primitives part 3: Rhythmic movements - studywolf - WordPress.com, https://studywolf.wordpress.com/2014/03/07/dynamic-movement-primitives-part-3-rhythmic-movements/</li>
<li>Fourier movement primitives: an approach for learning rhythmic robot skills from demonstrations, https://www.roboticsproceedings.org/rss16/p056.pdf</li>
<li>Generalization of Example Movements with Dynamic Systems - Humanoid and Cognitive Robotics Laboratory, https://hcr.ijs.si/resources/papers/humanoids09b.pdf</li>
<li>Learning and Adaptation of Periodic Motion Primitives Based on Force Feedback and Human Coaching Interaction - Humanoid and Cognitive Robotics Laboratory, https://hcr.ijs.si/resources/papers/humanoids14.pdf</li>
<li>(PDF) Locally Weighted Learning for Control - ResearchGate, https://www.researchgate.net/publication/225258072_Locally_Weighted_Learning_for_Control</li>
<li>Neural Dynamic Policies for End-to-End Sensorimotor Learning - NIPS, https://papers.nips.cc/paper/2020/file/354ac345fd8c6d7ef634d9a8e3d47b83-Paper.pdf</li>
<li>(PDF) Overcoming Some Drawbacks of Dynamic Movement Primitives, https://www.researchgate.net/publication/335463068_Overcoming_Some_Drawbacks_of_Dynamic_Movement_Primitives</li>
<li>Dynamic Movement Primitives Plus: For Enhanced Reproduction Quality and Efficient Trajectory Modification Using Truncated Kernel - Yan Wu, https://www.yan-wu.com/docs/wang2016dynamic.pdf</li>
<li>Composite dynamic movement primitives based on neural networks for human–robot skill transfer - ResearchGate, https://www.researchgate.net/publication/349308671_Composite_dynamic_movement_primitives_based_on_neural_networks_for_human-robot_skill_transfer</li>
<li>(PDF) Learning coupling terms for obstacle avoidance - ResearchGate, https://www.researchgate.net/publication/278671105_Learning_coupling_terms_for_obstacle_avoidance</li>
<li>Learning of Parametric Coupling Terms for Robot-Environment Interaction - Humanoid and Cognitive Robotics Laboratory, https://hcr.ijs.si/resources/papers/humanoids15b.pdf</li>
<li>(PDF) Movement reproduction and obstacle avoidance with dynamic …, https://www.researchgate.net/publication/228891557_Movement_reproduction_and_obstacle_avoidance_with_dynamic_movement_primitives_and_potential_fields</li>
<li>Reinforcement Learning with Dynamic Movement Primitives for Obstacle Avoidance - MDPI, https://www.mdpi.com/2076-3417/11/23/11184</li>
<li>Phase-independent Dynamic Movement Primitives with applications to human–robot co-manipulation and time optimal planning - IRIS Unimore, <a href="https://iris.unimore.it/retrieve/8e9c9fad-26b8-4bab-908a-6946aa0c50f4/Phase-independent%20Dynamic%20Movement%20Primitives%20with%20applications%20to%20human%E2%80%93robot%20co-manipulation%20and%20time%20optimal%20planning.pdf">https://iris.unimore.it/retrieve/8e9c9fad-26b8-4bab-908a-6946aa0c50f4/Phase-independent%20Dynamic%20Movement%20Primitives%20with%20applications%20to%20human%E2%80%93robot%20co-manipulation%20and%20time%20optimal%20planning.pdf</a></li>
<li>Human-Robot Cooperation Through Force Adaptation Using Dynamic Motion Primitives and Iterative Learning - ResearchGate, https://www.researchgate.net/publication/281701489_Human-Robot_Cooperation_Through_Force_Adaptation_Using_Dynamic_Motion_Primitives_and_Iterative_Learning</li>
<li>Learning and Force Adaptation for Interactive Actions, https://h2t.iar.kit.edu/pdf/Zhou2016b.pdf</li>
<li>MISO structure of the cooperative DMP system. Note that the coupling… - ResearchGate, https://www.researchgate.net/figure/MISO-structure-of-the-cooperative-DMP-system-Note-that-the-coupling-comes-from-the-force_fig1_264387644</li>
<li>Overcoming some drawbacks of Dynamic Movement Primitives | Request PDF, https://www.researchgate.net/publication/353107599_Overcoming_some_drawbacks_of_Dynamic_Movement_Primitives</li>
<li>Overcoming Some Drawbacks of Dynamic Movement Primitives - IRIS, https://iris.univr.it/retrieve/e14ff6e5-b14f-0209-e053-6605fe0ad24c/root.pdf</li>
<li>Probabilistic Movement Primitives - NIPS, https://papers.nips.cc/paper/5177-probabilistic-movement-primitives</li>
<li>Using Probabilistic Movement Primitives in … - IAS TU Darmstadt, https://www.ias.informatik.tu-darmstadt.de/uploads/Team/AlexandrosParaschos/promps_auro.pdf</li>
<li>Adaptation and Robust Learning of Probabilistic Movement Primitives - arXiv, https://arxiv.org/pdf/1808.10648</li>
<li>Experience Reuse with Probabilistic Movement Primitives, https://cps.unileoben.ac.at/wp/IROS2019Stark.pdf</li>
<li>Interactive Expressive Motion Generation Using Dynamic Movement Primitives - arXiv, https://arxiv.org/html/2504.06735v1</li>
<li>Episode-Based Reinforcement Learning using … - TransferLab, <a href="https://transferlab.ai/seminar/2024/episode-based-rl-with-movement-primitive/2024-02-08%20-%20Maximilian%20H%C3%BCttenrauch%20-%20Episode-based%20RL%20with%20Movement%20Primitive.pdf">https://transferlab.ai/seminar/2024/episode-based-rl-with-movement-primitive/2024-02-08%20-%20Maximilian%20H%C3%BCttenrauch%20-%20Episode-based%20RL%20with%20Movement%20Primitive.pdf</a></li>
<li>[PDF] Gaussian-process-based robot learning from demonstration | Semantic Scholar, https://www.semanticscholar.org/paper/00f2fef7a31b34452c30a0cdff6bc72fdfc3c517</li>
<li>FRMD: Fast Robot Motion Diffusion with Consistency-Distilled Movement Primitives for Smooth Action Generation - ResearchGate, https://www.researchgate.net/publication/389581353_FRMD_Fast_Robot_Motion_Diffusion_with_Consistency-Distilled_Movement_Primitives_for_Smooth_Action_Generation</li>
<li>One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks - arXiv, https://arxiv.org/pdf/2504.10011</li>
<li>Learning Deep Movement Primitives using … - mediaTUM, https://mediatum.ub.tum.de/doc/1430290/file.pdf</li>
<li>Neural Dynamic Policies for End-to-End Sensorimotor Learning - Shikhar Bahl, https://shikharbahl.github.io/neural-dynamic-policies/resources/ndp.pdf</li>
<li>(PDF) KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks - ResearchGate, https://www.researchgate.net/publication/393691115_KeyMPs_One-Shot_Vision-Language_Guided_Motion_Generation_by_Sequencing_DMPs_for_Occlusion-Rich_Tasks</li>
<li>KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks - arXiv, https://arxiv.org/html/2504.10011v1</li>
<li>pypi.org “trajectory generation” keyword - Packages - Ecosyste.ms, <a href="https://packages.ecosyste.ms/registries/pypi.org/keywords/trajectory%20generation">https://packages.ecosyste.ms/registries/pypi.org/keywords/trajectory%20generation</a></li>
<li>Deep autoencoder for robotic task learning in latent space - GitHub, https://github.com/markolalovic/latent-learning-robot</li>
<li>Dynamic movement primitives part 4: Avoiding obstacles – update - studywolf, https://studywolf.wordpress.com/2016/05/13/dynamic-movement-primitives-part-4-avoiding-obstacles/</li>
<li>DmpBbo: A versatile Python/C++ library for Function Approximation, https://elib.dlr.de/136060/</li>
<li>DmpBbo: A versatile Python/C++ library for Function Approximation, Dynamical Movement Primitives, and Black-Box Optimization - ResearchGate, https://www.researchgate.net/publication/332917286_DmpBbo_A_versatile_PythonC_library_for_Function_Approximation_Dynamical_Movement_Primitives_and_Black-Box_Optimization</li>
<li>DmpBbo: A versatile Python/C++ library for Function Approximation, Dynamical Movement Primitives, and Black-Box Optimization - Journal of Open Source Software, https://joss.theoj.org/papers/10.21105/joss.01225</li>
<li>(PDF) movement_primitives: Imitation Learning of Cartesian Motion with Movement Primitives - ResearchGate, https://www.researchgate.net/publication/381087939_movement_primitives_Imitation_Learning_of_Cartesian_Motion_with_Movement_Primitives</li>
<li>Degree Project - Halmstad University, https://hh.diva-portal.org/smash/get/diva2:1827519/FULLTEXT02.pdf</li>
<li>Modular ROS-Based Software Architecture for Reconfigurable, Industry 4.0 Compatible Robotic Workcells, https://hcr.ijs.si/resources/papers/icar21a.pdf</li>
<li>ros2_fanuc_interface: Design and Evaluation of a Fanuc CRX Hardware Interface in ROS2, https://arxiv.org/html/2506.14487v1</li>
<li>ROS-PyBullet Interface - Proceedings of Machine Learning Research, https://proceedings.mlr.press/v205/mower23a/mower23a-supp.pdf</li>
<li>ROS-LLM: A ROS framework for embodied AI with task feedback and structured reasoning - arXiv, https://arxiv.org/html/2406.19741v1</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>