<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:드론 자율 비행 및 충돌 회피를 위한 LiDAR, IMU, GNSS 융합</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>드론 자율 비행 및 충돌 회피를 위한 LiDAR, IMU, GNSS 융합</h1>
                    <nav class="breadcrumbs"><a href="../../../index.html">Home</a> / <a href="../../index.html">로봇공학 (Robotics)</a> / <a href="../index.html">드론 (Drones)</a> / <a href="index.html">드론 센서</a> / <span>드론 자율 비행 및 충돌 회피를 위한 LiDAR, IMU, GNSS 융합</span></nav>
                </div>
            </header>
            <article>
                <h1>드론 자율 비행 및 충돌 회피를 위한 LiDAR, IMU, GNSS 융합</h1>
<h2>1. 강인한 자율 비행을 향한 여정</h2>
<p>자율 비행 드론의 핵심은 ’자신이 어디에 있고, 어떻게 움직이고 있으며, 주변 환경은 어떠한가’를 정확하게 인지하는 능력에 있다. 이를 위해 다양한 센서를 사용하지만, 단일 센서만으로는 강인하고 신뢰성 있는 자율 비행을 달성하기 어렵다. 각 센서는 고유의 강점과 함께 명백한 한계를 가지고 있기 때문이다.</p>
<h3>1.1 자율 비행의 삼위일체: LiDAR, IMU, GNSS의 역할과 본질적 한계</h3>
<ul>
<li><strong>LiDAR (Light Detection and Ranging):</strong> 레이저 펄스를 사용하여 주변 환경과의 거리를 정밀하게 측정하고, 이를 통해 3차원 포인트 클라우드 맵을 생성한다. 3D 구조를 직접적으로 파악할 수 있어 매우 정확하지만, 벽이나 복도처럼 기하학적 특징이 없는 환경에서는 위치 추정에 어려움을 겪는다.1 또한, 데이터가 누적됨에 따라 오차(드리프트)가 점진적으로 쌓이며, 특정 재질의 표면에서는 레이저가 흡수되거나 난반사되어 측정에 실패할 수 있다.2</li>
<li><strong>IMU (Inertial Measurement Unit):</strong> 가속도계와 자이로스코프로 구성되어 드론의 가속도와 각속도를 측정한다. 이를 통해 매우 높은 주파수(수백 Hz)로 드론의 동적인 움직임을 파악할 수 있다. 하지만 IMU는 상대적인 변화량만을 측정하므로, 이 값을 적분하여 자세와 위치를 계산하는 과정에서 시간이 지남에 따라 오차가 기하급수적으로 누적되는 드리프트 현상이 필연적으로 발생한다.4</li>
<li><strong>GNSS (Global Navigation Satellite System):</strong> 위성 신호를 수신하여 지구 좌표계 기준의 절대 위치 정보를 제공한다. 이는 누적 오차 문제를 해결할 수 있는 강력한 수단이지만, 도심의 빌딩 숲(Urban Canyon), 실내, 터널, 숲 속 등 위성 신호가 차단되거나 반사되는(다중경로 오차) 환경에서는 수신이 불가능하거나 정확도가 미터 수준으로 급격히 저하된다.6</li>
</ul>
<h3>1.2 왜 융합이 필수적인가: 상호 보완을 통한 시스템 강인성 확보</h3>
<p>이 세 가지 센서는 서로의 약점을 완벽하게 보완하는 상보적(Complementary) 관계에 있다.8 GNSS가 수신 불가능한 실내나 도심 협곡에서는 LiDAR와 IMU의 결합(LiDAR-Inertial Odometry)이 주된 위치 추정 수단이 된다. 특징 없는 평평한 바닥이나 넓은 벽면을 지날 때 LiDAR가 방향을 잃으면, IMU가 단기적인 움직임을 정확히 추적하여 위치를 보정해준다. 장시간 비행으로 IMU와 LiDAR의 드리프트가 누적되더라도, 잠시 GNSS 신호가 양호한 곳으로 나오면 절대 위치 정보를 통해 누적된 오차를 한 번에 보정할 수 있다.</p>
<p>이러한 센서 융합의 가치는 단순히 여러 데이터를 평균내는 것을 넘어선다. 각 센서의 실패 모드(failure mode)가 서로 상관관계가 거의 없다는 점이 핵심이다. GNSS 신호가 끊긴다고 해서 IMU의 드리프트가 더 심해지지는 않으며, LiDAR가 특징 없는 벽 앞에서 성능이 저하된다고 해서 IMU의 회전 측정 능력이 영향을 받지는 않는다. 이 덕분에 융합 시스템은 하나의 센서가 일시적으로 무력화되더라도 다른 센서들의 정보를 바탕으로 안정적인 위치 추정을 지속할 수 있다. 이는 개별 센서의 합보다 훨씬 더 강인하고 신뢰성 있는 하나의 통합 인지 시스템을 만들어낸다.8</p>
<h3>1.3 튜토리얼 목표 및 시스템 아키텍처 개요: LIO-SAM을 중심으로</h3>
<p>본 튜토리얼은 LiDAR, IMU, GNSS 데이터를 효과적으로 융합하는 최신 기법을 상세히 다루는 것을 목표로 한다. 이를 위해 참조 아키텍처로 **LIO-SAM (Lidar-Inertial Odometry via Smoothing and Mapping)**을 채택한다.11 LIO-SAM은 팩터 그래프(Factor Graph)라는 최적화 기법을 기반으로 여러 센서 정보를 긴밀하게 결합(Tightly-coupled)하는 강력한 프레임워크다.</p>
<p>튜토리얼에서 다룰 전체 파이프라인은 다음과 같다:</p>
<ol>
<li><strong>센서 데이터 전처리:</strong> 각 센서에서 들어오는 원시 데이터를 정제하여 신뢰성을 높인다.</li>
<li><strong>LiDAR-IMU Odometry (프론트엔드):</strong> LiDAR와 IMU 데이터를 융합하여 빠르고 연속적인 상대 움직임을 추정한다.</li>
<li><strong>팩터 그래프 최적화 (백엔드):</strong> 프론트엔드에서 추정한 상대 움직임, GNSS 절대 위치, 루프 클로저(Loop Closure) 등 다양한 정보를 팩터 그래프에 통합하여 전역적으로 최적화된 전체 궤적을 계산한다.</li>
<li><strong>3D 맵핑 및 경로 계획:</strong> 최적화된 궤적 정보를 바탕으로 3차원 지도를 생성하고, 이를 기반으로 목표 지점까지 안전한 경로를 계획한다.</li>
</ol>
<h3>1.4 드론 탑재 센서 구성 분석</h3>
<p>본 튜토리얼은 사용자가 제시한 특정 하드웨어 구성을 가정한다. 이 구성은 자율 비행 드론을 위한 매우 실용적이고 강인한 설계다.</p>
<ul>
<li><strong>전방: Livox Avia:</strong> 장거리 탐지(최대 450m)와 높은 포인트 밀도(초당 최대 72만 포인트)를 자랑하며, 비행 방향의 원거리 장애물을 미리 인지하고 고품질의 지도를 작성하는 데 사용된다. 특히 3중 반사(Triple-return) 기능은 나뭇잎과 같은 식생을 투과하여 그 아래의 지형 정보를 얻는 데 매우 효과적이다. 이는 사진측량(Photogrammetry) 방식으로는 불가능한 장점이다.12</li>
<li><strong>상/하부: Livox Mid-360:</strong> 360도 수평 시야각(FOV)을 제공하여 드론의 즉각적인 주변 전체를 감지한다. 탐지 거리는 70m로 비교적 짧지만, 전방 센서가 보지 못하는 상하부 및 측후방의 사각지대를 완벽하게 커버한다. 이는 수직 이착륙, 측면 이동, 협소 공간 통과 시 충돌을 방지하는 데 결정적인 역할을 한다.15</li>
</ul>
<p>이러한 구성은 두 가지 다른 목적의 인식 시스템을 결합한 형태다. Avia는 장기적인 경로 계획과 지도 작성을 위한 ‘원시안(far-sighted eye)’ 역할을 하고, 두 개의 Mid-360은 즉각적인 충돌 회피를 위한 ’안전 버블(safety bubble)’을 형성한다. 이 조합은 다양한 환경에서 드론의 생존성과 임무 수행 능력을 극대화한다.</p>
<p><strong>표 1: 드론 탑재 센서 핵심 제원 (Livox Avia &amp; Mid-360)</strong></p>
<table><thead><tr><th>특징</th><th>Livox Avia</th><th>Livox Mid-360</th></tr></thead><tbody>
<tr><td>무게</td><td>498 g (케이블 제외) 12</td><td>265 g 15</td></tr>
<tr><td>탐지 범위 (80% 반사율)</td><td>320 m (@100 klx), 450 m (@0 klx) 13</td><td>70 m (@100 klx) 15</td></tr>
<tr><td>시야각 (H × V)</td><td>70.4° × 77.2° (비반복 스캔) 13</td><td>360° × 59° 16</td></tr>
<tr><td>포인트 생성률</td><td>240k/s (단일), 480k/s (이중), 720k/s (삼중) 13</td><td>200k/s (단일) 15</td></tr>
<tr><td>거리 정밀도 (1σ)</td><td>2 cm (@20m) 13</td><td>≤ 2 cm (@10m) 15</td></tr>
<tr><td>내장 IMU 모델</td><td>BMI088 13</td><td>ICM40609 15</td></tr>
<tr><td>방수/방진 등급</td><td>IP67 12</td><td>IP67 15</td></tr>
</tbody></table>
<hr />
<h2>2. 부: 데이터의 정제 - 신뢰할 수 있는 측정값 확보</h2>
<p>모든 센서 융합 시스템의 성능은 입력되는 데이터의 품질에 의해 결정된다. 원시(Raw) 데이터에는 노이즈, 이상치(outlier), 계산 부하를 유발하는 중복 정보가 포함되어 있다. 따라서 강력한 융합 알고리즘을 적용하기 전에, 데이터를 정제하여 신뢰할 수 있는 측정값을 확보하는 전처리 과정이 필수적이다.</p>
<h3>2.1  LiDAR 포인트 클라우드 전처리: 원시 데이터에서 의미 있는 정보로</h3>
<p>LiDAR 센서는 초당 수십만 개의 3D 포인트를 생성하며, 이 방대한 데이터를 실시간으로 처리하는 것은 상당한 계산 부담을 야기한다. 또한, 측정 과정에서 발생하는 노이즈는 후속 처리 단계에서 심각한 오류를 유발할 수 있다. 따라서 다운샘플링과 노이즈 제거는 LiDAR 처리 파이프라인의 첫 단추다.</p>
<h4>2.1.1 Voxel Grid 필터를 이용한 체계적 다운샘플링</h4>
<ul>
<li><strong>목적:</strong> 포인트 클라우드의 전체적인 형태는 유지하면서 포인트의 수를 줄여 계산 효율성을 높이는 것이 목표다. Voxel Grid 필터는 이 목적을 달성하는 가장 일반적이고 효과적인 방법 중 하나다.18</li>
<li><strong>원리:</strong> 이 필터는 3차원 공간을 사용자가 지정한 크기의 작은 정육면체, 즉 복셀(Voxel)로 나눈다. 그리고 각 복셀 내에 포함된 모든 포인트들을 그들의 무게 중심(Centroid)에 위치한 단 하나의 포인트로 근사(approximate)한다. 이 과정을 통해 포인트 클라우드의 밀도를 균일하게 만들고 데이터 양을 효과적으로 줄일 수 있다.18</li>
<li><strong>구현 (PCL - Point Cloud Library):</strong> PCL에서 <code>pcl::VoxelGrid</code> 클래스를 사용하여 간단하게 구현할 수 있다. 가장 중요한 파라미터는 <code>setLeafSize(lx, ly, lz)</code> 함수로 설정하는 복셀의 크기다. 복셀 크기를 작게 하면 더 많은 디테일이 보존되지만 데이터 감소 효과는 줄어든다. 반대로 크기를 키우면 데이터는 크게 줄지만 세밀한 구조가 손실될 수 있다. 따라서 이는 어플리케이션의 요구사항에 맞춰 정밀도와 계산량 사이의 균형을 맞추는 중요한 튜닝 파라미터다.18</li>
</ul>
<h4>2.1.2 Statistical Outlier Removal을 이용한 노이즈 및 이상치 제거</h4>
<ul>
<li><strong>목적:</strong> LiDAR 측정값에는 센서 자체의 노이즈나 빛의 흡수/반사 특성으로 인해 주변 포인트들과 동떨어진 위치에 생성되는 이상치(outlier)가 포함될 수 있다. 이러한 이상치들은 표면 법선(surface normal) 추정이나 포인트 클라우드 정합(registration)과 같은 후속 처리 단계에서 큰 오류를 야기하므로 반드시 제거해야 한다.22</li>
<li><strong>알고리즘:</strong> 이 필터는 각 포인트의 국소적인 밀도 특성을 통계적으로 분석하여 이상치를 식별한다. 알고리즘의 작동 방식은 다음과 같다 22:</li>
</ul>
<ol>
<li>포인트 클라우드의 각 포인트 <code>P_i</code>에 대해, 가장 가까운 <code>k</code>개의 이웃 포인트(k-nearest neighbors)를 찾는다.</li>
<li><code>P_i</code>로부터 <code>k</code>개의 이웃 포인트까지의 평균 거리를 계산한다.</li>
<li>모든 포인트에 대해 계산된 평균 거리들의 전체적인 분포를 구한다. 이 분포가 가우시안(정규) 분포를 따른다고 가정하고, 전체 분포의 평균(μ)과 표준편차(σ)를 계산한다.</li>
<li>각 포인트의 평균 거리가 <code>μ + α * σ</code> (여기서 <code>α</code>는 사용자가 지정하는 표준편차 배수)로 정의된 임계값을 벗어나면, 해당 포인트를 이상치로 간주하고 제거한다.</li>
</ol>
<ul>
<li><strong>구현 (PCL):</strong> <code>pcl::StatisticalOutlierRemoval</code> 클래스를 사용한다. <code>setMeanK(k)</code> 함수로 분석할 이웃의 수 <code>k</code>를 설정하고, <code>setStddevMulThresh(α)</code> 함수로 이상치 판단의 기준이 되는 표준편차 배수 <code>α</code>를 설정한다. <code>α</code> 값이 작을수록 더 공격적으로 이상치를 제거한다.22</li>
</ul>
<p>이 두 전처리 과정은 순서대로 적용하는 것이 효과적이다. 먼저 Voxel Grid 필터로 데이터의 양을 줄인 후, 더 적은 수의 포인트를 대상으로 계산 비용이 상대적으로 높은 Statistical Outlier Removal 필터를 적용하는 것이 전체적인 처리 속도를 향상시킨다. 이처럼 정제된 포인트 클라우드는 후속 LOAM 알고리즘의 성능과 안정성을 크게 향상시키는 기반이 된다.24</p>
<h3>2.2  IMU 교정: 드리프트와의 전쟁 선포</h3>
<p>IMU는 자율 비행 시스템의 동역학을 이해하는 데 필수적이지만, 그 측정값은 여러 노이즈 소스에 의해 오염되어 있다. 이러한 노이즈를 정확히 모델링하고 보상하지 않으면, IMU 데이터를 적분하는 과정에서 발생하는 드리프트로 인해 시스템 전체의 성능이 저하된다.</p>
<h4>2.2.1 IMU 오류 모델의 이해</h4>
<p>IMU 센서(가속도계, 자이로스코프)의 측정값은 이상적인 참값(true value)에 여러 확률적 오차 항들이 더해진 형태로 모델링된다. 주요 오차 항은 다음과 같다 4:</p>
<ul>
<li><strong>가산 백색 잡음 (Additive White Noise):</strong> 측정의 순간적인 불확실성을 나타내는 고주파 노이즈다. 이 노이즈는 시간에 따라 상관관계가 없으며, 평균이 0인 가우시안 분포를 따른다고 가정된다.</li>
<li><strong>바이어스 (Bias):</strong> 측정값에 더해지는 느리게 변하는 기상 변화: 비, 안개, 먼지, 오프셋(offset)이다. 바이어스는 시간에 따라 거의 변하지 않는 ’바이어스 불안정성(Bias Instability)’과, 시간에 따라 임의 보행(random walk)하는 ’비율 임의 보행(Rate Random Walk)’으로 구성된다.</li>
</ul>
<p>이러한 오차들은 단일 측정에서는 미미해 보일 수 있지만, 수백 Hz의 속도로 연속적으로 적분되면 위치 및 자세 오차가 빠르게 누적되어 심각한 드리프트를 유발한다.4</p>
<h4>2.2.2 알란 분산(Allan Variance) 분석: IMU의 숨겨진 노이즈 특성 파악</h4>
<ul>
<li><strong>목적:</strong> IMU의 고유한 확률적 노이즈 특성을 정량적으로 파악하기 위한 표준적인 오프라인 분석 기법이다. 이 분석을 통해 얻은 노이즈 파라미터는 칼만 필터의 공정 노이즈 공분산 행렬(<code>Q</code>)을 설정하는 데 사용되어 필터의 성능을 극대화한다.27</li>
<li><strong>절차:</strong></li>
</ul>
<ol>
<li><strong>데이터 수집:</strong> IMU를 진동과 온도 변화가 없는 안정적인 환경에 완전히 정지시킨 상태로 수 시간(최소 2시간, 길수록 좋음) 동안 가속도와 각속도 데이터를 수집한다.</li>
<li><strong>클러스터 생성:</strong> 전체 데이터 시퀀스를 다양한 시간 길이 <code>\tau</code>를 갖는 여러 개의 클러스터로 나눈다.</li>
<li><strong>알란 분산 계산:</strong> 각 <code>\tau</code>에 대해, 클러스터 평균들의 2-표본 분산(two-sample variance)을 계산한다. 이것이 알란 분산 <code>σ²(\tau)</code>이다.30</li>
<li><strong>알란 편차 플롯 생성:</strong> 알란 분산의 제곱근인 알란 편차 <code>σ(\tau)</code>를 <code>\tau</code>에 대해 log-log 스케일로 플로팅한다. 이 플롯을 ’시그마-타우 다이어그램’이라고도 부른다.29</li>
</ol>
<ul>
<li><strong>노이즈 파라미터 식별:</strong> log-log 스케일의 알란 편차 플롯은 특징적인 기울기를 가진 여러 영역으로 나뉜다. 이 기울기를 통해 주요 노이즈 항을 식별하고 그 계수를 산출할 수 있다 29:</li>
<li><strong>Angle/Velocity Random Walk (N):</strong> 플롯에서 기울기가 <strong>-1/2</strong>인 직선을 찾고, 이 직선을 <code>\tau = 1</code>초까지 연장했을 때의 <code>σ(\tau)</code> 값을 읽는다. 이 값은 각각 자이로스코프와 가속도계의 광대역 백색 잡음 계수에 해당한다.</li>
<li><strong>Bias Instability (B):</strong> 플롯에서 기울기가 <strong>0</strong>에 가까운, 즉 가장 평평하고 낮은 부분을 찾는다. 이 지점의 <code>σ(\tau)</code> 값을 <code>0.664</code>로 나누면 바이어스 불안정성 계수를 얻을 수 있다.</li>
<li><strong>Rate Random Walk (K):</strong> 플롯에서 기울기가 <strong>+1/2</strong>인 직선을 찾고, 이 직선을 <code>\tau = 3</code>초까지 연장했을 때의 <code>σ(\tau)</code> 값을 읽는다. 이는 바이어스의 랜덤 워크 특성을 나타내는 계수다.</li>
</ul>
<p>정확한 노이즈 파라미터(<code>N</code>, <code>B</code>, <code>K</code>)를 얻는 것은 ESKF(오류 상태 칼만 필터)의 성능에 지대한 영향을 미친다. 이 값들은 필터의 예측 단계에서 사용되는 공정 노이즈 공분산 행렬 <code>Q</code>를 구성하는 데 직접적으로 사용된다.31 부정확한</p>
<p><code>Q</code> 행렬은 필터가 IMU 예측값을 과도하게 신뢰하거나 불신하게 만들어, 결국 최적이 아닌 상태 추정이나 심할 경우 필터의 발산을 초래할 수 있다. 알란 분산 분석은 한 번의 오프라인 교정으로 온라인 융합 시스템 전체의 성능을 극적으로 향상시키는, 매우 중요한 엔지니어링 절차다.</p>
<h3>2.3  GNSS 이상치 제거: 멀티패스와의 싸움</h3>
<h4>2.3.1 문제점</h4>
<p>GNSS는 개활지에서 센티미터 수준의 정확도를 제공할 수 있지만, 도심이나 장애물이 많은 환경에서는 그 신뢰성이 크게 저하된다. 위성 신호가 건물과 같은 구조물에 반사된 후 수신기에 도달하는 다중경로(Multipath) 현상은 GNSS 측정값에 수 미터에서 수십 미터에 이르는 큰 오차를 유발한다. 이러한 오차는 일반적인 가우시안 노이즈 분포를 따르지 않는 이상치(outlier)의 형태로 나타나며, 표준적인 칼만 필터나 최소제곱법 기반의 위치 추정 알고리즘을 심각하게 오염시킨다.6 단 하나의 큰 이상치만으로도 필터의 상태 추정치가 완전히 잘못된 값으로 수렴할 수 있다.</p>
<h4>2.3.2 RANSAC (RANdom SAmple Consensus) 기반 이상치 탐지</h4>
<p>이러한 비-가우시안 이상치에 강인하게 대응하기 위해 RANSAC 알고리즘을 사용한 전처리 단계를 도입한다. RANSAC은 전체 데이터셋에 다수의 이상치가 포함되어 있다는 가정 하에, 일관성 있는 데이터의 최대 부분집합(inlier set)을 찾아내는 강력한 모델 피팅 기법이다.33</p>
<ul>
<li><strong>원리:</strong> RANSAC은 ’다수의 내재치(inlier)는 특정 모델 파라미터에 대해 일관된 지지를 보낼 것이지만, 이상치는 그렇지 않다’는 직관에 기반한다. 칼만 필터처럼 모든 데이터를 평균내어 오차를 최소화하려는 시도 대신, RANSAC은 이상치를 완전히 무시하고 내재치만으로 모델을 구성하는 전략을 취한다.34</li>
<li><strong>절차:</strong> GNSS 위치 추정에 RANSAC을 적용하는 과정은 다음과 같다:</li>
</ul>
<ol>
<li><strong>가설 생성 (Hypothesis Generation):</strong> 현재 수신 가능한 모든 위성 측정값(의사거리 등) 중에서, 위치를 계산하는 데 필요한 최소한의 위성 집합(Minimal Sample Set, MSS, 보통 4개)을 무작위로 선택한다. 이 MSS만을 사용하여 드론의 3D 위치를 계산한다. 이것이 하나의 ’가설 모델’이 된다.</li>
<li><strong>검증 (Verification):</strong> 선택되지 않은 나머지 모든 위성 측정값들을 사용하여, 1단계에서 계산된 가설 위치가 얼마나 정확한지 검증한다. 즉, 각 위성 측정값이 이 가설 위치와 일치하는지(미리 정의된 오차 임계값 이내에 있는지) 확인한다. 이 임계값 내에 들어오는 측정값들을 ‘동의 집합(Consensus Set)’ 또는 내재치(inlier)로 분류한다.</li>
<li><strong>반복:</strong> 위 1, 2단계를 미리 정해진 횟수만큼 반복한다. 매 반복마다 새로운 무작위 샘플로 가설을 생성하고, 그 가설을 지지하는 내재치의 수를 기록한다.</li>
<li><strong>최종 모델 선택:</strong> 모든 반복이 끝난 후, 가장 많은 내재치(가장 큰 동의 집합)를 확보한 가설 모델을 최적의 모델로 선택한다.</li>
<li><strong>최종 추정 (Refinement):</strong> 선택된 최적 모델의 내재치들만을 사용하여 최종적인 드론 위치를 정밀하게 다시 계산한다. 이 과정은 보통 최소제곱법을 통해 수행된다.</li>
</ol>
<p>이 RANSAC 과정을 통해 얻어진 ‘정제된’ GNSS 위치와 그에 해당하는 공분산은 이제 신뢰할 수 있는 측정값으로 간주될 수 있다. 이 값을 메인 융합 필터(ESKF)의 업데이트 단계에 사용함으로써, 다중경로로 인한 심각한 이상치가 필터 전체를 오염시키는 것을 효과적으로 방지할 수 있다.</p>
<hr />
<h2>3. 부: 융합의 심장 - 오류 상태 칼만 필터와 팩터 그래프 최적화</h2>
<p>데이터 정제를 통해 신뢰할 수 있는 측정값을 확보했다면, 이제 이들을 융합하여 드론의 상태를 정확하게 추정할 차례다. 이 과정의 핵심은 고주파의 IMU 데이터와 상대적으로 저주파이지만 정확한 LiDAR, GNSS 데이터를 결합하는 것이다. 본 튜토리얼에서는 LIO-SAM 아키텍처를 따라, 프론트엔드에서 LiDAR Odometry를 계산하고, 백엔드에서 ESKF와 팩터 그래프 최적화를 통해 전역적으로 일관된 궤적을 추정하는 방식을 다룬다.</p>
<h3>3.1  LiDAR Odometry의 원리: LOAM을 통한 특징점 기반의 움직임 추정</h3>
<p>수십만 개의 포인트로 구성된 전체 포인트 클라우드를 직접 정합하는 ICP(Iterative Closest Point)와 같은 방식은 계산 비용이 매우 높아 실시간 처리가 어렵다.7 LOAM(Lidar Odometry and Mapping)은 이 문제를 해결하기 위해, 기하학적으로 구별되는 소수의 ’특징점’만을 추출하여 움직임을 추정하는 효율적인 접근법을 제안한다.36</p>
<h4>3.1.1 곡률(Curvature) 기반 특징점 추출</h4>
<p>LOAM의 핵심 아이디어는 포인트 클라우드에서 안정적이고 반복적으로 검출될 수 있는 기하학적 특징을 찾는 것이다.</p>
<ul>
<li><strong>곡률 계산:</strong> 각 포인트의 주변에 있는 이웃 포인트들을 이용하여 해당 지점의 표면이 얼마나 휘어져 있는지를 나타내는 곡률(curvature)을 계산한다.</li>
<li><strong>특징점 분류:</strong> 계산된 곡률 값을 기준으로 포인트를 두 가지 주요 유형으로 분류한다 24:</li>
<li><strong>엣지 포인트 (Edge Points):</strong> 곡률이 매우 큰 지점. 이는 물체의 모서리나 날카로운 경계에 해당한다.</li>
<li><strong>평면 포인트 (Planar Points):</strong> 곡률이 매우 작은 지점. 이는 벽, 바닥, 천장과 같은 평평한 표면에 해당한다.</li>
<li><strong>균일한 분포:</strong> 특징점이 맵의 특정 영역에 집중되는 것을 방지하기 위해, 전체 스캔을 여러 하위 영역으로 나누고 각 영역에서 일정 수의 엣지 및 평면 포인트를 추출한다. 이는 정합의 안정성을 높이는 데 매우 중요하다.24</li>
</ul>
<h4>3.1.2 Scan-to-Map 정합을 통한 정밀한 상대 변환 추정</h4>
<p>추출된 특징점들은 드론의 움직임을 추정하는 데 사용된다. LOAM은 이전 스캔 하나(scan-to-scan)가 아닌, 여러 이전 스캔들이 누적된 지역 맵(local map)에 현재 스캔을 정합(scan-to-map)함으로써 드리프트를 효과적으로 억제한다.25</p>
<ul>
<li><strong>정합 과정:</strong></li>
</ul>
<ol>
<li>현재 스캔에서 추출된 <strong>엣지 포인트</strong>를 지역 맵에서 가장 가까운 **엣지 라인(두 개의 엣지 포인트로 정의됨)**에 정합한다.</li>
<li>현재 스캔에서 추출된 <strong>평면 포인트</strong>를 지역 맵에서 가장 가까운 **평면 패치(세 개의 평면 포인트로 정의됨)**에 정합한다.</li>
</ol>
<ul>
<li><strong>오차 최소화:</strong> 이 과정에서 ’점-선 거리(point-to-line distance)’와 ‘점-평면 거리(point-to-plane distance)’ 오차들의 합이 최소가 되는 현재 스캔의 상대적인 변환 행렬(회전 <code>R</code>과 이동 <code>t</code>)을 반복적으로 계산한다.36</li>
</ul>
<p>이 특징점 기반의 scan-to-map 정합 방식은 전체 포인트를 사용하는 것보다 훨씬 계산적으로 효율적이면서도 높은 정확도를 제공하여, 실시간 LiDAR Odometry의 핵심 기술로 자리 잡았다.</p>
<h3>3.2  IMU Preintegration: 고주파 IMU 측정값의 효율적 압축</h3>
<h4>3.2.1 이론적 배경: 왜 직접 적분은 비효율적인가</h4>
<p>팩터 그래프와 같은 최적화 기반의 SLAM 시스템에서는 일정 시간 동안의 모든 상태 변수(예: 여러 시점에서의 드론 자세)를 동시에 최적화한다. 만약 최적화 과정에서 과거의 어떤 상태 추정치(예: 1초 전의 드론 자세)가 수정되면, 그 상태에 의존하는 모든 미래의 측정값들을 다시 계산해야 한다. IMU는 200Hz 이상의 매우 높은 주파수로 측정값을 제공하므로, 과거 상태가 조금만 바뀌어도 그 이후의 수백, 수천 개의 IMU 측정값을 처음부터 다시 적분해야 하는 엄청난 계산 비효율이 발생한다.38</p>
<h4>3.2.2 수학적 유도: 두 키프레임 간의 상대 운동 제약(Constraint) 생성</h4>
<p>IMU Preintegration(사전적분)은 이 문제를 해결하는 우아한 수학적 기법이다.</p>
<ul>
<li><strong>핵심 아이디어:</strong> 두 키프레임(keyframe) <code>i</code>와 <code>j</code> 사이의 수많은 IMU 측정값들을, 시작 키프레임 <code>i</code>의 상태와는 무관한, 순수한 <strong>상대적인 움직임</strong>으로 미리 압축해 놓는 것이다.40 즉,</li>
</ul>
<p><code>i</code> 시점부터 <code>j</code> 시점까지 얼마나 회전하고, 속도가 얼마나 변했으며, 얼마나 이동했는지를 나타내는 <code>ΔR_ij</code>, <code>Δv_ij</code>, <code>Δp_ij</code> 값을 계산한다. 이 값들은 <code>i</code> 시점의 좌표계를 기준으로 표현된다.</p>
<ul>
<li>수학적 표현:</li>
</ul>
<p>키프레임 i와 j 사이의 IMU 측정값(a_m, ω_m)이 주어졌을 때, 사전적분된 상대 운동 측정값은 다음과 같이 정의된다.31<br />
<span class="math math-display">
  \Delta R_{ij} = \prod_{k=i}^{j-1} \text{Exp}((\omega_{m_k} - b_{g_k})\Delta t)
</span></p>
<p><span class="math math-display">
  \Delta v_{ij} = \sum_{k=i}^{j-1} \Delta R_{ik}(a_{m_k} - b_{a_k})\Delta t
</span></p>
<p><span class="math math-display">
  \Delta p_{ij} = \sum_{k=i}^{j-1} \left( \Delta v_{ik}\Delta t + \frac{1}{2}\Delta R_{ik}(a_{m_k} - b_{a_k})\Delta t^2 \right)
</span></p>
<p>여기서 <code>Exp(/)</code>는 <code>SO(3)</code> 그룹에서의 지수 맵(exponential map)을, <code>b_a</code>와 <code>b_g</code>는 각각 가속도계와 자이로스코프의 바이어스를 나타낸다.</p>
<ul>
<li>
<p><strong>장점:</strong></p>
</li>
<li>
<p><strong>불변성:</strong> 이렇게 계산된 <code>ΔR_ij</code>, <code>Δv_ij</code>, <code>Δp_ij</code>는 나중에 최적화를 통해 키프레임 <code>i</code>의 전역 자세 <code>R_i</code>, <code>p_i</code>가 어떻게 바뀌더라도 변하지 않는다.</p>
</li>
<li>
<p><strong>효율적 보정:</strong> 만약 IMU 바이어스 추정치 <code>b_a</code>, <code>b_g</code>가 업데이트되면, 전체 적분을 다시 할 필요 없이 1차 테일러 근사를 통해 사전적분된 값들을 매우 빠르게 보정할 수 있다.</p>
</li>
<li>
<p><strong>압축:</strong> 수백 개의 IMU 측정값들이 단 하나의 ’IMU 팩터’로 압축되어 팩터 그래프에 추가된다. 이 팩터는 키프레임 <code>i</code>와 <code>j</code>의 상태(자세, 속도, 위치, 바이어스)를 연결하는 강력한 제약 조건(constraint)으로 작용한다.39</p>
</li>
</ul>
<p>IMU 사전적분은 고주파의 IMU 데이터를 최적화 프레임워크에 효율적으로 통합할 수 있게 만든 핵심적인 이론적 돌파구이며, 현대의 고성능 VIO(Visual-Inertial Odometry) 및 LIO 시스템의 기반을 이룬다.</p>
<h3>3.3  오류 상태 칼만 필터(ESKF) 심층 해부</h3>
<p>ESKF는 비선형 시스템, 특히 IMU와 같이 회전 운동을 다루는 시스템의 상태를 추정하는 데 매우 효과적이고 안정적인 기법이다. 전체 상태를 직접 추정하는 표준 EKF(Extended Kalman Filter)와 달리, ESKF는 시스템의 ’오류’를 추정하는 간접적인 방식을 사용한다.</p>
<h4>3.3.1 상태 정의: 참(True), 공칭(Nominal), 오류(Error) 상태의 관계</h4>
<p>ESKF의 핵심 철학은 전체 상태를 두 부분으로 나누어 다루는 것이다.31</p>
<ul>
<li><strong>공칭 상태 (Nominal State) <code>x</code>:</strong> IMU 측정값을 직접 적분하여 얻는, 시스템의 비선형적인 움직임을 나타내는 주된 상태 값이다. 여기에는 노이즈가 없다고 가정한다.</li>
<li><strong>오류 상태 (Error State) <code>δx</code>:</strong> 공칭 상태에 포함된 작은 오차를 나타낸다. 이 오류는 항상 0에 가깝다고 가정되므로, 선형 시스템으로 근사할 수 있다.</li>
<li><strong>참 상태 (True State) <code>x_t</code>:</strong> 실제 시스템의 상태로, 공칭 상태와 오류 상태의 합성으로 표현된다.</li>
</ul>
<p><span class="math math-display">
x_t = x \oplus \delta x
</span></p>
<p>이 합성(composition) 연산 <code>⊕</code>는 상태 변수의 종류에 따라 다르게 정의된다 31:</p>
<ul>
<li>위치, 속도, 바이어스 (벡터 공간): 덧셈 <code>p_t = p + \delta p</code></li>
<li>자세 (회전 공간, <code>SO(3)</code>): 곱셈 <code>R_t = R \cdot \text{Exp}([\delta\theta]_\times)</code> 또는 <code>q_t = q \otimes \delta q</code></li>
</ul>
<p>이러한 분리 덕분에 칼만 필터는 항상 0 주변에서 동작하는 선형적인 오류 상태만을 다루게 되므로, EKF의 선형화 가정이 훨씬 더 잘 만족되어 필터의 안정성과 정확성이 크게 향상된다.43</p>
<p><strong>표 2: ESKF 상태 변수 정의</strong></p>
<table><thead><tr><th>상태</th><th>참 상태 (<code>x_t</code>)</th><th>공칭 상태 (<code>x</code>)</th><th>오류 상태 (<code>δx</code>)</th><th>차원</th></tr></thead><tbody>
<tr><td>위치</td><td><code>p_t</code></td><td><code>p</code></td><td><code>δp</code></td><td>3</td></tr>
<tr><td>속도</td><td><code>v_t</code></td><td><code>v</code></td><td><code>δv</code></td><td>3</td></tr>
<tr><td>자세</td><td><code>q_t</code></td><td><code>q</code></td><td><code>δθ</code></td><td>3 (오류)</td></tr>
<tr><td>가속도 바이어스</td><td><code>b_{at}</code></td><td><code>b_a</code></td><td><code>δb_a</code></td><td>3</td></tr>
<tr><td>자이로 바이어스</td><td><code>b_{gt}</code></td><td><code>b_g</code></td><td><code>δb_g</code></td><td>3</td></tr>
</tbody></table>
<h4>3.3.2 예측(Prediction) 단계: IMU 측정을 이용한 공칭 상태 및 오차 공분산 전파</h4>
<p>예측 단계에서는 외부 측정값 없이, 오직 IMU 측정값만을 사용하여 시스템의 상태를 다음 시간으로 전파시킨다.</p>
<ul>
<li><strong>공칭 상태 전파:</strong> IMU 측정값(<code>a_m</code>, <code>ω_m</code>)과 현재의 바이어스 추정치를 사용하여 비선형 운동학 모델을 통해 공칭 상태(위치 <code>p</code>, 속도 <code>v</code>, 자세 <code>q</code>)를 수치적으로 적분한다.31<br />
<span class="math math-display">
\dot{p} = v \\
\dot{v} = R(a_m - b_a) + g \\
\dot{q} = \frac{1}{2} q \otimes (0, \omega_m - b_g) \\
</span><br />
<strong>오류 공분산 전파:</strong> 선형화된 오류 상태 동역학 모델을 사용하여 오류 공분산 행렬 <code>P</code>를 다음 시간으로 전파한다. 이 과정에서 IMU의 노이즈(알란 분산으로 구한)가 공정 노이즈 공분산 <code>Q_d</code>로 시스템에 주입된다.31<br />
<span class="math math-display">
P_{k|k-1} = F_x P_{k-1|k-1} F_x^T + Q_d
</span><br />
여기서 <code>F_x</code>는 상태 전이 행렬(State Transition Matrix)이며, 이산화된 연속 시간 오류 동역학으로부터 유도된다.</li>
</ul>
<p><strong>표 3: ESKF 예측 단계 핵심 방정식</strong></p>
<table><thead><tr><th>설명</th><th>방정식</th></tr></thead><tbody>
<tr><td>오류 공분산 예측</td><td><span class="math math-inline">P \leftarrow F_x P F_x^T + Q_d</span></td></tr>
<tr><td>상태 전이 행렬 (<code>F_x</code>)</td><td><span class="math math-inline">\begin{bmatrix} I &amp; I\Delta t &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; I &amp; -R [a_m - b_a]_\times \Delta t &amp; -R\Delta t &amp; 0 \\ 0 &amp; 0 &amp; \text{Exp}(-[\omega_m - b_g]_\times \Delta t) &amp; 0 &amp; -I\Delta t \\ 0 &amp; 0 &amp; 0 &amp; I &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; I \end{bmatrix}</span></td></tr>
<tr><td>공정 노이즈 (<code>Q_d</code>)</td><td><span class="math math-inline">\text{diag}(\sigma_{v}^2 I, \sigma_{\theta}^2 I, \sigma_{b_a}^2 I, \sigma_{b_g}^2 I)</span></td></tr>
</tbody></table>
<h4>3.3.3 업데이트(Update) 단계: 외부 측정을 이용한 오차 보정</h4>
<p>업데이트 단계에서는 GNSS 위치나 LiDAR Odometry와 같은 외부 측정값을 사용하여 예측된 상태를 보정한다.</p>
<ol>
<li>
<p><strong>혁신(Innovation) 계산:</strong> 실제 측정값 <code>y</code>와 현재 공칭 상태로부터 예측된 측정값 <code>h(x)</code> 사이의 차이를 계산한다. <code>y_{innov} = y - h(x)</code>.</p>
</li>
<li>
<p><strong>측정 자코비안 계산:</strong> 측정 모델 <code>h</code>를 오류 상태 <code>δx</code>에 대해 편미분하여 측정 자코비안 <code>H</code>를 계산한다.</p>
</li>
<li>
<p><strong>칼만 이득(Kalman Gain) 계산:</strong> 오류 공분산 <code>P</code>, 측정 자코비안 <code>H</code>, 측정 노이즈 공분산 <code>V</code>를 이용하여 칼만 이득 <code>K</code>를 계산한다.<br />
<span class="math math-display">
K = P H^T (H P H^T + V)^{-1}
</span><br />
<strong>오류 상태 및 공분산 업데이트:</strong> 계산된 칼만 이득과 혁신을 사용하여 오류 상태의 평균과 공분산을 업데이트한다.<br />
<span class="math math-display">
\hat{\delta x} \leftarrow K y_{innov} \\
P \leftarrow (I - KH)P \\
</span><br />
<strong>공칭 상태 주입(Injection):</strong> 계산된 오류 상태 <code>δx</code>를 공칭 상태 <code>x</code>에 “주입“하여 보정한다.<br />
<span class="math math-display">
p \leftarrow p + \hat{\delta p}\\
v \leftarrow v + \hat{\delta v}\\
q \leftarrow q \otimes \text{quat}(\hat{\delta \theta})\\
b_a \leftarrow b_a + \hat{\delta b_a}\\
b_g \leftarrow b_g + \hat{\delta b_g}\\
</span><br />
<strong>리셋(Reset):</strong> 공칭 상태가 보정되었으므로, 오류 상태의 평균은 다시 0으로 리셋하고, 공분산 행렬도 이에 맞게 재조정하여 다음 예측 단계를 준비한다.31</p>
</li>
</ol>
<p><strong>표 4: ESKF 업데이트 단계 핵심 방정식</strong></p>
<table><thead><tr><th>설명</th><th>방정식</th></tr></thead><tbody>
<tr><td>혁신 (Innovation)</td><td><span class="math math-inline">y_{innov} = y - h(x)</span></td></tr>
<tr><td>칼만 이득 (Kalman Gain)</td><td><span class="math math-inline">K = P H^T (H P H^T + V)^{-1}</span></td></tr>
<tr><td>오류 상태 업데이트</td><td><span class="math math-inline">\hat{\delta x} \leftarrow K y_{innov}</span></td></tr>
<tr><td>공분산 업데이트</td><td><span class="math math-inline">P \leftarrow (I - KH)P</span></td></tr>
<tr><td>공칭 상태 주입</td><td><span class="math math-inline">x \leftarrow x \oplus \hat{\delta x}</span></td></tr>
</tbody></table>
<h3>3.4  LIO-SAM 아키텍처: 팩터 그래프를 이용한 전역 최적화</h3>
<p>ESKF가 고주파의 실시간 상태 추정에 뛰어나다면, 팩터 그래프는 일정 시간 동안의 전체 궤적을 전역적으로 최적화하여 더 높은 정확도와 일관성을 제공하는 백엔드(back-end) 기술이다. LIO-SAM은 이 두 가지 접근법의 장점을 결합한 하이브리드 구조를 가진다.11</p>
<h4>3.4.1 팩터 그래프(Factor Graph)의 구성 요소</h4>
<p>팩터 그래프는 상태 변수와 그들 사이의 제약 조건을 그래프 형태로 표현한 것이다.</p>
<ul>
<li><strong>변수 노드 (Variable Nodes):</strong> 우리가 추정하고자 하는 미지의 값들을 나타낸다. LIO-SAM에서는 특정 시간(키프레임)에서의 드론의 상태(자세 <code>x_i = {p_i, q_i}</code>, 속도 <code>v_i</code>, IMU 바이어스 <code>b_i</code>)가 변수 노드가 된다.</li>
<li><strong>팩터 노드 (Factor Nodes):</strong> 센서 측정이나 시스템 모델로부터 얻어지는 변수 노드들 간의 확률적 제약 조건을 나타낸다. 각 팩터는 해당 제약 조건이 얼마나 만족되는지를 나타내는 오차(비용) 함수와 연관된다.</li>
</ul>
<h4>3.4.2 주요 팩터 분석</h4>
<p>LIO-SAM의 팩터 그래프는 다음과 같은 주요 팩터들로 구성된다:</p>
<ul>
<li><strong>IMU Preintegration Factor:</strong> 2.2절에서 설명한 IMU 사전적분 값(<code>ΔR_ij</code>, <code>Δv_ij</code>, <code>Δp_ij</code>)을 이용하여 연속된 두 키프레임 <code>i</code>와 <code>j</code>의 상태(<code>x_i</code>, <code>v_i</code>, <code>b_i</code>와 <code>x_j</code>, <code>v_j</code>, <code>b_j</code>)를 연결한다. 이 팩터는 고주파의 동역학 정보를 시스템에 제공한다.</li>
<li><strong>LiDAR Odometry Factor:</strong> 2.1절에서 계산한 LiDAR Odometry 결과를 이용하여 연속된 두 키프레임 간의 상대적인 변환(relative pose)을 제약한다.</li>
<li><strong>GNSS Factor:</strong> 1.3절에서 정제된 GNSS 측정값을 이용하여 특정 키프레임의 전역 절대 위치에 대한 사전 정보(prior)를 제공한다. 이 팩터는 궤적의 드리프트를 전역 좌표계에 고정시키는 역할을 한다.</li>
<li><strong>Loop Closure Factor:</strong> 드론이 이전에 방문했던 장소를 다시 인식했을 때(예: LiDAR 스캔 매칭을 통해), 현재 키프레임과 과거의 키프레임 사이에 새로운 상대 변환 팩터를 추가한다. 이는 시간이 지남에 따라 누적된 전체 궤적의 드리프트를 극적으로 줄여주는 가장 강력한 제약 조건 중 하나다.</li>
</ul>
<h4>3.4.3 GTSAM 기반의 최적화</h4>
<p>LIO-SAM은 **GTSAM (Georgia Tech Smoothing and Mapping)**이라는 강력한 C++ 라이브러리를 백엔드로 사용한다.11</p>
<ul>
<li><strong>비선형 최소제곱 문제:</strong> GTSAM은 팩터 그래프를 구성하고, 그래프에 포함된 모든 팩터들의 오차 제곱 합(sum of squared errors)을 최소화하는 변수 노드들의 상태 값을 찾는다. 이는 본질적으로 비선형 최소제곱 최적화 문제다.</li>
<li><strong>Smoothing vs. Filtering:</strong> 칼만 필터가 매 측정마다 상태를 순차적으로 업데이트하고 과거 상태는 버리는 ‘필터링(filtering)’ 방식인 반면, 팩터 그래프는 일정 시간 윈도우(sliding window) 내의 모든 과거 상태와 측정값을 동시에 고려하여 최적화하는 ‘스무딩(smoothing)’ 방식이다. 이 덕분에 스무딩은 필터링보다 더 많은 정보를 활용하여 더 정확하고 전역적으로 일관된 결과를 얻을 수 있다.6</li>
</ul>
<p>이러한 팩터 그래프 기반의 전역 최적화는 LIO-SAM이 장시간 동안 복잡한 환경에서 낮은 드리프트와 높은 정확도를 유지할 수 있는 핵심적인 이유다.</p>
<hr />
<h2>4. 부: 지능의 구현 - 지도 작성 및 경로 계획</h2>
<p>성공적인 센서 융합을 통해 드론의 정확한 실시간 위치와 자세(Pose)를 얻었다면, 이제 이 정보를 활용하여 자율 비행의 고차원적인 임무를 수행할 수 있다. 그 핵심은 주변 환경을 이해하는 ’지도 작성(Mapping)’과 목표 지점까지 안전하게 이동하는 ’경로 계획(Path Planning)’이다.</p>
<h3>4.1  3D 환경 지도 작성: 비행 공간의 이해</h3>
<p>정확한 지도는 드론이 자신의 위치를 파악하고(localization), 장애물을 회피하며, 임무를 계획하는 데 필수적인 기반이다.</p>
<h4>4.1.1 다중 LiDAR 데이터 통합 전략</h4>
<p>드론에 장착된 3개의 LiDAR(전방 Avia, 상/하부 Mid-360)로부터 들어오는 포인트 클라우드는 각각 센서 자신의 좌표계를 기준으로 표현된다. 이를 하나의 일관된 지도로 만들기 위해서는 다음 과정이 필요하다.</p>
<ol>
<li><strong>좌표 변환:</strong> 2부에서 최적화된 드론의 전역 자세(Global Pose)를 사용한다. 각 LiDAR 스캔이 수집된 시점의 드론 자세를 기준으로, 각 포인트 클라우드를 전역 좌표계(Global Frame, 예: ‘map’ 또는 ‘world’ 프레임)로 변환한다.</li>
<li><strong>데이터 병합:</strong> 전역 좌표계로 변환된 전방, 상부, 하부의 포인트 클라우드들을 하나의 누적된 포인트 클라우드 맵으로 합친다.</li>
</ol>
<p>이 과정의 정확성은 각 센서의 드론 본체에 대한 상대적인 위치와 방향, 즉 **외부 파라미터 교정(Extrinsic Calibration)**이 얼마나 정밀하게 이루어졌는지에 크게 의존한다.</p>
<h4>4.1.2 OctoMap: 확률적 3차원 복셀 맵 생성 및 실시간 업데이트</h4>
<p>단순한 포인트 클라우드 맵은 점유된 공간만을 표현할 뿐, 드론이 비행할 수 있는 ’비어 있는 공간(Free Space)’에 대한 정보를 명시적으로 제공하지 않는다. OctoMap은 이러한 한계를 극복하는 효율적이고 강력한 3D 지도 표현 방식이다.</p>
<ul>
<li><strong>원리:</strong> OctoMap은 3차원 공간을 **옥트리(Octree)**라는 계층적 데이터 구조로 표현한다.44 큰 정육면체 공간에서 시작하여, 정보가 필요한 영역(예: 물체 표면 근처)만 재귀적으로 8개의 작은 자식 정육면체(복셀)로 분할한다. 이를 통해 넓은 빈 공간은 큰 복셀 몇 개로, 복잡한 구조물은 작은 복셀들로 효율적으로 표현하여 메모리 사용량을 크게 줄인다.</li>
<li><strong>확률적 업데이트:</strong> 각 말단 노드(복셀)는 단순히 ‘점유’ 또는 ‘자유’ 상태가 아닌, <strong>점유 확률(Occupancy Probability)</strong> 값을 가진다. 지도 업데이트는 LiDAR 광선(Ray)을 기반으로 한 베이즈 업데이트를 통해 이루어진다 44:</li>
<li>LiDAR 센서의 원점(드론의 현재 위치)에서부터 측정된 포인트까지의 광선이 통과하는 모든 복셀은 ‘자유(Free)’ 공간일 확률이 높아진다.</li>
<li>광선이 최종적으로 도달하여 반사된 지점이 포함된 복셀은 ‘점유(Occupied)’ 공간일 확률이 높아진다.</li>
<li>이러한 확률적 접근 방식을 통해, 센서 측정의 불확실성을 자연스럽게 모델링하고, 여러 번의 측정을 통해 지도에 대한 신뢰도를 점차 높여갈 수 있다. 또한, 아직 관측되지 않은 ‘미탐사(Unknown)’ 공간을 ‘자유’ 공간과 명확히 구분할 수 있게 된다.</li>
<li><strong>ROS 구현:</strong> ROS 환경에서는 <code>octomap_server</code> 패키지가 이 기능을 표준적으로 제공한다. <code>octomap_server</code> 노드는 <code>sensor_msgs/PointCloud2</code> 토픽과 해당 포인트 클라우드가 촬영된 센서의 자세 정보(<code>tf</code> 변환)를 구독하여 실시간으로 OctoMap을 생성하고, 이를 <code>octomap_msgs/Octomap</code> 메시지 형태나 시각화용 마커(MarkerArray), 포인트 클라우드 등의 토픽으로 발행한다.45</li>
</ul>
<p>정확한 LIO(LiDAR-Inertial Odometry)로부터 얻은 자세 추정치는 양질의 지도를 만드는 데 있어 절대적인 전제 조건이다. 자세 추정에 오차가 있으면, 지도상의 물체들이 여러 겹으로 겹쳐 보이거나 흐릿하게 나타나는 등 지도의 일관성이 깨지게 된다. 경로 계획 알고리즘은 ’점유’된 곳뿐만 아니라 ’자유’로운 곳에 대한 정보도 필요로 하므로, 미탐사 영역까지 명확히 구분해주는 OctoMap은 자율 비행을 위한 필수적인 지도 표현 방식이다.</p>
<h3>4.2  전역 및 지역 경로 계획: 목표 지점까지의 안전한 길 찾기</h3>
<p>안전하고 효율적인 자율 비행을 위해서는 계층적인 경로 계획(Hierarchical Path Planning) 접근법이 널리 사용된다. 이는 계산 비용이 높은 전역적인 최적 경로 탐색과, 실시간으로 빠르게 반응해야 하는 지역적인 충돌 회피를 분리하여 처리하는 방식이다.47</p>
<h4>4.2.1 전역 경로 계획: A* 알고리즘을 이용한 복셀 맵 기반 최적 경로 탐색</h4>
<ul>
<li>
<p><strong>원리:</strong> A*(A-Star) 알고리즘은 시작점에서 목표점까지의 최단 경로를 찾는 대표적인 그래프 탐색 알고리즘이다. 실제 이동 비용과 목표점까지의 예상 비용(휴리스틱)을 함께 고려하여 무작위 탐색을 줄이고 효율적으로 최적 경로를 찾아낸다.48</p>
</li>
<li>
<p><strong>3D 적용:</strong> 3.1절에서 생성한 OctoMap을 전역 경로 계획을 위한 그래프로 활용한다.</p>
</li>
<li>
<p>OctoMap의 ‘자유(Free)’ 상태인 복셀들을 그래프의 노드(Node)로 간주한다. ‘점유(Occupied)’ 상태인 복셀은 이동 불가능한 장애물이다.</p>
</li>
<li>
<p>인접한 자유 복셀 사이의 이동을 그래프의 엣지(Edge)로 간주하고, 이동에 따른 비용(Cost)을 부여한다.</p>
</li>
<li>
<p><strong>비용 함수:</strong> A*는 각 노드 <code>n</code>에 대해 다음 비용 함수 <code>f(n)</code>을 평가하여 탐색할 다음 노드를 결정한다.50<br />
<span class="math math-display">
f(n) = g(n) + h(n)
</span></p>
</li>
<li>
<p><code>g(n)</code>: 시작 노드에서 현재 노드 <code>n</code>까지 이동하는 데 소요된 실제 비용(예: 이동 거리).</p>
</li>
<li>
<p><code>h(n)</code>: 현재 노드 <code>n</code>에서 최종 목표 노드까지의 예상 비용. 보통 계산이 빠른 유클리드 거리(Euclidean distance)를 휴리스틱 함수로 사용한다.</p>
</li>
<li>
<p><strong>경로 생성:</strong> A* 알고리즘은 <code>f(n)</code> 값이 가장 작은 노드를 우선적으로 탐색하여, 시작점에서 목표점까지 이어지는 복셀 시퀀스, 즉 전역 경로(Global Path)를 생성한다.</p>
</li>
</ul>
<h4>4.2.2 지역 경로 계획: DWA(Dynamic Window Approach)를 이용한 동적 충돌 회피</h4>
<p>A*가 생성한 전역 경로는 이상적인 ’지도’일 뿐, 실제 드론이 따라가야 할 세부적인 제어 명령은 아니다. DWA는 전역 경로를 이정표 삼아, 실시간으로 변화하는 주변 환경과 드론의 물리적 한계를 고려하여 실제 모터에 전달할 최적의 속도(선속도 <code>v</code>, 각속도 <code>ω</code>)를 결정하는 지역 경로 계획(Local Planning) 기법이다.51</p>
<ul>
<li><strong>원리:</strong> DWA는 경로 공간이 아닌 속도 공간(Velocity Space)에서 직접 최적의 제어 명령을 탐색한다.52</li>
<li><strong>동적 창 (Dynamic Window):</strong> 드론이 다음 짧은 시간 간격(<code>Δt</code>) 동안 도달할 수 있는 속도의 집합을 ’동적 창’으로 정의한다. 이 창은 다음 두 가지 제약 조건에 의해 결정된다:</li>
</ul>
<ol>
<li>드론의 최대/최소 속도 및 각속도.</li>
<li>드론의 최대 가속/감속 능력과 현재 속도.</li>
</ol>
<ul>
<li><strong>속도 샘플링 및 평가:</strong></li>
</ul>
<ol>
<li><strong>샘플링:</strong> 동적 창 내에서 가능한 여러 <code>(v, ω)</code> 속도 쌍을 샘플링한다.</li>
<li><strong>궤적 예측:</strong> 각 샘플링된 속도로 <code>Δt</code> 시간 동안 주행한다고 가정하고, 그 결과로 생성될 단기적인 미래 궤적을 시뮬레이션한다. 만약 예측된 궤적이 장애물(OctoMap의 점유 복셀)과 충돌한다면 해당 속도 쌍은 즉시 폐기한다.</li>
<li><strong>목적 함수 평가:</strong> 충돌하지 않는 안전한 궤적들에 대해, 미리 정의된 목적 함수(Objective Function)를 사용하여 점수를 매긴다. 목적 함수는 보통 다음 세 가지 항목의 가중치 합으로 구성된다 52:</li>
</ol>
<ul>
<li><strong>목표 지향성 (Goal Heading):</strong> 예측된 궤적의 끝점이 전역 경로(A* 경로)에 얼마나 가까운가.</li>
<li><strong>장애물 회피 (Obstacle Avoidance):</strong> 예측된 궤적이 가장 가까운 장애물로부터 얼마나 멀리 떨어져 있는가.</li>
<li><strong>속도 (Velocity):</strong> 전진 속도가 얼마나 빠른가.</li>
<li><strong>최적 제어 선택:</strong> 모든 안전한 궤적 중에서 목적 함수 점수가 가장 높은 궤적에 해당하는 <code>(v, ω)</code> 속도 쌍을 최종 제어 명령으로 선택하여 모터에 전달한다.</li>
</ul>
<p>이러한 전역/지역 플래너의 조합은 매우 강인하고 효과적인 내비게이션 아키텍처를 구성한다. A*는 드론이 큰 규모의 막다른 길에 빠지는 것을 방지하는 전략적인 그림을 제공하고, DWA는 지도에 없던 동적 장애물에 반응하고 드론의 물리적 한계를 준수하는 전술적인 실시간 제어를 담당한다. 이 계층적 접근법은 계산 비용이 높은 전역 탐색과 빠른 반응성이 요구되는 지역 제어를 효과적으로 분리한다.47</p>
<hr />
<h2>5. 결론: 성공적인 시스템 구축을 위한 제언</h2>
<p>본 튜토리얼에서 제시한 LiDAR, IMU, GNSS 융합 파이프라인은 강인한 자율 비행 드론을 구현하기 위한 강력한 청사진이다. 하지만 성공적인 시스템을 구축하기 위해서는 알고리즘에 대한 이해를 넘어, 세심한 파라미터 튜닝과 실제 환경의 다양한 도전 과제에 대한 고려가 필수적이다.</p>
<h3>5.1 핵심 파라미터 튜닝 가이드: 성능을 좌우하는 변수들</h3>
<p>시스템의 성능은 여러 핵심 파라미터의 값에 크게 좌우된다. 각 파라미터는 서로 영향을 미치므로, 체계적인 접근과 반복적인 실험을 통해 최적의 값을 찾아야 한다.</p>
<ul>
<li><strong>전처리 단계:</strong></li>
<li><code>pcl::VoxelGrid</code>의 <code>leaf_size</code>: 작을수록 정밀하지만 계산량이 많아진다. 드론의 속도와 처리 능력에 맞춰, odometry가 실패하지 않는 선에서 최대한 작게 설정하는 것이 좋다.</li>
<li><code>pcl::StatisticalOutlierRemoval</code>의 <code>MeanK</code>와 <code>StddevMulThresh</code>: <code>MeanK</code>는 환경의 포인트 밀도에 따라, <code>StddevMulThresh</code>는 센서 노이즈 수준에 따라 결정된다. 너무 공격적으로 설정하면 유효한 데이터까지 제거할 수 있으므로 주의해야 한다.</li>
<li><strong>LOAM (LiDAR Odometry):</strong></li>
<li><code>MaxSharpEdgePoints</code>, <code>MaxLessSharpEdgePoints</code> 등 특징점 추출 개수: 환경의 복잡도에 따라 조절한다. 특징이 풍부한 환경에서는 개수를 줄여도 되지만, 복도와 같이 구조가 단조로운 환경에서는 더 많은 특징점을 추출해야 안정적인 정합이 가능하다.24</li>
<li><strong>ESKF / 팩터 그래프 최적화:</strong></li>
<li><strong>측정 노이즈 공분산 (<code>Q</code>, <code>V</code>):</strong> 시스템 성능에 가장 결정적인 영향을 미치는 파라미터다. IMU의 공정 노이즈 <code>Q</code>는 1.2절에서 설명한 알란 분산 분석을 통해 얻은 값을 초기값으로 설정하고, 실제 비행 데이터를 보며 미세 조정해야 한다. GNSS와 LiDAR Odometry의 측정 노이즈 <code>V</code>는 각 센서의 사양과 실제 환경에서의 성능 평가를 통해 결정된다. 이 값들은 필터가 각 센서 측정값을 얼마나 신뢰할지를 결정한다.</li>
<li><strong>경로 계획:</strong></li>
<li>DWA 목적 함수의 가중치 (<code>path_distance_bias</code>, <code>goal_distance_bias</code>, <code>occdist_scale</code>): 이 가중치들은 드론의 주행 성향을 결정한다. <code>occdist_scale</code>을 높이면 장애물을 멀리서부터 회피하는 보수적인 움직임을 보이고, <code>path_distance_bias</code>를 높이면 전역 경로를 더 공격적으로 따라가게 된다. 임무의 성격(고속 주행, 정밀 작업 등)에 맞게 튜닝해야 한다.47</li>
</ul>
<h3>5.2 실제 환경에서의 도전 과제: 동적 객체, 기상 변화, 센서 고장 대응</h3>
<p>본 튜토리얼에서 다룬 아키텍처는 주로 정적인 환경을 가정한다. 실제 환경에서는 더 복잡한 문제들이 발생할 수 있다.</p>
<ul>
<li><strong>동적 객체:</strong> 움직이는 사람, 차량 등은 정적 지도를 오염시키고, LiDAR Odometry가 이들을 고정된 배경으로 착각하여 잘못된 움직임을 추정하게 만들 수 있다. 이를 해결하기 위해서는 딥러닝 기반의 객체 탐지 및 추적 모듈을 추가하여 동적 객체를 식별하고, 이들을 지도 업데이트나 odometry 계산에서 제외하는 과정이 필요하다.54</li>
<li><strong>기상 변화:</strong> 비, 안개, 먼지, 강한 햇빛 등은 LiDAR 센서의 성능을 저하시킬 수 있다. 특히 악천후 조건에서의 강인성을 높이기 위해서는, 이러한 환경 변화에 덜 민감한 Radar와 같은 보조 센서를 추가로 융합하는 것을 고려할 수 있다.54</li>
<li><strong>센서 고장:</strong> 센서 융합 시스템의 큰 장점 중 하나는 하나의 센서가 고장 나더라도 성능이 저하된 상태(Degraded mode)로 임무를 지속할 수 있는 잠재력이다.9 이를 실현하기 위해서는 실시간으로 각 센서의 상태를 모니터링하고, 고장이 감지되었을 때 해당 센서의 데이터를 융합 과정에서 배제하거나 신뢰도를 낮추는 고장 탐지 및 분리(Fault Detection and Isolation, FDI) 로직을 설계하는 것이 중요하다.</li>
</ul>
<h3>5.3 미래 전망: 차세대 융합 기술 동향</h3>
<p>로보틱스 분야는 빠르게 발전하고 있으며, 센서 융합 기술 또한 새로운 패러다임으로 진화하고 있다.</p>
<ul>
<li><strong>딥러닝 기반 SLAM:</strong> 전통적인 기하학 기반의 SLAM 기법에 딥러닝을 접목하려는 연구가 활발하다. 딥러닝을 통해 더 강인한 특징점을 추출하거나, 데이터 연관(data association) 문제를 해결하고, 동적 객체를 의미론적으로(semantically) 분리하여 제거하는 등 기존 기법의 한계를 극복하려는 시도가 이루어지고 있다.56</li>
<li><strong>다중 로봇 협력 SLAM (Multi-Robot Collaborative SLAM):</strong> 여러 대의 드론이 각자 수집한 지도와 위치 정보를 실시간으로 공유하고 병합하여, 단일 드론으로는 불가능했던 빠르고 광범위한 탐사와 지도 작성을 수행하는 기술이다.</li>
<li><strong>새로운 센서 모달리티 융합:</strong> 이벤트 카메라(Event Camera)는 조도 변화에 매우 강하고 빠른 움직임을 낮은 지연 시간으로 포착할 수 있으며, 열화상 카메라(Thermal Camera)는 연기나 어둠 속에서도 사람이나 동물을 탐지할 수 있다. 이러한 새로운 센서들을 기존의 LiDAR-IMU-GNSS 시스템에 융합하여, 특정 극한 환경에서의 인지 능력과 강인성을 획기적으로 향상시키는 연구가 진행 중이다.54</li>
</ul>
<p>본 튜토리얼이 제시한 원리와 기법들을 깊이 이해하고, 실제 환경의 복잡성을 고려하여 시스템을 설계하고 끊임없이 개선해 나간다면, 어떤 환경에서도 신뢰성 있게 임무를 수행하는 진정한 의미의 자율 비행 드론을 구현할 수 있을 것이다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>Incorporating GNSS Information with LIDAR-Inertial Odometry for Accurate Land-Vehicle Localization - arXiv, accessed July 21, 2025, https://arxiv.org/html/2503.23199v1</li>
<li>Exploring LiDAR Drones: Applications &amp; Industry Uses - Flyability, accessed July 21, 2025, https://www.flyability.com/blog/lidar-drone</li>
<li>Strengths and limitations of LiDAR - Scout Aerial Australia, accessed July 21, 2025, https://www.scoutaerial.com.au/article-lidar/</li>
<li>IMU Challenges and Limitations - ANELLO, accessed July 21, 2025, https://www.anellophotonics.com/challenges-and-limitations</li>
<li>Advantages and Disadvantages of Inertial Measurement Units, accessed July 21, 2025, https://inertiallabs.com/advantages-and-disadvantages-of-inertial-measurement-units/</li>
<li>A GNSS/LiDAR/IMU Pose Estimation System Based on … - MDPI, accessed July 21, 2025, https://www.mdpi.com/2072-4292/15/3/790</li>
<li>High Definition 3D Map Creation Using GNSS/IMU/LiDAR Sensor …, accessed July 21, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC7039384/</li>
<li>What is sensor fusion? 1 + 1 = 50 | Ainstein, accessed July 21, 2025, https://ainstein.ai/what-is-sensor-fusion-1-1-50/</li>
<li>Sensors Fusion: An Overview - AZoSensors, accessed July 21, 2025, https://www.azosensors.com/article.aspx?ArticleID=3123</li>
<li>Precision without GPS: Multi-Sensor Fusion for Autonomous Drone Navigation in Complex Environments - ijircst.org, accessed July 21, 2025, https://www.ijircst.org/DOC/6-Precision-without-GPS-Multi-Sensor-Fusion-for-Autonomous-Drone-Navigation-in-Complex-Environments.pdf</li>
<li>LIO_SAM - Autoware Documentation, accessed July 21, 2025, https://autowarefoundation.github.io/autoware-documentation/pr-279/how-to-guides/integrating-autoware/creating-maps/open-source-slam/lio-sam/</li>
<li>Livox AVIA - LiDAR - BEYOND VISION, accessed July 21, 2025, https://beyond-vision.com/payloads/livox-avia-lidar/</li>
<li>Specs - Avia LiDAR sensor - Livox, accessed July 21, 2025, https://www.livoxtech.com/avia/specs</li>
<li>LIDAR for surveying drones: Functionality, advantages and disadvantag - Airclip, accessed July 21, 2025, https://www.airclip.de/LIDAR-for-surveying-drones-Functionality-advantages-and-disadvantages</li>
<li>Specs - Mid-360 LiDAR Sensor - Livox, accessed July 21, 2025, https://www.livoxtech.com/mid-360/specs</li>
<li>Livox Mid-360 - Sachtleben Technology, accessed July 21, 2025, https://www.sachtleben-technology.com/wp-content/uploads/sites/5/2024/07/LivoxMid-360UserManual.pdf</li>
<li>Unitree LIVOX MID360 LiDAR - STEMfinity, accessed July 21, 2025, https://stemfinity.com/products/livox-mid360-lidar</li>
<li>Downsampling a PointCloud using a VoxelGrid filter - Point Cloud Library, accessed July 21, 2025, https://pointclouds.org/documentation/tutorials/voxel_grid.html</li>
<li>Mastering 3D Computer Vision &amp; Point Cloud Processing-Mod 9-Point Cloud to Mesh and Point Cloud to Voxel Grid Conversion with Code - Rajavel PM (RPM), accessed July 21, 2025, https://pmrajavel.medium.com/mastering-3d-computer-vision-point-cloud-processing-mod-9-point-cloud-to-mesh-and-point-cloud-to-080adfc32d31</li>
<li>pcl::ApproximateVoxelGrid&lt; PointT &gt; Class Template Reference - Point Cloud Library, accessed July 21, 2025, https://pointclouds.org/documentation/classpcl_1_1_approximate_voxel_grid.html</li>
<li>Tutorial - Point Cloud Library – pmdtechnologies ag, accessed July 21, 2025, https://3d.pmdtec.com/en/tutorial-point-cloud-library/</li>
<li>Removing outliers using a StatisticalOutlierRemoval filter - Point Cloud Library 0.0 documentation - Compiling PCL, accessed July 21, 2025, https://pcl.readthedocs.io/projects/tutorials/en/latest/statistical_outlier.html</li>
<li>The algorithm behind pcl::StatisticalOutlierRemoval - Cross Validated - Stack Exchange, accessed July 21, 2025, https://stats.stackexchange.com/questions/288669/the-algorithm-behind-pclstatisticaloutlierremoval</li>
<li>detectLOAMFeatures - Detect LOAM feature points in point cloud - MATLAB - MathWorks, accessed July 21, 2025, https://www.mathworks.com/help/lidar/ref/detectloamfeatures.html</li>
<li>Build a Map with Lidar Odometry and Mapping (LOAM) Using Unreal Engine Simulation - MATLAB &amp; Simulink - MathWorks, accessed July 21, 2025, https://www.mathworks.com/help/lidar/ug/build-map-with-loam-using-unreal-engine.html</li>
<li>Drone IMU Calibration Explained - Pilot Institute, accessed July 21, 2025, https://pilotinstitute.com/drone-imu-calibration-explained/</li>
<li>Allan Variance: Noise Analysis for Gyroscopes - Telesens, accessed July 21, 2025, https://telesens.co/wp-content/uploads/2017/05/AllanVariance5087-1.pdf</li>
<li>Getting Started » Sensor Calibration - OpenVINS, accessed July 21, 2025, https://docs.openvins.com/gs-calibration.html</li>
<li>IMU Fundamentals, Part 4: Allan Deviation and IMU Error Modeling - Tangram Visions Blog, accessed July 21, 2025, https://www.tangramvision.com/blog/the-allan-deviation-and-imu-error-modeling-part-4-of-5</li>
<li>Inertial Sensor Noise Analysis Using Allan Variance - MATLAB &amp; Simulink - MathWorks, accessed July 21, 2025, https://www.mathworks.com/help/fusion/ug/inertial-sensor-noise-analysis-using-allan-variance.html</li>
<li>Quaternion kinematics for the error-state KF - IRI UPC, accessed July 21, 2025, https://www.iri.upc.edu/people/jsola/JoanSola/objectes/notes/kinematics.pdf</li>
<li>Outlier Detection in GNSS Pseudo-Range/Doppler Measurements for Robust Localization, accessed July 21, 2025, https://www.mdpi.com/1424-8220/16/4/580</li>
<li>Redalyc.OUTLIERS DETECTION BY RANSAC ALGORITHM IN THE TRANSFORMATION OF 2D COORDINATE FRAMES, accessed July 21, 2025, https://www.redalyc.org/pdf/3939/393933953008.pdf</li>
<li>A new inlier identification scheme for robust estimation problems - Robotics, accessed July 21, 2025, https://www.roboticsproceedings.org/rss02/p18.pdf</li>
<li>An Enhanced RANSAC-RTK Algorithm in GNSS-Challenged Environments - ResearchGate, accessed July 21, 2025, https://www.researchgate.net/publication/374524870_An_Enhanced_RANSAC-RTK_Algorithm_in_GNSS-Challenged_Environments</li>
<li>LOAM: Lidar Odometry and Mapping in Real-time - Carnegie Mellon University’s Robotics Institute, accessed July 21, 2025, https://www.ri.cmu.edu/pub_files/2014/7/Ji_LidarMapping_RSS2014_v8.pdf</li>
<li>Edge and planar features obtained from two different lidar odometry and… - ResearchGate, accessed July 21, 2025, https://www.researchgate.net/figure/Edge-and-planar-features-obtained-from-two-different-lidar-odometry-and-mapping_fig4_330592017</li>
<li>IMU Preintegration Theory - Manohar Kuse’s Cyber, accessed July 21, 2025, https://kusemanohar.info/2021/10/26/imu-preintegration-theory/</li>
<li>Any resources to learn about IMU pre integration? : r/robotics - Reddit, accessed July 21, 2025, https://www.reddit.com/r/robotics/comments/17ni2od/any_resources_to_learn_about_imu_pre_integration/</li>
<li>Continuous Integration over SO(3) for IMU Preintegration - Robotics, accessed July 21, 2025, https://www.roboticsproceedings.org/rss17/p078.pdf</li>
<li>IMU Fundamentals, Part 5: Preintegration Basics - Tangram Visions Blog, accessed July 21, 2025, https://www.tangramvision.com/blog/imu-preintegration-basics-part-5-of-5</li>
<li>Robust Error-State Kalman Filter For Estimating IMU Orientation | PDF - Scribd, accessed July 21, 2025, https://www.scribd.com/document/571135734/09206131</li>
<li>(PDF) Quaternion kinematics for the error-state KF - ResearchGate, accessed July 21, 2025, https://www.researchgate.net/publication/278619675_Quaternion_kinematics_for_the_error-state_KF</li>
<li>Create a OctoMap from a PointCloud - Google Groups, accessed July 21, 2025, https://groups.google.com/g/octomap/c/J5OoK3pYa7o</li>
<li>octomap_server - ROS Wiki, accessed July 21, 2025, http://wiki.ros.org/octomap_server</li>
<li>[ROS Q&amp;A] 085 - Basic usage of octomap_mapping package - Tutorial - YouTube, accessed July 21, 2025, https://www.youtube.com/watch?v=dF2mlKJqkUg</li>
<li>DWA-3D: A Reactive Planner for Robust and Efficient Autonomous UAV Navigation - arXiv, accessed July 21, 2025, https://arxiv.org/html/2409.05421v1</li>
<li>Improved A* Path Planning Method Based on the Grid Map - PMC, accessed July 21, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC9416044/</li>
<li>ALGORITHMS FOR VOXEL-BASED ARCHITECTURAL SPACE ANALYSIS - Autodesk Research, accessed July 21, 2025, https://www.research.autodesk.com/app/uploads/2023/06/Algorithms-for-VASA.pdf</li>
<li>Voxel-Based Path Planning for Autonomous Vehicles in Parking Lots - MDPI, accessed July 21, 2025, https://www.mdpi.com/2220-9964/14/4/147</li>
<li>Dynamic Window Approach (DWA) - 5.4.3 | Chapter 5: Motion Planning and Path Optimization | Robotics Advance - AllRounder.ai, accessed July 21, 2025, https://allrounder.ai/robotics-advance/chapter-5-motion-planning-and-path-optimization/dynamic-window-approach-dwa-543-lesson-683b0d</li>
<li>The Dynamic Window Approach to Collision Avoidance 1 Introduction - Carnegie Mellon University’s Robotics Institute, accessed July 21, 2025, https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf</li>
<li>dwa_local_planner - ROS Wiki, accessed July 21, 2025, http://wiki.ros.org/dwa_local_planner</li>
<li>Obstacle Detection and Collision Avoidance for Unmanned Vehicles, accessed July 21, 2025, https://www.unmannedsystemstechnology.com/expo/collision-obstacle-avoidance/</li>
<li>Sensor Fusion in Autonomous Vehicles: Enhancing Road Safety with LiDAR, Cameras, and AI - Promwad, accessed July 21, 2025, https://promwad.com/news/sensor-fusion-autonomous-transport-safety</li>
<li>Collision Avoidance Mechanism for Swarms of Drones - MDPI, accessed July 21, 2025, https://www.mdpi.com/1424-8220/25/4/1141</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>