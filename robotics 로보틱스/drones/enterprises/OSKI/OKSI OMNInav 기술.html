<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:OKSI OMNInav 기술</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>OKSI OMNInav 기술</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">로봇공학 (Robotics)</a> / <a href="../../index.html">드론 (Drones)</a> / <a href="../index.html">드론 기업 동향</a> / <a href="index.html">OSKI</a> / <span>OKSI OMNInav 기술</span></nav>
                </div>
            </header>
            <article>
                <h1>OKSI OMNInav 기술</h1>
<h2>1. 서론: GPS 거부 환경 항법의 패러다임 전환</h2>
<h3>1.1 전략적 필요성: 현대전과 GPS의 취약성</h3>
<p>현대전에서 무인 항공 시스템(UAS)의 역할은 정찰, 감시, 표적 획득 및 정밀 타격에 이르기까지 전 영역에 걸쳐 중추적인 위치를 차지한다.1 그러나 이러한 UAS 운용의 근간을 이루는 위성항법시스템(GPS)은 본질적인 취약성을 내포한다. 적대 세력에 의한 재밍(Jamming) 및 스푸핑(Spoofing)과 같은 전자전(EW) 위협은 GPS 신호를 교란하거나 기만하여 UAS의 위치, 항법, 시각(PNT) 정보의 신뢰도를 심각하게 훼손할 수 있다.3 이는 단순히 임무 실패를 넘어, 고가의 자산을 상실하거나 아군에게 위협이 되는 치명적인 결과로 이어질 수 있다. 따라서 GPS 신호에 대한 의존성을 탈피하고, 어떠한 전자기적 방해 환경에서도 임무를 지속할 수 있는 강인하고 독립적인 항법 능력의 확보는 현대 군사 작전의 성공을 위한 필수불가결한 전략적 과제로 부상했다.5</p>
<h3>1.2 OKSI의 기술적 유산과 OMNInav의 등장</h3>
<p>OKSI(Optical Knowledge Systems, Inc.)는 지난 30년 이상 국방 및 항공우주 분야에서 광학 센서, 신호 처리, 그리고 인공지능(AI) 기술을 개발하며 깊이 있는 기술적 유산을 축적해 온 기업이다.1 특히, 회사의 근간을 이루는 두 가지 핵심 역량은 OMNInav 개발의 자양분이 되었다. 첫째는 전기광학/적외선(EO/IR) 센서 시스템 설계 및 제작에 대한 오랜 전문성이다. 이는 다양한 스펙트럼의 광학 데이터를 정확하게 수집하고 이해하는 하드웨어적 기반을 제공한다.1 둘째는 ’지식 시스템(knowledge systems)’으로 불리던 초기 AI 연구부터 시작된 데이터 해석 및 머신러닝(ML) 알고리즘 개발 능력이다.7</p>
<p>이 두 유산의 융합은 OMNInav의 핵심적인 기술 철학을 형성한다. OMNInav는 단순히 최신 AI 기술을 적용한 제품이 아니라, 센서 물리(sensor physics)에 대한 깊은 이해를 바탕으로 수집된 데이터를 가장 효과적으로 해석하는 알고리즘을 결합한 결과물이다. 이러한 배경 덕분에 OMNInav는 가시광선 카메라뿐만 아니라 장파 적외선(LWIR) 카메라와 같은 다양한 종류의 센서로부터 입력되는 데이터를 차별 없이 처리할 수 있는 ’모달리티 불변성(modality-agnostic)’을 확보할 수 있었다.2 이는 OKSI가 최근 미 육군과 체결한 3세대 전방 감시 적외선 장치(FLIR) 소프트웨어 기술 계약에서도 확인할 수 있듯이, 회사의 EO/IR 전문성이 현재 진행형임을 보여주는 증거다.1 결국 OMNInav는 OKSI의 AI/ML 기술 포트폴리오의 정수로서, 차세대 자율 시스템이 요구하는 핵심적인 항법 능력을 제공하기 위해 탄생했다.9</p>
<h3>1.3 보고서의 목적 및 구성</h3>
<p>본 보고서는 OKSI OMNInav의 기술적 아키텍처, 핵심 알고리즘의 원리, 실환경에서의 운용 성능, 그리고 시장 내 경쟁 우위를 심층적으로 분석하는 것을 목표로 한다. 이를 통해 시스템 통합 엔지니어, 국방 R&amp;D 연구원, 그리고 관련 기술 프로그램 관리자들이 OMNInav에 대한 포괄적이고 전문적인 이해를 구축하는 데 기여하고자 한다. 보고서는 OMNInav의 다중 모드 융합 아키텍처 분석부터 시작하여, 핵심 기술의 수학적 모델, 성능 평가, 시스템 통합 방식, 그리고 경쟁 솔루션과의 비교 분석 순으로 구성된다.</p>
<h2>2. OMNInav의 다중 모드 융합 아키텍처</h2>
<h3>2.1 단일 모드 항법 시스템의 한계</h3>
<p>전통적인 GPS 거부 환경 항법 기술들은 각각 명확한 장점을 가지는 동시에 본질적인 한계에 직면해왔다.</p>
<ul>
<li><strong>광학 흐름 (Optical Flow):</strong> 이미지 프레임 간 픽셀의 움직임을 추적하여 상대 속도를 추정하는 방식으로, 계산적으로 매우 효율적이다. 그러나 고도가 높아지거나 기체의 기동이 빨라지면 성능이 급격히 저하되며, 정확한 고도 정보 없이는 추정치의 스케일(scale)을 정확히 결정하기 어렵다는 치명적인 단점이 있다.10</li>
<li><strong>시각-관성 주행 거리 측정 (Visual-Inertial Odometry, VIO):</strong> 카메라와 관성 측정 장치(IMU) 데이터를 결합하여 광학 흐름의 단점을 일부 보완하고 드리프트 누적을 줄인다. 하지만 초기화 과정에서 스케일 부정확성 문제가 발생하기 쉬우며, 카메라와 IMU 데이터 간의 정밀한 시간 동기화(synchronization)가 성능에 결정적인 영향을 미쳐 안정적인 구현이 까다롭다.2</li>
<li><strong>기본 특징점 기반 위치 인식 (Basic Feature-Based Localization):</strong> 사전에 저장된 위성 지도와 실시간 카메라 영상의 특징점을 비교하여 절대 위치를 파악하는 방식이다. 드리프트가 누적되지 않는다는 강력한 장점이 있으나, 사전에 지도를 기체에 탑재해야만 한다. 또한, 특징점이 부족하거나 식별이 어려운 지형(예: 사막, 바다)에서는 매칭 실패로 인해 위치 업데이트가 불가능한 ’항법 공백’이 발생할 수 있다.2</li>
<li><strong>군용 등급 관성 항법 장치 (Military-Grade INS):</strong> 매우 높은 정밀도와 신뢰성을 제공하지만, 수억 원에 달하는 엄청난 비용, 크기, 무게, 전력 소모(SWaP) 문제, 그리고 특정 플랫폼에 종속되는 독점적 시스템 구조로 인해 소형 UAS나 비용에 민감한 임무에는 적용이 사실상 불가능하다.2</li>
</ul>
<h3>2.2 OMNInav의 3대 기술 축</h3>
<p>OMNInav는 이러한 단일 모드 시스템들의 한계를 근본적으로 극복하기 위해 세 가지 핵심 기술을 유기적으로 융합하는 다중 모드(multi-modal) 아키텍처를 채택했다.2</p>
<ul>
<li><strong>SLAM 기반 정밀 지역 항법 (SLAM-Based Precise Local Navigation):</strong> OMNInav는 비행 중 실시간으로 주변 환경의 3차원 지도를 생성하고(Mapping), 그 지도 내에서 자신의 상대적 위치를 동시에 추정(Localization)하는 SLAM 기술을 활용한다.2 이는 사전 정보가 없는 지역에서도 매우 높은 주파수(high frequency)로 정밀한 위치 업데이트를 제공하여, 단기적인 기동 및 장애물 회피 시 요구되는 높은 수준의 지역적(local) 항법 정확성을 보장한다.10</li>
<li><strong>AI 특징점 매칭 기반 전역 위치 인식 (AI Feature Matching-Based Global Localization):</strong> OMNInav 아키텍처의 가장 핵심적인 차별점은 AI 기반의 전역 위치 인식 기능이다. 이 시스템은 기체에 탑재된 EO/IR 카메라로 획득한 실시간 영상에서 독자적인 특징점을 추출하고, 이를 사전 저장된 위성 지도 데이터베이스의 특징점과 비교 및 매칭한다. 성공적으로 매칭이 이루어지면, 시스템은 오차가 없는 절대 좌표를 획득하여 현재 위치를 보정한다.2 이 과정은 VIO나 SLAM 운용 시 필연적으로 누적되는 드리프트 오차를 주기적으로 ’리셋(reset)’하는 역할을 수행하며, 이를 통해 장거리 비행에서도 오차가 누적되지 않는 ‘드리프트 없는(drift-free)’ 항법을 실현한다.11</li>
<li><strong>확장 칼만 필터(EKF)를 이용한 강인한 센서 융합 (Robust Sensor Fusion via Extended Kalman Filter):</strong> OMNInav는 시각 센서(카메라), 관성 측정 장치(IMU), 기압 고도계, 대기 속도 센서 등 플랫폼에 탑재된 모든 가용 센서로부터 수집된 데이터를 통계적으로 최적 융합하기 위해 확장 칼만 필터(EKF)를 사용한다.11 EKF는 각 센서 데이터의 불확실성(noise)을 고려하여, SLAM이 제공하는 고주파의 상대적 위치 정보와 AI 특징점 매칭이 제공하는 저주파의 절대적 위치 정보를 결합한다. 이를 통해 각 센서의 단점은 상호 보완하고 장점은 극대화하여, 가장 신뢰도 높은 단일하고 일관된 상태 추정치(state estimation)를 실시간으로 도출한다.11</li>
</ul>
<p>이러한 아키텍처는 항법 문제에 대한 근본적인 접근 방식의 전환을 의미한다. 전통적인 VIO나 INS 기반 시스템은 상태 벡터(위치, 속도, 자세)를 추정하고 필연적으로 발생하는 오차(드리프트)의 ’증가율’을 최소화하는 데 초점을 맞춘다. 즉, ’오차 관리’가 핵심 과제다. 반면, OMNInav는 AI 기반 전역 위치 인식을 통해 단순히 상태를 추정하는 것을 넘어, 주기적으로 상태에 대한 절대적인 ’확실성’을 재확립한다. 이는 항법 문제를 연속적인 ’오차 관리’에서 주기적인 ’오차 제거’의 문제로 변환시킨다. 이러한 접근법은 장시간 임무 수행 시 오차 범위가 무한정 커지는 것이 아니라, 특징점 매칭이 성공할 때마다 일정한 범위 내로 다시 수렴하게 만든다. 결과적으로, 기존 시스템으로는 불가능했던 수준의 신뢰도를 바탕으로 장거리 자율 정찰이나 장시간 체공 후 정밀 타격과 같은 새로운 임무 프로파일을 가능하게 한다.</p>
<h2>3. 핵심 기술 심층 분석</h2>
<h3>3.1 시각-관성 주행 거리 측정(VIO)의 수학적 모델</h3>
<p>VIO는 저렴하고 가벼운 카메라와 IMU 센서를 결합하여 기체의 6자유도(6-DoF) 움직임을 추정하는 기술로, OMNInav의 지역 항법에 기여한다.13 이 기술은 몇 가지 핵심적인 수학적 모델에 기반한다.</p>
<ul>
<li>
<p><strong>상태 벡터 (State Vector):</strong> VIO 시스템이 추정하고자 하는 변수들의 집합으로, 일반적으로 시각 <span class="math math-inline">t_i</span>에서의 기체 상태 <span class="math math-inline">X_i</span>는 다음과 같이 정의된다.13<br />
<span class="math math-display">
X_i = [ T_I^W, V_I^W, b_i^a, b_i^g]^T
</span><br />
여기서 <span class="math math-inline">T^W_I</span>는 월드 좌표계(W)에 대한 IMU 좌표계(I)의 6-DoF 자세(위치 및 방향), <span class="math math-inline">V^W_I</span>는 IMU의 속도, <span class="math math-inline">b^a_i</span>와 <span class="math math-inline">b^g_i</span>는 각각 가속도계와 자이로스코프의 시간에 따라 변하는 바이어스를 나타낸다.</p>
</li>
<li>
<p><strong>IMU 측정 모델 (IMU Measurement Model):</strong> IMU 센서가 실제로 측정하는 값은 참값에 센서 고유의 바이어스(<span class="math math-inline">b</span>)와 랜덤 노이즈(<span class="math math-inline">n</span>)가 더해진 형태다. 측정된 각속도(<span class="math math-inline">\omega_m</span>)와 가속도(<span class="math math-inline">a_m</span>)는 다음과 같이 모델링된다.13<br />
<span class="math math-display">
\omega_m = \omega_{true} + b_g + n_g
</span></p>
<p><span class="math math-display">
a_m = R_{WI}(a_{true} - g) + b_a + n_a
</span></p>
</li>
</ul>
<p>여기서 <span class="math math-inline">R_{WI}</span>는 월드 좌표계에서 IMU 좌표계로의 회전 행렬이며, <span class="math math-inline">g</span>는 월드 좌표계에서의 중력 가속도 벡터를 의미한다. 이 모델을 통해 측정값으로부터 참값을 추정할 수 있다.</p>
<ul>
<li>
<p><strong>랜드마크 투영 모델 (Landmark Projection Model):</strong> 3차원 공간상의 특징점(랜드마크) <span class="math math-inline">P_w</span>가 카메라 이미지 평면의 2D 픽셀 좌표 <span class="math math-inline">u</span>로 어떻게 투영되는지를 설명하는 모델로, 일반적으로 핀홀 카메라 모델을 사용한다.13</p>
<p><span class="math math-display">
u = KP_w
</span><br />
여기서 <span class="math math-inline">K</span>는 초점 거리, 주점 등 카메라의 내부 파라미터를 담은 행렬이고, $$는 월드 좌표계에 대한 카메라의 자세를 나타내는 외부 파라미터(회전 및 이동) 행렬이다. VIO는 이 투영 관계를 이용하여 이미지상의 특징점 움직임으로부터 카메라의 움직임을 역으로 추정한다.</p>
</li>
</ul>
<h3>SLAM의 확률론적 기반</h3>
<p>SLAM(Simultaneous Localization and Mapping)은 로봇이 사전에 주어진 지도 없이 미지의 환경을 탐색하면서, 센서 데이터를 이용해 주변 환경의 지도를 실시간으로 작성함과 동시에 지도 내에서 자신의 위치를 추정하는 기술이다.16</p>
<p>SLAM은 본질적으로 확률론에 기반한 추정 문제다. 시간 <span class="math math-inline">t</span>까지의 제어 입력 <span class="math math-inline">u_{1:t}</span>와 관측 <span class="math math-inline">z_{1:t}</span>가 주어졌을 때, 로봇의 전체 경로 <span class="math math-inline">x_{1:t}</span>와 지도 <span class="math math-inline">m</span>에 대한 사후 확률(posterior probability) <span class="math math-inline">p(x_{1:t}, m \vert z_{1:t}, u_{1:t})</span>을 최대화하는 것을 목표로 한다.16 이는 베이즈 정리(Bayes’ theorem)를 통해 재귀적으로 풀 수 있다. 온라인 SLAM 문제, 즉 현재 시점의 위치  <span class="math math-inline">x_t</span>와 지도 <span class="math math-inline">m</span>을 추정하는 문제는 다음과 같은 식으로 표현된다.</p>
<p><span class="math math-display">
p(x_t, m \vert z_{1:t}, u_{1:t}) \propto p(z_t \vert x_t, m) \int p(x_t \vert x_{t-1}, u_t) p(x_{t-1}, m \vert z_{1:t-1}, u_{1:t-1}) dx_{t-1}
</span><br />
이 식에서 <span class="math math-inline">p(z_t \vert x_t, m)</span>은 관측 모델(likelihood), <span class="math math-inline">p(x_t \vert x_{t-1}, u_t)</span>은 움직임 모델(transition)을 나타낸다. OMNInav는 이러한 SLAM의 확률론적 프레임워크를 활용하여 GPS 신호가 없는 환경에서도 주변 지형지물을 랜드마크 삼아 신뢰성 높은 지역 항법을 수행한다.2</p>
<h3>확장 칼만 필터(EKF)의 재귀적 추정 프로세스</h3>
<p>확장 칼만 필터(EKF)는 로봇의 움직임이나 센서 모델이 비선형(non-linear)일 경우에 사용되는 표준적인 상태 추정 알고리즘이다.19 OMNInav에서 EKF는 VIO, SLAM, AI 특징점 매칭 등 여러 소스로부터 들어오는 비선형적인 항법 데이터를 융합하여 최적의 상태 추정치를 계산하는 핵심 엔진 역할을 한다.11 EKF는 예측과 갱신이라는 두 단계를 재귀적으로 반복한다.22</p>
<ul>
<li>
<p><strong>예측 단계 (Prediction Step):</strong> 이전 상태의 추정치와 시스템의 동역학 모델 <span class="math math-inline">f</span>를 사용하여 현재 시간의 상태를 예측한다.</p>
<ul>
<li>상태 예측 (State Prediction):</li>
</ul>
</li>
</ul>
<p><span class="math math-display">
\hat{x}_{k\vert k-1} = f(\hat{x}_{k-1\vert k-1}, u_k)
    </span><br />
<span class="math math-inline">\hat{x}_{k\vert k-1}</span>은 <span class="math math-inline">k-1</span> 시점까지의 정보를 바탕으로 예측한 <span class="math math-inline">k</span> 시점의 상태다.</p>
<ul>
<li>오차 공분산 예측 (Error Covariance Prediction):</li>
</ul>
<p><span class="math math-display">
P_{k\vert k-1} = F_k P_{k-1\vert k-1} F_k^T + Q_k
    </span><br />
<span class="math math-inline">P_{k\vert k-1}</span>는 예측된 상태의 불확실성을 나타내는 공분산 행렬이다. <span class="math math-inline">F_k</span>는 비선형 함수 <span class="math math-inline">f</span>를 현재 상태 추정치 주변에서 선형화한 자코비안 행렬이며, <span class="math math-inline">Q_k</span>는 모델 자체의 불확실성(프로세스 노이즈)을 나타낸다.</p>
<ul>
<li>
<p><strong>갱신 단계 (Update Step):</strong> 센서로부터 새로운 측정값 <span class="math math-inline">z_k</span>를 얻었을 때, 예측된 상태를 보정하여 더 정확한 추정치를 얻는다.</p>
<ul>
<li>칼만 이득 계산 (Kalman Gain Calculation):</li>
</ul>
</li>
</ul>
<p><span class="math math-display">
K_k = P_{k\vert k-1} H_k^T (H_k P_{k\vert k-1} H_k^T + R_k)^{-1}
    </span><br />
칼만 이득 <span class="math math-inline">K_k</span>는 예측값의 불확실성과 측정값의 불확실성을 비교하여, 측정값을 얼마나 신뢰할지를 결정하는 가중치다. <span class="math math-inline">H_k</span>는 측정 모델 <span class="math math-inline">h</span>의 자코비안 행렬, <span class="math math-inline">R_k</span>는 측정 노이즈의 공분산이다.</p>
<ul>
<li>상태 갱신 (State Update):</li>
</ul>
<p><span class="math math-display">
\hat{x}_{k\vert k} = \hat{x}_{k\vert k-1} + K_k (z_k - h(\hat{x}_{k\vert k-1}))
    </span><br />
실제 측정값과 예측된 측정값의 차이(innovation)에 칼만 이득을 곱하여 예측된 상태를 보정한다.</p>
<ul>
<li>오차 공분산 갱신 (Error Covariance Update):</li>
</ul>
<p><span class="math math-display">
P_{k\vert k} = (I - K_k H_k) P_{k\vert k-1}
    </span><br />
측정값을 통해 새로운 정보가 반영되었으므로, 상태의 불확실성을 나타내는 공분산 행렬을 갱신하여 줄여준다.</p>
<p>이러한 예측과 갱신 과정을 끊임없이 반복함으로써 EKF는 다양한 센서 정보의 장점만을 취합하여 시스템의 상태를 최적으로 추정해 나간다.</p>
<h2>실환경 운용성 및 강인성 평가</h2>
<h3>조명 및 센서 종류에 대한 불변성</h3>
<p>OMNInav의 핵심적인 강점 중 하나는 운용 환경의 조명 조건이나 탑재된 센서의 종류에 크게 구애받지 않는 강인성이다. 시스템에 적용된 AI 모델은 방대한 양의 가시광선 이미지와 적외선(특히 LWIR) 이미지를 모두 학습했다.2 이 덕분에 맑은 날 주간 비행은 물론, 구름 낀 날, 해 질 녘, 그리고 완전한 야간 환경에서도 안정적인 항법 성능을 유지한다. 이는 단순히 주야간 운용이 가능하다는 것을 넘어, 사용되는 카메라의 모달리티(modality)나 참조하는 지도의 종류(가시광선 지도, 적외선 지도 등)에 구애받지 않는 진정한 ’모달리티 불변성(agnostic modality capability)’을 의미한다.2 이러한 특성은 전천후 24시간 작전이 필수적인 국방 분야에서 매우 중요한 운용상의 이점을 제공한다.</p>
<h3>동적 환경 변화에 대한 적응성</h3>
<p>실제 작전 환경은 정적이지 않고 끊임없이 변화한다. OMNInav는 이러한 동적인 환경 변화에 대응할 수 있는 높은 수준의 적응성을 갖추고 있다.</p>
<ul>
<li><strong>계절적 변화 (Seasonal Variations):</strong> OMNInav의 AI 모델은 특정 시점의 위성 이미지만을 학습한 것이 아니라, 수년에 걸친 다계절 위성 이미지를 학습 데이터로 활용했다.2 그 결과, 여름철 녹음이 우거진 지형이 겨울철 눈 덮인 지형으로 바뀌거나, 나뭇잎이 모두 떨어진 황량한 모습으로 변하더라도 지형의 핵심적인 특징을 인식하고 안정적으로 위치를 매칭할 수 있다.</li>
<li><strong>인공적 변화 (Man-Made Transformations):</strong> 분쟁 지역에서는 폭격으로 인해 건물이 파괴되거나, 평화 시에는 새로운 건물이 들어서는 등 지형이 급격하게 변할 수 있다. OMNInav는 이러한 인공적인 환경 변화에도 놀라운 강인성을 보여준다. 실제 테스트에서 최대 10년 전에 촬영된 오래된 위성 이미지를 참조 지도로 사용했음에도 불구하고, 대규모 도시 파괴가 발생한 지역에서 성공적으로 항법 포인트를 등록하고 위치를 보정하는 데 성공했다.2 이는 OMNInav의 AI가 단순히 픽셀 단위의 패턴 매칭을 넘어, 변화 속에서도 유지되는 구조적, 맥락적 특징을 이해하고 활용함을 시사한다.</li>
</ul>
<h3>성능 지표: 드리프트 없는 항법의 실현</h3>
<p>OMNInav의 성능을 평가할 때, 전통적인 INS 시스템의 성능 지표인 ’드리프트율(drift rate, 예: 이동 거리의 N%)’을 직접적으로 적용하는 것은 시스템의 본질을 정확히 파악하지 못할 수 있다. OKSI는 OMNInav의 성능을 설명하며 구체적인 원형 공산 오차(CEP)나 드리프트율 수치를 제시하는 대신, ‘드리프트 없는(drift-free)’ 절대 위치 업데이트라는 개념을 반복적으로 강조한다.2</p>
<p>이는 OMNInav의 핵심 성능 지표가 누적 오차의 ’증가율’이 아니라, 누적 오차를 ’제거하는 능력’에 있음을 의미한다. VIO나 SLAM만으로는 시간이 지남에 따라 오차가 필연적으로 누적되지만, OMNInav는 AI 특징점 매칭을 통해 주기적으로 지상 기준점(위성 지도)에 대한 절대 위치를 확인함으로써 누적된 오차를 ’0’으로 리셋한다. 따라서 임무 시간이 길어지더라도 오차의 불확실성 반경이 무한정 커지는 것이 아니라, 특징점 매칭이 성공하는 주기마다 일정한 최대 오차 범위 내로 계속해서 수렴하게 된다. 이것이 OMNInav가 실현하는 ’드리프트 없는 항법’의 실질적인 의미이며, 장시간 임무 수행 시 신뢰도를 보장하는 핵심 메커니즘이다.</p>
<h2>시스템 통합 및 OMNISCIENCE 생태계</h2>
<h3>모듈식, 컨테이너화된 소프트웨어 아키텍처</h3>
<p>OMNInav는 단일 제품이 아니라, OMNISCIENCE™라는 더 큰 규모의 AI/ML 소프트웨어 포트폴리오를 구성하는 핵심 모듈 중 하나다.2 OMNISCIENCE는 전체적으로 모듈식(modular) 및 컨테이너화된(containerized) 소프트웨어 아키텍처를 채택하고 있다.7 이는 각 기능(항법, 표적 인식 등)이 독립적인 소프트웨어 컨테이너로 패키징되어 있음을 의미한다. 이러한 구조는 사용자에게 높은 수준의 유연성을 제공하여, 임무 요구사항에 따라 OMNInav 항법 모듈만 선택적으로 통합하거나, 표적 인식, 종말 유도 등 다른 모듈과 결합하여 전체 자율 임무 스택을 구성할 수 있게 한다.25 또한, 컨테이너화된 솔루션은 다양한 종류의 UAS 플랫폼에 탑재된 기존 컴패니언 컴퓨터(companion computer)에 최소한의 수정으로 신속하게 배포하고 이식할 수 있다는 장점을 가진다.2</p>
<h3>손쉬운 통합 및 호환성</h3>
<p>OMNInav는 개발 및 통합의 편의성을 극대화하도록 설계되었다. 이 소프트웨어는 PX4나 ArduPilot과 같이 업계에서 널리 사용되는 오픈소스 비행 제어 스택과 원활하게 통합된다.2 통합 시 OMNInav는 시스템의 GPS 입력 채널을 대체하는 역할을 한다. 즉, 자동 조종 장치(autopilot)는 OMNInav가 제공하는 고정밀의 실시간 위치 데이터를 마치 신뢰성 높은 GPS 데이터처럼 입력받아 항법, 경로점 비행, 자동 이착륙 등의 임무를 수행하게 된다. 이러한 접근 방식은 기존 시스템의 비행 제어 로직을 크게 수정할 필요 없이 GPS 거부 환경 대응 능력을 부여할 수 있게 해주며, 회전익, 고정익, 수직이착륙기(VTOL) 등 다양한 형태의 무인 항공기에 폭넓게 적용될 수 있다.2</p>
<h3>OMNISCIENCE 생태계와의 시너지</h3>
<p>OMNISCIENCE 생태계는 UAS 자율성을 위한 ’운영체제(Operating System)’와 유사한 개념으로 이해할 수 있다. 이 생태계 내에서 각 모듈은 특정 시스템 서비스를 담당하며, 이들이 결합될 때 강력한 시너지를 발휘한다.</p>
<ul>
<li><strong>OMNImind:</strong> 임무 실행 모듈로, 운영체제의 ’커널(kernel)’과 같은 역할을 한다. 조건부 행동 로직을 제공하고, 변화하는 임무 환경에 맞춰 다른 모듈들의 작동을 총괄하며 동적으로 임무 계획을 수정한다.25</li>
<li><strong>OMNInav:</strong> GPS 거부 환경 항법 모듈로, ’위치 서비스’를 제공한다.</li>
<li><strong>OMNIseek:</strong> 자동 표적 탐지/인식(ATD/ATR) 모듈로, ’인식 및 비전 서비스’를 담당한다.11</li>
<li><strong>OMNIlocate:</strong> GPS가 없는 환경에서도 CAT I/II 등급의 정밀 표적 좌표를 생성하는 ’표적 위치 측정 서비스’다.11</li>
<li><strong>OMNItarget:</strong> 획득된 표적을 향해 정밀 유도 비행을 수행하는 ’종말 유도 서비스’를 제공한다.11</li>
</ul>
<p>이러한 모듈식 접근법은 UAS 제조사에게 큰 이점을 제공한다. 복잡한 자율 항법 및 인식 시스템을 처음부터 개발하는 대신, 검증된 OMNISCIENCE ’운영체제’를 통합함으로써 개발 시간과 비용을 획기적으로 절감하고, 자사의 핵심 역량인 플랫폼 하드웨어 개발에 집중할 수 있다. 이는 국방부가 추구하는 ‘저렴한 대량 통합(affordable mass integration)’ 목표와도 일치하며 9, 신속한 양산 능력을 갖춘 Cyberlux와의 파트너십은 이러한 전략이 실제로 구현되는 대표적인 사례다.12 이 모듈들이 OMNImind의 지휘 아래 유기적으로 연동될 때, UAS는 외부의 GPS나 RF 통신에 전혀 의존하지 않는 완전한 수동형(passive) 자율 임무를 수행할 수 있게 된다.11</p>
<h3>하드웨어 옵션: 저-SWaP COTS 솔루션</h3>
<p>OKSI는 OMNInav를 주로 소프트웨어 솔루션으로 제공하지만, 신속한 통합을 원하는 고객을 위해 즉시 사용 가능한 상용(COTS) 하드웨어 패키지 옵션도 제공한다.10 이 하드웨어는 크기(Size), 무게(Weight), 전력(Power)을 최소화하는 저-SWaP 설계에 초점을 맞추고 있다. 구체적인 사양은 70x50x50 mm의 컴팩트한 크기, 300g의 가벼운 무게, 그리고 최저 5W에 불과한 낮은 소비 전력을 특징으로 한다. 특히, 장파 적외선(LWIR) 카메라 옵션을 포함하고 있어 별도의 센서 추가 없이 주야간 전천후 운용이 가능하다.10</p>
<h2>시장 내 경쟁 우위 및 비교 분석</h2>
<h3>OMNInav의 핵심 가치 제안</h3>
<p>OMNInav의 시장 내 핵심 가치 제안은 명확하다: 고가의 군용 등급 INS에 대한 비용 효율적인 대안을 제공하는 것이다.2 소프트웨어 정의(software-defined) 접근 방식을 통해 하드웨어 의존성을 최소화하고, 낮은 SWaP-C(Size, Weight, Power, and Cost)를 달성했다. 이는 기존에는 고성능 항법 장치를 탑재하기 어려웠던 소형 UAS 플랫폼에도 고도의 자율성을 부여할 수 있음을 의미한다. 결과적으로, OMNInav는 첨단 GPS 거부 환경 대응 능력을 저렴한 비용으로 대규모 UAS 플랫폼에 확산시킬 수 있는 길을 열었다.9</p>
<h3>경쟁 솔루션 비교 분석</h3>
<p>OMNInav의 경쟁 우위는 시장의 다른 주요 GPS 거부 환경 항법 솔루션과의 비교를 통해 더욱 명확해진다. 각 솔루션은 서로 다른 기술 철학과 장단점을 가지고 있다.</p>
<table><thead><tr><th>기능</th><th><strong>OKSI OMNInav</strong></th><th><strong>UAV Navigation Kit</strong></th><th><strong>NovAtel SPAN (예: CPT7)</strong></th><th><strong>SBG Systems (예: Ekinox)</strong></th><th><strong>Parker LORD (예: 3DM-GQ7)</strong></th></tr></thead><tbody>
<tr><td><strong>핵심 기술</strong></td><td>다중 모드 소프트웨어 융합 (SLAM + AI 특징점 매칭 + EKF) 2</td><td>강결합 AHRS + 시각 항법 시스템(VNS) 28</td><td>강결합 GNSS + MEMS IMU 29</td><td>강결합 GNSS + MEMS IMU 31</td><td>강결합 GNSS + MEMS IMU 33</td></tr>
<tr><td><strong>드리프트/오차 보정</strong></td><td>AI 전역 위치 인식 통한 주기적, 절대적 드리프트 리셋 (“Drift-Free”) 2</td><td>드리프트: 이동 거리의 1% (미지 지형), 드리프트 없음 (기지 지형) 28</td><td>INS가 GNSS 단절 구간을 연결; 시간 경과에 따라 드리프트 누적 4</td><td>INS가 GNSS 단절 구간을 연결; 시간 경과에 따라 드리프트 누적 31</td><td>전술급 IMU (&lt;2°/hr 바이어스 안정성)가 단절 중 드리프트 최소화 33</td></tr>
<tr><td><strong>환경 적응성</strong></td><td>높음: 다년간, 다중 모드 데이터로 학습된 AI 모델이 계절/인공적 변화에 적응 2</td><td>중간: 기지 지형에 대해 “템플릿 매칭“에 의존 28</td><td>낮음: 단절 중 주로 IMU 물리 모델에 의존 4</td><td>낮음: 단절 중 주로 IMU 물리 모델에 의존 32</td><td>낮음: 단절 중 주로 IMU 물리 모델에 의존 33</td></tr>
<tr><td><strong>SWaP-C</strong></td><td>매우 낮음: 소프트웨어 중심; 옵션 COTS 하드웨어 300g / 5W. 비용 효율적. 2</td><td>낮음: POLAR-300 (76g) + VNS01 (100g) = 총 176g. 28</td><td>중간: CPT7은 500g / 9W. 하드웨어 중심 비용. 30</td><td>중간: 모델에 따라 SWaP 상이. 하드웨어 중심. 34</td><td>매우 낮음: 3DM-GQ7은 78g. 3DM-GX5는 20g. 33</td></tr>
<tr><td><strong>통합 방식</strong></td><td>소프트웨어 기반: 컴패니언 컴퓨터용 컨테이너 솔루션. PX4/ArduPilot과 통합. 2</td><td>하드웨어 기반: 특정 키트 통합. 28</td><td>하드웨어 기반: 강결합 OEM 수신기 및 IMU. 29</td><td>하드웨어 기반: OEM 및 박스형 솔루션 제공. 32</td><td>하드웨어 기반: OEM 및 박스형 솔루션 제공. 33</td></tr>
</tbody></table>
<p>분석 결과, OMNInav는 경쟁 솔루션과 근본적으로 다른 접근법을 취하고 있음을 알 수 있다. 대부분의 경쟁 제품이 고성능 MEMS IMU를 중심으로 한 하드웨어적 강결합(Tightly-Coupled) 방식을 통해 GNSS 단절 구간 동안의 ’드리프트 최소화’에 집중하는 반면, OMNInav는 소프트웨어와 AI를 중심으로 ’드리프트 제거’에 초점을 맞춘다. 이러한 차이는 특히 환경 적응성에서 두드러진다. IMU 기반 시스템은 주변 환경 변화와 무관하게 물리 법칙에 따라 오차가 누적되지만, OMNInav는 AI를 통해 환경 변화 자체를 학습하고 적응하여 강인한 성능을 유지한다. 이는 OMNInav가 단순한 항법 장치를 넘어, 지능형 인식 시스템으로서의 특성을 가짐을 보여준다.</p>
<h2>결론: 차세대 자율 항법의 미래</h2>
<h3>OMNInav의 기술적 의의 및 파급 효과</h3>
<p>OKSI OMNInav는 GPS 거부 환경 항법 기술의 패러다임을 하드웨어 중심에서 소프트웨어 정의(software-defined) 및 AI 중심으로 전환하는 중요한 이정표를 제시한다. 고가의 고정밀 관성 센서에 대한 의존도를 낮추고, 대신 지능형 알고리즘과 저비용의 상용 센서를 결합함으로써 항법 시스템의 SWaP-C 문제를 근본적으로 해결할 수 있는 가능성을 보여주었다. 이러한 접근 방식은 UAS의 대량 생산 및 운용 비용을 절감시키는 동시에, 이전에는 불가능했던 소형, 저가 플랫폼에도 고도의 자율성을 부여할 수 있는 잠재력을 가진다.9 이는 미래 전장에서 요구되는 ‘저렴하고 소모 가능한(attritable)’ 자율 시스템의 확산에 기여하는 핵심 기술이 될 것이다.</p>
<h3>전략적 파트너십의 중요성: OKSI와 Cyberlux 사례</h3>
<p>첨단 기술이 실제 전력으로 이어지기 위해서는 기술 개발만큼이나 신속한 체계 통합 및 양산이 중요하다. OKSI와 Cyberlux의 전략적 파트너십은 이러한 측면에서 성공적인 협력 모델을 제시한다.12 OKSI는 OMNISCIENCE 스위트를 통해 최첨단 AI 기반 자율 항법 소프트웨어라는 ’두뇌’를 제공하고, Cyberlux는 신속한 UAS 플랫폼 설계 및 대규모 양산 능력이라는 ’신체’를 제공한다.39 이 두 기업의 결합은 최첨단 기술이 연구실에 머무르지 않고, 실제 작전을 수행하는 전술 제대(tactical edge)에 가장 필요한 시점에 신속하게 보급될 수 있는 시너지 효과를 창출한다. 이는 미래 국방 기술 혁신 생태계가 나아가야 할 방향을 보여주는 중요한 사례다.</p>
<h3>미래 전망: 완전 자율 시스템을 향하여</h3>
<p>OMNInav와 같은 AI 기반의 강인한 항법 기술은 단일 UAS의 생존성과 임무 성공률을 높이는 것을 넘어, 미래의 완전 자율 시스템 구현을 위한 필수적인 기반 기술이다. 특히, 다수의 UAS가 협력하여 임무를 수행하는 자율 팀 및 스웜(swarm) 작전에서 각 개체가 외부 도움 없이 자신의 위치를 정확히 인지하는 능력은 군집 전체의 운용 효율성과 안정성을 담보하는 핵심 요소다.6 GPS에 의존하지 않는 독립적인 고정밀 항법은 개별 기체의 생존성을 보장할 뿐만 아니라, 분산된 다수의 기체가 통신 두절 상황에서도 상호 위치를 기반으로 협력하여 복잡한 임무를 수행하는 것을 가능하게 할 것이다. 따라서 OMNInav는 차세대 자율 항법 기술의 현재를 보여주는 동시에, 미래 무인 전투체계가 나아갈 방향을 제시하고 있다.</p>
<h4><strong>참고 자료</strong></h4>
<ol>
<li>About - OKSI, 9월 21, 2025에 액세스, https://oksi.ai/about/</li>
<li>OMNInav: A Breakthrough in GPS-Denied Navigation for UAS - OKSI, 9월 21, 2025에 액세스, https://oksi.ai/omninav-gps-denied-navigation/</li>
<li>5.1 GNSS-Challenged Environments - VectorNav Technologies, 9월 21, 2025에 액세스, https://www.vectornav.com/resources/inertial-navigation-primer/alternative-navigation/altnav-gnsschallenged</li>
<li>GNSS Denied? | NovAtel, 9월 21, 2025에 액세스, https://novatel.com/tech-talk/velocity-magazine/velocity-2014/gnss-denied</li>
<li>OKSI: Homepage, 9월 21, 2025에 액세스, https://oksi.ai/</li>
<li>Defense - OKSI, 9월 21, 2025에 액세스, https://oksi.ai/defense/</li>
<li>OKSI Launches AI/ML Technology Portfolio for Unmanned Airborne Platforms, 9월 21, 2025에 액세스, https://www.latimes.com/b2bpublishing/business-announcements/story/2024-07-11/oksi-launches-ai-ml-technology-portfolio-for-unmanned-airborne-platforms</li>
<li>Oksi Awarded U.S. Army Contract on Technology for Enhanced Thermal Night Vision Sensors | Design and Development Today, 9월 21, 2025에 액세스, https://www.designdevelopmenttoday.com/industries/military/news/22926687/oksi-awarded-us-army-contract-on-technology-for-enhanced-thermal-night-vision-sensors</li>
<li>OKSI Announces their AI/ML Technology Portfolio for Unmanned Airborne Platforms: OMNISCIENCE | Sensors and Systems, 9월 21, 2025에 액세스, https://sensorsandsystems.com/oksi-announces-their-ai-ml-technology-portfolio-for-unmanned-airborne-platforms-omniscience/</li>
<li>Soldier Systems Daily Soldier Systems Daily, 9월 21, 2025에 액세스, https://soldiersystems.net/page/159/</li>
<li>OMNISCIENCE - OKSI, 9월 21, 2025에 액세스, https://oksi.ai/omniscience/</li>
<li>Cyberlux and OKSI Advance UAS Capabilities for GPS- and RF-Denied Environments, 9월 21, 2025에 액세스, https://www.businesswire.com/news/home/20250507811627/en/Cyberlux-and-OKSI-Advance-UAS-Capabilities-for-GPS–and-RF-Denied-Environments</li>
<li>(PDF) Visual-Inertial Odometry of Aerial Robots - ResearchGate, 9월 21, 2025에 액세스, https://www.researchgate.net/publication/333678568_Visual-Inertial_Odometry_of_Aerial_Robots</li>
<li>XR-VIO: High-precision Visual Inertial Odometry with Fast Initialization for XR Applications, 9월 21, 2025에 액세스, https://arxiv.org/html/2502.01297v1</li>
<li>A Comprehensive Introduction of Visual-Inertial Navigation - arXiv, 9월 21, 2025에 액세스, https://arxiv.org/pdf/2307.11758</li>
<li>SLAM in Navigation Systems of Autonomous Mobile Robots⋆ - CEUR-WS.org, 9월 21, 2025에 액세스, https://ceur-ws.org/Vol-3991/paper13.pdf</li>
<li>Research on UAV Positioning and Control Based on SLAM Approach - Atlantis Press, 9월 21, 2025에 액세스, https://www.atlantis-press.com/article/126015399.pdf</li>
<li>The Future of Drone Mapping with SLAM Technology, 9월 21, 2025에 액세스, https://www.thedroneu.com/blog/slam-technology/</li>
<li>Comparative Study of SLAM Techniques for UAV - ResearchGate, 9월 21, 2025에 액세스, https://www.researchgate.net/publication/357624934_Comparative_Study_of_SLAM_Techniques_for_UAV</li>
<li>Sensor Fusion With Kalman Filter. Introduction | by Satya - Medium, 9월 21, 2025에 액세스, https://medium.com/@satya15july_11937/sensor-fusion-with-kalman-filter-c648d6ec2ec2</li>
<li>Extended Kalman Filter Sensor Fusion in Practice for Mobile Robot Localization - The Science and Information (SAI) Organization, 9월 21, 2025에 액세스, https://thesai.org/Downloads/Volume13No2/Paper_4-Extended_Kalman_Filter_Sensor_Fusion_in_Practice.pdf</li>
<li>Kalman filter - Wikipedia, 9월 21, 2025에 액세스, https://en.wikipedia.org/wiki/Kalman_filter</li>
<li>explanation of kalman filter - Robotics Stack Exchange, 9월 21, 2025에 액세스, https://robotics.stackexchange.com/questions/14001/explanation-of-kalman-filter</li>
<li>Exposing the Power of the Kalman Filter - Towards Data Science, 9월 21, 2025에 액세스, https://towardsdatascience.com/exposing-the-power-of-the-kalman-filter-1b78621c3f56/</li>
<li>OKSI Announces their AI/ML Technology Portfolio for Unmanned Airborne Platforms: OMNISCIENCE, 9월 21, 2025에 액세스, https://oksi.ai/oksi-announces-their-ai-ml-technology-portfolio-for-unmanned-airborne-platforms-omniscience/</li>
<li>OKSI releases AI/ML suite for uncrewed systems - Unmanned airspace, 9월 21, 2025에 액세스, https://www.unmannedairspace.info/latest-news-and-information/oksi-releases-ai-ml-suite-for-uncrewed-systems/</li>
<li>UAS Capabilities for GPS- and RF-Denied Environments - Cyberlux, 9월 21, 2025에 액세스, https://cyberlux.com/uas-capabilities-for-gps-and-rf-denied-environments/</li>
<li>GNSS-Denied Navigation Kit | UAV Navigation, 9월 21, 2025에 액세스, https://www.uavnavigation.com/products/navigation-systems/gnss-denied-navigation-kit</li>
<li>GNSS Inertial Navigation Systems - NovAtel, 9월 21, 2025에 액세스, https://novatel.com/products/gnss-inertial-navigation-systems</li>
<li>CPT7 dual-antenna receiver enclosure with SPAN GNSS+INS …, 9월 21, 2025에 액세스, https://novatel.com/products/gnss-inertial-navigation-systems/combined-systems/cpt7</li>
<li>SBG Systems - USA - SUBSEA 20/20, 9월 21, 2025에 액세스, https://www.subsea2020.com/inertial-sensors</li>
<li>INS - inertial navigation systems for demanding applications - SBG Systems, 9월 21, 2025에 액세스, https://www.sbg-systems.com/ins/</li>
<li>3DM-GQ7-GNSS/INS | HBK, 9월 21, 2025에 액세스, https://www.microstrain.com/inertial-sensors/3dm-gq7</li>
<li>INS-GPS, AHRS, IMU Inertial Sensors for Contol &amp; Navigation | SBG Systems, 9월 21, 2025에 액세스, https://www.unmannedsystemstechnology.com/company/sbg-systems/</li>
<li>Inertial navigation for defense UAVs - SBG Systems, 9월 21, 2025에 액세스, https://www.sbg-systems.com/defense/uav-unmanned-aerial-vehicles-navigation-defense/</li>
<li>MicroStrain 3DM-GX5-GNSS/INS High Performance Navigation System | Parker NA, 9월 21, 2025에 액세스, https://ph.parker.com/us/en/microstrain-3dm-gx5-gnss-ins-high-performance-navigation-system/microstrain-3dm-gx5-gnss-ins</li>
<li>Architecture and System Performance of SPAN -NovAtel’s GPS/INS Solution - NET, 9월 21, 2025에 액세스, https://hexagondownloads.blob.core.windows.net/public/Novatel/assets/Documents/Papers/SPAN_PLANS2006/SPAN_PLANS2006.pdf</li>
<li>MicroStrain 3DM-CX5-GNSS/INS Embeddable High Performance Navigation System, 9월 21, 2025에 액세스, https://ph.parker.com/us/en/product/microstrain-3dm-cx5-gnss-ins-embeddable-high-performance-navigation-system/microstrain-3dm-cx5-gnss-ins</li>
<li>Cyberlux Showcases Advanced Rotary Wing UAS at US SOCOM TE 25-1 / Arctic Warrior Experiment - Stock Titan, 9월 21, 2025에 액세스, https://www.stocktitan.net/news/CYBL/cyberlux-showcases-advanced-rotary-wing-uas-at-us-socom-te-25-1-xyz1d5v9pk3o.html</li>
<li>Cyberlux Aligns with DoD’s Vision to Unleash U.S. Military Drone Dominance, 9월 21, 2025에 액세스, https://cyberlux.com/cyberlux-aligns-with-dods-vision-to-unleash-u-s-military-drone-dominance/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>