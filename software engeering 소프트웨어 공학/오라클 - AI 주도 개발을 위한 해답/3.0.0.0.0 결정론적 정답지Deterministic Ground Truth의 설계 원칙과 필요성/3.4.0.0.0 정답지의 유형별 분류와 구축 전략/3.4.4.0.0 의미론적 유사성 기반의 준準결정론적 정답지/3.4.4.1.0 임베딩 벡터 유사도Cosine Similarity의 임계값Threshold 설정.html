<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:3.4.4.1 임베딩 벡터 유사도(Cosine Similarity)의 임계값(Threshold) 설정</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>3.4.4.1 임베딩 벡터 유사도(Cosine Similarity)의 임계값(Threshold) 설정</h1>
                    <nav class="breadcrumbs"><a href="../../../../../index.html">Home</a> / <a href="../../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../../index.html">Chapter 3. 결정론적 정답지(Deterministic Ground Truth)의 설계 원칙과 필요성</a> / <a href="../index.html">3.4 정답지의 유형별 분류와 구축 전략</a> / <a href="index.html">3.4.4 의미론적 유사성 기반의 준(準)결정론적 정답지</a> / <span>3.4.4.1 임베딩 벡터 유사도(Cosine Similarity)의 임계값(Threshold) 설정</span></nav>
                </div>
            </header>
            <article>
                <h1>3.4.4.1 임베딩 벡터 유사도(Cosine Similarity)의 임계값(Threshold) 설정</h1>
<p>인공지능(AI) 및 대형 언어 모델(LLM)을 통합한 최신 소프트웨어 시스템의 자동화 테스트에 있어서 가장 큰 기술적 난제는 출력의 ’비결정성(Nondeterminism)’을 통제하는 것이다. 전통적인 단위 테스트(Unit Test) 체계는 기댓값과 실제 결과값의 정확한 문자열 일치(Exact Match)를 검증하는 확정적 오라클(Deterministic Oracle)에 기반을 둔다. 그러나 생성형 AI의 출력은 본질적으로 확률적이며, 시스템이 동일한 의미와 논리를 지닌 정답을 도출하더라도 실행 시점마다 형태적(Lexical) 배열이나 어휘의 선택이 달라진다. 이러한 상황에서 단순한 문자열 일치 방식이나 정규 표현식(Regular Expression) 기반의 검증은 무수한 오탐(False Negative)을 유발하여 테스트 스위트(Test Suite)의 신뢰성을 근본적으로 파괴한다.</p>
<p>이러한 한계를 극복하고 AI 소프트웨어 테스트에 결정론적 안전망을 제공하기 위해 제안된 핵심 메커니즘이 바로 의미론적 유사성(Semantic Similarity)을 기반으로 한 준(準)결정론적 정답지(Semi-deterministic Ground Truth)의 구축이다. 그 중심에는 텍스트를 고차원 공간의 밀집 벡터(Dense Vector)로 변환하여 비교하는 임베딩 벡터 유사도 평가가 자리 잡고 있으며, 이때 가장 널리 사용되는 수학적 거리가 코사인 유사도(Cosine Similarity)다.</p>
<p>코사인 유사도는 두 벡터가 이루는 사잇각의 코사인 값을 측정하여 방향성의 일치 정도를 평가하는 훌륭한 지표지만, -1에서 1 사이의 연속적인(Continuous) 실수 값을 반환한다. 이를 테스트 오라클이 필요로 하는 “테스트 통과(Pass)” 또는 “실패(Fail)“라는 이진적(Binary)이고 확정적인 판정 기준으로 변환하기 위해서는 **임계값(Threshold)**의 설정이 필수 불가결하다. 직관이나 경험칙(Rule of Thumb)에 의존한 임의의 임계값 설정은 치명적인 테스트 안티패턴을 초래한다. 본 절에서는 코사인 유사도의 수학적 본질과 통계적 분포 특성을 깊이 있게 해부하고, 통계적 유의성과 비즈니스 리스크 허용도(Risk Tolerance)에 기반하여 테스트 오라클의 임계값을 최적화하는 방법론을 심도 있게 기술한다.</p>
<h2>1.  코사인 유사도 기반 오라클의 수학적 기초와 기하학적 의미</h2>
<p>임계값 설정 방법론을 설계하기 위해서는 평가 메트릭 자체의 수학적 특성과 여타 거리 지표 대비 코사인 유사도가 갖는 기하학적 우위를 명확히 이해해야 한다.</p>
<p>텍스트 문서를 사전 학습된 임베딩 모델(예: Sentence-BERT, OpenAI text-embedding-3-large 등)을 통해 변환하면 <span class="math math-inline">d</span> 차원의 실수 벡터 <span class="math math-inline">A</span> 와 <span class="math math-inline">B</span> 가 생성된다. 두 벡터 간의 코사인 유사도는 내적(Dot Product)을 각 벡터의 <span class="math math-inline">L_2</span> 노름(Norm, 크기)의 곱으로 나눈 값으로 다음과 같이 정의된다.<br />
<span class="math math-display">
\cos(\theta) = \frac{A \cdot B}{\Vert A \Vert_{2} \Vert B \Vert_{2}} = \frac{\sum_{i=1}^{n} A_{i} B_{i}}{\sqrt{\sum_{i=1}^{n} A_{i}^{2}} \sqrt{\sum_{i=1}^{n} B_{i}^{2}}}
</span><br />
이 공식이 소프트웨어 테스트 검증 메트릭으로서 갖는 가장 강력한 이점은 **스케일 불변성(Scale-Invariance)**이다. 자연어 처리에서 두 텍스트의 유사도를 측정할 때 사용할 수 있는 대안적 지표들과 코사인 유사도의 특성을 비교하면 그 이유가 명확해진다.</p>
<table><thead><tr><th><strong>거리/유사도 지표</strong></th><th><strong>수학적 특성 및 계산식</strong></th><th><strong>장점 및 한계점</strong></th><th><strong>AI 오라클 적합성</strong></th></tr></thead><tbody>
<tr><td><strong>유클리디안 거리 (Euclidean Distance)</strong></td><td><span class="math math-inline">\sqrt{\sum (A_i - B_i)^2}</span></td><td>두 점 사이의 물리적 직선 거리를 측정한다. 벡터의 크기(Magnitude)에 매우 민감하여 텍스트 길이가 다르면 의미가 같아도 거리가 멀어진다.</td><td>낮음. 단, 정규화된 벡터에서는 코사인 유사도와 수학적으로 동치로 취급될 수 있다.</td></tr>
<tr><td><strong>맨해튼 거리 (Manhattan Distance)</strong></td><td><span class="math math-inline">\sum \vert A_i - B_i \vert</span></td><td>격자형 공간에서의 절대적 차이를 측정한다. 고차원 공간에서는 유클리디안 거리보다 강건(Robust)하지만 여전히 벡터 크기에 종속적이다.</td><td>낮음.</td></tr>
<tr><td><strong>내적 (Dot Product)</strong></td><td><span class="math math-inline">\sum (A_i \times B_i)</span></td><td>벡터의 방향과 크기를 동시에 고려한다. 텍스트 길이에 비례하여 점수가 폭발적으로 증가할 위험이 있다.</td><td>중간. 임베딩이 미리 스케일링된 경우에만 유효하다.</td></tr>
<tr><td><strong>코사인 유사도 (Cosine Similarity)</strong></td><td>내적을 <span class="math math-inline">L_2</span> 노름으로 정규화</td><td>벡터의 크기를 무시하고 오직 **방향성(Orientation)**만을 비교한다. 길이나 단어 빈도가 달라도 의미론적 지향점이 같으면 높은 점수를 반환한다.</td><td><strong>매우 높음.</strong></td></tr>
</tbody></table>
<p>위 표에서 보듯 유클리디안 거리는 텍스트의 길이나 특정 단어의 빈도수에 따라 벡터의 크기가 변할 경우 두 텍스트의 핵심 의미가 같음에도 거리가 크게 벌어지는 왜곡을 발생시킨다. 반면 코사인 유사도는 정답지로 설정된 기준 문장과 AI가 생성한 예측 문장의 길이가 다르더라도, 다차원 공간에서 가리키는 의미적 방향성이 일치한다면 1에 가까운 값을 반환한다. 단, 두 벡터가 <span class="math math-inline">L_2</span> 정규화(Normalized)를 거쳐 크기가 1이 된 상태라면, 코사인 유사도와 유클리디안 거리(<span class="math math-inline">d</span>) 사이에는 <span class="math math-inline">d = \sqrt{2 - 2\cos(\theta)}</span> 라는 관계가 성립하므로 실질적으로 동일한 순위를 산출하게 된다.</p>
<p>유사도 점수의 범위는 원칙적으로 [-1, 1]에 존재한다. 1은 완전히 동일한 방향(완벽한 의미적 일치), 0은 직교(Orthogonal, 의미적 무관함), -1은 완전히 반대되는 방향(상반된 의미)을 나타낸다. 그러나 현대의 대규모 코퍼스로 학습된 임베딩 모델이 생성하는 공간에서는 통계적으로 매우 독특한 기하학적 분포 특성이 관찰되며, 이는 임계값 설정을 극도로 까다롭게 만든다.</p>
<h2>2.  표현 공간의 비등방성(Anisotropy)과 통계적 귀무 분포(Null Distribution)</h2>
<p>실제 소프트웨어 테스트 환경에서 코사인 유사도를 오라클로 사용할 때 개발자들이 가장 당혹스러워하는 현상은 “문맥이 완전히 무관한 문장 간의 유사도 점수조차 0.7~0.8 이상으로 매우 높게 산출된다“는 점이다. 직관적으로 0(직교)에 가까워야 할 무작위 텍스트 쌍의 유사도가 비정상적으로 높은 이유는 무엇인가? 이를 이해하기 위해서는 임베딩 모델의 통계적 속성을 파악해야 한다.</p>
<h3>2.1  코사인 유사도의 귀무 분포와 고차원 집중 현상</h3>
<p>데이터 벡터가 다변량 정규 분포 <span class="math math-inline">x, y \sim \mathcal{N}(0, \Sigma)</span> 를 따른다고 가정할 때, 두 독립적인 무작위 벡터 간의 코사인 유사도가 이루는 귀무 분포(Null Distribution)는 평균이 0인 점근적 정규 분포(Asymptotically Normal Distribution)를 따른다. 연구(Smith et al., 2023)에 따르면 이 분포의 분산(Variance)은 공분산 행렬 <span class="math math-inline">\Sigma</span> 의 고윳값(Eigenvalues) <span class="math math-inline">\lambda_i</span> 에 의해 다음과 같이 근사된다.<br />
<span class="math math-display">
\operatorname{Var}[\cos(x, y)] \approx \frac{\sum_{i=1}^p \lambda_i^2}{\left(\sum_{j=1}^p \lambda_j\right)^2}
</span><br />
차원(Dimensionality)이 수백에서 수천에 달하는 현대의 임베딩(예: 1536차원) 환경에서는 분산이 극도로 축소되어 유사도 분포가 매우 좁은 구간에 고도로 집중(Concentration of Measure)되는 현상이 발생한다. 더욱이 실제 자연어 모델에서는 공분산 행렬이 완전한 등방성(Isotropic, <span class="math math-inline">\Sigma \propto I</span>)을 띠지 않기 때문에 문제가 심화된다.</p>
<h3>2.2  비등방성(Anisotropy)과 고빈도 어휘 편향</h3>
<p>자연어의 단어들은 지프의 법칙(Zipf’s Law)에 따라 극소수의 단어가 압도적인 빈도로 등장한다. 언어 모델은 학습 과정에서 이러한 고빈도 단어들의 영향으로 인해, 의미 벡터들이 고차원 공간 전체에 구형으로 고르게 퍼져 있는 것이 아니라, 특정 원뿔(Narrow Cone) 형태의 좁은 하위 공간(Subspace)에 밀집되는 비등방성(Anisotropy)을 띠게 된다.</p>
<p>그 결과, 랜덤하게 추출된 두 문장을 비교하더라도 이들의 벡터는 기하학적으로 같은 사분면이나 좁은 원뿔 내에 존재하게 되어 베이스라인 평균 자체가 0.7~0.8 이상으로 상향 편향된다. 논문 논문 <em>Frequency-induced similarity underestimation</em> (Zhou et al., 2022)은 이러한 코퍼스 내 어휘 빈도에 따른 벡터 <span class="math math-inline">L_2</span> 노름의 편향이 고빈도 단어들 간의 실제 유사도를 왜곡시키는 주요 원인임을 증명한 바 있다.</p>
<p>이러한 통계적 한계로 인해, <code>Cosine Similarity &gt; 0.5</code>라는 전통적이고 직관적인 기준을 임계값으로 설정하는 것은 자동화 테스트 환경에서 전혀 작동하지 않는다. AI의 치명적인 환각(Hallucination)조차 0.5를 가볍게 넘기며 테스트를 통과(False Positive)하기 때문이다. 반대로 <code>Cosine Similarity &gt; 0.95</code>와 같이 극단적으로 높은 기준을 일괄 적용하면, AI가 완벽하게 올바른 의미를 도출했음에도 불구하고 조사나 어미, 동의어 선택이 미세하게 다르다는 이유로 테스트가 실패(False Negative)하는 ’플래키 테스트(Flaky Test)’가 급증하여 CI/CD 파이프라인이 붕괴된다.</p>
<h2>3.  리스크 허용도 기반 임계값 결정 프레임워크 (Risk-based Framework)</h2>
<p>임베딩 기반 오라클에서 최적의 임계값( <span class="math math-inline">\tau</span> )을 결정하는 것은 단순한 모델 하이퍼파라미터 튜닝이 아니다. 이는 소프트웨어의 기능적 신뢰성과 프로덕션 환경의 사용자 리스크를 제어하는 중대한 비즈니스 의사결정 과정이다. 논문 <em>How to Choose a Threshold for an Evaluation Metric for Large Language Models</em> (Sarmah et al., 2024)는 AI 모델 평가 메트릭의 임계값을 결정하기 위해 금융권의 모델 리스크 관리(Model Risk Management, MRM) 체계를 차용한 체계적인 프레임워크를 제안했다.</p>
<p>해당 방법론에 따르면 임계값 설정은 비즈니스 요구사항에 기반한 ’리스크 수용도(Risk Tolerance)’를 통계적 수치로 변환하는 작업에서 출발해야 한다. 코사인 유사도 임계값은 필연적으로 정밀도(Precision)와 재현율(Recall) 간의 트레이드오프(Trade-off)를 유발하며, 시스템의 목적에 따라 이 교환비를 전략적으로 조절해야 한다.</p>
<ul>
<li><strong>저위험/탐색적 도메인 (Low Risk Zone):</strong> 아이디어 브레인스토밍, 초안 작성 보조, 혹은 창의적 답변이 요구되는 시스템에서는 정보의 포괄성과 다양성이 중요하다. 약간의 부정확성이 존재하더라도 유용한 응답이 오라클에 의해 거부(False Negative)되는 것을 방지하기 위해 재현율(Recall)을 우선시한다. 이 경우 임계값은 상대적으로 느슨한 구간인 <strong>0.60 ~ 0.70</strong> 사이에서 형성된다. 이 구간에서는 재현율이 0.95 수준으로 매우 높게 유지되지만, 오탐을 허용하므로 정밀도는 0.40 내외로 하락할 수 있다.</li>
<li><strong>교차/균형 도메인 (Balanced Zone):</strong> 일반적인 정보 검색(RAG)이나 챗봇 환경에서는 정밀도와 재현율이 적절히 타협하는 구간을 찾는다. 통상적으로 코사인 유사도 임계값이 <strong>0.80 ~ 0.85</strong>에 도달할 때 정밀도와 재현율이 모두 0.8 부근에서 교차하며 최적의 균형을 이룬다.</li>
<li><strong>고위험/엄격한 제어 도메인 (High Risk Zone):</strong> 의료 진단 데이터 추출, 금융 결제 로직 확인, 법률 검토 등에서는 모델이 오답을 정답으로 판단하고 통과시키는 오탐(False Positive)이 치명적인 사고로 직결된다. 여기서는 정밀도(Precision) 극대화가 지상 과제이므로, 코사인 유사도 임계값을 보수적으로 <strong>0.88 ~ 0.95</strong> 범위로 상향 설정해야 한다. 임계값을 0.95로 올리면 환각 통과 확률을 거의 0으로 만들어 정밀도를 0.98 이상으로 끌어올릴 수 있으나, 그 대가로 재현율은 0.3 이하로 급락하게 된다. 약간의 형태소 변화만 있어도 테스트가 실패로 간주하기 때문이다.</li>
</ul>
<p>이러한 트레이드오프 구조를 인지하고 나면, 개발팀은 “우리 소프트웨어 테스트는 100번의 정상 응답을 버리더라도 단 1번의 환각(Hallucination) 통과를 막아야 하는가?“와 같은 정책적 질문에 먼저 답해야 한다. 이를 통해 도출된 통계적 신뢰 수준 <span class="math math-inline">\alpha</span> 가 이후 진행될 임계값 도출 수식의 가중치로 작용하게 된다.</p>
<h2>4.  골든 데이터셋(Golden Dataset) 구축 및 통계적 임계값 도출 방법론</h2>
<p>목표로 하는 리스크 허용도가 정해졌다면, 실제 임계값을 산출하기 위해 통계적으로 유의미한 규모의 ’골든 데이터셋’을 구축해야 한다.</p>
<p>골든 데이터셋은 검증 대상 프롬프트와 예상되는 기준 정답(Reference Truth) 쌍은 물론, AI 모델이 과거에 생성했던 다양한 긍정적 변형(Positive Paraphrases)과 부정적 변형(환각, 동문서답 등) 샘플들을 모두 포함해야 한다. 이 샘플 데이터들에 대해 인간 평가자(Human-in-the-loop)가 기준 정답과 의미론적으로 일치하는지(Relevant=1) 또는 일치하지 않는지(Irrelevant=0)를 이진 라벨링(Binary Labeling)한다.</p>
<p>라벨링된 데이터셋과 각 쌍의 코사인 유사도 점수가 준비되면, 직관을 배제하고 아래의 엄밀한 수학적/통계적 방법론 중 하나를 채택하여 최적 임계값을 연산한다.</p>
<h3>4.1  방법론 A: 오류 교집합 최소화 (Minimization of FP + FN)</h3>
<p>논문 <em>Optimal Threshold Determination for Interpreting Semantic Similarity</em> (Bettembourg et al., 2015)에서 제안된 분포 기반 접근법을 소프트웨어 검증에 맞게 변형한 방식이다.</p>
<ol>
<li>수집된 골든 데이터셋에서 인간이 ’유사하다(Relevant=1)’고 판정한 응답들의 코사인 유사도 점수를 모아 확률 밀도 함수인 <span class="math math-inline">S</span> 분포(Similar Distribution)를 추정한다.</li>
<li>’유사하지 않다(Irrelevant=0)’고 판정한 응답들의 점수를 모아 <span class="math math-inline">N</span> 분포(Non-similar Distribution)를 추정한다.</li>
<li>벡터 공간의 비등방성 한계로 인해 <span class="math math-inline">S</span> 분포와 <span class="math math-inline">N</span> 분포는 필연적으로 꼬리 구간(Overlapping tails)에서 교차한다. 즉, 어떤 오답은 교묘한 단어 사용으로 점수가 높게 나오고, 어떤 정답은 독창적인 어휘 변형으로 인해 점수가 낮게 나온다.</li>
<li>임의의 임계값 <span class="math math-inline">\tau</span> 를 점수의 최솟값(min)에서 최댓값(max) 사이에서 이동시킨다.</li>
<li><span class="math math-inline">\tau</span> 보다 낮은 <span class="math math-inline">S</span> 분포의 적분 면적은 거짓 음성 비율(FN Rate)이 되고, <span class="math math-inline">\tau</span> 보다 높은 <span class="math math-inline">N</span> 분포의 적분 면적은 거짓 양성 비율(FP Rate)이 된다.</li>
<li>다음 목적 함수를 최소화하는 <span class="math math-inline">\tau_{sim}</span> 을 최적의 오라클 임계값으로 확정한다.</li>
</ol>
<p><span class="math math-display">
\tau_{sim} = \underset{\tau}{\mathrm{argmin}} \left( \alpha \cdot \text{FP Rate}(\tau) + \beta \cdot \text{FN Rate}(\tau) \right)
</span></p>
<p>여기서 <span class="math math-inline">\alpha</span> 와 <span class="math math-inline">\beta</span> 는 앞선 3장에서 정의한 비즈니스 리스크 가중치다. 거짓 양성(FP)을 극도로 회피해야 하는 고위험 시스템이라면 <span class="math math-inline">\alpha</span> 에 훨씬 큰 가중치(예: <span class="math math-inline">\alpha=0.9, \beta=0.1</span>)를 부여하여 <span class="math math-inline">\tau_{sim}</span> 을 분포의 우측 극단으로 이동시킨다.</p>
<h3>4.2  방법론 B: 매튜스 상관계수(MCC) 최대화 전략</h3>
<p>분류 모델의 성능 평가 지표를 활용하여 임계값을 스위핑(Sweeping)하는 기법이다. 코사인 유사도 임계값을 0.50부터 0.99까지 0.01 단위로 세밀하게 증가시키면서, 각 임계값에서의 예측 결과와 실제 인간의 라벨(1 또는 0) 간의 성능 지표를 산출한다.</p>
<p>전통적으로는 정밀도와 재현율의 조화 평균인 F1-Score (<span class="math math-inline">2 \cdot \frac{P \cdot R}{P + R}</span>) 가 최대화되는 지점을 찾는다. 그러나 소프트웨어 테스트 환경에서는 오답(Irrelevant)의 수가 정답(Relevant)의 수보다 압도적으로 많거나 적은 클래스 불균형(Class Imbalance)이 빈번하게 발생한다. 이 경우 F1-Score만으로는 임계값이 다수 클래스 쪽으로 편향될 수 있다.</p>
<p>따라서 참 양성(TP), 참 음성(TN), 거짓 양성(FP), 거짓 음성(FN)의 혼동 행렬(Confusion Matrix) 요소를 모두 균형 있게 고려하는 **매튜스 상관계수(Matthews Correlation Coefficient, MCC)**를 산출하여 최적화하는 것이 훨씬 견고하다.<br />
<span class="math math-display">
\text{MCC} = \frac{(TP \cdot TN) - (FP \cdot FN)}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}
</span><br />
경험적으로 사전 학습된 Sentence-BERT 등의 샴 네트워크(Siamese Network) 아키텍처를 사용할 때, 일반적인 의미론적 텍스트 유사성(STS) 작업에서 MCC가 최대화되는 코사인 유사도 임계값은 보통 0.75 ~ 0.85 구간에서 도출되는 경향이 있다.</p>
<h3>4.3  방법론 C: 로지스틱 회귀(Logistic Regression)를 통한 확률적 매핑</h3>
<p>코사인 점수를 확률 공간으로 직접 맵핑하여 설명 가능성(Explainability)을 확보하는 엔터프라이즈 친화적 방법이다.</p>
<p>코사인 유사도 점수(<span class="math math-inline">x</span>)를 로지스틱 회귀 모델의 독립 변수(Predictor)로 입력하고, 인간의 이진 판단 값(<span class="math math-inline">y \in \{0, 1\}</span>)을 종속 변수(Response)로 설정하여 곡선을 피팅한다. 학습이 완료되면, 특정 코사인 점수 <span class="math math-inline">x</span> 가 주어졌을 때 해당 응답이 실제로 의미론적 정답일 예측 확률 <span class="math math-inline">P(y=1|x)</span> 을 산출하는 로지스틱 방정식을 얻게 된다.</p>
<p>이후 시스템 관리자가 “우리는 AI 답변이 실제 정답일 확률이 95% 이상일 때만 테스트를 Pass 시키겠다“고 결정하면, <span class="math math-inline">P = 0.95</span> 에 대응하는 <span class="math math-inline">x</span> 축의 코사인 유사도 값을 수식에서 역산하여 임계값으로 확정한다. 이 방식은 임계값 설정에 대한 강력한 통계적 근거를 제공하여 감리나 품질 보증(QA) 부서를 설득하는 데 매우 효과적이다.</p>
<h2>5.  고급 의미 평가: BERTScore 메트릭과 베이스라인 재조정(Rescaling)</h2>
<p>단일 문장 단위의 임베딩(예: Sentence-BERT, text-embedding-3)을 전체적으로 비교하는 방식은 빠르고 직관적이지만, 생성된 텍스트가 매우 길거나 복잡한 구문적, 논리적 관계를 가질 경우 문장 전체를 하나의 벡터로 압축하면서 발생하는 정보 손실 병목 현상이 발생한다. 이를 극복하기 위해 제안된 것이 개별 토큰(Token) 수준의 문맥적 임베딩(Contextual Embeddings)을 활용하는 <strong>BERTScore</strong> 논문(Zhang et al., 2020)의 접근법이다.</p>
<h3>5.1  BERTScore의 토큰 매핑 매커니즘</h3>
<p>BERTScore는 단순한 단어 중복도(n-gram)를 보는 BLEU나 ROUGE와 달리, 트랜스포머 모델의 깊은 레이어에서 추출한 토큰 임베딩을 기반으로 의미론적 유사도를 계산한다. 후보 문장(Candidate)의 각 토큰과 기준 문장(Reference)의 각 토큰 간의 모든 코사인 유사도 쌍을 계산하여 유사도 행렬(Similarity Matrix)을 구성한 뒤, 그리디 매칭(Greedy Matching)을 통해 최대 유사도를 갖는 토큰끼리 정렬(Alignment)한다.</p>
<p>이를 바탕으로 정밀도(Precision), 재현율(Recall), F1 점수를 재정의한다. 소프트웨어 테스트 관점에서 볼 때 정밀도(<span class="math math-inline">P_{BERT}</span>)는 AI가 생성한 문장 내의 단어들이 기준 정답의 의미를 얼마나 벗어나지 않았는지를 측정하며, 재현율(<span class="math math-inline">R_{BERT}</span>)은 기준 정답이 요구하는 핵심 정보가 생성된 문장에 빠짐없이 포함되었는지를 측정한다. 또한 중요도가 떨어지는 관사나 접속사보다 핵심 도메인 명사에 가중치를 부여하기 위해 역문서 빈도(Inverse Document Frequency, IDF) 가중치 적용을 지원하여 오라클의 분별력을 크게 높인다.</p>
<h3>5.2  베이스라인 재조정(Baseline Rescaling)의 필수성</h3>
<p>앞서 2장에서 언급한 바와 같이, 트랜스포머 모델의 비등방성 문제로 인해 BERTScore의 원시 코사인 유사도 F1 점수 역시 극단적으로 좁은 구간(예: 0.85 ~ 0.95)에 밀집되어 산출된다. 이로 인해 임계값을 0.01만 조정해도 수많은 테스트 케이스의 Pass/Fail 결과가 뒤바뀌는 극도의 불안정성이 나타난다.</p>
<p>이러한 모델 의존성을 제거하고 결정론적 테스트 오라클의 일관성을 유지하기 위해 BERTScore 논문 저자들이 공식적으로 도입한 기법이 **베이스라인 재조정(Baseline Rescaling)**이다.</p>
<p>이 기법은 수백만 개의 무작위 문장 쌍으로 구성된 단일 언어 코퍼스(Monolingual Corpus)에서 코사인 유사도를 사전 계산하여 경험적 하한값(Lower Bound) 혹은 베이스라인(<span class="math math-inline">Base</span>)을 산출한 뒤, 실제 관측된 유사도 점수(<span class="math math-inline">X</span>)를 다음과 같은 선형 변환(Linear Transformation)을 통해 넓게 펼치는 것이다.<br />
<span class="math math-display">
\hat{X} = \frac{X - Base}{1 - Base}
</span><br />
이 변환을 테스트 프레임워크의 파이프라인에 적용하면, 기하학적 편향이 보정되어 최종 유사도 점수 <span class="math math-inline">\hat{X}</span> 가 0.0에서 1.0 사이의 전체 스펙트럼에 고르게 분포하게 된다. 이 변환은 피어슨(Pearson) 상관계수나 켄달 타우(Kendall’s <span class="math math-inline">\tau</span>) 등 점수 간의 상대적 순위 보존 능력에 전혀 악영향을 주지 않으면서 판독성을 극대화한다.</p>
<p><img src="./3.4.4.1.0%20%EC%9E%84%EB%B2%A0%EB%94%A9%20%EB%B2%A1%ED%84%B0%20%EC%9C%A0%EC%82%AC%EB%8F%84Cosine%20Similarity%EC%9D%98%20%EC%9E%84%EA%B3%84%EA%B0%92Threshold%20%EC%84%A4%EC%A0%95.assets/image-20260222124839466.jpg" alt="image-20260222124839466" /></p>
<p>재조정된 유사도를 활용하면, 인간의 직관에 완벽히 부합하는 <strong><span class="math math-inline">\tau = 0.5</span></strong> 라는 상식적 중앙값을 의미론적 일치와 불일치를 가르는 범용적인 초기 결정 경계(Decision Boundary)로 사용할 수 있다. 이는 수백 개의 테스트 케이스를 관리해야 하는 CI/CD 환경에서 오라클 규칙의 가독성과 유지보수성을 압도적으로 향상시킨다.</p>
<h2>6.  동적 임계값(Dynamic Threshold) 모델과 이중 임계값 아키텍처</h2>
<p>소프트웨어 시스템 전체에 걸쳐 수백 가지의 상이한 테스트 시나리오에 대해 단일한 전역 임계값(Global Uniform Threshold)을 일괄 적용하는 것은 자동화 테스트의 또 다른 안티패턴이다. 자연어에는 의미론적 다형성(Semantic Polysemy)이 존재하며, 질문의 복잡도나 도메인의 특성에 따라 언어적 엄격성(Linguistic Strictness)이 다르게 요구되기 때문이다.</p>
<p>최근의 지능형 오라클 연구는 이러한 한계를 극복하기 위해 문맥 및 라벨 특화(Label-Specific) 가중치를 적용한 동적 임계값 아키텍처를 도입하고 있다.</p>
<h3>6.1  코사인 어댑터(Cosine Adapter)를 통한 난이도 반영 매핑</h3>
<p>정보 검색(IR)이나 정밀한 답변 추출 환경에서 특정 쿼리는 고유 명사 위주의 엄격한 일치를 요구하는 반면, 다른 쿼리는 광범위한 동의어 처리를 필요로 한다. 이를 해결하기 위해 신경망 구조 내부에 ’코사인 어댑터(Cosine Adapter)’라는 경량 변환 컴포넌트를 주입할 수 있다.</p>
<p>코사인 어댑터는 테스트 쿼리 자체의 임베딩 정보(난이도, 특성)를 활용하여 원시 코사인 유사도 점수를 문맥을 인지하는(Context-aware) 관련도 점수로 동적 매핑한다.<br />
<span class="math math-display">
\mathcal{F}(x|\Theta) = \text{sgn}(x)a \vert x \vert + b
</span><br />
이러한 튜닝 가능한 선형 또는 비선형 함수 <span class="math math-inline">\mathcal{F}</span> 를 통과시키면, 시스템 관리자가 외부에서 동일한 <span class="math math-inline">\tau</span> 값을 주입하더라도, 오라클 내부적으로는 입력된 프롬프트의 복잡도 <span class="math math-inline">\Theta = (a, b)</span> 에 따라 실제로 요구되는 임베딩 간의 유사성 기준을 엄격하게 쪼이거나 느슨하게 푸는 자동 조절 효과를 얻을 수 있다.</p>
<h3>6.2  신뢰도 검증을 위한 이중 임계값 메커니즘 (Dual-Threshold Mechanism)</h3>
<p>의료 임상 노트 요약, 금융 거래 승인, 또는 법률 문서 분석과 같이 단 한 번의 오작동이나 환각이 치명적인 결과를 낳는 도메인에서는 단일 결정 경계에 모든 것을 의존하는 것이 매우 위험하다. 이를 보완하기 위해 도입된 개념이 **이중 임계값 메커니즘(Dual-threshold Mechanism)**이다.</p>
<p>최근 의료 기록 생성을 검증하는 AI 연구에서는 트리 파르젠 추정기(Tree Parzen Estimator, TPE)와 같은 하이퍼파라미터 최적화 알고리즘을 활용하여 두 개의 별도 임계값을 도출해 내는 파이프라인을 구축했다.</p>
<ul>
<li><strong>위험 임계값(Critical Threshold):</strong> 매우 보수적이고 높은 기준선(예: 0.90). 이 선을 넘지 못하는 모델의 출력은 ’환각(Hallucination)’이 포함되었거나 치명적인 정보 누락이 발생했다고 확정적으로 판단하여 테스트를 즉각 실패(Fail) 처리하고 배포를 차단한다.</li>
<li><strong>경고 임계값(Alert Threshold):</strong> 상대적으로 관대한 기준선(예: 0.75). 위험 임계값과 경고 임계값 사이에 위치한 점수(0.75 ~ 0.90)는 확정적 실패는 아니지만, 안전을 보장할 수 없는 ’회색 지대(Gray Zone)’로 간주된다. 시스템은 이 구간의 테스트 결과를 실패로 단정 짓는 대신, 인간 검토자(Human-in-the-loop)에게 로그를 에스컬레이션하여 최종 판단을 위임한다.</li>
</ul>
<p>이러한 이중 임계값 아키텍처는 자동화 검증의 효율성을 살리면서도 엣지 케이스(Edge Case)에 대한 안전망을 제공함으로써, 무인 오라클 시스템이 지닌 태생적인 위험도를 크게 낮추는 효과를 가져온다.</p>
<hr />
<h2>7.  결론: CI/CD 통합을 위한 임계값 관리 파이프라인</h2>
<p>결정론적 오라클을 CI/CD(지속적 통합/배포) 파이프라인에 이식하기 위한 코사인 유사도 임계값 최적화는 한 번 설정하고 잊어버리는(Set-and-Forget) 과정이 결코 아니다. 임베딩 벡터와 유사도 매트릭스는 살아있는 데이터 모델이며, 다음과 같은 체계적인 생명주기(Lifecycle)를 통해 지속적으로 관리되어야 한다.</p>
<ol>
<li><strong>시드 데이터 기반 기준점 설정:</strong> 초기 예상 출력값(Expected Outputs)과 예상 오답(Hallucinations)을 벡터 데이터베이스(예: ChromaDB)에 적재하고 , 무작위 샘플에 대한 휴먼 라벨링을 통해 최초의 골든 데이터셋을 구축한다.</li>
<li><strong>수학적 최적화 및 튜닝:</strong> 수집된 데이터를 바탕으로 로지스틱 회귀나 MCC 최대화 기법을 사용하여 시스템 도메인에 부합하는 <span class="math math-inline">\tau</span> 값을 도출한다. 필요한 경우 베이스라인 재조정을 통해 메트릭의 직관성을 확보한다.</li>
<li><strong>지속적 모니터링과 드리프트(Drift) 방어:</strong> 운영 환경에서 새로운 형태의 사용자 프롬프트가 유입되거나 임베딩 차원이 업그레이드될 때마다(예: 1536차원에서 3072차원으로 이동), 기존 임계값은 유효성을 상실할 수 있다. 따라서 정기적으로 쿼리 로그를 샘플링하고 오탐(FP)/미탐(FN) 비율을 추적하여 임계값 도출 알고리즘을 재실행해야 한다.</li>
<li><strong>다중 계층 검증(Multi-Layered Evaluation) 결합:</strong> 코사인 유사도 기반 의미론적 평가는 강력하지만 만능은 아니다. 매우 중요한 키워드(예: ‘결제 취소’, ‘환불 불가’)의 존재 여부를 놓칠 수 있다. 따라서 순수 임베딩 기반 오라클 뒤에 키워드 포함 여부나 구조 검증을 담당하는 룰 기반(Rule-based) 오라클을 앙상블로 결합할 때 비로소 완전한 확정적 테스트가 완성된다.</li>
</ol>
<p>단순히 “유사도 0.8 이상이면 통과“라는 매직 넘버(Magic Number)를 하드코딩하는 것은 AI 소프트웨어 개발에서 가장 피해야 할 기술 부채(Technical Debt)다. 통계적 엄밀성과 비즈니스 리스크 기반의 교차 검증을 거친 코사인 유사도 임계값만이, AI의 비결정성이라는 거대한 불확실성 속에서 소프트웨어의 신뢰성을 담보하는 확고한 닻(Anchor)이 될 수 있다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>Challenges in Testing Large Language Model Based Software, https://arxiv.org/html/2503.00481v2</li>
<li>Challenges in Testing Large Language Model Based Software - arXiv, https://arxiv.org/html/2503.00481v1</li>
<li>Testing AI Applications: How to Validate Non-Deterministic Outputs, https://medium.com/@navanathjadhav/testing-ai-applications-how-to-validate-non-deterministic-outputs-3c02c086e567</li>
<li>What Is Cosine Similarity? | IBM, https://www.ibm.com/think/topics/cosine-similarity</li>
<li>BERTScore For LLM Evaluation - Comet, https://www.comet.com/site/blog/bertscore-for-llm-evaluation/</li>
<li>A Guide to Cosine Similarity | Tiger Data, https://www.tigerdata.com/learn/understanding-cosine-similarity</li>
<li>Taking Text Embedding and Cosine Similarity for a Test Drive, https://tech.blueyonder.com/text-embedding-and-cosine-similarity/</li>
<li>How do I choose a good treshold for classification (using cosine, https://ai.stackexchange.com/questions/40597/how-do-i-choose-a-good-treshold-for-classification-using-cosine-similarity-scor</li>
<li>Rule of thumb cosine similarity thresholds? - API, https://community.openai.com/t/rule-of-thumb-cosine-similarity-thresholds/693670</li>
<li>Cosine Similarity - Oracle Help Center, https://docs.oracle.com/en/database/oracle/oracle-database/26/vecse/cosine-similarity.html</li>
<li>How Cosine Similarity Transforms NLP Text Summarization - MyScale, https://myscale.com/blog/transforming-nlp-text-summarization-cosine-similarity/</li>
<li>Measuring Similarity and Distance between Embeddings - Dataquest, https://www.dataquest.io/blog/measuring-similarity-and-distance-between-embeddings/</li>
<li>Cosine Distance vs Dot Product vs Euclidean in vector similarity, https://medium.com/data-science-collective/cosine-distance-vs-dot-product-vs-euclidean-in-vector-similarity-search-227a6db32edb</li>
<li>How can I determine the minimum cosine similarity score between 2, https://www.kaggle.com/discussions/questions-and-answers/483108</li>
<li>Cosine Similarity: The Unsung Hero of AI Tools - Annielytics.com, https://www.annielytics.com/blog/ai/cosine-similarity-the-unsung-hero-of-ai-tools/</li>
<li>Understanding Cosine Similarity and Word Embeddings, https://spencerporter2.medium.com/understanding-cosine-similarity-and-word-embeddings-dbf19362a3c</li>
<li>Cosine similarity - Wikipedia, https://en.wikipedia.org/wiki/Cosine_similarity</li>
<li>Cosine Similarity Threshold - Emergent Mind, https://www.emergentmind.com/topics/cosine-similarity-threshold</li>
<li>Solving Cosine Similarity Underestimation between High Frequency, https://aclanthology.org/2023.findings-acl.550.pdf</li>
<li>bert_score/journal/rescale_baseline.md at master - GitHub, https://github.com/Tiiiger/bert_score/blob/master/journal/rescale_baseline.md</li>
<li>Embedding Essentials: Cosine Similarity in SQL - e6data, https://www.e6data.com/blog/embedding-essentials-cosine-similarity-sql-with-vectors</li>
<li>How to Choose a Threshold for an Evaluation Metric for Large, https://ideas.repec.org/p/arx/papers/2412.12148.html</li>
<li>[2412.12148] How to Choose a Threshold for an Evaluation Metric, https://arxiv.org/abs/2412.12148</li>
<li>How to Choose a Threshold for an Evaluation Metric for … - ChatPaper, https://chatpaper.com/chatpaper/paper/91256</li>
<li>Understanding RAG Score Thresholds: The Fine Line Between, https://nickberens.me/blog/understanding-rag-score-thresholds/</li>
<li>Determination of threshold for cosine similarity score? - ResearchGate, https://www.researchgate.net/post/Determination-of-threshold-for-cosine-similarity-score</li>
<li>Optimal Threshold Determination for Interpreting Semantic Similarity, https://pmc.ncbi.nlm.nih.gov/articles/PMC4521860/</li>
<li>Comparing Threshold Selection Methods for Network Anomaly, https://ieeexplore.ieee.org/iel8/6287639/10380310/10659855.pdf</li>
<li>(PDF) Multi-Objective Optimal Threshold Selection for Similarity, https://www.researchgate.net/publication/385016031_Multi-Objective_Optimal_Threshold_Selection_for_Similarity_Functions_in_Siamese_Networks_for_Semantic_Textual_Similarity_Tasks</li>
<li>Multi-Objective Optimal Threshold Selection for Similarity Functions, https://www.preprints.org/manuscript/202407.0020</li>
<li>A Cosine Similarity-based Method for Out-of-Distribution Detection, https://openreview.net/pdf?id=QuXApqb8Yl</li>
<li>Sentence Embedding Models for Similarity Detection of Software, https://www.researchgate.net/profile/Agostino-Cortesi/publication/348979891_Sentence_Embedding_Models_for_Similarity_Detection_of_Software_Requirements/links/602a6f63a6fdcc37a82ab607/Sentence-Embedding-Models-for-Similarity-Detection-of-Software-Requirements.pdf</li>
<li>BERTScore Explained in 5 minutes - Medium, https://medium.com/@abonia/bertscore-explained-in-5-minutes-0b98553bfb71</li>
<li>A Fine-Grained Analysis of BERTScore - ACL Anthology, https://aclanthology.org/2021.wmt-1.59.pdf</li>
<li>BERTScore in AI: Enhancing Text Evaluation - Galileo AI, https://galileo.ai/blog/bert-score-explained-guide</li>
<li>BLEURT &amp; BERTScore - IEEE Xplore, https://ieeexplore.ieee.org/iel8/8782664/10834807/10964149.pdf</li>
<li>BERTScore - Lynxius, https://docs.lynxius.ai/evaluators/heuristic_evals/bert_score/</li>
<li>Exploring Variable Thresholds for Distance-Based Multi-Label Text, https://arxiv.org/pdf/2510.11160</li>
<li>Relevance Filtering for Embedding-based Retrieval - arXiv, https://arxiv.org/html/2408.04887v1</li>
<li>Hallucination Detection in Automatically Generated Medical Reports, https://aclanthology.org/2025.jeptalnrecital-mlpllm.1.pdf</li>
<li>Understanding Similarity Search with Cosine Similarity - CodeSignal, https://codesignal.com/learn/courses/implementing-semantic-search-with-chromadb-1/lessons/understanding-similarity-search-with-cosine-similarity</li>
<li>An Empirical Evaluation of Set Similarity Join Techniques, https://www.vldb.org/pvldb/vol9/p636-mann.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>