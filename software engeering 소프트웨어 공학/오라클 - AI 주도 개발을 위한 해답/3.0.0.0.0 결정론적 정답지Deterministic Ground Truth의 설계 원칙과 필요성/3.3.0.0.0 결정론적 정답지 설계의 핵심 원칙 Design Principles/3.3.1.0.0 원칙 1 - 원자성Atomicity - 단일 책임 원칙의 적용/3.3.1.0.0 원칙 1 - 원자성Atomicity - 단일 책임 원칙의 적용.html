<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:3.3.1 원칙 1: 원자성(Atomicity) - 단일 책임 원칙의 적용</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>3.3.1 원칙 1: 원자성(Atomicity) - 단일 책임 원칙의 적용</h1>
                    <nav class="breadcrumbs"><a href="../../../../../index.html">Home</a> / <a href="../../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../../index.html">Chapter 3. 결정론적 정답지(Deterministic Ground Truth)의 설계 원칙과 필요성</a> / <a href="../index.html">3.3 결정론적 정답지 설계의 핵심 원칙 (Design Principles)</a> / <a href="index.html">3.3.1 원칙 1: 원자성(Atomicity) - 단일 책임 원칙의 적용</a> / <span>3.3.1 원칙 1: 원자성(Atomicity) - 단일 책임 원칙의 적용</span></nav>
                </div>
            </header>
            <article>
                <h1>3.3.1 원칙 1: 원자성(Atomicity) - 단일 책임 원칙의 적용</h1>
<p>현대 소프트웨어 공학의 역사는 복잡성(Complexity)과의 투쟁이라 해도 과언이 아니다. 결정론적(Deterministic) 알고리즘에 기반한 전통적인 시스템 개발에서, 이 복잡성을 제어하고 시스템의 유지보수성과 견고함을 보장하기 위해 고안된 가장 강력하고도 근본적인 설계 철학이 바로 ’단일 책임 원칙(Single Responsibility Principle, 이하 SRP)’이다. 로버트 C. 마틴(Robert C. Martin)에 의해 체계화된 이 원칙은 “클래스는 변경해야 할 이유가 단 하나여야 한다“는 명제로 압축되며, 이는 모듈의 응집도(Cohesion)를 극대화하고 결합도(Coupling)를 최소화하여 시스템을 생물학적 세포나 원자처럼 독립적인 단위로 분할하는 핵심 기제로 작동해 왔다.</p>
<p>그러나 확률적(Probabilistic) 본성을 지닌 인공지능(AI), 특히 거대언어모델(LLM)을 포함한 생성형 AI 기반의 소프트웨어를 검증하는 영역으로 진입하는 순간, 이 원칙은 단순히 코드의 구조적 미학을 넘어선 생존의 문제가 된다. AI 모델은 본질적으로 비결정적(Nondeterministic)이고 다차원적인 출력을 생성한다. 하나의 프롬프트에 대한 응답 속에는 문법적 정확성(Syntactic Correctness), 사실적 일관성(Factual Consistency), 논리적 완결성(Logical Completeness), 윤리적 안전성(Ethical Safety), 그리고 포맷 준수 여부(Format Adherence) 등 서로 다른 층위의 요구사항들이 복잡하게 얽혀 있다.</p>
<p>이를 검증하기 위한 정답지(Ground Truth)와 오라클(Oracle)이 이 모든 요소를 한 덩어리로 뭉뚱그려 “이 답변은 좋은가?“라는 식의 단일한 불리언(Boolean) 판정을 내리려 한다면, 테스트는 실패의 원인을 식별할 수 없는 거대한 ’블랙박스’가 되어버린다. 따라서 AI 소프트웨어 테스트에서 결정론적 정답지를 설계하는 제1원칙은 평가의 단위를 더 이상 쪼갤 수 없는 논리적 최소 단위, 즉 ’원자(Atom)’로 분해하는 **원자성(Atomicity)**이다.</p>
<p>본 장에서는 전통적 소프트웨어 테스팅에서의 SRP 개념을 AI 오라클 설계의 관점에서 재해석하고, 확률적인 AI 출력을 결정론적으로 통제하기 위한 원자적 오라클(Atomic Oracle)의 정의와 계층 구조, 그리고 이를 구현하기 위한 구체적인 방법론을 심층적으로 분석한다.</p>
<h2>1.  확률적 출력과 단일 책임 원칙의 충돌 및 재해석</h2>
<p>전통적인 단위 테스트(Unit Test)의 세계에서 오라클은 입력 <span class="math math-inline">x</span>에 대해 기대되는 출력 <span class="math math-inline">y</span>가 정확히 일치하는지(<span class="math math-inline">x \rightarrow y</span>)를 확인하는 이진(Binary) 판별기였다. 이는 입력과 출력이 1:1로 매핑되는 결정론적 세계에서의 합리적인 접근이다. 그러나 생성형 AI는 동일한 입력 <span class="math math-inline">x</span>에 대해 조건부 확률 분포 <span class="math math-inline">P(y|x)</span>를 출력한다. 이때 우리가 검증하고자 하는 것은 출력된 <span class="math math-inline">y&#39;</span>가 분포 상에서 허용 가능한 범위(Acceptable Region) 내에 존재하는가이다. 문제는 이 ’허용 가능한 범위’를 정의하는 기준이 단일하지 않고 복합적이라는 데 있다.</p>
<h3>1.1 복합 오라클(Composite Oracle)의 실패와 기술 부채</h3>
<p>단일 책임 원칙을 위배한 ’복합 오라클’의 전형적인 실패 사례는 “생성된 요약문이 훌륭한가?“라는 포괄적인 질문을 던지는 것이다. 이 질문은 겉보기에는 단순해 보이지만, 그 내부에는 서로 다른 변경의 이유를 가진 수많은 책임들이 혼재되어 있다.</p>
<ol>
<li><strong>사실 관계(Factuality):</strong> 원문과 모순되지 않는가? (지식의 정확성 문제)</li>
<li><strong>완전성(Completeness):</strong> 핵심 내용을 빠짐없이 포함했는가? (정보 추출 능력의 문제)</li>
<li><strong>문법(Syntax):</strong> 비문이나 오탈자가 없는가? (언어 모델의 기초 능력 문제)</li>
<li><strong>포맷(Formatting):</strong> 요청된 글자 수 제한이나 JSON 구조를 지켰는가? (지시 이행 능력의 문제)</li>
<li><strong>어조(Tone/Style):</strong> 요청된 페르소나(예: 전문적, 친근함)를 유지했는가? (파인튜닝 또는 프롬프트 스타일링의 문제)</li>
</ol>
<p>만약 복합 오라클을 사용한 테스트가 실패(Fail)했다면, 개발자는 위 다섯 가지 요인 중 무엇이 문제인지 즉시 식별할 수 없다. 모델이 문맥을 이해하지 못한 것인지(사실 관계 오류), 단순히 출력 글자 수를 맞추지 못한 것인지(포맷 오류)를 구분할 수 없게 되면, 모델 개선을 위한 피드백 루프가 끊어진다. 이는 SRP 위반이 초래하는 “변경의 이유가 하나가 아니다“라는 고전적인 소프트웨어 공학의 문제와 직결된다.</p>
<p>더욱이, 이러한 복합 오라클은 테스트의 취약성(Brittleness)을 증가시킨다. 예를 들어, 모델의 성능이 개선되어 요약의 품질(사실 관계)은 좋아졌으나, 사소한 문체 변화로 인해 테스트가 실패할 수 있다. 이는 거짓 양성(False Positive) 실패를 유발하여 개발팀이 테스트 결과를 신뢰하지 않게 만드는 ‘양치기 소년’ 효과를 낳는다.</p>
<h3>1.2 원자적 오라클(Atomic Oracle)의 정의와 수식화</h3>
<p>이러한 문제를 해결하기 위해, AI 테스트 맥락에서 오라클은 원자적 단위로 재정의되어야 한다. **원자적 오라클(Atomic Oracle)**이란 **“단일한 실행(Execution)에 대해 단 하나의 속성(Property)만을 검증하는 결정론적 논리 단위”**로 정의된다.</p>
<p>AI 모델 <span class="math math-inline">M</span>의 출력 <span class="math math-inline">O</span>에 대해, 전체 검증 함수 <span class="math math-inline">V(O)</span>는 단일한 함수가 아니라, 상호 독립적인 개별 원자적 검증 함수 <span class="math math-inline">v_i</span>의 논리적 곱(Conjunction)으로 분해된다.</p>
<p><span class="math math-display">V(O) = \bigwedge_{i=1}^{n} v_i(O)</span></p>
<p>여기서 각 <span class="math math-inline">v_i</span>는 SRP에 따라 설계된 독립적인 검증 로직이다. 각 원자 <span class="math math-inline">v_i</span>는 테스트 실패 시 시스템의 수정해야 할 지점을 명확히 가리키는 지표(Pointer) 역할을 한다.</p>
<ul>
<li><span class="math math-inline">v_{syntax}</span> 실패 <span class="math math-inline">\rightarrow</span> 프롬프트의 출력 포맷 지시문(System Prompt) 수정 필요.</li>
<li><span class="math math-inline">v_{fact}</span> 실패 <span class="math math-inline">\rightarrow</span> RAG 파이프라인의 검색 모듈(Retriever) 또는 참조 문서(Context) 품질 점검 필요.</li>
<li><span class="math math-inline">v_{tone}</span> 실패 <span class="math math-inline">\rightarrow</span> 퓨샷(Few-shot) 예제 수정 또는 스타일 가이드라인 재조정 필요.</li>
</ul>
<p>이러한 접근은 최신 연구인 “Challenges in Testing Large Language Model Based Software” 에서 제시된 분류 체계와 정확히 일치한다. 해당 연구에서는 오라클을 <strong>원자적(Atomic)</strong> 오라클과 <strong>집계적(Aggregated)</strong> 오라클로 구분한다. 원자적 오라클은 개별 테스트 실행의 정확성을 판단하는 가장 기초적인 단위이며, 집계적 오라클은 이러한 원자적 결과들을 여러 번의 실행에 걸쳐 통계적으로 분석하여 모델의 일관성이나 강건성을 평가하는 상위 개념이다. 즉, 원자적 오라클의 확립 없이는 확률적 분포에 대한 평가(집계적 오라클) 자체가 불가능하다.</p>
<p><img src="./3.3.1.0.0%20%EC%9B%90%EC%B9%99%201%20-%20%EC%9B%90%EC%9E%90%EC%84%B1Atomicity%20-%20%EB%8B%A8%EC%9D%BC%20%EC%B1%85%EC%9E%84%20%EC%9B%90%EC%B9%99%EC%9D%98%20%EC%A0%81%EC%9A%A9.assets/image-20260218214232086.png" alt="image-20260218214232086" /></p>
<h2>3.3.1.2 정답지 설계에서의 원자성 계층 (The Hierarchy of Atomicity)</h2>
<p>결정론적 정답지를 설계하기 위해서는 검증 대상을 원자 단위로 쪼개는 계층적 접근이 필요하다. 모든 “정답“이 동일한 수준의 추상화를 가지는 것은 아니다. 원자성은 크게 구문론적(Syntactic), 의미론적(Semantic), 실용적(Pragmatic) 층위로 나뉘며, 이들은 마치 피라미드와 같은 의존 관계를 형성한다. 하위 계층의 원자성이 확보되지 않으면 상위 계층의 검증은 의미를 잃거나 불가능해진다.</p>
<h3>1. 구문론적 원자성 (Syntactic Atomicity): 기계 가독성의 기초</h3>
<p>가장 기초적인 단계이자 가장 엄격한 결정론이 적용되는 영역이다. AI가 생성한 결과물이 약속된 데이터 구조나 형식을 준수하는지를 검증한다. 여기서 “단일 책임“은 “올바른 형식을 갖추었는가?“라는 질문 하나에 집중된다. 내용이 아무리 훌륭해도 시스템이 파싱(Parsing)할 수 없는 형식이면 소프트웨어 관점에서는 명백한 버그다.</p>
<ul>
<li><strong>JSON Schema 검증:</strong> LLM이 도구 호출(Tool Calling)이나 API 연동을 위해 사용될 때, 출력된 JSON의 유효성은 타협할 수 없는 조건이다. 이때 정답지는 특정 값(Value)이 무엇인지를 따지기 전에, 필수 키(Key)가 존재하는지, 데이터 타입이 정수(Integer)인지 문자열(String)인지를 확인한다.
<ul>
<li><em>원자적 검증 예시:</em>
<ul>
<li><code>has_field_id</code>: “id” 필드가 존재하는가? (True/False)</li>
<li><code>type_check_age</code>: “age” 필드의 값이 숫자인가? (True/False)</li>
</ul>
</li>
</ul>
</li>
<li><strong>정규 표현식(Regex) 매칭:</strong> 특정 코드 패턴, 이메일 주소, 날짜 형식(YYYY-MM-DD), 또는 특정 XML 태그의 닫힘 여부 등을 확인한다. 이는 내용의 참/거짓과는 무관하게 기계적인 형식을 검증하는 원자적 행위다.</li>
</ul>
<p>구문론적 원자는 실패 시 모델의 “지능(Intelligence)” 문제가 아니라 “지시 따르기(Instruction Following)” 능력의 결함으로 귀결되므로, 디버깅의 방향을 시스템 프롬프트나 파인튜닝 데이터셋의 형식 일관성으로 명확히 제시한다.</p>
<h3>2. 의미론적 원자성 (Semantic Atomicity): 명제 단위의 검증</h3>
<p>텍스트의 “내용“을 검증하는 단계다. 전통적인 NLP에서는 BLEU나 ROUGE 점수와 같은 n-gram 중복도를 사용했으나, 이는 원자적이지 않다. 단어가 많이 겹친다고 해서 의미가 일치하는 것은 아니며, 반대로 단어가 겹치지 않아도(동의어 사용) 의미가 일치할 수 있기 때문이다. AI 시대의 의미론적 정답지는 <strong>명제(Proposition) 단위의 분해</strong>를 통해 원자성을 확보한다.</p>
<ul>
<li><strong>사실 분해(Fact Decomposition):</strong> 복잡한 문장을 참/거짓을 판별할 수 있는 최소 단위인 ’원자 명제’로 쪼갠다.
<ul>
<li><em>모델 출력:</em> “이순신 장군은 1592년 한산도 대첩에서 거북선을 사용하여 승리했다.”</li>
<li><em>원자적 정답지 분해:</em>
<ol>
<li>인물 검증: 주어가 이순신인가?</li>
<li>시기 검증: 연도가 1592년인가?</li>
<li>사건 검증: 사건명이 한산도 대첩인가?</li>
<li>수단 검증: 거북선이 사용되었는가?</li>
<li>결과 검증: 전투의 결과가 승리인가?</li>
</ol>
</li>
</ul>
</li>
</ul>
<p>이러한 분해를 통해, 모델이 “1592년“을 “1598년“으로 잘못 말했을 때, 전체 문장을 오답 처리하는 것이 아니라 “시기 정보 오류“라는 구체적인 레이블을 붙일 수 있게 된다. 이는 데이터셋 구축 시 “부분 점수“를 부여하거나, 환각(Hallucination)의 유형이 연도 오류인지, 인물 혼동인지를 분석하는 데 결정적인 기여를 한다.</p>
<h3>3. 실용적 원자성 (Pragmatic Atomicity): 안전과 정책 준수</h3>
<p>모델의 출력이 사용자의 의도나 시스템의 안전 정책, 윤리적 가이드라인에 부합하는지를 확인한다. 이는 상위 레벨의 검증이지만, 여전히 원자적으로 정의될 수 있다.</p>
<ul>
<li><strong>거부(Refusal) 원자:</strong> 유해한 질문(예: 폭탄 제조법)에 대해 모델이 명시적으로 거절 의사를 표시했는가?</li>
<li><strong>어조(Tone) 원자:</strong> 답변이 공격적이거나 비속어를 포함하지 않았는가?</li>
<li><strong>프라이버시(Privacy) 원자:</strong> PII(개인식별정보)가 마스킹 처리되었는가?</li>
</ul>
<p>이러한 요소들은 주관적일 수 있으나, “특정 금지어 목록(Blacklist)에 포함된 단어가 없는가?” 또는 “거절 메시지 패턴(Template Match)과 일치하는가?“와 같이 원자적 규칙으로 변환하여 결정론적 정답지로 만들 수 있다.</p>
<p>이 계층 구조는 피라미드 형태를 띤다. 피라미드의 <strong>최하단(기저)에는 구문론적 원자성</strong>이 위치한다. 출력이 기계가 읽을 수 없는 형태라면(예: 깨진 JSON), 그 안의 내용이 사실인지(의미론) 따지는 것은 불가능하다. <strong>중간층에는 의미론적 원자성</strong>이 위치하며, 사실 관계가 틀렸다면 안전성(실용성)을 논하기 이전에 유용성이 결여된 것이다. <strong>최상단에는 실용적 원자성</strong>이 위치하여 최종적인 사용자 경험과 안전을 검증한다. 상위 레벨의 검증은 하위 레벨의 성공을 전제로 수행된다.</p>
<h2>3.3.1.3 JSON Schema와 필드 레벨 원자성 (Field-Level Atomicity)</h2>
<p>AI 개발, 특히 에이전트(Agent) 시스템이나 백엔드 API와 연동되는 시스템 개발에서 가장 빈번하게 발생하는 문제는 구조화된 데이터 생성의 실패다. 여기서 단일 책임 원칙은 **“전체 문자열 비교 대신 필드별 독립 검증”**으로 구체화된다.</p>
<p>전통적인 테스트에서는 예상되는 JSON 문자열 전체가 <code>{"name": "Alice", "age": 30}</code>일 때, 출력값이 <code>{"age": 30, "name": "Alice"}</code>라면(키의 순서만 바뀌어도) 단순 문자열 비교에서는 실패할 수 있다. 이는 원자성을 위배한 검증이다. JSON 객체라는 컨테이너가 아니라, 그 안의 <strong>데이터 필드 하나하나가 검증의 원자 단위</strong>가 되어야 한다.</p>
<h3>결정론적 필드 검증 전략</h3>
<ol>
<li>
<p><strong>스키마 준수(Schema Compliance)의 원자성:</strong> 가장 먼저 검증해야 할 원자는 “이 출력이 약속된 스키마를 따르는가?“이다. 이는 Python의 <code>pydantic</code>이나 <code>jsonschema</code> 라이브러리를 통해 이진 판별(Pass/Fail)이 가능하다. 스키마 검증이 실패하면 값의 정확성을 따지는 것은 무의미하므로, 테스트는 여기서 즉시 중단(Short-circuit)되고 “포맷 오류“라는 명확한 진단을 내린다.</p>
</li>
<li>
<p><strong>값(Value) 검증의 독립성:</strong></p>
<p>스키마를 통과했다면, 각 필드는 독립적인 정답지와 비교되어야 한다. 이때 각 필드의 특성에 따라 서로 다른 원자적 기준을 적용한다.</p>
<ul>
<li><code>price</code> 필드 (수치형): 숫자형이며, 양수인가? (Syntactic) + 실제 상품 가격과 오차 범위(예: <span class="math math-inline">\pm 1\%</span>) 내에서 일치하는가? (Semantic)</li>
<li><code>description</code> 필드 (비정형 텍스트): 필수 키워드가 포함되어 있는가? (Keyword Match) + 금지어를 포함하지 않는가? (Safety Check)</li>
<li><code>category</code> 필드 (열거형): 미리 정의된 Enum 리스트(예: “Electronics”, “Clothing”) 중 하나인가?</li>
</ul>
</li>
</ol>
<p>이처럼 필드별로 다른 검증 로직(정규식, 범위 체크, 임베딩 유사도 등)을 적용하는 것이 SRP를 데이터 검증에 적용하는 핵심이다. 예를 들어, <code>price</code>가 틀렸다고 해서 <code>description</code>까지 오답 처리되어서는 안 된다. 각 필드는 독립된 “실패의 이유“를 가져야 하며, 이는 디버깅 시 “가격 정보 추출 로직“을 수정해야 할지 “설명 생성 로직“을 수정해야 할지를 알려준다.</p>
<h3>코드 기반 오라클 구현 (Code-Based Oracle)</h3>
<p>원자적 검증은 자연어 프롬프트(“이 JSON이 맞는지 확인해줘”)에 의존하기보다, 가능한 한 코드(Code)로 구현된 결정론적 로직에 위임해야 한다. 은 “Constrained Decoding“이나 “JSON Mode“를 통해 모델의 출력을 강제하는 기법을 소개하지만, 오라클은 이를 사후에 다시 한번 엄격하게 검증해야 한다. 다음은 Python을 이용한 원자적 검증 오라클의 개념적 구현이다.</p>
<pre><code class="language-Python"># 원자적 검증의 예시 (Python Pseudo-code)
def validate_response(response_json, ground_truth):
    results = {}
    
    # Atom 1: Schema Validation (Syntactic) - Short-circuit 가능
    if not validate_schema(response_json):
        return {"status": "Fatal Error", "reason": "Schema Violation"}

    # Atom 2: Field-level Exact Match (Deterministic)
    # ID는 정확히 일치해야 하는 결정론적 데이터
    results['id_match'] = (response_json['id'] == ground_truth['id'])
    
    # Atom 3: Field-level Logic Check (Deterministic)
    # 나이는 성인 인증 로직에 따라 18세 이상이어야 함
    results['age_valid'] = (response_json['age'] &gt;= 18)
    
    # Atom 4: Field-level Semantic Similarity (Probabilistic -&gt; Thresholded Determinism)
    # 자기소개 텍스트는 의미적 유사도가 0.85 이상이면 통과로 간주 (Thresholding)
    similarity = calculate_cosine_similarity(response_json['bio'], ground_truth['bio'])
    results['bio_accuracy'] = (similarity &gt; 0.85) 
    
    return results
</code></pre>
<p>위 코드에서 볼 수 있듯이, 원자적 오라클은 하나의 <code>True/False</code>를 반환하는 것이 아니라, 각 원자별 성공/실패 여부가 담긴 **상세한 성적표(Scorecard)**를 반환한다. 이는 “Challenges in Testing LLM Based Software” 논문에서 강조한 “집계적 오라클(Aggregated Oracle)“을 구성하는 기초 데이터가 된다. 이 성적표를 통해 우리는 “ID 추출 정확도 99%, 나이 검증 정확도 100%, 그러나 바이오 생성 정확도 70%“와 같은 세밀한 품질 지표를 얻을 수 있다.</p>
<h2>3.3.1.4 RAG 시스템에서의 정보 인출과 생성의 분리</h2>
<p>RAG(Retrieval-Augmented Generation) 시스템은 “검색(Retrieval)“과 “생성(Generation)“이라는 두 가지 이질적인 책임이 결합된 대표적인 복합 시스템이다. 따라서 RAG를 위한 정답지 설계 시 SRP 적용은 선택이 아닌 필수다. 전체 응답만 보고 “틀렸다“고 판단하면, 검색 엔진이 엉뚱한 문서를 가져온 탓인지(Garbage In), 문서를 잘 가져왔는데도 LLM이 엉뚱한 말을 한 탓인지(Hallucination) 알 수 없다.</p>
<h3>RAG 평가지표의 원자적 분해</h3>
<p>RAG 시스템의 정답지는 다음의 세 가지 원자적 요소로 분리되어야 한다. 이를 학계와 업계에서는 종종 ’RAG Triad’라 부른다.</p>
<ol>
<li><strong>Context Relevance (검색 품질 원자):</strong>
<ul>
<li><strong>책임:</strong> 사용자의 질문에 답변하는 데 필요한 정보를 검색 엔진이 정확히 찾아왔는가?</li>
<li><strong>정답지 유형:</strong> <code>Passage IDs</code> (질문과 관련된 문서 청크의 ID 집합)</li>
<li><strong>검증 질문:</strong> “검색된 상위 k개 청크(Chunk) 안에 정답을 포함한 청크가 있는가?” (Recall@k)</li>
<li>이 원자는 생성 모델(LLM)과는 무관하게 검색기(Retriever)의 성능만을 독립적으로 평가한다.</li>
</ul>
</li>
<li><strong>Groundness / Faithfulness (사실 부합성 원자):</strong>
<ul>
<li><strong>책임:</strong> 생성된 답변이 검색된 정보(Context)에만 기반했는가? 아니면 모델이 자신의 사전 지식이나 환각을 섞었는가?</li>
<li><strong>정답지 유형:</strong> <code>Attribution</code> (문장별 인용 출처 매핑)</li>
<li><strong>검증 질문:</strong> “답변의 각 문장이 검색된 청크의 내용에 의해 지지(Support)되는가?”</li>
<li>이 단계에서는 답변이 ’진실’인지는 중요하지 않다. 오직 ’주어진 문맥에 충실했는가’만을 본다.</li>
</ul>
</li>
<li><strong>Answer Relevance (답변 적절성 원자):</strong>
<ul>
<li><strong>책임:</strong> 답변이 사용자의 질문에 동문서답하지 않고 적절한 응답을 했는가?</li>
<li><strong>정답지 유형:</strong> <code>Golden Q&amp;A Pair</code> (모범 답안)</li>
<li><strong>검증 질문:</strong> “답변이 질문의 의도를 충족하는가?”</li>
<li>여기서 비로소 최종적인 유용성을 평가한다.</li>
</ul>
</li>
</ol>
<p>이러한 분리 없이 “답변이 정확한가?“만 묻는 것은 SRP를 위반하는 것이다. 예를 들어, 검색된 문서에 정답이 없는데(Retrieval 실패) 모델이 환각으로 우연히 정답을 맞혔다면(Generation의 우연한 성공), 통합 테스트(End-to-End)에서는 “성공“으로 기록된다. 이는 심각한 “거짓 양성(False Positive)“을 초래하며 시스템의 신뢰도를 저하시킨다. 원자적 오라클은 검색 단계에서 실패를 감지하여 이를 “검색 실패“로 명확히 기록함으로써, 개발자가 임베딩 모델을 튜닝해야 한다는 명확한 신호를 준다.</p>
<p><img src="./3.3.1.0.0%20%EC%9B%90%EC%B9%99%201%20-%20%EC%9B%90%EC%9E%90%EC%84%B1Atomicity%20-%20%EB%8B%A8%EC%9D%BC%20%EC%B1%85%EC%9E%84%20%EC%9B%90%EC%B9%99%EC%9D%98%20%EC%A0%81%EC%9A%A9.assets/image-20260218214406442.png" alt="image-20260218214406442" /></p>
<h2>3.3.1.5 결정론적 정답지의 함정: 과도한 결합(Tight Coupling) 피하기</h2>
<p>SRP를 적용한다고 해서 테스트 코드를 무작정 잘게 쪼개는 것만이 능사는 아니다. “단일 책임“의 오해 중 하나는 “함수는 무조건 한 줄이어야 한다“는 식의 극단적 미시화다. 정답지 설계에서 경계해야 할 것은 논리적 원자성이 아닌 물리적 분해다.</p>
<h3>유의미한 원자(Meaningful Atom) vs. 파편화(Fragmentation)</h3>
<p>“의미 있는 단위“로 쪼개야 한다. 예를 들어, 문장을 단어 단위로 쪼개어 각 단어의 존재 여부를 검사하는 것은 지나친 파편화다. 이는 문맥을 파괴한다. 대신 앞서 언급했듯이 **“명제(Proposition)”**가 원자의 최소 단위가 되어야 한다.</p>
<p>또한, 정답지 데이터셋(Golden Dataset) 자체가 SRP를 위반하는 경우도 있다. 하나의 테스트 케이스(Row)에 여러 의도가 섞여 있는 경우다.</p>
<ul>
<li><strong>나쁜 예 (복합 질문):</strong> “한국의 수도는 어디이며, 인구는 얼마이고, 주요 관광지 3곳을 나열하라.”
<ul>
<li>이 질문은 3가지 서로 다른 팩트를 요구한다. 모델이 수도는 맞혔으나 인구를 틀렸다면, 이 케이스는 Pass인가 Fail인가? 이를 판단하기 위해 복잡한 채점 로직이 필요해진다.</li>
</ul>
</li>
<li><strong>좋은 예 (원자적 질문):</strong>
<ol>
<li>Test Case A: “한국의 수도는 어디인가?” (Target: “서울”)</li>
<li>Test Case B: “서울의 인구는 얼마인가?” (Target: “~940만 명”)</li>
<li>Test Case C: “서울의 주요 관광지 3곳은?” (Target: 리스트 포함 여부)</li>
</ol>
</li>
</ul>
<p>이렇게 데이터셋 레벨에서부터 질문을 원자화(Atomization)하면, 각 질문에 대한 정답지(Ground Truth) 역시 명확하고 단순해진다. Choco와 같은 기업의 사례에서도 알 수 있듯이, 복잡한 주문 처리 워크플로우를 “음성 텍스트 변환”, “정보 수정”, “정보 추출“이라는 독립적인 태스크로 쪼개고 각각을 별도의 모델과 오라클로 검증했을 때 시스템의 확장성과 디버깅 용이성이 비약적으로 상승했다. “ProntoQA“와 같은 데이터셋은 이러한 논리적 원자성을 극대화하여, 추론의 각 단계(Hop)를 개별적으로 검증할 수 있도록 설계되었다. 이는 복잡한 추론 체인(Chain-of-Thought)을 검증할 때, 모델이 어디서 논리적 비약을 저질렀는지 정확히 찾아낼 수 있게 해준다.</p>
<h2>3.3.1.6 결론: 신뢰할 수 있는 오라클을 향하여</h2>
<p>원자성(Atomicity)은 AI 소프트웨어의 모호성을 걷어내고 신뢰성을 확보하기 위한 첫 번째 단추다. 단일 책임 원칙을 오라클 설계에 적용함으로써, 우리는 “AI가 틀렸다“라는 막연한 불안감을 “모델이 구문론적 규칙은 준수했으나, 특정 사실 관계(Entity X)에 대한 지식이 부족하다“라는 엔지니어링 차원의 문제로 환원시킬 수 있다.</p>
<p>이러한 원자적 접근은 초기에는 정답지 구축 비용을 증가시키는 것처럼 보일 수 있다. 단순한 텍스트 덩어리 대신 구조화된 스키마, 명제 리스트, 검증 로직을 작성해야 하기 때문이다. 그러나 장기적으로 볼 때, 이는 기술 부채를 획기적으로 줄여준다. 테스트의 유지보수성이 높아지고, 모델의 성능 저하(Regression) 원인을 즉각적으로 파악할 수 있으며, 자동화된 파이프라인(CI/CD) 내에서 신뢰할 수 있는 게이트키퍼(Gatekeeper) 역할을 수행할 수 있게 된다.</p>
<p>결국 결정론적 정답지는 우연에 기대지 않는다. 그것은 철저하게 설계된 원자적 책임들의 집합이며, 이것이 바로 AI를 ’마법’이 아닌 ’공학’의 영역으로 끌어오는 핵심 열쇠다.</p>
<h4><strong>참고 자료</strong></h4>
<ol>
<li>Single Responsibility Principle Matters for Secure Code - Xygeni, 2월 18, 2026에 액세스, https://xygeni.io/blog/why-the-single-responsibility-principle-matters-for-secure-code/</li>
<li>The Single Responsibility Principle: A Cornerstone of Clean Code, 2월 18, 2026에 액세스, https://medium.com/@jakemer10/the-single-responsibility-principle-a-cornerstone-of-clean-code-eb6ada66c1c2</li>
<li>Single-responsibility principle - Wikipedia, 2월 18, 2026에 액세스, https://en.wikipedia.org/wiki/Single-responsibility_principle</li>
<li>Challenges in Testing Large Language Model Based Software, 2월 18, 2026에 액세스, https://arxiv.org/html/2503.00481v2</li>
<li>arXiv:2503.00481v1 [cs.SE] 1 Mar 2025, 2월 18, 2026에 액세스, https://arxiv.org/pdf/2503.00481</li>
<li>The Single Responsibility Principle, Demystified - Level Up Coding, 2월 18, 2026에 액세스, https://levelup.gitconnected.com/the-single-responsibility-principle-demystified-e437a2454625</li>
<li>(PDF) Challenges in Testing Large Language Model Based Software, 2월 18, 2026에 액세스, https://www.researchgate.net/publication/389547844_Challenges_in_Testing_Large_Language_Model_Based_Software_A_Faceted_Taxonomy</li>
<li>LLM Evaluation: Key Concepts &amp; Best Practices - Nexla, 2월 18, 2026에 액세스, https://nexla.com/ai-readiness/llm-evaluation/</li>
<li>Taming LLM Outputs: Your Guide to Structured Text Generation, 2월 18, 2026에 액세스, https://www.dataiku.com/stories/blog/your-guide-to-structured-text-generation</li>
<li>LLM evaluation metrics and methods - Evidently AI, 2월 18, 2026에 액세스, https://www.evidentlyai.com/llm-guide/llm-evaluation-metrics</li>
<li>SLOT: Structuring the Output of Large Language Models - arXiv, 2월 18, 2026에 액세스, https://arxiv.org/html/2505.04016v1</li>
<li>Structured Output Generation in LLMs: JSON Schema and Grammar, 2월 18, 2026에 액세스, https://medium.com/@emrekaratas-ai/structured-output-generation-in-llms-json-schema-and-grammar-based-decoding-6a5c58b698a6</li>
<li>Mastering Structured Output in LLMs 1: JSON output with LangChain, 2월 18, 2026에 액세스, https://medium.com/@docherty/mastering-structured-output-in-llms-choosing-the-right-model-for-json-output-with-langchain-be29fb6f6675</li>
<li>Evaluating RAG Pipelines - Neptune.ai, 2월 18, 2026에 액세스, https://neptune.ai/blog/evaluating-rag-pipelines</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>