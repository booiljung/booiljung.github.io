<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:3.3.1.1 복합 질문의 분해와 개별 검증 가능한 단위 설정</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>3.3.1.1 복합 질문의 분해와 개별 검증 가능한 단위 설정</h1>
                    <nav class="breadcrumbs"><a href="../../../../../index.html">Home</a> / <a href="../../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../../index.html">Chapter 3. 결정론적 정답지(Deterministic Ground Truth)의 설계 원칙과 필요성</a> / <a href="../index.html">3.3 결정론적 정답지 설계의 핵심 원칙 (Design Principles)</a> / <a href="index.html">3.3.1 원칙 1: 원자성(Atomicity) - 단일 책임 원칙의 적용</a> / <span>3.3.1.1 복합 질문의 분해와 개별 검증 가능한 단위 설정</span></nav>
                </div>
            </header>
            <article>
                <h1>3.3.1.1 복합 질문의 분해와 개별 검증 가능한 단위 설정</h1>
<p>AI 소프트웨어, 특히 거대 언어 모델(Large Language Models, LLM)을 기반으로 한 시스템의 신뢰성을 확보하는 데 있어 가장 치명적인 장애물은 본질적인 ’비결정성(Nondeterminism)’과 그로부터 파생되는 ’모호성(Ambiguity)’이다. 전통적인 결정론적(Deterministic) 소프트웨어 엔지니어링에서는 단위 테스트(Unit Test)가 강력한 효력을 발휘했다. 이는 입력(Input)에 대한 기대 출력(Expected Output)이 수학적으로나 논리적으로 명확하게 고정되어 있었기 때문이다. 예를 들어, <span class="math math-inline">2+2</span>는 우주의 어느 곳에서 연산하든 항상 <span class="math math-inline">4</span>여야 하며, 데이터베이스에 저장된 ’홍길동’이라는 사용자 이름은 쿼리 시 정확히 그 바이트 열(Byte Sequence)로 반환되어야 한다. 이러한 환경에서 오라클(Oracle)은 단순한 등가 비교 연산자(<span class="math math-inline">==</span>)만으로도 충분했다.</p>
<p>그러나 생성형 AI의 시대에 접어들며 이러한 결정론적 가정은 붕괴되었다. “이 문서를 요약하라“거나 “사용자의 의도를 파악하여 적절한 상품을 추천하라“는 과업은 단일한 정답을 정의하기 어렵다. 동일한 프롬프트를 입력하더라도 모델은 확률적 샘플링(Sampling), 부동소수점 연산의 미세한 차이, 병렬 처리 과정에서의 경합 조건(Race Condition) 등으로 인해 매번 미묘하게 다른 텍스트를 생성한다. 이러한 비결정적 출력은 전통적인 정확도 일치(Exact Match) 테스트를 무력화시키며, AI 시스템의 품질 보증(QA)을 불가능에 가까운 영역으로 밀어넣는다.</p>
<p>이 난제를 해결하고 AI 시스템에 대해 ’결정론적 정답지(Deterministic Ground Truth)’를 구축하기 위한 첫 번째이자 가장 핵심적인 방법론은 **복합 질문의 분해(Decomposition of Complex Questions)**와 이를 통한 **개별 검증 가능한 단위(Individually Verifiable Units)**의 설정이다. 이것은 객체 지향 설계의 **단일 책임 원칙(Single Responsibility Principle, SRP)**을 프롬프트 엔지니어링과 테스트 오라클 설계에 적용하는 것으로, 거대하고 모호한 AI의 출력을 명확히 ‘참(True)’ 혹은 ’거짓(False)’으로 판별할 수 있는 원자적(Atomic) 단위로 쪼개는 과정을 의미한다. 본 절에서는 복합적인 비즈니스 요구사항과 사용자 질문을 AI가 이해하고 검증할 수 있는 최소 단위인 ’원자적 사실(Atomic Fact)’과 ’단위 질의(Sub-query)’로 변환하는 방법론을 심도 있게 기술한다.</p>
<p><img src="./3.3.1.1.0%20%EB%B3%B5%ED%95%A9%20%EC%A7%88%EB%AC%B8%EC%9D%98%20%EB%B6%84%ED%95%B4%EC%99%80%20%EA%B0%9C%EB%B3%84%20%EA%B2%80%EC%A6%9D%20%EA%B0%80%EB%8A%A5%ED%95%9C%20%EB%8B%A8%EC%9C%84%20%EC%84%A4%EC%A0%95.assets/image-20260218214718948.jpg" alt="image-20260218214718948" /></p>
<h3>0.1  비결정성의 해체: 왜 분해인가?</h3>
<p>거대 언어 모델(LLM)은 근본적으로 다음에 올 토큰(Token)을 확률적으로 예측하는 생성기이다. 아무리 <code>Temperature</code> 파라미터를 0으로 설정하여 결정론적 결과를 유도하려 해도, GPU 하드웨어 수준에서의 비결정성—병렬 연산 중 부동소수점 덧셈 순서의 차이(Atomic Adds) 등—으로 인해 완벽한 재현성은 보장되지 않는다. 더욱이, 모델의 ’창의성’을 위해 샘플링 기법을 사용할 경우, 같은 질문에 대해 매번 다른 어휘와 문장 구조를 가진 답변이 생성된다.</p>
<p>이러한 다양성은 챗봇과 같은 응용 분야에서는 장점이 될 수 있으나, 신뢰성이 필수적인 엔터프라이즈 환경이나 자동화된 테스트 환경에서는 치명적인 결함이 된다. 예를 들어, “2023년 마이크로소프트와 구글 중 누가 더 많은 수익을 냈는가?“라는 질문에 대해 AI는 다음과 같이 다양하게 답변할 수 있다.</p>
<ol>
<li>“구글이 더 많은 수익을 냈습니다.”</li>
<li>“2023년 알파벳(구글)의 매출은 3,074억 달러로 마이크로소프트의 2,119억 달러보다 높았습니다.”</li>
<li>“마이크로소프트가 구글보다 수익이 적었습니다.”</li>
<li>“수익(Revenue) 측면에서는 구글이 앞섰으나, 순이익(Net Income)은 다를 수 있습니다.”</li>
</ol>
<p>이 문장들은 텍스트 수준에서는 완전히 다르지만, 의미론적(Semantic)으로는 겹치거나 동일한 정보를 담고 있을 수 있다. 이를 검증하기 위해 오라클을 설계할 때, 문장 전체를 하나의 단위로 보고 검증하려 하면, 검증 로직 자체가 고도의 자연어 이해(NLU) 능력을 필요로 하게 된다. 즉, “AI의 출력을 검증하기 위해 또 다른 AI(LLM-as-a-Judge)를 사용해야 하는” 순환 논리에 빠지게 되며, 이는 검증 시스템의 신뢰성을 모델 자체의 신뢰성 수준으로 하락시키는 결과를 초래한다.</p>
<p>**분해(Decomposition)**는 이러한 딜레마를 해결하는 유일한 구조적 접근법이다. 복합적인 질문을 더 이상 쪼갤 수 없는 최소 단위의 명제(Proposition)나 데이터 조회 요청으로 나누면, 각 단위는 명확한 참/거짓 판별이 가능한 이진적 상태(Binary State)에 근접하게 된다. 복잡한 전체는 검증 불가능할지라도, 그것을 구성하는 부분들은 검증 가능하다는 것이 이 접근법의 핵심이다. 이는 복잡한 시스템을 모듈화하여 관리하는 소프트웨어 엔지니어링의 기본 원칙과도 일맥상통한다.</p>
<h3>0.2  원자성(Atomicity)의 정의와 철학적 배경</h3>
<p>AI 테스트 오라클 설계에서 말하는 ’원자성’은 단순히 문장을 짧게 끊어 쓰는 것을 의미하지 않는다. 이는 정보의 의미론적 최소 단위를 정의하는 작업으로, 버트런드 러셀(Bertrand Russell)의 **논리적 원자론(Logical Atomism)**과 신데이비드슨(Neo-Davidsonian) 의미론에 그 이론적 뿌리를 둔다.</p>
<p>러셀에 따르면, 세계는 더 이상 쪼갤 수 없는 ’원자적 사실(Atomic Facts)’들로 구성되어 있으며, 우리가 사용하는 모든 복합적인 명제나 언어는 이 원자적 사실들의 논리적 결합으로 환원될 수 있다. AI 검증의 맥락에서 이를 해석하면, AI의 출력 텍스트 <span class="math math-inline">T</span>는 일련의 원자적 사실 집합 <span class="math math-inline">A = {a_1, a_2,..., a_n}</span>으로 분해될 수 있다. 이때 전체 텍스트 <span class="math math-inline">T</span>의 정확성(Truthfulness)은 텍스트의 유창성이나 스타일이 아니라, 구성 요소인 개별 원자 <span class="math math-inline">a_i</span>가 정답지(Ground Truth) <span class="math math-inline">G</span>와 논리적으로 일치하는지의 여부(Entailment)로 결정된다.</p>
<p>원자적 단위가 되기 위해서는 다음의 세 가지 핵심 조건을 만족해야 한다.</p>
<ol>
<li><strong>최소성(Minimality)</strong>: 더 이상 분해할 경우 정보의 본질이 훼손되거나 의미를 상실하는 최소 단위여야 한다. 예를 들어, “이순신은 조선의 장군이다“라는 명제는 원자적이다. 이를 억지로 “이순신은 조선이다“와 “이순신은 장군이다“로 분리하면 원래의 의미(조선의 장군)를 온전히 보존하지 못하거나 왜곡할 수 있다. 최소성은 검증의 단위를 가장 작게 유지하여 오류의 원인을 정밀하게 타격(Pinpoint)할 수 있게 한다.</li>
<li><strong>독립성(Independence) 및 탈문맥화(Decontextualization)</strong>: 각 원자적 사실은 문맥(Context) 없이 그 자체만으로 참/거짓을 판별할 수 있어야 한다. 복합 문장에서 분리된 원자적 사실은 대명사나 지시어(“그”, “그녀”, “그것”, “전년 동기”)를 포함해서는 안 되며, 이를 구체적인 개체명(Entity Name)이나 절대적인 시점 값으로 치환해야 한다. 예를 들어, “그는 1443년에 훈민정음을 창제했다“는 “세종대왕은 1443년에 훈민정음을 창제했다“로 변환되어야 독립적인 검증이 가능하다.</li>
<li><strong>이진 검증 가능성(Binary Verifiability)</strong>: 모호한 해석의 여지 없이 True 혹은 False로 명확히 판정될 수 있어야 한다. “이순신은 훌륭한 장군이다“라는 명제는 ’훌륭한’이라는 주관적 형용사로 인해 이진 검증이 어렵다. 이를 결정론적 오라클로 검증하기 위해서는 “이순신은 임진왜란에서 23전 23승을 거두었다“와 같이 객관적 사실(Fact)이나 데이터로 환원 가능한 형태로 변환해야 한다.</li>
</ol>
<p>이러한 원자적 분해는 확률적인 AI의 출력을 결정론적인 데이터 포인트들의 집합으로 변환함으로써, 기존의 데이터베이스 검증 기술이나 로직 검증 기술을 AI 평가에 재사용할 수 있는 길을 열어준다.</p>
<h3>0.3  입력의 분해: 복합 쿼리 분해 (Query Decomposition) 전략</h3>
<p>결정론적 정답지를 만들기 위해서는 먼저 입력(Input) 단계에서부터 결정론적 검증이 가능한 형태로 과업이 정의되어야 한다. 사용자의 질문이 복합적이거나 다의적일 경우, AI는 내부적으로 이를 해석하는 과정에서 모호성을 겪게 되며, 이는 출력의 비결정성을 증폭시킨다. 따라서 **단일 책임 원칙(SRP)**에 따라 복합 질문을 여러 개의 하위 질문(Sub-questions)으로 분해하는 전략이 필수적이다. 이는 RAG(Retrieval-Augmented Generation) 시스템의 검색 정확도를 높이는 기법으로 널리 알려져 있으나, 본질적으로는 테스트 오라클을 구축하기 위한 전제 조건이다.</p>
<h4>0.3.1  명시적 분해 (Explicit Decomposition)와 병렬 처리</h4>
<p>가장 직관적이고 기초적인 방법은 복문(Complex Sentence)이나 다중 의도를 가진 질문을 독립적인 단문(Simple Sentence)들로 분리하는 것이다. 이 방식은 각 하위 질문들이 서로에게 영향을 주지 않는 <strong>병렬적(Parallel)</strong> 구조를 가질 때 유효하다.</p>
<ul>
<li><strong>사용자 입력 예시</strong>: “테슬라와 GM의 전기차 제조 방식의 차이점과 각 회사의 주요 공장 위치를 알려줘.”</li>
<li><strong>분해된 단위 (Sub-queries)</strong> :</li>
</ul>
<ol>
<li><span class="math math-inline">q_1</span>: “테슬라의 전기차 제조 방식은 무엇인가?”</li>
<li><span class="math math-inline">q_2</span>: “GM의 전기차 제조 방식은 무엇인가?”</li>
<li><span class="math math-inline">q_3</span>: “테슬라의 주요 제조 공장은 어디에 위치하는가?”</li>
<li><span class="math math-inline">q_4</span>: “GM의 주요 제조 공장은 어디에 위치하는가?”</li>
</ol>
<p>이렇게 분해된 <span class="math math-inline">q_1, q_2, q_3, q_4</span>는 각각 독립적인 검증 오라클을 가질 수 있다. 오라클은 “두 회사의 차이점을 잘 설명했는가?“라는 주관적이고 포괄적인 평가 대신, “테슬라의 기가 프레스(Giga Press) 방식이 언급되었는가?”, “GM의 얼티엄(Ultium) 플랫폼이 기술되었는가?”, “텍사스와 미시간이라는 지명이 포함되었는가?“와 같이 구체적이고 확인 가능한 사실 관계를 검증하는 데 집중할 수 있다. 이는 Multi-hop QA 검증 프레임워크에서 널리 사용되는 방식으로, 복잡한 문제를 단순한 정보 검색(IR) 문제들의 집합으로 환원시킨다.</p>
<h4>0.3.2  의존적 분해 (Dependency-based Decomposition)와 연쇄 처리</h4>
<p>어떤 질문은 논리적 순서가 존재하여, 앞선 질문의 답이 도출되어야만 다음 질문의 검증이 가능한 경우가 있다. 이를 <strong>연쇄적 분해(Chain Decomposition)</strong> 또는 계층적 분해(Hierarchical Decomposition)라고 한다.</p>
<ul>
<li><strong>사용자 입력 예시</strong>: “제미나이를 개발한 회사의 현재 CEO는 누구이며, 그가 취임한 연도는 언제인가?”</li>
<li><strong>분해된 단위</strong>:</li>
</ul>
<ol>
<li><span class="math math-inline">q_1</span>: “제미나이를 개발한 회사는 어디인가?” <span class="math math-inline">\rightarrow</span> 추출된 정답: <span class="math math-inline">A_1</span> (Google 또는 DeepMind)</li>
<li><span class="math math-inline">q_2</span>: “<span class="math math-inline">A_1</span>의 현재 CEO는 누구인가?” <span class="math math-inline">\rightarrow</span> 추출된 정답: <span class="math math-inline">A_2</span> (Sundar Pichai)</li>
<li><span class="math math-inline">q_3</span>: “<span class="math math-inline">A_2</span>가 <span class="math math-inline">A_1</span>의 CEO로 취임한 연도는 언제인가?” <span class="math math-inline">\rightarrow</span> 추출된 정답: <span class="math math-inline">A_3</span> (2015년)</li>
</ol>
<p>이 경우 테스트 오라클은 정적(Static)일 수 없다. 오라클은 <span class="math math-inline">q_1</span>의 수행 결과를 모니터링하고, 그 결과값(<span class="math math-inline">A_1</span>)을 동적으로 <span class="math math-inline">q_2</span>의 검증 조건에 반영하는 <strong>동적 오라클(Dynamic Oracle)</strong> 형태로 구성되어야 한다. 만약 AI가 <span class="math math-inline">q_1</span>에서 “OpenAI“라고 잘못 답변했다면, 이후의 <span class="math math-inline">q_2, q_3</span>에 대한 검증은 의미가 없어지거나 실패로 간주되어야 한다. 이러한 의존성 관리는 테스트 케이스의 원자성을 보장하면서도 복잡한 추론 과정을 검증할 수 있게 해준다.</p>
<p><img src="./3.3.1.1.0%20%EB%B3%B5%ED%95%A9%20%EC%A7%88%EB%AC%B8%EC%9D%98%20%EB%B6%84%ED%95%B4%EC%99%80%20%EA%B0%9C%EB%B3%84%20%EA%B2%80%EC%A6%9D%20%EA%B0%80%EB%8A%A5%ED%95%9C%20%EB%8B%A8%EC%9C%84%20%EC%84%A4%EC%A0%95.assets/image-20260218214740669.jpg" alt="image-20260218214740669" /></p>
<h4>0.3.3  분해를 위한 프롬프트 전략: Least-to-Most</h4>
<p>이러한 분해를 자동화하기 위해 ’Least-to-Most Prompting’과 같은 기법이 활용된다. 이는 복잡한 문제를 가장 간단한 하위 문제부터 순차적으로 해결하도록 AI를 유도하는 방식이다. 검증 관점에서는 이 과정 자체가 거대한 ’Chain of Verification’이 된다. 각 단계의 중간 산출물(Intermediate Output)을 캡처하여 검증함으로써, 최종 답변뿐만 아니라 ’추론 과정(Reasoning Process)’의 정합성까지 평가할 수 있다. 이는 단순한 결과 중심(Outcome-based) 평가를 넘어 과정 중심(Process-based) 평가로의 진화를 가능하게 한다.</p>
<h3>0.4  출력의 분해: 원자적 사실 추출 (Atomic Fact Extraction)과 FActScore</h3>
<p>입력의 분해가 ’무엇을 검증할 것인가’를 정의하는 과정이라면, 출력의 분해는 AI가 생성한 답변을 ’어떻게 검증할 것인가’를 구체화하는 단계이다. 텍스트 생성 모델의 환각(Hallucination)을 탐지하고 사실적 정확도(Factual Precision)를 정량적으로 측정하기 위해, 학계와 산업계에서 사실상의 표준으로 자리 잡고 있는 방법론은 <strong>FActScore (Factual Precision in Atomicity Score)</strong> 모델이다.</p>
<h4>0.4.1 FActScore 방법론의 핵심 메커니즘</h4>
<p>FActScore는 긴 생성 텍스트(Long-form Text)를 검증하는 난해한 문제를 일련의 단순한 이진 분류 문제(Binary Classification Problems)들로 변환하는 알고리즘이다.</p>
<ol>
<li><strong>원자적 사실 생성 (Atomic Fact Generation)</strong>:</li>
</ol>
<p>모델이 생성한 문장 <span class="math math-inline">S</span>를 원자적 사실들의 집합 <span class="math math-inline">A_S = {f_1, f_2,..., f_n}</span>으로 분해한다.</p>
<ul>
<li><em>생성 문장</em>: “세종대왕은 1443년에 훈민정음을 창제했고, 조선의 4대 왕이다.”</li>
<li>이 문장은 두 개의 원자적 사실로 분해된다:</li>
</ul>
<ol>
<li><span class="math math-inline">f_1</span>: “세종대왕은 1443년에 훈민정음을 창제했다.”</li>
<li><span class="math math-inline">f_2</span>: “세종대왕은 조선의 4대 왕이다.”</li>
</ol>
<p>이때 중요한 것은 각 사실이 **독립적(Self-contained)**이어야 한다는 점이다. 만약 문장이 “그는 1443년에…“로 시작했다면, 분해 과정에서 대명사 “그“는 “세종대왕“이라는 고유명사로 명시적으로 치환(Coreference Resolution)되어야 한다. 이를 통해 <span class="math math-inline">f_1</span>과 <span class="math math-inline">f_2</span>는 서로 의존하지 않고 독립적으로 검증될 수 있는 상태가 된다.</p>
<ol start="2">
<li><strong>개별 검증 (Individual Verification)</strong>:</li>
</ol>
<p>각 원자적 사실 <span class="math math-inline">f_i</span>에 대해 신뢰할 수 있는 지식 소스(Knowledge Source, 예: 위키피디아, 기업 내부 DB, 신뢰된 문서)를 기반으로 <span class="math math-inline">Supported</span> 또는 <span class="math math-inline">Not Supported</span>를 판별한다. 이 단계는 인간 평가자가 수행할 수도 있고, 검색 기반의 검증 에이전트(Retrieval-based Verification Agent)가 수행할 수도 있다.</p>
<p><span class="math math-display">f_i \in \{ \text{Supported}, \text{Not Supported} \}</span></p>
<ol start="3">
<li>
<p><strong>점수 산출 (Score Computation)</strong>:</p>
<p>전체 생성 텍스트의 신뢰도 점수는 검증된 원자적 사실의 비율로 결정된다.</p>
</li>
</ol>
<p><span class="math math-display">\text{FActScore} = \frac{1}{|A_S|} \sum_{f \in A_S} \mathbb{I}(f \text{ is Supported})</span></p>
<p>이 방식은 모호했던 AI의 출력을 ’그럴듯함’이나 ’유창성’이라는 주관적 지표가 아니라, ’팩트의 정확도’라는 정량적 지표로 치환해준다. 예를 들어, AI가 5개의 사실을 언급했는데 그중 3개만 정확하다면 정확도는 60%이다. 이는 결정론적 정답지가 없는 생성형 AI 작업에서 **부분 점수(Partial Credit)**를 부여하고, 모델의 성능 변화를 추적하는 **회귀 테스트(Regression Test)**를 가능하게 만드는 거의 유일한 방법론이다.</p>
<h4>0.4.2 명제 논리(Propositional Logic) 기반 분해와 정형 검증</h4>
<p>더 높은 수준의 엄밀함이 요구되는 분야, 예를 들어 법률(Legal)이나 의료(Medical) AI의 경우, 자연어 형태의 원자적 사실조차 여전히 모호할 수 있다. 이 경우 자연어 문장을 명제 논리 형태의 튜플(Tuple)이나 트리플(Triple)로 변환하여 검증한다.</p>
<ul>
<li><em>생성 문장</em>: “환자는 아스피린 알레르기가 있어 타이레놀을 처방했다.”</li>
<li><em>논리적 원자 분해</em>:</li>
</ul>
<ol>
<li><code>HasAllergy(Patient_ID, 'Aspirin')</code></li>
<li><code>Prescribed(Doctor_ID, 'Tylenol')</code></li>
<li><code>ContraindicationCheck('Aspirin', 'Tylenol')</code> (잠재적 검증 로직)</li>
<li><code>CausalRelation(Fact1, Fact2)</code> (인과관계: 알레르기 때문에 처방 변경)</li>
</ol>
<p>이러한 구조적 분해(Structured Decomposition)는 텍스트를 데이터베이스의 관계형 데이터나 지식 그래프(Knowledge Graph)의 엣지(Edge)와 직접적으로 매핑할 수 있게 해준다. 이를 통해 SQL 쿼리나 그래프 쿼리(SPARQL 등)를 통해 AI의 출력을 자동적이고 결정론적으로 검증하는 것이 가능해진다. 이는 자연어 처리(NLP) 문제를 데이터베이스 검증 문제로 치환하는 강력한 기법이다.</p>
<h3>0.5  단일 책임 원칙(SRP)의 적용과 격리된 오라클</h3>
<p>소프트웨어 설계의 **단일 책임 원칙(SRP)**은 “클래스는 변경해야 할 이유가 단 하나여야 한다“는 원칙이다. 이를 AI 검증 오라클에 적용하면, “하나의 오라클(또는 검증 프롬프트)은 오직 하나의 원자적 사실이나 하나의 논리적 측면만을 검증해야 한다“는 원칙이 된다.</p>
<h4>0.5.1 복합 검증 오라클의 위험성 (Anti-Pattern)</h4>
<p>흔히 범하는 실수는 하나의 검증용 프롬프트(LLM-as-a-Judge)에게 너무 많은 것을 요구하는 것이다. 예를 들어, “이 코드가 효율적이고, 버그가 없으며, PEP8 스타일을 준수하고, 보안 취약점이 없는지 확인하라“는 프롬프트는 실패할 확률이 매우 높다. LLM은 주의력(Attention) 자원이 한정되어 있어, 여러 기준을 동시에 평가할 때 일부 기준을 간과하거나 기준 간의 충돌로 인해 환각을 일으킬 수 있다. 이는 오라클의 신뢰도를 떨어뜨리는 주된 원인이다.</p>
<h4>0.5.2 SRP를 적용한 오라클 체인 (Oracle Chaining)</h4>
<p>따라서 검증 과정은 다단계의 독립된 오라클 체인으로 구성되어야 한다. 각 오라클은 자신의 책임 범위 내에서만 판정을 내린다.</p>
<ol>
<li><strong>구문 오라클 (Syntax Oracle)</strong>: 출력이 유효한 JSON 포맷인가? 스키마를 준수하는가? (Yes/No) - <em>책임: 형식(Format)</em></li>
<li><strong>사실 오라클 (Fact Oracle)</strong>: 언급된 날짜가 2024년 1월 1일 이후인가? (Yes/No) - <em>책임: 데이터 정합성(Data Integrity)</em></li>
<li><strong>정책 오라클 (Policy Oracle)</strong>: 비속어나 금지된 표현이 포함되지 않았는가? (Yes/No) - <em>책임: 안전성(Safety)</em></li>
<li><strong>논리 오라클 (Logic Oracle)</strong>: 결론이 전제로부터 타당하게 도출되었는가? (Yes/No) - <em>책임: 추론(Reasoning)</em></li>
</ol>
<p>이렇게 검증 단위를 분리하면, AI가 실패했을 때 “형식은 맞았으나 사실 관계가 틀렸다“거나, “사실은 맞으나 안전 정책을 위반했다“는 식으로 오류의 원인을 명확히 파악할 수 있다. 이는 디버깅과 모델 개선을 위한 피드백 루프를 훨씬 더 빠르고 정확하게 만든다. 에이전트(Agent) 시스템 평가에서도 마찬가지로, 전체 워크플로우의 성공 여부만 보는 것이 아니라 각 단계(Step)별로 원자적 목표(Atomic Goal)를 달성했는지 추적해야 한다.</p>
<h3>0.6  표: 검증 단위 분해 기법 비교</h3>
<p>다음 표는 앞서 논의한 다양한 분해 기법들을 대상과 단위, 그리고 검증 방식에 따라 체계적으로 정리한 것이다.</p>
<table><thead><tr><th><strong>분해 기법 (Decomposition Technique)</strong></th><th><strong>대상 (Target)</strong></th><th><strong>단위 (Unit)</strong></th><th><strong>검증 오라클 유형</strong></th><th><strong>적용 사례</strong></th></tr></thead><tbody>
<tr><td><strong>쿼리 분해 (Query Decomposition)</strong></td><td>사용자 입력 (Input)</td><td>하위 질문 (Sub-query)</td><td>정보 검색(IR) 정확도, 답변 일관성</td><td>RAG 시스템, 복합 질의 응답, 검색 엔진 최적화</td></tr>
<tr><td><strong>원자적 사실 추출 (Atomic Fact Extraction)</strong></td><td>모델 출력 (Output)</td><td>명제/사실 (Proposition)</td><td>지식 베이스 대조 (KB Lookup), NLI 모델</td><td>텍스트 요약, 환각 탐지, 뉴스 기사 생성, FActScore</td></tr>
<tr><td><strong>명제 논리 분해 (Propositional Logic)</strong></td><td>모델 출력 (Output)</td><td>논리 튜플 (Predicate Tuple)</td><td>SQL/Graph Query, 정형 데이터 검증</td><td>의료 진단 보조, 법률 계약서 검토, 규정 준수 확인</td></tr>
<tr><td><strong>단일 책임 프롬프트 (SRP Prompting)</strong></td><td>평가 프로세스 (Process)</td><td>평가 기준 (Criteria)</td><td>이진 분류기 (Pass/Fail)</td><td>코드 리뷰, 스타일 가이드 준수 여부, 보안 감사</td></tr>
</tbody></table>
<h3>0.7  실전 예제: 금융 보고서 자동 생성 AI의 검증</h3>
<p>AI가 기업의 분기별 실적 보고서를 자동으로 요약 및 생성하는 시나리오를 통해, 원자적 분해와 검증 과정이 실제 비즈니스 로직에 어떻게 적용되는지 구체적으로 살펴보자. 이 예제는 자연어 텍스트가 어떻게 결정론적 데이터 검증 로직으로 매핑되는지를 보여준다.</p>
<p><strong>시나리오</strong>: AI가 다음과 같은 문장을 생성했다.</p>
<blockquote>
<p>“A사의 2023년 4분기 매출은 전년 동기 대비 10% 증가한 500억 원이며, 이는 클라우드 부문의 성장에 기인한다.”</p>
</blockquote>
<p>이 복합 문장은 단일 검증으로는 확인이 어렵다. 따라서 이를 다음과 같은 원자적 검증 단위(Atomic Verification Units)로 분해한다.</p>
<ol>
<li><strong>사실 단위 1 (수치 정확성 - 절대값)</strong>: “2023년 4분기 매출 = 500억 원”</li>
</ol>
<ul>
<li><em>검증 로직</em>: 데이터베이스 쿼리 <code>SELECT revenue FROM financials WHERE company='A' AND quarter='2023-Q4'</code>의 반환값과 ’500억’을 비교한다. 이는 <span class="math math-inline">A=B</span> 형태의 완벽한 결정론적 검증이다.</li>
</ul>
<ol start="2">
<li><strong>사실 단위 2 (연산 정확성 - 상대값)</strong>: “전년 동기(2022년 4분기) 대비 증가율 = 10%”</li>
</ol>
<ul>
<li><em>검증 로직</em>: <code>(2023년매출 - 2022년매출) / 2022년매출 * 100</code> 수식을 계산하여 그 결과가 10%(<span class="math math-inline">\pm</span> 허용 오차)인지 확인한다. 이는 AI의 산술 연산 능력을 검증한다.</li>
</ul>
<ol start="3">
<li><strong>사실 단위 3 (인과관계 합당성 - 추론)</strong>: “성장 원인 = 클라우드 부문 성장”</li>
</ol>
<ul>
<li><em>검증 로직</em>: 클라우드 부문의 매출 증가율이 전체 매출 증가율보다 높은지 확인하거나, 재무제표 주석(Footnote) 텍스트 내에 ’클라우드’와 ‘성장’ 키워드가 공기(Co-occurrence)하는지 확인한다. 이는 반-결정론적일 수 있으나, 참조 문서(Source Document)와의 정합성을 체크하는 RAG 검증 로직을 따른다.</li>
</ul>
<p><img src="./3.3.1.1.0%20%EB%B3%B5%ED%95%A9%20%EC%A7%88%EB%AC%B8%EC%9D%98%20%EB%B6%84%ED%95%B4%EC%99%80%20%EA%B0%9C%EB%B3%84%20%EA%B2%80%EC%A6%9D%20%EA%B0%80%EB%8A%A5%ED%95%9C%20%EB%8B%A8%EC%9C%84%20%EC%84%A4%EC%A0%95.assets/image-20260218214806470.jpg" alt="image-20260218214806470" /></p>
<p>이 예제에서 볼 수 있듯이, 복합적인 문장을 원자 단위로 분해하면 AI의 오류를 정밀하게 진단할 수 있다. 만약 AI가 “매출은 500억이 맞지만 증가율 계산을 틀렸다“면, 이는 산술 연산 모듈의 문제이지 데이터 검색 모듈의 문제는 아니다. 반대로 “수치는 맞으나 원인 분석이 틀렸다“면, 이는 추론 능력의 부족을 시사한다. 이러한 정밀한 진단은 뭉뚱그려진 “답변이 이상함“이라는 피드백보다 훨씬 더 가치 있는 개선의 단서를 제공한다.</p>
<p>결론적으로, <strong>복합 질문의 분해와 개별 검증 가능한 단위 설정</strong>은 비결정적인 AI 출력을 통제 가능한 공학적 범위 내로 끌어들이는 가장 강력하고 필수적인 수단이다. 모호한 전체를 한 번에 평가하려 하지 말고, 명확한 부분들의 논리적 합으로 전체를 재구성해야 한다. 이것이 불확실성의 바다 위에서 신뢰할 수 있는 AI 소프트웨어를 구축하기 위한 결정론적 정답지 설계의 제1원칙이다.</p>
<h2>1. 참고 자료</h2>
<ol>
<li>Evaluation of LLMs Should Not Ignore Non-Determinism - arXiv, https://arxiv.org/abs/2407.10457</li>
<li>Defeating Nondeterminism in LLM Inference - Thinking Machines Lab, https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/</li>
<li>Opus A Quantitative Framework for Workflow Evaluation - arXiv, https://arxiv.org/html/2511.04220v1</li>
<li>Applying the Single Responsibility Principle in Industry: Modularity, https://www.researchgate.net/publication/331534092_Applying_the_Single_Responsibility_Principle_in_Industry_Modularity_Benefits_and_Trade-offs</li>
<li>Non Determinism &amp; Prompt Optimization in LLMs for AI Apps, https://futureagi.com/blogs/non-deterministic-llm-prompts-2025</li>
<li>Evaluating Non-Deterministic Results From RAG Systems, https://parserdigital.com/2025/09/10/evaluating-non-deterministic-results-from-rag-systems/</li>
<li>ORCHESTRATED AGENTIC SYSTEMS: DATASET, TAX, https://openreview.net/pdf/0106213e3d3728425a44a92b0da02cd36555d0b7.pdf</li>
<li>Complex Query Decomposition for Improved Relevance Ranking, https://thatware.co/complex-query-decomposition/</li>
<li>Advanced RAG Optimization: Boosting Answer Quality on Complex, https://blog.epsilla.com/advanced-rag-optimization-boosting-answer-quality-on-complex-questions-through-query-decomposition-e9d836eaf0d5</li>
<li>A Closer Look at Claim Decomposition - arXiv, https://arxiv.org/html/2403.11903v1</li>
<li>Visual Analytics for Improving Fact Annotations in Language Model, https://bib.dbvis.de/uploadedFiles/Schmidt2025Dissecting.pdf</li>
<li>NLI under the Microscope: What Atomic Hypothesis Decomposition, https://aclanthology.org/2025.naacl-long.130.pdf</li>
<li>Dynamic Atomic Fact Extraction - Emergent Mind, https://www.emergentmind.com/topics/dynamic-atomic-fact-extraction</li>
<li>FActScore: Metric for Factual Precision in LLMs - Emergent Mind, https://www.emergentmind.com/topics/factscore</li>
<li>Advanced RAG: Query Decomposition &amp; Reasoning | Haystack, https://haystack.deepset.ai/blog/query-decomposition</li>
<li>Exercise 3: RAG with Query Decomposition &amp; Tracing with LangSmith, https://medium.com/madailab/exercise-3-rag-with-query-decomposition-tracing-with-langsmith-146c140696c1</li>
<li>Query Decomposition: Tackling Semantic Dilution in RAG, https://blog.dataengineerthings.org/query-decomposition-tackling-semantic-dilution-in-rag-3fb4307126ff</li>
<li>From Complex to Atomic: Enhancing Augmented Generation via, https://icml.cc/virtual/2025/poster/45398</li>
<li>Natural Language Decomposition and Interpretation of Complex …, https://arxiv.org/abs/2305.08677</li>
<li>TempoBench: Temporal Reasoning Benchmark - Emergent Mind, https://www.emergentmind.com/topics/tempobench</li>
<li>FActScore: Fine-grained Atomic Evaluation of Factual Precision in, https://chatpaper.com/paper/11679</li>
<li>FActScore: Fine-grained Atomic Evaluation of Factual Precision in, https://www.researchgate.net/publication/370981225_FActScore_Fine-grained_Atomic_Evaluation_of_Factual_Precision_in_Long_Form_Text_Generation</li>
<li>Atomic-SNLI: Fine-Grained Natural Language Inference … - arXiv, https://arxiv.org/html/2601.06528v1</li>
<li>NLI under the Microscope: What Atomic Hypothesis Decomposition, https://arxiv.org/html/2502.08080v2</li>
<li>Hallucination Risks in AI Agents: How to Spot and Prevent Them, https://dac.digital/ai-hallucination-risks-how-to-spot-and-prevent/</li>
<li>Building Production-Ready AI Coding Teams with Claude Code Sub, https://dev.to/shinpr/zero-context-exhaustion-building-production-ready-ai-coding-teams-with-claude-code-sub-agents-31b</li>
<li>Using Evals to Build Reliable Agents, <a href="https://prakhar1114.github.io/prakharjain/blogs/Evals%20Blog/EvalsBlog.html">https://prakhar1114.github.io/prakharjain/blogs/Evals%20Blog/EvalsBlog.html</a></li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>