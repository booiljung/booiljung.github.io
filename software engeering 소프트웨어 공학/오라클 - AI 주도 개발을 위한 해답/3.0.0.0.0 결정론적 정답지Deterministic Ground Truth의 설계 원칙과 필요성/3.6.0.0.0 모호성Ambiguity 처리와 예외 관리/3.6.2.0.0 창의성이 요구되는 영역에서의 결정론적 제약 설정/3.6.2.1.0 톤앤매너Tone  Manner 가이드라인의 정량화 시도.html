<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:3.6.2.1 톤앤매너(Tone & Manner) 가이드라인의 정량화 시도</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>3.6.2.1 톤앤매너(Tone & Manner) 가이드라인의 정량화 시도</h1>
                    <nav class="breadcrumbs"><a href="../../../../../index.html">Home</a> / <a href="../../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../../index.html">Chapter 3. 결정론적 정답지(Deterministic Ground Truth)의 설계 원칙과 필요성</a> / <a href="../index.html">3.6 모호성(Ambiguity) 처리와 예외 관리</a> / <a href="index.html">3.6.2 창의성이 요구되는 영역에서의 결정론적 제약 설정</a> / <span>3.6.2.1 톤앤매너(Tone & Manner) 가이드라인의 정량화 시도</span></nav>
                </div>
            </header>
            <article>
                <h1>3.6.2.1 톤앤매너(Tone &amp; Manner) 가이드라인의 정량화 시도</h1>
<p>인공지능(AI) 기반 소프트웨어 개발의 패러다임이 확고하게 자리 잡으면서, 자연어 생성(Natural Language Generation, NLG) 모델을 활용한 애플리케이션의 검증 과제는 전례 없는 복잡성을 띠게 되었다. 전통적인 소프트웨어 테스트 환경에서는 입력값에 대한 예상 결괏값이 명확한 형태의 문자열이거나 숫자였으므로, 이를 결정론적(Deterministic) 정답지를 기반으로 철저하게 일치 여부를 검증하는 것만으로도 충분한 품질 보증이 가능했다. 그러나 대형 언어 모델(LLM)이 출력하는 문장들은 그 의미적 본질이 동일하더라도 어휘의 선택, 문장의 구조, 구문론적 배치, 그리고 문맥적 뉘앙스에 따라 무한에 가까운 변형을 창출해낸다. 이러한 생성형 AI의 본질적인 비결정성(Nondeterminism)을 소프트웨어 공학의 엄격한 품질 기준 안으로 포섭하고, 기업의 철학이 담긴 브랜드 보이스나 서비스의 특정한 목적에 부합하는 일관된 응답을 안정적으로 보장하기 위해서는, 인간의 창의성과 직관성이 교차하는 이른바 ’스타일(Style)’과 ’어조(Tone)’의 영역을 수학적이고 알고리즘적인 지표로 치환하는 정량화 작업이 절대적으로 요구된다.</p>
<p>단순히 내용의 정확성을 평가하는 것을 넘어 톤앤매너를 정량적으로 제어해야 하는 이유는 실제 비즈니스 환경에서의 사용자 경험과 직결되기 때문이다. 환자의 의료 서비스 경험에 대한 리뷰 데이터를 자연어 처리(NLP) 기법으로 분석한 대규모 연구에 따르면, 서비스에 대한 최하위 평가(1성급)는 단순히 절차적 오류나 물류적 문제에 기인한 것이 아니라, 소통의 부재와 관계 형성의 실패, 그리고 응답에 내포된 부정적인 톤(Negative tones) 및 화자의 무관심을 나타내는 어휘들과 가장 강력한 상관관계를 가지는 것으로 나타났다. 반면, 중간 수준 이상의 평가는 과정상의 매끄러움과 관련이 깊었다. 이는 시스템이 전달하는 텍스트의 ’내용(What)’이 아무리 정확하더라도 그것을 전달하는 ’방식(How)’이 부적절하다면, 해당 AI 에이전트는 사용자와의 관계 구축에 실패하며 궁극적으로 소프트웨어의 목적을 달성하지 못함을 시사한다. 웹 페이지 콘텐츠의 정렬(Alignment)과 검색 엔진 최적화(SEO)를 평가하는 또 다른 분석 시스템 역시, 문서 내 각 섹션 간의 감성(Sentiment)과 톤, 그리고 의미론적 임베딩의 일관성이 무너지는 지점(Drift)을 식별하여 사이트의 전반적인 품질과 사용자 경험을 정량화하고 있다. 이처럼 톤앤매너는 단순한 수식어가 아니라, 제품의 성공 여부를 가르는 핵심 비즈니스 로직 그 자체이다.</p>
<p>따라서 AI 소프트웨어 개발의 지속적 통합 및 배포(CI/CD) 파이프라인 내에서 자동화된 회귀 테스트(Regression Testing)를 수행하려면, “챗봇의 응답이 고객에게 친절하고 전문적인가?“라는 지극히 주관적인 질문을 “해당 텍스트 출력물의 정중성 지수(Politeness Score)가 0.85를 초과하며, 격식성(Formality) 점수가 60 구간에 위치하는가?“라는 결정론적이고 판별 가능한 논리 명제로 변환해야만 한다. 이러한 변환 과정이 바로 오라클(Oracle)의 구축이며, 이 오라클은 사람의 개입 없이 모델의 합격과 불합격을 판정하고, 모델 파라미터 업데이트 시 발생할 수 있는 의도치 않은 톤 이탈(Tone Drift)을 감지하며, 나아가 프롬프트 엔지니어링의 정밀한 A/B 테스트를 가능하게 하는 절대적인 기준선이 된다. 본 장에서는 이러한 주관적이고 추상적인 개념인 톤앤매너를 결정론적 오라클이 검증할 수 있는 형태의 정량적 지표로 치환하는 다양한 언어학적, 통계적, 딥러닝 기반의 방법론들을 심도 있게 해부하고 그 실전적 적용 방안을 제시한다.</p>
<h2>1. 언어학적 지표 및 품사(POS) 태깅에 기반한 격식성(Formality)의 알고리즘적 산출</h2>
<p>텍스트의 톤앤매너를 수치화하는 가장 고전적이면서도 수학적으로 견고한 방법은 품사(Part-of-Speech, POS) 태깅 및 문장 구조 분석 등 통계적 자연어 처리 기법을 활용하여 문장의 격식성(Formality)을 측정하는 것이다. 이 방식은 대형 언어 모델의 블랙박스적 확률 판단에 의존하지 않고, 정해진 알고리즘에 따라 명확한 값을 도출하므로 소프트웨어 테스트에서 완전히 확정적인(Deterministic) 함수 형태로 오라클을 구현할 수 있다는 강력한 장점을 지닌다.</p>
<p>텍스트의 격식을 측정하는 언어학계의 대표적인 수학적 모델은 학자 Heylighen과 Dewaele가 제안한 F-score(Formality Score) 공식이다. 이 수치화 모델은 ’문맥 의존성(Context-dependence)’이라는 심오한 언어학적 개념에 착안하여 개발되었다. 이들의 이론에 따르면, 텍스트가 특정한 대상이나 상황을 묘사할 때 명시적인 정보를 많이 담고 있을수록 그 텍스트는 시공간적 문맥에서 독립될 수 있으며, 이러한 성질을 가진 텍스트가 바로 고도로 ‘격식적인’ 언어이다. 명사(Noun), 형용사(Adjective), 전치사(Preposition), 관사(Article)와 같은 품사들은 외부의 맥락에 의존하지 않고 텍스트 자체만으로 정보를 명확하게 전달하는 역할을 수행하므로 텍스트의 격식을 높인다. 반면에 대명사(Pronoun), 동사(Verb), 부사(Adverb), 감탄사(Interjection) 등은 화자와 청자가 공유하고 있는 경험이나 현재의 대화 맥락에 크게 의존하는 성질을 띠며, 이를 많이 사용할수록 텍스트는 맥락 의존적이 되어 구어체적이고 ‘비격식적인’ 성격을 갖게 된다.</p>
<p>이러한 논리를 바탕으로 Heylighen과 Dewaele는 전체 텍스트 토큰 수에 대한 각 품사 그룹의 상대적 빈도를 수학적으로 규명하여 0에서 100 사이의 명확한 점수를 반환하는 공식을 도출했다. 원래 제안된 F-score의 수학적 정의는 전체 단어 수 <span class="math math-inline">N</span>에 대하여 격식적 품사의 빈도 <span class="math math-inline">n_f</span>와 비격식적 품사의 빈도 <span class="math math-inline">n_c</span>의 차이를 이용하는 방식으로 설계되었다. 이를 퍼센티지(%) 기반의 보다 직관적인 수치로 변환하여 널리 통용되는 공식은 다음과 같이 표현된다.<br />
<span class="math math-display">
F = \frac{(\text{Noun} + \text{Adjective} + \text{Preposition} + \text{Article}) - (\text{Pronoun} + \text{Verb} + \text{Adverb} + \text{Interjection}) + 100}{2}
</span><br />
이 공식에 따라 도출된 점수가 0에 가까울수록 지극히 맥락 의존적이고 극도로 비격식적인 구어체 문서를 의미하며, 100에 가까울수록 어떠한 사전 맥락 없이도 정보 전달이 완벽하게 이루어지는 객관적이고 학술적이며 고도로 격식을 갖춘 문서를 의미한다. 이러한 통계적 산출 방식은 영어와 같이 품사 구분이 명확한 언어에서 출발했지만, 다양한 언어권의 AI 시스템을 위해 철저한 현지화(Localization) 및 수정 과정을 거쳐 적용되고 있다. 예를 들어, 인도-이란어족이나 한국어와 같이 관사(Article)가 아예 존재하지 않는 언어의 경우, 공식에서 관사의 빈도를 완전히 제거하고 전치사 대신 조사가 결합된 후치사(Post-position)의 개념을 대체재로 삽입하여 공식을 현지화한다. 또한 고유명사(Proper Noun, NNP)나 장소 명사(Location Noun, NST)와 같은 세부적인 명사 태그들 역시 모두 공식을 상승시키는 형식적 언어의 범주로 통합하여 처리함으로써 분석의 정밀도를 높인다.</p>
<p>실제 소프트웨어 엔지니어링 실무에서는 이러한 언어학적 공식을 활용하여 자동화된 단위 테스트(Unit Test)를 작성한다. Python 생태계의 <code>NLTK</code>, <code>spaCy</code>, 또는 <code>TidyText</code> 라이브러리를 통해 AI가 생성한 응답 텍스트를 입력받아 실시간으로 형태소 분석 및 POS 태깅을 수행하고, 각 품사의 빈도수 배열을 바탕으로 F-score를 계산하는 확정적 함수를 파이프라인에 배치하는 것이다. 예를 들어, 기업의 금융 상품 약관을 설명하는 전문적인 챗봇이나 B2B(기업 간 거래) 이메일 자동 작성 에이전트를 개발한다고 가정할 때, 품질 보증 팀은 오라클의 평가 기준으로 “모든 최종 출력 응답의 F-score는 반드시 70 이상을 유지해야 한다“는 명확하고 반박 불가능한 테스트 통과 임계치(Threshold)를 설정할 수 있다.</p>
<p>그러나 Heylighen과 Dewaele의 방식은 수백 단어 이상으로 이루어진 문서 전체의 평균적인 분위기를 평가하는 데는 매우 신뢰할 만한 결과를 제공하지만, 단일 문장이나 모바일 환경에서의 짧은 챗봇 응답과 같이 토큰 수가 적은 환경에서는 치명적인 한계를 노출한다. 문장의 길이가 짧아질수록 특정 품사 하나가 우연히 등장하거나 생략됨에 따라 F-score 전체가 극단적으로 요동치는 통계적 불안정성이 발생하기 때문이다. 짧은 발화 단위에서 섬세한 톤의 변화를 일관되게 평가하고 검증하기 위해서는 단순 이분법적 품사 분류를 넘어서는 새로운 차원의 연속적 정량화 모델이 필요하다.</p>
<p>이러한 단문 중심의 AI 대화 환경적 한계를 극복하기 위해 제안된 최신의 접근법은, 문장 단위의 격식성을 이분법적 분류(Formal vs. Informal)가 아닌 연속적인 실수 척도(Continuous scale) 위에서 평가하는 회귀 분석(Regression) 모델의 도입이다. 대표적인 연구인 “A Question of Style: A Dataset for Analyzing Formality on Different Levels” 등의 논문에서는 이메일, 뉴스 기사, 블로그, 온라인 포럼 등 다양한 장르의 텍스트에 대해 사람의 직관적인 비교 판단을 거쳐 문장 단위의 연속적 격식성 점수를 매긴 방대한 데이터셋을 구축하였다. 이 과정에서 연구진들은 단일 문장의 격식성을 결정짓는 요소가 단순한 품사 빈도를 넘어 매우 다차원적임을 증명했다.</p>
<p>이러한 고품질 데이터셋을 기반으로 훈련된 최신의 Ridge 회귀 모델이나 트랜스포머(Transformer) 기반 텍스트 분류기들은 단순히 단어를 세는 것을 넘어, 문장의 복합적인 언어학적 지표들을 동시에 분석하여 0.0에서 1.0 사이의 정밀한 연속적 격식성 점수를 산출한다. 이러한 모델들이 오라클로서 작동할 때 주로 검사하는 핵심 자질(Features)은 다음과 같다.</p>
<p>첫째, 어휘적 특징(Lexical Features)이다. 문장에 포함된 단어들의 평균 길이가 길어질수록, 그리고 특정 금지어(비속어, 은어)나 축약형(Contractions)의 포함 빈도가 낮을수록 텍스트는 격식적인 것으로 점수화된다. 둘째, 구문론적 특징(Syntactic Features)이다. 단순한 주술 구조를 넘어 구문 분석 트리(Constituency parse tree)의 깊이가 깊고 복잡할수록, 그리고 행위의 주체를 숨기고 객관성을 담보하기 위해 수동태(Passive voice) 구조가 빈번하게 사용될수록 격식성 점수에 가산점이 부여된다. 셋째, 텍스트의 가독성 지수(Readability)이다. Flesch-Kincaid Grade Level 등의 가독성 점수는 단어의 음절 수와 문장의 길이를 기반으로 산출되는데, 흥미롭게도 이 가독성 점수가 높아질수록(즉, 일반 대중이 읽고 이해하기 어려워질수록) 해당 텍스트는 더 전문적이고 격식적인 것으로 평가되는 강력한 양의 상관관계를 보인다. 넷째, 문장의 주관성(Subjectivity) 지표이다. 1인칭 대명사의 잦은 출현, 감성을 강하게 드러내는 주관적 어휘, 그리고 문장의 확정성을 회피하는 ‘아마도’, ’~인 것 같다’와 같은 헤지 단어(Hedge words)의 사용 빈도는 문장을 지극히 개인적이고 구어체적인 상태로 끌어내리므로 격식성 산출에서 큰 감점 요인으로 작용한다.</p>
<p>통계적 분석 도구인 SHAP(SHapley Additive exPlanations)을 통해 이러한 자질들의 기여도를 분석한 결과, 문장의 길이, 평균적인 단어의 형식적 가중치, Flesch 가독성 점수, 그리고 평균 토큰 길이라는 단 네 가지 지표의 조합만으로도 인간이 느끼는 주관적 격식성 점수와 0.8 이상의 높은 스피어만 상관계수(Spearman’s <span class="math math-inline">\rho</span>)를 달성할 수 있음이 입증되었다. 따라서 AI 개발 파이프라인에서 응답 문장을 검증할 때, 이러한 다변량 회귀 분석 모델을 오라클로 편입시키면 단순한 길이 불균형에 흔들리지 않고 모델의 출력이 의도한 문서 스타일 가이드라인을 정확하게 궤적 내에서 추종하고 있는지를 연속적이고 안정적으로 테스트할 수 있다.</p>
<h2>2. 컴퓨터 화용론에 기반한 정중성(Politeness)의 계량적 추출 및 오라클화</h2>
<p>앞서 논의한 격식성(Formality)이 텍스트가 지닌 구조적 객관성과 문맥 독립성을 의미한다면, 정중성(Politeness)은 그와는 전혀 다른 축에 존재하는 화용론(Pragmatics)적 개념으로, 화자와 청자 간의 사회적 거리, 권력의 역학 관계, 그리고 상대방에 대한 예의와 배려를 나타내는 고차원적인 지표이다. 동일한 내용을 전달하더라도 상대방의 체면(Face)을 세워주기 위해 어떠한 언어적 전략을 선택했느냐가 정중성을 결정한다. 스탠퍼드 대학교의 연구진이 발표한 기념비적 논문 “A Computational Approach to Politeness with Application to Social Factors“는 주관성의 영역에 머물러 있던 텍스트 내의 정중성을 판별하는 구체적인 언어학적 마커(Linguistic Markers)들을 식별하고, 이를 기계학습 분류기(Classifier)로 구현해 내는 프레임워크를 최초로 제시함으로써 이 분야의 패러다임을 전환시켰다.</p>
<p>이 연구는 위키피디아(Wikipedia) 편집자들의 토론 기록과 스택 익스체인지(Stack Exchange)와 같은 온라인 커뮤니티의 방대한 발화 데이터를 바탕으로 인간의 정중성 인식을 훈련 데이터로 삼아 구축되었다. 연구진은 사회적 권력이 존재하는 집단에서 정중성이 어떻게 발현되는지 분석했는데, 흥미롭게도 높은 권력을 향해 상승하려는 사람들은 극도로 정중한 언어를 구사하지만, 선거를 통해 높은 지위에 오르고 권력을 획득한 이후에는 오히려 정중성이 유의미하게 하락하는 현상을 통계적으로 증명했다. 이러한 화용론적 발견은 텍스트의 정중성 마커들이 인간의 직관을 넘어 보편적이고 도메인 독립적인(Domain-independent) 언어적 자질로 존재함을 시사한다.</p>
<p>소프트웨어 시스템 내에서 정중성을 평가하고 통제하는 오라클은 문장 내에 존재하는 긍정적 마커(Boosters)와 부정적 마커(Penaltizers)의 존재 여부 및 그 결합을 분석하도록 설계된다. 이 오라클이 스캔하는 핵심적인 언어학적 전략들은 다음과 같이 분류된다. 정중성을 큰 폭으로 상승시키는 긍정적 마커에는 간접적 표현(Indirection, 예: “혹시 시간이 허락하신다면~”), 상대방의 권위를 인정하는 존중의 표현(Deference, 예: 극존칭 및 하대 회피), 책임을 분산시켜 상대의 부담을 줄여주는 비인칭화 및 수동태 활용(Impersonalization), 그리고 대화의 윤활유 역할을 하는 명시적인 감사와 사과의 표현(Gratitude &amp; Apology, 예: “알려주셔서 감사합니다만”, “불편을 드려 대단히 죄송하지만”) 등이 포함된다. 반면에, 상대방의 영역을 침범하거나 압박을 가하는 직접적인 요구(Direct Requests, 예: “~을 당장 제출해라”), 부정적 감정이 노골적으로 담긴 공격적 단어, 그리고 비속어의 사용(Swearing &amp; Aggression)은 정중성 점수를 곤두박질치게 만드는 강력한 하락 마커로 작동한다.</p>
<p>초기의 정중성 판별 오라클들은 이러한 마커들의 단순한 출현 빈도를 자질(Feature)로 추출하여 서포트 벡터 머신(SVM)과 같은 전통적인 머신러닝 분류기에 통과시켜 정중한지(Polite), 중립적인지(Neutral), 무례한지(Rude)를 판별하는 확률값을 도출하는 형태였다. 그러나 자연어의 복잡성은 특정 단어의 존재만으로 톤을 확정하는 것을 허락하지 않는다. 최신 NLP 연구들은 단순히 고립된 단어 사전(Lexicon)에 의존하는 것을 넘어, 주변 단어들과의 관계를 학습하는 문맥화된 임베딩(Contextualized Embeddings) 기술인 BERT 모델을 도입하여 정중성 분석의 정확도를 비약적으로 끌어올렸다. 기존 방식에서는 “Please“라는 단어가 포함되면 무조건 정중성 점수가 상승하는 치명적인 오류(False Positive)가 빈번했다. 그러나 BERT를 활용한 클러스터링 기반 모델은 단어가 위치한 문맥의 패턴을 세밀하게 포착하여, “제발 그 입 좀 다물어라(Please shut your mouth)“와 같은 문장에서 쓰인 “Please“가 지닌 냉소적이고 무례한 문맥적 특성을 정확히 식별하고 예측할 수 있게 되었다. 이는 정중성 평가 모델이 단어 중심적(Word-centric) 분석의 한계를 벗어나 진정한 의미의 화용론적 이해의 단계로 진입했음을 의미한다.</p>
<p>소프트웨어 개발 실무 및 CI/CD 자동화 환경에서는 이러한 진보된 정중성 분류기를 활용하여, 고객 응대 AI나 태스크 지향형 대화 에이전트(Task-oriented Dialog Agents)가 뱉어내는 모든 출력물에 대해 실시간으로 정중성 점수를 판별하는 ‘가드레일(Guardrails)’ 메커니즘을 견고하게 구축한다. 만약 결제 오류로 분노한 고객을 응대하는 AI가 생성한 텍스트를 오라클에 통과시켰을 때, 이진 분류 모델이 해당 문장이 ‘무례함(Impolite)’ 클래스에 속할 확률을 일정 수준 이상으로 보고하거나, 회귀 모델 기반의 정중성 확률 스코어가 개발팀이 설정한 엄격한 임계치(예: <span class="math math-inline">P(\text{Polite} \vert \text{Text}) &lt; 0.85</span>) 미만으로 떨어지는 경우, 시스템 파이프라인은 해당 응답이 사용자 화면에 노출되는 것을 즉각적으로 물리적으로 차단한다. 이후 메인 AI 언어 모델에게 더 높은 정중성 파라미터를 강제하는 시스템 프롬프트를 부여하여 안전한 수준의 정중성을 담보하는 응답이 도출될 때까지 내부적인 재작성(Regeneration) 루프를 실행하도록 소프트웨어 아키텍처를 설계하는 것이 현대 AI 엔지니어링의 표준적인 안전망 구축 방식이다.</p>
<h2>3. 텍스트 스타일 변환(Text Style Transfer, TST) 모델 평가 지표의 오라클 차용</h2>
<p>자연어 처리(NLP) 분야에서 원본 텍스트가 지닌 본질적인 정보나 의미를 훼손하지 않으면서, 그 문장을 특정한 어조, 감성, 정치적 성향, 혹은 특정한 작가의 문체로 변경하는 일련의 고도화된 작업을 ’텍스트 스타일 변환(Text Style Transfer, TST)’이라고 명명한다. AI 기반 소프트웨어가 사용자의 구체적인 요구사항에 맞게 올바른 톤앤매너를 구사하여 응답을 성공적으로 생성했는지 검증하는 과정은, 본질적으로 이 TST 시스템의 변환 성공 여부를 평가하는 것과 완벽하게 동일한 수학적, 논리적 과제를 안고 있다.</p>
<p>이 분야의 선구적인 기념비적 연구인 “Style Transfer from Non-Parallel Text by Cross-Alignment” 논문을 비롯한 다수의 TST 연구들은, 텍스트의 표면적 표현에서 ’스타일(Style)’과 ’핵심 내용(Content)’을 기계 학습적 잠재 공간(Latent Space) 내에서 완벽하게 분리(Disentanglement)해 내고 조작하는 획기적인 모델링 기법들을 제안했다. 이러한 연구들의 근본적인 통찰은 AI가 생성한 텍스트를 평가할 때 단일 차원적 시각에 매몰되어서는 안 된다는 점이다. 오라클은 텍스트의 어조가 의도한 대로 완벽하게 바뀌었는가에 대한 검증과 함께, 원래 전달해야 했던 핵심적인 비즈니스 정보와 사실관계(Content)가 왜곡이나 소실 없이 온전하게 보존되었는가를 동시에 입체적으로 모니터링해야 한다.</p>
<p>따라서 톤앤매너의 완전한 검증을 위해 결정론적 정답지를 구축하고 오라클을 설계할 때, 엔지니어는 AI의 최종 응답을 아래에 서술된 세 가지 독립적이고 핵심적인 평가 축에서 교차 검증하는 다차원 매트릭스(Multi-dimensional Matrix)를 구축해야만 한다.</p>
<p>첫 번째 축은 ’스타일 충실도(Style Fidelity)’이다. 이는 생성된 텍스트가 애초에 목표로 했던 특정 톤앤매너 속성(예를 들어, 극도로 긍정적인 감성, 고도로 격식적인 법률 문서 스타일, 또는 특정 페르소나의 말투 등)을 얼마나 강렬하고 정확하게 띠고 있는지를 확률적으로 측정하는 지표이다. 이를 시스템 내에서 자동화하여 정량화하기 위해, 테스트 환경에서는 타깃 스타일에 대해 방대한 양의 데이터로 사전 학습된(Pre-trained) 강력한 외부 평가자 모델(Evaluator Model)을 도입한다. 예를 들어, 부정적인 고객 리뷰를 긍정적인 톤의 피드백으로 변환하는 작업을 목표로 삼았다면, 높은 신뢰도를 지닌 딥러닝 기반 감성 분석기(Sentiment Classifier)가 생성된 텍스트를 입력받았을 때 이를 ‘긍정(Positive)’ 클래스로 분류할 확률값 <span class="math math-inline">P(Style \vert Text)</span> 자체를 직관적인 평가 지표로 채택한다. 이 확률이 개발자가 사전에 설정한 임계치를 상회해야만 스타일 변환의 첫 번째 관문을 통과한 것으로 간주한다.</p>
<p>두 번째 축은 ’내용 보존성(Content Preservation)’이다. 특정한 톤앤매너 규칙을 지나치게 억지로 강제하다 보면, 원본 입력에 존재했던 핵심적인 팩트나 사용자에게 반드시 제공해야 하는 중요한 비즈니스 로직의 정보가 심각하게 왜곡되거나 아예 누락되는 현상이 빈번하게 발생한다. 따라서 톤이 적용되기 전의 순수한 원본 내용(Ground Truth Content)과 최종적으로 생성된 텍스트 간의 의미론적 유사성을 수학적으로 비교 측정하는 방어 기제가 반드시 필요하다. 이 과정에서 다음과 같은 지표들이 사용된다.</p>
<ul>
<li><strong>어휘적 겹침 지표 (BLEU &amp; ROUGE Scores):</strong> 기계번역과 요약 모델 평가의 표준인 이 지표들은 원본 문장과 생성된 문장 간의 N-gram 단위의 단어 겹침 비율을 정밀하게 계산하여, 표면적인 텍스트 정보가 구조적으로 얼마나 온전하게 보존되었는지 측정한다. 하지만 톤을 바꾸기 위해 어휘 자체가 완전히 달라질 수 있으므로, 단어 수준의 일치도만으로는 의미의 보존을 완벽히 담보할 수 없다.</li>
<li><strong>임베딩 기반 코사인 유사도 (Cosine Similarity with Sentence Embeddings):</strong> 이러한 한계를 극복하기 위해 Sentence-BERT 등 최신 임베딩 모델을 활용하여 비교할 두 텍스트를 고차원의 조밀한 벡터(Dense Vector) 공간으로 투영한다. 그리고 원본 벡터 <span class="math math-inline">\mathbf{v}_1</span>과 생성문 벡터 <span class="math math-inline">\mathbf{v}_2</span> 간의 코사인 유사도 식 <span class="math math-inline">\frac{\mathbf{v}_1 \cdot \mathbf{v}_2}{\vert \mathbf{v}_1 \vert \vert \mathbf{v}_2 \vert}</span> 를 계산하여 두 벡터 간의 기하학적 거리를 구한다. 이 값이 1에 가까울수록 문장의 표면적 구조와 단어가 완전히 달라졌더라도 그 내면의 의미적 본질(Semantics)이 동일함을 강력하게 보장할 수 있다.</li>
<li><strong>Earth Mover’s Distance (EMD):</strong> 더 나아가 두 텍스트 집단 간의 전반적인 의미적 분포의 차이를 계산하는 알고리즘을 도입하여, 개별 단어의 매핑 비용을 최소화하는 관점에서 본질적인 정보량과 문맥이 원래의 의도대로 유지되었는지 거시적으로 평가한다.</li>
</ul>
<p>세 번째 축은 텍스트의 ‘유창성(Fluency)’ 지표이다. 엄격한 스타일 제약 조건과 정보 보존 조건을 동시에 억지로 만족시키려다 보면, AI 모델이 문법이 완전히 파괴된 비정상적인 문장 구조를 만들어내거나 해당 언어 사용자들이 절대 쓰지 않는 기괴한 단어 조합을 출력하는 부작용(Trade-off)이 종종 발생한다. 이를 사전에 차단하기 위해 생성된 문장이 인간의 언어로서 얼마나 자연스러운지를 통계적으로 정량화해야 한다. 이를 위해 신뢰할 수 있는 대규모 언어 모델(Language Model)을 활용하여 해당 문장을 평가 대상 언어권에서 마주칠 확률을 대변하는 퍼플렉서티(Perplexity, PPL) 값을 측정한다. 문장이 매끄럽고 자연스러울수록 모델이 다음 단어를 예측하기 쉬워지므로 퍼플렉서티 값은 낮아지며, 이는 유창성이 높다는 것을 정량적으로 입증한다.</p>
<p><strong>[표 1] 텍스트 스타일 변환(TST) 검증을 위한 핵심 3차원 정량 평가 지표 매트릭스</strong></p>
<table><thead><tr><th><strong>평가 범주 (Dimension)</strong></th><th><strong>오라클 검증 목적</strong></th><th><strong>대표적 측정 지표 (Evaluation Metrics)</strong></th><th><strong>수학적 계산 방식 및 통과 판별 기준</strong></th></tr></thead><tbody>
<tr><td><strong>Style Fidelity (스타일 충실도)</strong></td><td>타깃으로 삼은 목표 톤앤매너의 달성 강도 및 방향성 검증</td><td>Style Classifier Accuracy (분류기 정확도)</td><td>외부 딥러닝 분류기를 통과할 확률 <span class="math math-inline">P(Target Style \vert Generated Text)</span>. 설정된 하한 임계치 초과 시 Pass.</td></tr>
<tr><td><strong>Content Preservation (내용 보존성)</strong></td><td>핵심 팩트의 누락 및 치명적인 의미 왜곡 방지</td><td>Sentence Embedding Cosine Similarity (코사인 유사도), BLEU, ROUGE</td><td>임베딩 벡터 <span class="math math-inline">\mathbf{v}_1</span> (원본), <span class="math math-inline">\mathbf{v}_2</span> (생성)에 대하여 <span class="math math-inline">\frac{\mathbf{v}_1 \cdot \mathbf{v}_2}{\vert \mathbf{v}_1 \vert \vert \mathbf{v}_2 \vert}</span> 계산. 1.0에 근접할수록 우수하며, 하한선 미달 시 Fail 처리.</td></tr>
<tr><td><strong>Fluency (유창성)</strong></td><td>문법적 오류 및 인위적 억지 조어, 어색한 구문 구조 방지</td><td>Language Model Perplexity (퍼플렉서티, PPL)</td><td>평가 언어 모델이 해당 문장 시퀀스를 예측하는 복잡도. 낮을수록 자연스럽고 인간의 언어에 가까움 (Lower is better). 상한 임계치 초과 시 Fail.</td></tr>
</tbody></table>
<p>이러한 정교한 3차원 평가 체계는 AI 대화 에이전트나 문서 생성기의 톤앤매너 검증을 수행하는 하이브리드 오라클(Hybrid Oracle) 아키텍처의 핵심 뼈대가 된다. 만약 단일 지표에만 맹목적으로 의존하여 테스트를 수행할 경우, 챗봇의 톤은 완벽하게 예의 바르지만 정작 사용자가 질문한 내용과는 전혀 무관한 헛소리를 늘어놓거나(Style Fidelity만 비정상적으로 높음), 혹은 전달하는 비즈니스 정보는 무결하게 정확하지만 인간미가 배제된 기계적이고 차가운 응답만을 내뱉어 사용자의 불만을 초래하는(Content Preservation만 높음) 치명적인 상용화 부작용을 마주하게 될 것이다. 이 삼각 편대를 구축함으로써 오라클은 비로소 인간에 필적하는 균형 잡힌 심판관으로서의 역할을 수행할 수 있다.</p>
<h2>4. VibeCheck 및 LLM-as-a-Judge 방법론을 통한 다차원적 ’바이브’의 정량화</h2>
<p>기존에 확립된 형태소 빈도 분석 기반의 수학적 공식들이나 단일 목적의 분류기 모델들은 ‘격식성’, ‘가독성’, ’정중성’과 같이 언어학적으로 이미 사전 정의된 명확한 개념들을 독립적으로 측정하는 데는 탁월한 성능을 발휘한다. 그러나 “친근하면서도 전문적인 신뢰감을 잃지 않는”, “MZ세대의 유머 감각을 갖추었지만 선을 넘거나 무례하지 않은“과 같이 현대 기업 브랜드들이 빈번하게 요구하는 매우 복합적이고 다층적인 페르소나들을 모두 개별적인 수식이나 분류기로 커버하는 데는 근본적인 엔지니어링 한계가 뒤따른다. 오로지 인간의 직관만이 총체적으로 느낄 수 있는 미묘한 분위기, 이른바 ’바이브(Vibes)’를 기계적으로 정량화하기 위한 선구적인 시도로서 최근 초거대 언어 모델(LLM) 자체를 평가자로 직접 활용하는 ‘LLM-as-a-Judge’ 방법론이 테스트 자동화 생태계의 패러다임을 혁신적으로 바꾸고 있다.</p>
<h3>4.1 ’바이브(Vibes)’의 조작적 정의와 축(Axis) 식별 메커니즘</h3>
<p>arXiv에 발표된 획기적인 연구 “VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models” 논문은, 다양한 LLM 모델들이 생성해내는 텍스트 출력물들 사이의 미세한 정성적(Qualitative) 차이를 인간이 인지하고 이해할 수 있는 정량적 축(Quantitative Axis)으로 매핑하여 추출해 내는 파이프라인 프레임워크를 제안했다.</p>
<p>과거의 자연어 생성 평가 패러다임에서 오라클이 수행했던 역할이 주어진 답변이 “사실관계와 부합하는 정답인가, 아니면 환각으로 점철된 오답인가(Correctness)“만을 엄격하게 심사하는 이분법적 판단에 국한되었다면, VibeCheck 프레임워크는 출력 텍스트가 지니고 있는 특정한 질적 특성의 연속적인 스펙트럼(Spectrum)을 평가의 기준으로 새롭게 정의한다. 예를 들어 특정 프롬프트에 대해 Meta의 Llama 3 모델과 OpenAI의 GPT-4 모델이 생성한 두 가지 출력을 비교했을 때, 인간 사용자는 직관적으로 Llama 3의 답변이 전반적으로 더 ’친절하다’거나 GPT-4의 답변이 더 ’단호하고 전문적이다’라고 느낀다. VibeCheck는 이러한 막연한 느낌을 평가하기 위해 ’격식적인(Formal) <span class="math math-inline">\to</span> 친절하고 상냥한(Friendly)’이라는 하나의 명확한 바이브 축(Axis)을 알고리즘적으로 설정하고 계량화한다.</p>
<p>이러한 추상적인 바이브 축을 소프트웨어 평가 도구로 사용하기 위해 식별해 내고 정량화하는 전체 프로세스는 다음과 같은 정교한 파이프라인을 거친다.</p>
<ol>
<li><strong>프롬프트-출력 쌍(Prompt-Output Triplets)의 체계적 구성:</strong> 우선 광범위한 평가를 위해, 동일한 사용자 프롬프트 <span class="math math-inline">p</span>에 대하여 비교 대상인 모델 A가 생성한 출력 <span class="math math-inline">o_A</span>와 모델 B가 생성한 출력 <span class="math math-inline">o_B</span>를 수집하여 하나의 평가용 세트인 삼중항 <span class="math math-inline">(p, o_A, o_B)</span> 데이터베이스를 구축한다.</li>
<li><strong>LLM 프로포저(Proposer)를 통한 맹점 없는 바이브 추출:</strong> 인간 데이터 과학자가 수천 개의 샘플을 직접 읽으며 주관적으로 차이를 찾아내는 수동적인 질적 연구 방식 대신, GPT-4o와 같이 고도의 문맥 추론 능력을 지닌 강력한 LLM에게 프로포저(Proposer)의 역할을 부여한다. 수십 개의 샘플 세트 <span class="math math-inline">{ (p_1, o_{A1}, o_{B1}), \dots, (p_k, o_{Ak}, o_{Bk}) }</span>의 차이를 세밀하게 대조 분석하게 한 뒤, 두 모델 간에 나타나는 일관된 스타일의 차이를 인간의 언어로 명확히 해석 가능한 기준 축으로 추출해 내도록 지시한다. 이 과정을 통해 사전에 인간이 규정하지 않았던 ‘친절함’, ‘유머의 과감성’, ‘주장의 논쟁적 성향’ 등 모델 특유의 개성을 대변하는 새로운 평가 축들이 데이터 기반으로 동적 생성된다.</li>
<li><strong>LLM 심사위원(Judge) 패널을 통한 대규모 정량적 스코어링:</strong> 프로포저가 설정한 바이브 축이 검증되면, 이제 별도의 독립적인 LLM 심사위원 패널을 구성하여 대규모의 새로운 출력물 데이터들을 해당 축을 기준으로 일괄 평가한다. 예를 들어 새롭게 확립된 ’친절함’이라는 축에서 출력 A가 출력 B보다 텍스트 내에서 더 상냥하고 친절한 태도를 명확히 취하고 있다면 출력 A에 1점을, 반대로 출력 B가 더 친절하다면 -1점을, 양쪽 모두 차이가 없이 동일한 수준의 친절도를 보인다면 무승부인 0점을 부여하여 거대한 스코어링 행렬을 완성한다.</li>
</ol>
<h3>4.2 결정론적 LLM 오라클 도입을 위한 자기 일관성(Self-consistency) 확보 기술</h3>
<p>그러나 소프트웨어 자동화 테스트 환경이라는 지극히 통제된 세계에서 확률적 본성을 지닌 LLM을 오라클(Judge)로 편입하여 합격/불합격을 결정하는 중추로 사용하기 위해서는, 평가 시스템을 실행할 때마다 혹은 호출할 때마다 점수가 변동하는 비결정성(Nondeterminism) 문제를 반드시 공학적으로 해결해야만 한다. 아무리 추론 능력이 뛰어난 최고 성능의 모델이라 할지라도, 프롬프트 내 토큰의 미세한 위치 변화나 모델 내부의 확률적 디코딩(Decoding) 메커니즘, 심지어 동일한 입력일지라도 API 호출 시점에 따라 정성적 평가 결과가 정반대로 뒤바뀌는 불안정성이 존재하기 때문이다.</p>
<p>이러한 한계를 극복하고 신뢰할 수 있는 **결정론적 LLM 오라클(Deterministic LLM Oracle)**을 구축하기 위해 테스트 엔지니어링 실무에서는 다음과 같은 강력한 제어 기법들을 복합적으로 적용한다.</p>
<ul>
<li><strong>온도(Temperature) 파라미터의 극단적 통제:</strong> LLM 심사위원이 응답을 생성(즉, 평가 결과를 도출)할 때 사용하는 Temperature 파라미터를 0(Zero)으로 철저히 설정한다. 이는 모델이 다음 토큰의 분포를 계산할 때 다양한 가능성을 탐색하지 않고 확률값이 가장 높은 단일 토큰만을 기계적으로 선택하는 탐욕적 탐색(Greedy Search)을 강제함으로써, 생성 과정에 개입되는 확률적 변동성과 창의적 노이즈를 원천적으로 차단하는 가장 기본적인 통제 수단이다.</li>
<li><strong>자기 일관성 테스트(Self-consistency Test) 기반의 앙상블 평가:</strong> 단 한 번의 LLM 호출로 생성된 평가 결과를 맹신하는 것은 위험하다. 따라서 오라클 시스템은 완전히 동일한 텍스트에 대하여 복수의 독립적인 평가 세션(예를 들어 독립적으로 5회 또는 10회 반복 실행)을 백그라운드에서 수행한다. 이후 도출된 평가 결과들을 취합하여 통계적 과반수 투표(Majority Vote)를 진행하거나 스코어의 평균값을 도출함으로써, 단일 평가 세션에서 발생할 수 있는 일시적인 확률적 노이즈나 환각에 의한 오류 평가를 완벽하게 상쇄시키고 강건한 최종 결괏값을 확정한다.</li>
<li><strong>프롬프트 내 명시적 채점 기준(Rubric)의 하드코딩:</strong> LLM 심사위원에게 단순히 “이 텍스트의 친절도를 1점에서 10점 사이의 점수로 평가하라“고 개방형으로 지시하는 것은 환각을 유도하는 전형적인 안티 패턴이다. 그 대신, 소프트웨어 요구사항 명세서 수준으로 정교하게 설계된 평가 루브릭(Rubric) 매트릭스를 시스템 프롬프트에 명시적으로 하드코딩(Hardcoding)하여 함께 제공해야 한다. 예를 들어 “친절도 3점 부여 조건: 사용자의 감정에 명시적으로 공감하는 문장(예: 죄송합니다, 이해합니다, 얼마나 불편하셨습니까)이 텍스트 내에 최소 1회 이상 물리적으로 포함되어야 하며, 명령형 어미를 전혀 사용하지 않아야 함“과 같이, 판단의 재량권을 최소화하고 채점의 척도를 결정론적인 조건문 수준으로 구체화하여 프롬프트의 지침으로 제공한다.</li>
</ul>
<p>이러한 공학적 보완 장치들을 철저하게 결합하면, VibeCheck와 같은 고차원적이고 다차원적인 톤 평가 프레임워크는 단순히 신기한 실험적 도구에 머물지 않는다. 이 시스템은 인간만이 감지할 수 있는 모호한 뉘앙스조차 무려 80% 이상의 정확도로 모델의 정체성과 연결하고, 60%가 넘는 일치도로 인간 사용자의 선호도를 기계적으로 예측해 내는 산업 표준 규격의 신뢰성 높은 정량적 오라클로 기능하게 된다.</p>
<h2>5. 기업 브랜드 보이스(Brand Voice) 가이드라인의 정량적 제약 설정 실무 프레임워크</h2>
<p>지금까지 살펴본 언어학적 공식, 텍스트 스타일 변환(TST) 평가 메트릭, 그리고 딥러닝 기반의 VibeCheck 지표들을 실제 대규모 엔터프라이즈 소프트웨어 개발 파이프라인에 효과적으로 안착시키기 위해서는, 비즈니스 부서에서 기획한 추상적이고 정성적인 ’브랜드 보이스 가이드라인(Brand Voice Guidelines)’을 시스템 테스트가 가능한 명확한 코드와 수식의 논리 체계로 빈틈없이 매핑(Mapping)하는 고난도의 번역 작업이 요구된다.</p>
<h3>5.1 추상적 형용사의 결정론적 정량 지표 매핑 (Mapping Abstract Adjectives to Strict Metrics)</h3>
<p>브랜드 커뮤니케이션 전략의 모범 사례로 꼽히는 Mailchimp나 LinkedIn과 같은 거대 기술 기업들은 자사의 브랜드가 발산해야 하는 고유한 톤을 몇 가지의 지배적인 형용사로 정의하여 전사적으로 관리한다. 이메일 마케팅 플랫폼인 Mailchimp의 경우 자사의 브랜드 보이스를 “사용자에게 인간적이고 관계 지향적이며(Human &amp; Relatable), 명확하고 유용한 지침을 주되(Helpful), 절대 지나치게 딱딱하게 격식을 차리거나(Overly formal) 사용자에게 거만하게 굴어서는(Condesending) 안 된다“고 복합적으로 정의하고 있다. 반면 비즈니스 네트워킹 플랫폼인 LinkedIn의 톤앤매너는 철저하게 “전문적(Professional)이고, 포용적(Inclusive)이며, 자신감 있는(Confident)” 특성을 유지하면서 사용자의 업무적 신뢰를 획득하는 것을 최우선 목표로 한다.</p>
<p>기업들은 이러한 언어적 특성을 일관성 있게 통제하기 위해 브랜드를 ’성격(Personality), 스타일(Style), 어휘(Vocabulary), 에너지(Energy)’라는 4가지의 근본적인 차원(Dimensions)으로 철저하게 분해하여 관리한다. 이처럼 인간의 감성을 자극하는 추상적인 형용사 가이드라인을 AI 코드가 실행 결과를 검증하는 결정론적 오라클로 무결하게 전환하기 위해, 소프트웨어 아키텍트와 언어학자는 다음과 같은 명시적인 매핑 테이블 체계를 시스템에 구축해야 한다.</p>
<p><strong>[표 2] 엔터프라이즈 브랜드 톤앤매너의 정량적 제약조건 및 오라클 임계치 변환 매핑 테이블</strong></p>
<table><thead><tr><th><strong>브랜드 정의 형용사 (Abstract Adjective)</strong></th><th><strong>마케팅 부서 행동 지침 (DOs and DON’Ts)</strong></th><th><strong>소프트웨어 검증용 정량화 지표 (Quantifiable Deterministic Metric)</strong></th><th><strong>오라클 통과를 위한 허용 임계치 (Thresholds for Oracle Pass)</strong></th></tr></thead><tbody>
<tr><td><strong>Friendly (친근한)</strong></td><td>일상적이고 대화하는 듯한 편안한 문체 사용 필수, 학술적이거나 딱딱한 표현 지양</td><td>Heylighen &amp; Dewaele 기반 F-score (문맥 의존적 격식성 지수)</td><td><span class="math math-inline">30 \le \text{F-score} \le 50</span> (적절한 수준의 비격식성과 구어체 유지 강제)</td></tr>
<tr><td><strong>Helpful (유용한)</strong></td><td>명확하고 직관적인 정보 전달, 복잡한 전문 용어나 긴 수식어구의 사용 최소화</td><td>Flesch-Kincaid Grade Level (가독성 평가 지수)</td><td><span class="math math-inline">\text{Grade Level} \le 8.0</span> (미국 기준 중학교 2학년도 쉽게 이해할 수 있는 독해 난이도 유지)</td></tr>
<tr><td><strong>Confident (자신감 있는)</strong></td><td>행동을 촉구하는 능동태 사용 권장, 책임을 회피하려는 수동태 사용 금지</td><td>Syntactic Analysis 구문 분석 트리의 수동태(Passive Voice) 구문 비율 추출</td><td><span class="math math-inline">\text{Passive Voice Ratio} \le 5\%</span> (전체 문장에서 수동태 비중 엄격 통제)</td></tr>
<tr><td><strong>Respectful (존중하는)</strong></td><td>사용자의 감정을 자극하는 공격적 언어, 건방지거나 무례한 명령조의 언어 사용 절대 금지</td><td>딥러닝 기반 Politeness Classifier Score (정중성 확률)</td><td><span class="math math-inline">P(\text{Polite} \vert \text{Text}) \ge 0.85</span> (높은 수준의 존중 언어 사용 보장)</td></tr>
</tbody></table>
<p>위의 매핑 테이블에서 확인할 수 있듯이, 마케팅 전략 기획자가 문서를 통해 정의한 “자신감 있는(Confident)“이라는 지극히 추상적인 느낌은, 코드를 다루는 소프트웨어 엔지니어링 관점에서는 “전체 문장 트리 구조에서 수동태 구문의 비율이 5% 이하이어야 한다“는 명확하고 반박의 여지가 없는 결정론적 검증 조건으로 치환되어 기능한다. 이렇게 명확한 지표로 정의된 제약 조건들은 곧바로 자동화된 테스트 스위트(Test Suite)의 검증 스크립트에 통합되며, 생성형 AI가 사용자에게 응답을 출력하기 직전 결과물이 실시간 배포 요건을 완벽히 충족하는지 판단하는 절대적인 문지기(Gatekeeper) 기준선으로 동작하게 된다.</p>
<h3>5.2 RAG(Retrieval-Augmented Generation) 시스템 및 프롬프트 주입을 통한 톤앤매너의 사전 제어</h3>
<p>테스트 오라클을 통해 생성된 응답을 사후적으로 엄격히 평가하고 걸러내는 방어 기제만큼이나 비즈니스 효율성 측면에서 중요한 것은, 애초에 모델이 텍스트를 생성하는 단계에서부터 오라클의 기준을 완벽하게 통과할 수 있도록 의도한 톤앤매너를 구사하게끔 사전 유도하는 것이다. 기업 내부 문서를 활용하는 검색 증강 생성(Retrieval-Augmented Generation, RAG) 시스템 아키텍처를 전략적으로 활용하면 특정 톤을 생성 과정에 강제하는 메커니즘을 보다 지능적이고 견고하게 설계할 수 있다.</p>
<p>RAG 파이프라인의 백엔드에서 AI 에이전트에게 은밀하게 주입되는 시스템 프롬프트(System Prompt)는 단순히 질문에 답변해야 할 사실적 배경 데이터(Context)만을 수십 단어로 제공하는 데 그치지 않는다. 이 프롬프트는 에이전트가 어떤 성격의 페르소나를 장착하고 어떠한 톤앤매너로 답변을 전개해야 하는지에 대한 정밀한 행동 강령(Guardrails)을 수백 단어에 걸쳐 구체적이고 촘촘하게 명시한다. 예를 들어 프롬프트 설계자는 시스템 프롬프트 상단에 “너는 세계 최고 수준의 전문성을 지닌 LinkedIn의 프리미엄 고객 지원 챗봇이다. 너의 톤은 언제나 Confident하고 Professional해야만 한다. 답변을 작성할 때 Flesch-Kincaid 가독성은 8 레벨을 넘지 않도록 간결하게 구성하고, 문장의 능동성을 저해하는 수동태 사용을 최대한 피하라“와 같이, 테스트 오라클이 나중에 검증할 정량화된 지표 자체를 프롬프트의 직접적인 제약 조건으로 하드코딩하여 입력한다.</p>
<p>더 나아가, 단순히 지시문만 주는 제로샷(Zero-shot) 프롬프팅을 넘어, 과거 수년간 인간 우수 상담원이 직접 작성하여 해당 브랜드의 철학과 톤앤매너가 완벽하게 체화되어 있는 실제 이메일 로그나 모범 응답 사례(Golden Examples)를 RAG의 벡터 데이터베이스에서 실시간으로 검색하여 Few-shot 예제 형식으로 모델에게 함께 제공한다. 이렇게 하면 강력한 패턴 인식 능력을 지닌 LLM은 제공된 예제 문장들이 지닌 미세한 형태소 단위의 뉘앙스, 길이, 그리고 어투를 즉각적으로 분석하여 복제(Replicate)하고, 자신이 생성할 텍스트를 이와 완벽하게 유사한 스타일로 출력하도록 스스로의 파라미터 분포를 미세 조정(In-context learning)하게 된다.</p>
<p>이러한 선제적인 ‘생성 전 제어(Pre-generation control)’ 기법과, 생성 직후 출력물을 무자비하게 심사하는 ‘사후 검증(Post-generation evaluation)’ 오라클을 CI/CD 파이프라인 내에서 강력하게 결합하면, 근본적인 비결정성(Nondeterminism)이 지배하여 통제가 불가능해 보이는 LLM 생태계 환경 내에서도 사용자와 기업 모두가 온전히 신뢰할 수 있는 엔터프라이즈급 AI 소프트웨어를 구축하는 것이 가능해진다.</p>
<h2>6. 톤앤매너 검증용 결정론적 정답지(Deterministic Ground Truth) 구축 시의 실무적 한계와 극복 방안</h2>
<p>지금까지 살펴본 바와 같이 언어의 톤앤매너를 수치적으로 완벽하게 분해하여 소프트웨어 테스트 자동화 생태계에 편입시키는 것은 모델의 안전성을 확보하는 매우 훌륭한 공학적 방법론이다. 그러나 이러한 이상적인 이론들을 실제 거대한 트래픽이 몰리는 비즈니스 현장에 배포하려 할 때, 엔지니어들은 예상치 못한 여러 가지 실무적 한계와 극단적인 예외 상황(Edge Cases)에 직면하게 된다. 이러한 장애물들을 체계적으로 해결하지 못하면, 모델의 응답이 정상적임에도 불구하고 오라클의 설정이 부적절하여 끊임없이 테스트 실패를 보고하는 거짓 음성(False Failures) 사태가 발생하며, 이는 개발 조직의 생산성과 모델 배포 속도를 심각하게 저하시키는 기술 부채로 전락한다.</p>
<h3>6.1 단일 임계치(Threshold) 설정의 딜레마와 동적 임계치 할당 기법</h3>
<p>소프트웨어 시스템 내에서 오라클을 구축할 때 겪게 되는 가장 치명적인 난관은, 앞서 설정한 정량적 임계치(예를 들어, F-score가 50 초과여야 한다는 절대 규칙)가 모든 대화의 문맥과 상황에 일괄적으로, 동일하게 적용될 수는 없다는 본질적인 언어의 유연성 문제이다. “A Question of Style” 연구를 비롯한 광범위한 언어학적 분석 결과들에 따르면, 적절한 격식성이나 정중성의 기준점은 서비스가 속한 도메인(Domain)이나 발화가 이루어지는 구체적인 장르(Genre)에 따라 그 기본 스펙트럼의 위치 자체가 완전히 다르게 나타난다. 예를 들어, 고객의 소중한 자산을 다루는 보수적인 금융 도메인에서의 VIP 고객 응대 챗봇과, 편안한 즐거움을 제공해야 하는 캐주얼 게임 도메인 내의 NPC 챗봇은 동일하게 ’친절함’을 목표로 설계되었다 하더라도 그 표현 방식에서 요구되는 기본 격식성(Formality)의 임계치 수치가 하늘과 땅 차이만큼 크게 벌어질 수밖에 없다.</p>
<p>따라서 다양한 사용자의 입력이 쏟아지는 범용 AI 시스템에서 하드코딩된 단일한 고정 임계치(Static Threshold)를 사용하여 오라클을 획일적으로 동작시키는 것은 대단히 위험한 안티 패턴이다. 이러한 딜레마를 극복하기 위해 최신 AI 소프트웨어 엔지니어링에서는 **동적 임계치 할당(Dynamic Threshold Allocation)**이라는 지능형 라우팅 기법을 파이프라인 전면에 도입한다. 이 시스템은 사용자가 입력한 텍스트 프롬프트를 메인 LLM이 처리하기 전에, 가벼운 앞단 모델(Front-end Classifier)을 활용하여 사용자의 현재 감성 상태(Sentiment), 문제의 심각도 수준, 그리고 긴급도를 실시간으로 먼저 분류(Classification)한다. 그 후, 판단된 컨텍스트 상황에 가장 적합한 각기 다른 정답지 풀(Golden Dataset Pool)과 허용 임계치 범위를 오라클 스위트 내에서 동적으로 매핑하여 불러온 뒤, 생성된 최종 응답의 테스트 통과 기준을 탄력적으로 적용하는 방식이다.</p>
<p>예를 들어, 고객이 서비스 장애로 인해 강하게 분노와 불만을 표출하는(Negative Sentiment &amp; High Urgency) 위기 상황을 감지했다면, 챗봇이 단순히 ‘친절하고 캐주얼한’ 평소의 페르소나를 유지하는 것은 오히려 고객의 분노를 증폭시킬 수 있다. 따라서 시스템은 이 특정 세션에 한정하여 챗봇 응답 오라클의 Formality와 Politeness 임계치 기준선을 평소보다 훨씬 엄격하게 상향 조정하고, 사과와 책임 인정을 담은 무거운 톤앤매너로 전환하여 응답을 필터링하도록 동적 룰셋을 발동시켜야 한다. 이를 통해 시스템은 사용자의 감정 흐름을 거스르지 않으면서도 브랜드의 평판 리스크를 최소화하는 유연성을 획득한다.</p>
<h3>6.2 컴파일 가능성(Compilability) 검증 모델의 자연어 오라클 차용을 통한 하이브리드 통제</h3>
<p>비정형적이고 확률적인 자연어의 톤앤매너를 수치 기반의 오라클만으로 완벽하게 제어하려는 시도는 필연적으로 모호성을 수반한다. 이를 기술적으로 완벽하게 통제하고 보완하기 위해, 최근 소프트웨어 품질 보증 분야에서는 코파일럿(Copilot)과 같은 코드 생성 AI 모델들의 정확성을 평가할 때 주로 사용하는 ’컴파일 가능성 체크(Compilability Check)’의 확정적 개념을 자연어 처리의 품질 평가 영역으로 직접 차용하려는 혁신적인 시도들이 이루어지고 있다.</p>
<p>코드 생성 AI 모델의 성능을 평가하는 오라클은 매우 명확하다. 생성된 파이썬(Python)이나 C++ 코드 조각은 세미콜론 하나, 들여쓰기 공간 하나라도 문법에 어긋나게 작성되면 컴파일러가 무자비하게 에러(Syntax Error)를 뱉어내고 실행을 거부하므로, 컴파일러 그 자체가 완벽하게 바이너리한(1 or 0) 결과를 반환하는 ’절대적인 결정론적 오라클’로 기능하게 된다. 자연어 생성 검증 파이프라인에서도 이와 완전히 유사한 사상을 도입하여, **문법적 정합성(Grammaticality) 및 필수 정책 준수 여부를 검사하는 파서(Policy Parser)**를 별도의 엄격한 자연어 컴파일러처럼 최전방에서 동작하게 만드는 구조를 설계한다.</p>
<p>즉, 텍스트가 지닌 전체적인 감성이나 스타일의 뉘앙스는 앞서 논의한 회귀 모델이나 VibeCheck를 통해 연속적인 점수(Continuous Score)로 유연하게 평가하되, 동시에 텍스트 내의 치명적인 비즈니스 금지어(Blacklist)가 단 하나라도 포함되어 있는지 여부, 필수적으로 포함해야 하는 안내 문구(Whitelist)가 누락되지는 않았는지 여부, 또는 사과문을 작성할 때 반드시 충족해야 하는 논리 구조적 요소(예: 무엇을 잘못했는지 명시, 재발 방지 대책 포함 여부)가 하나라도 결여되었는지를 정규 표현식(Regular Expression)이나 심볼릭 로직을 활용하여 기계적으로 스캔한다. 이러한 핵심 정책적 규칙들은 타협의 여지가 없으므로, 통과(1) 혹은 실패(0)라는 정확한 이진값(Binary)만을 가차 없이 반환하는 엄격한 **결정론적 하드 오라클 레이어(Deterministic Hard Oracle Layer)**를 거치도록 시스템을 아키텍처링하는 것이다.</p>
<p>이러한 이중 구조, 즉 ’부드러운 정성적 평가(Soft Continuous Evaluation)’와 ’엄격한 정량적 정책 검사(Hard Binary Compilation Check)’가 상호 보완적으로 작동하도록 오라클을 결합 설계하면, 확률론적 생성 모델이 지닌 감성 표현의 모호성을 최소화하면서도 결코 타협할 수 없는 엔터프라이즈 시스템의 신뢰성과 무결성을 극대화할 수 있는 강력한 토대를 마련할 수 있다.</p>
<p>생성형 AI 기술의 도래는 소프트웨어 인터페이스의 응답을 차갑게 고정된 메뉴와 텍스트에서 살아 숨 쉬고 교감하는 인간 친화적 대화로 진화시켰다. 그러나 이러한 경이로운 진화는 역설적으로 소프트웨어의 신뢰성을 담보하기 위한 품질 보증(Quality Assurance, QA) 및 테스트 오라클 구축의 난이도와 복잡성을 전례 없이 기하급수적으로 폭발시켰다. 만약 과거에는 단순히 문학적이고 주관적이며 예술적인 감각의 영역으로만 치부되어 오던 ’톤앤매너(Tone &amp; Manner)’라는 정성적 요소를 수학과 공학의 영역으로 가져와 완벽하게 통제해 내지 못한다면, 기업은 공들여 쌓아온 브랜드 평판의 일순간적인 저하와 예측 불가능한 사용자 경험 훼손이라는 치명적인 기술적 리스크에 상시 무방비로 직면하게 될 것이다.</p>
<p>지금까지 본 절에서 심층적으로 해부한 톤앤매너의 정량화 시도와 다양한 오라클 모델들은, 텍스트가 내재한 모호성(Ambiguity)이라는 생성 AI의 거대한 본질적 특성에 맞서 수학적, 논리적, 알고리즘적 통제력을 확고히 구축하려는 컴퓨터 과학자들과 엔지니어들의 치열하고 눈물겨운 노력의 결정체이다. 텍스트 내 품사의 통계적 분포와 빈도 계산에 철저하게 기반한 고전적이면서도 견고한 형태소 공식에서부터 출발하여, 의미론적 보존 여부와 스타일의 전이 강도를 고차원 임베딩 공간에서 동시에 측정해 내는 최첨단 텍스트 스타일 변환(TST) 평가 매트릭스, 그리고 더 나아가 초거대 언어 모델 그 자체를 다차원적 스코어링의 심판관으로 기용하여 인간의 미묘한 직관마저 수치화해 내는 VibeCheck 프레임워크에 이르기까지, 정성적인 가치들을 결정론적 오라클의 판단 체계로 치환해 내는 눈부신 진보의 궤적을 확인하였다.</p>
<p>현대의 AI 기반 소프트웨어를 다루는 엔지니어와 아키텍트 집단은 이러한 지표들을 시스템에 단편적이거나 실험적으로 도입하는 수준에 그쳐서는 안 된다. 자사의 고유한 브랜드 가이드라인과 비즈니스 철학을 철저하게 해체하고 수치적인 데이터로 재구축하여, 이를 CI/CD 배포 파이프라인 내의 핵심적인 통합 테스트(Integration Test) 단계에 완전히 자동화된 방어 룰셋(Rule-set)으로 영구 편입시켜야만 한다. 인간의 창의성과 고도의 언어적 융통성이 필수적으로 요구되는 지극히 유동적인 자연어 생성의 영역일지라도, 그 기저의 시스템 작동 원리에는 예외 없는 결정론적 제약과 정밀한 수치적 평가라는 강철 같은 소프트웨어 엔지니어링의 대원칙이 확고히 자리 잡아야만 비로소 인간과 사회가 전적으로 신뢰하고 의존할 수 있는 안전한 AI 소프트웨어 아키텍처를 완성할 수 있을 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Natural Language Processing of Sentiments Identified in Patient Comments Associated with Less Than Top-Rated Care - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC11930458/</li>
<li>Content Alignment Assessment – Analyzing Sentiment, Tone, and Embedding Consistency, https://thatware.co/content-alignment-assessment/</li>
<li>Extractive Text Summarization Using Formality of Language - IEEE Xplore, https://ieeexplore.ieee.org/iel8/8782664/10834807/11130639.pdf</li>
<li>trinker/formality - GitHub, https://github.com/trinker/formality</li>
<li>formality function - RDocumentation, https://www.rdocumentation.org/packages/qdap/versions/2.4.6.1/topics/formality</li>
<li>Capturing Formality in Speech Across Domains and Languages - University of Edinburgh Research Explorer, https://www.research.ed.ac.uk/files/370167239/Capturing_Formality_BHATTACHARYA_DOA17052023_AFV_CC_BY.pdf</li>
<li>Briggs-Myer Personality Prediction with NLP | by Faaez Riaz - Medium, https://medium.com/@faaezriaz/briggs-myer-personality-prediction-with-nlp-ec7b30a08942</li>
<li>A Question of Style: A Dataset for Analyzing Formality on Different Levels - ACL Anthology, https://aclanthology.org/2023.findings-eacl.42.pdf</li>
<li>Findings of the Association for Computational Linguistics: EACL 2023 - ACL Anthology, https://aclanthology.org/volumes/2023.findings-eacl/</li>
<li>Groups of paraphrases ordered from most formal (left) to least formal (right), as described in Section 4.1. - ResearchGate, https://www.researchgate.net/figure/Groups-of-paraphrases-ordered-from-most-formal-left-to-least-formal-right-as_tbl1_284185908</li>
<li>An Empirical Analysis of Formality in Online Communication | Request PDF - ResearchGate, https://www.researchgate.net/publication/329977404_An_Empirical_Analysis_of_Formality_in_Online_Communication</li>
<li>From Chat to Academia: Calibrating Formality in Low-Resource Languages - IEEE Xplore, https://ieeexplore.ieee.org/iel8/6287639/11323511/11343771.pdf</li>
<li>An Empirical Analysis of Formality in Online Communication - ACL Anthology, https://aclanthology.org/Q16-1005.pdf</li>
<li>[1306.6078] A Computational Approach to Politeness with Application to Social Factors, https://arxiv.org/abs/1306.6078</li>
<li>A computational approach to politeness with application to social factors - Stanford NLP Group, https://nlp.stanford.edu/pubs/politeness.pdf</li>
<li>Frustrated, Polite, or Formal: Quantifying Feelings and Tone in Email - ResearchGate, https://www.researchgate.net/publication/325445440_Frustrated_Polite_or_Formal_Quantifying_Feelings_and_Tone_in_Email</li>
<li>Computational Politeness in Natural Language Processing: A Survey - arXiv, https://arxiv.org/html/2407.12814v1</li>
<li>Contextualized Embeddings for Enriching Linguistic Analyses on Politeness - ACL Anthology, https://aclanthology.org/2020.coling-main.198.pdf</li>
<li>The politeness Package: Detecting Politeness in Natural Language - The R Journal - R-project.org, https://journal.r-project.org/articles/RJ-2018-079/RJ-2018-079.pdf</li>
<li>Everything You Ever Wanted to Know About AI Agents - Boomi, https://boomi.com/blog/everything-you-ever-wanted-to-know-about-ai-agents/</li>
<li>The Art of the AI Insult: More Than Just a Joke? - Skywork.ai, https://skywork.ai/skypage/en/The-Art-of-the-AI-Insult-More-Than-Just-a-Joke/1976575227766435840</li>
<li>Text Style Transfer: An Introductory Overview - arXiv.org, https://arxiv.org/html/2407.14822v1</li>
<li>A Survey of Text Style Transfer: Applications and Ethical Implications - arXiv, https://arxiv.org/html/2407.16737v1</li>
<li>Style Transfer from Non-Parallel Text by Cross-Alignment - ResearchGate, https://www.researchgate.net/publication/317205288_Style_Transfer_from_Non-Parallel_Text_by_Cross-Alignment</li>
<li>Style Transfer from Non-Parallel Text by Cross-Alignment, http://www.cs.cmu.edu/~jeanoh/16-785/papers/shen-N2017-style.pdf</li>
<li>Deep Learning for Text Style Transfer: A Survey | Computational Linguistics | MIT Press, https://direct.mit.edu/coli/article/48/1/155/108845/Deep-Learning-for-Text-Style-Transfer-A-Survey</li>
<li>Multiple Text Style Transfer by using Word-level Conditional Generative Adversarial Network with Two-Phase Training - ACL Anthology, https://aclanthology.org/D19-1366/</li>
<li>Tunable Stylization Guidance - Emergent Mind, https://www.emergentmind.com/topics/tunable-stylization-guidance</li>
<li>Generative Text Style Transfer for Improved Language Sophistication - CS230, http://cs230.stanford.edu/projects_winter_2020/reports/32069807.pdf</li>
<li>Quick Estimate of Information Decomposition for Text Style Transfer - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC9955131/</li>
<li>Reinforced Rewards Framework for Text Style Transfer - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC7148230/</li>
<li>Text Style Transfer Evaluation - arXiv, https://arxiv.org/html/2502.04718v1</li>
<li>VibeCheck: Discover &amp; Quantify Qualitative Differences in Large Language Models - arXiv, https://arxiv.org/html/2410.12851v1</li>
<li>VIBECHECK: DISCOVER &amp; QUANTIFY QUALITATIVE DIFFERENCES IN LARGE LANGUAGE MODELS - ICLR Proceedings, https://proceedings.iclr.cc/paper_files/paper/2025/file/acbfe708197ff78ad04cc1beb1710979-Paper-Conference.pdf</li>
<li>VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models, https://www.researchgate.net/publication/385010119_VibeCheck_Discover_and_Quantify_Qualitative_Differences_in_Large_Language_Models</li>
<li>VibeCheck: Discover &amp; Quantify Qualitative Differences in Large Language Models - arXiv, https://arxiv.org/html/2410.12851v6</li>
<li>VibeCheck: Discover &amp; Quantify Qualitative Differences in Large Language Models - arXiv, https://arxiv.org/html/2410.12851v3</li>
<li>A Survey of Reinforcement Learning from Human Feedback - arXiv, https://arxiv.org/html/2312.14925v1</li>
<li>Towards More Data Efficient Deep Learning - UCL Discovery - University College London, https://discovery.ucl.ac.uk/id/eprint/10199689/1/Hayes__Thesis.pdf</li>
<li>ProPerSim: Developing Proactive and Personalized AI Assistants through User-Assistant Simulation - arXiv, https://arxiv.org/html/2509.21730v1</li>
<li>The Reality Check: Our Journey to AI-Powered Productivity | by Young Kwon | Medium, https://firstlove0.medium.com/the-reality-check-our-journey-to-ai-powered-productivity-9bd7931ce6c9?source=rss——ai-5</li>
<li>What Is Brand Voice? How To Create One With Examples &amp; Tips - SurveyMonkey, https://www.surveymonkey.com/learn/market-research/what-is-brand-voice-why-brand-tone-matters/</li>
<li>5 Brand Tone of Voice Examples to Help You Find Your Brand Personality - Grammarly, https://www.grammarly.com/business/learn/brand-tone-examples/</li>
<li>Brand Tone of Voice: Guide with Real Examples - Lokalise Blog, https://lokalise.com/blog/how-to-adapt-your-tone-of-voice-for-new-markets/</li>
<li>Brand Tone of Voice Examples: 12 Companies That Nail It - Iconic Fox, https://iconicfox.com.au/brand-tone-of-voice-examples/</li>
<li>RAG vs. Fine-Tuning: How to Choose - Generative AI - Oracle, https://www.oracle.com/artificial-intelligence/generative-ai/retrieval-augmented-generation-rag/rag-fine-tuning/</li>
<li>Microsoft 365 Copilot: Transforming Efficiency &amp; Recapturing Sanity - Kyle David Group, https://kyledavidgroup.com/articles/copilot-transforming-efficiency/</li>
<li>Training Deterministic Parsers with Non-Deterministic Oracles | Request PDF, https://www.researchgate.net/publication/303157008_Training_Deterministic_Parsers_with_Non-Deterministic_Oracles</li>
<li>Online Learning of Latent Linguistic Structure with Approximate Search, https://d-nb.info/1177800608/34</li>
<li>A Question of Style: A Dataset for Analyzing Formality on Different Levels - ResearchGate, https://www.researchgate.net/publication/373817661_A_Question_of_Style_A_Dataset_for_Analyzing_Formality_on_Different_Levels</li>
<li>CGGNet: Compiler-Guided Generation Network for Smart Contract Data Augmentation - IEEE Xplore, https://ieeexplore.ieee.org/iel8/6287639/10380310/10597542.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>