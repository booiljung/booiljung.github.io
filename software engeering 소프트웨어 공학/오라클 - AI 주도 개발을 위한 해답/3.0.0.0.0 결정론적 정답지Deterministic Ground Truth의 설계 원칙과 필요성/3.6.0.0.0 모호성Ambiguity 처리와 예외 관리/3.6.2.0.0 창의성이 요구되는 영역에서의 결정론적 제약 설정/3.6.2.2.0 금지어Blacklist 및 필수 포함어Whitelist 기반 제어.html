<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:3.6.2.2 금지어(Blacklist) 및 필수 포함어(Whitelist) 기반 제어</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>3.6.2.2 금지어(Blacklist) 및 필수 포함어(Whitelist) 기반 제어</h1>
                    <nav class="breadcrumbs"><a href="../../../../../index.html">Home</a> / <a href="../../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../../index.html">Chapter 3. 결정론적 정답지(Deterministic Ground Truth)의 설계 원칙과 필요성</a> / <a href="../index.html">3.6 모호성(Ambiguity) 처리와 예외 관리</a> / <a href="index.html">3.6.2 창의성이 요구되는 영역에서의 결정론적 제약 설정</a> / <span>3.6.2.2 금지어(Blacklist) 및 필수 포함어(Whitelist) 기반 제어</span></nav>
                </div>
            </header>
            <article>
                <h1>3.6.2.2 금지어(Blacklist) 및 필수 포함어(Whitelist) 기반 제어</h1>
<p>인공지능(AI), 특히 대규모 언어 모델(Large Language Model, LLM)을 엔터프라이즈 소프트웨어 시스템에 통합할 때 직면하는 가장 근본적인 난제는 출력의 ’비결정성(Nondeterminism)’이다. 전통적인 소프트웨어 엔지니어링 생태계는 동일한 입력 상태에 대해 항상 동일하고 예측 가능한 출력을 반환하는 결정론적 계약(Deterministic Contract)을 기반으로 구축된다. 단위 테스트(Unit Test), 통합 테스트(Integration Test), 그리고 시스템의 무결성을 검증하는 자동화된 오라클(Oracle)은 모두 이러한 확정적인 정답지(Deterministic Ground Truth)의 존재를 전제로 한다. 그러나 텍스트를 자기회귀(Auto-regressive) 방식으로 생성하는 LLM은 본질적으로 확률적(Probabilistic) 알고리즘에 의존하므로, 단순히 자연어 프롬프트를 정교하게 다듬는 것만으로는 완벽한 결정론을 보장할 수 없다.</p>
<p>프롬프트 엔지니어링은 모델의 어텐션(Attention) 가중치에 간접적인 영향을 미치는 ’제안’에 불과하며, 모델은 언제든 확률적 요인이나 악의적인 컨텍스트 주입에 의해 지시를 우회할 수 있다. 창의성이 요구되는 문장 생성 과정에서 환각(Hallucination)이 발생하거나, 엄격한 스키마가 요구되는 JSON 및 SQL 생성 과정에서 단 하나의 괄호를 누락하는 등의 문제는 시스템 전체의 치명적인 장애로 이어진다. 더욱 심각한 것은 민감한 개인정보(PII) 유출이나, 분산 시스템 내에서 자율 AI 에이전트가 승인되지 않은 파괴적인 명령(예: 프로덕션 데이터베이스 삭제)을 생성하는 보안 위협이다.</p>
<p>이러한 확률적 불확실성을 통제하고 AI 시스템에 절대적인 보안 경계(Absolute Boundaries)를 부여하기 위해 고안된 가장 직접적이고 수학적인 제어 방식이 토큰 수준(Token-level)의 ‘금지어(Blacklist)’ 및 ‘필수 포함어(Whitelist)’ 기반 제어 메커니즘이다. 이 기법은 사후 필터링이나 프롬프트 지시에 의존하지 않고, 모델이 다음 토큰을 예측하는 신경망의 가장 깊은 출력 계층인 로짓(Logits) 산출 단계에 직접 개입한다. 수학적인 편향(Bias)을 주입하여 특정 토큰의 생성 확률을 강제로 <span class="math math-inline">0%</span>로 만들거나 <span class="math math-inline">100%</span>로 고정함으로써, 비결정적인 AI 모델을 결정론적 오라클의 통제 하에 두는 이 방법론의 심층적인 원리와 시스템 구현 체계를 분석한다.</p>
<h2>1.  로짓 바이어스(Logit Bias)와 소프트맥스(Softmax)의 수학적 기초</h2>
<p>금지어와 필수 포함어 기반 제어가 어떻게 AI의 출력을 확정적으로 구속할 수 있는지 이해하기 위해서는, 먼저 언어 모델이 텍스트를 생성하는 토큰화(Tokenization) 과정과 확률 분포 산출의 수학적 구조를 규명해야 한다.</p>
<h3>1.1  토큰화와 원시 로짓(Raw Logits)의 정의</h3>
<p>LLM은 인간의 언어를 문자나 단어 단위가 아닌, 모델이 처리할 수 있는 고유한 정수 ID로 매핑된 ’토큰(Token)’의 시퀀스로 분해하여 이해한다. 모델의 어휘 사전(Vocabulary, <span class="math math-inline">\Sigma</span>)은 수만 개에서 수십만 개의 독립적인 토큰으로 구성된다. 수학적으로 언어 모델은 <span class="math math-inline">n</span>개의 토큰으로 이루어진 시퀀스 <span class="math math-inline">w_1 \dots w_n</span>에 대한 결합 확률 분포 <span class="math math-inline">P</span>를 조건부 확률의 곱으로 정의한다.<br />
<span class="math math-display">
P(w_1 \dots w_n) = \prod_{i=1}^n P(w_i \vert w_{1:i-1})
</span><br />
주어진 문맥(Context)을 기반으로 다음 위치에 올 토큰을 예측할 때, 신경망의 마지막 선형 계층(Linear layer)은 어휘 사전 내의 모든 토큰에 대해 원시 예측 점수를 계산한다. 이 정규화되지 않은(Unnormalized) 점수 벡터를 로짓(Logits, <span class="math math-inline">Z</span>)이라고 부른다. 로짓은 확률이 아니며, <span class="math math-inline">-\infty</span>에서 <span class="math math-inline">+\infty</span> 사이의 실수 값을 갖는다. 특정 토큰에 할당된 로짓 값이 클수록, 모델은 해당 토큰이 문맥상 논리적으로 뒤따를 가능성이 높다고 판단한 것이다.</p>
<h3>1.2  소프트맥스(Softmax) 활성화 함수를 통한 확률 변환</h3>
<p>원시 로짓 벡터 <span class="math math-inline">Z</span>를 해석 가능하고 샘플링 가능한 확률 분포로 변환하기 위해 소프트맥스(Softmax) 활성화 함수가 적용된다. 전체 <span class="math math-inline">K</span>개의 클래스(토큰 어휘 사전의 크기)에 대하여, 특정 토큰 <span class="math math-inline">k</span>가 선택될 조건부 확률 <span class="math math-inline">P(y=k \vert x; \theta)</span>는 다음과 같이 정의된다.<br />
<span class="math math-display">
P(y=k \vert x; \theta) = \frac{\exp(z_k)}{\sum_{j=1}^K \exp(z_j)}
</span><br />
이 수식에서 분자는 특정 토큰 <span class="math math-inline">k</span>의 로짓에 대한 지수 함수(Exponential function)이며, 분모는 모든 토큰의 지수 함수 값의 합이다. 이 연산을 통해 변환된 확률 벡터의 총합은 항상 1이 되며, 모델은 이 확률 분포를 바탕으로 그리디 디코딩(Greedy Decoding) 또는 다항 샘플링(Multinomial Sampling) 등의 후처리 방식을 거쳐 최종적으로 하나의 토큰을 선택한다.</p>
<h3>1.3  로짓 바이어스(Logit Bias)를 통한 수학적 개입</h3>
<p>블랙리스트와 화이트리스트 제어는 바로 이 소프트맥스 함수가 적용되기 직전의 단계에서 이루어진다. 시스템은 원시 로짓 벡터 <span class="math math-inline">Z</span>의 특정 토큰 인덱스에 인위적인 편향 값(Bias, <span class="math math-inline">b</span>)을 더하여 모델의 고유한 예측을 수학적으로 왜곡(Distortion)한다. 특정 토큰 <span class="math math-inline">i</span>에 대한 새로운 조작된 로짓 값 <span class="math math-inline">z_i&#39;</span>는 다음과 같이 계산된다.<br />
<span class="math math-display">
z_i&#39; = z_i + b_i
</span><br />
이러한 로짓 수준의 개입은 런타임에 모델의 가중치(Weights)를 수정하지 않고도 디코딩 행동을 정밀하게 제어할 수 있는 강력한 메커니즘을 제공한다. 소프트웨어 테스팅과 오라클 구축 관점에서 이는 모델의 환각이나 일탈을 근본적으로 차단하는 스위치가 된다.</p>
<ul>
<li><strong>블랙리스트 구현 (금지어 제어):</strong> 금지하고자 하는 토큰에 대해 편향 값 <span class="math math-inline">b_i</span>를 극단적인 음수(예: OpenAI API 기준 <span class="math math-inline">-100</span>)로 설정한다. 소프트맥스 연산에서 <span class="math math-inline">\exp(z_i - 100)</span>은 <span class="math math-inline">0</span>에 한없이 수렴하게 된다. 결과적으로 해당 토큰이 선택될 확률은 사실상 <span class="math math-inline">0%</span>로 소멸하며, 모델은 프롬프트에 아무리 강력한 유도 문맥이 존재하더라도 물리적으로 해당 토큰을 출력할 수 없게 된다.</li>
<li><strong>화이트리스트 구현 (필수 포함어 제어):</strong> 강제하고자 하는 특정 토큰 집합에 대해 편향 값 <span class="math math-inline">b_i</span>를 극단적인 양수(예: <span class="math math-inline">+100</span>)로 설정하거나, 반대로 허용된 토큰을 제외한 나머지 모든 <span class="math math-inline">\Sigma</span> 내의 토큰들에 극단적인 음수를 부여하여 마스킹(Masking)한다. 이 경우 허용된 토큰들의 확률의 합만이 분모를 구성하게 되어, 지정된 토큰들 중에서만 배타적 선택(Exclusive selection)이 강제된다.</li>
</ul>
<h2>2.  금지어(Blacklist) 제어의 실전 적용과 한계</h2>
<p>금지어 기반 제어는 특정 문자열, 토큰 패턴, 또는 민감한 정보가 출력에 나타나는 것을 원천적으로 차단하는 네거티브 제약(Negative Constraint) 전략이다. 이는 AI 소프트웨어 환경에서 ’결코 발생해서는 안 되는 상태’를 정의하고 보장하기 위한 가장 확실한 보안 오라클로 작용한다.</p>
<h3>2.1  토큰 변형과 모호성(Ambiguity) 처리의 복잡성</h3>
<p>단어 기반의 블랙리스트를 토큰 기반의 LLM 아키텍처에 적용할 때 가장 빈번하게 발생하는 함정은 토크나이저(Tokenizer)의 분절 방식에서 비롯된다. 인간의 언어로는 동일한 단어일지라도, 대소문자의 차이, 접두사로 붙는 공백(Space)의 유무, 심지어 특수문자와의 결합 상태에 따라 전혀 다른 토큰 ID로 매핑된다.</p>
<p>예를 들어, 텍스트 생성 중 “whisper“라는 단어의 출현을 금지하고자 할 때, 엔지니어는 단순히 “whisper“의 토큰 ID에만 <span class="math math-inline">-100</span>의 로짓 바이어스를 주어서는 안 된다. “ whisper” (앞에 공백 포함), “Whisper”, “ WHISPER“, 그리고 “wh”, “isper“처럼 쪼개져서 생성될 수 있는 모든 부분 단어(Subword)의 토큰 ID 조합을 색인화하여 모조리 블랙리스트에 추가해야 한다. 만약 단 하나의 변형 토큰이라도 차단 목록에서 누락된다면, 확률적 디코딩 과정은 그 우회 경로를 찾아내어 결국 금지된 단어를 생성해내고 만다. 이러한 토큰 매핑의 모호성은 동적 어휘 사전이나 다국어를 지원하는 시스템에서 블랙리스트 유지보수 비용을 기하급수적으로 증가시키는 요인이 된다.</p>
<h3>2.2  민감 정보(PII) 누출 방지와 프라이버시 오라클</h3>
<p>거대 언어 모델은 방대한 훈련 데이터를 처리하는 과정에서 사용자 이름, 식별 번호, 비밀번호, 의료 데이터 등 개인의 민감 정보(Personally Identifiable Information, PII)를 내재적으로 암기할 수 있다. 디코딩 과정 중 특정 문맥이 트리거되면 모델은 이러한 정보를 의도치 않게 누출할 위험이 있으며, 이는 기업 소프트웨어 환경에서 치명적인 법적 책임을 수반한다.</p>
<p>기존의 차등 프라이버시(Differential Privacy, DP) 미세 조정 기법은 데이터의 재구성을 어렵게 만들지만 모델의 전반적인 언어 생성 성능을 크게 저하시키는 부작용이 있다. 대안으로 사후 편집(Post-hoc redaction) 방식의 정규식 필터링이 사용되기도 하지만, 이는 처리 지연 시간(Latency)을 발생시키며 모델이 이미 내부 메모리에서 민감 정보를 표면으로 끌어올렸다는 근본적인 취약점을 남긴다.</p>
<p>반면 토큰 수준의 동적 블랙리스트 제어는 상태 비저장(Stateless) 디코딩 타임 메커니즘으로 작동하여, PII 패턴의 접두사(Prefix)가 발견되는 즉시 관련된 후속 토큰들의 로짓을 억제한다. 생성 자체를 원천 봉쇄하기 때문에 검열 로직의 지연을 최소화하면서도 증명 가능한 프라이버시(Provable privacy guarantees)를 제공할 수 있다.</p>
<h3>2.3  탈독성(Detoxification)과 자체 제약 디코딩(DSCD)</h3>
<p>블랙리스트 개념은 단순한 토큰 차단을 넘어 확률 분포의 동적 조정을 통한 모델 정렬(Alignment) 연구로 진화하고 있다. 기존의 안전 디코딩 기법들은 유해한 발언이나 할각을 억제하기 위해 외부 모델이나 대규모 검증 데이터셋에 의존하여 오버헤드가 컸다.</p>
<p>최근 주목받는 ’자기 제한적 디코딩(Detoxification with Self-Constrained Decoding, DSCD)’과 같은 방법론은 외부 제약에 의존하지 않고 모델 내부의 계층(Layer) 정보를 활용한다. 이 알고리즘은 출력 생성 중 안전을 담당하는 내부 계층의 다음 토큰 분포를 강화하고, 독성이나 환각을 유발하는 계층의 분포를 약화시키는 방식으로 로짓 바이어스를 동적으로 조정한다. 이는 모델의 생성 유창성(Fluency)을 훼손하지 않으면서도 유해한 출력으로 향하는 로짓 벡터 공간을 수학적으로 수축(Shrinking)시켜, 플러그 앤 플레이(Plug-and-play) 방식으로 안전한 LLM 배포를 가능하게 한다.</p>
<h2>3.  필수 포함어(Whitelist) 제어와 구조화된 출력(Structured Outputs) 강제</h2>
<p>블랙리스트가 시스템의 붕괴를 막는 방패라면, 화이트리스트(Whitelist) 제어는 AI의 출력을 다른 소프트웨어 모듈이 정확하게 파싱(Parsing)하고 처리할 수 있도록 보장하는 엄격한 파이프라인 역할을 한다. 모델이 오직 사전에 정의된 토큰의 집합만을 사용하여 텍스트를 생성하도록 강제하는 포지티브 제약(Positive Constraint)은 소프트웨어 테스트 관점에서 볼 때 가장 훌륭한 확정적 오라클(Deterministic Oracle)이다.</p>
<h3>3.1  모호성 제거 및 엄격한 데이터 유효성 검사</h3>
<p>AI를 기존 소프트웨어 시스템의 컴포넌트로 사용할 때, 자유 형식의 자연어(Free-form text) 출력은 통합 테스트(Integration testing)의 가장 큰 적이다. API 호출을 위한 매개변수 생성, 분석을 위한 SQL 쿼리 생성, 시스템 간 데이터 교환을 위한 JSON 생성 등의 작업에서 모델은 확률적 변동성으로 인해 쉼표를 누락하거나, 닫는 괄호를 잊어버리거나, 스키마에 정의되지 않은 여분의 문자열(예: “Sure, here is the JSON you requested:”)을 덧붙이는 경우가 빈번하다.</p>
<p>이러한 출력은 전체 시스템의 파싱 오류(Parsing error)를 유발한다. 이 문제를 회피하기 위해 과거에는 거부 샘플링(Rejection Sampling) 기법을 사용했다. 모델이 텍스트를 끝까지 생성하게 한 뒤 문법 검사기(Oracle)를 통과하지 못하면 출력을 폐기하고 성공할 때까지 계속 다시 생성하게 하는 방식이다. 그러나 이 접근법은 토큰 생성 비용을 막대하게 낭비하고, 특히 복잡한 제약 조건에서는 무한 루프에 빠질 위험이 있어 실제 프로덕션 환경에 적용하기 어렵다.</p>
<p>이러한 낭비를 막고 데이터 정합성을 보장하기 위해 런타임 화이트리스트 제어가 도입된다. 예를 들어, 모델이 <code>{"status": </code> 다음에 값을 생성해야 할 때, 제어 시스템은 허용된 상태 값(예: <code>"SUCCESS"</code>, <code>"ERROR"</code>)을 구성하는 토큰들을 제외한 어휘 사전(<span class="math math-inline">\Sigma</span>) 내의 모든 토큰에 <span class="math math-inline">-100</span>의 로짓 바이어스를 적용하여 마스킹한다. 이를 통해 소프트웨어는 LLM의 출력이 사전에 정의된 데이터 타입과 형식을 100% 준수할 것임을 컴파일 타임에 확신할 수 있으며, 테스트 환경에서는 단순한 문자열 일치(String Match)나 Enum 타입 비교만으로도 확정적인 어서션(Assertion)을 구성할 수 있다.</p>
<h3>3.2  자율 AI 에이전트를 위한 계약 기반 접근 제어</h3>
<p>LLM 기반의 자율 에이전트(Autonomous Agents)가 분산 시스템 내에서 파일 시스템에 접근하거나 API를 호출할 때, 기존의 역할 기반 접근 제어(RBAC) 모델은 한계를 드러낸다. RBAC는 호출자의 권한만을 확인할 뿐, 생성된 요청이 문맥상 안전하거나 합리적인지(Reasonable)는 판단하지 못한다. 2025년 발생한 Replit의 프로덕션 데이터베이스 삭제 사고나 GitHub MCP(Model Context Protocol) 서버의 취약점 사례는, 권한을 가진 에이전트가 환각이나 프롬프트 주입 공격에 의해 파괴적인 행동을 자율적으로 수행할 때의 위험성을 여실히 보여준다.</p>
<p>이러한 ’합리성 간극(Reasonableness Gap)’을 극복하기 위해, 로짓 수준의 화이트리스트 기반 제어가 스마트 컨트랙트(Smart Contract)와 유사한 ’계약 기반 접근 제어(Contract-Based Access Control)’의 핵심 기술로 부상했다. 보안 계층은 에이전트가 호출할 수 있는 도구(Tool)나 API 엔드포인트 명칭의 토큰에 대해 문맥에 따라 동적으로 화이트리스트를 구성한다. 만약 에이전트가 사용자의 악의적 지시(“모든 저장소를 읽어라”)에 의해 승인되지 않은 도구를 호출하려 시도하더라도, 해당 도구를 지칭하는 토큰 생성 자체가 확률적으로 완전히 차단(Blacklisted)되어 있으므로 익스플로잇은 실패하게 된다. 언어의 의도나 뉘앙스를 해석하려 애쓰는 대신, 수학적이고 결정론적인 규칙(Deterministic Guardrails)으로 토큰 출력을 억제하는 것은 프롬프트 주입 공격을 무력화하는 가장 절대적인 방어선이다.</p>
<h2>4.  제한적 디코딩(Constrained Decoding) 알고리즘의 최신 동향</h2>
<p>특정 단어를 억제하는 단일 토큰 수준의 정적(Static) 로짓 바이어스 조작은 한계가 명확하다. 정규 표현식, JSON 스키마, 프로그래밍 언어의 구문 트리와 같이 문맥에 따라 허용되는 토큰의 집합이 매 순간 달라지는 복잡한 구조적 제약을 강제하기 위해서는, 모델의 현재 디코딩 상태를 실시간으로 추적하며 동적으로 화이트리스트와 블랙리스트를 교체하는 ‘제한적 디코딩(Constrained Decoding)’ 프레임워크가 필요하다.</p>
<h3>4.1  FSM과 정규식 기반 인덱싱 알고리즘</h3>
<p>이 분야에 근본적인 도약을 가져온 연구는 Willard와 Louf가 발표한 <em>“Efficient Guided Generation for Large Language Models” (2023)</em> 이다. 기존에는 생성된 텍스트가 정규식을 만족하는지 확인하기 위해 매 스텝마다 전체 어휘 사전(약 5만~10만 개의 토큰)을 루프 돌며 파서(Parser)를 통과시켜야 했으므로, 검증 비용이 <span class="math math-inline">\mathcal{O}(N)</span>에 달해 실시간 생성이 불가능에 가까웠다.</p>
<p>해당 논문은 이 문제를 해결하기 위해 정규 표현식이나 문맥 자유 문법(CFG)을 유한 상태 기계(Finite-State Machine, FSM)로 사전 변환(Pre-compile)하는 방법론을 제시했다. 알고리즘의 동작 방식은 다음과 같다.</p>
<ol>
<li>개발자가 제공한 제약 조건(예: 이메일 정규식)을 기반으로 FSM을 생성한다.</li>
<li>모델의 거대한 어휘 사전 <span class="math math-inline">\Sigma</span>의 모든 토큰을 분석하여, FSM의 각 상태(State)에서 어느 토큰으로 전이(Transition)가 가능한지 사전에 매핑하여 인덱스를 구축한다.</li>
<li>추론 시 모델이 한 토큰을 생성할 때마다 FSM은 상태를 전이하며, 인덱스를 참조하여 다음 상태에서 허용되는 유효 토큰(Whitelist)들의 집합을 <span class="math math-inline">\mathcal{O}(1)</span>의 평균 비용으로 즉각 도출한다.</li>
<li>유효하지 않은 나머지 모든 토큰(Blacklist)에 부울 마스크(Boolean mask, <span class="math math-inline">m</span>)를 적용하여 로짓 값을 음의 무한대로 차단한다.</li>
</ol>
<p>Outlines, Guidance와 같은 라이브러리들은 이 알고리즘을 구현하여 모델의 추론 속도 저하 없이 완벽한 구문 준수를 달성해냈다.</p>
<h3>4.2  구조적 강제가 유발하는 확률 분포 왜곡과 ASAp 알고리즘</h3>
<p>그러나 문법 제약 기반 디코딩(Grammar-Constrained Decoding, GCD)은 완벽하지 않다. 그리디(Greedy)하게 다음 토큰의 유효성만을 검사하여 마스킹하는 방식은, 언어 모델이 학습 데이터를 통해 획득한 원래의 확률 분포를 심각하게 왜곡시키는 부작용을 낳는다.</p>
<p>Park 등의 논문 *“Grammar-Aligned Decoding” (NeurIPS 2024)*은 이 문제를 체계적으로 비판했다. GCD 알고리즘은 오직 ’현재 상태에서 문법에 맞는 토큰인가?’만을 판별한다. 그 결과, 당장은 문법에 맞지만 모델의 지식상으로는 극도로 확률이 낮은 경로로 진입하게 되어, 결국 생성되는 코드나 텍스트의 품질이 크게 떨어지는 현상이 발생한다.</p>
<p>이러한 분포의 불일치를 해결하기 위해 연구진은 ’문법 정렬 디코딩(Grammar-Aligned Decoding, GAD)’이라는 개념을 제안하고, <strong>ASAp (Adaptive Sampling with Approximate expected futures)</strong> 알고리즘을 도입했다. ASAp는 단순히 문법에 어긋나는 토큰의 로짓을 깎아내는 데 그치지 않고, 특정 출력 접두사(Prefix)가 미래에 문법적으로 완결된 문장으로 이어질 확률인 ’예상 미래 문법성(Expected Future Grammaticality, EFG)’을 근사적으로 계산한다.</p>
<p>수학적으로, ASAp는 이전 샘플 출력의 정보를 활용해 EFG를 귀납적으로 업데이트하며, 마스킹된 토큰으로 인해 잃어버린 확률 질량(Probability mass)을 보정해 나간다. 반복적인 샘플링을 통해 ASAp가 산출하는 제한된 모델 분포 <span class="math math-inline">\tilde{Q}_{ASAp}</span>는, 어떠한 제약도 없는 본래의 언어 모델 분포 <span class="math math-inline">P</span>와 주어진 문법 <span class="math math-inline">\mathcal{G}</span> 사이의 조건부 확률 분포 <span class="math math-inline">P(\cdot \vert w \in \mathcal{L}(\mathcal{G}))</span>와의 Kullback-Leibler 발산(KL Divergence)을 최소화하며 점진적으로 <span class="math math-inline">0</span>에 수렴하게 된다. 즉, 소프트웨어 시스템은 엄격한 화이트리스트 스키마를 100% 보장받으면서도, 모델이 가장 자연스럽고 지능적으로 생성할 수 있는 고품질의 추론 결과를 얻게 되는 것이다.</p>
<h3>4.3  비통사적(Non-syntactic) 규칙 제어: 논리적 제약 디코딩</h3>
<p>제한적 디코딩의 경계는 단순한 JSON 구문이나 정규 표현식을 넘어 수학적, 논리적 법칙을 제약 조건으로 편입하는 단계로 진화했다. Ma와 Hu의 연구 *“Logically Constrained Decoding” (ACL 2025)*은 체스 게임 규칙과 명제 논리 증명(Propositional resolution proofs) 같은 의미론적(Semantic) 세계 모델(World Model)을 디코딩 과정에 통합했다.</p>
<p>기존의 방식이 ’괄호의 개수’를 맞추는 데 집중했다면, 이 접근법은 외부의 심볼릭 제약 엔진(Symbolic Constraint Engine)을 통해 ’상태(State)’를 추적한다. 예를 들어 모델이 체스 기보를 출력할 때, 심볼릭 엔진은 현재 보드에 배치된 기물의 위치(World Model)를 계산하여, 체스 룰 상 절대 불가능한 ’불법적인 수(Illegal moves)’에 해당하는 토큰 집합을 식별한다. 이 토큰들은 즉시 블랙리스트 처리되어 모델의 로짓에서 마스킹되며, 모델은 오직 체스 룰에 부합하는 ‘합법적인 다음 토큰(Legal Next Tokens)’ 풀 안에서만 자유롭게 생성을 진행한다.</p>
<p>이러한 논리적 제약 디코딩(Logically Constrained Decoding)은 복잡한 논리 구조나 타입 안전성(Type safety)이 요구되는 코드 생성 작업에서 LLM의 환각을 원천적으로 배제하고 컴파일 오류를 획기적으로 낮추는 결과를 보여준다. 이는 오라클이 단순히 생성된 결과물의 정오를 사후에 판별하는 것을 넘어, 디코딩 프로세스 자체에 결합되어 모델을 결정론적 논리의 궤도 안에 가두는 능동적 통제 시스템으로 작용할 수 있음을 증명한다.</p>
<h2>5.  대규모 추론 엔진(Inference Engine)에서의 아키텍처 구현</h2>
<p>수학적 알고리즘과 FSM 구조가 아무리 정교하더라도, 이를 대규모 트래픽을 처리하는 프로덕션 환경의 GPU 추론 엔진에 구현하는 것은 별개의 아키텍처적 과제다. 제한적 디코딩 로직은 모델이 토큰을 하나 생성할 때마다 개입해야 하므로, 병목(Bottleneck) 현상을 유발하기 매우 쉽다.</p>
<h3>5.1  vLLM의 LogitsProcessor와 상태 동기화</h3>
<p>산업 표준으로 자리 잡은 오픈소스 추론 엔진 vLLM은 토큰 확률 분포를 런타임에 동적으로 조정하기 위해 상태 보존형(Stateful) <code>LogitsProcessor</code> 아키텍처를 제공한다.</p>
<p>vLLM은 높은 처리량(Throughput)을 달성하기 위해 개별 요청(Request)을 병렬로 처리하는 연속 배치(Continuous Batching) 방식을 사용한다. 따라서 로짓 프로세서 역시 개별 단위가 아닌 배치 단위의 거대한 로짓 텐서에 작용해야 한다. 추론의 매 스텝마다 모델 엔진이 <code>(num_requests) x (vocab_size)</code> 차원의 원시 로짓 텐서를 출력하면, 시스템은 스케줄러의 변동 사항(요청의 추가, 완료, 취소 등)에 맞추어 <code>update_state()</code> 메서드를 호출해 로짓 프로세서의 내부 상태를 동기화한다.</p>
<p>동기화가 완료되면, 로짓 프로세서는 배치 내에서 화이트리스트/블랙리스트 기능이 활성화된 특정 요청의 행(Row)을 식별하고, FSM 상태에 기반하여 계산된 마스크를 해당 행의 로짓 벡터에 적용한다. 예를 들어, <code>process_token</code> 함수 내에서 제약에 위배되는 토큰 ID들의 값을 <code>logits = -9999.999</code>와 같이 덮어쓰는(In-place modification) 방식이다. 변환이 완료된 텐서만이 소프트맥스를 거쳐 샘플링에 사용된다.</p>
<p>그러나 기존의 Outlines가 채택한 단일 토큰 단위의 FSM 방식은 한계가 명확했다. 각 요청마다 파이썬 레벨에서 거대한 어휘 사전을 순회하며 마스크를 계산하는 작업은 무거웠고, 한 요청의 마스크 연산이 완료될 때까지 배치 내의 다른 요청들이 블로킹(Blocking)되는 현상이 발생했다. 이는 첫 토큰 생성 시간(Time-To-First-Token, TTFT)을 극심하게 저하시켰다.</p>
<h3>5.2  Pushdown Automaton(PDA)과 XGrammar를 통한 병목 돌파</h3>
<p>이러한 단일 토큰 FSM의 성능적 한계를 극복하기 위해 vLLM 생태계는 XGrammar와 같은 차세대 컴파일 백엔드를 도입했다. XGrammar의 핵심 혁신은 FSM 대신 ’푸시다운 오토마타(Pushdown Automaton, PDA)’를 채택한 것이다.</p>
<p>단일 스텝 전이만을 허용하는 FSM과 달리, PDA는 내부적으로 스택(Stack) 메모리를 유지하며 문맥 자유 문법(CFG)을 표현하는 여러 하위 FSM들의 집합체로 구성된다. 이러한 재귀적(Recursive) 구조 덕분에 PDA는 단일 추론 스텝 내에서 문법적 규칙에 따라 여러 상태를 건너뛰는 다중 상태 전이(Jump-forward decoding)가 가능해져 파싱 속도를 비약적으로 끌어올린다.</p>
<p>더 나아가 XGrammar는 파이썬(Python) 환경에서 수행되던 무거운 문법 컴파일 및 마스크 연산 로직을 하위 레벨인 C/C++로 오프로딩(Off-loading)하고, <code>pthread</code>를 이용해 멀티스레딩 환경에서 병렬로 마스크를 계산한다. 계산된 비트 마스크(Bit-mask)는 텐서 연산을 통해 단일 프로세스에서 모든 GPU 워커(Worker)로 신속하게 브로드캐스팅되어 기존 방식 대비 최대 100배 이상의 압도적인 속도 향상을 입증했다. 이러한 아키텍처 레벨의 최적화는 거대 모델이 극도로 복잡한 JSON 스키마 제약을 준수하면서도 실시간 서비스가 가능하도록 만드는 근간이 된다.</p>
<h3>5.3  파이프라인 보안 오라클로서의 NVIDIA NeMo Guardrails</h3>
<p>프레임워크 수준에서 블랙리스트 제어를 비즈니스 로직에 통합한 대표적인 사례는 NVIDIA의 NeMo Guardrails 시스템이다. 이 시스템은 LLM 애플리케이션(RAG, 챗봇 등)과 사용자 사이에 위치하여 대화의 맥락을 모니터링하고 정책 위반을 제어하는 오케스트레이션(Orchestration) 플랫폼이다.</p>
<p>NeMo Guardrails는 단순히 하드코딩된 단어 차단을 넘어, 언어 모델 자체를 검열기(Self-Checking Judge)로 활용하는 하이브리드 오라클 구조를 채택한다. 예를 들어 <code>self_check_input</code> 레일(Rail)은 사용자의 입력이 프롬프트 주입 공격이나 탈옥(Jailbreak)을 시도하는지 판단하기 위해 별도의 평가용 LLM 프롬프트를 백그라운드에서 실행한다. 이 평가 모델의 출력을 기반으로 시스템은 결정론적 판단을 내린다. 만약 유해성(Toxicity)이 감지되거나 사전에 정의된 금지 주제(예: 정치적 발언)로 대화가 벗어나려 할 경우, 프레임워크는 즉각적으로 해당 대화 경로(Dialog path)를 강제로 변경하거나 응답 생성을 차단(Blacklist)하는 프로그램 가능한 가드레일을 실행한다.</p>
<p>이는 확률론적 추론 기능(AI 판단)과 결정론적 실행 기능(코드 기반 차단)이 결합된 하이브리드 제어의 실증적 사례이며, 기업이 엔터프라이즈 환경에 AI를 배포할 때 규정 준수(Compliance)를 보장할 수 있는 방패 역할을 수행한다.</p>
<h2>6.  결정론적 정답지(Oracle) 설계의 핵심 원칙 요약</h2>
<p>로짓 수준의 수학적 편향 삽입, 진보된 제한적 디코딩(PDA, ASAp) 알고리즘, 그리고 고성능 시스템 아키텍처의 통합은 종착적으로 소프트웨어 테스팅을 위한 ‘결정론적 오라클(Deterministic Oracle)’ 구축으로 이어진다. 테스트 자동화의 관점에서 볼 때, 비결정성(Nondeterminism)을 제거하는 금지어 및 필수 포함어 기반 제어는 다음의 핵심 원칙을 통해 시스템의 신뢰성을 극대화한다.</p>
<ol>
<li><strong>환각(Hallucination)에 의한 모호성 원천 제거:</strong> 자유 형식 생성 환경에서 모델이 생성하는 예측 불가한 자연어 문자열은 자동화 테스트 코드의 어서션(Assertion)을 무력화한다. 필수 포함어(Whitelist) 제어를 통해 모델의 출력 포맷을 엄격한 열거형(Enum)이나 확정적인 JSON 스키마로 강제함으로써, “데이터가 존재하지 않음“과 같은 모호한 문장을 <code>STATUS_CODE: 404</code>와 같은 확정적이고 테스트 가능한 상태 값으로 치환할 수 있다. 오라클은 더 이상 의미론적 유사성(Semantic similarity)을 평가할 필요 없이, 이진(Binary) 비교를 통해 성공 여부를 결정한다.</li>
<li><strong>보안 경계의 수학적 증명:</strong> 스마트 컨트랙트에 영감을 받은 ‘계약 기반 접근 제어(Contract-Based Access Control)’ 환경에서, AI 에이전트가 승인되지 않은 도구(Tool)를 호출하는 행위는 금지어(Blacklist) 마스킹을 통해 원천적으로 봉쇄된다. 이는 적대적 테스트(Adversarial Test) 과정에서 확률적 운에 의해 공격이 성공하거나 실패하는 불확실성을 제거하며, 시스템의 보안 위협 가능성이 ’수학적으로 0’임을 확정적으로 보증한다.</li>
<li><strong>모델 성능(Likelihood)과 규율의 융합:</strong> 단기적인 로짓 억제(GCD)가 초래할 수 있는 확률 분포의 왜곡을 인지하고, ASAp와 같은 진보된 샘플링 알고리즘을 도입하여 모델이 훈련 데이터로부터 학습한 본연의 지식(Probability mass)을 보존해야 한다. 이를 통해 엄격한 형식적 제약(Constraints) 하에서도 품질 저하(Low-quality)가 발생하지 않는 고도화된 정답지 데이터셋(Golden Dataset)을 구축할 수 있다.</li>
</ol>
<p>AI를 활용한 소프트웨어 개발 생태계에서 모델의 무한한 생성 자유도는 혁신의 원천인 동시에 치명적인 기술 부채(Technical Debt)를 야기한다. 로짓 바이어스(Logit Bias)를 기반으로 한 금지어와 필수 포함어 제어는 언어 모델이 단순히 단어를 확률적으로 뱉어내는 앵무새가 아니라, 엔지니어가 수학적으로 통제 가능한 ’결정론적 계산기’로서 기능할 수 있도록 돕는 가장 근본적이고 필수적인 제동 장치이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Engineering Accountability: Constructing Deterministic AI in a Probabilistic World | by Frank Morales Aguilera | AI Simplified in Plain English | Feb, 2026 | Medium, https://medium.com/ai-simplified-in-plain-english/engineering-accountability-constructing-deterministic-ai-in-a-probabilistic-world-d2d07685e91c</li>
<li>Understanding Deterministic AI: A Superpower for Cloud Infrastructure Security - Gomboc, https://www.gomboc.ai/blog/understanding-deterministic-ai-a-superpower-for-cloud-infrastructure-security</li>
<li>Testing AI Systems: Handling the Test Oracle Problem - DEV Community, https://dev.to/qa-leaders/testing-ai-systems-handling-the-test-oracle-problem-3038</li>
<li>You need deterministic guardrails for AI agent security - Civic.com, https://www.civic.com/resources/deterministic-guardrails-for-ai-agent-security</li>
<li>Beyond Free-Form Text: How Constrained Decoding is Reshaping Structured Generation in LLMs | by Brijesh Nambiar | Medium, https://medium.com/@brijeshrn/beyond-free-form-text-how-constrained-decoding-is-reshaping-structured-generation-in-llms-5f7a38bef259</li>
<li>Adaptive Token-Weighted Differential Privacy for LLMs: Not All Tokens Require Equal Protection - arXiv, https://arxiv.org/html/2509.23246v1</li>
<li>Building Deterministic Guardrails for Autonomous Agents - DEV Community, https://dev.to/suhavi/building-deterministic-guardrails-for-autonomous-agents-1c5a</li>
<li>Customizing LLM Output: Post-Processing Techniques - Neptune.ai, https://neptune.ai/blog/customizing-llm-output-post-processing-techniques</li>
<li>Token-Level Control in OpenAI Models: A Developer’s Guide to Logit Bias - Medium, https://medium.com/cyprox-io/token-level-control-in-openai-models-a-developers-guide-to-logit-bias-6fcc04a8a41f</li>
<li>From Logits to Tokens. Introduction | by Aditya Modi | Medium, https://medium.com/@adimodi96/from-logits-to-tokens-9a36feab9cab</li>
<li>From Logits to Probabilities: Understanding Softmax in Neural Networks | by Deepankar Singh | AI-Enthusiast | Medium, https://medium.com/ai-enthusiast/from-logits-to-probabilities-understanding-softmax-in-neural-networks-3ebea2e95cfe</li>
<li>arXiv:2504.05410v1 [cs.CL] 7 Apr 2025, https://arxiv.org/pdf/2504.05410</li>
<li>Grammar-Aligned Decoding - arXiv, https://arxiv.org/html/2405.21047v3</li>
<li>Understanding Logits And Their Possible Impacts On Large Language Model Output Safety, https://www.ioactive.com/understanding-logits-and-their-possible-impacts-on-large-language-model-output-safety/</li>
<li>Softmax Regression - Deep Learning, http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/</li>
<li>GUEST POST - Crafting Unique AI Personas: Harnessing the Power of Logit Bias in Large Language Models | Semantic Kernel - Microsoft Dev Blogs, https://devblogs.microsoft.com/semantic-kernel/guest-post-crafting-unique-ai-personas-harnessing-the-power-of-logit-bias-in-large-language-models/</li>
<li>Using logit bias to alter token probability with the OpenAI API, https://help.openai.com/en/articles/5247780-using-logit-bias-to-alter-token-probability-with-the-openai-api</li>
<li>What is Logit Bias and how to use it, https://www.vellum.ai/llm-parameters/logit-bias</li>
<li>Can someone please help me figure out understand logit bias? (API) : r/OpenAI - Reddit, https://www.reddit.com/r/OpenAI/comments/1bm6lsl/can_someone_please_help_me_figure_out_understand/</li>
<li>Constrained Decoding for Privacy-Preserving LLM Inference - NeurIPS, https://neurips.cc/virtual/2025/133163</li>
<li>DSCD: Large Language Model Detoxification with Self-Constrained Decoding - arXiv, https://arxiv.org/html/2510.13183v1</li>
<li>Token Highlighter: Inspecting and Mitigating Jailbreak Prompts for Large Language Models | Proceedings of the AAAI Conference on Artificial Intelligence, https://ojs.aaai.org/index.php/AAAI/article/view/34943</li>
<li>Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms - arXiv, https://arxiv.org/html/2503.24191v1</li>
<li>Grammar-Aligned Decoding - NeurIPS, https://proceedings.neurips.cc/paper_files/paper/2024/file/2bdc2267c3d7d01523e2e17ac0a754f3-Paper-Conference.pdf</li>
<li>Grammar-Aligned Decoding - arXiv, https://arxiv.org/html/2405.21047v1</li>
<li>[2302.01488] Perfect is the enemy of test oracle - arXiv.org, https://arxiv.org/abs/2302.01488</li>
<li>Select AI Agent Concepts - Oracle Help Center, https://docs.oracle.com/en-us/iaas/autonomous-database-serverless/doc/select-ai-agents-concepts.html</li>
<li>Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access - ACL Anthology, https://aclanthology.org/2024.acl-short.23.pdf</li>
<li>dottxt-ai/outlines: Structured Outputs - GitHub, https://github.com/dottxt-ai/outlines</li>
<li>[NLG] Outlines — Efficient Guided Generation for Large Language Models (Willard &amp; Louf 2023) - Youngrok Song, https://id2thomas.medium.com/nlg-outlines-efficient-guided-generation-for-large-language-models-willard-louf-2023-3c9463543901</li>
<li>structured decoding, a guide for the impatient, https://aarnphm.xyz/posts/structured-decoding</li>
<li>Guiding LLMs The Right Way: Fast, Non-Invasive Constrained Generation - arXiv, https://arxiv.org/html/2403.06988v1</li>
<li>Debate-Driven Multi-Agent LLMs for Phishing Email Detection - arXiv, https://arxiv.org/html/2503.22038v1</li>
<li>ABS: enforcing constraint satisfaction on generated Sequences via Automata-guided Beam Search - arXiv, https://arxiv.org/html/2506.09701v2</li>
<li>Grammar-Aligned Decoding - NeurIPS, https://proceedings.neurips.cc/paper_files/paper/2024/hash/2bdc2267c3d7d01523e2e17ac0a754f3-Abstract-Conference.html</li>
<li>Grammar-Aligned Decoding - OpenReview, https://openreview.net/forum?id=5G7ve8E1Lu</li>
<li>8 0Z0Z0Z0Z 7 S0a0skop 6 0ZpZ0o0Z 5 ZpZ0Z0Z0 4 0O0Z0Z0Z 3 ZpONZ0O0 2 0Z0Z0O0O 1 Z0Z0ZKZ0 - ACL Anthology, https://aclanthology.org/2025.mathnlp-main.11.pdf</li>
<li>Franklin Ma’s Portfolio, https://www.franklinma.me/cv.pdf</li>
<li>Logically Constrained Decoding - ResearchGate, https://www.researchgate.net/publication/397419142_Logically_Constrained_Decoding</li>
<li>Logits Processors - vLLM, https://docs.vllm.ai/en/latest/design/logits_processors/</li>
<li>How to use logits_processors · Issue #1728 · vllm-project/vllm - GitHub, https://github.com/vllm-project/vllm/issues/1728</li>
<li>Structured Decoding in vLLM: a gentle introduction, https://blog.vllm.ai/2025/01/14/struct-decode-intro.html</li>
<li>Structured Decoding in vLLM: A Gentle Introduction - BentoML, https://www.bentoml.com/blog/structured-decoding-in-vllm-a-gentle-introduction</li>
<li>Managing NeMo Guardrails — NVIDIA NIM Operator, https://docs.nvidia.com/nim-operator/latest/guardrail.html</li>
<li>Securing GenAI with AI Runtime Security and NVIDIA NeMo Guardrails - Palo Alto Networks, https://www.paloaltonetworks.com/blog/network-security/securing-genai-with-ai-runtime-security-and-nvidia-nemo-guardrails/</li>
<li>NeMo Guardrails | NVIDIA Developer, https://developer.nvidia.com/nemo-guardrails</li>
<li>Guardrail Catalog — NVIDIA NeMo Guardrails Library Developer Guide, https://docs.nvidia.com/nemo/guardrails/latest/configure-rails/guardrail-catalog.html</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>