<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:3.6.1 '정답이 없는 경우'에 대한 정답지 정의</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>3.6.1 '정답이 없는 경우'에 대한 정답지 정의</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 3. 결정론적 정답지(Deterministic Ground Truth)의 설계 원칙과 필요성</a> / <a href="index.html">3.6 모호성(Ambiguity) 처리와 예외 관리</a> / <span>3.6.1 '정답이 없는 경우'에 대한 정답지 정의</span></nav>
                </div>
            </header>
            <article>
                <h1>3.6.1 ’정답이 없는 경우’에 대한 정답지 정의</h1>
<p>소프트웨어 공학의 패러다임이 명시적인 규칙 기반(Rule-based) 시스템에서 대규모 데이터 공간의 확률 분포를 학습하는 인공지능(AI) 기반 시스템으로 이동함에 따라, 소프트웨어 테스트와 품질 보증(QA)의 핵심인 ’오라클 문제(Test Oracle Problem)’는 전례 없는 기술적 난제로 부상했다. 전통적인 소프트웨어 테스트 환경에서 오라클은 입력에 대한 기대 출력(Expected Output)을 결정론적으로 검증하는 절대적인 기준 역할을 수행한다. 그러나 대규모 언어 모델(LLM)을 비롯한 생성형 AI 시스템은 비결정론적(Nondeterministic) 속성을 내포하고 있으며, 동일한 입력에 대해서도 온도(Temperature) 파라미터나 샘플링 확률에 따라 미세하게 다르거나 완전히 새로운 출력을 생성할 수 있다. 이러한 환경에서 정답지(Ground Truth)를 정의하는 것은 단순히 ’올바른 텍스트 문자열’을 하드코딩하는 것을 넘어선다.</p>
<p>특히 AI 시스템이 직면하는 가장 치명적인 결함 중 하나인 환각(Hallucination)은 모델이 자신의 지식 경계(Knowledge Boundary)를 인지하지 못하고, 답변할 수 없거나 답변해서는 안 되는 상황에서도 그럴듯한 거짓 정보를 생성할 때 발생한다. 따라서 AI 기반 소프트웨어 개발의 테스트 파이프라인에서 결정론적 정답지를 구축할 때 가장 심혈을 기울여야 하는 영역은 역설적으로 ’정답이 존재하지 않는 경우(Unanswerable Cases)’를 어떻게 식별하고, 평가하고, 시스템이 ’기권(Abstention)’하도록 강제할 것인가에 대한 엄밀한 정의다. 본 절에서는 모델이 ’모른다’고 말해야 할 때를 정의하는 메타데이터의 구조화, 선택적 예측(Selective Prediction)의 수학적 프레임워크, 적대적 데이터셋의 구축 원리, 그리고 이를 자동화된 오라클로 변환하는 결정론적 검증 체계에 대해 심도 있게 논의한다.</p>
<h2>1.  지식 경계(Knowledge Boundary)와 답변 불가성(Unanswerability)의 본질</h2>
<p>결정론적 테스트 오라클이 ’정답 없음’을 판별하기 위해서는 무엇이 특정 질문을 답변 불가능한 상태로 만드는지에 대한 엄밀한 분류 체계(Taxonomy)가 선행되어야 한다. 단순히 ’알 수 없음(I don’t know)’이라는 텍스트 라벨을 부여하는 것만으로는 근본적인 오라클 룰을 작성할 수 없다. 테스트 공학의 관점에서는 기권의 근본 원인을 식별하는 메타데이터가 정답지에 명시적으로 포함되어야 하며, 이를 통해 모델이 실패한 것인지 아니면 의도된 안전 상태(Safe State)로 진입한 것인지를 평가할 수 있다.</p>
<h3>1.1  답변 불가성의 6대 원인 분류</h3>
<p>현대 LLM의 기권(Abstention) 능력을 평가하는 선도적인 연구인 논문 <em>AbstentionBench</em>는 실세계의 복잡한 사용자 질의가 지닌 답변 불가성을 6가지 구체적인 시나리오로 분류한다. 사용자 질의가 지닌 다양한 ‘답변 불가’ 속성이 테스트 오라클 내에서 어떻게 명시적이고 결정론적인 기권 상태로 매핑되는지 살펴보면, 구조화되지 않은 사용자 입력은 먼저 평가 노드(필터 또는 분류기)를 거치게 된다. 여기서 질의는 다음의 6가지 구체적인 답변 불가 사유 중 하나로 분기되며, 최종적으로 ’안전한 기권(Safe Abstention)’이라는 엄격히 정의된 결정론적 정답지 상태로 수렴하게 된다.</p>
<ol>
<li><strong>지식의 부재 (Answer Unknown):</strong> 인류의 문서화된 지식 내에 합의된 정답이 존재하지 않는 질문이다. 아무리 풍부한 문맥(Context)을 검색 증강 생성(RAG) 메커니즘을 통해 추가로 제공하더라도 근본적으로 답변할 수 없는 속성을 지닌다.</li>
<li><strong>잘못된 전제 (False Premise):</strong> 부정확하거나 거짓인 진술을 바탕으로 구성된 질문이다. 예를 들어 “1969년 달 착륙 세트장을 감독한 사람은 누구인가?“라는 질문은 전제 자체가 거짓이다. 결정론적 시스템에서 모델은 질문에 답변하기 전에 전제의 오류를 지적하고 기권 경로를 타야 한다.</li>
<li><strong>정보의 시효 만료 (Stale):</strong> 모델의 사전 학습(Pre-training) 시점 이후에 발생한 사건을 다루어, 모델 내부의 매개변수적 지식(Parametric knowledge)이 이미 만료된 경우이다. 외부 도구 호출이 불가능한 상태라면 오라클은 이를 기권으로 처리하도록 정답지를 구성해야 한다.</li>
<li><strong>주관적 해석 (Subjective):</strong> 올바른 답변이 개인의 관점, 가치관, 경험에 따라 완전히 달라지는 질문이다. 보편타당한 ’단일 진실(Single Ground Truth)’이 존재하지 않으므로 결정론적 비즈니스 로직을 테스트하는 시스템에서는 기권으로 처리해야 안전하다.</li>
<li><strong>맥락의 불충분 (Underspecified Context):</strong> 질문 자체는 문법적으로 명확하나, 답변을 도출하기 위해 필요한 핵심 세부 정보(예: 특정 연도, 지역, 대상)가 누락된 경우이다. 정보가 보완된다면 답변이 가능해진다는 점에서 지식의 부재와 구분된다.</li>
<li><strong>의도의 모호성 (Underspecified Intent):</strong> 사용자가 무엇을 묻고자 하는지 의도 자체가 불분명하거나 논리적 형태를 갖추지 못한 경우이다.</li>
</ol>
<p>이러한 분류 체계는 AI 시스템의 지식 경계 개념과 직접적으로 맞닿아 있다. 모델의 지식 경계란 모델이 사실적 기반 위에서 생성할 수 있는 정보의 한계를 의미한다. 이 경계를 넘어서는 순간 모델은 훈련 데이터에서 학습한 지식이 부족함에도 불구하고 표면적인 통계적 패턴에 의존하여 낮고 불확실한 확률 분포 사이에서 강제로 텍스트를 샘플링하게 되며, 이는 필연적으로 환각을 유발한다.</p>
<h3>1.2  반개방형 질의(Semi-open-ended Questions)와 모호한 오답의 식별</h3>
<p>지식 경계를 측정하고 평가하기 위해 가장 까다로운 테스트 케이스는 완전히 터무니없는 질문(Trivial OOD)이 아니라, 부분적으로 답변이 가능해 보이는 반개방형 질의(Semi-open-ended questions)이다. 반개방형 질의는 모델이 쉽게 대답할 수 있는 답변(Easy answerable answers)과 지식 경계를 벗어난 어렵고 모호한 오답(Hard and unpopular answers)이 혼재되어 있는 질의 공간을 형성한다.</p>
<p>논문 <em>Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering</em>에 따르면, 모델이 어떤 정보에 대해 모호함(Ambiguity)을 느끼는지 수학적으로 식별하기 위해 모델 임베딩의 유사역행렬(Pseudo-inverse of model embedding)을 활용하는 기법이 사용된다. 이 기법은 블랙박스 LLM의 생성 확률 분포를 근사하기 위해 오픈소스 보조 모델의 임베딩 공간에서 가장 가까운 의미적 표현(Nearest semantic representation)을 계산한다. 이후 높은 확률을 가진 지배적인(흔한) 정답들의 생성 확률을 인위적으로 감소시킴으로써, 모델이 강제적으로 탐색을 수행하여 생성해내는 저확률의 ’모호한 오답(Ambiguous answers)’을 추출한다.</p>
<p>이렇게 발견된 지식 경계 밖의 모호한 오답들은 단순히 버려지는 것이 아니라, ’정답이 없는 경우’를 평가하기 위한 가장 가치 있는 적대적 정답지(Adversarial Ground Truth) 데이터셋을 구축하는 핵심 재료가 된다. 테스트 엔지니어는 이러한 데이터를 활용하여 모델이 자신의 한계를 인지하지 못하고 모호한 답변을 진실처럼 출력하는 치명적인 실패 사례(Failure cases)를 선제적으로 잡아낼 수 있다.</p>
<h2>2.  선택적 예측(Selective Prediction) 프레임워크와 수학적 공식화</h2>
<p>소프트웨어 시스템이 ’정답 없음’을 결정하는 과정을 자동화하고 평가 오라클에 통합하기 위해서는 기권 동작을 수학적으로 모델링해야 한다. 기계 학습 및 자연어 처리(NLP) 분야에서 이는 주로 <strong>선택적 예측(Selective Prediction)</strong> 프레임워크를 통해 다루어진다. 선택적 예측은 모델이 자신의 예측에 대해 불확실성을 느낄 때 무리한 예측을 거부(Reject)하거나 기권(Abstain)할 수 있는 권한을 명시적으로 부여함으로써, 전체 소프트웨어 시스템의 신뢰성과 안전성을 보장하는 기법이다.</p>
<h3>2.1  기권 메커니즘의 수학적 모델링</h3>
<p>표준적인 분류기나 회귀 모델을 넘어, 선택적 예측 시스템은 모델 내부적으로 예측기(Predictor) 기능과 선택기(Selector) 기능을 분리하여 정의한다. 선택적 예측 모델은 쌍 <span class="math math-inline">(f, g)</span>로 공식화되며, 여기서 <span class="math math-inline">f</span>는 원래의 예측 모델(예: LLM의 텍스트 생성 또는 분류 논리)이고, <span class="math math-inline">g</span>는 해당 예측 결과를 사용자 또는 다음 파이프라인으로 전달할지 아니면 기권할지를 결정하는 이진 선택 함수(Binary selection function)이다. 입력 데이터 공간 <span class="math math-inline">\mathcal{X}</span>에 속하는 특정 입력 <span class="math math-inline">x</span>에 대하여 선택적 예측 시스템의 최종 출력은 다음과 같이 정의된다.<br />
<span class="math math-display">
(f,g)(x) =  \begin{cases}  f(x), &amp; \text{if } g(x) = 1 \\ \text{abstain}, &amp; \text{otherwise} \end{cases}
</span><br />
선택 함수 <span class="math math-inline">g(x)</span>를 설계하기 위해서는 모델의 예측 신뢰도(Confidence)를 정량화할 수 있는 스코어링 함수 <span class="math math-inline">v_f(x)</span>와, 시스템 엔지니어의 요구사항에 따라 설정되는 확신도 임계값(Threshold) <span class="math math-inline">\tau</span>가 필요하다. <span class="math math-inline">\tau</span>는 소프트웨어의 도메인 성격(예: 생명과 직결되는 의료 AI인지, 상대적으로 오류 허용도가 높은 추천 AI인지)에 따라 엄격하게 제어된다.<br />
<span class="math math-display">
g(x) = 1\{v_f(x) &gt; \tau\}
</span><br />
LLM과 같은 복잡한 비정형 데이터 처리 모델에서 신뢰도 스코어 <span class="math math-inline">v_f(x)</span>를 추정하는 방법은 모델의 아키텍처 접근 권한(블랙박스 혹은 화이트박스)에 따라 다양하게 구현된다.</p>
<table><thead><tr><th><strong>신뢰도 추정 기법</strong></th><th><strong>설명 및 수학적 특징</strong></th><th><strong>오라클 적용 시의 장단점</strong></th></tr></thead><tbody>
<tr><td><strong>최대 소프트맥스 확률 (MaxProb)</strong></td><td><span class="math math-inline">v_f(x) = \max_i f(x)_i</span> 로 정의되며, 모델 출력층의 로짓(Logit) 중 가장 높은 확률값을 신뢰도로 간주한다.</td><td>가장 구현이 간단하나, 최신 LLM은 과적합으로 인해 오답에 대해서도 높은 확률을 반환하는 과잉 확신(Overconfidence) 경향이 있어 오라클이 속기 쉽다.</td></tr>
<tr><td><strong>몬테카를로 드롭아웃 (MC Dropout)</strong></td><td>훈련 시에만 사용하던 드롭아웃을 추론(Inference) 단계에서도 활성화하여 동일한 입력 <span class="math math-inline">x</span>에 대해 여러 번 반복 샘플링을 수행한다. 예측 결과들의 평균(Mean)이나 분산(Variance)을 계산하여 모델의 인식적 불확실성(Epistemic uncertainty)을 측정한다.</td><td>신뢰도 측정의 정확성이 매우 높으나, 여러 번의 추론 패스가 필요하므로 실시간성(Latency)이 생명인 프로덕션 소프트웨어 검증에는 비용이 많이 든다.</td></tr>
<tr><td><strong>내부 상태 방향성 감지 (Activation Direction)</strong></td><td>추론 시 모델의 은닉층 활성화(Hidden activations) 벡터 공간에서 ’답변 불가성(Unanswerability)’을 나타내는 특정 방향(Direction) 성분을 추출하고 프로빙(Probing)하여 불확실성 신호로 사용한다.</td><td>텍스트 출력이라는 표면적 결과에 의존하지 않고 모델의 내부 신경망 상태를 화이트박스 관점에서 검증할 수 있어 오라클의 신뢰도가 극대화된다.</td></tr>
<tr><td><strong>언어적 확신도 (Linguistic Calibration)</strong></td><td>시스템 프롬프트를 통해 LLM 스스로 자신의 대답에 대한 신뢰도 점수(예: 0~100)를 메타데이터로 함께 출력하도록 강제하여(Self-evaluation) 이를 파싱해 사용한다.</td><td>API만 열려 있는 블랙박스 모델에서도 즉시 사용할 수 있으나, 모델의 자기 평가 능력 자체가 불완전할 경우 오라클의 기준선이 함께 붕괴될 위험이 있다.</td></tr>
</tbody></table>
<h3>2.2  리스크와 커버리지의 트레이드오프 (Risk-Coverage Trade-off)</h3>
<p>선택적 예측 모델을 평가하는 테스트 오라클을 설계할 때 벤치마크 지표로 삼아야 하는 가장 핵심적인 수학적 개념은 리스크(Risk)와 커버리지(Coverage) 간의 상충 관계이다.</p>
<ul>
<li>
<p><strong>커버리지 (Coverage, <span class="math math-inline">\phi(g)</span>):</strong> 시스템이 ’정답 없음’으로 기권하지 않고 답변을 제공하도록 선택된(Accepted) 인스턴스의 확률 질량(Probability mass)을 의미한다. 전체 테스트 셋에서 모델이 답변을 낸 비율이다.<br />
<span class="math math-display">
\phi(g) = \mathbb{E}[g(X)]
</span></p>
</li>
<li>
<p><strong>선택적 리스크 (Selective Risk, <span class="math math-inline">R(f,g)</span>):</strong> 시스템이 기권하지 않고 답변을 제공한 영역에 대해서만 계산된 오차율(Error rate)이다. 사용자 지정 손실 함수 <span class="math math-inline">l(f(X), Y)</span> (예를 들어 오답일 때 1, 정답일 때 0을 반환하는 0-1 손실 함수 <span class="math math-inline">l(f(X,Y) = 1\{f(X) \neq Y\}</span>)가 주어졌을 때, 선택적 리스크는 다음과 같다.<br />
<span class="math math-display">
R(f,g) = \frac{\mathbb{E}}{\phi(g)}
</span></p>
</li>
</ul>
<p>시스템 엔지니어가 임계값 <span class="math math-inline">\tau</span>를 높게 설정하면, 모델은 매우 확신하는 극소수의 질문에만 답변하게 되므로 선택적 리스크는 급격히 감소하지만 전체 시스템의 활용도인 커버리지 역시 바닥으로 하락한다. 반대로 <span class="math math-inline">\tau</span>를 낮추면 커버리지는 증가하지만, 잘못된 답변(환각)을 진실처럼 제공할 리스크가 기하급수적으로 증가한다.</p>
<p>이러한 상충 관계로 인해, ’정답이 없는 경우’를 판별하는 오라클은 무작정 모델이 기권하는 것만을 정답으로 간주해서는 안 된다. 과도한 기권(Over-abstention)은 소프트웨어의 유용성을 파괴하기 때문이다. 따라서 오라클은 시스템의 목적에 따라 다음 두 가지 수학적 최적화 문제 중 하나를 기반으로 모델의 기권 동작을 정량적으로 평가해야 한다.</p>
<ol>
<li><strong>제한된 개선 모델 (Bounded-improvement model):</strong> 허용 가능한 최대의 목표 리스크 한계점(Target Risk Bound) <span class="math math-inline">\epsilon</span>를 사전에 고정해 두고, 이 위험 수준을 초과하지 않으면서 커버리지 <span class="math math-inline">\phi(g)</span>를 극대화할 수 있는 모델 및 파라미터 쌍 <span class="math math-inline">(\theta^*, \psi^*)</span>을 찾는 최적화 방식이다. (예: 의료 AI 시스템에서 오진율을 0.01% 이하로 고정한 채, 얼마나 많은 환자의 질문에 답할 수 있는가?).</li>
<li><strong>제한된 기권 모델 (Bounded-abstention model):</strong> 비즈니스 요구사항에 따라 모델이 반드시 응답해야 하는 최소 목표 커버리지(Target Coverage) <span class="math math-inline">c</span>를 강제로 고정해 두고, 이 커버리지를 달성하는 조건 하에서 선택적 리스크 <span class="math math-inline">R(f,g)</span>를 최소화하는 파라미터를 찾는 방식이다. (예: 고객 센터 챗봇에서 최소 80%의 질문은 AI가 처리해야 한다는 KPI가 있을 때, 그 80% 안에서 오안내 비율을 어떻게 낮출 것인가?).</li>
</ol>
<p><img src="./3.6.1.0.0%20%EC%A0%95%EB%8B%B5%EC%9D%B4%20%EC%97%86%EB%8A%94%20%EA%B2%BD%EC%9A%B0%EC%97%90%20%EB%8C%80%ED%95%9C%20%EC%A0%95%EB%8B%B5%EC%A7%80%20%EC%A0%95%EC%9D%98.assets/image-20260222195231895.jpg" alt="image-20260222195231895" /></p>
<h3>2.3  등각 예측(Conformal Prediction)과 공정성(Fairness) 지표의 도입</h3>
<p>최신 오라클 설계에서는 단순한 스코어 임계값을 넘어, 보장된 커버리지 하에서 분포 독립적(Distribution-free)인 불확실성 정량화를 제공하는 <strong>등각 예측(Conformal Prediction, CP)</strong> 기법이 도입되고 있다. 이 기법은 모델이 점 추정(Point estimation)을 하는 대신, 정답이 포함될 확률이 수학적으로 보장된 예측 집합(Prediction set) <span class="math math-inline">C(x)</span>를 출력하도록 만든다. 단일 라벨만 도출되면 모델이 확신하는 것이고, 여러 라벨이 도출되거나 빈 집합이 도출되면 불확실성이 높아 기권하거나 인간의 개입(Human-in-the-loop)을 요청해야 한다는 신호로 해석된다.</p>
<p>이진 분류 문제에서 역확률 점수(Inverse probability score) 체계를 적용할 때 일치성 점수(Conformity Score)는 <span class="math math-inline">s(x, y) = 1 - f(x)_y</span> 로 정의된다. 이는 모델의 확신도가 높을수록 일치성 점수가 낮게 도출되는 단조 함수 특성을 가진다.</p>
<p>여기서 오라클은 모델의 기권 성능을 집단 간의 공정성 관점에서도 평가해야 한다. 특정 도메인(예: 백인 남성 데이터)에서는 완벽하게 답변하지만 엣지 도메인(예: 소수 인종 데이터)에서는 무분별하게 답변을 생성하거나 반대로 무조건 기권해버린다면 이는 신뢰할 수 없는 소프트웨어이다. 논문 <em>The Coverage-Deferral Trade-off in Conformal Prediction</em>에 따르면, 오라클은 다음과 같은 세 가지 핵심 갭(Gap) 지표를 측정해야 한다.</p>
<ol>
<li><strong>커버리지 격차 (Coverage Gap):</strong> <span class="math math-inline">| \text{Coverage}(G=0) - \text{Coverage}(G=1) |</span> - 특정 집단 간에 모델이 보장하는 정답 포함 확률의 차이.</li>
<li><strong>기권 격차 (Deferral Gap):</strong> <span class="math math-inline">| \text{DeferralRate}(G=0) - \text{DeferralRate}(G=1) |</span> - 집단 간에 모델이 답변을 포기하고 기권하는 비율의 차이.</li>
<li><strong>집합 크기 격차 (Set Size Gap):</strong> <span class="math math-inline">| \mathbb{E}[\vert \hat{C}(x)\vert \mid G=0] - \mathbb{E}[\vert \hat{C}(x)\vert \mid G=1] |</span> - 불확실성을 표현하는 예측 집합 크기의 집단 간 평균 차이.</li>
</ol>
<p>이처럼 정답지를 설계한다는 것은 단순히 데이터의 ’내용’을 명시하는 것을 넘어, 시스템이 기권이라는 행위를 수행함에 있어 수학적 임계값을 준수하고, 편향 없이 공정하게 동작하는지를 측정할 수 있는 다차원적 지표 모델을 수립하는 과정을 포괄한다.</p>
<h2>3.  기권 평가를 위한 적대적 벤치마크 설계의 진화: SQuAD 2.0 모델링</h2>
<p>자연어 처리 분야에서 ’정답이 없는 경우’를 평가 시스템에 공식적으로 도입하여 기존의 기계 독해(Machine Reading Comprehension, MRC) 패러다임에 근본적인 혁신을 가져온 연구는 스탠포드 대학교에서 발표한 논문 <em>Know What You Don’t Know: Unanswerable Questions for SQuAD</em>이다.</p>
<p>이 논문에서 발표한 SQuAD 2.0 벤치마크 이전의 SQuAD 1.1 데이터셋은 주어진 지문 내에 반드시 정답이 존재한다는 강한 전제하에 설계되었다. 따라서 모델은 단순히 지문 내에서 정답일 확률이 가장 높은 텍스트 구간(Span)을 스캐닝하여 추출해내기만 하면 높은 점수를 얻을 수 있었다. 그러나 이는 정보가 누락되어 있거나 전제가 잘못된 실세계의 비결정적 환경을 전혀 반영하지 못했다.</p>
<h3>3.1  적대적 정답 없음(Adversarial Unanswerability)의 설계 원칙</h3>
<p>SQuAD 2.0은 크라우드워커(Crowdworkers)를 동원하여 기존 10만 개의 답변 가능한 질문에 5만 개 이상의 **적대적으로 작성된 답변 불가능한 질문(Adversarial Unanswerable Questions)**을 추가했다. 이 데이터셋이 기존의 텍스트 기반 필터링 시스템이나 얕은 지식 검색 시스템을 완전히 파괴할 수 있었던 이유는 다음 두 가지 핵심 설계 원칙(Desiderata)을 엄격히 따랐기 때문이다.</p>
<ol>
<li><strong>관련성 (Relevance):</strong> 답변 불가능한 질문은 지문의 주제 및 문맥과 깊은 관련이 있어야 한다. 단순히 단어 중복도(Word overlap)를 측정하는 휴리스틱이나 TF-IDF 기반의 필터가 이를 ’관련 없는 무작위 질문’으로 걸러내지 못하도록, 지문에 등장하는 엔티티(Entity)와 키워드를 교묘하게 재사용하여 질문을 구성했다.</li>
<li><strong>그럴듯한 오답의 존재 (Existence of plausible answers):</strong> 지문 내에는 질문이 요구하는 데이터 타입(Data Type)과 일치하는 오답 구간이 반드시 존재해야 한다. 예를 들어 질문이 “1992년에 설립된 회사는 무엇인가?“라면, 지문에는 1992년이 아닌 다른 연도에 설립된 회사의 이름이나 1992년에 설립이 아닌 다른 사건(예: 합병)을 겪은 회사의 이름이 등장해야 한다. 이는 단순한 개체명 인식(NER) 기반의 타입 매칭 알고리즘을 무력화한다.</li>
</ol>
<p>이러한 고도의 적대적 설계로 인해 SQuAD 1.1에서 86%의 준수한 F1 스코어를 기록하던 강력한 신경망 모델이 SQuAD 2.0에 직면하자 66%로 성능이 급락하는 충격적인 결과를 낳았다. 이는 결정론적 정답지를 구성할 때 단순히 ’전혀 상관없는 텍스트를 주었을 때 거절하는가’를 테스트하는 것을 넘어, 문맥적으로 극히 유사하지만 논리적으로는 절대 정답이 도출될 수 없는 고도의 엣지 케이스(Edge case)를 설계해야 함을 시사한다.</p>
<h3>3.2  포인터 네트워크(Pointer Network)와 No-Answer 확률 스코어링 공식</h3>
<p>SQuAD 2.0 형식을 차용하여 텍스트의 시작과 끝을 예측하는 모델 평가 메커니즘에서는 정답의 시작 위치와 끝 위치를 찾는 전통적 과정 외에, 모델이 해당 지문 내에 답변이 없을 확률 즉 <code>no_answer_probability</code>를 내부적으로 계산하는 독립적인 손실 함수(Loss function) 체계가 필요하다.</p>
<p>BiDAF(Bidirectional Attention Flow)와 같은 기계 독해 모델 아키텍처는 지문(Passage) <span class="math math-inline">P</span>와 질문(Question) <span class="math math-inline">Q</span>를 고정된 크기의 벡터 시퀀스로 인코딩한 후, 상호 어텐션 메커니즘을 통해 상호 의존적인 표현 <span class="math math-inline">U</span>와 <span class="math math-inline">V</span>를 생성한다. 이후 질문의 표현을 요약한 밀집 벡터 <span class="math math-inline">t</span>를 사용하여 포인터 네트워크(Pointer Network)를 통해 지문의 각 단어가 정답의 시작점 혹은 끝점일 확률에 해당하는 두 개의 스코어 분포 <span class="math math-inline">\alpha</span>(시작)와 <span class="math math-inline">\beta</span>(끝)를 도출한다.<br />
<span class="math math-display">
\alpha, \beta = \text{pointer network}(U, t)
</span><br />
기존 방식들이 모든 가능한 답변 구간에 대한 확률 합과 기권 확률을 통합하여 단일 소프트맥스(Softmax) 계층으로 처리했다면, SQuAD 2.0에 대응하는 보다 정교한 시스템은 답변 추출 작업과 ‘정답 없음 감지(no-answer detection)’ 작업을 분리하여 독립적인 손실 함수로 모델링한다. 오라클은 모델이 출력한 <code>no_answer_probability</code>가 시스템이 사전에 정의한 <code>no_answer_threshold</code>를 초과하는지를 검사한다. 모델 학습 시에 사용되는 결합 손실 함수(Joint no-answer objective) <span class="math math-inline">L_{joint}</span>는 다음과 같이 정의된다.<br />
<span class="math math-display">
L_{joint} = -\log \left( \frac{(1-\delta)e^z + \delta e^{\alpha_a} e^{\beta_b}}{e^z + \sum_{i=1}^{l_p}\sum_{j=1}^{l_p} e^{\alpha_i} e^{\beta_j}} \right)
</span><br />
위 공식에서 <span class="math math-inline">z</span>는 모델이 내부적으로 계산한 특별한 ‘정답 없음(no-answer)’ 스코어이며, <span class="math math-inline">\alpha_a</span>와 <span class="math math-inline">\beta_b</span>는 각각 실제 정답(Ground-truth) 구간의 시작 <span class="math math-inline">a</span>와 끝 <span class="math math-inline">b</span> 위치의 확률을 나타낸다. 표시자 변수 <span class="math math-inline">\delta</span>는 해당 질문이 답변 가능한 정답이 있으면 1이 되고, 불가능한 질문이면 0이 된다.</p>
<p>테스트 파이프라인의 결정론적 오라클은 단순히 모델이 임의의 문자열을 생성했는지 여부가 아니라, 추론 과정에서 모델 내부적으로 계산된 불확실성 스코어 <span class="math math-inline">z</span>의 정규화된 값이 임계값을 넘어 성공적으로 기권(Abstention)을 유도했는지를 검증하는 역할을 수행해야 한다.</p>
<h3>3.3  ’정답 없음’에 특화된 평가 메트릭 (EM / F1)</h3>
<p>오라클이 평가 점수를 산정할 때 ’정답이 없는 경우’는 기존의 정확도(Accuracy) 지표 계산 방식을 완전히 재정의할 것을 요구한다.</p>
<table><thead><tr><th><strong>평가 지표 (Metric)</strong></th><th><strong>수식 및 계산 방식</strong></th><th><strong>기권(Unanswerable) 테스트 시의 적용 규칙</strong></th></tr></thead><tbody>
<tr><td><strong>Exact Match (EM)</strong></td><td>정답 문자열 배열과 모델 출력 문자열의 완벽한 일치 여부를 1(True) 또는 0(False)으로 반환</td><td>정답지에 정답이 없다고 정의되어 있을 때, 모델이 어떠한 형태든 텍스트를 하나라도 출력하면 즉시 0점 처리됨. 모델이 텍스트 출력을 기권해야 1점 부여.</td></tr>
<tr><td><strong>F1 Score</strong></td><td><span class="math math-inline">2 \times \frac{\text{precision} \times \text{recall}}{\text{precision} + \text{recall}}</span></td><td>모델이 정답이 없는 질문에 대해 답변을 뱉으면, 부분적으로 맞는 토큰이 있더라도 무조건 오답(0점)으로 페널티 부여. 정확히 기권했을 경우에만 F1 최고점인 1.0 획득.</td></tr>
</tbody></table>
<p>따라서 오라클 검증 시스템에 주입되는 정답지(Ground Truth) 파일 구조에는 단순히 빈 배열(<code>"answers":</code>)뿐만 아니라, <code>is_impossible: true</code>라는 명시적 불리언(Boolean) 플래그를 추가하여 이 항목이 반드시 기권을 검증하기 위한 테스트 케이스임을 시스템 계층에 강제로 인지시켜야 한다.</p>
<h2>4.  오라클 문제(Test Oracle Problem) 해결을 위한 결정론적 설계 기법</h2>
<p>소프트웨어 공학에서 ’오라클 문제(Test Oracle Problem)’란, 주어진 입력에 대해 시스템의 출력 결과가 올바른지 그른지를 판단할 수 있는 수단(Oracle)이나 메커니즘을 자동으로 식별하기 어려운 문제를 말한다. 통상적인 로직 기반 시스템의 단위 테스트(Unit test)에서는 <code>assertEquals(expected, actual)</code> 구문을 통해 확정된 값끼리의 단순 비교가 가능하지만, 생성형 AI 시스템은 확률론적 결과를 도출하므로 이러한 접근이 원천적으로 차단된다.</p>
<p>’정답이 없는 경우’에 대한 오라클을 설계할 때는 이 비결정성을 통제하기 위해 결과의 다형성을 제거하고, AI의 출력을 확정적인 메타데이터 구조로 강제화하는 <strong>구조화된 기권(Structured Abstention)</strong> 접근법이 필수적이다.</p>
<h3>4.1  비결정적 출력을 통제하는 고급 테스팅 기법</h3>
<p>LLM과 같은 자가 학습 및 확률 기반 모델의 기권 능력을 검증하기 위해 오라클은 전통적 비교 방식 외에 다음과 같은 고급 소프트웨어 테스팅 기법을 차용하여 적용할 수 있다.</p>
<ul>
<li><strong>변성 테스팅 (Metamorphic Testing):</strong> 입력과 출력 사이의 정확한 정답 값을 모를 때, 입력의 ’변환’이 출력에 미쳐야 하는 ’논리적 관계’를 오라클로 정의한다. 예를 들어 모델이 특정 모호한 질문 <span class="math math-inline">Q</span>에 대해 ’알 수 없음’으로 기권했다면, <span class="math math-inline">Q</span>에 동의어를 삽입하거나 문장 순서를 바꾼 <span class="math math-inline">Q&#39;</span>를 입력해도 여전히 ‘기권’ 상태가 유지되어야 한다는 속성(Property)을 검증한다.</li>
<li><strong>회귀 및 백투백 테스팅 (Regression &amp; Back-to-Back Testing):</strong> 새로운 버전의 모델이나 파인튜닝된 모델이, 이전에 안전하게 ‘기권’ 처리를 잘 해내던 과거 버전(Reference)의 테스트 셋에서 갑자기 잘못된 확신을 가지고 환각을 생성하지 않는지 두 시스템의 출력을 병렬로 실행하여 비교하는 방식이다.</li>
<li><strong>상태 머신 기반의 추적 (State-Machine Oracle):</strong> 불확실성을 지닌 반응형 시스템(Reactive systems)을 검증할 때 사용된다. 완벽히 결정론적인 유한 상태 기계(DFSM, Deterministic Finite State Machine)를 도출하기 전, 모델의 가능한 모호한 반응들을 표현하는 비결정론적 유한 상태 기계(NFSM, Non-deterministic Finite State Machine)를 정의하여 궤적(Trace)이 올바른 거부 상태로 전이되는지 검증한다.</li>
</ul>
<h3>4.2  답변 거부 프로토콜 (Reject-to-Answer Protocol)의 구조화</h3>
<p>안전한 시스템에서 모델의 품질을 판단하는 핵심 척도는 단순히 ’얼마나 많은 정답을 생성하는가’가 아니라 ’오답이 생성될 위험이 감지되었을 때 얼마나 안정적으로 답변을 거부(Reject-to-Answer)하는가’이다. 이를 단위 테스트 가능한 코드로 검증하기 위해, 정답지는 모델이 반드시 뱉어내야 할 ’거절의 행위와 원인’을 결정론적으로 명시해야 한다.</p>
<p>LLM에 대한 테스트 셋을 구성할 때, 기권의 정답지를 자유 발화 형태의 텍스트(예: “문서에 정보가 없어 알 수 없습니다”, “질문이 너무 모호합니다”)로 방치하면 오라클이 이를 평가하기 위해 다시 또 다른 자연어 처리 모듈에 의존해야 하는 취약점이 발생한다. 따라서 오라클 파이프라인은 AI의 출력을 JSON 등 결정론적 파싱이 가능한 구조체로 강제(Structured Output) 유도하고, 이 구조체 내의 상태 코드(Status code)를 평가해야 한다.</p>
<p><strong>결정론적 기권 정답지(Ground Truth) JSON 스키마 명세 예시:</strong></p>
<pre><code class="language-JSON">{
  "test_case_id": "TC-ABSTAIN-4092",
  "input_query": "2023년 대한민국 시장의 4분기 점유율 데이터를 기반으로 2026년의 정확한 영업이익률을 예측해줘.",
  "expected_behavior": {
    "action": "ABSTAIN",
    "primary_reason": "UNDERSPECIFIED_CONTEXT_AND_STALE",
    "required_missing_entities": ["2026년_예측_모델_파라미터", "미래_시장_변수"],
    "acceptable_fallback_responses": [
      "제공된 2023년 데이터만으로는 2026년의 영업이익률을 결정론적으로 예측할 수 없습니다.",
      "예측을 위한 추가적인 재무 가정 변수를 제공해주십시오."
    ],
    "must_not_contain_hallucination_regex": "(영업이익률은 [0-9]+%로 예측됩니다)"
  }
}
</code></pre>
<p>이러한 정답지를 기반으로 동작하는 오라클 로직은 모델이 생성한 자연어 문자열 자체의 유려함을 평가하지 않는다. 대신, 모델에게 함수 호출(Function Calling) 도구를 제공하여, 모델이 내부 판단을 거쳐 스스로 자신이 기권 상태(<code>action: "ABSTAIN"</code>)에 도달했음을 선언하는 JSON 객체를 출력하도록 만들고, 오라클은 그 구조체의 <code>action</code> 값과 <code>primary_reason</code> 값이 정답지와 정확히 일치하는지를 검사한다. 이는 모호성으로 가득한 AI 평가를 <code>assertEqual(expected.action, actual.action)</code>이라는 완전히 결정론적인 단위 테스트(Unit Test) 영역으로 끌어들이는 핵심 기술이다.</p>
<h2>5.  내부 상태(Internal State) 감지 및 지식 그래프(KG) 기반 오라클 메커니즘</h2>
<p>’정답이 없는 경우’를 판별하는 오라클은 더 이상 모델이 출력하는 텍스트 문자열(표면적 결과)에만 의존할 필요가 없다. 최신 AI 오라클 연구는 모델 내부의 활성화 공간을 들여다보거나 거대한 지식 그래프를 동원하여 더욱 완벽한 결정론적 검증을 시도하고 있다.</p>
<h3>5.1  활성화 공간에서의 방향성 기반 기권 신호 감지 (Direction-based Unanswerability Detection)</h3>
<p>최신 연구에 따르면, LLM은 정답을 전혀 모를 때에도 표면적으로는 매우 확신에 찬 어조로 유창하게 환각(Fluent hallucination)을 생성할 수 있다. 프롬프트를 조작하거나 출력된 텍스트를 외부 분류기(Classifier)로 검사하는 블랙박스 방식은 모델의 이러한 치명적인 과잉 확신(Overconfidence)에 속아 넘어가기 쉽다.</p>
<p>그러나 모델의 내부 신경망, 특히 은닉층 활성화(Hidden activations) 상태를 분석해보면, 모델이 실제로 지식을 가지고 정보를 추출해낼 때의 활성화 벡터 방향과, 지식이 전혀 없는 상태에서 확률적으로 그럴듯한 단어들을 조합해낼 때의 활성화 벡터 방향 사이에는 명확하게 분리 가능한 기하학적 차이가 존재한다.</p>
<p>고급 테스트 오라클 설계자는 이 원리를 응용하여 화이트박스(White-box) 형태의 검증 시스템을 구축할 수 있다. 추론(Inference) 과정에서 모델의 특정 중간 레이어 활성화 값을 추출하고, 이를 훈련 단계에서 미리 찾아낸 고유한 ’기권 벡터 방향(Abstention Direction)’과 내적(Dot product)한다. 오라클은 모델의 최종 텍스트 출력이 무엇이든 상관없이, 이 내적 값이 특정 임계값을 넘어 내부적인 불확실성 신호가 감지되었다면 해당 질의가 ’정답이 없는 경우’임을 결정론적으로 판정할 수 있다. 이는 모델이 단순히 시스템 프롬프트의 지시에 순응하여 우연히 ’모른다’고 대답한 것인지, 아니면 내부 인지 메커니즘상 실제로 정보의 부재를 자각하고 기권한 것인지를 구별해내는 매우 강력하고 근본적인 오라클 매커니즘이 된다.</p>
<h3>5.2  지식 그래프를 활용한 원자적 팩트체킹 (FAITH Framework)</h3>
<p>의료 전문 AI나 법률 AI와 같이 도메인 특화 지식이 요구되는 산업계에서는 ’정답이 없는 경우’를 인간 전문가가 일일이 검토하여 라벨링하고 골든 데이터셋(Golden Dataset)을 구축하는 데 천문학적인 비용과 시간이 소모된다. 인간 주석자(Annotator)의 지식 한계와 주관 개입을 배제하고, 참조 정답(Reference answer)이 없는 상황에서도 모델의 출력과 기권 여부를 완벽하게 평가할 수 있도록 FAITH(Factuality Assessment with Knowledge Graphs)와 같은 지식 그래프(KG) 기반의 오라클 프레임워크가 부상하고 있다.</p>
<p>지식 그래프 기반 오라클은 모델이 생성한 응답 텍스트를 가장 작은 의미 단위인 원자적 주장(Atomic claims)으로 분해한다. 이후 자연어 주장에 포함된 엔티티들을 UMLS(의학 전문어 시스템)나 기업 내부의 온톨로지(Ontology) 데이터베이스 구조에 존재하는 노드(Node)에 매핑하고, 주장하는 바를 엣지 경로(Evidence paths)로 탐색한다. 오라클은 탐색 결과에 따라 다음과 같은 절대적인 결정론적 규칙을 따른다.</p>
<ol>
<li>분해된 주장이 지식 그래프 내의 유효한 엣지 경로로 온전히 연결되어 검증되면, 해당 질의는 **답변 가능(Answerable) 및 사실(True)**로 판정된다.</li>
<li>지식 그래프 내에서 해당 주장을 명시적으로 반박하는 상충된 경로가 발견되면, 이는 **답변 가능 및 거짓(False)**으로 판정된다.</li>
<li>지식 그래프 내에서 해당 주장과 관련된 노드 간의 경로가 전혀 존재하지 않거나 단절되어 있다면, 이는 인간이 파악하지 못한 지식이거나 모델의 지식 경계를 넘어선 허구적 연결망이므로 <strong>답변 불가(Unanswerable) 및 정보 부재</strong> 상태로 판정된다.</li>
</ol>
<p>이러한 지식 그래프 매핑 과정에서, 만약 모델이 무리하게 텍스트를 생성하여 원자적 주장을 만들어냈는데 그것이 3번(단절된 경로)에 해당한다면 오라클은 즉시 테스트 실패(Fail)를 반환한다. 반대로 모델이 사전에 정보의 부재를 인지하고 기권(Abstention)을 선언했다면 오라클은 테스트 성공(Pass)을 반환한다. 이 방식은 인간의 주관적 평가나 편향 없이도 모델이 도메인 내의 모호함과 정보 부재를 올바르게 처리했는지를 검증할 수 있는 완벽히 결정론적이고 자동화된 검사 수단이다.</p>
<h2>6.  정답지 구축 프로세스에서의 안티 패턴(Anti-Patterns)과 데이터 무결성 보장 체계</h2>
<p>’정답이 없는 경우’에 대한 정답지를 구축하고 오라클을 구성하는 실무 과정에서, 많은 소프트웨어 조직들이 모델의 능력을 과대평가하거나 테스트 베드의 한계를 인지하지 못하여 치명적인 안티 패턴(Anti-patterns)에 빠지게 된다. 결정론적 오라클의 무결성을 유지하기 위한 전략과 함정을 명확히 인지해야 한다.</p>
<h3>6.1  단순 키워드 기반의 무작위 OOD 함정 (The Trivial OOD Trap)</h3>
<p>가장 빈번하게 관찰되는 안티 패턴은 단순히 시스템의 비즈니스 목적과 완전히 동떨어진 분포 외(Out-of-Distribution, OOD) 질의만을 모아 ‘정답 없음’ 테스트 셋으로 구성하는 관행이다. 예를 들어, 금융 상품 추천 챗봇을 테스트하면서 “사과의 칼로리는 얼마인가요?” 혹은 “우주의 기원은 무엇인가요?“와 같은 뜬금없는 질문만 수백 개 던져놓고 모델이 대답을 거부하는지를 평가하며 시스템이 안전하다고 착각하는 방식이다.</p>
<p>이러한 단순 OOD 탐지는 문맥의 의미적 거리감이 너무 커서 최신 LLM에게는 극히 쉬운 과제이며, 모델이 실제로 직면하게 될 도메인 내의 정교한 모호성(In-domain ambiguity)을 처리하는 능력을 전혀 평가하지 못한다. 진정한 의미의 ‘정답 없음’ 테스트는 앞서 분석한 SQuAD 2.0의 핵심 설계 원칙처럼, 모델의 도메인 지식 범위 내에 있으나 핵심 전제가 교묘하게 틀렸거나, 특정 변수 조건이 누락된 **부분적 답변 가능 질문(Semi-open-ended questions)**으로 구성되어야 한다. 그래야만 모델이 단순한 텍스트 표면 패턴 매칭(Keyword matching)을 넘어 진정한 추론(Reasoning)을 거쳐 확신도의 임계값(Threshold)을 넘지 못해 기권하는지를 정밀하게 검증할 수 있다.</p>
<h3>6.2  LLM-as-a-Judge에 대한 맹신과 아부(Sycophancy) 효과</h3>
<p>정답 없는 모호한 상황을 평가하기 위해 프롬프트를 통해 또 다른 LLM을 심판(Judge)으로 사용하는 하이브리드 방식은 자동화 측면에서 효율적이지만, 치명적인 무결성 위험을 내포하고 있다. 평가용 프롬프트와 LLM 심판 역시 자신이 모르는 정보에 대해 과잉 확신을 가질 수 있으며, 평가 과정에서 인간 작성자나 입력 프롬프트의 어조에 과도하게 동조하는 아부(Sycophancy) 현상을 보일 수 있다.</p>
<p>즉, 테스트 케이스의 질문이 매우 그럴듯하게 쓰여 있다면 평가 모델조차 “이 질문은 답변 불가능해야 한다“는 정답지의 지시를 망각하고 “합리적인 답변을 생성했으므로 테스트 통과“라는 잘못된 평가를 내릴 수 있다. 이를 방지하기 위해서는 오라클 파이프라인이 순수하게 LLM-as-a-Judge의 자연어 기반 정성 평가에만 의존해서는 안 된다. 앞서 4장과 5장에서 논의한 것처럼 JSON 강제 구조화를 통한 명시적 상태 코드(<code>action: "ABSTAIN"</code>) 반환 요구, 지식 그래프를 통한 결정론적 팩트 매핑, 내부 활성화 벡터의 방향성 검증 등 다중 계층의 엄격한 방어 기제를 두어 평가 과정의 비결정성을 통제해야 한다.</p>
<h3>6.3  과도한 거부(False Refusals)와 유용성(Utility)의 충돌 방지</h3>
<p>’정답이 없는 경우’에 기권하도록 훈련하고 이를 평가하는 과정에서 나타나는 또 다른 심각한 부작용은 모델이 지나치게 방어적으로 변모하여 답변이 가능한 안전한 질문조차 거부해버리는 과도한 거부(False Refusals) 현상이다. 예를 들어 폭력성을 거부하도록 정렬된 모델이 “어디서 멋진 사진을 ‘찍을(shoot)’ 수 있나요?“라는 완전히 무해한 질문에 포함된 특정 단어에 과민 반응하여 기권하는 사례가 대표적이다.</p>
<p>이러한 유용성의 붕괴를 막기 위해, 정답지 구축 팀은 모델이 유해하거나 모호한 지시를 거절하는 ‘거절 이유(Refusal rationales)’ 자체를 파인튜닝 데이터나 프롬프트 데모(In-Context Learning)에 명시적으로 포함시켜야 한다. 오라클은 기권의 횟수만 세는 것이 아니라, 오탐지(False positive)를 별도의 실패(Failure) 케이스로 분류하여 시스템 엔지니어가 리스크와 커버리지의 트레이드오프 곡선에서 최적의 임계값 <span class="math math-inline">\tau</span>를 찾아낼 수 있도록 정밀한 피드백 루프를 제공해야 한다.</p>
<h3>6.4  골든 데이터셋(Golden Dataset)의 계층적 진화와 유지보수</h3>
<p>결과적으로, AI 모델의 신뢰성을 시간의 흐름에 따라 지속적으로 보장하기 위해서는 인간 전문가의 엄격한 품질 관리가 적용된 **골든 데이터셋(Golden Dataset)**이 CI/CD 파이프라인의 핵심 검증 게이트로 흔들림 없이 작동해야 한다. 이 데이터셋 내에서 ’정답이 없는 경우’에 해당하는 적대적 항목들은 단순히 배포 전에 모델의 성능 지표를 깎아내리기 위한 함정이 아니라, 모델이 자신의 지식 경계를 직시하고 정직함(Honesty)을 유지하는지를 측정하는 가장 신뢰할 수 있는 척도이자 기준점이다.</p>
<p>실무 조직은 지속적인 반복(Iterative) 업데이트를 통해 실제 운영 환경에서 발생했던 모호한 엣지 케이스들을 수집하고, 이를 이 골든 데이터셋에 편입시켜야 한다. 도메인 전문가는 질의가 왜 답변 불가능한지를 앞서 분류한 6가지 범주(알 수 없음, 전제 오류, 만료됨, 주관적, 문맥 부족, 의도 모호)에 따라 엄밀히 태깅해야 하며, 이렇게 확립된 고품질의 기권 정답지야말로 끊임없이 진화하는 에이전트(Agentic AI) 시스템이 사용자의 의도를 벗어나 폭주하지 않도록 통제하는 굳건한 닻(Anchor)의 역할을 수행한다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Testing AI Systems: Handling the Test Oracle Problem, https://dev.to/qa-leaders/testing-ai-systems-handling-the-test-oracle-problem-3038</li>
<li>The Oracle Problem in Software Testing: A Survey, http://www0.cs.ucl.ac.uk/staff/m.harman/tse-oracle.pdf</li>
<li>The Oracle Problem - YLD, https://www.yld.io/blog/the-oracle-problem</li>
<li>Simulation-Driven Automated End-to-End Test and Oracle Inference, https://arxiv.org/pdf/2302.02374</li>
<li>Ground Truth Data for AI | SuperAnnotate, https://www.superannotate.com/blog/ground-truth-data-for-ai</li>
<li>What Is Ground Truth in Machine Learning? - IBM, https://www.ibm.com/think/topics/ground-truth</li>
<li>Why ground truth matters in AI - Telnyx, https://telnyx.com/learn-ai/ground-truth</li>
<li>Perception of Knowledge Boundary for Large … - NIPS - NeurIPS, https://proceedings.neurips.cc/paper_files/paper/2024/file/a1e0d6fa0c30b7d4f75dd9c7ed6189f2-Paper-Conference.pdf</li>
<li>What is Ground Truth in Machine Learning? | Domino Data Lab, https://domino.ai/data-science-dictionary/ground-truth</li>
<li>AbstentionBench: Reasoning LLMs Fail on Unanswerable Questions, https://arxiv.org/html/2506.09038v1</li>
<li>When Should LLMs Be Less Specific? Selective Abstraction for, https://arxiv.org/html/2602.11908v1</li>
<li>Selective Prediction in Natural Language Processing - Medium, https://medium.com/@nvarshney97/selective-prediction-in-natural-language-processing-838244f1e8e1</li>
<li>Detecting (Un)answerability in Large Language Models with Linear, https://arxiv.org/html/2509.22449v1</li>
<li>Things Machine Learning Models Know That They Don’t Know, https://ojs.aaai.org/index.php/AAAI/article/view/35094/37249</li>
<li>Selective Prediction for Confidence-Aware Evaluation of Language, https://www.researchgate.net/publication/373809616_Selective-LAMA_Selective_Prediction_for_Confidence-Aware_Evaluation_of_Language_Models</li>
<li>Know Your Limits: A Survey of Abstention in Large Language Models, https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00754/131566/Know-Your-Limits-A-Survey-of-Abstention-in-Large</li>
<li>Know Your Limits: A Survey of Abstention in Large Language Models, https://www.researchgate.net/publication/393331033_Know_Your_Limits_A_Survey_of_Abstention_in_Large_Language_Models</li>
<li>The Coverage-Deferral Trade-Off: Fairness Implications of, https://www.preprints.org/manuscript/202512.2631</li>
<li>Reducing Unnecessary Abstention in Vision-Language Reasoning, https://aclanthology.org/2024.findings-acl.767/</li>
<li>Unanswerable Questions for SQuAD - Stanford NLP Group, https://nlp.stanford.edu/pubs/rajpurkar2018squad.pdf</li>
<li>Know What You Don’t Know Unanswerable Questions For SQuAD, https://www.scribd.com/document/954193332/Know-What-You-Don-t-Know-Unanswerable-Questions-for-SQuAD</li>
<li>Small pre-trained model for background understanding in multi, https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1308206/pdf</li>
<li>Know What You Don’t Know: Unanswerable Questions for SQuAD, https://www.researchgate.net/publication/325709682_Know_What_You_Don’t_Know_Unanswerable_Questions_for_SQuAD</li>
<li>SQuAD 2.0: Know What You Don’t Know: Unanswerable Questions, https://sh-tsang.medium.com/brief-review-squad-2-0-know-what-you-dont-know-unanswerable-questions-for-squad-482494cce943</li>
<li>evaluate/metrics/squad_v2/README.md at main - GitHub, https://github.com/huggingface/evaluate/blob/main/metrics/squad_v2/README.md</li>
<li>Question Answering - NVIDIA Docs, https://docs.nvidia.com/tao/tao-toolkit-archive/tlt-30/text/nlp/question_answering.html</li>
<li>Machine Reading Comprehension with Unanswerable Questions, https://ojs.aaai.org/index.php/AAAI/article/view/4619/4497</li>
<li>Approaches for Question Answering on SQuAD 2.0, https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/reports/final_reports/report260.pdf</li>
<li>Using Machine Learning to Generate Test Oracles - Gregory Gay, https://greg4cr.github.io/pdf/21oracleslr.pdf</li>
<li>Mining Precise Test Oracle Modelled by FSM - UQO, https://lrsi.uqo.ca/wp-content/uploads/2022/02/mining_oracle.pdf</li>
<li>When Silence Is Golden: Can LLMs Learn to Abstain in Temporal QA, https://openreview.net/forum?id=PhUCxfS0yf</li>
<li>(PDF) Assessing Automated Fact-Checking for Medical LLM, https://www.researchgate.net/publication/397701920_Assessing_Automated_Fact-Checking_for_Medical_LLM_Responses_with_Knowledge_Graphs</li>
<li>Anti-patterns that cause problems for AI implementation - MindTitan, https://mindtitan.com/resources/blog/ai-implementation/</li>
<li>Five key factors blocking widespread AI implementation in … - Xurrent, https://www.xurrent.com/blog/ai-implementation-barriers</li>
<li>A Structural Analysis of Safety-Tuning Responses for Reducing, https://openreview.net/pdf?id=01LEQ9Uz46</li>
<li>Out-of-Distribution Detection for Safety Assurance of AI and … - arXiv, https://arxiv.org/html/2510.21254v1</li>
<li>FactGuard: Detecting Unanswerable Questions in Long-Context, https://openreview.net/forum?id=c4nZkkyl6E</li>
<li>HonestLLM: Toward an Honest and Helpful Large Language Model, https://neurips.cc/virtual/2024/poster/96003</li>
<li>arXiv:2502.11681v4 [cs.CL] 5 Mar 2025, https://arxiv.org/pdf/2502.11681</li>
<li>Agentic AI starts with ground truth - RWS, https://www.rws.com/blog/agentic-ai-starts-with-ground-truth/</li>
<li>Evaluating “Honesty” in LLM Unlearning - OpenReview, https://openreview.net/pdf?id=fhrOSzieCS</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>