<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:4.5.1 제로샷(Zero-Shot)의 불확실성과 퓨샷(Few-Shot)의 지향성</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>4.5.1 제로샷(Zero-Shot)의 불확실성과 퓨샷(Few-Shot)의 지향성</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 4. AI 모델 응답의 일관성 확보를 위한 프롬프트 엔지니어링 및 파라미터 제어</a> / <a href="index.html">4.5 퓨샷 러닝(Few-Shot Learning): 예제를 통한 정답 패턴 고정</a> / <span>4.5.1 제로샷(Zero-Shot)의 불확실성과 퓨샷(Few-Shot)의 지향성</span></nav>
                </div>
            </header>
            <article>
                <h1>4.5.1 제로샷(Zero-Shot)의 불확실성과 퓨샷(Few-Shot)의 지향성</h1>
<p>인공지능(AI)을 활용한 소프트웨어 개발, 특히 결정론적 정답지(Deterministic Ground Truth) 역할을 수행해야 하는 오라클(Oracle)의 구축에 있어서 대형 언어 모델(LLM)의 본질적 비결정성(Nondeterminism)은 가장 큰 기술적 장애물로 작용한다. 소프트웨어 테스트와 검증은 동일한 입력에 대해 항상 동일하고 예측 가능한 출력을 요구하는 엄격한 연역적 시스템이다. 반면, 언어 모델은 방대한 매개변수 공간 내에서 확률적 분포를 바탕으로 다음 토큰을 예측하는 귀납적 시스템이다. 이러한 확률적 AI와 결정론적 소프트웨어 공학 간의 근본적인 충돌을 중재하고 제어하는 핵심 메커니즘이 바로 프롬프트 엔지니어링의 문맥 내 학습(In-Context Learning, ICL)이며, 그 중심에 제로샷(Zero-Shot)과 퓨샷(Few-Shot) 프롬프팅이 존재한다.</p>
<p>본 절에서는 모델이 사전 학습된 가중치에만 의존하여 추론을 수행하는 제로샷 환경에서 발생하는 불확실성의 근원적 원인을 수리적, 아키텍처적 관점에서 철저히 분석한다. 나아가 소수의 예제를 통해 모델의 확률 분포를 특정 작업 공간으로 좁혀주는 퓨샷 러닝이 어떻게 강력한 지향성(Directionality)을 부여하여 오라클의 결정론적 무결성을 확보하는지 심층적으로 탐구한다. 특히, 단순히 응답의 정확도를 높이는 것을 넘어, 엄격한 문법 규칙과 비즈니스 로직을 준수해야 하는 소프트웨어 엔지니어링 환경에서 두 프롬프팅 기법이 나타내는 행동 양식의 차이를 실증적 연구 결과를 바탕으로 비교한다.</p>
<h2>1. 제로샷(Zero-Shot) 추론의 기하학적 불확실성과 내재적 한계</h2>
<p>제로샷 러닝(Zero-Shot Learning)은 모델에게 명시적인 작업 예제를 제공하지 않고, 자연어 지시문(Instruction)만을 통해 새로운 작업을 수행하도록 요구하는 기법이다. 이 방식은 라벨링된 데이터가 전혀 없는 상황에서도 모델의 광범위한 사전 학습(Pre-training) 지식을 활용할 수 있다는 점에서 극도의 확장성과 편의성을 제공한다. 전통적인 기계 학습 시스템이 수천, 수만 건의 훈련 데이터를 필요로 했던 것과 달리, 제로샷 학습은 작업에 대한 의미론적 설명(Semantic Description)이나 지시문만으로도 모델이 한 번도 본 적 없는 범주(Unseen Classes)를 분류하거나 텍스트를 생성할 수 있게 해준다.</p>
<p>그러나 오라클과 같이 확정적이고 구조화된 출력이 요구되는 소프트웨어 검증 환경에서, 제로샷 프롬프팅은 치명적인 불확실성을 수반한다. 모델은 무엇을 출력해야 할지에 대한 맥락적 힌트가 부족하기 때문에, 내부적으로 수많은 가능한 경로 중 하나를 임의로 선택하게 되며, 이는 결과적으로 출력의 형태, 어조, 내용의 일관성을 크게 떨어뜨린다.</p>
<h3>1.1 인식론적 불확실성(Epistemic)과 우연적 불확실성(Aleatoric)의 수리적 이해</h3>
<p>제로샷 환경에서 모델이 나타내는 불확실성은 단순히 ’틀린 답을 낼 가능성’을 넘어, 확률론적 관점에서 크게 두 가지 차원으로 엄밀히 분류된다. 첫째는 우연적 불확실성(Aleatoric Uncertainty)으로, 이는 입력 데이터 자체에 내재된 본질적인 노이즈나 지시문의 모호성에서 기인한다. 데이터 수집 과정의 오류나 자연어 자체가 가지는 다의성 때문에 발생하는 이 불확실성은 모델의 크기를 키우거나 훈련 데이터를 늘린다고 해서 감소하지 않는 기저의 잡음이다.</p>
<p>둘째는 인식론적 불확실성(Epistemic Uncertainty)으로, 모델이 훈련 과정에서 해당 특정 작업이나 도메인에 대한 충분한 지식을 학습하지 못했거나, 현재 주어진 프롬프트만으로는 사전 학습된 지식 공간 중 어느 부분을 활성화해야 할지 결정하지 못해 발생하는 불확실성이다. 제로샷 프롬프팅에서 가장 치명적으로 작용하는 것이 바로 이 인식론적 불확실성이다. 제로샷 환경에서는 모델에게 기대되는 출력의 형식이나 구조를 고정해주는 ’닻(Anchor)’이 존재하지 않기 때문이다.</p>
<p>이러한 불확실성은 모델의 확신도를 정량화하는 지표인 섀넌 엔트로피(Shannon Entropy)를 통해 수학적으로 관찰할 수 있다. 화이트박스(White-box) LLM에서 예측 토큰 확률 분포의 엔트로피는 다음과 같이 정의된다.</p>
<table><thead><tr><th><strong>개념</strong></th><th><strong>수식 표현</strong></th></tr></thead><tbody>
<tr><td><strong>섀넌 엔트로피 (Shannon Entropy)</strong></td><td><span class="math math-inline">H(p) = -\sum_{v \in \mathcal{V}} p(v) \log(p(v))</span></td></tr>
<tr><td><strong>인식론적 불확실성 (JSD 기반)</strong></td><td><span class="math math-inline">\mathcal{U}_{epis}(\mathcal{S}) = \frac{1}{\vert\mathcal{S}\vert} \sum_{i \in \mathcal{S}} D_{JS}(p_i \Vert \bar{p})</span></td></tr>
<tr><td><strong>우연적 불확실성 (이진 엔트로피 기반)</strong></td><td><span class="math math-inline">\mathcal{U}_{alea}(\mathcal{S}) = \frac{1}{\vert\mathcal{S}\vert} \sum_{i \in \mathcal{S}} (-p_i \log p_i - (1-p_i) \log(1-p_i))</span></td></tr>
</tbody></table>
<p>위 표에서 보듯, 제로샷 프롬프트가 주어졌을 때 모델은 방대한 어휘 공간(<span class="math math-inline">\mathcal{V}</span>) 전체에 걸쳐 확률을 평탄하게 분산시키게 되며, 이는 결과적으로 높은 섀넌 엔트로피 값을 산출한다. 즉, 모델이 다음에 올 단어나 코드 스니펫에 대해 강한 확신을 가지지 못하고 여러 대안 사이에서 주저하고 있음을 의미한다. 특히 의학적 진단, 법률 분석, 소프트웨어 버그 검출과 같이 복잡한 논리 추론이나 도메인 특화 작업에서 제로샷의 인식론적 불확실성은 출력의 신뢰성을 근본적으로 훼손하는 요인이 된다.</p>
<p>최근 연구에 따르면, 이러한 인식론적 불확실성을 측정하고 제어하기 위해 자기 일관성(Self-consistency) 기법이나 다중 LLM 앙상블(Multi-LLM Ensembles) 기법이 도입되고 있다. 예컨대 ’MUSE (Multi-LLM Uncertainty via Subset Ensembles)’와 같은 방법론은 여러 언어 모델의 예측 분포 간의 젠슨-섀넌 발산(Jensen-Shannon Divergence, JSD)을 계산하여 인식론적 불확실성을 정량화한다. 제로샷 상황에서 여러 모델이 서로 다른 출력을 낸다면 JSD 값이 급증하며, 이는 해당 프롬프트가 충분한 지향성을 제공하지 못하고 있음을 수리적으로 증명하는 것이다.</p>
<h3>1.2 온도(Temperature) 0에서의 비결정성: 하드웨어 노이즈와 환상</h3>
<p>일반적으로 소프트웨어 엔지니어들은 LLM의 하이퍼파라미터 중 하나인 온도(Temperature)를 0으로 설정(Greedy Decoding)하면 모델이 항상 가장 높은 확률의 토큰만을 선택하므로 완전한 결정론적(Deterministic) 출력을 보장할 것이라고 가정한다. 온도가 높을수록 확률 분포가 평탄해져 창의적이고 다양한 출력이 나오지만, 온도가 0에 수렴하면 확률 분포가 극도로 첨예해져(Spiked) 이론적으로는 단일한 확정적 결과물만을 산출해야 하기 때문이다.</p>
<p>그러나 실전 소프트웨어 개발 환경에서 이 가정은 위험한 환상에 불과하다. 최근 발표된 “Non-Determinism of Deterministic LLM Settings” 및 관련 실증 연구들에 따르면, 완전히 통제된 환경과 T=0 설정 하에서도 LLM의 출력은 심각한 수준의 비결정성을 드러낸다. 다섯 개의 주요 LLM을 대상으로 한 자연스러운 실행 환경 테스트에서 최고 성능과 최저 성능 간에 최대 70%의 격차가 발생할 수 있으며, 동일 입력에 대한 정확도 편차가 최대 15%에 달함이 입증되었다. 더욱이 120B(1,200억 개) 매개변수를 가진 대형 모델의 경우, 금융 등 규제가 심한 도메인의 엄격한 작업에서 출력 일관성이 12.5%까지 붕괴되는 치명적인 결과가 보고되기도 하였다.</p>
<p>이러한 비결정성의 근본 원인은 단순히 모델의 가중치 결함이나 샘플링 알고리즘의 한계가 아니라, 모델을 구동하는 하드웨어 및 시스템 아키텍처의 저수준(Low-level) 연산 특성에 깊이 뿌리내리고 있다. 그 핵심에는 부동소수점(Floating-point) 연산의 누적 오차가 존재한다. 현대의 대형 언어 모델들은 계산 자원과 메모리 대역폭의 효율성을 극대화하기 위해 FP32 대신 BF16(Bfloat16)이나 FP16과 같은 저정밀도 데이터 타입을 널리 채택하고 있다.</p>
<p>이러한 저정밀도 환경 하에서 텐서 병렬 처리(Tensor Parallelism)가 수행될 때, GPU 커널 내에서 스레드가 비동기적으로 스케줄링되며 부동소수점 덧셈의 순서가 미세하게 뒤바뀌게 된다. 부동소수점 연산은 수학적으로 결합 법칙(Associative Law)이 성립하지 않기 때문에, 연산 순서의 변경은 최종 로짓(Logit) 값에 미세한 반올림 오차(Rounding Errors)를 누적시킨다. 평가 배치 크기(Batch Size)의 변동, 연속 배칭(Continuous Batching), 접두사 캐싱(Prefix Caching)과 같은 시스템 최적화 기법들 역시 입력 버퍼 내의 데이터 정렬 상태를 변화시켜 동일한 프롬프트에 대해서도 매번 다른 메모리 액세스 패턴과 연산 순서를 유발한다.</p>
<p>특히 희소 전문가 혼합(Mixture-of-Experts, MoE) 아키텍처를 채택한 모델의 경우 이러한 문제는 더욱 극대화된다. MoE 모델은 입력 토큰마다 가장 적합한 소수의 ‘전문가(Expert)’ 신경망을 동적으로 선택하여 연산을 라우팅(Dynamic Routing)하는데, 배치 내의 다른 요청들이 라우팅 과정에 간섭을 일으키며 미세한 타이밍 지연과 연산 경로 변경을 초래하기 때문이다.</p>
<p>이러한 하드웨어 및 시스템 레벨의 미세한 노이즈는 소프트맥스(Softmax) 함수를 거치기 전의 로짓 값 차이가 극히 미미한 상황에서 치명적인 나비 효과를 일으킨다. 상위 두 개 토큰의 확률이 소수점 아래 미세한 영역에서 경합을 벌이는 안장점(Saddle Point) 상황이라면, T=0의 탐욕적 디코딩 설정 하에서도 반올림 오차에 의해 최종적으로 선택되는 토큰이 뒤바뀔 수 있다.</p>
<p>제로샷 환경은 문맥적 제약 조건이 빈약하여 확률 분포가 넓게 퍼져 있으므로 이러한 안장점이 발생할 확률이 매우 높다. 즉, 제로샷 프롬프트는 하드웨어의 미세한 노이즈만으로도 문장의 구조나 코드의 논리가 완전히 다른 방향으로 튀어버릴 수 있는 근원적인 취약성을 안고 있는 것이다. 따라서 엄격한 결정론적 오라클을 구축하기 위해서는 제로샷이 가지는 수학적, 아키텍처적 한계를 명확히 인식하고 이를 제어할 수 있는 보완 기법을 필수적으로 도입해야 한다.</p>
<p><strong>주요 자연어 처리 작업에서의 제로샷 및 퓨샷 추론 정확도 비교</strong></p>
<p><img src="./4.5.1.0.0%20%EC%A0%9C%EB%A1%9C%EC%83%B7Zero-Shot%EC%9D%98%20%EB%B6%88%ED%99%95%EC%8B%A4%EC%84%B1%EA%B3%BC%20%ED%93%A8%EC%83%B7Few-Shot%EC%9D%98%20%EC%A7%80%ED%96%A5%EC%84%B1.assets/image-20260226001813794.jpg" alt="image-20260226001813794" /></p>
<p><em>동일한 모델 환경에서 제로샷과 퓨샷 추론 기법을 적용했을 때의 성능 변화. 단순 텍스트 분류와 감성 분석에서는 제로샷도 유의미한 성능을 보이나, 복잡한 문맥 이해가 필요한 기계 번역과 질의응답 작업에서는 퓨샷 예제가 제공될 때 각각 11.4%p, 15.5%p의  비약적인 정확도 향상이 관찰된다.</em></p>
<h2>2. 퓨샷 러닝(Few-Shot Learning) 메커니즘과 지향성(Directionality)의 부여</h2>
<p>소프트웨어 시스템에서 LLM이 오라클로 기능하기 위해서는 앞서 분석한 제로샷의 무한한 생성 가능성과 하드웨어적 비결정성이라는 악조건 속에서도 특정 목적에 부합하는 단일한 결정 경로로 출력을 압축해 내야만 한다. 이러한 제약과 지향성을 가장 효과적이고 실용적으로 부여하는 방법이 바로 퓨샷 러닝(Few-Shot Learning)이다. 퓨샷 프롬프팅은 지시문과 함께 소수(일반적으로 2개에서 10개 내외)의 라벨링된 입력-출력 예제 쌍을 문맥(Context) 내에 배치하여, 모델이 가중치 업데이트 없이도 작업의 패턴을 모방하도록 유도하는 기법이다.</p>
<p>기념비적인 연구인 “Language Models are Few-Shot Learners” (OpenAI의 GPT-3 논문)는 매개변수 규모가 1,750억 개에 달하는 거대 모델이 그레이디언트 업데이트(Gradient Updates)나 데이터 기반의 가중치 미세 조정(Fine-tuning)을 전혀 거치지 않고도 문맥 내 정보만을 활용해 퓨샷 환경에서 뛰어난 성능을 발휘함을 입증하였다. 이 논문은 모델의 크기가 커질수록 인컨텍스트 학습(In-Context Learning, ICL) 능력, 즉 문맥 내에 주어진 예제로부터 과제의 본질을 빠르게 파악하고 적응하는 메타 학습(Meta-Learning) 능력이 기하급수적으로 향상된다는 이른바 ’스케일링 법칙(Scaling Laws)’을 최초로 제시하였다.</p>
<p>이는 LLM을 느리게 학습하는 외부 루프(Outer-loop gradient descent) 메커니즘과, 문맥 내에서 빠르게 새로운 작업에 적응하는 내부 루프(Inner-loop in-context learning) 메커니즘을 동시에 수행하는 메타 학습기(Meta-Learner)로 바라볼 수 있음을 시사한다. 제로샷 환경에서 모델이 사전 학습 데이터베이스라는 드넓은 바다 한가운데서 나침반 없이 표류하는 상태라면, 퓨샷 환경에서 제공되는 예제들은 출력의 형식, 도메인의 어조, 그리고 논리적 제약 조건이라는 뚜렷한 등대 역할을 수행하여 모델의 확률 공간에 강력한 지향성을 부여한다.</p>
<p>특히, 복잡한 비즈니스 로직이나 수학적 추론을 요구하는 작업에서 퓨샷 예제는 단순한 패턴 인식을 넘어선다. 모델 특유의 블랙박스(Black-box) 특성을 완화하기 위해 제안된 사고의 사슬(Chain of Thought, CoT) 프롬프팅과 결합될 경우, 퓨샷 예제는 모델이 최종 결론에 도달하기까지 거쳐야 하는 중간 추론 단계(Intermediate Reasoning Steps)를 모방하도록 강제한다. 이는 모델의 내부 연산 절차를 구조화하여 환각(Hallucination)을 줄이고 논리적 비약을 방지하는 결정적인 기여를 한다.</p>
<p><img src="./4.5.1.0.0%20%EC%A0%9C%EB%A1%9C%EC%83%B7Zero-Shot%EC%9D%98%20%EB%B6%88%ED%99%95%EC%8B%A4%EC%84%B1%EA%B3%BC%20%ED%93%A8%EC%83%B7Few-Shot%EC%9D%98%20%EC%A7%80%ED%96%A5%EC%84%B1.assets/image-20260226001849139.jpg" alt="image-20260226001849139" /></p>
<h2>3. 데몬스트레이션(Demonstrations)의 진정한 역할: 정답인가, 형식인가?</h2>
<p>퓨샷 러닝이 강력한 지향성을 제공하여 불확실성을 축소한다는 사실은 명백하지만, 학계에서는 예제(Demonstration)의 구체적인 ’어떤 특성’이 이러한 경이로운 성능 향상을 이끄는지에 대해 치열한 논쟁이 진행 중이다. 소프트웨어 테스트 오라클 설계자는 이 논쟁의 핵심을 정확히 이해해야만 결정론적 출력을 보장하는 ’골든 예제(Golden Examples)’를 올바르게 구성할 수 있다.</p>
<h3>3.1 형식이 내용을 압도한다는 발견: “Rethinking the Role of Demonstrations”</h3>
<p>이 논쟁의 포문을 연 것은 워싱턴 대학교 연구진이 발표한 “Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?” 연구다. 기존에는 퓨샷 예제에 포함된 올바른 입력과 출력의 논리적 연결(Input-Label Mapping), 즉 ’정답성’이 모델 학습의 핵심이라고 믿어왔다. 그러나 해당 연구진은 GPT-3, GPT-J, MetaICL 등 774M에서 175B에 이르는 12개의 다양한 언어 모델을 대상으로, 퓨샷 예제 내의 정답 라벨(Ground Truth Labels)을 무작위의 틀린 라벨로 교체하거나 아예 무의미한 영어 단어(예: ‘apple’, ‘orange’)로 대체하는 파격적인 실험을 수행했다.</p>
<p>실험 결과는 인공지능 학계에 큰 충격을 주었다. 정답 쌍이 완전히 파괴되어 오답과 노이즈로 가득 찬 예제를 제공받았음에도 불구하고, 모델의 성능 저하는 분류 및 다중 선택 과제 전반에 걸쳐 평균 0%에서 5% 내외에 불과했던 것이다. 심지어 인컨텍스트 학습을 명시적 목표로 메타 훈련(Meta-training)된 MetaICL 모델의 경우 성능 하락폭이 0.1%에서 0.9% 수준으로 거의 무시할 수 있는 정도였다. 무의미한 단어로 라벨을 교체한 Out-of-Distribution (OOD) 실험에서도 모델은 퓨샷 학습이 제공하는 성능 향상분의 75%에서 87%를 그대로 유지했다.</p>
<p>이 획기적인 연구는 퓨샷 프롬프트가 모델에게 올바른 ‘입력-출력 매핑의 논리’ 자체를 새롭게 학습(Learning)시키는 메커니즘이 아님을 시사한다. 대신, 예제가 모델에게 제공하는 핵심적인 지향성 메커니즘은 정답의 진위 여부가 아닌 다음 세 가지 형태적 요소로 압축된다.</p>
<ol>
<li><strong>라벨 공간의 정의 (Label Space Definition)</strong>: 퓨샷 예제는 모델이 최종적으로 선택해야 할 유효한 출력 값의 집합(예: 감성 분석의 ‘Positive/Negative’, 테스트 결과의 ‘Pass/Fail’, 특정 JSON 키 구조의 제약)을 명확히 파악하게 해준다. 이는 모델이 수십만 개의 단어라는 무한한 텍스트 생성 가능성을 극도로 제한된 상태 공간(State Space)으로 축소시키게 만들며, 앞서 논의한 엔트로피를 급격히 낮추는 결정적 요인이다.</li>
<li><strong>입력 데이터 분포의 제시 (Distribution of the Input Text)</strong>: 예제에 포함된 입력 텍스트들의 통계적 분포는 쿼리가 속한 특정 맥락과 도메인을 한정 짓는다. 이를 통해 모델은 사전 학습된 방대한 신경망의 가중치 중 현재 작업과 연관성이 높은 특정 지식 클러스터(Latent Concepts)만을 선별적으로 활성화하게 된다.</li>
<li><strong>시퀀스의 전체적 형식 고정 (Overall Format of the Sequence)</strong>: 입력과 출력이 특정한 기호나 패턴으로 쌍을 이루어 연속적으로 나열되는 시퀀스의 구조적 형태(Structural Format) 그 자체가 예측 가능성을 높이는 핵심 인자다. 모델은 이 패턴을 인식하고 단순히 해당 패턴을 완성하려는 방향으로 문장을 생성해 나간다.</li>
</ol>
<p>즉, 언어 모델 관점에서 퓨샷 예제는 새로운 논리적 규칙을 ‘가르치는’ 교과서라기보다는, 모델이 이미 내부에 내재화하고 있는 방대한 잠재 지식 중에서 현재 작업 형태에 딱 맞는 지식 구조를 끄집어내는 ’트리거(Trigger)’이자 ’형식적 주형(Mold)’으로 작용하는 것이다. 이러한 특성은 구조화된 출력이 절대적인 소프트웨어 오라클 생성 시, 정답 자체를 모델에게 설득하려 하기보다 일관된 포맷을 강력하게 반복 제시하는 것이 훨씬 효과적일 수 있음을 시사한다.</p>
<p><img src="./4.5.1.0.0%20%EC%A0%9C%EB%A1%9C%EC%83%B7Zero-Shot%EC%9D%98%20%EB%B6%88%ED%99%95%EC%8B%A4%EC%84%B1%EA%B3%BC%20%ED%93%A8%EC%83%B7Few-Shot%EC%9D%98%20%EC%A7%80%ED%96%A5%EC%84%B1.assets/image-20260226001910660.jpg" alt="image-20260226001910660" /></p>
<h2>4. 정답의 중요성을 옹호하는 반론: 복잡한 추론과 오라클에서의 진실성</h2>
<p>그러나 소프트웨어 검증과 같이 고도로 복잡한 연역적 추론이 요구되는 도메인에서도 ’형식’만이 전부일 수는 없다. 앞선 연구 결과에 대해 반박하며, 작업의 난이도가 올라갈수록 퓨샷 예제에 포함된 정답의 논리적 정확성(Ground-Truth)이 결정적인 영향을 미친다는 반론성 연구들이 속속 발표되며 논쟁의 깊이를 더하고 있다.</p>
<h3>4.1 기계론적 해석: 과잉 사고(Overthinking)와 거짓 귀납 헤드</h3>
<p>“Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations” 연구와 “Overthinking the Truth: Understanding how Language Models Process False Demonstrations” 연구는 퓨샷 예제의 내용적 정합성이 훼손될 경우 모델 내부의 어텐션 메커니즘에서 치명적인 오작동이 발생함을 기계론적 해석(Mechanistic Interpretability) 관점에서 최초로 규명했다.</p>
<p>기계론적 해석은 신경망을 블랙박스로 두지 않고, 개별 파라미터나 어텐션 헤드(Attention Heads) 단위로 정보의 흐름을 역추적하는 접근법이다. 연구진이 오답으로 채워진 퓨샷 예제를 모델에 주입하고 각 신경망 계층(Layers)에서의 상태 변화를 추적한 결과, 흥미로운 현상이 관찰되었다. 연산의 초기 계층(Early Layers)에서는 올바른 예제와 틀린 예제를 처리할 때 모델의 행동 양식에 큰 차이가 없었다. 즉, 모델은 초반부 연산에서는 예제의 형태적인 피처(Feature)를 추출하는 데 집중한다.</p>
<p>그러나 특정 임계 계층(Critical Layer)을 지나는 순간부터 두 조건 간의 거동이 날카롭게 분기하기 시작한다. 정답 예제를 받은 모델은 층이 깊어질수록 정확도가 점진적으로 상승하지만, 오답 예제에 노출된 모델은 임계 계층 이후 오히려 정확도가 급격히 붕괴되는 ‘과잉 사고(Overthinking)’ 현상을 일으킨다. 초기에는 사전 학습된 지식을 바탕으로 올바른 정답을 도출해 내는 듯 보이지만, 연산이 깊어질수록 퓨샷 예제로 주어진 ’오답의 함정’을 너무 깊이 숙고한 나머지 자신의 올바른 판단을 뒤집어버리는 것이다.</p>
<p>이러한 붕괴의 주범은 모델의 후반부 계층에 똬리를 틀고 있는 이른바 ’거짓 귀납 헤드(False Induction Heads)’로 밝혀졌다. 귀납 헤드는 문맥 내에서 이전에 등장했던 특정 패턴을 기억하고 이를 다음 예측에 복사(Copying)하는 역할을 수행하는 핵심 어텐션 메커니즘이다. 문제는 이 헤드들이 예제로 주어진 잘못된 정보 패턴, 즉 치명적인 사실관계의 오류나 논리적 모순에 과도하게 주의(Attention)를 기울이고 이를 무비판적으로 현재의 쿼리에 복사-붙여넣기 하는 악의적인 모방 행위를 수행한다는 점이다. 실제로 연구진이 모델 전체 헤드 중 불과 1%에 해당하는 5개의 거짓 귀납 헤드만을 인위적으로 제거(Ablation)하자, 오답 프롬프트로 인해 발생했던 정확도 하락폭의 38.3%가 즉시 복구되는 놀라운 결과가 확인되었다.</p>
<h3>4.2 소프트웨어 공학 도메인에서의 함의</h3>
<p>이러한 발견은 소프트웨어 공학 도메인, 특히 코드 분석, 수학적 추론, 논리적 증명 등을 수행하는 오라클을 설계할 때 막대한 시사점을 던진다. 감성 분석이나 텍스트 주제 분류와 같이 단순 패턴 인식이 주가 되는 작업에서는 퓨샷 예제가 무작위 라벨을 가지더라도 형식의 힘으로 극복이 가능하다. 하지만 구조가 복잡하고 도메인 지식이 요구되는 작업에서는 퓨샷 프롬프트 내에 단 한 줄의 잘못된 코드 로직이나 잘못 짝지어진 Assert 문이 존재할 경우, 거짓 귀납 헤드가 이를 포착하여 검증 결과 전체를 오염시키게 된다.</p>
<p>특히, 소프트웨어 코딩이나 테스트 생성과 같은 작업은 입력과 출력 간의 관계가 자연어처럼 느슨하지 않고 수학적으로 엄밀하게 결합되어 있다. 따라서 퓨샷 예제의 형식을 통일하여 라벨 공간을 제어하는 것은 기본 전제 조건일 뿐이며, 비즈니스 로직의 결함을 짚어내는 오라클의 일관성을 담보하기 위해서는 논리적 결함이 전혀 없는 완벽한 ’골든 예제(Golden Examples)’의 제공이 필수 불가결하다.</p>
<p>결론적으로, 오라클 구축을 위한 퓨샷 엔지니어링은 두 학파의 주장을 전략적으로 통합해야 한다. JSON 형식 강제나 SQL 구문 규칙과 같은 ’형식적 일관성’을 부여하기 위해서는 구조적 통일성이 극대화된 예제를 다수 제공하여 엔트로피를 낮추어야 한다. 동시에, 도메인 특화 추론이나 보안 취약점 점검과 같은 ’내용적 무결성’을 확보하기 위해서는 거짓 귀납 헤드의 역기능을 차단할 수 있도록, 엣지 케이스를 포함하되 사실관계가 100% 검증된 정밀한 예제만을 프롬프트에 주입하는 이원화된 접근이 요구된다.</p>
<h2>5. 소프트웨어 테스트 오라클 구축을 위한 제로샷과 퓨샷의 실전 적용</h2>
<p>결정론적 정답지(Deterministic Ground Truth) 설계 원칙에 비추어 볼 때, AI 모델을 기반으로 한 소프트웨어 오라클은 테스트 케이스의 통과 여부(Pass/Fail)를 판별하거나, 엄격한 구조를 지닌 테스트 스크립트 및 단언문(Assert)을 자동 생성해야 하는 막중한 책임을 지닌다. 이러한 고도의 정확성과 문법적 무결성이 요구되는 환경에서 제로샷과 퓨샷의 차이는 단순한 벤치마크 점수 몇 퍼센트의 차이를 넘어, 시스템의 컴파일 성공 여부와 전체 CI/CD 파이프라인의 안정성을 좌우하는 생존의 문제로 직결된다.</p>
<h3>5.1 테스트 오라클 생성에서의 실증적 격차와 함정</h3>
<p>최근 소프트웨어 공학 분야에서 수행된 ’LLM 기반 테스트 오라클 생성’에 대한 대규모 실증 연구(Empirical Study)는 프롬프팅 기법과 컨텍스트의 제공 수준이 생성된 오라클의 품질에 지대한 영향을 미친다는 것을 명백히 입증했다. 해당 연구진은 제로샷, 퓨샷, 그리고 복잡한 논리 전개를 유도하는 CoT(Chain-of-Thought) 및 ToT(Tree-of-Thought) 기법을 실제 버그 검출 코드베이스에 적용하여 결과를 분석했다.</p>
<p>분석 결과는 흥미롭게도 프롬프트 엔지니어링의 통념을 뒤집었다. 일반적으로 복잡한 문제 해결에 유리하다고 알려진 CoT나 ToT 기법은, 코드를 작성하고 컴파일해야 하는 오라클 생성 작업에 있어서 오히려 컴파일 성공률이 50% 미만으로 추락하는 저조한 성적을 기록했다. 모델이 스스로 중간 추론 단계를 자연어로 장황하게 풀어내는 과정에서 소스 코드의 엄격한 문법과 충돌하거나 불필요한 주석 처리를 양산하여 코드의 형태적 무결성을 스스로 파괴한 탓이다.</p>
<p>반면, 퓨샷(Few-Shot) 프롬프팅은 72.96%라는 압도적으로 높은 컴파일률과 54.56%의 버그 검출 정확도를 달성하며 모든 프롬프팅 기법 중 가장 뛰어난 안정성과 유용성을 입증했다. 제로샷 역시 67.38%의 준수한 컴파일률을 보였으나, 버그를 잡아내는 실질적인 정확도 면에서는 퓨샷에 미치지 못했다. 이는 소프트웨어 컴파일이라는 극도로 엄격한 구문 규칙(Syntax Rules) 세계에서는 모델에게 ’생각하는 방법(CoT)’을 자율적으로 맡기며 불확실성을 키우는 것보다, 올바른 코드 작성 패턴과 Assert 구조를 직접 명시적으로 보여주는 퓨샷 예제가 형태적 제약 조건을 훨씬 더 강력하고 안전하게 강제함을 의미한다.</p>
<p>더불어, 입력으로 제공되는 컨텍스트의 범위 또한 오라클의 품질을 가르는 중요한 변수였다. 모델에게 단순히 테스트 대상 메서드(MUT, Method Under Test)의 정보만 제공했을 때보다, 해당 메서드가 포함된 클래스 전체(CUT, Class Under Test)의 컨텍스트를 제로샷이나 퓨샷과 결합하여 제공했을 때 오라클의 오류 검출 능력이 40.74%에서 53.64%로 급상승하며 가장 안정적인 성능을 발휘했다. 이는 퓨샷의 지향성 부여 능력에 더해, 클래스 레벨의 넓은 문맥이 결합될 때 인식론적 불확실성이 최소화됨을 보여준다.</p>
<p>그러나 퓨샷 기반의 테스트 생성 시스템을 구축할 때 반드시 주의해야 할 치명적인 함정이 존재한다. LLM은 본질적으로 문맥 내의 코드 패턴과 명명 규칙(Naming Conventions)을 통계적으로 모방하는 데 극도로 특화되어 있다. 이러한 모방 편향성 때문에, 퓨샷 예제를 부주의하게 구성할 경우 모델은 개발자가 진정으로 의도한 ’기대되는 올바른 동작(Expected Behavior)’을 검증하는 오라클을 생성하는 대신, 프롬프트에 포함된 현재 결함이 있는 코드의 ’실제 동작(Actual Behavior)’을 그대로 정답으로 간주하는 회귀 테스트(Regression Test)용 오라클만을 무비판적으로 양산하게 될 위험이 매우 높다.</p>
<p>실제로 퓨샷 기반 테스트 생성기에 대한 분석 결과, 많은 LLM들이 기존 코드의 변수명이나 구조적 흐름에 지나치게 얽매여 논리적 결함마저도 테스트 통과 기준으로 삼는 현상이 다수 보고되었다. 따라서 확정적 오라클로 기능하기 위해서는 퓨샷 예제 내에 도메인의 비즈니스 로직과 시스템 명세(Specification)가 뚜렷이 드러나는 골든 데이터를 엄선해야 하며, 모델이 모호한 함수명 대신 명시적이고 시맨틱한 명명 규칙을 참고하여 실제 동작과 기대 동작을 명확히 분리해 낼 수 있도록 강제해야 한다.</p>
<h3>5.2 텍스트-SQL (Text-to-SQL) 및 구조화 작업에서의 확정적 검증 오라클 구축</h3>
<p>AI를 활용한 소프트웨어 개발 중 가장 대표적이고 난이도 높은 과제 중 하나인 텍스트-SQL(Text-to-SQL) 파싱 시스템의 경우, 자연어 쿼리를 정확하고 실행 가능한 결정론적 데이터베이스 쿼리로 변환해야 하므로 오라클의 통제 역할이 절대적이다. 텍스트-SQL 과제는 WikiSQL, Spider 등 다양한 벤치마크 데이터셋을 통해 그 한계가 철저히 분석되어 왔는데, 특히 기존의 제로샷 접근법은 훈련 데이터에 한 번도 등장하지 않은 새로운 테이블 스키마(Zero-Shot Subset)를 마주했을 때 심각한 환각(Hallucination) 현상을 일으킨다. 조인(JOIN) 조건을 누락하거나, 존재하지 않는 컬럼명을 창조해내거나, 잘못된 집계 함수(Aggregation)를 사용하는 등 치명적인 구조적 오류를 발생시켜 실행조차 불가능한 SQL을 토해내는 경우가 빈번하다.</p>
<p>이러한 제로샷의 한계를 극복하기 위해 제안된 ’DeepEye-SQL’과 같은 최신 프레임워크는 퓨샷 학습과 다중 버전 프로그래밍(N-version Programming)을 결합하여 강력한 오라클 도구 체인(Tool-Chain)을 구축하는 하이브리드 전략을 취한다. 이 시스템은 단순히 모델 한 번의 제로샷 생성을 맹신하지 않는다. 대신, 입력된 자연어 쿼리와 가장 유사한 시맨틱 구조를 가진 사전에 검증된 예제들을 동적으로 검색하여 최적화된 퓨샷 프롬프트를 구성한다.</p>
<p>더 나아가, 퓨샷을 통해 생성된 산출물은 단일 모델의 확률적 결과물로 종결되지 않고, 결정론적 규칙 기반의 유닛 테스트 묶음을 차례대로 통과하는 파이프라인을 거치게 된다. 예를 들어, 구문 검사기(Syntax Checker)가 기본 컴파일 여부를 확인하고, 조인 검사기(JOIN Checker)가 테이블 간의 연결 무결성을 판별하며, MaxMin 검사기가 최적화되지 않은 정렬 구문을 찾아내고, NULL 검사기가 잠재적 예외 상황을 방어하는 방식이다.</p>
<p>이러한 아키텍처에서 퓨샷 프롬프트는 제로샷이 가진 무한하고 무질서한 SQL 생성 궤도를 사전에 정의된 데이터베이스 스키마와 문법의 궤도 내부로 안전하게 진입시키는 1차적인 ’방향타(Directional Rudder)’로 작용한다. 그리고 뒤이어 촘촘히 배치된 결정론적 파서(Parser) 기반의 오라클 체인은 이 궤도 내에서 미세하게 어긋난 오류를 확정적으로 검증하고 수정 지침을 내려 다시 모델에게 자체 교정(Self-Correction)을 요구하는 2차 방어선 역할을 수행한다. 이는 확률적 생성의 유연성(Few-Shot Generation)과 연역적 검증의 엄밀성(Deterministic Oracle)이 완벽하게 조화를 이룬 파이프라인의 모범 사례라 할 수 있다.</p>
<table><thead><tr><th><strong>제어 계층</strong></th><th><strong>역할 분담</strong></th><th><strong>달성 목적</strong></th><th><strong>핵심 메커니즘</strong></th></tr></thead><tbody>
<tr><td><strong>1차 방어선</strong> (확률적 제어)</td><td>퓨샷 프롬프팅 (Few-Shot Prompting)</td><td>어휘 공간 축소 및 문법/형식의 초기 지향성 부여</td><td>입력-출력 매핑 예제 주입, 라벨 공간 정의</td></tr>
<tr><td><strong>2차 방어선</strong> (구조적 제어)</td><td>제약 기반 디코딩 (Constrained Decoding)</td><td>구문적 무결성 확보 및 구조적 이탈 원천 차단</td><td>JSON Schema 강제, Logit 바이어싱 제어</td></tr>
<tr><td><strong>3차 방어선</strong> (결정론적 제어)</td><td>툴 체인 오라클 (Deterministic Tool-Chain)</td><td>의미론적 정합성 및 실행 가능성 최종 검증</td><td>구문 파서, 정적 분석, 단위 테스트 기반 검사</td></tr>
</tbody></table>
<p>결론적으로, 확률과 불확실성의 산물인 대형 언어 모델을 소프트웨어 엔지니어링의 가장 엄격한 결정론적 도구로 탈바꿈시키기 위해서는 단일한 기술에 의존해서는 안 된다. 제로샷이 가진 인식론적 불확실성의 본질을 이해하고, 이를 통제하기 위해 ‘골든 예제’ 기반의 퓨샷 러닝으로 모델의 사고 궤도를 정밀하게 세팅해야 한다. 더 나아가, 부동소수점 연산의 미세한 노이즈로 인해 발생하는 시스템적 비결정성마저 억제하기 위해서는, 최종 출력단에 파서나 컴파일러와 같은 전통적인 규칙 기반의 확정적 검증 오라클을 덧대는 다층적 하이브리드(Multi-layered Hybrid) 프레임워크의 도입이 필수 불가결하다. 이것만이 AI 시대의 소프트웨어 개발에서 완벽에 가까운 재현성과 신뢰성을 쟁취할 수 있는 유일한 공학적 해법이다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>Few-Shot, Zero-Shot, and In-Context Learning: Business Value, https://medium.com/@amitkharche/few-shot-zero-shot-and-in-context-learning-business-value-explained-541741eb216b</li>
<li>LLM Empowered Prototype Learning for Zero and Few-Shot Tasks, https://arxiv.org/html/2508.09263v1</li>
<li>Zero-Shot vs One-Shot vs Few-Shot Learning - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/zero-shot-vs-one-shot-vs-few-shot-learning/</li>
<li>(PDF) Few-Shot and Zero-Shot Learning: Generalizing from Minimal, https://www.researchgate.net/publication/390122544_Few-Shot_and_Zero-Shot_Learning_Generalizing_from_Minimal_or_No_Data</li>
<li>An Information-Theoretic Perspective on Multi-LLM Uncertainty, https://www.medrxiv.org/content/10.1101/2025.07.09.25331207v1.full-text</li>
<li>NOISE INFORMED LLM FOR ZERO-SHOT TIME SERIES, https://openreview.net/pdf?id=MrZKs5ZlP2</li>
<li>Uncertainty Estimation and Quantification for LLMs - arXiv, https://arxiv.org/html/2404.15993v1</li>
<li>Non-Determinism of “Deterministic” LLM Settings - arXiv, https://arxiv.org/html/2408.04667v4</li>
<li>Non-Determinism of “Deterministic” LLM Settings - arXiv, https://arxiv.org/html/2408.04667v5</li>
<li>On Measuring Large Language Models Performance with Inferential, https://www.mdpi.com/2078-2489/16/9/817</li>
<li>LLM Output Drift: Cross-Provider Validation &amp; Mitigation for Financial, https://www.alphaxiv.org/overview/2511.07585v1</li>
<li>Understanding and Mitigating Numerical Sources of … - OpenReview, https://openreview.net/pdf?id=Q3qAsZAEZw</li>
<li>Defeating Nondeterminism in LLM Inference, The Future is Predictable, https://hackernoon.com/re-defeating-nondeterminism-in-llm-inference-the-future-is-predictable</li>
<li>What is Zero, One, and Few-Shot LLM Prompting? | by Tahir | Medium, https://medium.com/@tahirbalarabe2/what-is-zero-one-and-few-shot-llm-prompting-946fc5f64ec3</li>
<li>Review — GPT-3: Language Models are Few-Shot Learners, https://sh-tsang.medium.com/review-gpt-3-language-models-are-few-shot-learners-ff3e63da944d</li>
<li>Language Models are Few-Shot Learners - NIPS, https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</li>
<li>(PDF) Language Models are Few-Shot Learners - ResearchGate, https://www.researchgate.net/publication/341724146_Language_Models_are_Few-Shot_Learners</li>
<li>Language models are few-shot learners - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/language-models-are-few-shot-learners/</li>
<li>Zero-Shot and Few-Shot Learning with Reasoning LLMs, https://machinelearningmastery.com/zero-shot-and-few-shot-learning-with-reasoning-llms/</li>
<li>Zero-Shot vs Few-Shot Prompting: Key Differences - newline, https://www.newline.co/@zaoyang/zero-shot-vs-few-shot-prompting-key-differences–b4c84775</li>
<li>Understanding LLM-Driven Test Oracle Generation - arXiv, https://arxiv.org/html/2601.05542v1</li>
<li>Rethinking the Role of Demonstrations: What Makes In-Context …, https://arxiv.org/abs/2202.12837</li>
<li>Rethinking the Role of Demonstrations: What Makes In-Context, https://www.researchgate.net/publication/358898642_Rethinking_the_Role_of_Demonstrations_What_Makes_In-Context_Learning_Work</li>
<li>Rethinking the Role of Demonstrations: What Makes In-Context, https://aclanthology.org/2022.emnlp-main.759/</li>
<li>[PDF] Rethinking the Role of Demonstrations - Semantic Scholar, https://www.semanticscholar.org/paper/f4df78183261538e718066331898ee5cad7cad05</li>
<li>Large Language Models Are Latent Variable Models: Explaining and, <a href="https://openreview.net/forum?id=BGvkwZEGt7&amp;noteId=iq77U55B2P">https://openreview.net/forum?id=BGvkwZEGt7¬eId=iq77U55B2P</a></li>
<li>(PDF) Overthinking the Truth: Understanding how Language Models, https://www.researchgate.net/publication/372444766_Overthinking_the_Truth_Understanding_how_Language_Models_Process_False_Demonstrations</li>
<li>EMNLP 2022 Papers with Semantic Skimming, https://skim.scholar.cat/</li>
<li>DeepEye-SQL: A Software-Engineering-Inspired Text-to … - arXiv.org, https://arxiv.org/html/2510.17586v1</li>
<li>Understanding LLM-Driven Test Oracle Generation - ResearchGate, https://www.researchgate.net/publication/399667319_Understanding_LLM-Driven_Test_Oracle_Generation</li>
<li>Understanding LLM-Driven Test Oracle Generation - arXiv, https://www.arxiv.org/pdf/2601.05542</li>
<li>An Empirical Evaluation of Using Large Language Models for, https://www.computer.org/csdl/journal/ts/2024/01/10329992/1SrOoQORr2w</li>
<li>(PDF) Do LLMs generate test oracles that capture the actual or the, https://www.researchgate.net/publication/385318406_Do_LLMs_generate_test_oracles_that_capture_the_actual_or_the_expected_program_behaviour</li>
<li>Zero-Shot Text-to-SQL Learning with Auxiliary Task, https://ojs.aaai.org/index.php/AAAI/article/view/6246/6102</li>
<li>Natural Language Interfaces for Tabular Data Querying and, https://www.computer.org/csdl/journal/tk/2024/11/10530359/1WWdVpae7FC</li>
<li>A Systematic Literature Review of Text-to-SQL: Performance … - ICCK, https://www.icck.org/article/abs/tacs.2025.497935</li>
<li>Publications – Alex Polozov, https://alexpolozov.com/publication/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>