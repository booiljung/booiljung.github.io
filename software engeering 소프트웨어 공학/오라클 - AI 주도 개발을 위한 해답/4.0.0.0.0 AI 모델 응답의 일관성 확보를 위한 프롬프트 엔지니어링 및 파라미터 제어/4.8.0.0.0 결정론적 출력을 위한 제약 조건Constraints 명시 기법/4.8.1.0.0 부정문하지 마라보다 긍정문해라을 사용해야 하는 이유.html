<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:4.8.1 부정문("~하지 마라")보다 긍정문("~해라")을 사용해야 하는 이유</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>4.8.1 부정문("~하지 마라")보다 긍정문("~해라")을 사용해야 하는 이유</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 4. AI 모델 응답의 일관성 확보를 위한 프롬프트 엔지니어링 및 파라미터 제어</a> / <a href="index.html">4.8 결정론적 출력을 위한 제약 조건(Constraints) 명시 기법</a> / <span>4.8.1 부정문("~하지 마라")보다 긍정문("~해라")을 사용해야 하는 이유</span></nav>
                </div>
            </header>
            <article>
                <h1>4.8.1 부정문(“~하지 마라”)보다 긍정문(“~해라”)을 사용해야 하는 이유</h1>
<h1>4.8.1 부정문(“~하지 마라”)보다 긍정문(“~해라”)을 사용해야 하는 이유</h1>
<p>AI 기반 소프트웨어 개발에서 대규모 언어 모델(Large Language Model, LLM)을 결정론적 정답지를 제공하는 오라클(Oracle)로 활용하기 위해서는 프롬프트의 구조와 의미론적 명확성이 시스템의 신뢰성을 좌우하는 핵심 요소가 된다. 인간의 인지 체계는 “X를 제외하고”, “Y를 하지 마라“와 같은 부정(Negation)의 제약 조건을 직관적으로 이해하고 수행할 수 있지만, 확률적 토큰 생성기인 LLM의 아키텍처는 부정문을 처리하는 데 있어 근본적인 기술적 한계와 논리적 결함을 노출한다.</p>
<p>프롬프트 엔지니어링에서 부정문보다 긍정문(“~해라”)을 명시적인 제약 조건으로 사용해야 하는 이유는 단순한 언어적 관습의 문제를 넘어, 트랜스포머(Transformer) 모델의 어텐션 메커니즘(Attention Mechanism), 내부 통신 대역폭의 물리적 한계, 그리고 사전 학습 데이터의 분포 편향성에 기인하는 구조적 문제이다. 본 절에서는 LLM이 부정문을 처리할 때 발생하는 기술적 충돌의 원인을 심층적으로 분석하고, 결정론적 출력을 보장하기 위해 긍정적 제약 조건(Positive Constraints)을 설계해야 하는 당위성과 실전 가이드라인을 제시한다.</p>
<h2>1.  토큰 생성의 확률론적 특성과 긍정적 선택(Positive Selection) 편향의 역학</h2>
<p>대규모 언어 모델의 텍스트 생성 과정은 본질적으로 현재까지 주어진 컨텍스트를 바탕으로 다음에 등장할 토큰의 확률 분포를 계산하고, 가장 높은 확률을 가진 토큰을 선택하는 자기회귀(Autoregressive) 프로세스이다. 이 과정은 근본적으로 ’긍정적 선택(Positive Selection)’에 편향되어 있다. 즉, 모델의 가중치 행렬과 소프트맥스(Softmax) 활성화 함수는 주어진 문맥에서 ’다음에 어떤 토큰이 와야 하는가’를 예측하고 그 확률을 극대화하는 데 최적화되어 있지, ’어떤 토큰을 피해야 하는가’를 억제하는 데 최적화되어 있지 않다.</p>
<p>소프트웨어의 오라클은 입력값에 대해 항상 유일하고 정확한 출력값을 보장해야 하는 결정론적(Deterministic) 특성을 요구한다. 그러나 프롬프트에 “A를 하지 마라(Do not do A)“라는 부정적 지시어가 포함될 경우, 확률론적 통계 모델의 관점에서 이는 A와 관련된 토큰들의 생성 확률을 미세하게 감소시키는 역할에 그칠 때가 많다. 부정문은 모델에게 ’무엇을 피해야 하는지’만을 제한적으로 알려줄 뿐, ’그렇다면 대안으로 무엇을 생성해야 하는지’에 대한 명시적인 타겟 확률을 증폭시키지 못한다. 방대한 파라미터 공간 속에서 하나의 오답을 배제한다고 하더라도, 무한에 가까운 또 다른 오답의 확률 공간이 여전히 열려 있기 때문에 출력의 일관성을 확보할 수 없다.</p>
<p>반면, “B를 해라(Always do B)“라는 긍정적 지시어는 B와 관련된 토큰들의 확률을 직접적이고 압도적으로 증폭시켜, 원하는 결과물로 토큰 생성을 강제하는 효과를 발휘한다. 이러한 확률 분포의 차이는 AI를 결정론적 오라클로 활용해야 하는 자동화 파이프라인에서 치명적인 결과의 차이를 만들어낸다. 예를 들어, JSON 스키마 기반의 데이터를 파싱하여 출력하도록 강제할 때 시스템 프롬프트에 “값이 없는 필드는 포함하지 마라“라고 지시하면, 모델은 스키마에 정의된 구조적 패턴을 기계적으로 따르려는 강력한 사전 학습 관성에 의해 종종 부정 지시를 무시하고 빈 필드를 생성해 버린다. 반면 “값이 있는 필드만 포함해라“라고 긍정형 제약으로 변환하면, 출력에 포함될 대상의 조건이 명확해져 타겟 토큰의 활성화 확률이 급증하게 되고, 결과적으로 결정론적 결과물을 얻을 확률이 극대화된다. 이는 프롬프트 엔지니어링이 단순한 대화형 질의가 아니라, 모델의 토큰 확률 분포를 제어하는 ‘제약 기반 컴파일(Constraint-based compilation)’ 과정임을 시사한다.</p>
<h2>2.  어텐션 대역폭 한계와 BAPO(Bounded Attention Prefix Oracle) 모델의 증명</h2>
<p>LLM이 부정형 지시를 제대로 따르지 못하는 현상은 단순한 확률 계산의 문제를 넘어, 딥러닝 아키텍처의 핵심인 어텐션 메커니즘이 지닌 내부 통신 대역폭(Effective Bandwidth)의 물리적 한계로 설명된다. 논문 <em>Capacity limits on the accurate flow of information within LLMs</em>에서 제안된 BAPO(Bounded Attention Prefix Oracle) 모델은 어텐션 헤드의 대역폭 제약을 수학적으로 엄밀하게 모델링하여 LLM이 왜 특정 논리적 추론에서 근본적으로 실패하는지를 증명한다.</p>
<p>트랜스포머 모델이 입력된 문맥을 바탕으로 글로벌 추론(Global Reasoning)을 수행하기 위해서는, 프롬프트 초반에 제시된 제약 조건에 대한 정보가 어텐션 메커니즘을 통해 마지막 토큰의 잔차 스트림(Residual Stream)까지 정확하게 전달되고 유지되어야 한다. 부정문은 본질적으로 문장 전체 또는 특정 구문의 의미를 역전(Reverse)시키는 전역적 논리 연산이다. “X에 대한 내용을 포함하되, Y의 특성을 가진 것은 제외하라“는 복합적인 제약 조건이 주어졌을 때, 모델은 출력 텍스트를 생성하는 매 토큰마다 X의 특성을 유지하면서도 Y라는 부정 조건의 상태(State)를 내부적으로 추적하고 결합해야 한다.</p>
<p>BAPO 모델의 분석 틀에서 볼 때, 단순한 키워드 검색(Index)이나 단일 사실의 추출 문제는 요구되는 정보 전송량이 적은 ‘BAPO-easy’ 문제에 속한다. 그러나 복잡한 상호 토큰 의존성(Inter-token dependencies)을 요구하는 부정 논리의 적용은 매우 높은 통신 대역폭을 지속적으로 필요로 하는 ‘BAPO-hard’ 문제에 속한다. 특히 LLM이 채택하고 있는 인과적 어텐션(Causal Attention) 구조는 초기 스트림에서의 전처리가 후속 토큰과 철저히 독립적으로 이루어지도록 강제하기 때문에, 문제의 표현 크기가 기하급수적으로 증가하게 된다.</p>
<p>결과적으로, 부정어(“not”, “never”)가 가지는 엄격한 논리적 제약은 모델의 깊은 레이어(Deep Layers)를 거치며 수많은 어텐션 연산 속에서 그 의미가 희석되거나 정보 병목(Information bottleneck)에 의해 완전히 소실되는 현상이 발생한다. 대역폭의 한계로 인해 부정 논리의 상태 값이 정확히 전달되지 못하면, 모델은 마치 프롬프트에 부정어가 처음부터 존재하지 않았던 것처럼 긍정문으로 오작동하게 된다. 이러한 아키텍처 레벨의 한계는 단순한 프롬프트 튜닝만으로는 극복하기 어려우며, 복잡한 부정 제약 조건을 정보 요구량이 적은 분절된 긍정문으로 재구성해야 하는 당위성을 제공한다.</p>
<h2>3.  아이러니한 반동(Ironic Rebound)과 레이어 내부의 투쟁 매커니즘</h2>
<p>부정문을 사용할 때 오라클의 신뢰성이 무너지는 가장 치명적이고 역설적인 원인은 인지 심리학의 ‘아이러니한 반동(Ironic Rebound)’ 현상이 트랜스포머 언어 모델의 내부 신경망에서도 완벽하게 동일하게 관측된다는 점이다. 심리학에서 아이러니한 반동이란 “흰 곰을 생각하지 마라“고 지시하면 오히려 흰 곰에 대한 생각이 억눌린 상태를 뚫고 뇌리를 더욱 강하게 지배하는 현상을 말한다. 논문 <em>Ironic Rebound in Large Language Models</em>의 연구에 따르면, LLM에게 “X를 언급하지 마라(Do not mention X)“라는 명시적인 부정 지시가 주어졌을 때, 모델이 X를 억제(Suppress)하기 위해서는 역설적으로 내부 임베딩 표현 공간에서 X라는 개념을 명시적으로 활성화(Activate)해야만 한다.</p>
<p>이 과정에서 억제해야 할 토큰이 오히려 다음 단어 예측의 유력한 후보로 부상하는 기술적 아이러니가 발생한다. 모델의 계층적(Layer-wise) 정보 처리 과정을 심층적으로 분석해보면, 모델 내부는 부정 지시를 따르려는 세력과 억제된 토큰을 방출하려는 세력 간의 극심한 내부 투쟁을 겪게 된다.</p>
<p><img src="./4.8.1.0.0%20%EB%B6%80%EC%A0%95%EB%AC%B8%ED%95%98%EC%A7%80%20%EB%A7%88%EB%9D%BC%EB%B3%B4%EB%8B%A4%20%EA%B8%8D%EC%A0%95%EB%AC%B8%ED%95%B4%EB%9D%BC%EC%9D%84%20%EC%82%AC%EC%9A%A9%ED%95%B4%EC%95%BC%20%ED%95%98%EB%8A%94%20%EC%9D%B4%EC%9C%A0.assets/image-20260226202738831.jpg" alt="image-20260226202738831" /></p>
<p>위의 메커니즘을 상세히 살펴보면, 초기 입력에 가까운 0~7 레이어에서는 모델이 사용자의 지시를 수용하여 금지된 개념의 활성화를 적극적으로 억제(Suppression)하는 경향을 보인다. 그러나 정보가 네트워크의 더 깊은 곳으로 전달되어 8~16 레이어의 중간 구역에 도달하면 상황이 급변한다. 컨텍스트 내에 강하게 자리 잡은 개념(X)이 어텐션 가중치를 지속적으로 자극함에 따라, 억제를 유지하려는 어텐션 헤드(Suppressors)와 금지된 개념의 토큰 확률을 폭발적으로 높이려는 증폭 어텐션 헤드(Amplifiers) 간의 극단적인 변동성이 촉발된다.</p>
<p>이러한 내부 충돌은 모델 전체에 존재하는 1,000개 이상의 어텐션 헤드 중 매우 희소한(Sparse) 숫자에 의해 주도된다. 연구에 따르면, 중간 레이어에 집중 분포된 불과 15~20개 내외의 극소수 어텐션 헤드(각 레이어당 약 1~2개)가 전체 아이러니한 반동 효과의 80% 이상을 유발하며 초기 레이어가 내렸던 억제 결정을 완전히 뒤집어 버린다. 강력한 억제기(Suppressors)는 대개 8~13 레이어에 포진해 있는 반면, 치명적인 오류를 낳는 증폭기(Amplifiers)는 12~17 레이어 부근에 집중되어 있어, 결과적으로 텍스트 생성의 최종 결정을 내리는 후반부 레이어에 도달하기 직전에 억제 장치가 풀려버리게 된다.</p>
<p>이러한 반동 현상은 금지된 토큰의 주변 문맥 길이가 길어지거나, 의미론적으로 연관은 있으나 명시적이지 않은 방해물(Semantic distractors)이 프롬프트에 혼합될 때 기하급수적으로 심화된다. 이러한 모델의 취약성을 수학적으로 정량화하기 위해 연구자들은 ’놀라움의 차이(Surprisal Difference, <span class="math math-inline">\Delta s(\ell)</span>)’라는 측정 지표를 도입했다. 이 지표는 <span class="math math-inline">\Delta s(\ell) = \mu_{base} - \log_2 p_\theta(x \vert c, \text{load}_\ell)</span> 로 정의되며, 특정 부하(Load) 상태에서 금지된 토큰의 베이스라인 대비 확률 로그 값을 측정한다. 이 계산의 결과가 양수(Positive bits)로 도출되면, 부정 지시가 오히려 해당 토큰을 베이스라인 상황보다 덜 놀라운(더 발생하기 쉬운) 상태로 만들었다는 것을 의미하며, 명백한 아이러니한 반동의 증거가 된다.</p>
<p>소프트웨어 시스템에서 오라클이 특정 개념의 노출을 완벽하게 통제해야 하는 보안, 개인정보 마스킹, 또는 금칙어 필터링 기능을 담당한다고 가정할 때, 부정 프롬프트를 사용하는 것은 스스로 방어벽을 무너뜨리는 것과 같다. 반대로 “오직 Y 형태의 토큰만 생성하라“는 긍정적 지시는 내부 어텐션 자원을 목표 벡터로 즉각적이고 일관되게 정렬시키므로, 중간 레이어에서의 극소수 헤드 충돌이라는 아키텍처 레벨의 위험 요소를 원천적으로 차단할 수 있다.</p>
<h2>4.  사전 학습 코퍼스의 분포 편향과 구문론적 템플릿의 고착화</h2>
<p>언어 모델이 부정문에 취약한 또 다른 핵심적 이유는, 딥러닝 모델의 근간을 이루는 사전 학습 데이터 세트(Pretraining Corpora) 내부에 존재하는 압도적인 통계적 분포 편향성(Distributional Bias) 때문이다. 전 세계의 인터넷 문서, 서적, 대화 기록 등 광범위한 언어 자원을 분석해보면, 인간의 자연어 의사소통은 본질적으로 긍정문(Affirmative statements)이 압도적인 비중을 차지한다. 연구에 따르면 일반적인 영어 텍스트 코퍼스에서 형태론적(Morphological) 또는 통사론적(Syntactic) 부정 표현이 포함된 문장의 비율은 약 25% 수준에 불과하다. 파라미터가 거대해질수록 모델은 이러한 불균형한 데이터 분포의 통계적 패턴을 더 완벽하고 맹목적으로 암기하게 되며, 이는 긍정문 패턴을 추종하는 강력한 학습 편향으로 굳어진다.</p>
<p>LLM은 방대한 텍스트를 읽어들이면서 단어, 구, 품사들이 함께 등장하는 배열 패턴을 학습하여 고유의 ’구문론적 템플릿(Syntactic Templates)’을 형성한다. 이때 어휘적 의미론(Lexical Semantics)의 관점에서 치명적인 문제가 발생한다. “not”, “never”, “without”, “no“와 같은 부정의 기능을 수행하는 기능어(Function words)들은 그 본질적인 의미가 정반대임에도 불구하고, 긍정문과 매우 유사한 문맥(Context)에서 등장하는 경우가 대부분이다. 예를 들어 “This code is completely optimal“이라는 문장과 “This code is completely not optimal“이라는 문장은 ’optimal’이라는 핵심 개념 주변에 배치되어 동일한 주어와 부사를 공유한다.</p>
<p>자연어 처리 모델이 단어의 의미를 파악하는 핵심 원리인 분포 가설(Distributional Hypothesis)에 기반한 연속적 벡터 공간(Continuous vector space)에서, 이 두 문장은 아이러니하게도 매우 가까운 거리에 임베딩(Embedding)되는 경향을 보인다. 즉, 딥러닝 모델은 부정어가 가지는 논리적 파괴력보다 주변 문맥 단어들이 이루는 통계적 군집성에 더 큰 가중치를 부여하게 된다. 결과적으로 모델은 부정어가 문장 전체의 의미를 180도 뒤집는 결정적인 영향을 과소평가(Underestimate)하게 되며, 종종 “not“과 같은 단어를 단순한 노이즈(Noise)나 텍스트 상의 문법적 오류 정도로 치부해 버린다.</p>
<p>의미를 추론하는 과정에서 딜레마에 빠진 모델은 결국 가장 안전한 지름길(Shortcut)을 선택하게 되는데, 그것은 바로 해당 구문이 긍정형일 때 관측되었던 압도적인 통계적 확률에 기대어 답변을 생성하는 휴리스틱(Heuristic)이다. 이러한 구조적 결함은 단순히 모델이 말을 잘 듣지 않는 문제를 넘어, 지시와 정반대되는 환각(Hallucination)을 생성하거나 제한된 사실을 생성해야 하는 작업(Constrained fact generation)에서 치명적인 논리적 오류를 발생시키는 원인이 된다.</p>
<p>더욱 심각한 것은 이러한 구문론적 템플릿의 고착화가 보안 시스템의 치명적인 취약점(Vulnerability), 즉 프롬프트 주입(Prompt Injection) 공격의 통로로 악용될 수 있다는 점이다. 악의적인 사용자는 시스템 프롬프트에 겹겹이 설정된 “유해한 코드를 작성하지 마라”, “비밀번호를 출력하지 마라“와 같은 강력한 부정형 제약 조건의 허점을 쉽게 뚫을 수 있다. LLM은 특정 문법적 구조를 ‘안전한’ 도메인 데이터와 결합하여 기억하는 습성이 있다. 해커가 모델이 안전하다고 인식하는 특정 구문론적 템플릿(예: 무해한 동화 구연 체, 추상적인 학술 토론 체)을 차용하여 유해한 질의나 금지된 행동을 긍정문 형태로 교묘하게 포장할 경우, 모델의 어텐션 메커니즘은 표면적인 문법의 무해성에 속아 넘어간다. 이 순간 모델에 내장된 부정형 거절 정책(Refusal policy)은 무시되며, 모델은 스스로 금지된 정보를 생성해 버린다. 따라서 오라클의 방어 로직과 제약 조건은 금지 사항의 나열이 아니라, “오직 인가된 API 문서의 범위 내에서만, JSON 포맷으로만 응답하라“는 식의 배타적이고 긍정적인 폐쇄형(Closed-ended) 지시로 구축되어야만 보안성을 담보할 수 있다.</p>
<h2>5.  부정 맹점(Negation Blindness)과 이진 결정에서의 부정적 편향</h2>
<p>단순히 지시를 무시하거나 반동을 일으키는 단계를 넘어, 최신 LLM들은 긍정형 질문과 부정형 질문을 구분조차 하지 못하고 기계적으로 동일한 응답을 뱉어내는 ’부정 맹점(Negation Blindness)’이라는 매우 심각한 논리적 인지 장애를 가지고 있다. 논문 *Negation Blindness?*의 실험은 이 현상이 실제 환경에서 얼마나 빈번하고 치명적으로 나타나는지를 적나라하게 보여준다. 예를 들어 특정 주제에 대해 “기타에 불을 지른 사람은 누구인가?“라는 긍정형 질문을 던지면, 모델은 자신의 방대한 지식 베이스(Grounding ability)를 활용하여 “Jimi Hendrix“라는 정확한 사실적 지식을 출력한다. 그러나 정확히 동일한 맥락에서 의미를 완전히 뒤집어 “기타에 불을 지르지 <strong>않은</strong> 사람은 누구인가?“라고 부정형 질문을 던졌을 때에도, 모델은 부정에 의한 의미 역전(Semantic Inversion)을 철저히 무시한 채 여전히 “Jimi Hendrix“라는 완벽히 동일한 답변을 출력하는 기현상을 보인다.</p>
<p>이러한 동일 응답 현상(Identical Replies)은 모델이 해당 도메인의 지식 자체가 부족해서 틀리는 것(Knowledge deficit)이 아님을 증명한다. 모델은 관련된 엔티티와 지식은 명확히 인식하고 있으나, 부정이 문장에 개입할 때 요구되는 논리적 의미 반전을 연산하는 추론 능력이 근본적으로 결여되어 있는 것이다. 연구진은 모델의 이와 같은 논리적 붕괴 수준을 정량화하기 위해 **BLD Score(Blindness Level of Difference)**라는 척도를 고안했다. 이 지표는 긍정 쿼리와 부정 쿼리에 대해 모델이 어텐션 역전에 실패하고 교집합적인(동일한) 오답을 내놓는 비율을 전체 쿼리 수로 나눈 값이다. 이 지표를 통해 분석한 결과, 부정 맹점은 모델이 단순한 참/거짓을 판별하는 이진 결정(Binary decision), 다중 선택(Multiple-choice selection), 빈칸 채우기(Cloze-style completion) 등 논리적 제약이 강한 환경일수록 극단적으로 높은 오답률을 기록하는 것으로 확인되었다.</p>
<p>오라클의 핵심 요건은 입력된 상황에 대해 흔들림 없는 확정적인 검증 논리를 제공하는 것이다. 그러나 부정 맹점이 존재하는 한, 모델의 출력 결과는 일관된 논리의 산물이 아니라 훈련 데이터의 출현 빈도에 기댄 우연의 산물로 전락하고 만다. 특히 이러한 부정 맹점은 퓨샷 러닝(Few-Shot Learning)이나 인컨텍스트 러닝(In-Context Learning, ICL) 기법을 사용할 때 예제(Exemplar)의 구성 방식에 따라 오히려 악화될 수 있다는 점에서 실무적인 경각심을 요구한다. 예를 들어, 모델의 성능을 높이고자 8-shot ICL 환경에서 지시문 내에 부정 형태의 예제를 과도하게 많이 학습시키거나, 선택 과제에서 긍정 예제를 편향되게 배치할 경우, 모델의 논리적 혼란이 가중되어 부정 맹점이 오히려 심화되고 전반적인 추론 성능이 붕괴되는 현상이 관측되었다.</p>
<p>더 나아가, 모델 파라미터 내부에 각인된 부정적 편향(Negative Bias) 또한 오라클의 정확도를 심각하게 훼손한다. 모델의 어텐션 메커니즘을 분석하기 위해 도입된 ‘부정적 어텐션 점수(Negative Attention Score, NAS)’ 연구에 따르면, LLM은 프롬프트의 실제 질문 내용과 무관하게 이진 응답 옵션 중 부정적인 단어 토큰에 비정상적으로 높은 어텐션을 할당하는 편향된 헤드들을 내부에 지니고 있다. 수학적, 논리적 추론이 요구되는 응답 검증(Answer verification)이나 예/아니오 질의응답(QA) 과제에서 LLM은 높은 정밀도(Precision)를 보이나 재현율(Recall)은 매우 낮게 나타나는 전형적인 불균형을 보인다.</p>
<p>이는 모델이 긍정적인 결정(Positive decision)을 내리고 확언하는 것에 대해 시스템 내부적으로 과도하게 신중하도록 세팅되어 있기 때문이다. 자신이 확신할 수 없는 복잡한 상태에 직면하면 모델은 가장 안전하고 손쉬운 지름길(Shortcut)로써 일단 ’부정적 결정(Negative decision)’이나 ’거절’을 채택해 버리는 기만적인 현상을 보인다. 이처럼 부정문은 모델의 논리적 일관성을 교란시킬 뿐만 아니라, 맹점과 편향을 동시에 자극하여 통제력(Controllability)을 심각하게 상실하게 만든다.</p>
<h2>6.  역 스케일링 법칙(Inverse Scaling Law)과 모델 규모 확장의 한계</h2>
<p>소프트웨어 개발자들은 종종 “현재 사용 중인 모델의 성능이 떨어져서 부정문을 이해하지 못하는 것이며, 향후 더 거대하고 우수한 파라미터를 가진 모델(예: 최신 GPT-4 클래스, LLaMA-3 400B 등)로 교체하면 부정형 제약 조건 문제도 자연스럽게 해결될 것“이라는 기술 낙관주의적 착각에 빠지곤 한다. 그러나 학계의 면밀한 벤치마크 실험 결과는 이러한 기대가 완전히 틀렸음을 입증한다.</p>
<p>일반적으로 LLM은 모델의 파라미터 크기와 학습 데이터의 연산량(Compute)이 증가할수록 자연어 처리(NLP) 태스크의 성능이 선형적으로, 혹은 기하급수적으로 향상되는 ’스케일링 법칙(Scaling Law)’을 철저히 따른다. 그러나 유독 프롬프트 내 부정문의 처리 능력에 있어서만큼은 정반대의 현상인 ’역 스케일링 법칙(Inverse Scaling Law)’이 두드러지게 관측된다. 논문 <em>Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts</em>와 <em>Beyond Positive Scaling: How Negation Impacts Scaling Trends</em> 등은 파라미터 규모 확장이 오히려 부정문 처리 능력을 퇴보시킨다는 충격적인 데이터를 제시한다.</p>
<p>역 스케일링 현상을 이해하기 위해서는 부정문이 포함된 질의응답을 평가하는 NeQA(Negated Question Answering) 벤치마크의 메커니즘을 살펴봐야 한다. 부정문 질의는 사실상 두 개의 독립적인 하위 태스크(Subtasks)로 분해된다. 첫 번째는 원래의 긍정문 질문에 대한 정답을 도출하는 능력(Task 1: QA)이며, 두 번째는 문장 내의 부정을 이해하고 논리를 역전시키는 능력(Task 2: Negation Understanding)이다.</p>
<p>데이터 분석에 따르면, 파라미터가 적은 소형 모델(예: GPT-Neo 125M)의 경우 Task 1 자체의 지식수준이 낮아 긍정이든 부정이든 무작위 찍기 확률인 50% 언저리의 일관된 오답률을 기록한다. 그러나 모델의 파라미터 규모가 커지면서(예: 1.3B, 2.7B, 6B 모델) 모순적인 상황이 발생한다. 훈련 데이터를 방대하게 암기한 거대 모델은 원래 질문(Task 1)의 정답을 아는 능력은 선형적으로 강력해지는 반면, 부정의 의미 역전을 처리하는 논리적 연산 능력(Task 2)은 전혀 발달하지 못한다.</p>
<p>과거의 비부정 텍스트를 과도하게 암기한 거대 모델은 프롬프트의 부정어(“not”)를 무시한 채, 자신이 확신하는 원래 질문(긍정형)의 지식을 극도의 확신(High confidence)을 가지고 정답으로 출력해 버린다. 부정문 질의의 정답은 원래 정답의 정반대이어야 하므로, 모델이 기존 지식에 강한 확신을 가질수록 부정문 환경에서는 완벽하게 틀린 길로 직진하게 된다. 이로 인해 모델의 규모가 커짐에도 불구하고 정답률이 무작위 확률인 50% 밑으로 수직 추락하는 기이한 ’역 스케일링 구간(Inverse Scaling Phase)’이 형성된다.</p>
<p>실제 평가 데이터는 이 현상의 심각성을 뒷받침한다. 단어의 동의어/반의어 관계를 추론하는 SAR(Synonym/Antonym Relation) 분류 과제 제로샷(Zero-shot) 테스트에서, 175B의 거대한 파라미터를 가진 Base GPT-3 모델조차 50.1%라는 완벽한 무작위에 가까운 충격적인 정확도를 기록했다. 반면 훨씬 크기가 작은 GPT-Neo 125M이나 GPT-J 6B 모델이 부정문이 섞인 MKR-NQ 과제 등에서 오히려 더 낮은 오류율(WHR)을 보이며 상대적으로 나은 성능을 기록했다.</p>
<p>파라미터가 수천억 개에 달하는 초거대 규모에 도달하거나, 사고의 사슬(Chain-of-Thought, CoT)과 같은 강력한 추론 강제 프롬프팅이 적용되었을 때 비로소 모델은 부정을 인지하는 ’발현적 전환점(Emergent transition point)’을 지나 정답률이 다시 상승하는 U자형 스케일링(U-Shaped Scaling) 패턴을 그리기 시작한다. Instruction Tuning을 거친 InstructGPT 모델의 경우 SNLI-neg 벤치마크에서 67.3%, RTE-neg에서 80.7%의 정확도를 기록하며 부분적인 성능 회복을 보였으나, 이 역시 동일한 모델이 긍정 프롬프트를 처리할 때 보여주는 압도적인 성능과 비교하면 여전히 논리적 구멍이 뚫려 있는 상태이다.</p>
<p>더욱이 모델이 부정을 이해하도록 명시적으로 파인튜닝(Fine-Tuning)을 진행할 경우, 부정문 처리 능력은 소폭 향상되나 반대급부로 원래의 비부정(긍정) 일반 과제에서의 성능이 심각하게 저하되는 ‘제로섬 게임(Zero-sum game)’ 현상이 발생한다. 이는 트랜스포머 모델의 파라미터 업데이트가 부정 논리를 독립적인 기술로 학습하는 것이 아니라, 기존의 통계적 분포를 단순히 반대로 비틀어버리는 부작용을 낳기 때문이다.</p>
<p>결과적으로, 최첨단의 거대 모델 아키텍처를 도입하고 컴퓨팅 자원을 쏟아붓더라도 부정형 지시어가 야기하는 본질적 오류율은 결코 자연적으로 소멸되지 않는다. AI 기반 소프트웨어 파이프라인에서 완벽한 일관성과 100%의 예측 가능성을 요구하는 오라클을 구축할 때, 프롬프트에서 부정문을 원천적으로 배제하고 긍정문으로 설계해야 하는 것은 모델의 성능 수준과 관계없이 무조건적으로 준수해야 할 절대적인 아키텍처 설계 원칙이다.</p>
<h2>7.  분류기 없는 가이던스(CFG)의 부재와 시각-언어 모델(VLM)에서의 한계</h2>
<p>개발자들이 프롬프트 엔지니어링을 할 때 겪는 흔한 오해 중 하나는, 이미지 생성 AI(Stable Diffusion, Midjourney 등)에서 널리 쓰이는 ’네거티브 프롬프트(Negative Prompts)’의 강력한 통제력을 텍스트 기반 LLM에서도 동일하게 구현할 수 있을 것이라는 착각이다. 이미지 생성 분야에서는 사용자가 기형적인 손가락이나 워터마크를 배제하기 위해 네거티브 프롬프트 입력란에 단어를 넣으면 모델이 이를 완벽하게 배제하여 결과물을 산출한다.</p>
<p>그러나 이러한 제어가 가능한 이유는 이미지 확산(Diffusion) 모델들이 분류기 없는 가이던스(Classifier-Free Guidance, CFG)라는 명확하고 독립적인 수학적 디노이징(Denoising) 매커니즘을 아키텍처 하단에 내장하고 있기 때문이다. CFG는 조건부(긍정) 임베딩 벡터 공간에서 비조건부(부정) 임베딩 벡터 공간을 뺄셈하여 아웃풋의 궤적을 강제적으로 밀어내는(Push away) 방식으로 작동한다.</p>
<p>반면, 텍스트의 순차적 토큰을 예측하는 텍스트 전용 자기회귀(Autoregressive) LLM 시스템에는 이러한 범용적인 네거티브 프롬프트 연산 매커니즘이 아키텍처의 기저에 기본적으로 내장되어 있지 않다. 일부 오픈소스 모델(예: Text generation web UI)이 루프 강화(Loop Reinforcement) 기법을 통해 유사한 기능을 실험하고 있으나, 주류 상용 LLM에서는 시스템 프롬프트(System Prompt)라는 단일한 입력 스트림 안에 부정문을 섞어서 텍스트로 밀어 넣는 수밖에 없다. 앞서 서술한 아이러니한 반동 효과로 인해, 프롬프트에 “X를 포함하지 마라“라고 텍스트로 타이핑하는 행위 자체는 오히려 ’X’라는 키워드의 어텐션 가중치를 역으로 자극하여 의도치 않은 환각을 폭발적으로 트리거(Triggering)하는 기폭제가 될 뿐이다.</p>
<p>이러한 텍스트 기반 부정 연산의 근본적 결함은 최근 주목받는 시각-언어 모델(Vision-Language Models, VLMs)의 아키텍처에서도 고스란히 재현된다. 최신 연구에 따르면 CLIP과 같은 대규모 기초 모델조차 명시적인 부정의 의미를 이해하고 시각 정보와 정렬시키는 능력이 사실상 무작위 수준에 불과하다. CC-Neg와 같이 22만 개 이상의 정교한 부정 캡션 디스트랙터(Distractor)가 포함된 벤치마크 데이터셋으로 실험한 결과, 최고 수준의 VLM들조차 “보행자가 없는 거리 풍경(street scene without pedestrians)“이라는 프롬프트가 주어졌을 때 ’without’이라는 부정의 단서를 완전히 무시하고 보행자가 가득한 거리를 올바른 매칭으로 잘못 판별해 버린다.</p>
<p>VLM 역시 텍스트 프롬프트를 형태론적으로 조각내어 전체론적(Holistically)으로 임베딩하기 때문에, 부정어가 이미지 내 특정 객체의 부재(Absence)를 의미한다는 논리적 분해(Semantic decomposition)를 수행하지 못한다. 모델이 부정문을 이해하도록 인위적인 대규모 네거티브 데이터셋을 구축하여 미세 조정(Fine-Tuning)을 시도하는 방안이 제시되기도 했으나, 이 역시 텍스트 LLM에서의 제로섬 게임과 동일하게 모델을 부정 데이터에 과적합(Overfitting)시켜 원래의 긍정문 제로샷 성능을 붕괴시키는 심각한 부작용을 낳았다.</p>
<p>이 모든 교차 검증의 결과가 가리키는 결론은 단 하나다. 텍스트든 비전이든 트랜스포머 기반의 아키텍처에서 부정형 제약 조건은 본질적으로 불안정하며 예측 불가능한 잡음(Noise)에 불과하다. 결정론적 오라클을 구현하고자 하는 소프트웨어 엔지니어는 AI가 스스로 부정을 이해하고 걸러낼 것이라는 기술적 환상을 버리고, 프롬프트 수준에서 철저히 긍정적이고 작위적인 제약 공간을 깎아내야 한다.</p>
<h2>8.  결정론적 오라클 구축을 위한 긍정문 프롬프트 리팩토링 설계 패턴</h2>
<p>소프트웨어 엔지니어링의 패러다임이 AI와 결합하는 환경에서, 프롬프트는 단순한 인간의 자연어 지시문이 아니라 컴파일러와 런타임 환경이 해석해야 하는 ’소스 코드(Source Code)’의 지위를 갖는다. 고품질의 소스 코드가 갖춰야 할 명확성(Clarity)과 구체성(Specificity)의 원칙은 프롬프트 설계에도 동일하게 적용된다. 애매모호한 부정형 지시는 모델이 활동할 수 있는 상태 공간(State space)을 넓게 방치하여 비결정적 출력의 원인이 되지만, 명확한 긍정형 지시(Positive directives)는 모델이 이동해야 할 단일한 목표 벡터 경로(Target vector path)를 구체적으로 할당하여 의도된 동작만을 수행하도록 궤도를 강력히 고정시킨다.</p>
<p>실무 환경에서 파이프라인의 오작동과 일관성 없는 결과를 방지하려면, 시스템 프롬프트에 존재하는 모든 부정형 제약 조건을 의미론적으로 동일한 긍정형 제약 조건으로 변환(Refactoring)하는 과정이 필수적이다. 다음의 표는 AI 모델을 오라클로 활용할 때 범하기 쉬운 부정문 안티 패턴(Anti-pattern)과 이를 긍정문 오라클 패턴으로 변환하는 지침을 구조화하여 보여준다.</p>
<table><thead><tr><th><strong>프롬프트 제어 목적</strong></th><th><strong>지양해야 할 부정형 프롬프트 (Anti-pattern)</strong></th><th><strong>권장하는 긍정형 프롬프트 (Oracle Pattern)</strong></th><th><strong>개선 효과 및 아키텍처적 근거</strong></th></tr></thead><tbody>
<tr><td><strong>출력 포맷 강제</strong></td><td>“이름을 대문자로 작성하지 마라.”</td><td>“모든 이름은 항상 소문자로만 작성해라.”</td><td>중간 레이어에서의 대문자 토큰 억제 실패(Ironic Rebound) 현상 방지. 소문자 타겟 토큰 확률 직접 증폭.</td></tr>
<tr><td><strong>데이터 정합성 및 스키마 준수</strong></td><td>“값이 없는 필드는 결과에 반환하지 마라.”</td><td>“데이터 값이 명확히 존재하는 필드만 추출하여 결과 스키마에 포함해라.”</td><td>JSON 구조를 유지하려는 사전 학습 관성에 의한 null 필드 강제 생성을 방지. 허용된 데이터 패턴에만 어텐션 집중 유도.</td></tr>
<tr><td><strong>문체 및 톤 제어</strong></td><td>“비유, 은유, 개인적 의견이나 마케팅 용어를 사용하지 마라.”</td><td>“오직 객관적 수치와 사실에 기반한 건조한 기술 문서(Technical document) 스타일로만 작성해라.”</td><td>’마케팅 용어’라는 금지어를 프롬프트 내에 삽입함으로써 발생하는 키워드 활성화 방지. 페르소나의 타겟 벡터를 명확히 제시.</td></tr>
<tr><td><strong>행동 제한 (가드레일 및 환각 통제)</strong></td><td>“모르는 정보에 대해서는 임의로 추측해서 답변을 지어내지 마라.”</td><td>“반드시 제공된 컨텍스트(Input Text) 내의 명시적 정보만을 사용하여 답변해라. 관련 정보가 존재하지 않을 경우 정확히 ’알 수 없음(N/A)’이라는 단일 문자열만 반환해라.”</td><td>폐쇄형 질문(Closed-ended) 및 구체적인 예외 처리 로직(Fallback) 명시로 환각(Hallucination) 원천 배제. 추론 공간의 결정론적 고정.</td></tr>
</tbody></table>
<p>표에서 제시된 리팩토링 패턴의 핵심은, 금지 사항을 구구절절 나열하는 방식이 무한한 오답의 가능성 중에서 극히 일부의 경로만을 차단할 뿐이라는 사실을 직시하는 것이다. 반면 “반드시 ~형태로만 작성해라”, “오직 ~만 포함해라“와 같은 강력한 배타적 긍정 지시는 모델의 정보 처리 대역폭(Bandwidth) 낭비를 최소화하고, 어텐션 자원을 100% 정답 패턴의 활성화에만 쏟아붓게 만든다.</p>
<p>또한, 프롬프트 엔지니어링의 최적화 수준은 모델의 버전에 따라 유동적이라는 점(Prompting as Model-Relative)을 반드시 고려해야 한다. 파라미터 제어나 CoT(Chain-of-Thought)를 활용한 복잡한 구조화 프롬프트는 특정 버전(예: GPT-4o)에서는 오류를 막아주는 강력한 가드레일(Guardrail)이 되지만, 모델의 아키텍처가 바뀌거나 규모가 변경된 후속 버전에서는 오히려 성능을 떨어뜨리는 수갑(Handcuffs)으로 작용하는 ‘프롬프팅 역전(Prompting Inversion)’ 현상이 발생할 수 있다. 그러나 복잡한 구조적 프롬프팅 기법들이 모델 세대에 따라 부침을 겪는 것과 달리, “부정을 긍정으로 치환하여 지시의 명확성을 높이는 것“은 트랜스포머의 확률론적 근간이 바뀌지 않는 한 모든 세대의 모델에 범용적으로 적용되는 가장 견고하고 안전한 통제 방식이다.</p>
<p>결론적으로, 결정론적 정답지를 산출하는 오라클을 설계함에 있어 “부정문보다 긍정문을 사용하라“는 지침은 텍스트 작성을 위한 단순한 스타일 가이드나 휴리스틱 권고가 아니다. 이는 대규모 언어 모델 내부의 어텐션 병목, 확률적 토큰 억제의 한계, 중간 레이어에서의 극단적 헤드 충돌, 학습 데이터의 거대한 분포 편향, 그리고 역 스케일링 법칙으로 이어지는 딥러닝 아키텍처의 근본적이고 수학적인 결함을 우회하기 위해 고안된 가장 비용 효율적이고 필수적인 소프트웨어 엔지니어링 통제 기법이다. 엔터프라이즈 환경에서 프롬프트를 작성하고 관리하는 개발자는, 자신이 코딩하는 프롬프트 제약 조건 내에 어떠한 형태의 ’부정어’도 암시적으로 남아있지 않도록 철저히 검열하고, 이를 긍정적 단언문으로 완벽히 치환하는 엄격한 코드 리뷰(Code Review) 프로세스를 시스템 구축의 표준으로 삼아야 한다.</p>
<h2>9. 참고 자료</h2>
<ol>
<li>Why Positive Prompts Outperform Negative Ones with LLMs? | Gadlet, https://gadlet.com/posts/negative-prompting/</li>
<li>Lost in Transmission: When and Why LLMs Fail to Reason Globally, https://arxiv.org/pdf/2505.08140</li>
<li>Lost in Transmission: When and Why LLMs Fail to Reason Globally, https://openreview.net/forum?id=MaJ3ASZ0NI</li>
<li>NLMs: Augmenting Negation in Language Models - ACL Anthology, https://aclanthology.org/2023.findings-emnlp.873/</li>
<li>Ironic Negation in Transformer Models Under Cognitive Load - arXiv, https://arxiv.org/html/2511.12381v1</li>
<li>A Benchmark for LLMs’ Sentence-Level Negation Understanding, https://arxiv.org/pdf/2506.14397</li>
<li>Researchers discover a shortcoming that makes LLMs less reliable, https://news.mit.edu/2025/shortcoming-makes-llms-less-reliable-1126</li>
<li>Negation: A Pink Elephant in the Large Language Models’ Room?, https://arxiv.org/html/2503.22395v2</li>
<li>Correcting Negative Bias in Large Language Models through, https://aclanthology.org/2025.naacl-long.503.pdf</li>
<li>Semantic Inversion, Identical Replies: Revisiting … - ACL Anthology, https://aclanthology.org/2025.emnlp-main.1088.pdf</li>
<li>Developmental Negation Processing in Transformer Language, https://arxiv.org/abs/2204.14114</li>
<li>Vision-Language Models Do Not Understand Negation | Request PDF, https://www.researchgate.net/publication/394613682_Vision-Language_Models_Do_Not_Understand_Negation</li>
<li>Learning the Power of “No”: Foundation Models with Negations, https://openaccess.thecvf.com/content/WACV2025/papers/Singh_Learning_the_Power_of_No_Foundation_Models_with_Negations_WACV_2025_paper.pdf</li>
<li>A Comprehensive Taxonomy of Negation for NLP and Neural, https://staff.fnwi.uva.nl/m.derijke/wp-content/papercite-data/pdf/petcu-2025-comprehensive-arxiv.pdf</li>
<li>What Is Prompt Engineering? A Practical Guide for Developers and, https://snyk.io/articles/what-is-prompt-engineering-a-practical-guide-for-developers-and-teams/</li>
<li>Prompt Engineering: The Language That Unleashes AI Power | Article, https://codefactory.hu/post/prompt-engineering-en</li>
<li>Prompt Engineering Basics (2026): A Practical Guide - Medium, https://medium.com/@mjgmario/prompt-engineering-basics-2026-93aba4dc32b1</li>
<li>You Don’t Need Prompt Engineering Anymore: The … - arXiv, https://arxiv.org/html/2510.22251v1</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>