<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:4.3 재현성(Reproducibility) 보장을 위한 Seed 파라미터 활용</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>4.3 재현성(Reproducibility) 보장을 위한 Seed 파라미터 활용</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 4. AI 모델 응답의 일관성 확보를 위한 프롬프트 엔지니어링 및 파라미터 제어</a> / <a href="index.html">4.3 재현성(Reproducibility) 보장을 위한 Seed 파라미터 활용</a> / <span>4.3 재현성(Reproducibility) 보장을 위한 Seed 파라미터 활용</span></nav>
                </div>
            </header>
            <article>
                <h1>4.3 재현성(Reproducibility) 보장을 위한 Seed 파라미터 활용</h1>
<p>소프트웨어 엔지니어링의 근간은 결정론(Determinism)에 기초한다. 동일한 입력 값, 동일한 환경 설정, 그리고 동일한 실행 경로가 주어졌을 때 소프트웨어는 언제나 한 치의 오차도 없이 동일한 출력을 반환해야 한다. 이러한 결정론적 속성은 소프트웨어의 신뢰성을 담보하는 핵심 기둥이며, 단위 테스트(Unit Test), 통합 테스트, 그리고 지속적 통합 및 배포(CI/CD) 파이프라인이 정상적으로 기능할 수 있게 하는 필수 전제 조건이다. 개발자는 이러한 결정론적 기반 위에서 예상되는 정확한 결괏값, 즉 ’오라클(Oracle)’을 정의하고 시스템의 회귀(Regression) 여부를 검증한다.</p>
<p>그러나 대규모 언어 모델(Large Language Model, LLM)을 소프트웨어 아키텍처의 핵심 컴포넌트로 통합하는 순간, 이 견고했던 결정론적 기반은 확률론적 불확실성(Stochastic Uncertainty)에 의해 크게 흔들리게 된다. LLM은 본질적으로 방대한 텍스트 코퍼스에서 학습된 확률 분포를 기반으로 다음 토큰을 예측하는 통계적 모델이다. 따라서 동일한 프롬프트를 입력하더라도 모델은 내부의 샘플링 무작위성에 의해 매번 미세하게, 혹은 완전히 다른 텍스트를 생성할 수 있다. 결정론적 정답지인 오라클을 구축하여 AI의 응답을 검증하고 비즈니스 로직의 정합성을 보장해야 하는 소프트웨어 개발자에게, 이러한 비결정성은 테스트의 신뢰도를 떨어뜨리는 ’플래키 테스트(Flaky Test)’를 유발하는 치명적인 장애물이다.</p>
<p>이러한 문제를 해결하고 확률적 텍스트 생성 과정에 소프트웨어 공학적 통제력을 부여하기 위해 고안된 가장 직접적인 도구가 바로 <code>seed</code> 파라미터다. 이 절에서는 LLM의 토큰 생성 및 샘플링 메커니즘을 수학적으로 심층 분석하고, <code>seed</code> 파라미터가 의사 난수 생성(Pseudorandom Number Generation) 과정에 개입하여 어떻게 일관된 출력을 유도하는지 살펴본다. 나아가 시드의 한계점인 하드웨어 수준의 부동소수점 연산 비결정성 및 시스템 아키텍처 요인을 해부하며, 최신 학술 연구 결과를 바탕으로 실전 AI 소프트웨어 개발에서 견고한 검증 오라클을 구축하는 구체적인 방법론과 아키텍처를 제시한다.</p>
<h2>1.  언어 모델의 확률적 생성 메커니즘과 통계적 디코딩</h2>
<p>언어 모델이 텍스트를 생성하는 과정은 본질적으로 조건부 확률(Conditional Probability)의 연속적인 연산 사슬이다. 자기회귀(Autoregressive) 특성을 가진 모델은 프롬프트를 포함하여 이전까지 생성된 모든 토큰의 시퀀스 <span class="math math-inline">x_{&lt;t}</span> 가 주어졌을 때, 어휘 사전(Vocabulary) <span class="math math-inline">V</span> 내에 존재하는 모든 가능한 다음 토큰 <span class="math math-inline">x_t</span> 에 대한 확률 분포를 계산한다. 이 전체 시퀀스의 결합 확률은 다음과 같이 개별 조건부 확률의 곱으로 분해된다.<br />
<span class="math math-display">
p(x_{1:T}) = \prod_{t=1}^{T} p(x_t \vert x_{&lt;t})
</span><br />
추론(Inference) 단계에서 모델은 신경망의 최종 레이어를 통과한 결괏값으로 각 토큰 후보에 대해 정규화되지 않은 실수 형태의 점수인 로짓(Logit) 벡터 <span class="math math-inline">z = (z_1, \dots, z_n)</span> 를 출력한다. 이 로짓은 모델이 현재 문맥에서 해당 토큰이 등장할 합리성에 대해 부여하는 ’내적 확신도’를 의미한다. 하지만 로짓 그 자체로는 확률로 사용할 수 없으므로, 이를 총합이 1이 되는 유효한 확률 분포 <span class="math math-inline">q = (q_1, \dots, q_n)</span> 로 변환하기 위해 소프트맥스(Softmax) 함수가 적용된다.</p>
<p>이 변환 과정에서 생성의 무작위성을 제어하는 핵심 하이퍼파라미터인 온도(Temperature, <span class="math math-inline">T</span>)가 로짓에 대한 스케일링 요소로 작용하게 된다. 온도를 반영한 소프트맥스 함수의 수학적 정의는 다음과 같다.<br />
<span class="math math-display">
p(x_t = i \vert x_{&lt;t}) = \frac{\exp(z_i / T)}{\sum_{j=1}^{n} \exp(z_j / T)}
</span><br />
이 수식에서 볼 수 있듯, 온도 <span class="math math-inline">T</span>의 값은 확률 분포의 형태를 극적으로 변화시킨다. <span class="math math-inline">T = 1</span>일 때는 모델이 학습한 원본 확률 분포가 그대로 유지된다. <span class="math math-inline">T &gt; 1</span>로 설정되면 지수 함수의 특성상 로짓 간의 차이가 축소되어 확률 분포가 평탄해지며, 결과적으로 확률이 낮았던 희귀한 토큰들이 선택될 가능성이 높아져 창의적이고 다양한 텍스트가 생성된다. 반대로 <span class="math math-inline">T</span>가 0에 한없이 가까워질수록(<span class="math math-inline">T \to 0^+</span>), 확률 질량은 가장 로짓 값이 높은 단일 토큰에 거의 100% 집중되며, 사실상 소프트맥스 함수는 가장 높은 확률의 토큰만을 선택하는 아그맥스(Argmax) 함수처럼 작동하게 된다.</p>
<p>확률 분포가 계산된 후, 모델은 이 분포를 바탕으로 다음 토큰을 최종적으로 ’샘플링(Sampling)’한다. 그리디 디코딩(Greedy Decoding) 방식은 단순히 매 단계마다 가장 확률이 높은 토큰만을 선택하지만, 이 방식은 종종 국소 최적해(Local Optima)에 빠져 반복적이고 단조로우며 부자연스러운 텍스트를 생성하는 한계가 있다. 따라서 실제 애플리케이션 및 API 제공 환경에서는 확률 분포에 기반하여 무작위로 토큰을 추출하되, 품질 저하를 막기 위해 후보군을 통제하는 Top-K 및 Top-P(Nucleus Sampling) 기법이 결합되어 사용된다.</p>
<p>Top-K 샘플링은 확률이 가장 높은 <span class="math math-inline">K</span>개의 토큰만을 후보로 남기고 나머지 토큰의 확률을 0으로 잘라낸(Truncate) 뒤, 남은 확률 질량을 재정규화(Renormalization)하여 샘플링한다. Top-P 샘플링은 누적 확률이 임계값 <span class="math math-inline">P</span>에 도달할 때까지의 토큰 집합만을 후보로 선정하여 샘플링을 수행한다. 이는 확률 분포의 형태에 따라 동적으로 후보군의 크기를 조절하므로 문맥에 더욱 유연하게 적응하는 장점이 있다.</p>
<p>바로 이 최종 샘플링 단계, 즉 ’확률 분포 내에서 어떤 토큰을 뽑을 것인가’를 결정하는 주사위 던지기 과정에서 LLM의 비결정성이 발생한다. 그리고 <code>seed</code> 파라미터가 소프트웨어 엔지니어의 통제 수단으로써 개입하는 지점이 바로 이곳이다.</p>
<hr />
<h2>2.  Seed 파라미터를 통한 의사 난수 통제와 시뮬레이션</h2>
<p>디지털 컴퓨터 시스템에서 생성되는 난수(Random Number)는 진정한 의미의 무작위가 아니라, 복잡한 수학적 알고리즘에 의해 계산된 의사 난수(Pseudorandom Number)다. 의사 난수 생성기(PRNG)는 초기 시작점인 시드(Seed) 값을 바탕으로 길고 복잡한, 그러나 완전히 결정론적인 숫자 시퀀스를 생성한다.</p>
<p>LLM의 샘플링 메커니즘 역시 내부적으로 이 PRNG가 제공하는 난수를 사용하여 확률 분포 상의 특정 지점을 선택한다. 만약 개발자가 API 호출 시 <code>seed</code> 파라미터를 임의의 정수(예: <code>42</code>, <code>12345</code> 등)로 명시적으로 고정한다면, 토큰을 샘플링할 때마다 PRNG가 도출하는 난수 시퀀스의 시작점과 궤적이 이전 호출과 정확히 동일하게 고정된다.</p>
<p><strong>Seed 파라미터 기반의 토큰 확률 분포 및 샘플링 메커니즘</strong></p>
<p><img src="./4.3.0.0.0%20%EC%9E%AC%ED%98%84%EC%84%B1Reproducibility%20%EB%B3%B4%EC%9E%A5%EC%9D%84%20%EC%9C%84%ED%95%9C%20Seed%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%20%ED%99%9C%EC%9A%A9.assets/image-20260225195212974.jpg" alt="image-20260225195212974" /></p>
<p>소프트맥스 함수를 통과한 상위 5개 토큰의 확률 분포. Seed 파라미터는 PRNG의 난수 생성 위치(화살표)를 고정하여, 동일한 확률 분포 하에서 항상 동일한 토큰이 샘플링되도록 보장한다.</p>
<p>즉, 프롬프트 입력이 동일하여 문맥이 같고, <code>temperature</code>, <code>top_p</code>, <code>top_k</code> 등 로짓을 확률 분포로 변환하는 하이퍼파라미터가 완벽히 동일하게 유지된 상태에서 <code>seed</code>까지 고정된다면, 수학적 및 논리적으로는 매 호출마다 100% 동일한 토큰 시퀀스가 생성되어야 한다. 이러한 재현성 확보는 단위 테스트(Unit Test)를 작성하여 코드 변경 사항을 검증하거나, 서로 다른 프롬프트 디자인의 성능을 A/B 테스트할 때 일관된 통제 변인을 제공하므로 AI 기반 소프트웨어 개발 파이프라인에서 필수적인 기술로 자리 잡았다.</p>
<h2>3.  상용 LLM API 생태계의 Seed 지원과 시스템 지문(System Fingerprint)</h2>
<p>결정론적 검증에 대한 소프트웨어 엔지니어들의 강력한 요구에 부응하여, 현재 상용화된 대다수의 거대 언어 모델 API 제공업체는 텍스트 생성 과정에 관여하는 <code>seed</code> 파라미터를 외부에 노출하고 있다. 그러나 클라우드 기반의 분산 처리 시스템에서 모델이 구동되는 특성상, 제공업체들은 이 기능이 완벽한 결정론을 보장하지 못한다는 점을 명확히 명시하고 있다.</p>
<p>OpenAI는 <code>gpt-4-1106-preview</code> 및 <code>gpt-3.5-turbo-1106</code> 모델부터 Chat Completions API에 <code>seed</code> 파라미터를 정식으로 도입했다. 개발자는 요청 본문에 임의의 정수형 시드 값(예: <code>12345</code>)을 명시하여 동일한 프롬프트에 대해 거의 일관된(mostly consistent) 응답을 유도할 수 있다. 그러나 OpenAI 공식 문서는 “시스템이 최선을 다해(best effort) 결정론적 샘플링을 시도하지만, 완벽한 결정론은 보장되지 않는다“고 명시한다.</p>
<p>이러한 클라우드 환경의 블랙박스적 한계를 극복하고 개발자에게 디버깅의 기준점을 제공하기 위해, OpenAI는 API 응답 메타데이터에 <code>system_fingerprint</code>라는 필드를 도입했다. 이 시스템 지문은 단순한 해시값이 아니라, 해당 요청을 처리한 시점의 OpenAI 백엔드 시스템 설정, 모델 가중치(Weight)의 미세 조정 상태, 추론 인프라의 구성 등 모델 실행 환경의 고유한 조합을 나타내는 식별자다.</p>
<p>만약 개발자가 프롬프트, <code>temperature</code>, <code>top_p</code>, 그리고 <code>seed</code>를 이전 요청과 완벽하게 동일하게 설정했음에도 불구하고 생성된 응답 텍스트가 달라졌다면, 가장 먼저 응답 객체 내의 <code>system_fingerprint</code>가 변경되었는지 확인해야 한다. 만약 지문이 <code>fp_44709d6fcb</code>에서 <code>fp_772e8125bb</code> 등으로 변경되었다면, 이는 프롬프트나 시드의 문제가 아니라 OpenAI 백엔드 인프라의 숫자적 연산 구조나 모델 가중치가 업데이트되었음을 의미한다. 시스템 구성이 달라지면 로짓 연산의 미세한 결과값이 달라지므로, 동일한 시드 값을 사용하더라도 과거의 출력 결과를 완벽하게 재현할 수 없게 된다. 반면, 모든 파라미터가 동일하고 시스템 지문까지 동일함에도 불구하고 결과가 다르다면, 이는 모델 내부의 내재적 비결정성(Inherent Non-determinism)으로 인한 것이다.</p>
<p>Google의 Gemini API(Vertex AI 및 Google AI Studio) 역시 유사한 메커니즘을 제공한다. <code>GenerationConfig</code> 객체를 통해 <code>seed</code> 파라미터를 정수 형태로 지원하며, 이는 디코딩 단계에서 재현성을 높이기 위해 사용된다.</p>
<pre><code class="language-Python">from google import genai
from google.genai import types

# 클라이언트 초기화 (Gemini API)
client = genai.Client()

# 오라클 구축을 위한 엄격한 생성 설정
config = types.GenerateContentConfig(
    temperature=0.0,      # 무작위성을 최소화하여 0에 가깝게 설정
    top_p=1.0,            # 전체 분포 고려
    top_k=1,              # 그리디 디코딩 성향 극대화
    seed=42,              # 의사 난수 생성기(PRNG) 궤적 고정
    max_output_tokens=256
)

response = client.models.generate_content(
    model='gemini-2.5-flash',
    contents='다음 시스템 로그를 분석하고 장애의 원인을 한 단어로 출력하라: "Error: Connection timed out to DB cluster at port 5432"',
    config=config
)
print(response.text)
</code></pre>
<p>하지만 Google의 문서 또한 “시드를 고정하더라도 결정론적 출력이 완전히 보장되지는 않으며, 파라미터나 모델의 미세한 변경이 응답의 변형을 초래할 수 있다“고 경고한다. 특히 최근 개발자 커뮤니티에서는 Gemini 1.5 Pro와 같은 최신 고성능 모델에서 <code>temperature=0</code>과 고정된 <code>seed</code>를 함께 사용했음에도 불구하고, 동일한 프롬프트에 대해 빈 배열(``)과 특정 데이터가 포함된 배열(<code>["11"]</code>)을 번갈아 반환하는 명백한 비결정적 동작이 다수 보고되고 있다. 일부 개발자들은 Vertex AI 환경에서는 <code>generation_config</code>를 통한 시드 적용이 가능하지만, 일반 Gemini API 환경에서는 시드 설정 시 오류가 발생하거나 무시되는 현상에 대해 문제를 제기하기도 했다. 이는 상용 API 환경에서 결정론을 확보하는 것이 단순한 파라미터 주입을 넘어선 시스템 차원의 난제임을 시사한다.</p>
<p>반면, Hugging Face Transformers나 Ollama, vLLM과 같은 로컬 호스팅 기반 추론 환경에서는 API 대비 상대적으로 높은 수준의 재현성 제어가 가능하다. 개발자는 <code>torch.manual_seed()</code>를 통해 PyTorch 프레임워크 수준에서 난수 발생기를 고정하고, <code>do_sample=False</code>를 통해 완전한 그리디 디코딩을 강제할 수 있다. 나아가 <code>torch.use_deterministic_algorithms(True)</code> 설정을 활성화하여 연산 알고리즘 자체의 결정론을 강제할 수 있지만, 이 역시 완전히 동일한 하드웨어 디바이스와 소프트웨어 스택(CUDA 버전 등) 내에서만 보장되며 성능 상의 비용을 수반한다.</p>
<hr />
<h2>4.  환상의 결정론: 하드웨어 수준의 비결정성과 부동소수점 오차</h2>
<p>소프트웨어 엔지니어들은 흔히 <code>temperature=0</code>으로 설정하면 모델이 샘플링을 생략하고 오직 가장 확률이 높은 토큰만을 취하는 그리디 디코딩을 수행하므로 항상 동일한 결과가 도출될 것이라 가정한다. 거기에 추가로 <code>seed</code>까지 고정하면 무작위성에 의한 변수는 완벽히 차단된다고 믿는다. 그러나 클라우드 규모의 실전 LLM 시스템에서는 이러한 가정이 빈번하게 깨진다. 그 근본적인 원인은 LLM의 수학적 이론의 결함이 아니라, 연산을 물리적으로 수행하는 하드웨어(GPU)의 아키텍처와 분산 시스템 스케줄러(Dynamic Batching)의 고유한 특성에 기인한다.</p>
<p>가장 핵심적이고 극복하기 어려운 원인은 **부동소수점 덧셈 연산의 비결합 법칙(Non-associativity of floating-point arithmetic)**이다. 수학적 정의에 따르면 실수의 덧셈은 결합 법칙이 완벽하게 성립한다: <span class="math math-inline">(a + b) + c = a + (b + c)</span>. 그러나 컴퓨터가 사용하는 IEEE 754 표준 기반의 부동소수점(FP16, BF16, FP32 등) 연산 체계에서는 메모리 한계로 인해 표현할 수 있는 유효 숫자(Mantissa)의 길이에 제약이 있다. 크기가 확연히 다른 두 부동소수점 숫자를 더할 경우 정밀도 유지를 위해 지수(Exponent)를 맞추는 과정에서 하위 비트가 잘려나가는 버림(Rounding/Truncation) 오차가 필연적으로 발생한다. 따라서 동일한 숫자들을 더하더라도 연산을 어떤 순서로 수행하느냐에 따라 최종 누적 결과값이 미세하게 달라지게 된다.</p>
<p>대규모 언어 모델의 순전파(Forward Pass) 연산은 거대한 행렬 곱셈(Matrix Multiplication)과 정규화(LayerNorm, RMSNorm), 그리고 어텐션(Attention) 연산으로 구성된다. 이 연산들은 본질적으로 방대한 배열의 요소들을 하나로 합치는 리덕션(Reduction) 연산을 수반한다. 최신 GPU는 수천 개의 스트리밍 멀티프로세서(SM)를 동원하여 이 리덕션 연산을 고도로 병렬화하여 처리한다. 이때 다수의 병렬 스레드가 동일한 메모리 주소에 결괏값을 누적하기 위해 ’원자적 덧셈(Atomic Add)’을 수행하는 경우가 발생한다. 문제는 하드웨어의 미세한 온도 변화나 전압 스파이크, 클럭 속도 등에 의해 어떤 스레드가 연산을 먼저 끝내고 덧셈을 수행할지 예측할 수 없는 경합 조건(Race Condition)이 발생한다는 점이다. 스레드의 도착 순서가 달라지면 부동소수점 덧셈의 순서가 바뀌고, 비결합 법칙에 의해 최종 로짓(Logit) 값의 끄트머리 소수점에서 미세한 불일치가 발생한다.</p>
<p>더 나아가, 클라우드 기반 API 제공업체들은 GPU 활용률과 서버 처리량을 극대화하기 위해 ‘동적 배치(Dynamic Batching)’ 기법을 필수적으로 사용한다. 내가 보낸 API 요청은 그 순간 전 세계의 다른 사용자들이 전송한 길이가 제각각인 프롬프트들과 실시간으로 하나의 배치(Batch)로 묶여 GPU 메모리에 적재된다.</p>
<p><strong>GPU 부동소수점 연산 오차와 LLM 비결정성 발생 매커니즘</strong></p>
<p><img src="./4.3.0.0.0%20%EC%9E%AC%ED%98%84%EC%84%B1Reproducibility%20%EB%B3%B4%EC%9E%A5%EC%9D%84%20%EC%9C%84%ED%95%9C%20Seed%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%20%ED%99%9C%EC%9A%A9.assets/image-20260225195303443.jpg" alt="image-20260225195303443" /></p>
<p><em>동일한 행렬 곱셈 연산이라도 GPU 내의 스레드 처리 순서나 동적 배치의 크기에 따라 부동소수점 덧셈 순서가 변경 된다. 이 미세한 반올림(Rounding) 오차의 누적이 상위 토큰 간의 확률이 매우 비슷할때 순위를 뒤바꾸는 (Token Flip) 결과를 초래 한다.</em></p>
<p>배치의 전체 크기나 시퀀스 길이의 합이 변경되면, GPU 내에서 구동되는 행렬 연산 커널(예: cuBLAS, Triton, FlashAttention 등)은 연산 효율성을 위해 내부의 리덕션 스케줄(Reduction Schedule)이나 덧셈 트리의 구조를 동적으로 재구성한다. 즉, 어제 단독으로 실행했을 때의 덧셈 순서와 오늘 다른 사용자의 요청과 묶여서 실행될 때의 덧셈 순서가 근본적으로 달라지는 것이다.</p>
<p>이러한 연산 순서의 차이로 인해 발생한 소수점 단위의 미세한 오차는 일반적으로는 무시할 만한 수준이다. 그러나 특정 생성 단계에서 어휘 사전 내 1순위 토큰과 2순위 토큰이 모델의 계산 결과 거의 동일한 확률(예: <span class="math math-inline">49.999999\%</span> 대 <span class="math math-inline">49.999998\%</span>)을 가지며 치열하게 경합하는 상황이 발생한다면 이야기가 달라진다. 이때 미세한 부동소수점 오차가 두 토큰의 순위를 뒤바꾸어 버리는 현상인 ’토큰 플립(Token Flip)’이 발생한다.</p>
<p>LLM은 이전에 생성된 텍스트를 입력으로 받아 다음 텍스트를 생성하는 자기회귀(Autoregressive) 구조를 띠고 있다. 따라서 단 하나의 토큰이라도 다른 토큰으로 교체되어 출력되면, 그 다음 단계의 연산에서는 완전히 다른 입력 문맥(Context)을 바탕으로 확률을 계산하게 된다. 이는 카오스 이론의 나비효과와 같이 초기 조건의 미세한 차이가 출력 텍스트 전체의 서사, 구조, 심지어 논리적 결론까지 완전히 빗나가게 만드는 눈덩이 효과(Snowball Effect)를 유발한다.</p>
<p>결론적으로, 개발자가 API 계층에서 제어할 수 있는 <code>seed</code>와 <code>temperature</code> 파라미터는 디코딩 단계의 의사 난수 생성만을 통제할 수 있을 뿐, 그 이면에 존재하는 GPU 하드웨어의 부동소수점 비결합성과 인프라의 동적 스케줄링으로 인한 근원적 비결정성까지는 완벽히 제거할 수 없다. 완벽한 비트 수준의 재현성을 얻기 위해서는 로컬 환경에서 동적 배치를 비활성화하고 배치 불변성(Batch-invariant)을 보장하는 특수 커널을 사용해야 하지만, 이는 엄청난 성능 저하를 감수해야 하므로 대용량 상용 API 시스템에서는 채택되지 않는다.</p>
<hr />
<h2>5.  학술적 지표로 본 비결정성의 양상과 오라클 검증의 한계</h2>
<p>소프트웨어의 무결성을 검증하기 위한 자동화 오라클을 설계할 때, 이러한 하드웨어 기반의 간헐적 비결정성은 테스트 전략 전체를 뒤흔드는 심각한 리스크다. 동일한 입력 값에 대해 동일한 로직을 수행했음에도 시스템 외부의 물리적 상태(스레드 경합 등)로 인해 어제는 통과(Pass)했던 테스트 코드가 오늘은 실패(Fail)하는 현상이 필연적으로 발생하기 때문이다. 최근 학계에서는 이러한 상용 LLM의 불안정성을 정량적으로 측정하고, 작업 유형에 따른 재현성의 한계를 규명하는 연구들이 잇달아 발표되고 있다.</p>
<p>코넬 대학교 등의 연구진이 발표한 논문 <em>Large Language Models are Unstable at Zero Temperature</em>는 최첨단 LLM의 숨겨진 비결정성을 적나라하게 보여준다. 연구진은 GPT-4o, Claude-3.5-Sonnet, Gemini-1.5-Pro와 같은 현존 최고 성능의 모델들을 대상으로, 무작위성을 배제하기 위해 <code>temperature=0</code>으로 설정하고 고정된 시스템 프롬프트를 사용하여 복잡한 법률 기반 이진 판별 문제(어느 당사자가 승소해야 하는가?)를 20회 반복 평가했다. 상식적인 소프트웨어라면 20회 모두 완벽히 동일한 답변을 내놓아야 하지만, 실험 결과 Claude-3.5는 10.6%, GPT-4o는 더 높은 비율, 그리고 Gemini-1.5는 최대 50.4%의 질문에서 동일한 프롬프트에 대해 승소 당사자를 번복하는 치명적인 불안정성(Instability)을 보였다. 연구진은 이러한 결과가 앞서 언급한 부동소수점 누적 오차(Floating-point accumulation)에 의한 토큰 플립에 기인한다고 분석했다. 이는 복잡한 논리적 추론이 필요한 영역에서 단일 API 호출의 결과를 절대적인 오라클 정답지로 신뢰할 수 없음을 강력히 시사한다.</p>
<p>한편, 재무 및 회계 분야의 LLM 재현성을 방대하게 분석한 <em>Assessing Consistency and Reproducibility in the Outputs of Large Language Models: Evidence Across Diverse Finance and Accounting Tasks</em> 연구는 오라클 설계에 실질적인 지침이 될 수 있는 유의미한 통계를 제공한다. 이 연구는 세 가지 OpenAI 모델을 사용하여 50일 동안 50번의 독립적인 추론(서로 다른 시드 부여)을 통해 총 340만 개 이상의 출력을 생성하고 그 일관성을 측정했다. 분석 결과, 모델의 비결정성은 ’수행하는 작업(Task)의 복잡도와 출력 공간의 크기’에 따라 극심한 편차를 보였다.</p>
<ol>
<li><strong>출력 공간이 제한된 단순 작업의 높은 일관성:</strong> 문장의 감성을 긍정/부정/중립으로 분류하거나, 문서가 미래 예측 정보를 포함하는지 판별하는 이진 분류(Binary Classification) 작업에서는 <code>seed</code>와 낮은 <code>temperature</code> 설정만으로도 50번의 실행 중 92% 이상의 문장에서 완벽히 동일한 결과를 유지했다 (Fleiss’ Kappa 계수 0.93 이상 달성).</li>
<li><strong>자유도가 높은 생성 작업의 변동성:</strong> 반면, 문서 요약(Summarization)이나 긴 텍스트 생성 작업에서는 모델의 출력 변동성이 뚜렷하게 증가했다. 의미론적 일관성(Semantic Consistency)을 나타내는 코사인 유사도는 평균 0.94 이상으로 높았으나, 생성된 텍스트의 구조, 어조, 문장 길이 등은 매번 달랐다. 이는 출력해야 할 토큰의 수가 길어질수록 하드웨어적 연산 오차가 누적되어 토큰 플립이 발생할 확률이 선형적으로 증가하기 때문이다.</li>
<li><strong>인간 전문가 수준과의 비교:</strong> 흥미로운 점은, 이러한 비결정성에도 불구하고 감성 분류 작업에서 LLM은 인간 전문가보다 오히려 더 높은 일관성을 보였다는 것이다. 복잡한 재무 텍스트에 대해 인간 분석가들이 심각한 의견 불일치를 보이는 경우에도 LLM은 96.8% ~ 98.3%의 높은 합의율(Agreement)을 유지했다. 이는 LLM의 응답이 흔들리더라도, 인간의 주관적 편향보다는 훨씬 예측 가능성이 높음을 의미한다.</li>
</ol>
<p>또한 ICLR 2026에 채택된 <em>String Seed of Thought: Prompting LLMs for Distribution-Faithful and Diverse Generation</em> 연구는 LLM이 지닌 또 다른 확률적 결함을 지적한다. 특정 확률 분포(예: 정확히 50대 50의 비율로 ‘앞면’ 또는 ’뒷면’을 출력)를 따르도록 지시하는 확률적 명령 추종(Probabilistic Instruction Following, PIF) 작업에서 LLM은 심각한 편향성을 보이며 실패한다. 연구진은 이를 해결하기 위해 프롬프트 전반부에 모델이 임의의 문자열(Random String)을 강제로 출력하게 하여 초기 엔트로피를 확보한 뒤, 이 문자열을 조작하여 최종 답변을 도출하게 하는 SSoT(String Seed of Thought) 기법을 제안했다. 이는 역설적으로 완벽한 결정론뿐만 아니라 완벽한 무작위성을 시뮬레이션하는 환경조차도 LLM의 자체적인 메커니즘만으로는 제어하기 어려움을 보여주는 학술적 증거다.</p>
<hr />
<h2>6.  실전 AI 시스템을 위한 견고한 합의 기반 오라클(Consensus Oracle) 구축 전략</h2>
<p>앞선 분석을 통해 클라우드 기반의 LLM API는 소프트웨어 레벨의 파라미터 조작만으로 100% 결정론적 하드웨어 동작을 보장할 수 없다는 사실이 명백해졌다. 따라서 AI 애플리케이션의 테스트와 품질 보증을 책임지는 소프트웨어 엔지니어는 “LLM의 응답이 단 한 글자도 변하지 않기를 기대하는” 기존의 엄격한 TDD(Test-Driven Development) 철학을 수정해야 한다. 그 대신, “LLM의 근원적 변동성을 포용하면서도, 통계적 안정성을 부여하여 확정적인 통과/실패(Pass/Fail) 판별이 가능한 오라클 시스템을 설계하는 것“으로 패러다임을 전환해야 한다.</p>
<p>안정적인 자동화 검증 오라클을 구축하기 위해 <code>seed</code> 파라미터를 실무 파이프라인에 효과적으로 융합하는 4단계 아키텍처 방법론은 다음과 같다.</p>
<h3>6.1 단계 1. 극단적인 매개변수 제어 및 System Fingerprint 형상 관리</h3>
<p>비록 완벽하지 않더라도, 통제 가능한 모든 무작위성 변수는 사전에 제거해야 한다. 테스트 환경이나 CI/CD 파이프라인에서 API를 호출할 때는 <code>temperature</code>를 <code>0</code> (또는 API가 허용하는 최솟값)으로, <code>top_p</code>는 제약 조건 없이 가장 높은 확률만 탐색하도록 설정하고(<code>1.0</code>), <code>top_k</code>는 <code>1</code>로 설정하여 그리디 디코딩을 강제해야 한다. 그리고 모든 검증 요청에 동일한 <code>seed</code> 값을 부여한다. 특히 OpenAI API를 사용할 경우, 파이프라인의 테스트 러너(Test Runner)는 반드시 응답 객체에 포함된 <code>system_fingerprint</code>를 테스트 결과 데이터베이스나 Git 형상 관리 시스템에 함께 로깅해야 한다.</p>
<p>오라클의 검증 실패 원인 분석 기준은 다음과 같이 시스템 지문을 기준으로 이원화되어야 한다.</p>
<table><thead><tr><th><strong>검증 시나리오</strong></th><th><strong>검증 방법 (Assert)</strong></th><th><strong>실패 원인 분석 기준 (Root Cause Analysis)</strong></th></tr></thead><tbody>
<tr><td><strong>정확한 일치 (Exact Match)</strong></td><td><code>assert actual == expected</code></td><td><code>system_fingerprint</code>가 동일한데 실패했다면 프롬프트 누수(Prompt Leakage), 데이터베이스 변경 등 외부 RAG 파이프라인 동적 데이터 변경에 의한 논리적 버그일 확률이 높다.</td></tr>
<tr><td><strong>인프라 변경 (Backend Update)</strong></td><td><code>fingerprint</code> 비교</td><td>텍스트가 달라졌으나 지문 식별자가 이전 버전과 다르다면 코드 버그가 아니라 OpenAI 측의 인프라 업데이트/모델 가중치 재조정에 의한 것이다. 이 경우 개발팀은 새로운 시스템 지문을 기준으로 골든 데이터셋(Golden Dataset)의 정답지를 갱신하는 캘리브레이션 프로세스를 가동해야 한다.</td></tr>
<tr><td><strong>의미론적 일치 (Semantic Match)</strong></td><td>ROUGE, BERTScore, LLM-as-a-Judge</td><td>텍스트의 미세한 어조 변화나 토큰 플립은 허용하되, 비즈니스의 핵심 의미(예: 추출된 총액 수치)가 유지되는지 검증하는 유연한 오라클 매칭 방식을 도입해야 한다.</td></tr>
</tbody></table>
<p>프롬프트 내에 포함된 RAG(Retrieval-Augmented Generation) 검색 결과의 공백 문자 하나, 혹은 JSON 직렬화 시 키(Key)의 배열 순서 하나만 변경되어도 이는 완전히 새로운 프롬프트로 인식되어 시드가 보장하는 PRNG 궤적을 빗나가게 만든다. 따라서 입력 데이터의 엄격한 정규화(Normalization) 전처리가 선행되어야 한다.</p>
<h3>6.2 단계 2. 구조화된 출력(Structured Outputs)을 통한 확률 공간 압축</h3>
<p>단순 텍스트 생성이 아닌, 출력 포맷을 엄격하게 제한하는 기능(예: OpenAI의 <code>response_format: { "type": "json_object" }</code> 또는 Gemini의 <code>responseSchema</code>)을 <code>seed</code> 파라미터와 결합하면 재현성이 극대화된다. 이는 출력 형태를 이진 분류나 열거형(Enum)에 가깝게 강제함으로써 LLM이 선택할 수 있는 확률 공간(Vocabulary Space)을 극단적으로 압축하는 효과를 낳는다. 후보군이 적어지면 토큰 플립이 발생할 확률이 현저히 낮아지므로, 하드웨어적 비결정성의 여지를 최소화하여 오라클이 정답과 대조하기 훨씬 수월해진다.</p>
<h3>6.3 단계 3. 자가 일관성(Self-Consistency) 및 앙상블을 통한 합의 오라클(Consensus Oracle) 도입</h3>
<p>의료 처방 분석, 금융 리스크 판별, 자동화된 SQL 쿼리 생성 등 단 하나의 토큰 오류로도 치명적인 서비스 장애가 발생할 수 있는 비즈니스 로직에 대해서는 단일 <code>seed</code> 평가 결과에 운명을 맡겨서는 안 된다.</p>
<p>최신 추론 최적화 기법 중 하나인 자가 일관성(Self-Consistency) 프롬프팅은 단일 프롬프트에 의존하는 것을 넘어, 언어 모델의 디코더에서 여러 개의 서로 다른 추론 경로(Reasoning Path)를 샘플링한 후 이들을 주변화(Marginalize)하여 가장 일관된 정답을 선택하는 방법론이다. 이 기법을 실전 오라클 아키텍처로 구현하려면 다음과 같은 앙상블 체계를 구축해야 한다.</p>
<p>먼저 온도를 <code>0</code>이 아닌 <code>0.2</code> 혹은 <code>0.3</code> 수준으로 미세하게 높여 의도적으로 무작위성을 부여한다. 그 후, 동일한 프롬프트를 3개에서 5개의 서로 다른 <code>seed</code> 값(예: <code>100</code>, <code>200</code>, <code>300</code>…)을 주어 병렬로 호출한다. 이 과정에서 모델은 토큰 단위의 미세한 변동이나 서로 다른 Chain-of-Thought 경로를 탐색하게 된다. 최종적으로 각 호출에서 도출된 결론들을 모아 다수결(Majority Voting) 알고리즘을 수행하여 가장 지배적인 응답을 최종 검증 정답지로 채택한다.</p>
<p>재무 연구에서 증명되었듯, 단일 호출 대신 3~5회의 독립적인 평가를 평균화하는 취합(Aggregation) 전략은 간헐적으로 발생하는 하드웨어 오차나 확률적 환각(Hallucination)을 수학적으로 상쇄하여 오라클의 일관성을 94% 이상으로 끌어올린다. 비용과 지연 시간(Latency)이 다소 증가한다는 단점이 있으나, 야간 회귀 테스트나 배포 전 CI/CD 파이프라인과 같이 신뢰성이 속도보다 우선시되는 오라클 검증 환경에서는 필수적인 아키텍처 설계다.</p>
<hr />
<h2>7.  실전 예제: Gemini API를 활용한 견고한 단위 테스트 오라클 구성</h2>
<p>다음은 실무 AI 애플리케이션 개발 과정에서 <code>seed</code> 파라미터와 재시도/합의 로직을 결합하여, 하드웨어 수준의 불안정성마저 우회하는 파이썬(Python) 기반의 오라클 검증 클래스(<code>RobustAIOracle</code>) 구현 예제다.</p>
<p>이 클래스는 <code>google-genai</code> 최신 SDK를 활용하며, 단순한 추출 로직을 위한 ’단일 고정 시드 평가(Strict Deterministic)’와 복잡한 추론 로직의 플래키 테스트 방지를 위한 ‘다수결 앙상블 평가(Consensus-based)’ 기능을 모두 구현하여 테스트 환경의 신뢰성을 극대화한다.</p>
<pre><code class="language-Python">import unittest
from collections import Counter
from google import genai
from google.genai import types

class RobustAIOracle(unittest.TestCase):
    def setUp(self):
        # Gemini API 최신 클라이언트 초기화 (ADC 또는 API Key 기반)
        # 프로덕션 환경에서는 Vertex AI 백엔드 사용을 권장한다.
        self.client = genai.Client()
        self.model_id = 'gemini-2.5-flash'
        self.base_seed = 12345
        
    def generate_with_seed(self, prompt: str, seed: int, temperature: float = 0.0) -&gt; str:
        """
        주어진 프롬프트와 시드로 모델을 호출하여 텍스트 결과를 반환한다.
        하드웨어적 비결정성을 최대한 억제하기 위해 하이퍼파라미터를 엄격하게 통제한다.
        """
        config = types.GenerateContentConfig(
            temperature=temperature,
            top_p=0.95,
            top_k=1, # Greedy decoding 성향을 강제
            seed=seed,
            max_output_tokens=50
        )
        response = self.client.models.generate_content(
            model=self.model_id,
            contents=prompt,
            config=config
        )
        return response.text.strip()

    def test_strict_deterministic_extraction(self):
        """
        [단위 테스트] 단일 Seed를 이용한 엄격한 결정론적 출력 검증
        주로 단순한 엔티티 추출, 이진 분류 등 출력 공간이 매우 좁은 경우에 적합하다.
        """
        prompt = "다음 문장에서 글로벌 기업의 이름만 정확히 추출하라: '어제 Microsoft는 새로운 데이터센터 건립을 발표했다.'"
        expected_oracle = "Microsoft"
        
        # 고정된 시드(base_seed)로 3회 반복 호출하여 
        # 시스템 내부의 하드웨어적 변동이 없는지 1차적으로 확인한다.
        results = [self.generate_with_seed(prompt, self.base_seed) for _ in range(3)]
        
        for result in results:
            self.assertEqual(result, expected_oracle, 
                             msg=f"검증 실패. 예상된 오라클 정답: {expected_oracle}, 실제 모델 반환: {result}")
            
    def test_consensus_based_reasoning(self):
        """
        [단위 테스트] 앙상블 합의(Consensus)를 통한 견고한 오라클 검증
        복잡한 추론이나 토큰 플립(Token Flip)이 발생할 수 있는 취약한 로직의 검증을 대비한다.
        단일 시드의 결과에 의존하지 않고, 다중 시드의 다수결 합의를 통해 정답을 도출한다.
        """
        prompt = "A가 B에게 5만원을 빌렸다. 이후 B는 A의 가게에서 2만원어치 물건을 샀다. 최종적으로 상계 처리 시 누가 누구에게 얼마를 현금으로 주어야 하는가? '누가', '누구에게', '금액' 정보만 띄어쓰기로 구분하여 간결하게 적어라."
        expected_oracle = "A가 B에게 3만원"
        
        # 의도적으로 온도를 미세하게 올리고(0.2), 서로 다른 5개의 Seed를 사용하여 다양한 추론 궤적을 탐색한다.
        seeds = 
        predictions =
        
        for seed in seeds:
            pred = self.generate_with_seed(prompt, seed=seed, temperature=0.2)
            predictions.append(pred)
            
        # collections.Counter를 이용한 다수결 합의(Majority Voting) 처리
        most_common_pred, count = Counter(predictions).most_common(1)
        
        # 5번 중 최소 3번(과반수) 이상 모델이 동일한 결론에 도달하여 합의를 이루었는지 확인
        self.assertGreaterEqual(count, 3, msg="모델이 통계적으로 유의미한 합의(Consensus)에 도달하지 못하여 오라클 신뢰도가 낮습니다.")
        
        # 가장 지배적으로 합의된 결과가 사전에 정의된 오라클 정답지와 일치하는지 최종 검증
        self.assertEqual(most_common_pred, expected_oracle, 
                         msg=f"합의는 이루었으나 오라클 정답과 불일치. 예상: {expected_oracle}, 도출된 다수결: {most_common_pred}")

if __name__ == "__main__":
    # 소프트웨어 엔지니어가 CI/CD 파이프라인에서 실행할 수 있도록 구성
    unittest.main()
</code></pre>
<p>이 접근법은 <code>seed</code> 파라미터가 가지는 “최선의 노력(Best Effort)“이라는 기술적 한계와 클라우드 인프라의 본질적 비결정성을 정면으로 인정한다. 동시에 분산 소프트웨어 공학에서 널리 쓰이는 다중화(Redundancy) 및 합의 알고리즘 기법을 AI 프롬프트 검증에 도입함으로써, 오라클 시스템의 통계적 신뢰성을 극대화하는 실전적인 방법론을 제시한다.</p>
<p>요약하자면, <code>seed</code> 파라미터는 AI 모델의 비결정성을 완벽하게 통제하는 만능 열쇠가 아니다. 오히려 하드웨어 수준에서 발생하는 노이즈에도 불구하고 디버깅과 테스팅 파이프라인의 재현성을 비약적으로 끌어올리기 위해 사용해야 하는 필수적인 ’통제 변인 도구’로 인식해야 한다. 테스트의 목적(단순 추출 vs. 복잡한 추론)에 맞게 <code>seed</code> 고정 기법과 자가 일관성에 기반한 앙상블 합의 기법을 전략적으로 배합하고, 실패 원인을 시스템 지문(System Fingerprint) 레벨에서 추적할 수 있는 체계를 갖출 때, 소프트웨어 엔지니어는 진정으로 견고하고 예측 가능한 AI 아키텍처를 완성할 수 있을 것이다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>The LLM probability distribution - vassnotes - Obsidian Publish, https://publish.obsidian.md/vassnotes/The+LLM+probability+distribution</li>
<li>Token Sampling Methods - aman.ai, https://aman.ai/primers/ai/token-sampling/</li>
<li>How LLMs Choose Their Words: A Practical Walk-Through of Logits, https://machinelearningmastery.com/how-llms-choose-their-words-a-practical-walk-through-of-logits-softmax-and-sampling/</li>
<li>LLM Sampling: Engineering Deep Dive | MatterAI Blog, https://www.matterai.so/blog/llm-sampling</li>
<li>LLM Parameters Explained: A Practical, Research-Oriented Guide, https://promptrevolution.poltextlab.com/llm-parameters-explained-a-practical-research-oriented-guide-with-examples/</li>
<li>Self-Consistency Improves Chain of Thought Reasoning in … - arXiv, https://arxiv.org/pdf/2203.11171</li>
<li>Content generation parameters | Generative AI on Vertex AI, https://docs.cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters</li>
<li>How to Use the Seed parameter? - Vellum AI, https://www.vellum.ai/llm-parameters/seed</li>
<li>OpenAI Seeding, Model Fingerprints &amp; Log Probabilities, https://cobusgreyling.medium.com/openai-seeding-model-fingerprints-log-probabilities-cedf094e8b02</li>
<li>Seed Parameter: Achieving Reproducible LLM Outputs, https://michaeljohnpena.com/blog/2023-11-08-seed-parameter-reproducible-outputs/</li>
<li>How to get consistent and reproducible LLM outputs in 2025, https://www.keywordsai.co/blog/llm_consistency_2025</li>
<li>[PROBLEM] Inconsistent Deterministic Outputs with Seed Parameter, https://github.com/openai/openai-cookbook/issues/861</li>
<li>How to make your completions outputs consistent with the new seed …, https://developers.openai.com/cookbook/examples/reproducible_outputs_with_the_seed_parameter/</li>
<li>Controlling randomness in LLMs: Temperature and Seed, https://dylancastillo.co/posts/seed-temperature-llms.html</li>
<li>Seed param and reproducible output do not work - Page 2 - API, https://community.openai.com/t/seed-param-and-reproducible-output-do-not-work/487245?page=2</li>
<li>Why is my RAG model giving non-deterministic answer to same, https://learn.microsoft.com/en-us/answers/questions/2120851/why-is-my-rag-model-giving-non-deterministic-answe</li>
<li>Interactions API - Gemini API | Google AI for Developers, https://ai.google.dev/api/interactions-api</li>
<li>GenerationConfig | Generative AI on Vertex AI | Google Cloud …, https://docs.cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/GenerationConfig</li>
<li>Experiment with parameter values | Generative AI on Vertex AI, https://docs.cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values</li>
<li>The Gemini API is exhibiting non-deterministic behavior for the, https://discuss.ai.google.dev/t/the-gemini-api-is-exhibiting-non-deterministic-behavior-for-the-gemini-2-5-pro-model-it-is-producing-different-outputs-for-identical-requests-even-when-a-fixed-seed-is-provided-along-with-a-constant-temperature-this-behavior-has-been-reliably-rep/101331</li>
<li>Gemini API: Playground and SDK give different results with identical, https://discuss.ai.google.dev/t/gemini-api-playground-and-sdk-give-different-results-with-identical-configuration/106768</li>
<li>Not able to set seed parameter in generation_config #536 - GitHub, https://github.com/google-gemini/deprecated-generative-ai-python/issues/536</li>
<li>Defeating nondeterminism in LLM inference, in practice - Medium, https://medium.com/@siddhantg314/defeating-nondeterminism-in-llm-inference-in-practice-38a7dd1e4112</li>
<li>It’s worth noting that LLMs are non-deterministic, This is probably, https://news.ycombinator.com/item?id=44527256</li>
<li>Question about the Use of Seed Parameter and Deterministic Outputs, https://community.openai.com/t/question-about-the-use-of-seed-parameter-and-deterministic-outputs/773638</li>
<li>LLMs Provide Unstable Answers to Legal Questions - arXiv, https://arxiv.org/html/2502.05196v1</li>
<li>[Discussion] Non deterministic behaviour in LLMs when temperature, https://www.reddit.com/r/MachineLearning/comments/16hmwcc/discussion_non_deterministic_behaviour_in_llms/</li>
<li>Enabling Determinism in LLM Inference with Verified Speculation, https://arxiv.org/html/2601.17768v2</li>
<li>Defeating Nondeterminism in LLM Inference - Thinking Machines Lab, https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/</li>
<li>Solving Reproducibility Challenges in Deep Learning and LLMs, https://www.ingonyama.com/oldblogs/solving-reproducibility-challenges-in-deep-learning-and-llms-our-journey</li>
<li>(PDF) Assessing Consistency and Reproducibility in the Outputs of …, https://www.researchgate.net/publication/390114073_Assessing_Consistency_and_Reproducibility_in_the_Outputs_of_Large_Language_Models_Evidence_Across_Diverse_Finance_and_Accounting_Tasks</li>
<li>PROMPTING LLMS FOR DISTRIBUTION-FAITHFUL AND DIVERSE, https://openreview.net/pdf/77ee56c1ce86c85b8cc1b51f8069a95f89cb0346.pdf</li>
<li>Prompting LLMs for Distribution-Faithful and Diverse Generation, https://arxiv.org/pdf/2510.21150</li>
<li>Prompting LLMs for Distribution-Faithful and Diverse Generation, https://arxiv.org/abs/2510.21150</li>
<li>Prompting LLMs for Distribution-Faithful and Diverse Generation, https://arxiv.org/html/2510.21150v3</li>
<li>The seed inference parameter for reproducibility - API, https://community.openai.com/t/the-seed-inference-parameter-for-reproducibility/556118</li>
<li>ChatGoogleGenerativeAI integration - Docs by LangChain, https://docs.langchain.com/oss/python/integrations/chat/google_generative_ai</li>
<li>Google Gen AI SDK documentation, https://googleapis.github.io/python-genai/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>