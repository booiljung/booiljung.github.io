<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:4.4 시스템 프롬프트(System Prompt)를 이용한 페르소나 및 규칙 고정</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>4.4 시스템 프롬프트(System Prompt)를 이용한 페르소나 및 규칙 고정</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 4. AI 모델 응답의 일관성 확보를 위한 프롬프트 엔지니어링 및 파라미터 제어</a> / <a href="index.html">4.4 시스템 프롬프트(System Prompt)를 이용한 페르소나 및 규칙 고정</a> / <span>4.4 시스템 프롬프트(System Prompt)를 이용한 페르소나 및 규칙 고정</span></nav>
                </div>
            </header>
            <article>
                <h1>4.4 시스템 프롬프트(System Prompt)를 이용한 페르소나 및 규칙 고정</h1>
<p>AI 기반 소프트웨어 개발 파이프라인에서 대형 언어 모델(Large Language Model, LLM)을 검증 및 자동화 로직의 구성 요소로 사용할 때 직면하는 가장 치명적인 문제는 응답의 비결정성(Nondeterminism)이다. 결정론적 정답지(Ground Truth)를 판단하는 오라클(Oracle)로 기능해야 할 시스템이 입력 환경이나 내부 확률 분포에 따라 매번 다른 응답을 내놓는다면, 전체 소프트웨어 시스템의 신뢰성은 근본적으로 무너진다. 특히 코드 생성, 유닛 테스트 합성, 데이터 정합성 검사와 같이 엄격한 형식과 논리가 요구되는 작업에서는 모델의 자유도를 극도로 제한하고 동작의 경계를 설정하는 강력한 통제 매커니즘이 필수적이다.</p>
<p>이러한 비결정성을 제어하고 모델의 행동을 확정적으로 고정하는 가장 직접적이고 핵심적인 기술이 바로 시스템 프롬프트(System Prompt)이다. 일반적인 대화형 AI 사용 환경에서는 프롬프트를 일회성 질문이나 작업 지시를 위한 사용자 프롬프트(User Prompt)로 취급하지만, 소프트웨어 엔지니어링 환경에서는 시스템 프롬프트를 전역 설정 파일이자 모델의 헌법(Constitution)으로 취급해야 한다. 시스템 프롬프트는 보이지 않는 백그라운드에서 모델의 페르소나(Persona), 출력 형식, 금지 사항, 윤리적 제약을 정의하며, 입력의 맥락이 아무리 변하더라도 반드시 지켜져야 하는 규칙을 강제한다. 이는 마치 운영체제의 커널(Kernel) 수준에서 작동하는 보안 정책과 같이, 애플리케이션 계층(사용자 입력)의 변동성으로부터 시스템의 핵심 동작 원리를 보호하는 역할을 수행한다.</p>
<h3>0.1  시스템 프롬프트의 본질과 주의 집중(Attention) 비대칭성 및 보안성</h3>
<p>시스템 프롬프트는 구조적으로 사용자 프롬프트와 완전히 분리되어 처리되며, 그 영향력과 가중치에 있어서 철저한 비대칭성을 갖는다. 기반 모델(Foundation Model)의 훈련 과정에서 시스템 프롬프트는 일반 입력 텍스트와 구별되는 특수한 토큰(Special Token)으로 래핑되며, 신경망 내부의 주의 집중 메커니즘(Attention Mechanism)에서 훨씬 더 높은 가중치를 부여받도록 설계된다. 이는 모델이 다중 턴(Multi-turn) 대화나 복잡한 추론 과정을 거칠 때, 사용자의 가변적인 입력에 휘둘리지 않고 초기 설정된 제약 조건과 정체성을 최우선적으로 유지하도록 만들기 위함이다.</p>
<p>여러 상용 LLM의 어텐션 가중치를 분석한 연구 결과에 따르면, 모델은 특정 위치에 배치된 메시지에 더 높은 가중치를 두는 포지션 편향(Position Bias)을 가지며, 시스템 프롬프트가 위치한 최상단 영역은 모델의 내부 상태 추론을 주도하는 가장 강력한 신호 원천이 된다. 이러한 특성은 특히 정보의 계층적 구조화가 필수적인 오라클 시스템 설계에서 매우 중요한 의미를 갖는다. 시스템 프롬프트에 정의된 페르소나와 논리적 경계는 사용자 프롬프트에 포함될 수 있는 악의적인 프롬프트 인젝션(Prompt Injection)이나 맥락을 벗어나는 요구를 우선적으로 차단(Override)하는 강력한 방어기제로 작동한다.</p>
<p>시스템 프롬프트가 모델의 기저 층위에서 발휘하는 물리적 통제력은 보안 및 적대적 공격 방어 연구를 통해 수학적으로 입증되었다. 논문 <em>AttentionDefense</em>에 제시된 연구 결과는 대형 언어 모델의 시스템 프롬프트 토큰에 대한 어텐션(Attention) 가중치를 분석하는 것만으로도, 프롬프트의 의미론적 임베딩(Semantic Embedding)을 텍스트 분류기로 분석하는 전통적인 방식보다 훨씬 더 높은 정확도로 탈옥(Jailbreak) 및 적대적 공격을 탐지할 수 있음을 보여준다. 특히, 수백억 개의 파라미터를 가진 거대 모델이 아닌 소형 언어 모델(Small Language Model, SLM)인 Phi-2 모델의 어텐션 맵(Attention Map)을 기반으로 랜덤 포레스트(Random Forest) 분류기를 적용했을 때, 정밀도(Precision)가 0.99를 초과하는 압도적인 방어 성능(F1-score 0.86)을 기록했다.</p>
<p>이러한 결과는 여러 가지 시사점을 제공한다. 모델의 어텐션 메커니즘 내에서 시스템 프롬프트의 ‘메커니즘(Mechanism)’ 지시어(예: 어떻게 행동할 것인가)와 ‘페이로드(Payload)’ 지시어(예: 무엇을 출력할 것인가) 중, 고정밀도를 보장하기 위해서는 메커니즘 지시어에 대한 어텐션이 훨씬 더 결정적인 역할을 한다는 점이다. 즉, 소프트웨어 오라클을 구축할 때 단순한 지식의 주입보다, 정보를 어떻게 검증하고 어떤 논리적 절차를 거쳐 출력할 것인지에 대한 절차적 규칙을 시스템 프롬프트에 명시하는 것이 모델의 비결정성 제어에 직접적인 타격을 준다는 것을 의미한다. 결과적으로 시스템 프롬프트는 단순한 가이드라인 텍스트 뭉치가 아니라, LLM의 잠재 공간(Latent Space)과 파라미터 활성화 벡터를 물리적으로 재조정하는 핵심 제어기인 것이다.</p>
<p><strong>다중 턴 환경에서의 시스템 프롬프트 주의 집중 유지율 분석</strong></p>
<p><img src="./4.4.0.0.0%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8System%20Prompt%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%ED%8E%98%EB%A5%B4%EC%86%8C%EB%82%98%20%EB%B0%8F%20%EA%B7%9C%EC%B9%99%20%EA%B3%A0%EC%A0%95.assets/image-20260225232820140.jpg" alt="image-20260225232820140" /></p>
<h3>0.2  고스트 어텐션(Ghost Attention)과 다중 턴(Multi-turn) 환경에서의 페르소나 지속성</h3>
<p>단일 프롬프트-응답 사이클에서는 시스템 프롬프트가 규칙을 완벽하게 통제하는 것처럼 보이나, 대화형 추론이나 여러 단계의 프로세스 체인(Chain)이 이어지는 다중 턴 환경에서는 치명적인 기술적 결함이 발생한다. 컨텍스트 윈도우(Context Window)가 사용자 입력과 모델의 이전 생성물, 외부 도구(Tool)의 실행 결과값 등으로 채워지기 시작하면, 가장 초기에 주입되었던 시스템 프롬프트의 영향력이 점진적으로 희석되는 맥락 망각(Context Forgetting) 현상이 필연적으로 일어난다. 소프트웨어 테스트 자동화에서 여러 단계를 거쳐 오라클을 검증할 때 중간에 모델이 설정된 평가자로서의 페르소나를 잊고 범용적인 어시스턴트로 회귀하는 현상(Persona Drift)은 오라클의 일관성을 파괴하며, 종국에는 오라클로서의 가치를 상실하게 만든다.</p>
<p>이러한 어텐션 희석의 한계를 극복하기 위해, 메타(Meta)의 Llama 2 파운데이션 모델 등 최신 LLM 아키텍처는 고스트 어텐션(Ghost Attention, GAtt)이라는 진보된 미세 조정 및 훈련 기법을 도입하였다. 논문 <em>Llama 2: Open Foundation and Fine-Tuned Chat Models</em>에 상술된 고스트 어텐션 기법은, 추론(Inference) 단계에서 사용자가 매번 시스템 프롬프트를 반복적으로 입력하지 않더라도 모델이 다중 턴 내내 시스템 프롬프트를 유령(Ghost)처럼 기억하도록 강제하는 혁신적인 방법론이다.</p>
<p>고스트 어텐션의 훈련 메커니즘은 교묘하게 설계되었다. 훈련 데이터셋을 구성할 때, 다중 턴 대화의 매 턴마다 시스템 지시어(Instruction String)를 사용자의 메시지 앞에 인위적으로 병합(Prepend)하여 모델에 제공한다. 그러나 손실(Loss)을 계산하고 가중치를 업데이트하는 과정에서는 반복적으로 추가된 지시어 토큰 부분을 무시하고 오직 이전 턴들의 맥락 위에서 생성된 답변에 대해서만 학습을 진행한다. 이 과정을 인간 피드백 기반 강화학습(RLHF) 및 근접 정책 최적화(PPO), 기각 샘플링(Rejection Sampling) 파이프라인과 결합하여 미세 조정하면, 모델의 자체 어텐션(Self-attention) 메커니즘은 대화가 깊어지더라도 초기 시스템 프롬프트의 제약 사항을 끈질기게 붙잡도록 신경망 구조가 재편성된다.</p>
<p>이 기법의 도입 결과는 놀랍다. 어텐션 히트맵(Heatmap)을 분석해 보면, 대화가 20턴 이상 진행되어 컨텍스트 윈도우가 가득 찬 상태에서도 고스트 어텐션이 적용된 모델은 초기 시스템 프롬프트에 할당된 토큰들에 대해 여전히 매우 강한 주의 집중 가중치를 유지한다. 모델은 설정된 인물의 페르소나, 특정한 언어적 제약(예: 오직 이모지로만 대답하라, 또는 엄격한 JSON으로만 출력하라), 지식의 한계망을 망각하지 않고 확정적으로 유지할 수 있게 된다. 즉, 결정론적 소프트웨어 컴포넌트를 구현하기 위해서는 단순히 프롬프트를 잘 작성하는 것을 넘어, 호출하고자 하는 기반 모델이 고스트 어텐션 혹은 이에 준하는 시스템 지시어 유지 훈련을 거쳐 포지션 편향을 의도적으로 최적화한 아키텍처인지를 확인하는 것이 시스템 설계의 첫 단계라 할 수 있다.</p>
<h3>0.3  페르소나 조향성(Steerability)과 일관성의 수학적 모델링 및 평가</h3>
<p>소프트웨어 시스템 내에서 AI 에이전트가 오라클로 기능하기 위해서는 모델이 시스템 프롬프트에 의해 지시받은 페르소나를 얼마나 확정적으로 받아들이고 제어 및 조향(Steering)될 수 있는가를 수학적으로 검증해야 한다. 엔지니어링 환경에서 페르소나는 단순한 챗봇의 텍스트 롤플레잉(Role-playing) 수준이 아니라, 모델의 지식 검색 경로, 문제 해결 방법론, 출력 포맷을 완전히 재구성하고 특정 도메인의 전문가로 국한시키는 운영 체제의 모드 스위치(Mode Switch)와 같다.</p>
<p>조향 가능성(Steerability)이란 시스템 프롬프트를 통해 모델의 결합 행동 분포(Joint Behavioral Distribution)를 고유의 베이스라인(Baseline) 행동에서 사용자가 목적하는 방향으로 얼마나 강력하고 신뢰성 있게 이동시킬 수 있는지를 측정하는 지표이다. 논문 <em>Evaluating the Prompt Steerability of Large Language Models</em>에서는 이를 정량화하기 위해 조향성 지수(Steerability Indices)를 제안한다. 이 프레임워크는 모델의 응답 확률을 베타 분포(Beta Distribution)로 모델링하고, 시스템 프롬프트가 주입되기 전과 후의 행동 분포 간의 차이를 바서슈타인 거리(Wasserstein Distance)와 같은 수학적 메트릭을 사용하여 측정한다. 이 수치가 높을수록 해당 모델은 시스템 프롬프트의 통제에 잘 순응하여 의도된 페르소나로 완벽하게 전환됨을 의미한다.</p>
<p>페르소나의 일관성을 섀넌 엔트로피(Shannon Entropy)로 수학화한 최신 연구인 논문 <em>Are Economists Always More Introverted? Analyzing Consistency in Persona-Assigned LLMs</em>의 모델링은 시스템 프롬프트의 무결성을 검증하는 데 필수적인 통찰을 제공한다. 특정 시스템 프롬프트 <span class="math math-inline">s</span>, 평가 카테고리 <span class="math math-inline">c</span>, 페르소나 카테고리 <span class="math math-inline">p</span>, 그리고 차원 <span class="math math-inline">d</span>에 대한 일관성 척도 엔트로피는 다음과 같이 계산된다.<br />
<span class="math math-display">
H(s, c, p, d) = - \sum_{k=1}^{K} P(k) \log P(k)
</span><br />
위 수식에서 <span class="math math-inline">K</span>는 페르소나 카테고리가 가질 수 있는 특성의 총 수(예를 들어 이진 성격 특성의 경우 2, 직업군의 경우 6 등)이며, <span class="math math-inline">P(k)</span>는 특성 <span class="math math-inline">k</span>로 분류된 응답의 확률을 나타낸다. 만약 시스템 프롬프트가 ’엄격하고 분석적인 시니어 데이터베이스 관리자’라는 페르소나와 그에 따른 규칙을 완벽하게 고정했다면, 모델은 어떤 질문에도 해당 특성을 유지한 응답만을 산출하게 되어 <span class="math math-inline">P(k)</span> 중 하나는 1에 가까워지고 나머지 확률은 0에 수렴하게 된다. 결과적으로 엔트로피 <span class="math math-inline">H</span>값은 0에 수렴한다. 반면, 시스템 프롬프트의 지배력이 약하여 모델이 비결정성에 휘둘려 무작위의 태도를 보이거나 기본 모델에 내재된 편향(Default Persona)으로 회귀하는 경우, 각 특성이 발현될 확률이 균등해지면서 엔트로피는 극대화된다.</p>
<p>소프트웨어 아키텍처에서 오라클 시스템은 반드시 이 엔트로피 <span class="math math-inline">H</span>가 0에 수렴하도록 설계되어야 한다. 최근 연구자들은 이를 달성하기 위해 메타 학습(Meta-Learning) 기반의 이중 시스템 프롬프트 최적화(Bilevel System Prompt Optimization, MetaSPO) 기법을 제안했다. 프롬프트-대-프롬프트(Prompt-to-Prompt) 관점에서의 이중 최적화는 다음과 같은 수학적 손실 함수를 최소화하는 방향으로 전개된다.<br />
<span class="math math-display">
\mathcal{L}(s,u) = \mathbb{E}_{(x,y)\sim D}[\ell(f_\theta(x \vert s,u), y)]
</span><br />
여기서 <span class="math math-inline">f_\theta</span>는 파라미터 <span class="math math-inline">\theta</span>를 가지는 거대 언어 모델, <span class="math math-inline">x</span>는 입력 환경 데이터, <span class="math math-inline">y</span>는 결정론적 정답지(Ground Truth), <span class="math math-inline">u</span>는 작업 종속적인 사용자 프롬프트(User Prompt), 그리고 <span class="math math-inline">s</span>는 작업 독립적인 시스템 프롬프트(System Prompt)이다. 하위 수준(Lower-level)에서는 개별 작업의 성능을 극대화하기 위해 <span class="math math-inline">u</span>를 최적화하지만, 상위 수준(Upper-level)의 최적화 목표는 어떠한 사용자 프롬프트 <span class="math math-inline">u</span>가 입력되더라도 일반화 가능한 최강의 시스템 프롬프트 <span class="math math-inline">s</span>를 학습하는 것이다.</p>
<p>MetaSPO 방법론은 다수의 소스 태스크(Source Tasks)에서 얻은 메타 지식을 활용하여 시스템 프롬프트를 튜닝함으로써, 전혀 학습에 포함되지 않았던 미지의 타겟 태스크(Unseen Target Tasks)가 주어지더라도 뛰어난 성능 향상을 이끌어낸다. 이는 수식적으로 사용자 프롬프트 <span class="math math-inline">u</span>가 극심한 분산을 보이며 변동하더라도, 메타 학습으로 최적화된 시스템 프롬프트 <span class="math math-inline">s</span>가 강력한 경계를 제공한다면, 전체 결합 모델 출력 <span class="math math-inline">f_\theta(x \vert s,u)</span>은 의도된 정답 <span class="math math-inline">y</span>에 대한 손실 <span class="math math-inline">\ell</span>을 최소화하는 방향으로 수렴할 수 있음을 증명한다. 즉, 시스템 프롬프트는 단순한 텍스트 지시가 아니라, 본질적으로 비결정적인 확률 모델에 통제된 제약을 부여하여 예측 불가능성을 억제하는 고도화된 수학적 바운더리(Boundary) 매커니즘으로 작동하는 것이다.</p>
<h3>0.4  소프트웨어 공학적 접근: 프롬프트웨어 엔지니어링(Promptware Engineering) 파이프라인</h3>
<p>단순히 엔트로피를 낮추는 이론적 증명을 넘어 실질적인 시스템 프롬프트를 통해 완전한 오라클을 구축하기 위해서는, 프롬프트 개발 과정을 일반적인 소프트웨어 공학 주기와 완벽히 동일하게 취급하는 프롬프트웨어 엔지니어링(Promptware Engineering) 방법론을 도입해야 한다. 현대의 AI 애플리케이션에서 프롬프트는 단순한 텍스트 파일이 아니라, 모델이라는 확률적 런타임 환경(Probabilistic Runtime Environment)에서 실행되는 소프트웨어 아티팩트 그 자체인 ’프롬프트웨어(Promptware)’로 정의된다.</p>
<p>프롬프트웨어 엔지니어링은 본질적으로 모호하고 문맥 의존적인 자연어 지시문을 확정적이고 평가 가능한 코드로 변환하기 위해 요구사항 분석, 모듈식 설계, 구현, 디버깅, 테스트, 형상 관리 등 고전적인 소프트웨어 개발 생명주기(SDLC)를 재해석하여 적용한다.</p>
<table><thead><tr><th><strong>프롬프트웨어 생명주기 (SDLC)</strong></th><th><strong>전통적 소프트웨어 공학의 대응 개념</strong></th><th><strong>프롬프트웨어 엔지니어링에서의 구현 방법론</strong></th></tr></thead><tbody>
<tr><td><strong>요구사항 공학 (Requirements)</strong></td><td>기능 명세서 및 비기능적 요구사항 도출</td><td>의도된 오라클의 페르소나 명시, 다중 목표(정확도 vs 창의성) 간의 트레이드오프 문서화, 도메인 지식의 한계 설정.</td></tr>
<tr><td><strong>설계 및 모듈화 (Design)</strong></td><td>아키텍처 패턴 설계 및 인터페이스 정의</td><td>제로샷(Zero-shot), 사고의 사슬(CoT), RAG 통합 등 프롬프팅 패턴의 인스턴스화. XML이나 JSON 스키마를 이용한 계층적 프롬프트 구조 설계.</td></tr>
<tr><td><strong>구현 (Implementation)</strong></td><td>코드 작성 및 컴파일</td><td>도메인 특화 언어(DSL)나 파이프라인 템플릿(예: LangChain, LlamaIndex)을 활용한 프롬프트 주입. 매개변수화(Parameterization)를 통한 동적 조립.</td></tr>
<tr><td><strong>테스트 및 디버깅 (Testing)</strong></td><td>단위 테스트, 통합 테스트, 회귀 테스트</td><td>메타모픽 테스트(Metamorphic Testing), LLM-as-a-Judge 평가, 적대적 탈옥(Jailbreak) 테스트. 환각(Hallucination) 억제율 및 응답 일관성 평가.</td></tr>
<tr><td><strong>배포 및 진화 (Evolution)</strong></td><td>CI/CD 파이프라인, 버전 관리(Git), 패치</td><td>시맨틱 버저닝(Semantic Versioning) 태그 관리, 모델 버전 업그레이드에 따른 프롬프트 드리프트(Drift) 감지 및 지속적 재조정.</td></tr>
</tbody></table>
<p>특히 테스트 및 디버깅 단계에서 프롬프트웨어의 신뢰성과 시스템 프롬프트의 지배력은 엄격한 정량적 메트릭을 통해 평가되어야 한다. 이 파이프라인 내에서 프롬프트의 결정론(Determinism)은 확률적으로 정의되며, 프롬프트웨어의 일관성은 아래의 공학적 분산(Variance) 지표 공식을 통해 계산된다.<br />
<span class="math math-display">
\sigma = 1 - \text{Var}_p(\text{model}(p, \text{seed}); \text{seed})
</span><br />
어떤 특정 시스템 프롬프트 <span class="math math-inline">p</span>와 파라미터 설정(예: 특정 시드값 고정)에 대해 모델이 동일한 입력에 대해 생성하는 응답의 분산이 0으로 수렴할 때, 조향성 계수 <span class="math math-inline">\sigma</span>는 1이 되며, 이는 해당 시스템 프롬프트가 모델을 완벽하게 결정론적 상태로 제어하고 있음을 증명한다. 반대로 프롬프트의 불안정성(Flakiness)은 <span class="math math-inline">F = 1 - \text{success ratio}</span> 로 측정되며, <span class="math math-inline">F</span> 값이 높다면 해당 시스템 프롬프트는 안전장치가 부실하거나 지시어의 해석적 모호성이 존재하여 오라클 테스트 자동화용으로 부적합하다는 의미가 된다.</p>
<p>이러한 수치적 평가를 기반으로 프롬프트웨어 파이프라인은 지속적인 반복 개선(Iterative Refinement) 루프를 돈다. 이 과정에서 엔지니어는 경험적 직관에 의존하는 것이 아니라 베이지안 최적화(Bayesian Optimization)나 빔 서치(Beam Search)와 같은 알고리즘을 사용하여 프롬프트의 엔트로피 점수를 최적화하고, 오라클 검증 시스템의 일관성을 극대화한다.</p>
<p><img src="./4.4.0.0.0%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8System%20Prompt%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%ED%8E%98%EB%A5%B4%EC%86%8C%EB%82%98%20%EB%B0%8F%20%EA%B7%9C%EC%B9%99%20%EA%B3%A0%EC%A0%95.assets/image-20260225232903756.jpg" alt="image-20260225232903756" /></p>
<h3>0.5  관심사의 분리(Separation of Concerns)와 계층적 시스템 프롬프트 설계 원칙</h3>
<p>결정론적 결과를 강제하는 고성능 시스템 프롬프트는 결코 자연어 에세이처럼 서술되어서는 안 되며, 마치 컴퓨터 코드를 작성하는 것과 같은 구조화된 아키텍처와 구문을 지녀야 한다. 전통적인 소프트웨어 공학에서 비즈니스 로직, 데이터 접근 계층, UI 렌더링을 철저히 분리하는 것처럼, 시스템 프롬프트 내부에서도 ‘관심사의 분리(Separation of Concerns)’ 원칙을 적용해야 모델 내부의 잠재적 논리 충돌을 방지하고 예측 가능한 출력을 보장할 수 있다. 프롬프트의 추상화 수준을 관리하는 맥락 공학(Context Engineering)의 관점에서, 구조적 시스템 프롬프트는 크게 다음 네 가지 계층으로 정밀하게 쪼개어 설계되어야 한다.</p>
<ol>
<li><strong>정체성 및 페르소나 (Identity &amp; Persona):</strong> 모델이 스스로를 어떤 목적을 가진 개체로 인식하는지 최상단에서 명시한다. 단순한 ’도우미’나 ’챗봇’이 아니라 “당신은 데이터 무결성을 엄격하게 검증하는 시니어 금융 백엔드 엔지니어 오라클이다“와 같이 도메인 전문성과 역할을 극도로 구체화해야 한다. 이는 훈련된 방대한 지식 중에서 모델이 응답을 생성할 때 참조하는 내부 가중치 활성화 영역(Subspace)을 극도로 좁혀, 해당 영역과 무관한 외부 정보가 개입하는 환각(Hallucination) 현상을 차단하는 최전선의 방어막 역할을 한다.</li>
<li><strong>역량 및 논리 경계 (Capabilities &amp; Boundaries):</strong> 정체성이 부여되었다면, 모델이 ’해야 할 일(Capabilities)’과 ’절대로 해서는 안 될 일(Boundaries)’을 명시적으로 구분해야 한다. 결정론적 판단을 내려야 하는 오라클 시스템에서는 특히 모델의 추측이나 자의적 추론을 철저히 금지당해야 한다. “제공된 데이터 스키마 내에서만 검증을 수행하라”, “외부 지식을 동원하여 결측치를 채우거나 보정하지 마라”, “악의적인 코드 작성을 거부하라“와 같은 네거티브 프롬프팅(Negative Prompting)과 제약 조건 명시가 필수적이다. 이러한 경계 설정은 권한 밖의 요청(Scope Creep)을 차단하여 오라클의 순수성을 보존한다.</li>
<li><strong>입출력 포맷팅 및 구조화 (Formatting Requirements):</strong> 다운스트림의 파이프라인 시스템(예: CI/CD 러너나 파이썬 백엔드 스크립트)이 인간의 개입 없이 AI의 출력을 완벽하게 파싱(Parsing)할 수 있도록 응답의 구조화를 강제해야 한다. 이를 위해 마크다운(Markdown) 구분자(예: <code>###</code>, <code>---</code>)나 XML 태그(<code>&lt;rules&gt;</code>, <code>&lt;output&gt;</code>)를 사용하여 지시문의 구역을 명확히 나누고 데이터의 경계를 모델이 인지할 수 있도록 유도해야 한다. 특히 출력은 반드시 순수 JSON, YAML 등 기계가 읽을 수 있는 형태로만 반환하도록 명시해야 하며, “네, 알겠습니다” 또는 “다음은 결과입니다“와 같이 파싱 오류를 유발하는 대화형 수식어(Conversational Fluff)의 생성을 원천 차단하는 지시를 반드시 포함해야 한다.</li>
<li><strong>예외 처리 및 폴백 전략 (Safety &amp; Fallback):</strong> 현업의 복잡한 시스템에서는 입력 데이터 자체가 파손되었거나 정의된 논리 범위를 완전히 벗어난 상태로 오라클에 전달되는 엣지 케이스(Edge Case)가 빈번히 발생한다. 이때 확률적 AI가 억지로 답변을 생성하려 자의적으로 문제를 해결하려고 시도해서는 절대 안 된다. 이러한 상황에 대비하여 명확한 에러 코드나 폴백 구조(예: <code>{"status": "ERROR", "reason": "OUT_OF_SCOPE"}</code>)를 반환하도록 시스템 프롬프트 내에 사전 정의해 두어야 한다. 이는 시스템의 장애가 조용히 넘어가지 않고 명시적으로 로깅되어 인간 엔지니어에게 알림이 가도록 만드는 핵심적인 안정성 장치이다.</li>
</ol>
<p>이러한 모듈식 계층화 구조는 시스템 프롬프트를 레고 블록처럼 관리할 수 있게 해준다. 공통된 안전 규칙이나 페르소나 설정은 시스템 전반에서 재사용하고, 지역(Region)이나 특정 검증 로직에 맞춘 모듈만을 동적으로 교체하여 런타임에 조합하는 방식으로 시스템의 확장성과 유지보수성을 극대화할 수 있다.</p>
<h3>0.6  결정론적 함정(Deterministic Trap)과 프롬프트 캐싱 메커니즘의 물리적 한계</h3>
<p>시스템 프롬프트를 활용하여 오라클을 구축할 때 실무 엔지니어들이 가장 빈번하게 겪으면서도 원인을 파악하기 힘든 패러독스는 이른바 ’결정론적 함정(Deterministic Trap)’이다. 최근의 상용 API 서비스 환경이나 자체 호스팅 모델들은 막대한 컴퓨팅 비용 최적화와 레이턴시 감소를 위해 프롬프트 캐싱(Prompt Caching) 메커니즘을 적극 활용한다. 이는 수천 토큰에 달하는 방대한 시스템 프롬프트가 매번 다시 계산되는 것을 막기 위해, 초기 입력의 연산 결과(키-값 상태, KV Cache)를 저장하여 단기 기억 장치에 영구적으로 로드하는 기술이다.</p>
<p>일반적으로 소프트웨어 엔지니어들은 코딩이나 테스트 생성 작업에서 모델의 무작위성을 배제하고 절대적인 결정론을 확보하기 위해 모델 파라미터 중 온도(Temperature)를 0으로 설정한다. 이론상 온도가 0이면 모델은 확률 공간에서 항상 가장 가능성 높은 토큰만을 단일 궤적으로 선택해야 한다. 그러나 최신 거대 모델 아키텍처(예: 전문가 혼합 모델, MoE)와 분산 GPU 컴퓨팅 환경에서는 이 가정이 완전히 무너진다. 부동소수점 연산(Floating-point Arithmetic)은 다중 스레드 스케줄링 순서에 따라 비결합적(Non-associative) 특성을 띠므로, 연산의 순서가 미세하게 변경될 때마다 미세한 반올림 오차가 발생한다. 두 토큰의 확률이 거의 동일한 지점에서는 이 현미경적 오차가 토큰 선택의 역전을 유발하여, 온도가 0임에도 불구하고 완전히 동일한 텍스트 출력이 보장되지 않는 하드웨어적 비결정성이 발생한다.</p>
<p>여기에 프롬프트 캐싱이 결합되면 더 치명적인 문제가 발생한다. 캐시된 시스템 프롬프트 환경에서 모델이 한 번 잘못된 추론 경로(Local Minimum)에 빠져 불완전한 코드나 편향된 결과를 출력했을 경우, 온도(Temperature)가 0인 상태에서는 모델이 그 “나쁜 주사위 굴림(Bad Roll)“의 결과를 고정된 것으로 인식하여 동일한 잘못된 궤적을 무한히 반복하는 악순환에 빠진다. 모델이 한 번 환각에 빠지면 시스템 프롬프트가 강제하는 강력한 통제력 때문에 오히려 그 환각에서 빠져나오지 못하는 역설이 발생하는 것이다. 단순히 API를 재호출하거나 재시도(Retry) 로직을 돌린다고 해서 결과가 달라지지 않는다.</p>
<p>이러한 결정론적 함정을 타파하기 위해서는 자연어 처리의 나비 효과(Butterfly Effect)를 엔지니어링 적으로 활용해야 한다. 모델이 오답 궤적에 갇혔다고 판단될 때, 시스템 프롬프트 내의 부가적인 지시어나 쓸모없는 주석, 심지어는 보이지 않는 공백이나 줄바꿈 하나를 미세하게 변형(Perturbation)하여 API를 호출해야 한다. 이 의도적이고 미세한 변형은 기존의 KV 캐시를 강제로 무효화시키고 초기 토큰의 확률 분포 공간을 물리적으로 흔들어 주어, 모델이 기존의 실패한 연산 경로를 강제로 폐기하고 확률 공간 내에서 완전히 새로운 연산 궤적을 그리도록 유도한다. 궁극적으로 이는 모델이 국소적 최적해의 수렁에서 벗어나 올바른 정답(Ground Truth) 경로를 재탐색하도록 돕는 필수적인 런타임 유지보수 전략이다.</p>
<h3>0.7  실전 예제: 다중 에이전트 기반 오라클과 시스템 프롬프트 체인 구성</h3>
<p>단일한 LLM 호출만으로는 복잡한 비즈니스 로직을 완벽하게 검증하는 오라클을 구축하기 어렵다. 이에 따라 최근의 고도화된 소프트웨어 테스트 자동화 프레임워크들은 서로 다른 페르소나와 극도로 특화된 시스템 프롬프트를 부여받은 다중 에이전트(Multi-Agent) 체인을 구성하여 합의에 기반한 확정적 결과를 도출한다.</p>
<p>예를 들어, 단위 테스트를 합성하고 검증하는 <em>CANDOR</em> 프레임워크나 비회귀 테스트 오라클을 생성하는 <em>Nexus</em> 프레임워크는 실행 기반(Execution-Grounded)의 다중 에이전트 패널 구조를 채택하고 있다. 복잡한 금융 코드베이스 로직을 검증하기 위해 4개의 특화된 에이전트 패널을 구성한다고 가정해 보자. 각 에이전트는 서로 충돌하거나 보완적인 시스템 프롬프트를 통해 다음과 같은 역할을 수행하도록 강제받는다.</p>
<ol>
<li><strong>Edge Case Explorer (경계 탐색자):</strong> 오로지 코드의 맹점과 극단적 경계값(Boundary Values), 널(Null) 예외 상황만을 주입하여 시스템을 파괴하려는 페르소나를 강제받는다.</li>
<li><strong>Security Analyzer (보안 분석가):</strong> SQL 인젝션, 버퍼 오버플로우 등 보안 취약점 패턴만을 전문적으로 스캐닝하도록 지시받은 엄격한 시스템 프롬프트를 기반으로 동작한다.</li>
<li><strong>Logic Validator (로직 검증자):</strong> 정해진 요구사항 명세서에 기반하여 핵심 비즈니스 로직의 분기문 정합성만을 검증하는 오라클 페르소나를 적용받는다.</li>
<li><strong>Consensus Judge (합의 재판관):</strong> 앞선 3개 에이전트의 출력을 취합하고, 상호 모순을 분석하여 다수결 및 합의 알고리즘에 기반해 최종 판단(Pass/Fail)을 내리는 최고위 시스템 프롬프트를 적용받는다.</li>
</ol>
<p>이 과정에서 각 에이전트는 내부적으로 사고의 사슬(Chain-of-Thought, CoT)과 최소-최대(Least-to-Most) 분해 전략을 구사하여 문제를 해결하지만 , 모든 행동의 경계는 상위 시스템 프롬프트가 설정한 규칙에 의해 철저히 통제된다. 만약 특정 에이전트의 출력이 시스템 프롬프트가 강제한 형식(예: 엄격한 JSON 스키마)을 위반할 경우, 프롬프트웨어 파이프라인은 이를 실행 샌드박스 단계에서 런타임 에러로 감지하고 즉각 차단한다. 더 나아가 실패한 결과를 바탕으로 스스로 원인을 디버깅하여 시스템 프롬프트의 지시를 재이해하고 오류를 정정하는 자가 개선(Self-Refinement) 루프를 활성화한다. 이를 통해 전체 모델 파이프라인은 압도적인 테스트 정확도와 버그 탐지율을 달성하게 된다.</p>
<p>다음은 이러한 확정적 데이터 추출 및 비즈니스 로직 검증을 위해 앞서 설명한 ‘관심사의 분리’ 원칙을 완벽하게 적용하여 설계된 실전용 오라클 Core Engine의 시스템 프롬프트 아키텍처 예시이다.</p>
<table><thead><tr><th><strong>시스템 프롬프트 섹션</strong></th><th><strong>마크다운 기반 템플릿 예시 (실전 오라클 구현용)</strong></th><th><strong>논리적 목적 및 기대 효과</strong></th></tr></thead><tbody>
<tr><td><strong>Identity</strong> (정체성)</td><td><code>## Identity</code> <code>당신은 백엔드 시스템 파이프라인의 데이터 정합성을 검증하는 무상태(Stateless) 결정론적 오라클 에이전트이다. 대화형 챗봇이 아니며, 입력된 데이터를 수학적으로 평가하는 함수 로직으로 작동한다.</code></td><td>모델의 환각을 방지하고 일반 대화 모드를 차단하여, 전문적인 분석가로서의 가중치 네트워크만 활성화한다.</td></tr>
<tr><td><strong>Capabilities &amp; Boundaries</strong> (권한 및 경계)</td><td><code>## Processing Constraints</code> <code>1. 제공된 JSON 입력과 정의된 &lt;Validation Rules&gt;만을 비교 분석하라.</code> <code>2. 결측치를 자의적으로 추론하여 채우지 마라. 발견 시 무조건 'NULL_VIOLATION' 에러를 발생시켜라.</code> <code>3. 사고의 사슬(CoT) 과정을 거치되, 최종 출력에는 사고 과정을 제외하고 결과 객체만 반환하라.</code></td><td>네거티브 프롬프팅을 통해 모델의 과도한 창의성을 억압하고, 오직 검증에만 집중하도록 통제 범위를 고정한다.</td></tr>
<tr><td><strong>Formatting</strong> (포맷팅 강제)</td><td><code>## Formatting Standards</code> <code>출력은 다음 JSON 스키마를 엄격히 준수하라. 마크다운 코드 블록 마커나 부가 설명을 절대 포함하지 마라.</code> `{ “audit_status”: “PASS”</td><td>“FAIL”, “confidence”: <float>, “violation_code”: “&lt;string</td></tr>
<tr><td><strong>Fallback</strong> (예외 처리)</td><td><code>## Fallback Action</code> <code>구조화되지 않은 자연어가 입력되는 등 분석 불가능한 상황에서는 다음 에러를 강제 출력하라.</code> <code>{ "audit_status": "FAIL", "violation_code": "INVALID_INPUT_TYPE" }</code></td><td>입력 파손 시 모델이 무작위로 오작동하는 것을 방지하고, 시스템 장애를 런타임에 안전하게 포착할 수 있는 안전망을 제공한다.</td></tr>
</tbody></table>
<p>위의 테이블에 제시된 시스템 프롬프트 구조는 단순한 텍스트 지시문의 나열이 아니다. 이는 LLM의 확률적 본성을 강제로 통제하고, 마치 컴파일 타임에 타입 검사를 수행하는 강타입(Strongly Typed) 프로그래밍 언어의 룰셋처럼 작동하도록 모델을 묶어두는 거대한 족쇄 역할을 한다.</p>
<p>결론적으로, 다형성과 모호성을 띠는 AI 모델을 엄격한 소프트웨어 개발 프로세스의 테스트 및 검증 오라클로 편입시키기 위한 여정은 “어떻게 프롬프트를 창의적으로 잘 쓸 것인가“를 고민하는 문과적 접근이 아니다. 이는 철저하게 “어떻게 고도로 구조화된 시스템 프롬프트를 통해 확률적 모델의 불확실성을 기계적 결정론으로 격리하고, 잠재 공간을 억압할 것인가“를 풀어내는 가장 극단적인 소프트웨어 공학적 과제이다. 이중 최적화를 거쳐 정교하게 다듬어지고 버전 관리되는 시스템 프롬프트 아키텍처야말로, 현대 AI 기반 소프트웨어 개발론의 비결정성을 통제하고 시스템의 신뢰성을 지탱하는 가장 견고하고 핵심적인 주춧돌이 될 것이다.</p>
<h2>1. 참고 자료</h2>
<ol>
<li>The Importance of System Prompts in Shaping AI Agent Responses, https://www.getmaxim.ai/articles/the-importance-of-system-prompts-in-shaping-ai-agent-responses/</li>
<li>Prompt Engineering for Developers: The Ultimate Guide … - Medium, https://medium.com/@metafluxtech/prompt-engineering-for-developers-the-ultimate-guide-with-examples-b38efa7fc6ad</li>
<li>Guide to Writing System Prompts: The Hidden Force Behind Every, https://saharaai.com/blog/writing-ai-system-prompts</li>
<li>System Prompts as a Mechanism of Bias in Large Language Models, https://arxiv.org/html/2505.21091v2</li>
<li>System Prompt vs. User Prompt : r/LocalLLaMA - Reddit, https://www.reddit.com/r/LocalLLaMA/comments/1k88k0h/system_prompt_vs_user_prompt/</li>
<li>Diagnosing Bias and Instability in LLM Evaluation: A Scalable, https://www.mdpi.com/2078-2489/16/8/652</li>
<li>What is Context Engineering? Architecting Reliable AI | Elastic, https://www.elastic.co/what-is/context-engineering</li>
<li>The “system” role - How it influences the chat behavior - API, https://community.openai.com/t/the-system-role-how-it-influences-the-chat-behavior/87353</li>
<li>Leveraging System Prompt Attention for Explainable Defense … - arXiv, https://arxiv.org/html/2504.12321v1</li>
<li>Toward universal steering and monitoring of AI models - arXiv, https://arxiv.org/html/2502.03708v2</li>
<li>An Empirical Study of the Non-Determinism of ChatGPT in Code, https://www.researchgate.net/publication/384371697_An_Empirical_Study_of_the_Non-determinism_of_ChatGPT_in_Code_Generation</li>
<li>SysBench: Can Large Language Models Follow System Messages?, https://arxiv.org/html/2408.10943v1</li>
<li>Understanding Ghost Attention in LLaMa 2 | Towards Data Science, https://towardsdatascience.com/understanding-ghost-attention-in-llama-2-dba624901586/</li>
<li>Consistently Simulating Human Personas with Multi-Turn, https://openreview.net/forum?id=A0T3piHiis</li>
<li>Beyond the System Prompt: Engineering Robust AI Personas, https://medium.com/@n0x/beyond-the-system-prompt-engineering-robust-ai-personas-a495e41575e4</li>
<li>LLAMA 2 Paper and Model Deep Dive — The GenAI Guidebook, https://ravinkumar.com/GenAiGuidebook/deepdive/llama2.html</li>
<li>(PDF) Llama 2: Open Foundation and Fine-Tuned Chat Models, https://www.researchgate.net/publication/372445526_Llama_2_Open_Foundation_and_Fine-Tuned_Chat_Models</li>
<li>How well does it adhere to the system prompt? The base Llama, https://news.ycombinator.com/item?id=36988090</li>
<li>Prompt engineering using Llama 2 on watsonx.ai best practices, https://developer.ibm.com/tutorials/awb-prompt-engineering-llama-2/</li>
<li>Prompting for Business using Llama 2 | by Jerry Cuomo | Medium, https://medium.com/@JerryCuomo/prompting-for-business-using-llama-2-661f0272f761</li>
<li>Evaluating the Prompt Steerability of Large Language Models - arXiv, https://arxiv.org/html/2411.12405v1</li>
<li>Evaluating the Prompt Steerability of Large Language Models, https://aclanthology.org/2025.naacl-long.400.pdf</li>
<li>[Literature Review] Evaluating the Prompt Steerability of … - Moonlight, https://www.themoonlight.io/en/review/evaluating-the-prompt-steerability-of-large-language-models</li>
<li>[Literature Review] Are Economists Always More Introverted, https://www.themoonlight.io/en/review/are-economists-always-more-introverted-analyzing-consistency-in-persona-assigned-llms</li>
<li>System Prompt Optimization with Meta-Learning - ResearchGate, https://www.researchgate.net/publication/391776522_System_Prompt_Optimization_with_Meta-Learning</li>
<li>System Prompt Optimization with Meta-Learning - arXiv, https://arxiv.org/html/2505.09666v1</li>
<li>Prompt-to-Prompt Method Overview - Emergent Mind, https://www.emergentmind.com/topics/prompt-to-prompt-method</li>
<li>Prompt Engineering with LLMs - Emergent Mind, https://www.emergentmind.com/topics/prompt-engineering-with-language-models</li>
<li>Promptware Engineering - Emergent Mind, https://www.emergentmind.com/topics/promptware-engineering</li>
<li>LLM-Integrated Software Systems - Emergent Mind, https://www.emergentmind.com/topics/llm-integrated-software</li>
<li>Jie M. Zhang’s research works | The London College and other places, https://www.researchgate.net/scientific-contributions/Jie-M-Zhang-2240577286</li>
<li>Prompt Engineering Pipeline - Emergent Mind, https://www.emergentmind.com/topics/prompt-engineering-pipeline</li>
<li>Advanced Prompt Engineering Techniques: Examples &amp; Best, https://www.patronus.ai/llm-testing/advanced-prompt-engineering-techniques</li>
<li>The Art of Writing Great System Prompts | by Saurabh Singh, https://blog.stackademic.com/the-art-of-writing-great-system-prompts-abb22f8b8f37</li>
<li>What Is Prompt Engineering? The Ultimate Beginner’s Guide - Medium, https://medium.com/@rohithlyadalla/what-is-prompt-engineering-the-ultimate-beginners-guide-9d474e85291f</li>
<li>What is prompt engineering? - GitHub, https://github.com/resources/articles/what-is-prompt-engineering</li>
<li>The Hidden Behavior of LLMs - Prompt Caching and Determinism, https://community.sap.com/t5/technology-blog-posts-by-sap/the-hidden-behavior-of-llms-prompt-caching-and-determinism/ba-p/14285663</li>
<li>How to make AI Agents deterministic in their responses ? : r/AI_Agents, https://www.reddit.com/r/AI_Agents/comments/1iqfn9y/how_to_make_ai_agents_deterministic_in_their/</li>
<li>Multi-Agent LLMs for End-to-End Test Generation with Accurate, https://arxiv.org/html/2506.02943v3</li>
<li>Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis, https://www.researchgate.net/publication/397087653_Nexus_Execution-Grounded_Multi-Agent_Test_Oracle_Synthesis</li>
<li>Ultimate Guide to Prompt Engineering | by Sunil Rao - Towards AI, https://pub.towardsai.net/ultimate-guide-to-prompt-engineering-940d463ba0e5</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>