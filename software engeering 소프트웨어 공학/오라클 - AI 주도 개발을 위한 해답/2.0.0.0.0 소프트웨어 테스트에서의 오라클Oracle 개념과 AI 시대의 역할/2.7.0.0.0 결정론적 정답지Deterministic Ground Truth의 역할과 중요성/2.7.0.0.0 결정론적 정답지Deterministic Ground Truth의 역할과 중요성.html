<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2.7 결정론적 정답지(Deterministic Ground Truth)의 역할과 중요성</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2.7 결정론적 정답지(Deterministic Ground Truth)의 역할과 중요성</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 2. 소프트웨어 테스트에서의 오라클(Oracle) 개념과 AI 시대의 역할</a> / <a href="index.html">2.7 결정론적 정답지(Deterministic Ground Truth)의 역할과 중요성</a> / <span>2.7 결정론적 정답지(Deterministic Ground Truth)의 역할과 중요성</span></nav>
                </div>
            </header>
            <article>
                <h1>2.7 결정론적 정답지(Deterministic Ground Truth)의 역할과 중요성</h1>
<h2>1.  서론: 확률적 유동성과 엔지니어링 불변성의 충돌</h2>
<p>인공지능, 특히 제미나이(Gemini)와 같은 대규모 언어 모델(LLM)을 기반으로 한 현대적 소프트웨어 시스템의 구축 과정은 근본적으로 이질적인 두 세계의 충돌을 내포하고 있습니다. 한쪽에는 확률적(Probabilistic)이고 유동적이며 창의적인 생성형 AI의 세계가 존재합니다. 다른 한쪽에는 결정론적(Deterministic)이고 엄격하며 반복 가능한 전통적 엔지니어링의 세계가 버티고 있습니다. 우리가 서적을 집필하거나, 코드를 생성하거나, 기업의 데이터를 분석할 때 기대하는 결과물은 대부분 단 하나의 정확한 답, 즉 ’정답(Ground Truth)’이 명확히 존재하는 영역에 속합니다. 그러나 LLM은 본질적으로 다음 토큰을 예측하는 통계적 모델이며, 이는 본질적으로 불확실성을 내포하고 있습니다. 이러한 확률적 속성은 창의적인 글쓰기나 브레인스토밍에는 유리하게 작용하지만, 정확성이 필수적인 엔터프라이즈 환경이나 미션 크리티컬 시스템에서는 치명적인 ’환각(Hallucination)’이나 ’비결정론적 오류’를 유발하는 원인이 됩니다.</p>
<p>따라서 에이전트(Agentic) 워크플로우와 복잡한 비즈니스 로직이 결합된 고도화된 AI 시스템 개발에 있어 ’결정론적 정답지(Deterministic Ground Truth)’의 확보는 단순한 테스트 데이터 구축의 차원을 넘어섭니다. 그것은 통제 불가능한 확률 분포를 엔지니어링 가능한 신뢰의 영역으로 끌어들이는 유일한 닻(Anchor)이자, 시스템의 무결성을 보장하는 최후의 보루입니다. 본 장에서는 LLM이 가진 확률적 본능을 통제하고, 엔터프라이즈급 신뢰성을 확보하기 위해 결정론적 검증 메커니즘이 어떻게 설계되어야 하는지, 그리고 그것이 전체 시스템 아키텍처에서 차지하는 핵심적인 위상을 심도 있게 분석합니다.</p>
<p><img src="./2.7.0.0.0%20%EA%B2%B0%EC%A0%95%EB%A1%A0%EC%A0%81%20%EC%A0%95%EB%8B%B5%EC%A7%80Deterministic%20Ground%20Truth%EC%9D%98%20%EC%97%AD%ED%95%A0%EA%B3%BC%20%EC%A4%91%EC%9A%94%EC%84%B1.assets/image-20260217190736915.jpg" alt="image-20260217190736915" /></p>
<h3>1.1  확률론적 AI와 결정론적 기대의 괴리</h3>
<p>확률론적 AI 모델은 불확실성을 모델링하고 가능성에 기반한 결과를 제공합니다. 이는 동일한 입력에 대해 항상 하나의 확정적인 답변을 제공하지 않고, 확률 분포에 따라 다양한 가능성의 범위를 제시한다는 것을 의미합니다. 이러한 특성은 자연어 처리, 이미지 인식, 창작 활동과 같이 모호성이 내재된 복잡한 환경에서는 강력한 성능을 발휘합니다. 반면, 결정론적 시스템은 규칙 기반(Rule-based)으로 설계되어 특정 입력에 대해 변동성 없이 예측 가능한 단일 출력을 산출합니다. 금융 거래 처리, 산업 자동화, 규정 준수 확인과 같이 반복성과 일관성이 핵심인 분야에서는 결정론적 접근이 필수적입니다.</p>
<p>문제는 현대의 사용자들이 LLM과 같은 확률적 모델에게 결정론적 정확성을 요구할 때 발생합니다. 예를 들어, 사용자가 “내 계좌의 이자율을 계산해 줘“라고 물었을 때, LLM이 문맥적으로 그럴듯해 보이는 숫자를 ’생성’해내는 것은 허용되지 않습니다. 여기서는 오직 회사의 규정과 수식에 따른 정확한 값만이 정답입니다. 이 지점에서 확률적 추론 능력과 결정론적 검증 시스템의 결합이 요구되며, 그 결합을 매개하는 것이 바로 결정론적 정답지입니다.</p>
<h2>2.  오라클 문제(The Oracle Problem)의 현대적 재해석</h2>
<p>소프트웨어 테스팅 분야에서 오랜 역사를 가진 ’오라클 문제(The Oracle Problem)’는 AI 시대에 접어들며 더욱 복잡하고 중요한 의미를 갖게 되었습니다.</p>
<h3>2.1  전통적 오라클 문제와 AI의 도전</h3>
<p>오라클 문제는 주어진 입력에 대해 시스템의 실행 결과가 올바른지 판단하는 메커니즘, 즉 ’오라클’을 확보하는 것의 어려움을 지칭합니다. 전통적인 소프트웨어 공학에서는 입력값에 대한 기대 출력값이 명세서(Specification)에 의해 비교적 명확하게 정의되었습니다. 예를 들어 <code>2 + 2</code> 함수의 결과는 언제나 <code>4</code>여야 하며, 이를 검증하는 테스트 코드를 작성하는 것은 간단합니다.</p>
<p>그러나 제미나이와 같은 생성형 AI는 ‘비결정론적(Non-deterministic)’ 특성을 가집니다. 동일한 프롬프트에 대해 매번 다른 텍스트 구조, 코드 스타일, 데이터 포맷을 생성할 수 있습니다. “이 코드가 안전한가?”, “이 요약문이 원문의 핵심을 누락하지 않았는가?“와 같은 질문에 대한 답은 단 하나의 문자열로 정의되지 않습니다. 이로 인해 기존의 단순한 문자열 매칭 방식의 테스트 오라클은 무용지물이 되기 쉽습니다. 정답을 정의하기 위해 인간이 일일이 개입하는 것은 비용 효율적이지 않으며, 확장성(Scalability) 문제를 야기합니다.</p>
<h3>2.2  결정론적 정답지의 정의와 속성</h3>
<p>이러한 맥락에서 **결정론적 정답지(Deterministic Ground Truth)**란, AI의 출력을 평가하거나 제어할 때 인간의 주관적 감각(Vibe Check)이나 또 다른 AI의 확률적 평가(LLM-as-a-Judge)에 의존하지 않고, <strong>수학적, 논리적, 프로그래밍적으로 명백하게 참/거짓을 판별할 수 있는 불변의 기준</strong>을 의미합니다. 이는 다음과 같은 핵심 속성을 가져야 합니다:</p>
<table><thead><tr><th><strong>속성 (Attribute)</strong></th><th><strong>설명 (Description)</strong></th><th><strong>AI 시스템에서의 역할</strong></th></tr></thead><tbody>
<tr><td><strong>재현성 (Reproducibility)</strong></td><td>언제, 어디서, 누가 검증하더라도 동일한 결과를 보장함.</td><td>AI 모델의 버전이 바뀌어도 평가 기준의 일관성을 유지하게 함.</td></tr>
<tr><td><strong>검증 가능성 (Verifiability)</strong></td><td>모호함 없이 기계적으로 Pass/Fail을 이분법적으로 나눌 수 있음.</td><td>자동화된 테스트 파이프라인(CI/CD) 구축의 기반이 됨.</td></tr>
<tr><td><strong>비타협성 (Inflexibility)</strong></td><td>문맥이나 상황에 따라 해석이 달라지지 않는 절대적인 기준임.</td><td>규제 준수(Compliance) 및 보안 감사(Audit)의 근거가 됨.</td></tr>
<tr><td><strong>추적 가능성 (Traceability)</strong></td><td>결정의 근거가 되는 규칙이나 데이터 소스로 역추적이 가능함.</td><td>AI의 ‘설명 가능성’ 부족을 보완하고 책임 소재를 명확히 함.</td></tr>
</tbody></table>
<h3>2.3  정답지의 계층 구조: 통사론에서 의미론까지</h3>
<p>결정론적 정답지는 단일한 형태가 아니며, 검증의 깊이에 따라 다음과 같은 계층으로 나뉩니다:</p>
<ol>
<li><strong>구문론적 정답(Syntactic Ground Truth):</strong> 생성된 결과물이 시스템이 약속한 형식을 준수하는가? (예: 유효한 JSON 스키마인가? 코드가 문법 에러 없이 컴파일되는가?) 이는 가장 기초적인 단계의 결정론적 검증입니다.</li>
<li><strong>실행적 정답(Execution Ground Truth):</strong> 생성된 코드가 실행 환경에서 예외 없이 돌아가는가? 그리고 사전에 정의된 테스트 케이스를 통과하여 기대한 상태 변화를 일으키는가? 이는 코드 생성 AI 평가의 핵심입니다.</li>
<li><strong>의미론적 정답(Semantic Ground Truth):</strong> (Text-to-SQL 등에서) 생성된 쿼리문 자체는 정답과 다를지라도, 그 쿼리가 데이터베이스에서 추출해낸 결과 집합(Result Set)이 의도한 데이터와 정확히 일치하는가? 이는 결과 중심의 실용적 검증입니다.</li>
</ol>
<h2>3.  구조적 강제: JSON 스키마와 데이터 무결성</h2>
<p>LLM을 엔터프라이즈 시스템에 통합할 때 가장 먼저 마주하는 결정론적 정답지의 형태는 **데이터 구조(Schema)**입니다. AI 에이전트가 외부 도구를 호출하거나 백엔드 API와 통신하기 위해서는 자연어 텍스트가 아닌 엄격하게 구조화된 데이터(JSON, XML 등)가 필요합니다. 이때 JSON 스키마(JSON Schema)는 AI의 확률적 출력을 시스템이 이해할 수 있는 결정론적 입력으로 변환하는 강력한 필터이자 1차적인 정답지 역할을 수행합니다.</p>
<h3>3.1  스키마 유효성 검사(Schema Validation)의 메커니즘</h3>
<p>단순히 프롬프트 엔지니어링을 통해 “JSON 형식을 지켜달라“고 요청하는 것만으로는 충분하지 않습니다. 최신 LLM 프레임워크들은 ‘제약된 디코딩(Constrained Decoding)’ 기법이나 사후 검증 로직을 통해 출력이 특정 스키마를 100% 준수하도록 기술적으로 강제합니다.</p>
<ul>
<li><strong>타입 강제(Type Enforcement):</strong> 스키마에서 특정 필드가 반드시 <code>Integer</code>여야 한다고 정의되어 있다면, 모델이 <code>String</code> 형태로 “3개“라고 출력하는 것을 허용하지 않습니다. 시스템은 이를 <code>3</code>이라는 숫자로 변환하거나, 변환이 불가능할 경우 오류를 발생시켜 재생성을 요청합니다.</li>
<li><strong>필수 필드 검증(Required Fields):</strong> 비즈니스 로직 수행에 필수적인 <code>user_id</code>, <code>transaction_amount</code>, <code>currency</code> 등의 필드가 누락되었는지 기계적으로 검증합니다. 하나라도 누락되면 프로세스는 진행되지 않습니다.</li>
<li><strong>열거형 제약(Enum Constraints):</strong> 카테고리 분류나 상태 값 지정과 같은 작업에서 모델이 창의적인 단어를 만들어내는 것을 방지합니다. 사전 정의된 `` 중 하나만 선택하도록 강제함으로써 데이터의 정합성을 보장합니다.</li>
</ul>
<p>이 과정에서 스키마 유효성 검사기(Schema Validator)는 AI 출력의 품질을 판단하는 <strong>1차 오라클</strong>이 됩니다. 스키마를 통과하지 못한 출력은 비즈니스 로직으로 진입조차 시키지 않음으로써 시스템 전체의 안정성을 확보하는 방화벽 역할을 수행합니다.</p>
<p><img src="./2.7.0.0.0%20%EA%B2%B0%EC%A0%95%EB%A1%A0%EC%A0%81%20%EC%A0%95%EB%8B%B5%EC%A7%80Deterministic%20Ground%20Truth%EC%9D%98%20%EC%97%AD%ED%95%A0%EA%B3%BC%20%EC%A4%91%EC%9A%94%EC%84%B1.assets/image-20260217190803611.jpg" alt="image-20260217190803611" /></p>
<h3>3.2  환각 방지 및 보안 강화</h3>
<p>JSON 스키마 검증은 단순히 형식을 맞추는 것을 넘어, 보안 측면에서도 중요한 역할을 합니다. 특히 OpenAI의 함수 호출(Function Calling)이나 기타 에이전트 프레임워크에서 모델이 존재하지 않는 인자를 만들어내거나(Hallucination), 악의적인 명령을 주입하려는 시도를 스키마 수준에서 차단할 수 있습니다. 예를 들어, SQL 쿼리를 생성하는 도구에서 테이블 이름이나 컬럼 이름을 스키마로 제한함으로써, 모델이 허가되지 않은 데이터에 접근하는 쿼리를 작성하는 것을 원천적으로 봉쇄할 수 있습니다. 이는 AI 보안의 ’최소 권한 원칙(Principle of Least Privilege)’을 구현하는 결정론적 수단이 됩니다.</p>
<h2>4.  실행의 정확성: Text-to-SQL과 코드 생성의 정답지</h2>
<p>자연어를 SQL 쿼리나 프로그래밍 코드로 변환하는 작업(Code Generation)은 결정론적 정답지가 가장 강력하게 요구되며, 동시에 가장 효과적으로 작동하는 영역입니다. 코드의 세계에서는 문장 표현의 유사성이 아닌, 오직 ’실행 결과’만이 진실을 말해줍니다.</p>
<h3>4.1  문자열 매칭의 한계와 실행 정확도(Execution Accuracy)</h3>
<p>초기의 Text-to-SQL 연구들은 생성된 SQL 쿼리가 정답 쿼리와 텍스트적으로 얼마나 유사한지(Exact String Match, BLEU 점수 등)를 측정하는 데 집중했습니다. 그러나 SQL과 같은 선언형 언어는 동일한 결과 집합을 도출하는 다양한 작성 방식이 존재합니다. 예를 들어 <code>JOIN</code>의 순서를 바꾸거나, 서브쿼리를 사용하는 대신 조인을 사용하는 경우 쿼리문의 형태는 완전히 다르지만 기능적으로는 동일할 수 있습니다. 따라서 문자열 매칭 방식은 기능적으로 올바른 쿼리를 오답으로 처리하는 위음성(False Negative) 문제를 빈번하게 야기합니다.</p>
<p>현대의 Text-to-SQL 평가, 예를 들어 Spider나 BIRD 벤치마크에서는 **실행 정확도(Execution Accuracy, EA)**를 표준 지표로 채택하고 있습니다. 실행 정확도의 원리는 다음과 같습니다:</p>
<ol>
<li>정답 쿼리(Ground Truth Query)와 AI가 생성한 쿼리를 준비된 데이터베이스 환경(Sandbox)에서 각각 실행합니다.</li>
<li>두 쿼리가 반환한 **결과 테이블(Result Set)**의 행(Row)과 열(Column), 그리고 값(Value)들이 정확히 일치하는지를 비교합니다.</li>
<li>순서가 중요하지 않은 경우(ORDER BY가 없는 경우) 집합(Set)으로서의 일치 여부를 확인합니다.</li>
</ol>
<p>이 방식에서 ‘데이터베이스 엔진’ 자체가 결정론적 오라클이 됩니다. AI가 아무리 문법적으로 완벽하고 그럴듯한 쿼리를 작성하더라도, 실제 데이터베이스가 실행 오류를 반환하거나 엉뚱한 데이터를 가져온다면 가차 없이 오답으로 처리됩니다. 이는 AI 모델이 데이터 스키마와 비즈니스 질문의 의도를 정확히 파악했는지를 검증하는 가장 확실한 방법입니다.</p>
<h3>4.2  컴파일러와 단위 테스트(Unit Test)를 통한 검증</h3>
<p>일반적인 소프트웨어 코드 생성(Python, Java 등)에서도 유사한 원리가 적용됩니다. **컴파일러(Compiler)**와 **테스트 러너(Test Runner)**는 인간의 개입 없이 수천 개의 AI 생성 코드를 즉시 검증할 수 있는 강력한 자동화 도구입니다.</p>
<ul>
<li><strong>컴파일 가능성(Compilability):</strong> 생성된 코드가 해당 프로그래밍 언어의 문법 규칙을 위반하지 않는지 1차적으로 검증합니다(Syntax Check). 이는 코드 생성 모델의 기본적인 언어 이해 능력을 평가하는 척도입니다.</li>
<li><strong>단위 테스트 통과율(Test Pass Rate):</strong> 사전에 정의된 입출력 쌍(I/O Pairs)을 만족하는지 확인합니다. 예를 들어, “문자열을 뒤집는 함수“를 요청했다면, <code>input: "abc" -&gt; output: "cba"</code>와 같은 테스트 케이스를 통과해야 합니다.</li>
<li><strong>런타임 무결성(Runtime Integrity):</strong> 실제 실행 시 메모리 누수, 무한 루프, 예외 발생 등이 없는지 확인합니다.</li>
</ul>
<p>BitDive와 같은 최신 도구들은 애플리케이션의 실제 런타임 상태(Runtime State)를 캡처하여 이를 ’Ground Truth’로 활용합니다. 이를 통해 AI가 생성한 코드가 기존 시스템의 불변성(Invariants)을 깨뜨리지 않는지, 레거시 시스템과 통합되었을 때 사이드 이펙트를 발생させ지 않는지 자동으로 검증합니다. 이러한 접근은 AI가 생성한 코드에 대한 신뢰를 막연한 ’확률’에서 검증된 ’보장(Guarantee)’의 영역으로 격상시킵니다.</p>
<h2>5.  심층 검증: 신경-상징적(Neuro-symbolic) 접근과 형식 검증</h2>
<p>단순한 테스트 케이스 통과를 넘어, 수학적으로 무결함을 증명해야 하는 고위험 영역(금융 시스템, 사이버 보안, 스마트 컨트랙트)에서는 **형식 검증(Formal Verification)**과 결합된 결정론적 정답지가 요구됩니다. 이 분야에서는 단 하나의 예외 케이스도 허용되지 않기 때문입니다.</p>
<h3>5.1  SMT 솔버(SMT Solver)의 활용</h3>
<p>최근의 연구들(LLMFP, SSV 등)은 LLM의 자연어 처리 능력과 정형 방법론(Formal Methods)의 엄밀함을 결합하는 신경-상징적 접근을 시도하고 있습니다. 이들은 LLM을 사용하여 문제를 자연어에서 정형화된 명세(Specification)로 변환하고, 이를 Z3와 같은 **SMT 솔버(Satisfiability Modulo Theories Solver)**를 통해 검증합니다.</p>
<p>이 검증 프로세스는 엄격한 피드백 루프를 형성합니다. 먼저 LLM이 자연어 요구사항을 해석하여 논리적 제약 조건(Constraints)이나 정형 명세로 변환하는 ’초안’을 작성합니다. 그러면 SMT 솔버가 이 제약 조건들이 논리적으로 모순되지 않는지, 그리고 해(Solution)가 존재하는지를 수학적으로 증명합니다. 만약 솔버가 “불충족(Unsatisfiable)” 판정을 내리면, 이는 절대적인 ’오답’을 의미하므로, 구체적인 반례(Counter-example)와 함께 LLM에게 피드백을 전달하여 수정을 요청합니다.</p>
<p>이 과정에서 SMT 솔버는 ’절대적 진실’을 말하는 오라클 역할을 수행하며, LLM 특유의 환각을 원천적으로 차단합니다. “그럴듯해 보이는” 답은 통하지 않으며, 오직 “논리적으로 참인” 답만이 솔버의 검증을 통과하여 최종 결과물로 채택됩니다. 이는 법률 규제 준수나 복잡한 금융 상품 설계와 같이 논리적 정합성이 최우선인 분야에서 AI를 활용하기 위한 필수적인 안전장치입니다.</p>
<h3>5.2  블록체인과 오라클 문제의 교훈</h3>
<p>블록체인 기술 영역에서의 오라클 문제는 결정론적 정답지의 부재가 어떤 재앙을 초래할 수 있는지 보여주는 극명한 사례입니다. 스마트 컨트랙트는 한 번 배포되면 수정이 불가능하고, 코드는 법(Code is Law)처럼 작동합니다. 그러나 블록체인 외부에 존재하는 데이터(예: 실시간 주가, 날씨 정보, 스포츠 경기 결과)를 컨트랙트 내부로 가져올 때 신뢰성 문제가 발생합니다.</p>
<p>만약 AI 에이전트가 외부 데이터를 가져와 스마트 컨트랙트에 입력하는 역할을 한다면, AI의 미세한 확률적 판단 오류나 데이터 조작이 수백만 달러 규모의 자산 탈취로 이어질 수 있습니다. 실제로 오라클 조작 공격으로 인한 DeFi(탈중앙화 금융) 생태계의 손실은 2025년 기준 누적 88억 달러에 달합니다. 이를 해결하기 위해 Chainlink와 같은 탈중앙화 오라클 네트워크는 단일 출처에 의존하지 않고, 다수의 독립된 노드로부터 데이터를 받아 중앙값(Median)을 취하거나 암호학적 증명을 통해 <strong>데이터의 결정론적 합의</strong>를 도출합니다. AI 모델이 이 과정에 통합될 때에도, AI의 출력은 반드시 온체인(On-chain)에서 검증 가능한 형태로 변환되거나, 복수의 검증자(Verifier)에 의해 합의된 정답지만이 유효한 입력으로 인정받아야 합니다. 이는 고신뢰 AI 시스템 설계에 있어 ’합의(Consensus)’와 ’다중 검증’이 결정론적 정답지를 구성하는 중요한 요소임을 시사합니다.</p>
<h2>6.  에이전트 평가를 위한 궤적(Trajectory) 기반 정답지</h2>
<p>단순한 질의응답을 넘어 도구를 사용하여 복잡한 작업을 수행하고 계획을 수립하는 <strong>에이전트(Agent) AI</strong>의 경우, 최종 결과(Final Answer)만으로는 충분한 검증이 되지 않습니다. 에이전트가 올바른 도구를 적절한 순서로 사용했는지, 중간 단계의 논리는 타당했는지 등 <strong>과정(Process)</strong> 전체에 대한 결정론적 정답지가 필요합니다.</p>
<h3>6.1  골든 데이터셋(Golden Dataset)과 궤적 평가</h3>
<p>’골든 데이터셋’은 단순한 입력-출력 쌍을 넘어, 인간 전문가가 검증한 **모범 답안 궤적(Reference Trajectory)**을 포함해야 합니다. 에이전트의 수행 과정은 다음과 같은 기준들로 엄격하게 평가됩니다:</p>
<ul>
<li><strong>도구 호출 적합성(Tool Selection):</strong> 에이전트가 “서울의 날씨 알려줘“라는 질문에 대해 <code>get_weather(city='Seoul')</code> 함수를 호출했는지 확인합니다. 만약 날씨 정보를 얻기 위해 <code>get_news(topic='Seoul')</code>을 호출하여 뉴스 기사에서 날씨를 추론했다면, 최종 답변이 맞더라도 이는 비효율적이고 불안정한 방식이므로 감점 요인이거나 ’실패’로 간주될 수 있습니다.</li>
<li><strong>파라미터 정합성(Parameter Correctness):</strong> 함수에 전달된 인자값이 API 스펙과 정확히 일치하는지 검증합니다. 날짜 형식이 <code>YYYY-MM-DD</code>여야 하는데 <code>DD-MM-YYYY</code>로 전달했다면, 이는 결정론적인 오류입니다.</li>
<li><strong>논리적 의존성 검증(DAG Evaluation):</strong> 작업의 순서가 논리적 인과관계를 따르고 있는지 유향 비순환 그래프(DAG) 형태로 검증합니다. 예를 들어, “파일을 저장하고 이메일로 전송하라“는 작업에서 ‘전송’ 행위가 ‘저장’ 행위보다 먼저 발생했다면, 이는 논리적 오류입니다.</li>
</ul>
<p>이러한 궤적 기반의 결정론적 평가는 에이전트가 우연히 정답을 맞히는 경우(False Positive)를 걸러내고, 시스템이 다양한 상황에서도 견고하게(Robust) 작동할 수 있음을 보장합니다.</p>
<h3>6.2  메타모픽 테스팅(Metamorphic Testing): 정답을 모를 때의 검증</h3>
<p>때로는 정확한 정답(Ground Truth)을 미리 알 수 없는 경우가 있습니다. 예를 들어, 복잡한 시뮬레이션 결과나 새로운 과학적 발견을 위한 AI 모델링의 경우, 무엇이 정답인지 아무도 모를 수 있습니다. 이때 활용되는 것이 **메타모픽 테스팅(Metamorphic Testing)**입니다.</p>
<p>메타모픽 테스팅은 입력값의 변화에 따른 출력값의 **관계(Relation)**를 검증합니다. 정답 자체는 모르지만, 정답이 만족해야 할 불변의 법칙(Invariants)은 알고 있다는 점을 이용합니다.</p>
<ul>
<li><strong>예시:</strong> 두 정수의 최대공약수(GCD)를 구하는 AI 함수 <code>GCD(a, b)</code>를 테스트한다고 가정해 봅시다. <code>GCD(1071, 462)</code>의 정답을 모를 수 있습니다. 하지만 수학적 성질에 의해 <code>GCD(a, b)</code>는 <code>GCD(b, a)</code>와 같아야 하고, <code>GCD(a, b)</code>는 <code>GCD(a, b + a)</code>와 같아야 한다는 것은 알 수 있습니다.</li>
<li><strong>적용:</strong> 만약 AI가 <code>GCD(1071, 462)</code>와 <code>GCD(462, 1071)</code>에 대해 서로 다른 값을 출력한다면, 둘 중 하나는 반드시 오답입니다.</li>
</ul>
<p>이 방식은 정답 데이터셋이 없는 상황에서도 AI 모델의 논리적 일관성과 결정론적 속성을 검증할 수 있는 강력한 방법론을 제공하며, 특히 생성형 AI의 신뢰성을 평가하는 데 있어 중요한 대안으로 부상하고 있습니다.</p>
<h2>7.  결론: 신뢰할 수 있는 AI를 위한 필수 조건</h2>
<p>제미나이와 같은 LLM은 강력한 언어 능력을 지니고 있지만, 그 자체로는 확률적인 ’추론 엔진’일 뿐입니다. 이 엔진이 실세계의 복잡하고 엄중한 문제를 해결하는 신뢰할 수 있는 ’솔루션’으로 기능하기 위해서는 <strong>결정론적 정답지라는 가드레일</strong>이 필수적입니다. JSON 스키마를 통한 구조적 제어, 컴파일러와 데이터베이스 엔진을 통한 실행 검증, SMT 솔버를 통한 수학적 증명, 그리고 궤적 분석을 통한 프로세스 검증은 AI의 창의성을 억압하는 것이 아닙니다. 오히려 이는 AI가 안전하게 작동할 수 있는 ’운동장’의 경계를 명확히 정의함으로써, AI가 그 안에서 마음껏 능력을 발휘할 수 있도록 돕는 기반이 됩니다.</p>
<p>결국, 성공적인 엔터프라이즈 AI 애플리케이션의 핵심은 **“확률적인 공감(Empathy)과 결정론적 논리(Logic)의 결합”**에 있습니다. 사용자와의 인터페이스는 유연하고 인간적이어야 하지만, 그 배후에서 돌아가는 데이터 처리, 의사결정, 자산 관리 등은 수학적으로 검증 가능한 정답지 위에서 엄격하게 수행되어야 합니다. 이것이 바로 우리가 제미나이를 활용한 시스템을 설계할 때, 프롬프트를 다듬는 것 이상으로 결정론적 검증 체계의 구축에 엔지니어링 리소스를 집중해야 하는 이유입니다.</p>
<p><img src="./2.7.0.0.0%20%EA%B2%B0%EC%A0%95%EB%A1%A0%EC%A0%81%20%EC%A0%95%EB%8B%B5%EC%A7%80Deterministic%20Ground%20Truth%EC%9D%98%20%EC%97%AD%ED%95%A0%EA%B3%BC%20%EC%A4%91%EC%9A%94%EC%84%B1.assets/image-20260217190838464.jpg" alt="image-20260217190838464" /></p>
<h2>8. 참고 자료</h2>
<ol>
<li>The Basics of Probabilistic vs. Deterministic AI: What You Need to, https://www.dpadvisors.ca/post/the-basics-of-probabilistic-vs-deterministic-ai-what-you-need-to-know</li>
<li>Deterministic AI vs. Probabilistic AI: Scaling Securely, https://moveo.ai/blog/deterministic-ai-vs-probabilistic-ai</li>
<li>What is Test Oracle in Software Testing? - testRigor, https://testrigor.com/blog/what-is-test-oracle-in-software-testing/</li>
<li>The Oracle Problem in Software Testing: A Survey - EECS 481, http://www0.cs.ucl.ac.uk/staff/m.harman/tse-oracle.pdf</li>
<li>(PDF) The Oracle Problem in Software Testing: A Survey, https://www.researchgate.net/publication/276255185_The_Oracle_Problem_in_Software_Testing_A_Survey</li>
<li>Can artificial intelligence solve the blockchain oracle problem, https://www.frontiersin.org/journals/blockchain/articles/10.3389/fbloc.2025.1682623/full</li>
<li>Quality Assurance for AI: Things You Need to Know - QATestLab Blog, https://blog.qatestlab.com/2025/08/05/qa-for-ai-things-you-need-to-know/</li>
<li>Deterministic vs. probabilistic models: Guide for data teams, https://www.rudderstack.com/blog/deterministic-vs-probabilistic/</li>
<li>Beyond Guardrails: Why True AI Trust Requires Deterministic, https://rainbird.ai/beyond-guardrails-why-true-ai-trust-requires-deterministic-reasoning/</li>
<li>Blog | Automated Regression Testing &amp; Deterministic Verification, https://bitdive.io/blog/</li>
<li>LLM evaluation techniques for JSON outputs - Promptfoo, https://www.promptfoo.dev/docs/guides/evaluate-json/</li>
<li>LLM-Based Structured Generation Using JSONSchema - Medium, https://medium.com/@damodharanjay/llm-based-structured-generation-using-jsonschema-139568c4f7c9</li>
<li>Comparison of Deterministic and Probabilistic Machine Learning, https://arxiv.org/pdf/2509.16233</li>
<li>Oracle Breaks New Ground in Multilingual Text-to-SQL by Winning, https://blogs.oracle.com/cloud-infrastructure/oracle-wins-archer-nl2sql-challenge</li>
<li>Improving Text-to-SQL Evaluation Methodology - ACL Anthology, https://aclanthology.org/P18-1033.pdf</li>
<li>Get consistent data from your LLM with JSON Schema - Thoughtbot, https://thoughtbot.com/blog/get-consistent-data-from-your-llm-with-json-schema</li>
<li>Structured outputs in LLMs: Definition, techniques, applications, https://www.leewayhertz.com/structured-outputs-in-llms/</li>
<li>The Invoke Large Language Model Component - Oracle Help Center, https://docs.oracle.com/en/cloud/paas/digital-assistant/use-chatbot/invoke-large-language-model-component.html</li>
<li>How Oracle is Bridging the Gap Between JSON Schema and, https://json-schema.org/blog/posts/oracle-case-study</li>
<li>What is LLM Regression Testing? Design &amp; What to Include, https://www.deepchecks.com/glossary/llm-regression-testing/</li>
<li>Ensuring Data Accuracy in Text-to-SQL Systems, <a href="https://www.ijcttjournal.org/Volume-72%20Issue-12/IJCTT-V72I12P103.pdf">https://www.ijcttjournal.org/Volume-72%20Issue-12/IJCTT-V72I12P103.pdf</a></li>
<li>Understanding LLM-Driven Test Oracle Generation - arXiv, https://arxiv.org/html/2601.05542v1</li>
<li>Understanding LLM-Driven Test Oracle Generation - arXiv, https://www.arxiv.org/pdf/2601.05542</li>
<li>A dual perspective review on large language models and code, https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1655469/full</li>
<li>Neuro-Symbolic Compliance: Integrating LLMs and SMT Solvers for, https://arxiv.org/pdf/2601.06181</li>
<li>Almost Sure Reasoning: Generating Verified Formalizations with, https://openreview.net/forum?id=aNf8VCQE0h</li>
<li>Critical Review of Software Testing Problems in the Current Decade, https://www.ijsat.org/papers/2025/2/9469.pdf</li>
<li>Smart Contract Oracle Manipulation: The $8.8M Data Poisoning, https://medium.com/@instatunnel/smart-contract-oracle-manipulation-the-8-8m-data-poisoning-ff0712c43ab8</li>
<li>Can Artificial Intelligence solve the blockchain oracle problem, https://arxiv.org/pdf/2507.02125</li>
<li>Evaluating AI agents: Tools for smarter performance analysis - Medium, https://medium.com/@online-inference/evaluating-ai-agents-tools-for-smarter-performance-analysis-065481be85c1</li>
<li>The Evaluation Imperative: Building Robust Agentic Applications, <a href="https://prakhar1114.github.io/prakharjain/blogs/Evals%20Blog/EvalsBlog.html">https://prakhar1114.github.io/prakharjain/blogs/Evals%20Blog/EvalsBlog.html</a></li>
<li>How effectively does metamorphic testing alleviate the oracle, https://vuir.vu.edu.au/33046/1/TSEmt.pdf</li>
<li>LLM-Powered Security Test Generation: Oracles, Vulnerability, https://www.computer.org/csdl/magazine/co/2026/02/11370987/2dOhh5MzH1e</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>