<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2.6.3 정량적 점수(Score)를 이진 판정(Pass/Fail) 오라클로 변환하는 기준</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2.6.3 정량적 점수(Score)를 이진 판정(Pass/Fail) 오라클로 변환하는 기준</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 2. 소프트웨어 테스트에서의 오라클(Oracle) 개념과 AI 시대의 역할</a> / <a href="index.html">2.6 AI 모델 평가 지표(Metrics)와 테스트 오라클의 구분</a> / <span>2.6.3 정량적 점수(Score)를 이진 판정(Pass/Fail) 오라클로 변환하는 기준</span></nav>
                </div>
            </header>
            <article>
                <h1>2.6.3 정량적 점수(Score)를 이진 판정(Pass/Fail) 오라클로 변환하는 기준</h1>
<p>전통적인 소프트웨어 엔지니어링 패러다임에서 테스트 오라클(Test Oracle)은 시스템의 실행 결과가 올바른지 혹은 잘못되었는지를 판별하는 절대적이고 결정론적인(Deterministic) 기준점이다. 이러한 환경에서 시스템은 동일한 입력에 대해 항상 동일한 출력을 반환하며, 테스트 프레임워크는 예상되는 정답(Ground Truth)과 실제 출력 간의 정확한 일치(Exact Match) 여부를 확인하여 ‘성공(Pass)’ 또는 ’실패(Fail)’라는 이진적(Binary) 판정을 내린다. 그러나 인공지능(AI) 모델과 거대 언어 모델(LLM)이 소프트웨어 아키텍처의 핵심 컴포넌트로 편입되면서, 시스템의 출력은 본질적으로 비결정성(Nondeterminism)을 띠게 되었고, 기존의 테스트 패러다임은 근본적인 한계에 직면하게 되었다.</p>
<p>AI 시스템은 결정론적인 정답을 출력하는 대신, 모델의 가중치와 확률 분포에 기반하여 특정 결과가 정답일 가능성을 나타내는 신뢰도 점수(Confidence Score), 생성된 텍스트와 기준 데이터 간의 의미론적 유사도(Semantic Similarity), 또는 이상 탐지 모델이 반환하는 이상 점수(Anomaly Score)와 같은 연속적인 정량적 점수(Continuous Quantitative Score)를 반환한다. 이러한 확률론적(Probabilistic) 특성은 지속적 통합 및 배포(CI/CD) 파이프라인과 같이 철저하게 이진적인 논리 게이트에 의존하는 자동화된 소프트웨어 개발 프로세스에 심각한 마찰을 일으킨다. 자동화된 테스트 파이프라인은 코드를 다음 단계로 배포할지 말지를 결정하기 위해 오직 ‘Pass’ 혹은 ’Fail’의 확정적 신호만을 요구하기 때문이다.</p>
<p>따라서 AI를 활용한 소프트웨어 개발 프로세스에서 가장 중대한 엔지니어링 과제 중 하나는 이처럼 연속적이고 변동성이 있는 정량적 점수를 신뢰할 수 있고 재현 가능한 이진 판정 오라클로 변환하는 수학적, 통계적 기준을 확립하는 것이다. 본 절에서는 소프트웨어 테스팅의 오라클 문제(The Oracle Problem)를 조명하고, 정량적 평가 지표를 결정론적 테스트 오라클로 승격시키기 위한 임계값(Threshold) 설정 이론, 통계적 최적화 알고리즘, 비용 민감형(Cost-Sensitive) 의사결정 모델, 그리고 비결정성을 통제하는 신뢰 구간(Confidence Interval) 기반의 다중 집계 방식을 심층적으로 분석한다.</p>
<h2>1.  정량적 지표와 이진 판정의 본질적 괴리 및 오라클 문제의 진화</h2>
<p>정량적 점수를 이진 판정으로 변환하는 과정의 어려움은 소프트웨어 검증 분야에서 오랫동안 난제로 취급되어 온 ’오라클 문제(The Oracle Problem)’와 직결된다. 연구자 Barr 등(2015)의 기념비적인 논문 <em>The Oracle Problem in Software Testing: A Survey</em>에 따르면, 테스트 오라클 문제는 주어진 입력에 대해 시스템이 보인 동작이 올바른지 잠재적으로 잘못되었는지를 판별하는 메커니즘을 자동화하는 과정에서 발생하는 근본적인 어려움을 의미한다.</p>
<p>일반적인 소프트웨어 테스팅에서는 <code>assert(expected == actual)</code>와 같이 개발자가 명시적으로 정의한 명세 기반 오라클(Specified Oracle)을 사용하여 이 문제를 우회한다. 하지만 AI 시스템의 경우, 동일한 입력에 대해서도 반복 실행마다 출력의 형태가 달라질 수 있으며, 언어 모델의 텍스트 생성이나 추천 시스템의 결과물처럼 ’정답’의 형태가 무한히 다양할 수 있다. 이에 따라 AI 테스팅에서는 시스템의 출력을 완전한 정답과의 일치 여부로 판단하는 대신, 휴리스틱이나 참조 모델(Reference Model), LLM-as-a-Judge 등을 동원하여 모델의 성능을 0.0에서 1.0 사이의 정량적 점수로 변환하는 확률론적 오라클(Probabilistic Oracle)을 도입하게 된다.</p>
<p>확률론적 오라클은 시스템의 품질을 세밀하게 측정할 수 있다는 장점이 있으나, 테스트 프레임워크가 요구하는 자동화의 종착점인 이진 판정을 스스로 내리지는 못한다. 결국 테스트 파이프라인은 최종적으로 임계값(Threshold) <span class="math math-inline">\tau</span>를 적용하여 정량적 점수 <span class="math math-inline">S</span>를 이진 예측 변수 <span class="math math-inline">\hat{y}</span>로 변환하는 단계를 반드시 거쳐야 한다.<br />
<span class="math math-display">
\hat{y} = \begin{cases} \text{Pass} (1), &amp; \text{if } S \geq \tau \\ \text{Fail} (0), &amp; \text{if } S &lt; \tau \end{cases}
</span><br />
여기서 제기되는 가장 핵심적인 질문은 “최적의 임계값 <span class="math math-inline">\tau</span>를 어떻게 결정할 것인가“이다. 과거에는 개발자의 직관에 의존하여 임의로 0.5 나 0.8과 같은 고정된 임계값을 설정하는 방식이 만연했다. 그러나 이러한 접근은 모델의 실제 성능 분포, 비즈니스 요구사항의 맥락, 그리고 데이터의 특성을 철저히 무시하는 결과를 초래한다. 잘못 설정된 임계값은 실제로는 실패해야 할 심각한 결함 케이스가 테스트를 통과해버리는 거짓 양성(False Positive)이나, 정상적으로 동작하는 케이스가 미세한 점수 부족으로 실패 처리되는 거짓 음성(False Negative)을 대량으로 유발하여 테스트 스위트 전체에 대한 개발팀의 신뢰를 완전히 파괴한다. 따라서 <span class="math math-inline">\tau</span>를 결정하는 과정은 임의의 선택이 아닌, 통계적 엄밀성과 수학적 근거를 바탕으로 한 최적화 과정이 되어야 한다.</p>
<h2>2.  임계값(Threshold) 설정의 기초 체계: 정적 및 동적 접근법</h2>
<p>정량적 점수를 이진 판정으로 변환하는 아키텍처는 임계값의 가변성 여부와 산출 시점에 따라 크게 정적 임계값(Static Threshold) 접근법과 동적 임계값(Dynamic Threshold) 접근법으로 분류된다.</p>
<h3>2.1  정적 임계값 (Static Thresholding)</h3>
<p>정적 임계값은 소프트웨어 테스트 명세서나 비즈니스 규칙에 의해 사전에 확정된 고정 수치를 사용하여 테스트의 통과 여부를 결정하는 가장 직관적인 방식이다. 예를 들어, “LLM 응답의 환각(Hallucination) 지수가 0.1 이하일 때만 Pass 처리한다”, 혹은 “기존 골든 데이터셋(Golden Dataset) 정답과의 코사인 유사도(Cosine Similarity) 점수가 0.85 이상이어야 Pass로 간주한다“와 같이 절대적인 기준선을 설정한다.</p>
<p>이 방식은 구현이 매우 단순하며, 테스트 결과의 평가 기준이 파이프라인의 실행 환경이나 시간에 관계없이 동일하게 유지된다는 점에서 일관성을 제공한다. 특히 인명 안전과 직결되는 자율주행 시스템이나 규제가 엄격한 금융권 AI 모델에서는 타협할 수 없는 품질의 하한선을 강제하기 위해 의도적으로 엄격한 정적 임계값을 채택하기도 한다.</p>
<p>그러나 정적 임계값은 AI 시스템의 자연스러운 진화 과정이나 입력 데이터 분포의 변화(Data Drift)를 전혀 반영하지 못한다는 치명적인 단점을 지닌다. AI 모델이 새로운 데이터로 미세 조정(Fine-tuning)되거나 프롬프트 엔지니어링을 통해 응답의 스타일이 최적화됨에 따라 전반적인 점수 분포가 이동할 경우, 기존에 설정된 정적 임계값은 더 이상 유효하지 않게 된다. 이로 인해 테스트 엔지니어는 파이프라인이 깨질 때마다 수동으로 임계값을 재조정해야 하는 과도한 유지보수 부담(기술 부채)을 안게 되며, 시스템은 변화에 대해 극도로 경직된 상태에 놓이게 된다.</p>
<h3>2.2  동적 임계값 (Dynamic Thresholding)</h3>
<p>동적 임계값은 시스템의 현재 동작 상태, 과거의 평가 이력, 그리고 평가 대상 데이터의 통계적 분포를 알고리즘이 실시간으로 분석하여 판정 기준을 스스로 조정하는 방식이다. 이는 AI 모델 출력의 내재적 변동성이나 환경적 노이즈를 필터링하고, 의미 있는 회귀(Regression)나 성능 저하만을 탐지하는 데 탁월한 성능을 발휘한다. 소프트웨어 테스트 자동화에서 주로 활용되는 동적 임계값 산정 수학 모델은 다음과 같다.</p>
<p><strong>A. Z-점수 (Z-Score) 기반 변동성 통제 임계값</strong> Z-점수 기반 방식은 특정 테스트 실행의 점수 <span class="math math-inline">X</span>가 과거에 기록된 정상적인 테스트 결과들의 평균 <span class="math math-inline">\mu</span>로부터 표준편차 <span class="math math-inline">\sigma</span>의 몇 배만큼 벗어나 있는지를 측정하여 이진 판정을 내린다.<br />
<span class="math math-display">
Z = \frac{X - \mu}{\sigma}
</span><br />
회귀 테스트 파이프라인에서 Z-점수는 모델 성능의 ’비정상적인 하락’을 탐지하는 데 매우 효과적이다. 새로운 코드가 병합된 후 배포된 모델의 평가 점수가 기존 빌드들의 점수 분포 대비 <span class="math math-inline">Z &lt; -2</span> 또는 <span class="math math-inline">Z &lt; -3</span>을 기록한다면, 이는 단순한 확률적 변동성이 아니라 통계적으로 극히 이례적인(유의미한) 품질 저하가 발생했음을 의미하므로 즉각적으로 Fail 판정을 내릴 수 있다. 이 방식은 절대적인 점수 기준이 아니라, 시스템이 형성한 ’과거 정상 상태’와의 상대적인 거리를 기준으로 판정하므로 데이터의 점진적인 변화에 유연하게 대응한다. 또한 극단적인 이상치(Outlier)에 의한 평균의 왜곡을 방지하기 위해 일반적인 Z-점수 대신 중앙값(Median)과 절대 중앙 편차(Median Absolute Deviation, MAD)를 사용하는 수정된 Z-점수(Modified Z-score) 기법이 병행되기도 한다.</p>
<p><strong>B. 지수 가중 이동 평균 (EWMA) 기반 임계값</strong> 소프트웨어 모니터링 및 테스트 이력이 시계열적 특성을 가질 때, 과거의 모든 데이터에 동일한 가중치를 부여하는 것은 효율적이지 않다. 지수 가중 이동 평균(Exponentially Weighted Moving Average, EWMA)은 최근의 테스트 결과에 기하급수적으로 더 큰 가중치를 부여하여 동적인 평균선과 임계값을 형성한다. 이 방식은 AI 모델이 지속적으로 온라인 학습(Online Learning)을 수행하거나 환경 데이터에 실시간으로 적응하는 시스템에서, 현재의 트렌드를 반영한 합리적인 Pass/Fail 기준을 동적으로 생성하는 데 기여한다.</p>
<p><strong>C. 백분위수 (Percentile) 클러스터링 기반 임계값</strong> AI 모델의 평가 점수 분포는 언제나 정규 분포를 따르지 않으며, 종종 비대칭적인(Skewed) 멱법칙 분포나 다봉형 분포를 형성한다. 이러한 상황에서 평균과 표준편차를 사용하는 방법은 심각한 오판을 부를 수 있다. 이에 대한 대안으로, 과거의 테스트 점수들을 정렬한 후 특정 백분위수에 기반하여 동적 임계값을 설정하는 방식이 활용된다. 예를 들어, 과거 <span class="math math-inline">N</span>번의 테스트 실행 기록에서 하위 5%(<span class="math math-inline">P_{0.05}</span>)에 해당하는 점수 선을 실시간으로 추적하여, 이 선을 붕괴시키는 결과가 나타날 때만 Fail로 판정하는 것이다. 이는 테스트 스위트의 진화 과정에서 수동 개입 없이 자연스럽게 기준을 표준화(Normalization)하는 강력한 모델 불가지론적(Model-agnostic) 메커니즘을 제공한다.</p>
<table><thead><tr><th><strong>비교 항목</strong></th><th><strong>정적 임계값 (Static Threshold)</strong></th><th><strong>동적 임계값 (Dynamic Threshold)</strong></th></tr></thead><tbody>
<tr><td><strong>정의</strong></td><td>고정된 상수로 절대적인 Pass/Fail 기준 정의</td><td>데이터 분포, 시계열 트렌드에 따라 판정 기준 변동</td></tr>
<tr><td><strong>핵심 활용 사례</strong></td><td>비즈니스 규칙 강제 (예: LLM 유해성 탐지율 99% 이상 필수 보장)</td><td>회귀 테스트 및 성능 모니터링 (예: 과거 100회 평균 대비 2<span class="math math-inline">\sigma</span> 이상 하락 시 Fail)</td></tr>
<tr><td><strong>장점</strong></td><td>명확한 기준 제공, 파이프라인 일관성 보장, 최적화 연산이 불필요함</td><td>데이터 드리프트(Data Drift) 자동 적응, 모델 특성 변화에 따른 수동 튜닝 비용 대폭 감소</td></tr>
<tr><td><strong>단점</strong></td><td>환경 변화에 취약, 엄격성으로 인해 코드 진화 과정에서 빈번한 오탐(False Fail) 유발</td><td>알고리즘 복잡도 증가, 점진적인 치명적 성능 저하를 ’새로운 정상(New Normal)’으로 오인할 위험 내포</td></tr>
</tbody></table>
<h2>3.  이진 판정 최적화를 위한 통계적 및 수학적 임계값 도출 기법</h2>
<p>정적 임계값을 테스트 명세로 확정하든, 동적 임계값의 초기 기준선을 설정하든, 결국 “어느 수준의 점수가 가장 합리적인 기준점인가“를 결정하기 위해서는 수학적 최적화 과정이 선행되어야 한다. AI 시스템의 성능 검증에서 가장 보편적으로 활용되는 수신기 조작 특성(Receiver Operating Characteristic, ROC) 곡선과 정밀도-재현율(Precision-Recall) 곡선은 최적의 이진 판정 기준을 수학적으로 도출하기 위한 견고한 프레임워크를 제공한다.</p>
<p>테스트 엔지니어는 사전에 인간 평가자(Human Evaluator)나 기존의 규칙 기반 시스템을 통해 ’Pass’와 ‘Fail’ 라벨이 부착된 골든 데이터셋(Golden Dataset)을 구축하고, AI 오라클 시스템이 출력하는 연속적인 정량적 점수와 실제 라벨 간의 관계를 수식화하여 최적의 임계값 <span class="math math-inline">\tau</span>를 도출한다.</p>
<h3>3.1  Youden의 J 통계량 (Youden’s J Statistic) 기반 이진화</h3>
<p>Youden’s Index(또는 J 통계량)는 이진 분류기나 진단 테스트의 성능을 요약하는 단일 통계량으로, 정량적 점수의 임계값을 변화시킬 때 도출되는 ROC 곡선 상에서 민감도(Sensitivity)와 특이도(Specificity)의 합을 최대화하는 지점을 찾아내는 수학적 최적화 기준이다.</p>
<p>소프트웨어 테스트 맥락에서 각 지표는 다음과 같이 해석된다.</p>
<ul>
<li><strong>민감도 (Sensitivity 또는 True Positive Rate, TPR):</strong> 실제 테스트를 통과해야 할 올바른 케이스(Pass) 중, 시스템이 정확히 Pass로 판정해 낸 비율이다. <span class="math math-inline">\frac{TP}{TP + FN}</span>로 계산된다.</li>
<li><strong>특이도 (Specificity 또는 True Negative Rate, TNR):</strong> 실제 실패해야 할 결함 케이스(Fail) 중, 시스템이 정확히 Fail로 차단해 낸 비율이다. <span class="math math-inline">\frac{TN}{TN + FP}</span>로 계산된다.</li>
</ul>
<p>Youden’s Index <span class="math math-inline">J</span>는 가능한 모든 임계값 <span class="math math-inline">t</span>에 대하여 다음과 같이 정의된다 :<br />
<span class="math math-display">
J = \max_{t} \{ \text{Sensitivity}(t) + \text{Specificity}(t) - 1 \} = \max_{t} \{ \text{TPR}(t) - \text{FPR}(t) \}
</span><br />
이 수식에서 <span class="math math-inline">FPR(t)</span>는 위양성률(False Positive Rate)로 <span class="math math-inline">1 - \text{Specificity}(t)</span>를 의미한다. <span class="math math-inline">J</span>의 값은 0(테스트가 우연과 다를 바 없이 무의미함)에서 1(거짓 양성과 거짓 음성이 전혀 없는 완벽한 판정) 사이의 범위를 가진다.</p>
<p>오라클 설계자는 골든 데이터셋을 기반으로 가능한 모든 연속형 점수 <span class="math math-inline">t</span>에 대해 민감도와 특이도를 계산한 뒤, <span class="math math-inline">J</span> 값이 최대가 되는 지점의 점수 <span class="math math-inline">t^*</span>를 최종적인 이진 판정 오라클의 임계값으로 채택한다. Youden’s Index를 사용하는 방식은 오탐(False Positive)과 미탐(False Negative)이 야기하는 위험의 무게가 동일하다고 가정할 때 가장 이상적인 타협점을 제공하며, 골든 데이터셋 내의 정상 데이터와 결함 데이터의 비율이 불균형할 때도 비교적 편향되지 않은 강건한 임계값을 산출한다는 장점이 있다.</p>
<h3>3.2  F1-Score 기반 임계값 최적화 전략</h3>
<p>소프트웨어 테스팅 환경, 특히 버그나 결함을 찾아내는 프로세스에서는 정상 코드(Pass 대상)에 비해 심각한 결함(Fail 대상)이 차지하는 비율이 압도적으로 적은 극심한 데이터 불균형(Class Imbalance) 현상이 발생한다. 이렇게 불균형이 심한 데이터셋에서 ROC 곡선 기반의 Youden’s Index는 클래스의 기저 비율을 반영하지 못하여, 실제로는 정밀도(Precision)가 형편없는 임계값을 최적으로 잘못 제시할 위험이 있다.</p>
<p>이러한 한계를 극복하기 위해, 특이도를 배제하고 정밀도(Precision)와 재현율(Recall) 간의 조화 평균(Harmonic Mean)인 F1-Score를 최적화 기준으로 삼는 전략이 사용된다.</p>
<ul>
<li><strong>정밀도 (Precision):</strong> 오라클이 Pass라고 판정한 케이스 중에서 실제로 Pass여야 하는 케이스의 비율이다. <span class="math math-inline">\frac{TP}{TP + FP}</span>로 계산된다. 오탐(False Positive)을 줄일수록 상승한다.</li>
<li><strong>재현율 (Recall):</strong> 전체 실제 Pass 대상 중에서 오라클이 정확히 Pass로 판정해낸 비율이다 (민감도와 동일).</li>
</ul>
<p>임계값 <span class="math math-inline">t</span>에 대한 F1-Score는 다음과 같이 정의된다 :<br />
<span class="math math-display">
F1(t) = 2 \times \frac{\text{Precision}(t) \times \text{Recall}(t)}{\text{Precision}(t) + \text{Recall}(t)}
</span><br />
오라클 최적화 알고리즘은 그리드 탐색(Grid Search)이나 임계값 이동(Threshold Moving) 기법을 사용하여, 주어진 검증 데이터셋에서 <span class="math math-inline">F1(t)</span>를 최대화하는 임계값 <span class="math math-inline">t</span>를 찾아 이를 CI/CD 파이프라인의 이진 오라클 기준점으로 고정한다. 이 방식은 희귀한 결함을 절대 놓쳐서는 안 된다는 목표와 무해한 코드 변경을 결함으로 잘못 인식하여 배포를 가로막는 오탐 사이에서, 개발 조직의 생산성을 극대화하는 가장 실용적인 타협점을 도출해낸다.</p>
<h3>3.3  Otsu의 방법론 (Otsu’s Method): 히스토그램 기반 비지도 분리</h3>
<p>앞서 다룬 Youden’s Index나 F1-Score 기법은 모두 정확한 Pass/Fail 라벨이 부착된 양질의 골든 데이터셋이 존재함을 전제로 하는 지도 학습(Supervised) 기반의 최적화 방식이다. 그러나 AI 테스트 자동화 영역에서는 방대한 양의 테스트 결과에 대해 인간 평가자가 일일이 정답 라벨을 부여하는 것이 시간적, 비용적으로 불가능한 경우가 빈번하다.</p>
<p>이처럼 정답 라벨이 전혀 없는 무분포(Distribution-Free) 상태에서, 테스트 결과 점수들의 통계적 히스토그램 특성 자체만으로 최적의 이진 판정 기준을 찾아야 할 때, 컴퓨터 비전 분야에서 흑백 이미지의 이진화(Binarization)에 광범위하게 사용되는 ’Otsu의 방법론(Otsu’s Method)’을 테스트 오라클 임계값 설정에 차용할 수 있다.</p>
<p>대규모 소프트웨어 프로젝트에서 정상적인 코드 실행 결과와 비정상적인 버그 케이스가 혼재된 상태로 AI 모델의 성능 평가 점수(예: LLM 응답 품질 점수)를 추출하여 히스토그램으로 시각화하면, 대개 높은 점수 구간(Pass 가능성이 높은 정상 범주)과 낮은 점수 구간(Fail 가능성이 높은 결함 범주)에 데이터가 집중되는 쌍봉형(Bimodal) 분포가 나타난다. Otsu의 방법론은 이 두 군집 간의 클래스 간 분산(Between-Class Variance)을 최대화하거나, 반대로 클래스 내 분산(Intra-Class Variance)을 최소화하는 최적의 점수 <span class="math math-inline">k</span>를 기하학적으로 찾아낸다.</p>
<p>임계값 <span class="math math-inline">k</span>를 기준으로 점수 분포를 두 클래스 <span class="math math-inline">C_1</span>(점수가 <span class="math math-inline">k</span> 이하인 그룹, Fail 예측)과 <span class="math math-inline">C_2</span>(점수가 <span class="math math-inline">k</span> 초과인 그룹, Pass 예측)로 나눈다고 가정할 때, 클래스 간 분산 <span class="math math-inline">\sigma_B^2(k)</span>는 다음과 같이 수식화된다 :<br />
<span class="math math-display">
\sigma_B^2(k) = P_1(k)P_2(k)[m_1(k) - m_2(k)]^2
</span><br />
수식의 각 구성 요소는 다음과 같다:</p>
<ul>
<li><span class="math math-inline">P_1(k) = \sum_{i=0}^{k} p_i</span> (임의의 점수 레벨 <span class="math math-inline">i</span>가 <span class="math math-inline">k</span> 이하일 누적 확률, 즉 <span class="math math-inline">C_1</span>의 가중치)</li>
<li><span class="math math-inline">P_2(k) = \sum_{i=k+1}^{L-1} p_i = 1 - P_1(k)</span> (점수가 <span class="math math-inline">k</span>를 초과할 확률, 즉 <span class="math math-inline">C_2</span>의 가중치)</li>
<li><span class="math math-inline">m_1(k) = \frac{1}{P_1(k)} \sum_{i=0}^{k} i \cdot p_i</span> (<span class="math math-inline">C_1</span> 클래스에 속한 점수들의 평균)</li>
<li><span class="math math-inline">m_2(k) = \frac{1}{P_2(k)} \sum_{i=k+1}^{L-1} i \cdot p_i</span> (<span class="math math-inline">C_2</span> 클래스에 속한 점수들의 평균)</li>
</ul>
<p>Otsu 알고리즘은 0부터 <span class="math math-inline">L-1</span>(가능한 최대 점수)까지의 모든 가능한 점수 <span class="math math-inline">k</span>를 순회하며 위 수식에 따른 분산을 계산하고, <span class="math math-inline">\sigma_B^2(k)</span>의 값을 수학적으로 가장 크게 만드는 <span class="math math-inline">k^*</span>를 찾아내어 이를 최종 오라클의 임계값으로 확정한다.</p>
<p>이 기법은 테스트 케이스의 정답 라벨이 부재한 상황에서도 점수 히스토그램의 형태적 특징만을 분석하여 수학적으로 가장 깔끔하게 정상군과 결함군을 가르는 단층(Fault Line)을 그어준다는 점에서, 데이터 라벨링 비용이 극도로 높은 AI 테스트 환경에서 매우 혁신적이고 독립적인 비지도(Unsupervised) 이진화 방법론으로 기능한다.</p>
<h2>4.  소프트웨어 테스팅의 비대칭적 위험을 반영한 비용 민감형(Cost-Sensitive) 임계값 산정</h2>
<p>수학적 지표 최적화 기법(Youden’s J, F1-Score, Otsu)들은 데이터의 통계적 분포나 전체적인 판정 정확도를 극대화하는 데 초점을 맞추지만, 이는 소프트웨어 엔지니어링의 현실적인 비즈니스 컨텍스트를 간과할 위험이 있다. 실제 엔터프라이즈 환경에서는 오라클이 내리는 두 가지 형태의 오류—거짓 양성(False Positive, 결함을 정상으로 오판)과 거짓 음성(False Negative, 정상을 결함으로 오판)—가 비즈니스에 미치는 파급 효과와 비용이 결코 동일하지 않으며, 고도로 비대칭적(Asymmetric)이다.</p>
<p>극단적인 예로, 의료 데이터를 다루는 진단 보조 AI나 자율주행 시스템의 제어 모듈을 테스트하는 상황을 가정해보자. 테스트 오라클이 시스템의 치명적인 결함을 포착하지 못하고 정상(Pass)으로 판정하여 프로덕션 환경에 배포되게 놔두는 거짓 양성(False Positive)의 비용은 인명 사고나 막대한 법적 책임과 직결된다. 반면, 단순한 코드 자동 완성 모델이나 챗봇 시스템에서 유효한 응답을 결함(Fail)으로 잘못 판단하는 거짓 음성(False Negative)은 개발자의 수동 리뷰 시간을 조금 증가시키거나 배포 주기를 약간 지연시키는 정도의 가벼운 비용만을 초래한다.</p>
<p>따라서 정량적 점수를 이진 오라클로 변환할 때는 단순한 수리적 정확도 극대화를 넘어서, 비즈니스 위험도를 수학적으로 모델링한 예상 비용(Expected Cost, EC) 함수를 목적 함수로 도입하여 임계값을 편향(Shift)시켜야 한다. 주어진 임계값 <span class="math math-inline">c</span>에 대한 예상 비용 함수는 다음과 같이 도출된다.<br />
<span class="math math-display">
\text{EC}(c) = \text{Cost}_{\text{FP}} \cdot P(\text{FP} \vert c) \cdot P(\text{Negative}) + \text{Cost}_{\text{FN}} \cdot P(\text{FN} \vert c) \cdot P(\text{Positive})
</span><br />
여기서 <span class="math math-inline">\text{Cost}*{\text{FP}}</span>와 <span class="math math-inline">\text{Cost}*{\text{FN}}</span>은 각각 거짓 양성과 거짓 음성이 발생했을 때 조직이 감당해야 할 정량화된 패널티이며, <span class="math math-inline">P(\text{Negative})</span>와 <span class="math math-inline">P(\text{Positive})</span>는 전체 테스트 데이터 중 결함과 정상 케이스의 사전 확률(Prevalence)을 의미한다. 보다 실용적인 의사결정 모델 적용을 위해, 절대적인 비용의 크기보다는 두 오류 간의 상대적 비용 비율(Ratio of Costs) <span class="math math-inline">r</span>을 사용하여 다음과 같이 표현할 수도 있다 :<br />
<span class="math math-display">
r = \frac{\text{Cost}_{\text{FP}}}{\text{Cost}_{\text{FN}} + \text{Cost}_{\text{FP}}}
</span><br />
이 비용 비율을 통계적 판별식에 통합하여 전역 최적해를 구하게 되면, 테스트 오라클의 임계값은 일반적인 Youden’s Index가 가리키는 중립적인 위치에서 벗어나게 된다. 예를 들어, <span class="math math-inline">\text{Cost}_{\text{FP}}</span>가 극도로 높은 도메인에서는, 정상 코드를 다수 기각(Fail)하더라도 단 하나의 결함 코드도 통과시키지 않기 위해 임계값 <span class="math math-inline">c</span>가 보수적인 방향(매우 높은 점수 요구)으로 이동한다. 이는 비용 민감형 학습(Cost-Sensitive Learning)의 핵심 철학을 소프트웨어 검증에 적용한 것으로 , 테스트 오라클을 단순한 품질 게이트키퍼에서 리스크 기반 테스팅(Risk-Based Testing)을 수행하는 비즈니스 방어 기제로 격상시킨다.</p>
<h2>5.  비결정성(Nondeterminism) 제어를 위한 반복 평가와 신뢰 구간(Confidence Interval) 기반 이진 판정</h2>
<p>지금까지 살펴본 임계값 최적화 알고리즘들은 모두 단일 테스트 실행(Single Run)에서 반환된 단일 정량적 점수를 다루는 데 초점이 맞추어져 있다. 그러나 최신 LLM이나 생성형 AI 모델들은 모델의 내재적 확률성(예: Temperature, Top-P, Top-K 파라미터), 하드웨어 부동소수점 연산의 미세한 차이, 혹은 병렬 처리 타이밍 등으로 인해 동일한 입력 프롬프트와 동일한 환경 설정 하에서도 실행할 때마다 매번 다른 텍스트를 생성하고 각기 다른 정량적 평가 점수를 반환하는 심각한 비결정성(Nondeterminism)을 내포하고 있다.</p>
<p>이러한 상황에서, 단 한 번의 테스트 실행으로 0.88의 유사도 점수(지정된 임계값 0.85 상회)를 획득했다고 하여 해당 테스트 케이스를 ’Pass’로 영구히 단정 짓는 것은 통계적 기만이며 극도로 위험한 엔지니어링 관행이다. 단일 실행의 통과는 단순한 요행(Flakiness)일 수 있기 때문이다. 이처럼 근본적으로 요동치는 확률론적 시스템을 완벽한 결정론적 오라클의 통제 하에 두기 위해서는, 동일한 테스트 케이스를 <span class="math math-inline">N</span>회 반복 실행(Repeated Runs)한 뒤, 그 결과의 분포를 통계적으로 집계(Aggregation)하여 최종적인 이진 판정으로 압축하는 메커니즘이 필수적으로 수반되어야 한다.</p>
<h3>5.1  단순 집계 전략의 한계와 분류</h3>
<p>다중 평가 결과를 단일 Pass/Fail로 변환하는 가장 기초적인 전략은 테스트 속성에 따라 두 가지로 나뉜다.</p>
<ul>
<li><strong>엄격한 통과 (Strict Pass):</strong> “생성된 응답은 반드시 지정된 JSON 스키마를 준수해야 한다“와 같은 절대적 제약 조건의 경우, 10번의 반복 실행 중 단 1번이라도 임계값을 넘지 못하는 파싱 실패가 발생하면 그 즉시 전체 테스트를 Fail로 판정한다.</li>
<li><strong>다수결 원칙 (Majority Vote):</strong> “응답의 어조가 공손하고 유창해야 한다“와 같은 연성 요구사항(Soft Requirement)의 경우, 다수의 실행(예: 과반수 이상)이 임계값을 넘는 Pass를 기록했다면 최종적으로 시스템이 해당 속성을 만족했다고 간주하고 Pass 판정을 내린다.</li>
</ul>
<p>그러나 이러한 단순 집계 방식은 반복 횟수 <span class="math math-inline">N</span>이 작을 경우 극심한 통계적 오류에 빠지게 된다. AI 모델의 API 호출 비용이나 테스트 지연 시간의 제약으로 인해 <span class="math math-inline">N</span>을 5회나 10회 정도로 작게 설정하는 상황을 가정해보자. 3번의 실행 중 3번 모두 성공(성공률 100%)한 테스트 결과가, 1,000번 실행 중 990번 성공(성공률 99%)한 결과보다 본질적인 시스템 안정성이 더 높다고 확언할 수는 없다.</p>
<h3>5.2  Wilson 점수 구간 (Wilson Score Interval)을 이용한 확정적 통계 판정</h3>
<p>표본의 크기 <span class="math math-inline">N</span>이 충분히 크지 않은 조건에서 반복 실행된 Pass/Fail 결과 이력으로부터 시스템의 진정한 성공 확률(모비율, Population Proportion)을 안전하게 추정하려면, 단순한 성공 횟수 비율 대신 수학적 신뢰 구간(Confidence Interval, CI)을 적용해야 한다. 특히 소프트웨어 테스트에서 <span class="math math-inline">N</span>이 작거나, 성공 비율이 0(전부 실패) 혹은 1(전부 성공)에 극단적으로 가까울 때 흔히 사용되는 정규 근사법(Wald Interval)은 실제 확률 범위를 과소평가(Under-coverage)하는 치명적인 결함을 드러낸다.</p>
<p>이러한 문제를 극복하고 엄밀한 이진 판정 오라클을 구축하기 위해 가장 강력하게 권장되는 통계적 도구가 바로 <strong>Wilson 점수 구간(Wilson Score Interval)</strong> 이다. Wilson 점수 구간은 이항 분포(Binomial Distribution)를 따르는 테스트 결과에서, 우연에 의한 변동성을 제거하고 모비율이 위치할 것으로 예상되는 진정한 하한선과 상한선을 정밀하게 그려낸다.</p>
<p>원하는 신뢰 수준(Confidence Level, 예: 95%)에 해당하는 표준 정규 분포의 임계값을 <span class="math math-inline">z</span> (95% 신뢰 수준의 경우 <span class="math math-inline">z \approx 1.96</span>), 전체 반복 실행 횟수 <span class="math math-inline">N</span>번 중 정적 임계값을 통과한(단일 실행 Pass) 횟수의 비율을 <span class="math math-inline">\hat{p}</span>라고 할 때, Wilson 점수 구간의 공식은 다음과 같이 도출된다 :<br />
<span class="math math-display">
\text{CI} = \frac{\hat{p} + \frac{z^2}{2N}}{1 + \frac{z^2}{N}} \pm \frac{z}{1 + \frac{z^2}{N}} \sqrt{\frac{\hat{p}(1-\hat{p})}{N} + \frac{z^2}{4N^2}}
</span><br />
이 복잡한 수식은 오라클이 비결정성 AI 시스템을 평가할 때 결정적인 패러다임 전환을 가져온다. 이제 테스트 엔지니어는 “단순 평균 성공률 <span class="math math-inline">\hat{p}</span>가 90% 이상일 때 통과시킨다“라는 피상적인 규칙 대신, **“95% 신뢰 수준에서 계산된 Wilson 점수 구간의 하한선(Lower Bound)이 85% 이상일 때만 최종적으로 파이프라인을 Pass 시킨다”**라는 통계적으로 철저하게 검증된 확정적(Deterministic) 기준을 강제할 수 있게 된다.</p>
<p>유사한 접근법으로 <span class="math math-inline">\hat{p}</span> 계산식의 분자와 분모에 특정 상수(예: +2, +4)를 가산하여 스무딩(Smoothing) 효과를 내는 Agresti-Coull “Plus-four” 근사법을 함께 적용하기도 한다. 이러한 신뢰 구간 기반의 이진 판정법은, 우연히 연속으로 몇 번 성공하여 마치 시스템이 완벽한 것처럼 위장하는 불안정한(Flaky) 코드의 배포를 효과적으로 차단하며 , 실행 샘플 수가 극히 적은 경제적 제약 속에서도 통계적 자신감(Confidence)을 담보하여 정량적이고 확률론적인 점수 데이터를 확고부동한 이진 오라클로 격상시킨다.</p>
<h2>6.  오라클의 신뢰도 확보를 위한 수용 대역(Acceptance Bands) 및 다중 집계 전략</h2>
<p>통계적 엄밀성을 적용하더라도, 단일한 절단선(Cut-off) 임계값만을 사용할 경우, 점수가 기준선 바로 주변에 맴돌 때 사소한 노이즈로 인해 테스트 결과가 통과와 실패 사이를 끊임없이 오가는 플리핑(Flipping) 현상이 발생한다. 이는 CI/CD 파이프라인의 신뢰도를 급격히 떨어뜨리는 주범이 된다. 최신 MLOps 프레임워크 및 선도적인 AI 품질 관리(QA) 조직에서는 이를 방지하기 위해 단일 선(Line) 형태의 임계값 대신 <strong>수용 대역(Acceptance Bands)</strong> 개념을 도입한다.</p>
<p>점수가 0에서 100까지 존재할 때, 단순 이진 임계값을 80으로 잡으면 79.9는 Fail, 80.1은 Pass가 되는 경직성이 발생한다. 수용 대역 기법은 이를 분절하여 Pass 대역(예: 85 이상), Fail 대역(예: 75 미만), 그리고 그 사이의 경고 대역(75 이상 85 미만)을 설정한다. CI/CD 환경에서는 시스템의 점수가 명확한 Pass 대역이나 Fail 대역에 속하면 즉각적으로 이진 판정을 내려 파이프라인의 진행 혹은 중단을 결정한다. 하지만 점수가 경고 대역에 진입할 경우 자동 판정을 유보하고 다음과 같은 2단계 검증(Two-stage validation) 메커니즘을 작동시킨다.</p>
<ol>
<li><strong>동적 <span class="math math-inline">N</span> 증가를 통한 재평가:</strong> 초기 테스트가 <span class="math math-inline">N=5</span>로 수행되어 결과가 경고 대역에 위치했다면, 알고리즘이 자동으로 반복 횟수 <span class="math math-inline">N</span>을 20이나 50으로 증가시켜 추가 테스트를 수행한다. <span class="math math-inline">N</span>이 증가하면 Wilson 점수 구간의 오차 범위가 좁아지므로, 모호했던 점수 분포가 확정적인 Pass 대역이나 Fail 대역으로 편입될 확률이 높아진다.</li>
<li><strong>인간 평가자(Human-in-the-loop) 개입:</strong> 통계적 샘플링을 늘려도 경계선에 머물거나 특정 비즈니스 로직에 대해 기계가 확신할 수 없는 경우, 해당 테스트 결과를 대시보드에 플래그(Flag)하여 인간 리뷰어가 직접 이진 판정을 확정짓도록 한다.</li>
</ol>
<p>이러한 수용 대역 전략은 정량적 점수를 이진 판정으로 변환하는 과정에서 발생하는 흑백 논리의 폭력을 완화하고, 기계적 테스트의 효율성과 인간의 유연한 판단을 결합하는 하이브리드 오라클을 구축하는 핵심 기법으로 자리 잡고 있다.</p>
<h2>7.  실전 소프트웨어 아키텍처에서의 정량적 점수 변환 파이프라인 통합</h2>
<p>앞서 심층적으로 분석한 이론적, 수학적 기법들을 실제 소프트웨어 개발 라이프사이클(SDLC)에 통합하여, 정량적 점수를 이진 오라클로 실체화하는 통합 파이프라인의 아키텍처 구성을 살펴볼 필요가 있다.</p>
<p>최근 대두되는 챗봇이나 텍스트 기반 RAG(Retrieval-Augmented Generation) 시스템의 회귀 테스트(Regression Testing)를 예로 들어보자. 전통적인 회귀 테스트 도구들은 코드의 변경 전과 후의 출력이 바이트 단위까지 ’정확히 일치(Exact Match)’하는지를 검증하였다. 그러나 AI 시스템의 응답은 비결정적이며, “로그인 페이지로 가세요“와 “로그인을 위해 페이지를 이동해 주세요“는 문맥상 동일한 의미를 지니지만 문자열은 완전히 다름에도 불구하고 기존의 정적 오라클은 이를 100% Fail로 판정해버린다.</p>
<p>이를 해결하기 위해 최신 테스팅 프레임워크는 AI 텍스트 출력을 고차원 벡터 임베딩(Vector Embedding)으로 변환하고, 데이터베이스 내 기존 골든 데이터 출력(Reference)과 코사인 유사도를 구하는 정량적 평가를 선행한다. 그리고 앞서 서술한 통계적 검증 게이트를 CI 파이프라인 로직에 주입한다.</p>
<p>전체 통합 파이프라인의 실행 흐름은 다음과 같이 체계화된다:</p>
<ol>
<li><strong>트리거 및 실행:</strong> 개발자가 새로운 코드를 브랜치에 커밋하면 회귀 테스트 스위트가 가동되어 자동화된 테스트 러너(Runner)가 실행된다.</li>
<li><strong>비결정성 수집 (<span class="math math-inline">N</span>회 런):</strong> 테스트 러너는 동일한 입력 프롬프트를 시스템에 <span class="math math-inline">N</span>회 주입하고, 산출된 결과 텍스트 배열 <span class="math math-inline">R_{new}</span>를 획득한다.</li>
<li><strong>정량적 점수 연산:</strong> <span class="math math-inline">R_{new}</span>의 각 응답과 기준 데이터 <span class="math math-inline">R_{base}</span> 간의 코사인 유사도 점수 <span class="math math-inline">S_{sim}</span>을 각각 계산한다.</li>
<li><strong>임계값 1차 평가:</strong> 각각의 <span class="math math-inline">S_{sim}</span>이 사전 학습 단계에서 Youden’s Index와 비용 민감도 모델(Cost-Sensitive Model)을 융합하여 도출된 최적 임계값 <span class="math math-inline">\tau_{optimal}</span> (예: 0.92)을 넘는지 판별한다. 이를 넘은 결과는 임시적으로 <span class="math math-inline">1</span> (Pass), 넘지 못한 결과는 <span class="math math-inline">0</span> (Fail)으로 변환된다.</li>
<li><strong>통계적 신뢰 구간(Wilson Score) 2차 판정:</strong> 임계값 평가기(Threshold Evaluator)가 <span class="math math-inline">N</span>개의 임시 Pass/Fail 비율(<span class="math math-inline">\hat{p}</span>)을 바탕으로 95% 신뢰 수준의 Wilson 점수 구간을 계산한다. 산출된 하한선(Lower Bound) 수치가 파이프라인에 지정된 수용 대역(Acceptance Band)의 합격 기준을 상회하는지 최종 검사한다.</li>
<li><strong>CI/CD 명령 반환:</strong> 모든 통계적 기준을 완벽히 충족했다면 운영 체제 시스템 명령으로 <code>exit 0</code> (최종 Pass)를 반환하여 빌드 및 배포 파이프라인을 다음 단계로 통과시킨다. 기준 미달 시 <code>exit 1</code> (최종 Fail)을 반환하여 즉시 파이프라인을 멈추고 슬랙(Slack) 등의 채널로 에러 리포트와 점수 히스토그램을 전송한다.</li>
</ol>
<p>이러한 고도의 파이프라인 구조를 구축함으로써, 테스트 엔지니어는 AI 모델이 내뿜는 끝없는 불확실성과 확률의 안개 속에서도, 전통적인 소프트웨어 테스트 도구(JUnit, PyTest 등)가 요구하는 견고한 이진 단언문(Binary Assertions)을 어떤 결함이나 오탐 없이 무결하게 실행할 수 있게 된다. 정량적 점수를 이진 판정 오라클로 변환하는 이 일련의 정교한 과정은, 기계의 확률론적 본성을 인간의 엔지니어링 통제력 아래로 완전히 복속시키는 가장 진보적인 테스팅 아키텍처의 완성이라 평가할 수 있다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>How to Test Your AI Apps and Features: A Comprehensive Guide for QA Leaders, https://techstrong.ai/features/how-to-test-your-ai-apps-and-features-a-comprehensive-guide-for-qa-leaders/</li>
<li>Testing AI Systems: Handling the Test Oracle Problem - DEV Community, https://dev.to/qa-leaders/testing-ai-systems-handling-the-test-oracle-problem-3038</li>
<li>Research on probabilistic methods for control system design - Politecnico di Torino, <a href="https://staff.polito.it/giuseppe.calafiore/Home_Page/Publications_files/Automatica_survey%20randomized_2011.pdf">https://staff.polito.it/giuseppe.calafiore/Home_Page/Publications_files/Automatica_survey%20randomized_2011.pdf</a></li>
<li>Challenges in Testing Large Language Model Based Software: A Faceted Taxonomy - arXiv, https://arxiv.org/html/2503.00481v2</li>
<li>A Gentle Introduction to Threshold-Moving for Imbalanced Classification - MachineLearningMastery.com, https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/</li>
<li>Cascaded Machine Learning Models For Anomaly Detection At The Edge - Diva-portal.org, http://www.diva-portal.org/smash/get/diva2:1987621/FULLTEXT01.pdf</li>
<li>Essential LLM evaluation metrics for AI quality control: From error analysis to binary checks, https://langwatch.ai/blog/essential-llm-evaluation-metrics-for-ai-quality-control</li>
<li>Pass or fail? Binary AI evaluations are key | by Joerg (Jörg) Firnkorn - Medium, https://medium.com/@joerg.firnkorn/pass-or-fail-binary-ai-evaluations-are-key-d111b335eb5e</li>
<li>A Problem-Oriented Taxonomy of Evaluation Metrics for Time Series Anomaly Detection, https://arxiv.org/html/2511.18739v1</li>
<li>Leveraging N-Version Testing to Define Approximate Oracles for Performance Testing, https://sol.sbc.org.br/index.php/sbes/article/download/37064/36849</li>
<li>(PDF) The Oracle Problem in Software Testing: A Survey - ResearchGate, https://www.researchgate.net/publication/276255185_The_Oracle_Problem_in_Software_Testing_A_Survey</li>
<li>Embedding and classifying test execution traces using neural networks | IET Software, https://digital-library.theiet.org/doi/full/10.1049/sfw2.12038</li>
<li>Estimating Correctness Without Oracles in LLM-Based Code Generation - arXiv, https://arxiv.org/html/2507.00057v1</li>
<li>Oracle AI Vector Search User’s Guide, https://docs.oracle.com/en/database/oracle/oracle-database/23/vecse/ai-vector-search-users-guide.pdf</li>
<li>The Oracle Problem in Software Testing: A Survey - IEEE Xplore, https://ieeexplore.ieee.org/iel7/32/7106034/06963470.pdf</li>
<li>Formal Reasoning About Bernstein-Vazirani Algorithm | Request PDF - ResearchGate, https://www.researchgate.net/publication/399327152_Formal_Reasoning_About_Bernstein-Vazirani_Algorithm</li>
<li>[E] Selecting the optimal threshold for a binary classifier : r/statistics - Reddit, https://www.reddit.com/r/statistics/comments/z7552l/e_selecting_the_optimal_threshold_for_a_binary/</li>
<li>Challenges in Evaluating Performance Testing Results | by Mesut Güneş | Medium, https://medium.com/@gunesmes/challenges-in-evaluating-performance-testing-results-f546ecb9c266</li>
<li>Comparing Threshold Selection Methods for Network Anomaly Detection - IEEE Xplore, https://ieeexplore.ieee.org/iel8/6287639/10380310/10659855.pdf</li>
<li>Evaluate Agents - Oracle Help Center, https://docs.oracle.com/en/cloud/saas/fusion-ai/aiaas/evaluate-agents.html</li>
<li>Trust at Scale: Regression Testing Multi-Agent Systems in Continuous Deployment Environments | by Parv Bhargava | Medium, https://medium.com/@bhargavaparv/trust-at-scale-regression-testing-multi-agent-systems-in-continuous-deployment-environments-99dfcc5872e9</li>
<li>Static vs Dynamic Alert Thresholds for Monitoring - eG Innovations, https://www.eginnovations.com/blog/static-vs-dynamic-alert-thresholds-for-monitoring/</li>
<li>Dual Dynamic Threshold Adjustment Strategy for Deep Metric Learning - arXiv, https://arxiv.org/html/2404.19282v1</li>
<li>Machine Learning for Time Series Anomaly Detection Ihssan Tinawi - DSpace@MIT, <a href="https://dspace.mit.edu/bitstream/handle/1721.1/123129/1128282917-MIT.pdf?sequence">https://dspace.mit.edu/bitstream/handle/1721.1/123129/1128282917-MIT.pdf?sequence=</a></li>
<li>Anomaly Detection Using a Sliding Window Technique and Data Imputation with Machine Learning for Hydrological Time Series - MDPI, https://www.mdpi.com/2073-4441/13/13/1862</li>
<li>Detecting Anomalies with Z-Scores: A Practical Approach | by Akash Srivastava - Medium, https://medium.com/@akashsri306/detecting-anomalies-with-z-scores-a-practical-approach-2f9a0f27458d</li>
<li>Iterative rolling difference-Z-score and machine learning imputation for wind turbine foundation monitoring - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC12412959/</li>
<li>How to Implement Anomaly Detection Integration - OneUptime, https://oneuptime.com/blog/post/2026-01-30-anomaly-detection-integration/view</li>
<li>Anomaly Detection Techniques Summary - Kaggle, https://www.kaggle.com/code/praxitelisk/anomaly-detection-techniques-summary</li>
<li>AI-powered models for overcrowding prediction at TUMS hospitals - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC12780012/</li>
<li>Kaggle Winning Solutions: AI Trends &amp; Insights, https://www.kaggle.com/code/tahaalselwii/kaggle-winning-solutions-ai-trends-insights</li>
<li>Percentile — Indikator dan Strategi - TradingView, https://id.tradingview.com/scripts/percentile/</li>
<li>Youden Index and the optimal threshold for markers with mass at zero - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC2749250/</li>
<li>Classifier Calibration and the End of ROC-Based Threshold Selection, https://valeman.medium.com/classifier-calibration-and-the-end-of-roc-based-threshold-selection-d8e52086cb12</li>
<li>Machine Learning Evaluation Metrics -, https://kevalnagda.github.io/evaluation-metrics</li>
<li>Youden’s J statistic - Wikipedia, <a href="https://en.wikipedia.org/wiki/Youden&#x27;s_J_statistic">https://en.wikipedia.org/wiki/Youden%27s_J_statistic</a></li>
<li>Measures of Diagnostic Accuracy: Basic Definitions - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC4975285/</li>
<li>Confidence Interval Estimation of the Youden index and corresponding cut-point for a combination of biomarkers under normality - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC8991305/</li>
<li>ThresholdROC: Optimum Threshold Estimation Tools for Continuous Diagnostic Tests in R - Journal of Statistical Software, https://www.jstatsoft.org/article/view/v082i04/1177</li>
<li>Model Evaluation with Weighted Threshold Optimization (and the “mewto” R package) - SSRN, https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID3805911_code4597536.pdf?abstractid=3805911&amp;mirid=1&amp;type=2</li>
<li>What Is AI Model Training &amp; Why Is It Important? - Oracle, https://www.oracle.com/artificial-intelligence/ai-model-training/</li>
<li>Otsu’s method - Wikipedia, <a href="https://en.wikipedia.org/wiki/Otsu&#x27;s_method">https://en.wikipedia.org/wiki/Otsu%27s_method</a></li>
<li>Understanding Otsu’s Method for Image Segmentation | Baeldung on Computer Science, https://www.baeldung.com/cs/otsu-segmentation</li>
<li>otsuthresh - Global histogram threshold using Otsu’s method - MATLAB - MathWorks, https://www.mathworks.com/help/images/ref/otsuthresh.html</li>
<li>Optimum Global Thresholding Using Otsu’s Method - GeeksforGeeks, https://www.geeksforgeeks.org/computer-vision/optimum-global-thresholding-using-otsus-method/</li>
<li>Cost-Sensitive Active Learning for Incomplete Data, http://www.fansmale.com/downloadRAR/publicationPdf/2022CALS(WangMin).pdf</li>
<li>Reduction from Cost-sensitive Ordinal Ranking to Weighted Binary Classification, https://www.csie.ntu.edu.tw/~htlin/paper/doc/redordinal.pdf</li>
<li>Benchmarking Quality-Dependent and Cost-Sensitive Score-Level Multimodal Biometric Fusion Algorithms | UGA-MILAB, https://milab.uga.edu/wp-content/uploads/2022/04/Benchmarking_Quality-Dependent_and_Cost-Sensitive_Score-Level_Multimodal_Biometric_Fusion_Algorithms.pdf</li>
<li>A review on cost-based feature selection algorithms in the various applications of machine learning - Journal of Mahani Mathematical Research, https://jmmrc.uk.ac.ir/article_4871_6c5fc71fee2bf18310e995fffc395f46.pdf</li>
<li>Do LLMs generate test oracles that capture the actual or the expected program behaviour?, https://arxiv.org/html/2410.21136v1</li>
<li>A note on Youden’s J and its cost ratio - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC2959030/</li>
<li>Oracles for Testing Software Timeliness with Uncertainty - ORBilu, https://orbilu.uni.lu/bitstream/10993/36987/1/Wang-STUIOS-TOSEM-Orbi.lu.pdf</li>
<li>
<ol start="4">
<li>The riddle of confidence levels and the levels of significance in the era of artificial intelligence - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC12534097/</li>
</ol>
</li>
<li>Confidence Intervals for Machine Learning - MachineLearningMastery.com, https://machinelearningmastery.com/confidence-intervals-for-machine-learning/</li>
<li>Confidence intervals for binary classification probabilities - Data Science Stack Exchange, https://datascience.stackexchange.com/questions/18919/confidence-intervals-for-binary-classification-probabilities</li>
<li>Non-Linear Scoring Model for Translation Quality Evaluation - arXiv, https://arxiv.org/html/2511.13467v3</li>
<li>Quantifying Flaky Tests to Detect Test Instabilities - Concordia University, http://users.encs.concordia.ca/~pcr/paper/Rehman2019FlakyTestsThesis.pdf</li>
<li>Metrics for Physical Unclonable Functions - mediaTUM, https://mediatum.ub.tum.de/doc/1612868/1612868.pdf</li>
<li>Improved Selectivity Estimation by Combining Knowledge from Sampling and Synopses - VLDB Endowment, https://www.vldb.org/pvldb/vol11/p1016-muller.pdf</li>
<li>An improved catalogue for whole-genome sequencing prediction of bedaquiline resistance in Mycobacterium tuberculosis using a reproducible algorithmic approach - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC12177157/</li>
<li>Non-Linear Scoring Model for Translation Quality Evaluation - arXiv, https://arxiv.org/pdf/2511.13467</li>
<li>ClinAgent: A Five-Layer Architecture for Autonomous Clinical Trial Statistical Programming - medRxiv, https://www.medrxiv.org/content/10.64898/2026.01.09.26343542v1.full.pdf</li>
<li>What is Regression Testing? An In-Depth Guide for 2026 - Leapwork, https://www.leapwork.com/blog/regression-testing</li>
<li>Regression Testing Optimization for ROS-based Autonomous Systems: A Comprehensive Review of Techniques - arXiv, https://arxiv.org/html/2506.16101</li>
<li>How to achieve automated regression testing with AI image processing? - Tencent Cloud, https://www.tencentcloud.com/techpedia/125438</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>