<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2.4.1 결정론적(Deterministic) 출력에서 확률적(Stochastic) 출력으로의 전환</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2.4.1 결정론적(Deterministic) 출력에서 확률적(Stochastic) 출력으로의 전환</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 2. 소프트웨어 테스트에서의 오라클(Oracle) 개념과 AI 시대의 역할</a> / <a href="index.html">2.4 AI 및 LLM(거대 언어 모델) 도입으로 인한 테스트 패러다임의 붕괴</a> / <span>2.4.1 결정론적(Deterministic) 출력에서 확률적(Stochastic) 출력으로의 전환</span></nav>
                </div>
            </header>
            <article>
                <h1>2.4.1 결정론적(Deterministic) 출력에서 확률적(Stochastic) 출력으로의 전환</h1>
<h2>1.  서론: 소프트웨어 엔지니어링의 인식론적 대전환</h2>
<p>소프트웨어 엔지니어링의 역사는 예측 가능성(Predictability)과 제어(Control)를 확보하기 위한 투쟁의 기록이었다. 폰 노이만(Von Neumann) 아키텍처가 정립된 이래, 컴퓨터 프로그램은 명확한 입력(Input)에 대해 사전 정의된 로직을 수행하고, 언제나 동일한 출력(Output)을 반환하는 결정론적 기계(Deterministic Machine)로 간주되었다. 이러한 결정론적 패러다임 하에서 소프트웨어 품질 보증(QA)은 “기대 결과(Expected Result)“와 “실제 결과(Actual Result)“의 일치 여부를 확인하는 이진적 판별 과정이었다. <code>assert(calculate_total(100, 0.1) == 110)</code>과 같은 단위 테스트 코드는 이러한 세계관을 상징한다. 여기서 오류란 시스템의 버그이며, 제거되어야 할 대상이었다.</p>
<p>그러나 제미나이(Gemini)와 같은 대규모 언어 모델(Large Language Model, LLM)의 등장은 이 견고한 패러다임을 뿌리째 뒤흔들고 있다. 생성형 AI 시스템은 본질적으로 확률적(Stochastic)이다. 동일한 프롬프트를 입력하더라도 모델은 내부의 확률 분포와 샘플링 전략, 그리고 하드웨어 수준의 미세한 연산 차이로 인해 매번 다른 응답을 생성할 수 있다. 이는 단순한 기능적 차이를 넘어, 시스템을 설계하고 검증하며 유지보수하는 엔지니어링 방법론 전체의 재구성을 요구한다. 개발자는 이제 “정답이 무엇인가?“라는 질문 대신 “이 출력이 타당한 범주 내에 있는가?” 혹은 “출력의 분포가 얼마나 일관적인가?“라는 통계적 질문을 던져야 한다.</p>
<p>이 장에서는 결정론적 세계에서 확률적 세계로의 전환이 갖는 기술적, 철학적 의미를 심층 분석한다. 우리는 먼저 LLM이 왜 필연적으로 비결정론적일 수밖에 없는지 그 기술적 기원을 탐구하고, 이로 인해 발생하는 ’오라클 문제(The Oracle Problem)’의 실체를 규명할 것이다. 나아가, 이러한 불확실성을 통제하고 신뢰할 수 있는 시스템을 구축하기 위해 학계와 산업계가 고안해 낸 메타모픽 테스트(Metamorphic Testing), 자기 일관성(Self-Consistency), LLM-as-a-Judge와 같은 새로운 검증 방법론을 상세히 다룰 것이다.</p>
<h2>2.  비결정론(Non-Determinism)의 기술적 심층 분석</h2>
<p>LLM 기반 애플리케이션에서 관찰되는 비결정론은 단순히 ’무작위성’을 의미하지 않는다. 이는 모델의 학습 방식, 추론(Inference) 과정의 수학적 원리, 그리고 이를 연산하는 물리적 하드웨어의 특성이 복합적으로 상호작용한 결과다. 이를 이해하기 위해서는 소프트웨어 레이어부터 하드웨어 레이어까지 수직적인 기술 분석이 필요하다.</p>
<h3>2.1  자기회귀적 생성(Autoregressive Generation)과 확률 분포</h3>
<p>LLM의 텍스트 생성 과정은 근본적으로 ’다음 토큰 예측(Next-Token Prediction)’의 연쇄다. 모델은 주어진 문맥(Context) <span class="math math-inline">C</span>에 대해 어휘 사전(Vocabulary) <span class="math math-inline">V</span>에 존재하는 모든 토큰 <span class="math math-inline">x</span>의 등장 확률 <span class="math math-inline">P(x|C)</span>를 계산한다. 이 과정은 다음과 같은 단계를 거친다.</p>
<ol>
<li><strong>인코딩(Encoding):</strong> 입력된 텍스트는 토큰화되어 벡터로 변환되고, 트랜스포머(Transformer) 네트워크를 통과하며 고차원의 특징 공간에 매핑된다.</li>
<li><strong>로짓(Logits) 계산:</strong> 모델의 마지막 레이어는 각 토큰에 대한 로짓(Logit) 값을 출력한다. 로짓은 정규화되지 않은 점수로, 각 토큰이 다음에 올 가능성을 수치화한 것이다.</li>
<li><strong>소프트맥스(Softmax) 변환:</strong> 로짓 값들은 소프트맥스 함수를 통해 확률 분포로 변환된다. 이때 모든 토큰의 확률 합은 1이 된다.</li>
<li><strong>샘플링(Sampling):</strong> 계산된 확률 분포에서 다음 토큰을 선택한다.</li>
</ol>
<p>여기서 결정적인 차이는 <strong>샘플링</strong> 단계에서 발생한다. 전통적인 분류 모델(Classification Model)은 가장 높은 확률을 가진 클래스를 정답으로 선택하지만, 생성 모델은 다양성과 창의성을 위해 확률적 샘플링을 수행한다. “사과는“이라는 입력 뒤에 “맛있다(60%)”, “빨갛다(30%)”, “과일이다(10%)“라는 확률이 나왔을 때, 30%나 10%의 확률을 가진 토큰이 선택될 수 있는 가능성을 열어두는 것이다. 이 선택이 반복되면서, 초기의 작은 선택 차이가 문장 전체의 의미를 완전히 다른 방향으로 이끄는 **나비 효과(Butterfly Effect)**가 발생한다. 이를 ’연쇄 효과(Cascade Effect)’라고도 하며, 3번째 토큰의 변화가 10번째 토큰의 문맥을 바꾸고, 이것이 100번째 토큰의 결과물을 완전히 다르게 만드는 현상을 설명한다.</p>
<h3>2.2  하이퍼파라미터에 의한 확률 조작: Temperature와 Top-p</h3>
<p>개발자는 <code>Temperature</code>, <code>Top-k</code>, <code>Top-p</code>와 같은 하이퍼파라미터를 통해 이 확률적 과정을 제어하려 시도한다. 이들의 작동 원리를 깊이 이해하는 것은 확률적 출력을 관리하는 첫걸음이다.</p>
<ul>
<li><strong>Temperature (온도):</strong> 이 파라미터는 확률 분포의 형태(Shape)를 변형시킨다. 수식적으로는 소프트맥스 함수 적용 전 로짓 값을 <span class="math math-inline">T</span>로 나누는 연산이다 (<span class="math math-inline">z_i / T</span>).</li>
<li><span class="math math-inline">T &lt; 1</span> (저온): 분포가 뾰족해진다(Sharpening). 1등 토큰과 2등 토큰의 확률 차이가 극대화되어, 모델은 더욱 보수적이고 결정론적인 선택을 하게 된다. 사실적 정보 전달이나 코드 생성과 같이 정확성이 요구되는 작업에 적합하다.</li>
<li><span class="math math-inline">T &gt; 1</span> (고온): 분포가 평평해진다(Flattening). 모든 토큰의 확률 차이가 줄어들어, 평소라면 선택되지 않았을 낮은 확률의 토큰이 선택될 기회가 늘어난다. 이는 문장의 다양성을 높이지만, 환각(Hallucination)이나 비문 생성의 위험도 함께 증가시킨다.</li>
<li>주의할 점은 <span class="math math-inline">T</span>가 낮다고 해서 0이 아닌 확률을 가진 토큰이 선택될 가능성이 완전히 사라지는 것은 아니라는 점이다.</li>
<li><strong>Top-p (Nucleus Sampling):</strong> 누적 확률 분포를 자르는(Truncation) 방식이다. 확률이 높은 순서대로 토큰을 나열하고, 그 누적 합이 <span class="math math-inline">p</span> (예: 0.95)가 되는 지점에서 후보군을 자른다. 나머지 하위 5%의 토큰은 고려 대상에서 제외된다. 이는 문맥상 전혀 엉뚱한 토큰이 선택되는 것을 방지하면서도, 후보군 내에서는 다양성을 유지하게 한다. Top-p는 후보군의 크기가 분포의 평탄도에 따라 동적으로 변하기 때문에, 고정된 개수를 자르는 Top-k보다 언어의 유연성을 더 잘 반영한다.</li>
</ul>
<h3>2.3  하드웨어의 비결정성: <code>Temperature=0</code>도 안전하지 않다</h3>
<p>많은 엔지니어들이 빠지는 함정 중 하나는 “Temperature를 0으로 설정하면 모델은 100% 결정론적으로 동작할 것“이라는 믿음이다. 이론적으로 <code>Temperature=0</code>은 항상 확률이 가장 높은 단일 토큰만을 선택하는 탐욕적 디코딩(Greedy Decoding)을 강제하므로, 결과가 고정되어야 한다. 그러나 실제 운영 환경, 특히 제미나이와 같은 대규모 클라우드 API 환경에서는 <code>Temperature=0</code> 설정 하에서도 출력의 미세한 변동이 관찰된다.</p>
<p>이 현상의 근본적인 원인은 소프트웨어 알고리즘이 아닌, <strong>GPU 하드웨어의 부동소수점 연산 특성</strong>에 있다.</p>
<ol>
<li><strong>부동소수점의 비결합성(Non-associativity):</strong> 컴퓨터가 실수를 표현하는 부동소수점 방식(IEEE 754 등)은 수학적 실수와 달리 결합 법칙이 성립하지 않는다. 즉, <span class="math math-inline">(a + b) + c</span>의 결과와 <span class="math math-inline">a + (b + c)</span>의 결과가 미세하게 다를 수 있다. 이는 유효숫자의 제한으로 인한 반올림 오차(Rounding Error) 때문이다.</li>
<li><strong>GPU의 병렬 처리와 비결정적 실행 순서:</strong> 딥러닝 모델의 연산, 특히 행렬 곱셈(Matrix Multiplication)은 수천 개의 GPU 코어에서 병렬로 수행된다. 효율성을 극대화하기 위해 GPU 스케줄러는 연산 작업(Warp)을 비동기적으로 분배하며, 각 코어가 작업을 완료하고 결과를 합산(Reduction)하는 순서는 실행 시점의 하드웨어 상태, 온도, 다른 프로세스의 간섭 등에 따라 매번 달라진다.</li>
<li><strong>Atomic Operations의 무작위성:</strong> 병렬 스레드들이 공유 메모리에 값을 더하는 Atomic Add 연산은 경합 조건(Race Condition)을 피하기 위해 순서가 강제되지 않는다. 따라서 덧셈의 순서가 바뀌고, 앞서 언급한 부동소수점 비결합성과 결합하여 최종 합산 결과(Logit 값)에 미세한 차이(Numeric Drift)를 발생시킨다.</li>
</ol>
<p>이 미세한 차이는 대부분 무시할 수 있는 수준이지만, 두 토큰의 확률이 소수점 아래 6~7자리까지 비슷할 정도로 경합하는 상황에서는 순위를 뒤바꿀 수 있다. 1위 토큰과 2위 토큰이 바뀌는 순간, 자기회귀적 특성으로 인해 이후 생성되는 모든 텍스트 경로가 달라지게 된다.</p>
<p>이러한 하드웨어적 한계로 인해, OpenAI나 Google과 같은 LLM 제공자들은 API 문서에서 “대부분 결정론적(mostly deterministic)“이라는 표현을 사용하며, 완전한 재현성을 보장하지 않음을 명시하고 있다.</p>
<h2>3.  오라클 문제(The Oracle Problem)와 테스트 패러다임의 붕괴</h2>
<p>전통적인 소프트웨어 테스트 이론에서 ’오라클(Oracle)’은 테스트 수행 결과가 정확한지 판별하는 메커니즘을 지칭한다.Barr et al. (2014)의 정의에 따르면, 오라클은 입력에 대한 기대 출력(Expected Output)과 실제 출력(Actual Output)을 비교하는 절차다. 결정론적 시스템에서는 이 비교가 명확했다. 입력값 <code>x</code>에 대해 함수 <code>f(x)</code>는 항상 <code>y</code>를 반환해야 했고, <code>y</code>가 아니면 버그였다. 이를 **원자적 오라클(Atomic Oracle)**이라 한다.</p>
<p>그러나 생성형 AI의 확률적 출력은 이 원자적 오라클을 붕괴시킨다. 이를 학계에서는 **오라클 문제(The Oracle Problem)**라 부르며, 특히 LLM 환경에서 더욱 심각하게 대두되고 있다.</p>
<h3>3.1  정확성(Correctness)에서 타당성(Plausibility)으로의 이동</h3>
<p>제미나이에게 “창의적인 마케팅 슬로건을 작성하라“고 요청했을 때, 정답은 존재하지 않는다. “혁신을 경험하세요“도 정답일 수 있고, “미래를 만나는 방법“도 정답일 수 있다. 심지어 “대한민국의 수도는 어디인가?“와 같은 사실적 질문조차 모델은 “서울”, “서울입니다”, “대한민국의 수도는 서울입니다”, “Seoul” 등 다양한 형태로 답할 수 있다.</p>
<p>이러한 맥락에서 기존의 **정확한 문자열 매칭(Exact String Matching)**이나 <strong>정규 표현식(Regular Expression)</strong> 기반의 테스트는 무용지물이 된다. 테스트가 실패했을 때, 이것이 모델의 오류인지 아니면 단순히 표현의 다양성인지 구분할 수 없기 때문이다. 따라서 평가의 기준은 ’정확성(Correctness)’이라는 이진적 척도에서 ‘타당성(Plausibility)’, ‘일관성(Consistency)’, ’유용성(Utility)’과 같은 스펙트럼적 척도로 이동해야 한다.</p>
<h3>3.2  오라클의 유형 변화: 원자적 오라클에서 집계형 오라클로</h3>
<p>최근 연구들은 LLM 테스트를 위해 오라클의 개념을 확장하고 있다. 원자적 오라클이 단일 실행(Single Execution)의 결과를 검증한다면, **집계형 오라클(Aggregated Oracle)**은 다수 실행(Multiple Executions)의 결과 분포를 검증한다.</p>
<ul>
<li><strong>원자적 오라클의 한계:</strong> 확률적 시스템에서 단 한 번의 실행 결과로 전체 시스템의 품질을 판단하는 것은 통계적으로 유의미하지 않다. 운 좋게 정답을 맞혔거나, 운 나쁘게 오답을 냈을 가능성을 배제할 수 없기 때문이다.</li>
<li><strong>집계형 오라클의 필요성:</strong> 동일한 입력에 대해 시스템을 100번 실행했을 때, 95번 이상 정답 범주에 속하는 출력을 내는지를 확인해야 한다. 이는 시스템의 신뢰성을 ’확률’로 정의하는 것이다. 예를 들어, “이 모델은 95% 신뢰수준에서 정확한 SQL 쿼리를 생성한다“라고 명시하는 것이 “이 모델은 정확한 SQL 쿼리를 생성한다“라고 말하는 것보다 엔지니어링적으로 훨씬 정직하고 정확한 표현이다.</li>
</ul>
<table><thead><tr><th><strong>특성</strong></th><th><strong>원자적 오라클 (Atomic Oracle)</strong></th><th><strong>집계형 오라클 (Aggregated Oracle)</strong></th></tr></thead><tbody>
<tr><td><strong>검증 대상</strong></td><td>단일 실행 결과 (Single Run)</td><td>다수 실행 결과의 통계적 분포 (Distribution)</td></tr>
<tr><td><strong>판단 기준</strong></td><td>정확한 값의 일치 여부 (Equality)</td><td>결과의 분산, 빈도, 합의(Consensus)</td></tr>
<tr><td><strong>적합한 시스템</strong></td><td>결정론적 알고리즘, 수학 연산</td><td>LLM, 확률적 최적화, 강화학습 에이전트</td></tr>
<tr><td><strong>구현 비용</strong></td><td>낮음 (단순 비교)</td><td>높음 (다수 실행 및 통계 분석 필요)</td></tr>
<tr><td><strong>주요 메트릭</strong></td><td>Pass/Fail</td><td>Pass Rate@k, Consistency Score, Incoherence</td></tr>
</tbody></table>
<h3>3.3  프롬프트 변동성과 인과적 불확실성</h3>
<p>오라클 문제를 더욱 복잡하게 만드는 것은 프롬프트의 미세한 변화가 결과에 미치는 영향, 즉 **프롬프트 민감성(Prompt Sensitivity)**이다. “요약해줘“와 “다음 글을 요약해줘“라는 의미상 동일한 요청이 전혀 다른 품질의 결과를 낳을 수 있다. 이는 개발자가 입력(프롬프트)과 출력(응답) 사이의 인과관계를 명확히 추론할 수 없게 만든다. Barr et al. (2014)가 정의한 확률적 오라클은 주로 시스템 내부의 무작위성을 다루었으나, LLM 시대의 오라클은 사용자 입력의 모호성까지 처리해야 하는 이중고를 겪고 있다.</p>
<p>이러한 불확실성은 기존의 회귀 테스트(Regression Test)를 어렵게 만든다. 모델 업데이트 후 테스트가 실패했을 때, 이것이 모델 성능 저하 때문인지, 프롬프트가 새로운 모델과 맞지 않아서인지, 아니면 단순히 확률적 변동 때문인지 파악하기 어렵기 때문이다. 이를 해결하기 위해서는 단순한 결과 비교를 넘어선 새로운 차원의 테스트 방법론이 필요하다.</p>
<h2>4.  새로운 테스트 패러다임과 검증 방법론</h2>
<p>확률적 출력을 통제하고 신뢰할 수 있는 시스템을 구축하기 위해, 엔지니어링 커뮤니티는 기존의 테스트 기법을 재해석하거나 완전히 새로운 방법론을 도입하고 있다.</p>
<h3>4.1  메타모픽 테스트(Metamorphic Testing): 정답이 없어도 검증 가능하다</h3>
<p>메타모픽 테스트는 오라클 문제를 해결하기 위해 고안된 가장 유망한 기법 중 하나다. 이 기법의 핵심은 ’정답’을 몰라도 ’관계’는 검증할 수 있다는 점이다. 입력값의 변화에 따른 출력값의 변화 관계, 즉 **메타모픽 관계(Metamorphic Relation, MR)**를 정의하여 테스트를 수행한다.</p>
<ul>
<li><strong>메타모픽 관계의 예시:</strong></li>
<li><strong>패러프레이징(Paraphrasing) 불변성:</strong> 입력 문장을 의미가 같은 다른 문장으로 바꾸었을 때(예: “나는 사과를 좋아해” <span class="math math-inline">\rightarrow</span> “사과는 내가 좋아하는 과일이야”), 감정 분석 모델의 결과나 요약 모델의 핵심 내용은 변하지 않아야 한다. 만약 결과가 긍정에서 부정으로 바뀐다면, 정답 레이블이 없더라도 모델에 결함이 있음을 알 수 있다.</li>
<li><strong>순서 불변성(Permutation Invariance):</strong> 뉴스 기사의 순서를 섞어서 요약을 요청했을 때, 요약된 결과의 사실 관계는 변하지 않아야 한다.</li>
<li><strong>부분집합 성질(Subset Property):</strong> 긴 문서에서 특정 정보를 검색할 때, 해당 정보가 포함된 문단만을 입력으로 주었을 때도 동일한 정보를 찾아내야 한다.</li>
<li><strong>장점과 한계:</strong> 메타모픽 테스트는 값비싼 인간 레이블링 데이터 없이도 대량의 테스트 케이스를 자동으로 생성할 수 있다는 강력한 장점이 있다. 특히 LLM의 강건성(Robustness)과 일관성을 평가하는 데 매우 효과적이다. 그러나 유효한 메타모픽 관계를 정의하는 것 자체가 도메인 지식을 요하며, 모든 오류 유형을 잡아낼 수는 없다는 한계가 있다.</li>
</ul>
<h3>4.2  LLM-as-a-Judge: AI로 AI를 평가하다</h3>
<p>가장 현실적이고 널리 채택되는 대안은 <strong>LLM-as-a-Judge(심판으로서의 LLM)</strong> 기법이다. 이는 고성능 LLM(예: GPT-4, Gemini Ultra)을 평가자로 활용하여, 다른 LLM(주로 더 작거나 특화된 모델)의 출력을 채점하는 방식이다.</p>
<ul>
<li><strong>작동 원리:</strong> 평가자 모델에게 “다음 텍스트가 주어진 기준(정확성, 유창성, 안전성 등)을 얼마나 잘 충족하는지 1점에서 5점 사이로 평가하고 그 이유를 설명하라“는 상세한 지침(Rubric)을 프롬프트로 제공한다.</li>
<li><strong>골든 데이터셋(Golden Dataset)과의 결합:</strong> 평가의 신뢰도를 높이기 위해, 단순한 입력뿐만 아니라 모범 답안(Ideal Answer)과 필수 포함 요소(Criteria)가 포함된 ’골든 데이터셋’을 구축하여 비교 기준으로 삼는다. LLM 심판은 생성된 답변이 골든 데이터셋의 모범 답안과 의미적으로 얼마나 유사한지 판단한다.</li>
<li><strong>신뢰도와 편향:</strong> 연구에 따르면, 잘 튜닝된 LLM 심판은 인간 평가자와 80% 이상의 일치도를 보일 수 있다. 그러나 LLM 심판 역시 편향(Bias)을 가질 수 있다. 예를 들어, 자신이 생성한 것과 유사한 스타일의 문장을 선호하거나(Self-Preference Bias), 긴 답변을 무조건 좋게 평가하는 경향(Verbosity Bias)이 있다. 이를 보정하기 위해 쌍대 비교(Pairwise Comparison)나 평가 기준의 무작위 섞기(Shuffling) 등의 기법이 활용된다.</li>
</ul>
<h3>4.3  자기 일관성(Self-Consistency)과 비일관성(Incoherence) 지표</h3>
<p>정답이 없는 상황에서 모델의 확신 수준을 측정하고 오류를 탐지하기 위해 <strong>자기 일관성(Self-Consistency)</strong> 개념이 도입되었다. 이는 “진실은 일관되지만, 거짓은 무작위적이다“라는 직관에 기반한다.</p>
<ul>
<li><strong>다수결 투표(Majority Voting)와 Sampling:</strong> 동일한 프롬프트에 대해 모델을 여러 번(예: 5~10회, <span class="math math-inline">k</span>번) 실행시켜 다양한 추론 경로(Reasoning Path)를 탐색하게 한다. 수학 문제나 코딩과 같이 정답이 명확한 경우, 가장 빈번하게 등장한 답안(Mode)을 최종 결과로 채택함으로써 단일 실행 대비 정확도를 획기적으로 높일 수 있다.</li>
<li><strong>비일관성(Incoherence) 측정:</strong> 최근 연구에서는 모델의 오류 가능성을 추정하기 위한 공식적인 지표로 ’비일관성’을 제안한다. 비일관성은 독립적으로 생성된 두 개의 프로그램이나 답변이 기능적으로 다른 동작을 할 확률로 정의된다.</li>
<li><strong>이론적 배경:</strong> 연구에 따르면 비일관성 지표(<span class="math math-inline">I(d)</span>)는 실제 오류율(<span class="math math-inline">E(d)</span>)의 하한선(Lower Bound)을 제공한다 (<span class="math math-inline">I(d) \leq 2E(d)</span>). 즉, 오라클 없이 모델끼리의 불일치만 측정해도, 실제 오류가 얼마나 발생할지 예측할 수 있다는 것이다.</li>
<li><strong>실증적 효과:</strong> 16개의 최신 LLM을 대상으로 한 실험에서, 비일관성 지표는 약 2/3의 오류를 오라클 없이 자동으로 탐지해 냈다. 이는 정답 데이터셋(Ground Truth)이 없는 실제 운영 환경에서 모델의 신뢰성을 모니터링하는 핵심 지표로 활용될 수 있다.</li>
</ul>
<h2>5.  결론: 확률을 수용하는 엔지니어링 마인드셋</h2>
<p>제미나이와 같은 LLM을 활용하여 서적 집필 시스템을 구축하는 과정은 결정론적 세계에서 확률적 세계로의 이주를 의미한다. 이는 단순한 도구의 변화가 아니라, 시스템을 바라보는 관점의 근본적인 변화다. 개발자는 이제 코드가 항상 같은 결과를 낼 것이라는 기대를 버리고, <strong>출력의 분포를 관리하고 리스크를 완화하는 설계</strong>에 집중해야 한다.</p>
<p>우리는 하드웨어의 미세한 비결정성이 나비 효과를 일으켜 출력의 다양성을 만든다는 것을 이해했다. 또한 오라클 문제로 인해 전통적인 테스트가 붕괴되었음을 확인하고, 이를 극복하기 위한 대안으로 메타모픽 테스트, LLM-as-a-Judge, 그리고 자기 일관성 기법을 살펴보았다.</p>
<p>결정론적 정확성을 포기하는 대신, 우리는 창의성과 유연성이라는 더 큰 가치를 얻게 된다. 확률적 출력을 통제 가능한 범위 내에 두고, 이를 시스템의 강점으로 승화시키는 것이야말로 AI 엔지니어링의 본질이자 미래다. 다음 장에서는 이러한 확률적 검증 기법을 실제 파이프라인(CI/CD)에 어떻게 통합할 수 있는지 구체적인 MLOps 전략을 다룰 것이다.</p>
<table><thead><tr><th><strong>구분</strong></th><th><strong>결정론적 소프트웨어 (Traditional)</strong></th><th><strong>확률적 AI 소프트웨어 (GenAI)</strong></th></tr></thead><tbody>
<tr><td><strong>핵심 원리</strong></td><td>논리적 연산, 고정된 규칙</td><td>확률적 생성, 통계적 분포</td></tr>
<tr><td><strong>실행 특성</strong></td><td>재현 가능성 (Reproducibility) 100%</td><td>통계적 일관성, 하드웨어 비결정성 존재</td></tr>
<tr><td><strong>테스트 오라클</strong></td><td>정확한 값 비교 (Assert Equal, Atomic)</td><td>의미적 유사성, 속성 검증, 집계형 오라클</td></tr>
<tr><td><strong>주요 실패 원인</strong></td><td>논리 오류, 예외 처리 미비</td><td>환각(Hallucination), 프롬프트 민감성, 확률적 드리프트</td></tr>
<tr><td><strong>품질 보증 전략</strong></td><td>단위 테스트, 통합 테스트</td><td>LLM-as-a-Judge, 골든 데이터셋, 메타모픽 테스트, 자기 일관성</td></tr>
</tbody></table>
<h2>6. 참고 자료</h2>
<ol>
<li>What is the difference between a deterministic and stochastic policy?, https://milvus.io/ai-quick-reference/what-is-the-difference-between-a-deterministic-and-stochastic-policy</li>
<li>AI and Deterministic Testing - Medium, https://medium.com/nerd-for-tech/ai-and-deterministic-testing-1be8d1a0348a</li>
<li>Stochastic vs. Deterministic Optimization: A Comparative Analysis, https://www.ijesi.org/papers/Vol(14)i5/14057782.pdf</li>
<li>Deterministic vs Stochastic Environment in AI - GeeksforGeeks, https://www.geeksforgeeks.org/artificial-intelligence/deterministic-vs-stochastic-environment-in-ai/</li>
<li>Why is deterministic output from LLMs nearly impossible? - Unstract, https://unstract.com/blog/understanding-why-deterministic-output-from-llms-is-nearly-impossible/</li>
<li>Creating Deterministic, Consistent and Reproducible text in LLMs, https://pub.aimind.so/creating-deterministic-consistent-and-reproducible-text-in-llms-e589ba230d44</li>
<li>LLM Sampling: Temperature, Top-K, Top-P, and Min-P Explained, https://www.letsdatascience.com/blog/llm-sampling-temperature-top-k-top-p-and-min-p-explained</li>
<li>Complete Guide to Prompt Engineering with Temperature and Top-p, https://promptengineering.org/prompt-engineering-with-temperature-and-top-p/</li>
<li>Token Probabilities Expose Large Language Model Nondeterminism, https://arxiv.org/html/2601.06118v1</li>
<li>Impacts of floating-point non-associativity on reproducibility for HPC, https://www.osti.gov/servlets/purl/2538294</li>
<li>Solving Reproducibility Challenges in Deep Learning and LLMs, https://www.ingonyama.com/post/solving-reproducibility-challenges-in-deep-learning-and-llms-our-journey</li>
<li>[PDF] The Impact of Nondeterminism on Reproducibility in Deep, https://www.semanticscholar.org/paper/The-Impact-of-Nondeterminism-on-Reproducibility-in-Nagarajan-Warnell/c12afa35f740558c34b5903ac4601eb0b562660a</li>
<li>Non-Determinism in TensorFlow ResNets - arXiv, https://arxiv.org/pdf/2001.11396</li>
<li>The Oracle Problem in Software Testing: A Survey - Earl Barr, https://earlbarr.com/publications/testoracles.pdf</li>
<li>understanding the oracle problem and automated test case generation, https://www.researchgate.net/publication/380028105_UNDERSTANDING_THE_ORACLE_PROBLEM_AND_AUTOMATED_TEST_CASE_GENERATION_A_COMPARATIVE_SURVEY</li>
<li>Challenges in Testing Large Language Model Based Software - arXiv, https://arxiv.org/html/2503.00481v2</li>
<li>The Challenges of Testing in a Non-Deterministic World, https://www.sei.cmu.edu/blog/the-challenges-of-testing-in-a-non-deterministic-world/</li>
<li>(PDF) Metamorphic Testing of Large Language Models for Natural, https://www.researchgate.net/publication/394085166_Metamorphic_Testing_of_Large_Language_Models_for_Natural_Language_Processing</li>
<li>Metamorphic Testing of Large Language Models for Natural … - arXiv, https://arxiv.org/html/2511.02108v1</li>
<li>Metamorphic Testing of Large Language Models for Natural, https://valerio-terragni.github.io/assets/pdf/cho-icsme-2025.pdf</li>
<li>Towards Generating Executable Metamorphic Relations … - ORBilu, https://orbilu.uni.lu/handle/10993/61576</li>
<li>How to test Machine Learning Models? Metamorphic testing - Giskard, https://www.giskard.ai/knowledge/how-to-test-ml-models-4-metamorphic-testing</li>
<li>A Comprehensive Guide to LLM Evaluations - Caylent, https://caylent.com/blog/a-comprehensive-guide-to-llm-evaluations</li>
<li>Primers • LLM-as-a-Judge / Autoraters - aman.ai, https://aman.ai/primers/ai/LLM-as-a-judge/</li>
<li>What Is a Golden Dataset in AI and Why Does It Matter? - DAC.digital, https://dac.digital/what-is-a-golden-dataset/</li>
<li>Arena G-Eval vs Single-Output “LLM-as-a-judge” — Case Study, https://medium.com/@jolalf/arena-g-eval-vs-single-output-llm-as-a-judge-case-study-43c86fe0f1c9</li>
<li>Confidence Improves Self-Consistency in LLMs - arXiv, https://arxiv.org/html/2502.06233v1</li>
<li>Consistency Meets Verification: Enhancing Test Generation Quality, https://arxiv.org/html/2602.10522v1</li>
<li>Incoherence as Oracle-less Measure of Error in LLM-Based Code, https://mpi-softsec.github.io/papers/AAAI26-incoherence.pdf</li>
<li>Estimating Correctness Without Oracles in LLM-Based Code … - arXiv, https://arxiv.org/html/2507.00057v1</li>
<li>Incoherence as Oracle-less Measure of Error in LLM-Based Code, https://arxiv.org/html/2507.00057v2</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>