<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:1.3.2 확률적 AI 출력의 본질적 결함: 환각(Hallucination)과 창의성 사이의 모호한 경계</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>1.3.2 확률적 AI 출력의 본질적 결함: 환각(Hallucination)과 창의성 사이의 모호한 경계</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 1. AI 기반 소프트웨어 개발의 패러다임 변화와 비결정성(Nondeterminism)의 한계</a> / <a href="index.html">1.3 결정론적(Deterministic) 시스템 vs 확률적(Probabilistic) 시스템의 충돌</a> / <span>1.3.2 확률적 AI 출력의 본질적 결함: 환각(Hallucination)과 창의성 사이의 모호한 경계</span></nav>
                </div>
            </header>
            <article>
                <h1>1.3.2 확률적 AI 출력의 본질적 결함: 환각(Hallucination)과 창의성 사이의 모호한 경계</h1>
<p>소프트웨어 엔지니어링의 역사는 결정론적(Deterministic) 정합성을 확보하기 위한 끊임없는 투쟁이었다. 입력값이 동일하면 출력값도 반드시 동일해야 한다는 이 원칙은 컴파일러, 운영체제, 그리고 비즈니스 로직의 근간을 이룬다. 그러나 거대 언어 모델(Large Language Models, LLMs)이 도입되면서 개발 패러다임은 확률적(Probabilistic) 시스템으로 급격히 선회했다. 이러한 전환의 중심에는 ’환각(Hallucination)’이라는 치명적인 결함이 존재하며, 이는 아이러니하게도 모델의 가장 강력한 무기인 ’창의성(Creativity)’과 기술적으로 동일한 뿌리를 공유한다. 엔터프라이즈 환경에서 AI 기반 개발 도구를 신뢰하기 위해서는 이 모호한 경계의 본질을 수학적, 공학적 관점에서 철저히 해부해야 한다.</p>
<h2>1. 확률적 생성 엔진의 기저와 환각의 정의</h2>
<p>현대 언어 모델의 핵심인 트랜스포머(Transformer) 아키텍처는 사실(Fact)을 저장하는 데이터베이스가 아니라, 문맥에 따라 다음에 올 토큰(Token)의 확률 분포를 예측하는 통계적 엔진이다. 모델은 학습 데이터 세트에서 관찰된 패턴을 바탕으로 “가장 그럴듯한(Plausible)” 문자열을 생성하는데, 이 과정에서 발생하는 사실과의 괴리를 환각이라 정의한다.</p>
<p>학계에서는 환각을 크게 두 가지 축으로 분류한다. “Survey of Hallucination in Natural Language Generation“에 따르면, 환각은 입력 정보와의 모순 여부에 따라 내재적 환각과 외재적 환각으로 나뉜다.</p>
<table><thead><tr><th><strong>환각 유형</strong></th><th><strong>정의</strong></th><th><strong>특징</strong></th><th><strong>소프트웨어 개발에서의 예시</strong></th></tr></thead><tbody>
<tr><td>내재적 환각 (Intrinsic)</td><td>제공된 입력 문맥이나 소스 문서와 직접적으로 충동하는 출력을 생성하는 현상</td><td>논리적 모순 및 문맥 무시</td><td>앞서 정의한 변수명을 무시하고 새로운 변수 사용</td></tr>
<tr><td>외재적 환각 (Extrinsic)</td><td>입력 정보에는 없으나 실제 세계의 사실이나 상식에 어긋나는 정보를 생성하는 현상</td><td>검증 불가능한 허구의 사실 생성</td><td>존재하지 않는 라이브러리 함수 호출 제안</td></tr>
</tbody></table>
<p>이러한 환각은 단순히 모델의 성능 부족이 아니라, “Stochastic Parrots“라 불리는 확률적 생성 모델의 구조적 한계에서 기인한다. 모델은 문장의 의미를 이해하는 것이 아니라, 통계적으로 높은 확률을 가진 토큰들의 조합을 찾아낼 뿐이며, 이 과정에서 ’정확성’보다 ’유창성’이 우선시되는 경향이 있다.</p>
<h2>2. 환각과 창의성의 수학적 이중성</h2>
<p>AI 모델에서 환각과 창의성은 별개의 현상이 아니다. 이들은 모델이 예측하는 토큰 분포의 엔트로피(Entropy)라는 동일한 수학적 공간에서 공존한다. “A Mathematical Investigation of Hallucination and Creativity in GPT Models“에 따르면, 모델의 불확실성은 다음과 같은 엔트로피 공식으로 정량화된다.<br />
<span class="math math-display">
H(x_{i+1} \vert x_1, x_2, \dots, x_i; \Theta) = - \sum_{x \in V} p(x \vert x_1, x_2, \dots, x_i; \Theta) \log p(x \vert x_1, x_2, \dots, x_i; \Theta)
</span><br />
여기서 <span class="math math-inline">H</span>는 다음 토큰 예측의 불확실성을 나타낸다. 엔트로피가 높다는 것은 모델이 다음에 올 토큰을 확신하지 못하고 여러 가능성을 열어두고 있음을 의미한다. 예술적 작문이나 아이디어 브레인스토밍에서 이 불확실성은 ’다양성’과 ’창의성’으로 변모하지만, 엄밀한 구문과 논리가 요구되는 코딩 작업에서는 ’환각’과 ’오류’로 이어진다.</p>
<p>모델의 성능을 최적화하기 위한 목적 함수 <span class="math math-inline">J(\Theta, \alpha)</span>는 환각 최소화와 창의성 최대화 사이의 피할 수 없는 트레이드오프를 보여준다.<br />
<span class="math math-display">
J(\Theta, \alpha) = (1 - \alpha) \cdot J_{hallucination}(\Theta) - \alpha \cdot J_{creativity}(\Theta)
</span><br />
이 식에서 파라미터 <span class="math math-inline">\alpha</span>는 모델이 어느 쪽에 더 무게를 둘지를 결정한다. <span class="math math-inline">\alpha</span>가 0에 수렴할수록 모델은 극도로 보수적이고 사실적인 답변만을 내놓으며, 1에 수렴할수록 극도로 분산된, 즉 창의적이지만 위험한 답변을 생성한다. 소프트웨어 개발에서 결정론적 오라클을 구축한다는 것은 기술적으로 이 <span class="math math-inline">\alpha</span> 값을 제어하고, 모델이 생성한 ’창의적 시도’가 ’환각적 오류’가 되지 않도록 검증 경계를 세우는 작업이다.</p>
<h2>3. 확률 분포의 제어: Temperature와 Nucleus Sampling의 공학적 영향</h2>
<p>개발자는 추론(Inference) 단계에서 Temperature(<span class="math math-inline">T</span>)와 Top-p(Nucleus Sampling) 파라미터를 통해 환각과 창의성의 경계를 조절한다. 이 설정은 소프트맥스(Softmax) 함수를 통과하는 로짓(Logits)의 분포를 변형시킨다.</p>
<h3>3.1 Temperature(<span class="math math-inline">T</span>)의 역할과 코드 정합성</h3>
<p>Temperature는 확률 분포의 첨도(Kurtosis)를 조절하는 역할을 수행한다.<br />
<span class="math math-display">
P(x_i) = \frac{\exp(z_i / T)}{\sum_j \exp(z_j / T)}
</span><br />
<span class="math math-inline">T</span>가 1보다 작아지면 상위 토큰의 확률이 증폭되어 모델은 더욱 결정론적으로 변한다. 반면 <span class="math math-inline">T</span>가 1보다 커지면 분포가 평탄해지며 낮은 확률의 토큰이 선택될 기회가 많아진다.</p>
<table><thead><tr><th><strong>Temperature 값</strong></th><th><strong>확률 분포 특성</strong></th><th><strong>소프트웨어 엔지니어링에 미치는 영향</strong></th><th><strong>환각 발생 가능성</strong></th></tr></thead><tbody>
<tr><td><span class="math math-inline">T \to 0</span></td><td>결정론적(Greedy)</td><td>동일 입력에 대해 항상 동일 출력. 유닛 테스트 및 구조화된 데이터 추출에 적합.</td><td>최저 (하지만 학습 데이터의 편향은 강화됨)</td></tr>
<tr><td><span class="math math-inline">0.1 \sim 0.3</span></td><td>보수적</td><td>코드 구문 오류가 적고 논리적 일관성이 높음.</td><td>낮음</td></tr>
<tr><td><span class="math math-inline">0.7 \sim 0.9</span></td><td>균형적</td><td>일반적인 대화 및 요약에 적합하나, 코딩 시 존재하지 않는 API를 호출할 위험 증가.</td><td>중간</td></tr>
<tr><td><span class="math math-inline">T \ge 1.0</span></td><td>무작위적</td><td>창의적 알고리즘 제안에는 유리하나, 컴파일 가능한 코드를 얻기 어려움.</td><td>매우 높음</td></tr>
</tbody></table>
<p>실제 실험에 따르면, <span class="math math-inline">T=0.7</span>의 기본 설정을 사용할 경우 <span class="math math-inline">T=0</span>일 때보다 유효한 함수를 생성하는 비용이 최대 67%까지 증가하는데, 이는 환각으로 인한 재시도(Retry) 비용이 발생하기 때문이다.</p>
<h3>3.2 Top-p(Nucleus Sampling)를 통한 동적 필터링</h3>
<p>Top-p는 누적 확률이 임계값 <span class="math math-inline">p</span>를 넘는 토큰들만 샘플링 후보에 포함시킨다. 이는 모델이 특정 지점에서 확신이 없을 때만 선택 범위를 넓히도록 유도한다. 그러나 코딩 환경에서 <span class="math math-inline">p</span> 값을 높게 설정하면, 문맥상 그럴싸해 보이지만 실제로는 존재하지 않는 라이브러리 이름을 ‘핵심(Nucleus)’ 후보에 포함시킬 위험이 있다.</p>
<h2>4. 코드 생성에서의 치명적 결함: 패키지 환각(Package Hallucination)</h2>
<p>언어 모델의 확률적 특성이 소프트웨어 공급망 보안에 직접적인 위협을 가하는 사례가 바로 ’패키지 환각’이다. 모델은 학습 데이터에 포함된 수많은 오픈소스 라이브러리의 명명 규칙을 학습한다. 이로 인해 개발자가 특정 기능을 구현해 달라고 요청할 때, 실제로는 존재하지 않지만 마치 실존할 것 같은 이름의 패키지를 설치하라고 제안한다.</p>
<p>“We Have a Package for You: A Comprehensive Analysis of Package Hallucinations” 연구에 따르면, 테스트 과정에서 약 205,474개의 고유한 비실존 패키지 이름이 생성되었다. 더욱 놀라운 점은 이러한 환각이 일회성이 아니라는 것이다. 환각된 패키지의 약 45%는 동일한 프롬프트에 대해 지속적으로 생성되었으며, 이는 공격자가 예측 가능한 환각을 악용할 수 있음을 시사한다.</p>
<p>이 현상의 메커니즘은 다음과 같은 공격 시나리오로 연결된다.</p>
<ol>
<li>공격자는 주요 LLM이 빈번하게 환각하는 패키지 이름을 수집한다.</li>
<li>공격자는 PyPI나 npm과 같은 공식 저장소에 해당 환각된 이름으로 악성 패키지를 등록한다.</li>
<li>AI의 제안을 신뢰한 개발자가 해당 패키지를 설치하는 순간, 기업의 인프라에 백도어가 설치되거나 데이터가 유출된다.</li>
</ol>
<p>이는 확률적 시스템의 결과물을 결정론적 검증 없이 수용했을 때 발생하는 보안 오라클의 붕괴를 단적으로 보여준다.</p>
<h2>5. ‘거의 맞는(Mostly Correct)’ 코드와 엔터프라이즈의 실패</h2>
<p>엔터프라이즈 소프트웨어 개발에서 99%의 정확도는 때때로 0%보다 위험하다. AI가 생성한 코드가 1,000라인 중 900라인이 완벽하고 나머지 10%에서 미세한 논리적 환각을 일으킬 경우, 인간 개발자는 코드가 “대체로 맞다“고 판단하여 세밀한 검증을 소홀히 할 가능성이 크다. 이를 ’Overreliance(과도한 의존)’라 부른다.</p>
<p>특히 복잡한 비즈니스 로직이나 금융 거래와 같이 높은 수치적 정밀도를 요구하는 분야에서, 모델은 문맥 길이가 길어짐에 따라 앞부분의 제약 조건을 잊어버리는 ‘Lost in the Middle’ 현상을 겪는다. 이로 인해 발생하는 미세한 논리적 균열은 단순한 버그를 넘어 시스템 전체의 멱등성(Idempotency)을 파괴하고 데이터 무결성을 훼손한다.</p>
<table><thead><tr><th><strong>결함 유형</strong></th><th><strong>원인</strong></th><th><strong>엔지니어링적 결과</strong></th></tr></thead><tbody>
<tr><td>문맥 소실 (Context Loss)</td><td>긴 문맥에서의 주의력(Attention) 분산</td><td>이전 단계의 상태 정보를 망각하고 모순된 로직 생성</td></tr>
<tr><td>유효성 환각 (Validity Hallucination)</td><td>학습 데이터의 편향 및 통계적 일반화</td><td>문법적으로는 맞으나 존재하지 않는 API 또는 인자(Argument) 사용</td></tr>
<tr><td>추론 오류 (Reasoning Error)</td><td>기호 논리(Symbolic Logic) 처리 능력의 한계</td><td>알고리즘의 엣지 케이스(Edge Case) 처리 실패</td></tr>
</tbody></table>
<h2>6. 년의 연구 전환: 데이터 오류에서 인센티브 구조의 문제로</h2>
<p>최근의 연구는 환각을 단순한 데이터 품질의 문제로 보지 않고, 모델의 학습 및 평가 방식에 내재된 인센티브 구조의 결함으로 파악하기 시작했다. OpenAI의 2025년 연구에 따르면, 현재의 학습 목표(Next-token Objective)와 리더보드 순위 경쟁은 모델로 하여금 ’모른다’고 답하기보다는 ’자신 있게 추측’하도록 장려한다. 모델이 불확실성을 정밀하게 보정(Calibration)하지 못하고 허위 사실을 유창하게 늘어놓는 것은, 그러한 방식이 보상 모델(Reward Model)로부터 더 높은 점수를 받았기 때문이라는 분석이다.</p>
<p>따라서 미래의 오라클 시스템은 모델의 출력 자체뿐만 아니라, 모델의 ’자신감’에 대한 확률적 보정 수치까지 검증 범위에 포함시켜야 한다. “Rewarding Doubt (2025)” 연구에서 제시하듯, 모델이 확신이 없을 때 기권(Abstention)하도록 학습시키는 것이 창의성과 환각의 경계에서 안전을 확보하는 핵심 전략이 될 것이다.</p>
<h2>7. 결론: 확률적 시스템을 다루는 공학적 태도</h2>
<p>환각과 창의성 사이의 모호한 경계는 제거해야 할 ’버그’가 아니라, 거대 언어 모델이라는 도구가 가진 본질적 ’속성’이다. 소프트웨어 개발 프로세스에 AI를 통합하는 엔지니어는 모델이 언제든지 환각을 일으킬 수 있다는 확률적 전제를 수용해야 한다.</p>
<p>창의성은 모델이 학습 데이터의 경계를 넘어 새로운 경로를 탐색할 때 발생하며, 환각은 그 탐색이 사실의 궤도를 벗어날 때 발생한다. 이 둘을 가르는 유일한 기준은 모델 내부에 있는 것이 아니라, 우리가 구축한 결정론적 정답지(Ground Truth)와 실시간 검증 오라클에 있다. 패키지 환각에 대비한 화이트리스트 검증, <span class="math math-inline">T=0</span> 설정을 통한 일관성 확보, 그리고 RAG를 통한 지식의 외부 접지(Grounding)는 확률적 시스템의 결함을 공학적 안전장치로 보완하는 필수적인 단계다.</p>
<p>결국 AI 기반 소프트웨어 개발의 성패는 모델의 창의성을 얼마나 극대화하느냐가 아니라, 그 창의성이 환각의 영역으로 넘어가는 지점을 얼마나 정밀하게 감지하고 차단할 수 있느냐에 달려 있다. 확률적 시스템의 비결정성을 통제하기 위한 결정론적 오라클의 설계는 더 이상 선택이 아닌 필수적인 엔지니어링 표준이 되어야 한다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>AI Hallucinations Explained: Turning Errors into Innovation - Presidio, https://www.presidio.com/technical-blog/ai-hallucinations-explained-turning-errors-into-innovation/</li>
<li>What is LLM Hallucination? Causes &amp; Mitigation - Ultralytics, https://www.ultralytics.com/glossary/hallucination-in-llms</li>
<li>[PDF] Survey of Hallucination in Natural Language Generation, https://www.semanticscholar.org/paper/Survey-of-Hallucination-in-Natural-Language-Ji-Lee/3def68bd0f856886d34272840a7f81588f2bc082</li>
<li>Stop LLM Hallucinations: Reduce Errors by 60–80% - Master of Code, https://masterofcode.com/blog/hallucinations-in-llms-what-you-need-to-know-before-integration</li>
<li>Hallucination in Natural Language Generation - Emergent Mind, https://www.emergentmind.com/topics/hallucination-in-natural-language-generation</li>
<li>Guide to LLM Hallucination Detection in App Development - Comet, https://www.comet.com/site/blog/llm-hallucination/</li>
<li>LLM Hallucinations in 2025: How to Understand and Tackle AI’s, https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models</li>
<li>(PDF) A Mathematical Investigation of Hallucination and Creativity in …, https://www.researchgate.net/publication/370853178_A_Mathematical_Investigation_of_Hallucination_and_Creativity_in_GPT_Models</li>
<li>Temperature and Top-P: The Creativity Knobs - Signal &amp; Syntax, https://tomarcher.io/posts/temperature-top-p-creativity-knobs/</li>
<li>The Temperature Trap: Why Your AI Keeps Giving the Same Wrong, https://dev.to/tawe/the-temperature-trap-why-your-ai-keeps-giving-the-same-wrong-answer-3h88</li>
<li>LLM Temperature - The Secret Sauce to Tuning AI Responses, https://www.projectpro.io/article/llm-temperature/1073</li>
<li>LLM Temperature Setting: Control Randomness &amp; Creativity, https://blog.promptlayer.com/temperature-setting-in-llms/</li>
<li>What is LLM Temperature? - IBM, https://www.ibm.com/think/topics/llm-temperature</li>
<li>Temperature, top_p and top_k for chatbot responses - Prompting, https://community.openai.com/t/temperature-top-p-and-top-k-for-chatbot-responses/295542</li>
<li>2월 15, 2026에 액세스, [https://medium.com/@annie_7775/tech-sketch-temperature-and-top-p-explained-in-plain-english-4d552733b307#:<sub>:text=High%20Temperature%20flattens%20the%20probabilities,must%20be%20monitored%20for%20hallucinations.](https://medium.com/@annie_7775/tech-sketch-temperature-and-top-p-explained-in-plain-english-4d552733b307#:</sub>:text=High Temperature flattens the probabilities, <a href="https://medium.com/@annie_7775/tech-sketch-temperature-and-top-p-explained-in-plain-english-4d552733b307#:~:text=High%20Temperature%20flattens%20the%20probabilities,must%20be%20monitored%20for%20hallucinations.">https://medium.com/@annie_7775/tech-sketch-temperature-and-top-p-explained-in-plain-english-4d552733b307#:~:text=High%20Temperature%20flattens%20the%20probabilities,must%20be%20monitored%20for%20hallucinations.</a></li>
<li>Complete Guide to Prompt Engineering with Temperature and Top-p, https://promptengineering.org/prompt-engineering-with-temperature-and-top-p/</li>
<li>Package Hallucinations: How LLMs Can Invent Vulnerabilities …, https://www.usenix.org/publications/loginonline/we-have-package-you-comprehensive-analysis-package-hallucinations-code</li>
<li>LLM09:2025 Misinformation - OWASP Gen AI Security Project, https://genai.owasp.org/llmrisk/llm092025-misinformation/</li>
<li>LLM Risks: Enterprise Threats and How to Secure Them, https://www.lasso.security/blog/llm-risks-enterprise-threats</li>
<li>7 Practical Techniques to Reduce LLM Hallucinations, https://www.analyticsvidhya.com/blog/2025/09/reducing-hallucinations-in-llms/</li>
<li>Making o1, o3, and Sonnet 3.7 hallucinate for everyone | Hacker News, https://news.ycombinator.com/item?id=43222027</li>
<li>A Benchmark for Hallucination Detection in Financial Long-Context QA, https://openreview.net/pdf?id=5YQAo0S3Hm</li>
<li>Survey of Hallucination in Natural Language Generation, https://www.researchgate.net/publication/365484692_Survey_of_Hallucination_in_Natural_Language_Generation</li>
<li>Unfamiliar Finetuning Examples Control How Language Models, https://www.researchgate.net/publication/392505980_Unfamiliar_Finetuning_Examples_Control_How_Language_Models_Hallucinate</li>
<li>AI risk: 10 pitfalls to avoid when building AI products, https://www.evidentlyai.com/blog/ai-risk</li>
<li>What are LLM Hallucinations? - Software Mind, https://softwaremind.com/blog/llm-hallucinations-definition-examples-and-potential-remedies/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>