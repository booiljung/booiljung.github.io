<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.1.4 성공 정의의 전환: '정확한 문장 일치'에서 '의도 및 제약 조건 충족'으로</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.1.4 성공 정의의 전환: '정확한 문장 일치'에서 '의도 및 제약 조건 충족'으로</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 5. 유닛 테스트 기반의 확정적 검증 오라클 구축 기법</a> / <a href="index.html">5.1 AI 소프트웨어에서의 유닛 테스트 재정의와 범위 설정</a> / <span>5.1.4 성공 정의의 전환: '정확한 문장 일치'에서 '의도 및 제약 조건 충족'으로</span></nav>
                </div>
            </header>
            <article>
                <h1>5.1.4 성공 정의의 전환: ’정확한 문장 일치’에서 ’의도 및 제약 조건 충족’으로</h1>
<p>인공지능(AI) 시스템, 특히 대규모 언어 모델(LLM)을 소프트웨어 개발 및 검증 파이프라인의 핵심 컴포넌트로 통합하면서 엔지니어링 조직이 직면하게 되는 가장 근본적이고 철학적인 딜레마는 바로 ’정답(Ground Truth)’을 정의하는 방식의 충돌이다. 전통적인 소프트웨어 공학에서의 유닛 테스트는 함수의 입력에 대해 미리 정의된 단일한 결정론적 출력값이 정확히 반환되는지를 확인하는 ‘정확한 문자열 일치(Exact String Match)’ 또는 ‘상태 일치(Exact State Match)’ 모델에 전적으로 의존해 왔다. 그러나 확률적이고 비결정적인(Nondeterministic) 텍스트 생성 특성을 지닌 AI 모델의 출력을 평가할 때, 이러한 고전적인 일치 방식은 필연적으로 붕괴한다. 동일한 프롬프트 입력에 대해서도 문맥적 의미와 논리적 결괏값은 동일하지만 표면적인 형태, 어휘의 선택, 문장의 구조가 다른 수십, 수백 가지의 유효한 변형(Valid Variations)이 생성될 수 있기 때문이다.</p>
<p>이러한 소프트웨어 패러다임의 변화는 테스트 성공의 정의를 단순히 ’기대 출력과 실제 출력이 토큰(Token) 수준에서 정확히 일치하는가?’에서 ’모델의 출력이 사용자의 근본적인 의도(Intent)를 내포하고 있으며, 시스템 아키텍처가 요구하는 엄격한 제약 조건(Constraints)을 충족하는가?’로 전환할 것을 강력히 요구한다. 본 절에서는 기계적인 문장 일치 검증이 지닌 치명적인 한계와 이로 인해 발생하는 평가의 왜곡을 분석하고, 이를 극복하기 위해 의도와 제약 조건을 분리하여 검증하는 하이브리드 오라클(Hybrid Oracle)의 수학적, 구조적 메커니즘을 심도 있게 탐구한다. 더불어 실전 소프트웨어 개발 환경에서 결정론적 정답지를 구축하고 자동화된 검증을 수행하는 실무적인 예제를 제시한다.</p>
<h2>1.  정확한 문장 일치(Exact Match) 평가의 구조적 붕괴와 한계</h2>
<p>고전적인 소프트웨어 테스트 및 초기 자연어 처리(NLP) 평가에서 ’정확한 문장 일치(Exact Match)’는 평가 방법론을 가장 환원주의적(Reductionist)으로 단순화한 형태이다. 이는 복잡한 언어적, 논리적 이해의 결과를 단일한 이진 결정(Binary Decision)으로 축소시킨다. 결정론적 소프트웨어에서는 이러한 접근이 완벽하게 작동하지만, AI 소프트웨어의 유닛 테스트에서 이분법적 접근은 시스템의 실제 성능을 심각하게 왜곡하는 여러 가지 구조적 결함을 노출한다.</p>
<h3>1.1  의미론적 동치성 무시와 거짓 이분법(False Binary)</h3>
<p>정확한 일치 지표의 가장 큰 결함은 ’의미론적 동치성(Semantic Equivalence)’의 완전한 무시다. 예를 들어 모델이 “automobile“이라는 단어를 생성했고 기준 정답지가 “car“로 설정되어 있다면, 이 두 단어는 동일한 개념을 표상함에도 불구하고 시스템은 이를 실패(Fail)로 간주한다. 이는 다국어 환경, 다양한 번역어구, 혹은 도메인 특화 용어가 혼용되는 상황에서 다수의 허위 음성(False Negatives)을 유발한다. 또한, 모델이 “42“라는 정답 대신 “The answer is 42“라고 출력했을 때, 두 문장은 동일한 시맨틱 콘텐츠를 담고 있음에도 불구하고 정확한 일치 지표에서는 극도로 낮은 점수를 받게 되며 이는 평가 지표로서의 취약성(Brittleness)을 극명하게 드러낸다.</p>
<p>더욱이 정확한 일치 기반 평가는 ‘부분 점수(Partial Credit)’ 부여가 불가능하다는 치명적인 단점을 지닌다. 90%의 정확한 논리를 포함한 응답과 완전히 무의미한 환각(Hallucination) 응답이 정확한 일치 기준에서는 동일하게 0점으로 처리된다. 이는 마이너한 오류와 근본적인 논리적 실패를 구분할 수 없게 만들어, 모델의 점진적인 개선을 추적하는 것을 불가능하게 만든다.</p>
<h3>1.2  질문 답변(Question Answering) 시스템에서의 재앙적 결과</h3>
<p>질문 답변 및 문맥 추출 작업에서 정확한 일치 지표의 맹목적인 남용은 재앙적인 결과를 초래한 바 있다. 대표적으로 Rajpurkar et al. (2016)이 구축한 SQuAD 데이터셋은 정확한 일치를 주요 평가 지표로 사용함으로써, 모델이 사용자에게 가장 유용한 정보를 제공하는 대신 참조 텍스트의 형식에만 억지로 맞추는 ’답변 엔지니어링(Answer Engineering)’에 과적합되도록 만들었다. “오바마의 출생 연도는 언제인가?“라는 질문에 대해 “버락 오바마는 1961년에 태어났습니다.“라는 사용자 친화적이고 유용한 답변은 기각되고, 오직 “1961“이라는 숫자만 출력해야 높은 점수를 받는 기현상이 발생한 것이다.</p>
<p>결과적으로, 시스템은 90% 이상의 Exact Match 점수를 기록함에도 불구하고 실제 배포 환경에서는 답변 형식이 조금만 달라져도 완전히 실패하는 패턴 매칭 기계로 전락하게 되었다. Jia and Liang (2017)의 연구는 모델이 약간의 형식이 다른 정답을 제공하더라도 문맥에 방해 문장이 추가되면 Exact Match 점수가 극적으로 하락함을 증명하며 이러한 지표의 한계를 지적했다. 평가 기준을 게임화(Gaming)하기 위해 모델의 역량을 개선하는 대신, 참조 답변을 모델의 출력에 맞게 수정하는 ’참조 엔지니어링(Reference Engineering)’과 같은 부적절한 관행까지 등장하게 되었다.</p>
<p><img src="./5.1.4.0.0%20%EC%84%B1%EA%B3%B5%20%EC%A0%95%EC%9D%98%EC%9D%98%20%EC%A0%84%ED%99%98%20-%20%EC%A0%95%ED%99%95%ED%95%9C%20%EB%AC%B8%EC%9E%A5%20%EC%9D%BC%EC%B9%98%EC%97%90%EC%84%9C%20%EC%9D%98%EB%8F%84%20%EB%B0%8F%20%EC%A0%9C%EC%95%BD%20%EC%A1%B0%EA%B1%B4%20%EC%B6%A9%EC%A1%B1%EC%9C%BC%EB%A1%9C.assets/image-20260228181855148.jpg" alt="image-20260228181855148" /></p>
<h3>1.3  임상 및 정밀 도메인에서의 구문론적 평가의 위험성</h3>
<p>임상 의학 및 정밀 과학 도메인에서도 표면적 텍스트 일치 기반 평가의 취약성은 극명하게 드러난다. MIMIC-CDM(Clinical Decision Making) 데이터셋을 사용한 대형 언어 모델의 자율적 임상 의사 결정 평가 연구에 따르면, 현재의 LLM은 지시사항의 사소한 문구 변화나 환자 정보의 제공 순서 변경에 극도로 민감하게 반응하는 것으로 나타났다. 예를 들어, 프롬프트 상의 ’final diagnosis(최종 진단)’를 ’main diagnosis(주 진단)’로 변경하는 것만으로도 모델의 진단 정확도가 크게 요동쳤다.</p>
<p>또한 질병의 진단 가이드라인이 신체검사(Physical Examination)를 가장 첫 번째 행동으로 요구할 때, Llama 2 Chat 모델만이 일관되게 신체검사를 가장 먼저 요청했으며, 다른 모델들은 검사 순서를 바꾸거나 건너뛰는 양상을 보였다. 이러한 맥락에서 출력의 표면적인 텍스트만을 검증하는 것은 모델의 실제 추론 능력이나 임상적 안전성을 평가하는 데 아무런 신뢰할 수 있는 단서를 제공하지 못한다. 모델이 정답지에 기재된 특정 실험실 테스트 이름(Lab test)을 정확히 출력했더라도, 그 테스트의 결과가 정상(Normal)인지 비정상(Abnormal)인지를 일관되게 해석하지 못한다면 해당 모델의 임상적 추론은 완전히 실패한 것이다.</p>
<p>결과적으로, 정적 평가 지표인 BLEU나 ROUGE-1/2, 혹은 순수한 Exact Match 지표는 토큰 수준의 N-gram 중복도에 집착함으로써 LLM 출력에 담긴 깊은 의미론적 뉘앙스와 구조적 타당성을 포착하는 데 실패한다. N-gram 일치 기반 지표는 단어의 배열 순서와 무관하게 동일한 단어가 많이 포함될수록 높은 점수를 주거나, 반대로 동의어를 사용하면 점수를 삭감하는 모순을 지닌다. 모델은 훈련 데이터의 통계적 분포를 학습하여 가장 확률적으로 높은 다음 토큰을 생성하는 엔진이므로, 동일한 의미를 전달하는 수백 가지의 구문적 변형을 합법적으로 생성할 수 있다. 이에 따라, 유닛 테스트의 오라클은 텍스트의 ’형태(Form)’를 검증하는 구시대적 프레임워크에서 벗어나, 텍스트가 수행하는 ’기능(Function)’과 준수해야 할 ’규칙(Rule)’을 검증하는 차원으로 진화해야만 한다.</p>
<h2>2.  코드 생성 및 구조화 데이터에서의 일치 지표 한계와 대안</h2>
<p>자연어를 넘어, Python 코드, SQL 쿼리, JSON 등 고도의 구조적 엄밀성이 요구되는 도메인에서 텍스트 기반 일치 지표의 무용성은 더욱 두드러진다. 소프트웨어 코드는 그 본질이 ’텍스트’가 아니라 ’실행 가능한 논리 구조’이기 때문이다.</p>
<h3>2.1  CodeBLEU와 정적 유사도 평가의 한계</h3>
<p>AI 기반 코드 생성 영역에서 널리 사용된 BLEU 지표의 변형인 CodeBLEU는 단순한 N-gram 매칭의 한계를 극복하기 위해 추상 구문 트리(Abstract Syntax Tree, AST) 매칭과 시맨틱 데이터 흐름(Data-flow) 분석을 결합하여 다차원적인 평가 시스템을 구축하려 시도했다. 그러나 이러한 진전에도 불구하고 CodeBLEU 역시 근본적으로는 ’기준 정답 코드(Reference Implementation)’와의 쌍방향 유사도(Pairwise Similarity)를 측정하는 데 머무른다.</p>
<p>Ren 등(2020)의 연구에 따르면, 전통적인 BLEU 지표는 코드의 의미론(Semantics)과 상관관계가 매우 낮으며, 표면적 토큰을 공유하지 않으면서도 기능적으로 완벽히 동일한 수많은 프로그램들을 처리하지 못한다. 변수명을 변경하거나, <code>for</code> 루프 대신 <code>while</code> 루프를 사용하거나, 리스트 내포(List Comprehension)를 사용하는 등 개발자의 구현 스타일 차이나 AI의 확률적 생성에 따른 구조적 변형은 정답 코드와의 텍스트 일치도를 급락시킨다.</p>
<h3>2.2  구조적 엔트로피(Structural Entropy)를 통한 안정성 측정</h3>
<p>최근 연구는 LLM이 생성하는 코드의 극심한 변동성(Variability)을 정량화하기 위해 단순한 정확도 측정을 넘어 **구조적 엔트로피(Structural Entropy)**라는 개념을 도입하고 있다. Kossen 등이 제안한 시맨틱 엔트로피(Semantic Entropy) 개념에서 영감을 받은 이 지표는, 동일한 프롬프트에 대해 LLM이 여러 번 생성한 코드들의 AST 구조가 얼마나 일관된지를 측정한다.</p>
<p>동일한 단위 테스트를 모두 통과하는 정답 코드라 할지라도, 모델이 매번 완전히 다른 알고리즘 구조를 생성한다면 해당 시스템은 엔트로피가 높으며 신뢰성과 재현성이 낮다고 평가된다. 반면 구조적 엔트로피가 낮다는 것은 모델이 일관된 프로그래밍 구조와 접근 방식을 취하고 있음을 의미한다. AST의 부분 트리(Subtree) 기호를 추출하여 구조적 교차 엔트로피(Structural Cross-Entropy)를 계산하는 과정은 다음과 같은 확률 분포 모델링에 기반한다. 주어진 기준 AST <span class="math math-inline">T</span>와 생성된 AST <span class="math math-inline">T&#39;</span>에서 깊이가 제한된 부분 트리들의 다중 집합(Multiset) <span class="math math-inline">S, S&#39;</span>를 추출하고, 이를 기반으로 주파수 분포 <span class="math math-inline">P</span>와 <span class="math math-inline">Q</span>를 산출한다.<br />
<span class="math math-display">
P(u) = \frac{c(u)}{n}, \quad Q(u) = \max\left(\frac{c&#39;(u)}{n&#39;}, \epsilon\right)
</span><br />
여기서 <span class="math math-inline">c(u)</span>와 <span class="math math-inline">c&#39;(u)</span>는 기호 <span class="math math-inline">u</span>의 발생 횟수이며, <span class="math math-inline">\epsilon</span>은 0으로 나누는 것을 방지하는 스무딩(Smoothing) 상수다. 이를 통해 평가자는 특정 코드가 정답과 텍스트가 일치하는지를 넘어서, 모델이 생성하는 구조적 어휘(Structural Vocabularies)의 예측 가능성과 안정성을 심층적으로 검증할 수 있다.</p>
<p><img src="./5.1.4.0.0%20%EC%84%B1%EA%B3%B5%20%EC%A0%95%EC%9D%98%EC%9D%98%20%EC%A0%84%ED%99%98%20-%20%EC%A0%95%ED%99%95%ED%95%9C%20%EB%AC%B8%EC%9E%A5%20%EC%9D%BC%EC%B9%98%EC%97%90%EC%84%9C%20%EC%9D%98%EB%8F%84%20%EB%B0%8F%20%EC%A0%9C%EC%95%BD%20%EC%A1%B0%EA%B1%B4%20%EC%B6%A9%EC%A1%B1%EC%9C%BC%EB%A1%9C.assets/image-20260228181915353.jpg" alt="image-20260228181915353" /></p>
<h2>3.  성공 기준의 이원화: ’의도(Intent)’와 ‘제약 조건(Constraints)’</h2>
<p>AI를 활용한 소프트웨어 개발 프로세스에서 유닛 테스트가 신뢰할 수 있는 품질 보증(QA) 파이프라인으로 기능하기 위해서는, 모호한 ’정답’의 개념을 **의도(Intent)**와 **제약 조건(Constraints)**이라는 두 가지 직교(Orthogonal)하는 평가 축으로 분해(Decomposition)해야 한다.</p>
<h3>3.1  의도(Intent)의 추출과 시맨틱 검증</h3>
<p>의도는 사용자가 프롬프트를 통해 시스템에 요구한 궁극적인 목표나 핵심 의미를 뜻한다. AI 출력 평가에서 의도 충족 여부를 확인한다는 것은, 출력된 결과가 달성하고자 하는 비즈니스적, 논리적 결과물(Outcome)과 의미론적으로 정렬(Aligned)되어 있는지를 측정하는 과정이다.</p>
<p>전통적인 지식 기반 RAG(Retrieval-Augmented Generation) 시스템은 복잡한 다중 관계나 조건이 포함된 질의에서 사용자의 의도를 빈번하게 오해(Misinterpretation)하여 잘못된 문맥을 검색하는 한계를 보였다. 이러한 기존 시스템의 치명적인 오류 유형은 다음과 같이 분류된다. 문맥 오해에 따른 의도 추론 실패(F1), 잘못된 릴레이션 매핑(F2), 모호성으로 인한 광범위하고 부정확한 검색(F3), 조건 누락(F5), 복잡한 값 유형 노드 처리 오류(F6), 의미는 맞으나 형식이 불완전한 응답(F7) 등이다.</p>
<p>이러한 문제를 해결하기 위해 고안된 최신 <strong>Mindful-RAG 프레임워크</strong>는 질의 <span class="math math-inline">Q</span>에서 독립적인 의도 임베딩(Intent Embedding) <span class="math math-inline">v_I</span>와 문맥 임베딩(Context Embedding) <span class="math math-inline">v_C</span>를 추출하여 모델의 평가 및 검색 과정에 개입시킨다.<br />
<span class="math math-display">
v_I = f_{\mathrm{intent}}(Q), \quad v_C = f_{\mathrm{context}}(Q)
</span><br />
추출된 의도 임베딩은 단순히 생성 과정을 돕는 것을 넘어, 후보 릴레이션(Candidate-Relation)과 트리플(Triple) 지식을 점수화하고 필터링하는 강력한 오라클의 기준값으로 작동한다. 후보 릴레이션 스코어링은 다음과 같은 코사인 유사도 결합 공식을 통해 이루어진다.<br />
<span class="math math-display">
S_{\mathrm{rel}}(Q, r_j) = \alpha \cos(v_I, f_{\mathrm{rel}}(r_j)) + (1 - \alpha) \cos(v_C, f_{\mathrm{rel}}(r_j))
</span><br />
이 아키텍처는 알고리즘 파이프라인의 최종 단계에 피드백 루프를 내장하고 있다. 만약 생성된 최종 답변 <span class="math math-inline">\hat{A}</span>가 표면적으로는 완벽한 문장 형태를 띠고 있더라도, 사용자의 본래 의도나 제약 조건을 충족하지 못한다고 판단되면 시스템은 내부 파라미터(<span class="math math-inline">\alpha, \beta, K</span>)를 업데이트하고 검색 및 생성 과정을 반복한다. 이는 성공의 기준이 ’텍스트 형태’가 아니라 철저히 ’의도의 논리적 충족’에 있음을 보여주는 대표적인 사례다.</p>
<h3>3.2  Web3 인텐트 기반 아키텍처(Intent-based Architecture)와의 철학적 동형성</h3>
<p>AI 테스트에서 의도를 검증하는 개념은 Web3 및 블록체인 생태계에서 최근 각광받는 ’인텐트 기반 아키텍처(Intent-based Architecture)’의 철학과 정확히 일치한다. 전통적인 이더리움 스마트 컨트랙트 환경에서 사용자는 트랜잭션을 실행하기 위해 정확한 실행 경로(Path)와 코드를 명시적으로 승인(Code Authorization)해야 했다. 그러나 인텐트 기반 시스템에서 사용자는 세부 절차를 무시하고 오직 자신이 원하는 최종 결과물(Outcome, 예: “1 ETH를 2,000 USDC 이상으로 교환하라”)만을 표현하고 승인(Conditional Authorization)한다.</p>
<p>이 과정에서 솔버(Solver)라 불리는 오프체인 에이전트 네트워크가 사용자의 의도를 실현하기 위한 최적의 경로를 탐색하고 경쟁한다. 최종적인 거래의 성립은 오라클(Oracle)이나 스마트 컨트랙트가 사용자가 서명한 ’제약 조건(예: EIP-712 메시지로 인코딩된 최소 수령액, 시간 제한 등)’이 런타임에 완벽히 충족되었는지를 검증함으로써 이루어진다.</p>
<p>AI 소프트웨어 테스트 역시 정확히 이와 동일한 구조를 취해야 한다. 테스터는 모델이 생성해야 할 텍스트의 표면적 형태나 중간 절차를 하드코딩하는 대신, 모델(솔버)이 달성해야 할 논리적 결과 상태(의도)와 절대 위반해서는 안 되는 규칙(제약 조건)만을 정의해야 한다. 모델이 어떤 창의적인 어휘를 사용했든 간에, 검증자(Oracle)가 규정한 의도 상태에 도달했다면 테스트는 성공으로 간주되어야 한다.</p>
<h3>3.3  제약 조건(Constraints)의 강제와 결정론적 평가</h3>
<p>의도 검증이 유연하고 의미론적인 차원의 평가라면, <strong>제약 조건(Constraints)</strong> 평가는 시스템이 절대적으로 위반해서는 안 되는 하드 바운더리(Hard Boundary)를 결정론적으로 검사하는 과정이다. LLM은 뛰어난 언어적 추론 능력을 보여주지만, 본질적으로는 훈련 데이터의 분포를 바탕으로 다음 토큰을 순차적으로 자동 회귀(Autoregressive) 예측하는 구조이므로 외부의 명시적인 제어 메커니즘 없이는 구문론적 규칙이나 보안 정책을 완벽하게 준수하기 어렵다.</p>
<p>유닛 테스트에서 결정론적 오라클이 절대적으로 검증해야 하는 제약 조건은 다음과 같은 카테고리로 세분화된다.</p>
<ul>
<li><strong>형식 및 구조적 제약(Structural Constraints):</strong> 출력이 유효한 JSON 스키마를 따르는가? 지정된 XML 태그가 모두 닫혀 있는가? 코드 생성 시 파이썬의 들여쓰기 규칙이나 SQL 쿼리의 문법적 오류가 없는가?</li>
<li><strong>엔티티 및 파라미터 제약(Entity Constraints):</strong> 특정 시간적(Temporal) 또는 지리적(Geographical) 한계 조건이 결과에 반영되었는가? 필수적으로 포함되어야 할 고유 키워드나 제품 ID가 누락되지 않았는가?</li>
<li><strong>보안 및 정책 제약(Safety &amp; Policy Constraints):</strong> 출력에 PII(개인식별정보)가 누출되지 않았는가?  금지된 유해 단어(Toxicity)나 편향적인 내용이 포함되지 않았는가?  모델의 응답 길이가 시스템이 수용 가능한 한계를 초과하지 않는가?</li>
</ul>
<p>이러한 제약 조건들은 의미론적 해석이나 LLM의 주관적 판단이 필요 없는 완전한 결정론적(Deterministic) 규칙 엔진, 정규 표현식, 파서(Parser)를 통해 평가할 수 있다. 모델 응답의 논리 전개가 얼마나 훌륭하든 간에, JSON 형식이 깨져 파싱이 불가능하거나 지정된 반환 길이를 초과했다면 해당 테스트는 명백한 실패(Fail)이다. 따라서 성공적인 AI 유닛 테스트는 **‘LLM 기반의 시맨틱 의도 평가(의도)’**와 **‘코드 기반의 규칙 검사기(제약 조건)’**가 상호 보완적으로 결합된 구조를 띠게 된다.</p>
<h2>4.  실행 기반 오라클(Execution-based Oracle)과 기능적 정확성</h2>
<p>소프트웨어 엔지니어링 도메인에서 의도와 제약 조건을 가장 완벽하게 검증하는 오라클은 인간의 주관적 텍스트 평가가 아니라 생성된 산출물을 시스템 환경에서 실제로 구동해보는 **실행 기반 검증(Execution-based Verification)**이다.</p>
<h3>4.1  런타임 실행 지표: Pass@k 와 기능적 완전성</h3>
<p>코드를 생성하는 LLM을 평가할 때 가장 확실한 의도 충족 여부 확인은 기능적 정확성(Functional Correctness)을 측정하는 것이다. Pass@k 지표는 모델이 <span class="math math-inline">k</span>개의 후보 코드를 생성했을 때, 그중 적어도 하나가 주어진 유닛 테스트 케이스(Unit Test Cases)를 통과하는지를 몬테카를로 샘플링(Monte Carlo Sampling)을 통해 수학적으로 계산한다.</p>
<p>이러한 실행 기반 방법론은 코드의 작성 스타일, 변수명, 제어 흐름의 종류와 무관하게 “주어진 입력에 대해 올바른 출력을 반환하는가?“라는 코드의 근본적인 <strong>의도</strong>를 100% 확정적으로 판별한다. 인간 작성 코드와 AI 생성 코드를 비교할 때, AI가 생성한 코드가 정답과 텍스트 수준에서는 현저히 다르더라도 테스트 스위트 커버리지를 완벽히 달성한다면 기능적으로는 완벽한 동치로 인정받아야 한다.</p>
<h3>4.2  Constraints-of-Thought (Const-o-T) 모델링</h3>
<p>복잡한 다단계 논리가 필요한 도메인(예: 수학 추론, CAD 계획 등)에서 LLM은 초기에는 올바른 방향을 잡더라도 단계가 깊어질수록 상위 수준의 사용자 의도를 망각하고 기호적 제약 조건(Symbolic Constraints)을 위반하는 환각에 빠지기 쉽다. 이를 해결하기 위해 제안된 혁신적인 프레임워크가 바로 **Constraints-of-Thought (Const-o-T)**이다.</p>
<p>Const-o-T는 추론의 매 단계를 단순히 자연어 텍스트로 이어가는 것이 아니라, <span class="math math-inline">\langle \text{의도(Intent)}, \text{제약 조건(Constraint)} \rangle</span>의 구조화된 쌍으로 정의하도록 모델을 강제한다. 여기서 의도는 모델의 다음 행동에 대한 전략적 목표를 서술한 것이며, 제약 조건은 다음 단계의 가능한 행동 공간(Search Space)을 기계가 검증할 수 있는 형태(Machine-checkable conditions)로 제한하는 명세다. 이를 MCTS(Monte Carlo Tree Search)와 통합하면, 컴파일러나 수학적 검증기와 같은 결정론적 오라클이 노드 확장 시점에 즉각 개입한다. 오라클은 생성된 행동이 명시된 제약 조건을 위반하는지 즉각적으로 판단하여, 타당하지 않은 가지(Infeasible branches)를 탐색 트리에서 과감하게 잘라낸다(Pruning). 이 아키텍처는 평가자(Evaluator)가 LLM의 최종 결과물을 사후에 교정하는 것이 아니라, 생성 과정 내부에 결정론적 검증 오라클을 직접 내재화하여 의미론적으로 유효한 결과물만 도출되도록 구조적으로 보장한다.</p>
<h3>4.3  컴파일러를 결정론적 오라클로 활용하는 아키텍처 (CGGNet 및 HELIOS)</h3>
<p>스마트 컨트랙트 생성, 이진 코드 디컴파일(Binary Decompilation)과 같이 무결성이 극도로 요구되는 환경에서는 컴파일러 자체가 완벽한 결정론적 오라클의 역할을 수행한다. 기존 NLP 분야의 텍스트 증강에 사용되던 GAN(Generative Adversarial Networks) 모델은 생성된 문장의 정합성을 판별하기 위해 또 다른 확률적 신경망인 판별자(Discriminator)를 사용했다. 그러나 프로그래밍 소스 코드의 경우, 생성된 코드의 문법적 타당성 및 실행 가능성을 100% 확정적으로 판단할 수 있는 ’컴파일러’라는 내재적 오라클이 존재한다.</p>
<p>**CGGNet(Compiler-Guided Generation Networks)**은 이러한 특성을 활용하여 확률적인 판별자를 완전히 제거하고 그 자리에 컴파일러 오라클을 도입했다. 모델이 생성한 스마트 컨트랙트 코드가 컴파일을 통과(제약 조건 충족)하는지 여부만을 절대적인 보상 신호로 사용하여 MCTS 탐색을 안내한다. 이는 비결정적인 AI 출력물에 대해 오류 없는 100% 신뢰 구간의 검증을 수행할 수 있는 가장 명확한 패러다임이다.</p>
<p>마찬가지로 이진 코드 디컴파일 분야의 <strong>HELIOS</strong> 프레임워크는 단순히 모델이 바이트코드를 텍스트로 번역하도록 두는 것을 넘어섰다. HELIOS는 함수의 제어 흐름 그래프(Control Flow Graph, CFG)와 호출 그래프(Call Graph) 등 구조적 데이터를 명시적으로 모델에 주입하고, 컴파일러의 피드백을 오라클로 활용하는 다중 피드백 루프를 구축했다. 그 결과, 텍스트 프롬프팅 방식에서는 45.0% (Gemini 2.0) ~ 71.4% (GPT-4.1 Mini)에 머물렀던 컴파일 성공률(Compilability)이 HELIOS 프레임워크 하에서는 최대 94%를 초과하며, 기능적 정확도 역시 텍스트 매칭 모델들을 압도하는 성과를 보였다.</p>
<h3>4.4  데이터베이스 엔진을 활용한 Text-to-SQL 검증</h3>
<p>Text-to-SQL 모델의 평가 역시 실행 기반 오라클의 중요성을 여실히 보여준다. 사용자가 자연어로 입력한 질의를 데이터베이스 쿼리로 변환하는 태스크에서, 정답으로 제시된 기준 SQL과 모델이 생성한 SQL을 텍스트 수준에서 비교하는 Exact Set Match(정확한 집합 일치)는 SQL 특유의 선언적(Declarative) 특성을 무시한 조악한 지표다.</p>
<p>예컨대, <code>SELECT A, B FROM T</code>와 <code>SELECT B, A FROM T</code>는 문자열로는 확연히 다르지만 관계형 데이터베이스에서 실행된 결과는 완전히 동일한 의미론적 동치이다. 따라서 GEMMA-SQL Instruct와 같은 최신 최적화 모델들은 단순히 텍스트를 검증하는 Exact Set Match(63.3%) 대신, 실제 데이터베이스 엔진에 생성된 쿼리를 실행하여 반환된 결과 셋(Row Set)이 정답 쿼리의 결과 셋과 일치하는지를 검증하는 **Test-Suite Accuracy(66.8%)**를 핵심 지표로 채택하여 모델의 실제 유용성을 정확히 측정하고 있다. 데이터베이스 엔진이라는 결정론적 오라클이 쿼리의 의도(올바른 데이터 추출)가 충족되었는지를 최종적으로 확정하는 것이다.</p>
<h2>5.  시맨틱 오라클(Semantic Oracle)과 다중 에이전트 하이브리드 검증</h2>
<p>모든 AI 결과물을 컴파일러나 데이터베이스처럼 명확한 실행 환경에서 검증할 수 있는 것은 아니다. 고객 서비스 챗봇의 자연어 응답, 긴 문서의 요약, 비정형 데이터 추출 등 연속적인 문장이 반환되는 태스크에서는 여전히 의미론적 평가가 필수적이다. 이러한 비결정적 출력의 질적 수준을 자동화하여 평가하기 위해, 현대 AI 소프트웨어 개발 파이프라인은 ’LLM-as-a-Judge(평가자로서의 LLM)’를 **시맨틱 오라클(Semantic Oracle)**로 활용하는 하이브리드 검증 아키텍처를 적극 도입하고 있다.</p>
<h3>5.1  정렬 기반 지표와 의미론적 유사도 측정</h3>
<p>시맨틱 오라클은 기계적인 문자열 비교에 의존하지 않고, 문장의 기저에 깔린 의미망(Semantic Nuance)을 분석하여 의도 충족 여부를 판단한다. 이를 수학적으로 계량화하기 위해 BERTScore, MoverScore, METEOR 등 정렬 기반 지표(Alignment-Based Metrics)가 도입되었다.</p>
<p>예를 들어 <strong>BERTScore</strong>는 참조 텍스트와 모델 생성 텍스트의 각 토큰을 사전 훈련된 언어 모델을 통해 고차원 임베딩 벡터(예: BERT-base의 경우 768차원)로 변환한다. 이후 두 텍스트의 모든 토큰 쌍 간의 코사인 유사도(Cosine Similarity)를 계산하여 거대한 유사도 행렬(Similarity Matrix)을 구성한다.<br />
<span class="math math-display">
\text{similarity\_matrix}[i][j] = \frac{E(\text{ref}_i) \cdot E(\text{pred}_j)}{\vert E(\text{ref}_i) \vert \vert E(\text{pred}_j) \vert}
</span><br />
이 행렬을 바탕으로 참조 텍스트의 각 토큰에 대해 예측 텍스트 내에서 가장 유사도가 높은 최적 매칭(Optimal Matching)을 찾고, 이를 집계하여 최종적인 정밀도(Precision), 재현율(Recall), F1 점수를 산출한다. 형태소, 동의어, 심지어 패러프레이징(Paraphrasing)된 구문까지 의미적으로 연결할 수 있는 METEOR 지표 역시 이러한 정렬 기반 평가의 일환이다.</p>
<p>그러나 이러한 통계적 유사도 지표만으로는 “응답이 유해성을 포함하는가?”, “주어진 문서에 없는 내용을 환각(Hallucination)했는가?“와 같은 복잡한 비즈니스 로직 및 제약 조건의 달성 여부를 평가하기에 불충분하다. 따라서 팩트체크, 관련성(Relevance), 지시 준수 여부(Instruction Following) 등 구체적인 평가 기준(Rubric)을 명확히 프롬프팅한 LLM 자체를 심판(Judge)으로 사용하여 다차원적인 평가를 수행하는 방식이 주류로 자리 잡았다.</p>
<h3>5.2  시맨틱 오라클의 신뢰성 한계와 환각 딜레마</h3>
<p>시맨틱 오라클로 사용되는 LLM 역시 확률적 모델이므로 비결정성이라는 태생적 한계를 지니고 있다. 이는 곧 “평가자(오라클) 자체의 환각이나 편향은 누가 검증할 것인가?“라는 무한 퇴행(Infinite Regress)의 문제를 야기한다.</p>
<p>실제로 코드 생성 평가에서 LLM 심판의 능력을 분석한 CodeJudgeBench 논문에 따르면, GPT-4-turbo와 같은 최고 수준의 상용 모델조차 코드의 실제 실행 없이 눈으로만 버그를 찾아내고 기능적 정확성을 판단하는 데 심각한 결함을 보였다. 해당 연구에서 GPT-4는 Java 언어의 경우 잘못 작성된 오답 코드의 50%를 올바른 코드로 잘못 판별(False Positives)했으며, Python 언어에서는 완벽하게 동작하는 정답 코드의 54%를 잘못된 코드로 오판(False Negatives)하는 참담한 결과를 나타냈다. 또한 평가자 LLM은 AI가 생성한 ‘기계적인’ 코드를 선호하고 인간이 작성한 자연스러운 코드를 체계적으로 과소평가하는 편향(Bias)을 지니고 있음이 확인되었다.</p>
<h3>5.3  PoCEvaluator 프로토콜: 증거 기반 다중 에이전트 협상</h3>
<p>이러한 시맨틱 오라클의 불안정성을 통제하고 신뢰성 있는 검증 시스템을 구축하기 위해서는, 단일 프롬프트 호출에 의존하는 맹목적인 평가를 탈피해야 한다. 그 대안으로 떠오르는 것이 다중 에이전트 협상(Multi-Agent Negotiation) 및 증거 기반(Evidence-based) 검증 프레임워크다. 최신 블록체인 스마트 컨트랙트 취약점(PoC) 검증 프레임워크인 <strong>PoCEvaluator Protocol</strong>은 결정론적 환경과 시맨틱 오라클을 융합하는 완벽한 청사진을 제시한다.</p>
<p>이 프로토콜은 단일 LLM 오라클에 평가를 전임하지 않고, 여러 독립적인 LLM 에이전트가 후보 코드를 ’라이브 온체인 포크(Live On-chain Fork) 환경’이라는 격리된 샌드박스(Sandboxed Execution Environment)에서 실제로 컴파일하고 실행하도록 지시한다. 이 과정은 철저히 결정론적이다. 각 에이전트는 코드 실행 과정에서 추출된 로그와 델타 상태(State-delta)라는 명백한 물리적 증거를 기반으로 독립적인 평가 보고서를 작성한다.</p>
<p>이후 취합자(Aggregator Agent)가 에이전트 간의 평가 결과 불일치(Disagreement)를 식별하면, 일방적인 투표로 결정하는 대신 실제 런타임 증거(API 호출 결과 등)를 다시 주입하여 만장일치에 이를 때까지 반복적인 협상(Multi-Round Negotiation)을 조율한다. 이는 AI 유닛 테스트의 미래가 나아가야 할 방향을 명확히 보여준다. **‘결정론적 환경에서의 실행(Execution)’**을 통해 획득한 불변의 증거 데이터를 **‘확률적 시맨틱 오라클(LLM Agent)’**에게 컨텍스트로 한정하여 제공함으로써 검증의 일관성을 강제하는 하이브리드 교차 검증 시스템이다. 이 아키텍처 하에서 오라클은 텍스트의 표면적 논리나 그럴싸한 환각에 속지 않고, 시스템의 실제 런타임 동작이 ’의도’에 부합했는지를 물리적 데이터에 근거하여 확정적으로 판단할 수 있다.</p>
<h2>6.  실전 예제: 의도 및 제약 조건 기반의 하이브리드 오라클 구현</h2>
<p>이론적인 패러다임 전환을 실제 소프트웨어 개발 파이프라인에 적용하기 위해, 기업의 비즈니스 데이터를 조회하는 AI 에이전트를 테스트하는 유닛 테스트 프레임워크를 구성해 보자. 이 에이전트는 사용자의 모호한 자연어 질문을 해석하여 <strong>실행 가능한 SQL 쿼리와 메타데이터를 포함한 JSON 형식의 응답</strong>을 생성하는 역할을 수행한다.</p>
<p><strong>[테스트 시나리오 정의]</strong></p>
<ul>
<li><strong>사용자 입력 (프롬프트):</strong> “지난달에 가입한 사용자 중 총 결제액이 1,000달러를 초과하는 VIP 고객들의 이메일 주소 목록을 추출해 줘.”</li>
<li><strong>시스템의 비즈니스 목적:</strong> 정확한 필터링 조건이 반영된 SQL을 생성하여 데이터베이스에서 고객 정보를 추출하고, 후속 파이프라인이 즉시 파싱할 수 있는 규격화된 JSON으로 반환한다.</li>
</ul>
<p>기존의 Exact Match 테스트 방식이라면, 시스템 엔지니어는 완벽하게 띄어쓰기까지 일치하는 단일한 SQL 문자열과 JSON 페이로드를 정답지로 하드코딩해 두었을 것이다. 하지만 하이브리드 오라클 아키텍처는 모델의 비결정성을 포용하면서도 시스템의 안정성을 보장하기 위해, 다음과 같이 **제약 조건(Hard Constraints)**과 **의도 충족(Intent Satisfaction)**을 분리하여 결정론적 정답지를 구축한다.</p>
<h3>6.1  Phase 1: 제약 조건 검증 (결정론적 하드 오라클)</h3>
<p>가장 먼저 수행되는 테스트 파이프라인은 AI 응답이 시스템의 물리적, 보안적 규칙을 위반하지 않았는지 코드로 검사하는 것이다. 이 검증은 100% 결정론적 연산이며, 실패 시 즉각적인 테스트 오류(Fail)를 반환하고 시맨틱 평가 단계로 넘어가지 않는다.</p>
<table><thead><tr><th><strong>검증 항목 (제약 조건 카테고리)</strong></th><th><strong>검증 방법 및 오라클 메커니즘</strong></th><th><strong>성공 기준 (Pass Criteria)</strong></th></tr></thead><tbody>
<tr><td><strong>응답 구조 (JSON 정합성)</strong></td><td>표준 JSON Parser를 이용한 파싱 및 린팅(Linting) 로직</td><td>구문 예외(Exception) 발생 없이 딕셔너리 또는 객체 트리로 파싱 성공</td></tr>
<tr><td><strong>스키마 준수 (필드 강제)</strong></td><td>JSON Schema 유효성 검사기 적용</td><td><code>sql_query</code>, <code>target_table</code>, <code>confidence</code> 키가 모두 존재하고 데이터 타입이 명세와 일치함</td></tr>
<tr><td><strong>SQL 문법 유효성</strong></td><td>격리된 데이터베이스 엔진의 <code>EXPLAIN</code> 또는 문법 파서 호출</td><td>구문 오류(Syntax Error) 없이 데이터베이스 엔진에서 쿼리 실행 계획이 정상 생성됨</td></tr>
<tr><td><strong>보안 정책 (PII 누출 필터링)</strong></td><td>정규표현식 기반 룰 엔진 및 토큰 스캐닝 적용</td><td>생성된 텍스트 내에 마스킹되지 않은 실제 주민등록번호(<code>\d{6}-\d{7}</code>)나 카드번호 패턴 부재</td></tr>
</tbody></table>
<h3>6.2  Phase 2: 의도 충족 검증 (결정론적 실행 및 시맨틱 혼합 오라클)</h3>
<p>제약 조건을 무사히 통과한 응답에 대해서는 사용자의 논리적 의도가 올바르게 반영되었는지를 검사한다. 여기서는 단순히 쿼리의 텍스트 형태를 보는 것이 아니라, 쿼리가 실제로 수행하는 ’행동’과 결과물의 ’의미’를 복합적으로 평가한다.</p>
<table><thead><tr><th><strong>검증 항목 (의도 카테고리)</strong></th><th><strong>검증 방법 및 오라클 메커니즘</strong></th><th><strong>성공 기준 (Pass Criteria)</strong></th></tr></thead><tbody>
<tr><td><strong>기능적 정확성 (SQL 실행 결괏값)</strong></td><td>격리된 테스트용 데이터베이스(Mock DB) 환경에서 모델 생성 SQL 직접 실행</td><td>반환된 레코드 집합(Row Set)이 정답 쿼리의 실행 결과와 <strong>정확히 일치(Exact Set Match)</strong></td></tr>
<tr><td><strong>엔티티 의도 보존 (기간 설정)</strong></td><td>LLM-as-a-judge 평가 또는 AST 기반 쿼리 파서 분석 적용</td><td>SQL의 조건절(WHERE)에 ’지난달’을 의미하는 정확한 날짜 범위(예: 2026-01-01 ~ 2026-01-31)가 반영되어 있음</td></tr>
<tr><td><strong>환각(Hallucination) 부재</strong></td><td>스키마 메타데이터 대조 로직 (규칙 기반 오라클)</td><td>모델이 생성한 <code>SELECT</code> 절이나 <code>WHERE</code> 절에 참조 DB 스키마에 존재하지 않는 허구의 컬럼명 미사용</td></tr>
</tbody></table>
<h3>6.3  테스트 프레임워크 파이썬 구현 코드 (Pseudo-code)</h3>
<p>실제 지속적 통합(CI/CD) 파이프라인 내에서 위의 하이브리드 오라클은 다음과 같은 형태의 검증 스크립트로 구체화된다. 테스트 엔지니어는 AI 응답의 표면적 텍스트 형태(Form)를 하드코딩하는 대신, 검증해야 할 제약과 의도의 **행동적 경계(Behavioral Bounding Box)**를 프로그래밍한다.</p>
<pre><code class="language-Python">def test_ai_sql_agent_intent_and_constraints():
    # 1. 테스트 입력 정의 및 샌드박스 환경 설정
    user_prompt = "지난달에 가입한 사용자 중 결제액이 1,000달러를 초과하는 VIP 고객의 이메일 목록을 추출해 줘."
    mock_db = setup_isolated_test_db() # 결정론적 실행을 보장하는 테스트용 DB 인스턴스
    
    # 2. AI 에이전트 실행 (비결정적 응답 획득)
    ai_response_text = ai_agent.generate_response(user_prompt)
    
    # =====================================================================
    # Phase 1: 결정론적 제약 조건 검증 (Deterministic Hard Constraints Oracle)
    # =====================================================================
    
    # 제약 1: 유효한 JSON 포맷인지 파싱 시도
    try:
        response_data = json.loads(ai_response_text)
    except json.JSONDecodeError:
        pytest.fail("제약 위반: 응답 텍스트가 유효한 JSON 포맷이 아님 (문법 깨짐)")
        
    # 제약 2: JSON Schema에 따른 필수 필드 누락 검사
    assert "sql_query" in response_data, "제약 위반: 필수 필드 'sql_query' 누락"
    assert "explanation" in response_data, "제약 위반: 필수 필드 'explanation' 누락"
    
    # 제약 3: 데이터베이스 컴파일러 오라클을 통한 SQL 문법 유효성 검사
    generated_sql = response_data["sql_query"]
    is_valid_syntax = mock_db.validate_syntax(generated_sql) # EXPLAIN PLAN 등 활용
    assert is_valid_syntax == True, f"제약 위반: SQL 구문 오류 발생 - 쿼리: {generated_sql}"
    
    # =====================================================================
    # Phase 2: 의도 충족 검증 (Intent Satisfaction via Execution &amp; Semantic Oracle)
    # =====================================================================
    
    # 의도 1: 기능적 정확성 (Test-Suite Accuracy 기반 실행 결과 집합 비교)
    # 개발자가 미리 작성해둔 완벽한 논리의 정답 쿼리 (Ground Truth)
    ground_truth_query = """
        SELECT email FROM users 
        WHERE signup_date &gt;= '2026-01-01' AND signup_date &lt; '2026-02-01' 
        AND total_spent &gt; 1000
    """
    expected_rows = mock_db.execute(ground_truth_query)
    actual_rows = mock_db.execute(generated_sql)
    
    # 모델 생성 쿼리의 텍스트 일치 여부가 아닌, 반환된 데이터 집합(Row Set)의 일치 여부를 검사
    assert sorted(actual_rows) == sorted(expected_rows), "의도 실패: 정답 쿼리와 다른 데이터 집합을 추출함"
    
    # 의도 2: LLM-as-a-judge 시맨틱 오라클을 활용한 설명 텍스트 환각 검사
    explanation = response_data.get("explanation", "")
    if explanation:
        # 평가 전용 프롬프트 및 판단 모델 호출
        relevance_score = evaluate_with_llm_judge(
            criteria="제공된 설명 텍스트가 SQL 쿼리에 명시된 조건(지난달 가입, 1000달러 초과 필터링)만을 사실에 기반하여 설명하고 있는가?",
            input_text=explanation
        )
        assert relevance_score &gt;= 0.85, "의도 실패: 설명 텍스트에 환각적 논리 도약이 포함됨 (시맨틱 평가 임계치 미달)"
</code></pre>
<p>이 실전 예제에서 명확히 확인할 수 있듯이, 의도 및 제약 조건 기반의 하이브리드 오라클 설계는 소프트웨어 테스트의 본질을 회복시킨다. 이 구조 하에서 테스트 코드는 더 이상 깨지기 쉬운 문자열 비교에 취약(Brittle)하지 않다. 모델이 테이블 별칭을 추가하여 <code>SELECT email</code> 대신 <code>SELECT u.email</code>을 생성하든, <code>WHERE</code> 절의 논리 연산자 순서를 뒤바꾸든 전혀 상관하지 않는다. 파이프라인에 중요한 것은 오직 **데이터베이스 엔진(컴파일러 오라클)이 반환한 데이터 레코드 세트가 비즈니스 로직과 동일한가(기능적 의도 충족)**와, <strong>응답의 JSON 구조가 후속 애플리케이션 파이프라인의 파싱 오류를 유발하지 않는가(결정론적 제약 충족)</strong> 뿐이다.</p>
<h2>7. 결론: 평가 패러다임 전환이 가져오는 조직적 ROI와 시스템 복원력</h2>
<p>’정확한 문장 일치(Exact Match)’라는 낡은 환상에서 벗어나 ’의도 및 제약 조건 충족’을 기반으로 테스트 성공을 재정의하는 것은 단순한 테스트 도구 문법의 변경을 넘어선다. 이는 AI 소프트웨어 개발 라이프사이클(SDLC) 전체의 투자 수익률(ROI)과 품질 보증 철학을 근본적으로 재편하는 행위다.</p>
<p>전통적인 고정 텍스트 매칭 기반의 테스트 환경에서는 기저 모델(Foundation Model) 버전을 업데이트하거나 프롬프트의 조사 하나만 수정해도 수많은 테스트 케이스가 오탐(False Negative)으로 인해 무더기로 실패했다. 소프트웨어 품질 관리자(QA)들은 AI가 실제로 비즈니스 기능을 망가뜨렸기 때문이 아니라, 단순히 생성 텍스트의 어조(Tone)나 띄어쓰기, 변수 명명 규칙을 바꾸었다는 이유만으로 빨간 불이 들어온 테스트들을 수동으로 복구하는 데 막대한 시간을 허비해야 했다. 이는 자동화된 테스트 파이프라인이 개발 속도를 가속하는 핵심 엔진이 아니라, 오히려 지속적인 유지보수 비용을 요구하는 거대한 기술 부채이자 병목(Bottleneck)으로 전락하게 만들었다.</p>
<p>그러나 의도와 제약 조건을 명확히 분리한 하이브리드 결정론적 오라클을 구축하면, 자동화 테스트 스위트의 유연성과 복원력(Resilience)이 극대화된다. 모델이 사용자에게 “42“라고 단답형으로 대답하든 “계산 결과 정답은 42입니다“라고 길게 대답하든, 내부의 데이터 추출 파서가 숫자만을 정확히 추출해낼 수 있다면(제약 조건 충족), 그리고 추출된 그 숫자가 비즈니스 로직의 정답과 수학적으로 동치라면(의도 충족), 이 시스템은 어떠한 프롬프트 변경에도 견고하게 ‘성공(Pass)’ 상태를 유지한다. 이는 테스트 코드의 소모적인 유지보수 비용을 획기적으로 낮추면서도, 실제 치명적인 정보의 환각(Hallucination), 스키마 형식의 파괴, 또는 런타임 에러가 발생했을 때는 결정론적 오라클이 이를 확실하고 투명하게 잡아내는 압도적인 신뢰성을 보장한다.</p>
<p>AI 소프트웨어 엔지니어링 생태계가 단순한 텍스트 완성을 넘어 점차 다중 도구를 활용하는 자율적인 에이전틱 워크플로우(Agentic Workflow)로 진화함에 따라, 시스템이 내부적으로 어떤 추론 경로(Path)를 선택하든 간에 명시된 목표 결과(Outcome)에 안전하게 도달하도록 제어하는 역량이 소프트웨어 품질의 척도가 될 것이다. 따라서 유닛 테스트의 아키텍처 역시 AI의 확률적 추론 및 창의성을 최대한 허용하는 넓은 의미론적 경계 공간(Semantic Intent Space)과, 런타임 안정성을 보장하기 위해 단 1바이트의 예외도 허용하지 않는 엄격한 하드웨어적, 구문론적 경계 벽(Deterministic Constraints Wall)을 동시에 설계하는 고차원적 사고방식으로 진화해야 한다. 실행 기반의 결정론적 검증과 다중 에이전트 기반의 시맨틱 평가를 통합한 이원화된 오라클 아키텍처야말로, 비결정성의 시대를 가장 통제력 있게 이끌어갈 강력한 엔지니어링 지휘봉이 될 것이다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>LLM evaluation metrics and methods, explained simply - Evidently AI, https://www.evidentlyai.com/llm-guide/llm-evaluation-metrics</li>
<li>LLM evaluation metrics: Full guide to LLM evals and key metrics, https://www.braintrust.dev/articles/llm-evaluation-metrics-guide</li>
<li>LLM Evaluation Is Broken: Why BLEU and ROUGE Don’t Measure …, https://pub.towardsai.net/llm-evaluation-is-broken-why-bleu-and-rouge-dont-measure-real-understanding-8f3b167f7931</li>
<li>Evaluation and mitigation of the limitations of large language models, https://pmc.ncbi.nlm.nih.gov/articles/PMC11405275/</li>
<li>LLM Evaluation Metrics: The Ultimate LLM Evaluation Guide, https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation</li>
<li>Using Large Language Models for Aerospace Code Generation, https://www.mdpi.com/2226-4310/12/6/498</li>
<li>HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM, https://www.ndss-symposium.org/wp-content/uploads/lastx2026-79.pdf</li>
<li>Measuring LLM Code Generation Stability via Structural Entropy, https://arxiv.org/html/2508.14288v1</li>
<li>(PDF) Measuring LLM Code Generation Stability via Structural Entropy, https://www.researchgate.net/publication/394790504_Measuring_LLM_Code_Generation_Stability_via_Structural_Entropy</li>
<li>Instruction Following is not all you need: Rethinking LLM, https://openreview.net/forum?id=RuY1r1PDdQ</li>
<li>Decoding Intents: Revolutionizing Web3 User Experience and, https://medium.com/@sevenxventures/decoding-intents-revolutionizing-web3-user-experience-and-orderflow-in-blockchain-f927dd2936cb</li>
<li>A Generative Intelligence Approach to Structuring, Optimizing, and, https://zenodo.org/records/18084235/files/EJAET-9-1-105-116.pdf?download=1</li>
<li>Mindful-RAG: Intent &amp; Context-Aware Generation - Emergent Mind, https://www.emergentmind.com/topics/mindful-rag</li>
<li>How to Revolutionize Web3 User Experience and Order Flow Model, https://www.binance.com/en/square/post/1140115809746</li>
<li>Intent-Based Lending Security Risks in DeFi - QuillAudits, https://www.quillaudits.com/blog/lending-borrowing/intent-based-lending-security-risks</li>
<li>LLM Testing: A Complete Guide for Application Developers - Comet, https://www.comet.com/site/blog/llm-testing/</li>
<li>Large Language Model Meets Constraint Propagation - IJCAI, https://www.ijcai.org/proceedings/2025/1115.pdf</li>
<li>Constraints-of-Thought: A Framework for Constrained Reasoning in, https://openreview.net/forum?id=SjJe67VJU1</li>
<li>CGGNet: Compiler-Guided Generation Network for Smart Contract, https://ieeexplore.ieee.org/iel8/6287639/10380310/10597542.pdf</li>
<li>(PDF) GEMMA-SQL: A Novel Text-to-SQL Model Based on Large, https://www.researchgate.net/publication/397441870_GEMMA-SQL_A_Novel_Text-to-SQL_Model_Based_on_Large_Language_Models</li>
<li>(PDF) GEMMA-SQL: A Novel Text-to-SQL Model Based on Large, https://www.researchgate.net/publication/397793363_GEMMA-SQL_A_Novel_Text-to-SQL_Model_Based_on_Large_Language_Models</li>
<li>APEX-SQL: Talking to the data via Agentic Exploration for Text-to-SQL, https://arxiv.org/html/2602.16720v1</li>
<li>Utilising LLM-as-a-Judge to Evaluate LLM-Generated Code - Medium, https://medium.com/softtechas/utilising-llm-as-a-judge-to-evaluate-llm-generated-code-451e9631c713</li>
<li>LLM-as-a-Judge: automated evaluation of search query parsing, https://pmc.ncbi.nlm.nih.gov/articles/PMC12319771/</li>
<li>A Practical Guide to Evaluating Large Language Models (LLM), https://medium.com/@thomas.zilliox/a-practical-guide-to-evaluating-large-language-models-llm-4882fb22892f</li>
<li>A Practical Guide for Evaluating LLMs and LLM-Reliant Systems, https://arxiv.org/html/2506.13023v1</li>
<li>PoCEvaluator Protocol for DeFi Exploits - Emergent Mind, https://www.emergentmind.com/topics/pocevaluator-protocol</li>
<li>LLM evaluation metrics: A comprehensive guide for large language, https://wandb.ai/onlineinference/genai-research/reports/LLM-evaluation-metrics-A-comprehensive-guide-for-large-language-models–VmlldzoxMjU5ODA4NA</li>
<li>Quality at scale: The next phase of GenAI in software testing, https://www.devprojournal.com/software-development-trends/software-testing/quality-at-scale-the-next-phase-of-genai-in-software-testing/</li>
<li>AI Testing in Regulated Environments: Smarter Testing Starts With, https://applitools.com/blog/ai-testing-for-regulated-environments/</li>
<li>AI in end-to-end testing explained - Tricentis, https://www.tricentis.com/learn/ai-end-to-end-testing</li>
<li>AI Test Case Generation Guide: How It Works, Benefits, and the Best, https://www.getpanto.ai/blog/ai-test-case-generation</li>
<li>AI Agents in Software Testing - testRigor, https://testrigor.com/ai-agents-in-software-testing/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>