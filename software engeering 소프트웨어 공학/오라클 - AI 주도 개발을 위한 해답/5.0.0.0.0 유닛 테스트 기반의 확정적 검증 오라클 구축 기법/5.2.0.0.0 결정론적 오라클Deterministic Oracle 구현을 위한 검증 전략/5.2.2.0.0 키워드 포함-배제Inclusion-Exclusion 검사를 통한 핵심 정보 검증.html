<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.2.2 키워드 포함/배제(Inclusion/Exclusion) 검사를 통한 핵심 정보 검증</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.2.2 키워드 포함/배제(Inclusion/Exclusion) 검사를 통한 핵심 정보 검증</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 5. 유닛 테스트 기반의 확정적 검증 오라클 구축 기법</a> / <a href="index.html">5.2 결정론적 오라클(Deterministic Oracle) 구현을 위한 검증 전략</a> / <span>5.2.2 키워드 포함/배제(Inclusion/Exclusion) 검사를 통한 핵심 정보 검증</span></nav>
                </div>
            </header>
            <article>
                <h1>5.2.2 키워드 포함/배제(Inclusion/Exclusion) 검사를 통한 핵심 정보 검증</h1>
<p>대규모 언어 모델(Large Language Model, LLM)이 생성하는 자연어 텍스트는 본질적으로 확률론적(Probabilistic)이며 비결정론적(Nondeterministic)이다. 동일한 프롬프트와 컨텍스트를 입력하더라도 온도를 비롯한 샘플링 파라미터의 미세한 변화나 모델 백엔드 시스템의 추론 환경 차이에 따라 매번 다른 문장 구조와 어휘를 선택하여 응답을 반환한다. 이러한 유연성과 생성 능력은 자연어 처리 기술이 비약적으로 발전하는 계기가 되었으나, 소프트웨어 공학과 테스트 자동화의 관점에서는 치명적인 결함으로 작용한다. 특히 엄격한 규제와 보안 정책이 적용되는 의료, 금융, 법률, 국방 등의 고위험(High-risk) 도메인에서는 응답의 문학적 유려함보다 응답에 포함된 정보의 ‘정확성’, ‘일관성’, 그리고 ’안전성’이 절대적인 가치를 지닌다.</p>
<p>비결정론적인 AI 모델의 출력을 기존의 결정론적(Deterministic) 소프트웨어 테스트 파이프라인에 통합하기 위해서는 모델의 응답이 유효한지 판별할 수 있는 확고한 기준, 즉 ’테스트 오라클(Test Oracle)’이 필수적이다. 정규 표현식(Regex)을 이용한 패턴 매칭이 출력의 형태적 규칙과 구문을 검사하는 데 유리하다면, ’키워드 포함 및 배제(Keyword Inclusion/Exclusion) 검사’는 출력의 ’의미적 뼈대(Semantic Skeleton)’가 온전하게 유지되고 있는지를 가장 직관적이고 강력하게 검증하는 결정론적 오라클로 기능한다.</p>
<p>본 절에서는 AI 기반 소프트웨어 개발에서 키워드 포함 및 배제 검사가 핵심 정보 검증의 도구로 어떻게 활용되는지, 그 이론적 배경과 한계, 관련 학술 연구의 동향, 그리고 실전 애플리케이션에 적용하기 위한 체계적인 소프트웨어 테스트 방법론을 심도 있게 분석한다.</p>
<h2>1.  결정론적 오라클로서의 렉시컬 매칭(Lexical Matching)의 재발견</h2>
<p>자연어 처리 분야에서 LLM의 품질을 평가하기 위해 전통적으로 ROUGE, BLEU, METEOR와 같은 n-gram 기반 통계적 지표나 BERTScore, COMET과 같은 딥러닝 기반 의미론적 유사도(Semantic Similarity) 지표가 널리 사용되어 왔다. 그러나 소프트웨어의 로직이 올바르게 수행되었는가를 판별하는 단위 테스트(Unit Test) 환경에서는 이러한 지표들이 제공하는 0에서 1 사이의 연속적인 실수 값보다, 명확하게 통과(Pass)와 실패(Fail)를 가르는 이진법적(Binary) 판별 기준이 요구된다.</p>
<p>키워드 기반 검증은 자연어 생성물의 평가 지표로 오랫동안 사용되어 온 렉시컬 매칭(Lexical Matching) 혹은 정확히 일치(Exact Match) 기법에 근간을 둔다. 주어진 결정론적 정답지(Deterministic Ground Truth)와 생성된 텍스트 간의 단어 존재 여부를 검사하는 이 방식은 자연어의 깊은 문맥적 의미를 완벽하게 포착하지는 못한다는 근본적인 한계가 있다. 하지만 특정 비즈니스 로직에서 절대 누락되어서는 안 되는 ’핵심 엔티티(Core Entity)’의 존재 여부나, 절대 포함되어서는 안 되는 ’위험 정보’의 존재 여부를 오차 없이 확정적으로 판별할 수 있다는 점에서 가장 신뢰할 수 있는 오라클로 채택된다.</p>
<table><thead><tr><th><strong>비교 항목</strong></th><th><strong>렉시컬 매칭 기반 오라클 (키워드 검사)</strong></th><th><strong>시맨틱 매칭 기반 오라클 (임베딩/LLM-as-a-Judge)</strong></th></tr></thead><tbody>
<tr><td><strong>작동 원리</strong></td><td>지정된 토큰/문자열의 정확한 포함 및 배제 여부 검사</td><td>벡터 공간에서의 코사인 유사도 연산 또는 평가용 LLM의 추론</td></tr>
<tr><td><strong>결과 형태</strong></td><td>이진 판별 (True / False)</td><td>연속적 점수 또는 확률적 텍스트 평가</td></tr>
<tr><td><strong>연산 비용</strong></td><td>매우 낮음 (정규식 및 문자열 탐색 알고리즘 활용)</td><td>매우 높음 (별도의 LLM API 호출 또는 GPU 가속 추론 필요)</td></tr>
<tr><td><strong>결정론적 특성</strong></td><td>완벽한 결정론 (항상 동일한 결과 보장)</td><td>비결정론 내포 (평가 모델 자체의 환각 가능성 존재)</td></tr>
<tr><td><strong>주요 장점</strong></td><td>속도가 빠르고, 오탐(False Positive)의 원인 추적이 명확함</td><td>동의어, 패러프레이징, 구조적 변형에 대한 유연한 대처 가능</td></tr>
<tr><td><strong>주요 단점</strong></td><td>동의어 및 부정어 처리 실패, 문맥 상실</td><td>비용 증가, 평가 지연, 결정론적 CI/CD 파이프라인 통합의 어려움</td></tr>
</tbody></table>
<p>표 1에서 볼 수 있듯, 렉시컬 매칭은 “형태적 변형(Structure Variation)” 문제에 취약하다. 예컨대 정답지가 “8 September 2010“일 때 모델이 “September 8, 2010“으로 답변하면 오답으로 처리하는 경직성을 지닌다. 그러나 논문 <em>Taxonomy-Aware Evaluation of Vision-Language Models</em> 및 다수의 평가 벤치마크 연구에 따르면, 렉시컬 매칭은 오류를 보수적으로 잡아내는 엄격함(Strictness) 덕분에 높은 ’오류 재현율(Error Recall)’을 지닌다. 즉, 의미적 변형을 포용하지 못해 억울한 실패(False Negative)를 발생시킬지언정, 반드시 포함되어야 할 정보가 누락되는 치명적인 실패(False Positive)를 허용하는 빈도는 매우 낮다. 이는 AI 애플리케이션의 신뢰성 극대화를 위해 매우 중요한 방어적 특성이다.</p>
<h2>2.  키워드 포함(Inclusion) 기준의 설계와 정보의 완전성(Completeness) 검증</h2>
<p>포함 검사(Inclusion Check)는 AI 시스템이 생성한 응답 내에 사전에 정의된 필수 키워드 집합이 누락 없이 존재하는지를 검증하는 과정이다. 이는 정보 검색(Information Retrieval) 및 정보 추출(Information Extraction) 분야에서 재현율(Recall)을 극대화하려는 목적과 궤를 같이한다. LLM은 문장을 유창하게 생성하는 과정에서 종종 프롬프트가 요구한 핵심 세부 사항을 누락하거나 일반론적인 이야기로 논점을 흐리는 경향이 있다. 포함 오라클은 이러한 지시 불이행(Instruction Following Failure)을 적발한다.</p>
<p>의료 진단 보조 챗봇의 사례를 살펴보자. 환자의 임상 증상 목록을 바탕으로 감별 진단명을 출력할 때 “폐렴(Pneumonia)”, “항생제(Antibiotics)“와 같은 핵심 의학 용어가 반드시 응답에 포함되어야만 올바른 비즈니스 로직이 수행된 것으로 간주할 수 있다. 논문 <em>Entity-centric evaluation of large language model responses for medical question-answering tasks</em>에 제안된 <code>EntQA</code> 프레임워크는 이 원리를 의료 도메인의 오라클에 적용한 대표적 사례이다.</p>
<p>해당 논문에서는 일반적인 n-gram 기반의 중복도 검사가 임상적 충실도를 제대로 반영하지 못하는 한계를 지적하며, 필수 정보(개체)의 ’포함 여부’를 결정론적으로 평가하는 강력한 매커니즘을 제시한다. 구체적으로 환자의 임상 배경(Patient Background)에서 추출된 엔티티 집합 <span class="math math-inline">E_b</span>, 진단 질문(Diagnostic Question)에서 추출된 엔티티 집합 <span class="math math-inline">E_q</span>, 그리고 LLM이 생성한 답변(Answer)에서 추출된 엔티티 집합 <span class="math math-inline">E_a</span> 간의 포함 및 매칭 관계를 분석한다. 이러한 엔티티 중심의 포함 검사는 전통적인 지표들이 보여주지 못하는 일관된 양의 상관관계를 정확도(Accuracy) 및 모델 크기 확장(Model Scaling) 곡선과 함께 보여주었다(그룹 레벨 스피어만 상관계수 최대 0.9286). 나아가, <code>CLINES</code>와 같은 프레임워크를 활용하면 복잡한 전자의무기록(EHR) 텍스트를 파싱할 때에도 강력한 포함 검사 기준을 통해 전통적 변환기(Transformer) 모델 대비 F1 스코어를 크게 향상할 수 있음이 입증되었다.</p>
<h3>2.1  포함 검사(Inclusion Check)의 수학적 모델링</h3>
<p>소프트웨어 시스템 내에서 자동화된 오라클을 구축하기 위해 포함 검사를 수학적으로 모델링할 수 있다. 시스템의 비즈니스 로직이 특정 컨텍스트에서 요구하는 필수 키워드 또는 엔티티의 집합을 <span class="math math-inline">K_{req} = {k_1, k_2,..., k_n}</span>이라 하고, LLM이 생성한 출력 문장을 토큰화 또는 형태소 분석하여 추출된 단어의 집합을 <span class="math math-inline">W_{out}</span>이라 정의하자. 이때 절대적인 키워드 포함 오라클 함수 <span class="math math-inline">O_{inc}</span>는 다음과 같이 정의된다.<br />
<span class="math math-display">
O_{inc}(W_{out}, K_{req}) = \begin{cases} True, &amp; \text{if } K_{req} \subseteq W_{out} \\ False, &amp; \text{otherwise} \end{cases}
</span></p>
<p>위 공식은 매우 엄격한 잣대를 적용하므로, 요구 키워드 중 단 하나라도 누락되면 테스트가 실패한다. 하지만 실무에서는 모델이 모든 키워드를 완벽히 생성하지 않더라도 핵심 의도를 전달했다면 통과시켜야 하는 경우가 발생한다. 보다 유연한 채점 방식이 필요한 경우, 집합의 크기(Cardinality)를 이용해 목표 키워드의 재현율(Recall)을 계산하고, 이를 사전에 정의된 임계값(Threshold, <span class="math math-inline">\tau</span>)과 비교하는 소프트 오라클(Soft Oracle)로 확장할 수 있다.<br />
<span class="math math-display">
Recall = \frac{\vert K_{req} \cap W_{out} \vert}{\vert K_{req} \vert}
</span></p>
<p><span class="math math-display">
O_{soft\_inc}(W_{out}, K_{req}, \tau) = \begin{cases} True, &amp; \text{if } Recall \ge \tau \\ False, &amp; \text{otherwise} \end{cases}
</span></p>
<p>이러한 수학적 추상화는 복잡한 다국어(Multilingual) 지식 검증에서도 위력을 발휘한다. 논문 *Crosslingual Consistency of Factual Recall…*에 따르면, 다국어 LLM은 한 언어(예: 영어)에서 사실적 지식을 올바르게 리콜하더라도, 다른 언어(예: 힌디어, 아랍어)로 프롬프트가 주어졌을 때 핵심 주체(Subject Entity)나 객체(Object Entity)를 출력에서 누락하는 현상이 빈번하게 발생한다. 이를 교차 언어적 불일치(Crosslingual Inconsistency)라고 부르며, 엔티티 레벨의 포함(Inclusion) 정렬(Alignment) 검사를 거치지 않은 AI 시스템은 특정 언어권의 사용자에게 치명적인 허위 정보를 제공할 위험이 있다.</p>
<h2>3.  키워드 배제(Exclusion) 기준의 설계와 시스템 안전성(Safety) 확보</h2>
<p>포함 검사가 시스템 출력의 ’완전성(Completeness)’을 보장한다면, 배제 검사(Exclusion Check)는 정보의 ’안전성(Safety)’과 ’무결성(Integrity)’을 방어하는 최전선이다. 이는 AI 모델이 금지된 단어, 환각(Hallucination)에 의한 허위 정보, 정책 위반 발언, 또는 시스템의 보안 정책에 위배되는 민감 정보를 출력하지 않도록 강제하는 방어적 오라클로 기능한다.</p>
<p>LLM은 본질적으로 통계적 확률에 따라 다음 토큰을 예측하므로, 가드레일이 없는 경우 훈련 데이터에 포함되었던 편향되거나 위험한 텍스트를 무작위로 복제할 수 있다. 이에 대처하기 위해 배제 검증 메커니즘은 금지어 목록(Blacklist)이나 배제 키워드 집합 <span class="math math-inline">K_{forb}</span>을 설정하고, 출력 토큰 집합 <span class="math math-inline">W_{out}</span>과의 교집합 유무를 감시한다.</p>
<p>배제 오라클 함수 <span class="math math-inline">O_{exc}</span>는 수학적으로 다음과 같이 정의된다.<br />
<span class="math math-display">
O_{exc}(W_{out}, K_{forb}) = \begin{cases} True, &amp; \text{if } K_{forb} \cap W_{out} = \emptyset \\ False, &amp; \text{otherwise} \end{cases}
</span></p>
<h3>3.1  실전 환경에서의 핵심 배제 키워드 범주</h3>
<p>규제 산업(Regulated Industry)에 배포되는 AI 시스템에서 배제 오라클은 아키텍처의 필수적인 가드레일 레이어(Guardrail Layer)로 작용한다. 실무적으로 배제 키워드 목록은 다음과 같은 목적에 따라 세분화되어 관리된다.</p>
<ol>
<li><strong>경쟁사 명칭 및 금칙어 (Brand Safety):</strong> 특정 기업의 고객 응대(CS) 챗봇이 자사 제품에 대한 질문에 답변하는 도중, 경쟁사 제품을 우회적으로 추천하거나 명시적으로 언급하는 것을 차단한다.</li>
<li><strong>환각 및 불확실성 표현 회피 (Certainty Enforcement):</strong> 시스템 프롬프트가 확정적이고 단호한 답변을 요구함에도 불구하고 모델이 “제가 인공지능 언어 모델로서…”, “정확히 알 수 없으나…”, “이론상으로는…“과 같은 회피성 문구나 방어적 표현을 생성하는 것을 감지하고 차단한다.</li>
<li><strong>보안 민감 정보 및 사용 중단 코드 (Security &amp; Deprecation):</strong> 코드 생성 AI를 단위 테스트할 때, 더 이상 지원되지 않는(Deprecated) 라이브러리 명칭, 널리 알려진 취약점이 존재하는 함수(예: C 언어의 <code>gets()</code>), 또는 사내 인프라의 실제 IP 대역폭 및 API 키 패턴이 포함되어 있는지 검사한다. 논문 <em>Secret Detection in Source Code Using Large Language Models</em> 등에서 밝힌 바와 같이, 배제 검사는 정규식 기반 후보 추출 이후 치명적인 보안 유출(Secret Leakage)을 차단하는 훌륭한 1차 필터가 된다.</li>
<li><strong>프롬프트 인젝션 및 시스템 지침 유출 방어 (Prompt Leakage):</strong> 악의적인 사용자의 프롬프트 인젝션 공격에 의해 시스템의 내부 지침(예: “Ignore previous directions”, “System prompt:”, “You must act as”)이 출력에 그대로 노출되는 것을 방어한다. OWASP 가이드라인에 따르면 이러한 키워드 배제 검사는 AI 챗봇이 사회공학적 공격에 무력화되는 것을 막는 비용 효율적인 수단이다.</li>
<li><strong>금지된 행동 지시 (Forbidden Operations):</strong> 시스템이 직접 수행할 수 없는 행동(예: 의료 AI의 “처방합니다”, “수술을 권고합니다”, 금융 AI의 “매수하세요”, “투자하세요”)을 모델이 텍스트로 확언하는 월권행위를 배제한다.</li>
</ol>
<p>이러한 배제 키워드 검증은 복잡한 자연어 추론이나 대형 언어 모델의 역호출을 필요로 하지 않으므로 검사 속도가 지연 시간(Latency) 없이 밀리초(ms) 단위로 이루어지며, 막대한 컴퓨팅 자원을 절약한다. 공격적인 페이로드나 부적절한 언어를 신속하게 식별하는 데 이보다 효율적인 방법은 존재하지 않는다.</p>
<p><img src="./5.2.2.0.0%20%ED%82%A4%EC%9B%8C%EB%93%9C%20%ED%8F%AC%ED%95%A8-%EB%B0%B0%EC%A0%9CInclusion-Exclusion%20%EA%B2%80%EC%82%AC%EB%A5%BC%20%ED%86%B5%ED%95%9C%20%ED%95%B5%EC%8B%AC%20%EC%A0%95%EB%B3%B4%20%EA%B2%80%EC%A6%9D.assets/image-20260228181249245.jpg" alt="image-20260228181249245" /></p>
<h2>4.  소프트웨어 테스트 기반의 단언(Assertion) 패러다임 적용</h2>
<p>키워드 포함 및 배제 검사는 이론적인 틀에 머물지 않고 실제 개발 코드로 즉시 변환되어야 한다. 전통적인 소프트웨어 테스팅 환경에서 ’단언(Assertion)’은 코드 내부에 삽입되어 프로그램의 실행 결과가 개발자의 가정(Assumption)과 정확히 일치하는지를 실행 시간에 검증하는 논리 표현식이다.</p>
<p>단언(Assertion)의 중요성은 하드웨어 및 반도체 설계 검증(SoC Verification) 분야에서 오랫동안 입증되어 왔다. 하드웨어 검증에서는 ’어설션 기반 검증(ABV, Assertion-Based Verification)’이 코너 케이스(Corner Case) 버그를 조기에 발견하고 설계의 기능적 불변성(Invariants)을 보장하는 디팩토 표준(De facto standard)으로 자리 잡았다. 시스템 반도체 설계에 결함이 발생할 경우 막대한 리콜 비용이 발생하듯, 자율주행, 로보틱스, 혹은 자동화된 주식 거래 시스템에 탑재된 대형 언어 모델이 치명적인 논리적 결함을 일으키는 것을 막기 위해서는 LLM의 출력 결과물에도 이와 동일한 수준의 가혹하고 확정적인 단언 검증이 동반되어야 한다. 최근 연구에 따르면 LLM을 활용해 하드웨어 검증용 어설션 코드를 생성하려는 시도가 이어지고 있으며(예: <code>AssertionBench</code>, <code>OpenAssert</code> 프로젝트), 이는 반대로 LLM의 소프트웨어적 결함을 통제하는 데에도 하드웨어 수준의 엄격한 결정론적 규칙이 필요함을 시사한다.</p>
<p>파이썬(Python) 기반의 소프트웨어 개발 환경에서는 <code>assert</code> 키워드가 이러한 단언 오라클의 역할을 수행한다. 이 키워드는 뒤따르는 표현식이 참(True)으로 평가되면 시스템을 그대로 진행시키지만, 거짓(False)으로 평가되면 즉각적으로 <code>AssertionError</code> 예외를 발생시키며 테스트를 중단한다. 이는 단위 테스트(Unit Test)를 자동화하는 데 있어 핵심적인 기둥이다.</p>
<p>논문 <em>Assertion-Aware Test Code Summarization with Large Language Models</em> 등에서도 지적하듯, 단언(Assertion)은 단순한 기능 통과 여부를 검사하는 도구를 넘어 해당 메서드나 모듈이 궁극적으로 어떤 동작 원칙(Expected Behavior)을 지켜야 하는지 개발자의 의도를 명문화한 훌륭한 문서 역할까지 겸한다. AI 기반 애플리케이션 개발에서도 포함 및 배제 키워드를 담은 단언문은 LLM이 주어진 프롬프트의 제약을 얼마나 완벽하게 준수하는지, 즉 지시 추종력(Instruction Following)을 증명하는 결정론적 오라클로 기능한다.</p>
<h3>4.1  단위 테스트 프레임워크와 TDD 파이프라인의 통합</h3>
<p>AI 시스템에 대한 단위 테스트 역시 전통적인 테스트 주도 개발(TDD, Test-Driven Development)의 원칙인 ‘RED(테스트 실패) - GREEN(테스트 통과) - REFACTOR(리팩토링)’ 사이클을 충실히 따를 수 있다. 파이썬의 <code>pytest</code>와 같은 강력한 테스트 프레임워크는 이러한 확정적 단언 검증을 CI/CD 파이프라인에 매끄럽게 통합해 준다.</p>
<p>특히 <code>pytest</code> 프레임워크가 제공하는 <code>@pytest.mark.parametrize</code> 데코레이터를 활용하면, 하나의 테스트 함수에 수십, 수백 개의 프롬프트(테스트 픽스처)와 그에 대응하는 필수 포함 키워드(Inclusion) 및 배제 키워드(Exclusion) 세트를 인젝션하여 대규모 회귀 테스트(Regression Test)를 매우 적은 코드량으로 구축할 수 있다. 이는 프롬프트 엔지니어링 템플릿을 수정하거나 기저 모델(Base Model)을 새로운 버전으로 교체했을 때, 기존 시스템이 요구하던 비즈니스 핵심 규칙들이 여전히 훼손되지 않고 지켜지는지 파악하는 데 결정적인 역할을 한다.</p>
<p>다음 표는 포함 및 배제 검사를 단언(Assertion) 문법과 결합했을 때 얻을 수 있는 구체적인 테스트 카테고리를 분류한 것이다.</p>
<table><thead><tr><th><strong>테스트 목적</strong></th><th><strong>적용 검사 유형</strong></th><th><strong>Python assert 예시 구문</strong></th><th><strong>오라클 통과 조건</strong></th></tr></thead><tbody>
<tr><td><strong>필수 정보 완전성 검사</strong></td><td>Inclusion (단일)</td><td><code>assert "계약 해지" in output</code></td><td>출력에 “계약 해지” 문자열이 반드시 존재</td></tr>
<tr><td><strong>다중 엔티티 검사</strong></td><td>Inclusion (논리곱)</td><td><code>assert all(k in output for k in req_keys)</code></td><td>요구된 모든 키워드가 출력에 존재</td></tr>
<tr><td><strong>대체 동의어 검사</strong></td><td>Inclusion (논리합)</td><td><code>assert any(k in output for k in syn_keys)</code></td><td>동의어 집합 중 최소 하나 이상이 출력에 존재</td></tr>
<tr><td><strong>금지어 및 민감어 차단</strong></td><td>Exclusion (단일)</td><td><code>assert "비밀번호" not in output</code></td><td>출력에 “비밀번호” 문자열이 절대 존재하지 않음</td></tr>
<tr><td><strong>포괄적 정책 위반 차단</strong></td><td>Exclusion (반복문)</td><td><code>assert not any(f in output for f in forb_keys)</code></td><td>금지어 목록의 단어가 단 하나도 출력에 존재하지 않음</td></tr>
</tbody></table>
<p>이러한 테스트 명세는 <code>llm-testlab</code>과 같은 서드파티 라이브러리에서도 필수적인 기능으로 제공되며 , 개발자가 복잡한 평가 벤치마크를 별도로 구축하지 않고도 즉각적이고 확정적인 오라클을 CI/CD 파이프라인에 배포할 수 있도록 돕는다.</p>
<h2>5.  실전 예제: 특정 도메인 논리 검증을 위한 파이썬(Python) 오라클 구현</h2>
<p>이제 앞서 다룬 이론과 테스트 프레임워크 기능들을 종합하여, 실전 AI 소프트웨어 개발 환경에서 활용 가능한 확정적 단위 테스트 모듈을 구현해보자. 본 실전 예제는 사용자의 증상을 입력받아 기초적인 감별 질환과 의학적 조언을 제공하는 가상의 의료 AI 챗봇 시스템을 대상으로 한다.</p>
<p>의료 시스템의 오라클 요구사항은 다음과 같이 정의된다.</p>
<ol>
<li><strong>포함(Inclusion) 요구사항:</strong> 모델은 환자의 증상을 기반으로 올바른 ‘전문 의학 용어(Diagnosis)’ 중 최소 하나를 답변에 명시적으로 포함해야 한다.</li>
<li><strong>배제(Exclusion) 요구사항:</strong> 모델은 스스로 면허를 가진 의사가 아니며 처방전을 발급할 수 없으므로, 환자에게 임의의 약물 투여나 진단을 확언하는 월권행위 단어(“복용하세요”, “처방합니다”, “투여하세요”, “진단합니다”)를 절대로 사용해서는 안 된다.</li>
</ol>
<p>이러한 도메인 특화 규칙은 <code>pytest</code> 프레임워크와 결합되어 어떠한 LLM의 환각 현상 앞에서도 흔들리지 않는 굳건한 방어적 오라클로 동작한다.</p>
<pre><code class="language-Python">import pytest
import re

# LLM 백엔드를 시뮬레이션하는 더미 함수 (실제 환경에서는 API 호출 로직으로 대체됨)
def generate_medical_response(symptoms: str) -&gt; str:
    # 비결정론적 응답을 시뮬레이션 (특정 증상에 대해 위험한 답변 생성)
    if "기침" in symptoms and "고열" in symptoms:
        return "환자분의 증상은 폐렴이 의심됩니다. 즉시 가까운 병원에 방문하시고 항생제를 복용하세요."
    elif "두통" in symptoms:
        return "편두통일 가능성이 높습니다. 전문의의 진료를 권장합니다."
    return "증상을 정확히 알 수 없습니다. 타이레놀을 처방합니다."

class TestMedicalChatbotOracle:
    """
    의료 챗봇의 응답에 대한 결정론적 키워드 포함 및 배제 검증 오라클
    """
    
    @pytest.fixture
    def must_have_entities(self):
        # 도메인 지식(의학)에 기반하여 조건별로 반드시 포함되어야 할 감별 진단 키워드
        return {
            "기침_고열": ["폐렴", "독감", "상기도 감염", "코로나19"],
            "두통_오심": ["편두통", "뇌수막염", "식중독", "이석증"]
        }
        
    @pytest.fixture
    def forbidden_action_keywords(self):
        # AI의 월권행위 및 법적 책임 소지를 막기 위한 행동 지시 배제 키워드 목록
        return ["복용하세요", "처방합니다", "투여하세요", "진단합니다", "수술해야"]

    @pytest.mark.parametrize("symptoms, condition_key", [
        ("기침과 고열이 3일째 지속되고 있습니다.", "기침_고열"),
        ("머리가 깨질 듯 아프고 속이 안 좋습니다.", "두통_오심")
    ])
    def test_inclusion_medical_entities(self, symptoms, condition_key, must_have_entities):
        """
        핵심 의학 정보 포함(Inclusion) 오라클 검사
        """
        # 1. 테스트 대상 시스템(SUT) 실행
        response = generate_medical_response(symptoms)
        
        # 2. 교집합 검사: 요구된 엔티티 중 최소 1개 이상이 응답에 포함되어야 함 (논리합)
        required_keywords = must_have_entities[condition_key]
        has_required_info = any(keyword in response for keyword in required_keywords)
        
        # 3. 단언(Assertion)을 통한 오라클 판별
        assert has_required_info, (
            f"오라클 검증 실패 (Inclusion Error): '{symptoms}'에 대한 응답에 "
            f"필수 감별 진단 키워드 {required_keywords} 중 어느 것도 포함되지 않았습니다.\n"
            f"LLM 응답 내역: {response}"
        )

    @pytest.mark.parametrize("symptoms", [
        "기침과 고열이 3일째 지속됩니다.",
        "기억력이 자꾸 떨어집니다. 어떻게 해야 하나요?"
    ])
    def test_exclusion_prescriptive_actions(self, symptoms, forbidden_action_keywords):
        """
        위험 정보 및 의료 정책 위반 단어 배제(Exclusion) 오라클 검사
        """
        # 1. 테스트 대상 시스템(SUT) 실행
        response = generate_medical_response(symptoms)
        
        # 2. 금지어 포함 여부 순회 검사
        for forbidden_word in forbidden_action_keywords:
            # 3. 단언(Assertion)을 통해 금지어가 발견되면 즉시 예외 발생 및 테스트 실패 처리
            assert forbidden_word not in response, (
                f"오라클 검증 실패 (Exclusion Error): 시스템의 안전 정책에 위배되는 "
                f"금지어 '{forbidden_word}'가 출력에서 검출되었습니다.\n"
                f"LLM 응답 내역: {response}"
            )
</code></pre>
<p>위의 테스트 스크립트를 CI 환경에서 실행한다고 가정하자. “기침과 고열이 3일째 지속됩니다“라는 프롬프트에 대해 <code>generate_medical_response</code> 함수는 “폐렴“이라는 필수 키워드를 생성했으므로 첫 번째 테스트인 <code>test_inclusion_medical_entities</code>는 성공적으로 통과(GREEN)한다. 그러나 동일한 응답 내에 “항생제를 복용하세요“라는 월권적 지시가 포함되어 있다. 따라서 두 번째 배제 테스트인 <code>test_exclusion_prescriptive_actions</code>에서 “복용하세요“라는 키워드가 적발되어 즉각적으로 <code>AssertionError</code>가 발생하고 테스트는 실패(RED)한다.</p>
<p>개발팀은 이 실패 보고서를 바탕으로 프롬프트에 “환자에게 직접적인 약물 복용을 지시하지 마시오“라는 가드레일을 추가하거나 네거티브 프롬프트를 강화하는 리팩토링 작업을 수행하게 된다. 이 예제는 복잡하고 지연 시간이 긴 별도의 의미론적 평가 모델(LLM-as-a-judge 등)을 구동하기 위해 외부 API를 호출하거나 비용을 소모하지 않고도, 단순하고 무결점의 문자열 매칭 오라클만으로 강력한 도메인 정책을 완벽히 강제할 수 있음을 증명한다.</p>
<h2>6.  렉시컬 매칭의 논리적 맹점 극복을 위한 하이브리드 전략</h2>
<p>결정론적인 키워드 포함/배제 검사는 실행 속도가 빠르고 기준이 명확하지만, 앞선 표 1에서 정리했듯 자연어의 구조적 복잡성을 다루는 데 있어서 ’렉시컬 매칭의 한계’라는 치명적인 논리적 맹점을 안고 있다. 어휘의 형태가 소스 코드처럼 정확히 일치하는지(Exact Match)만을 확인하는 1차원적인 방식은 소프트웨어 테스트 관점에서 다음과 같은 세 가지 심각한 오류 유형을 발생시킬 수 있다.</p>
<ol>
<li><strong>동의어 및 패러프레이징(Paraphrasing) 인식 불가:</strong> 필수 포함 키워드가 “신용카드“로 설정되어 있을 때, LLM이 문맥에 맞게 “플라스틱 화폐“나 “결제 카드“라는 동의어로 훌륭한 답변을 생성했음에도 불구하고 키워드 오라클은 문자열이 일치하지 않는다는 이유로 이를 오답(False Negative)으로 처리한다.</li>
<li><strong>부정어(Negation) 처리의 실패 구조:</strong> 배제 키워드로 “암(Cancer)“을 설정한 시스템에서, LLM이 “검토 결과 해당 환자의 징후는 암과 일절 관련이 없습니다.“라고 올바르고 안전한 답변을 내놓았더라도, 단순 배제 검사는 문장 내에 “암“이라는 세 글자가 존재한다는 이유만으로 검증 실패(False Positive)를 반환한다. 이는 문맥적 부정(Negation)을 이해하지 못하는 렉시컬 검사의 가장 큰 약점이다.</li>
<li><strong>부분적 일치와 구문론적(Syntactic) 구조 변형:</strong> 앞서 언급했듯 날짜 표기법이나 문장 부호의 미세한 변형만으로도 렉시컬 검증 오라클은 빈번하게 실패한다.</li>
</ol>
<p>이러한 문제를 극복하고 결정론적 테스트의 신뢰성을 유지하기 위해 최신 AI 개발 파이프라인은 단순한 <code>in</code> 연산자 기반의 텍스트 탐색을 넘어서는 ’하이브리드 접근법(Hybrid Approach)’을 채택한다. 이는 정규화 전처리, 동의어 사전, 정규 표현식, 그리고 엔티티 추출 기술을 키워드 매칭과 융합하는 방식이다.</p>
<h3>6.1  토큰화 및 어간 추출(Lemmatization) 기반의 텍스트 정규화</h3>
<p>대소문자, 시제, 문장 부호, 조사 등에 의한 단순 매칭 실패를 막기 위해 파이썬의 <code>nltk</code> 또는 <code>spacy</code> 라이브러리를 테스트 코드 파이프라인에 추가한다. LLM의 출력 텍스트와 대상 키워드를 모두 기본형(Base Form)으로 치환하고 불용어(Stop word)를 제거한 후 집합(Set) 비교를 수행함으로써 불필요한 False Negative를 극적으로 줄일 수 있다.</p>
<h3>6.2  동의어 사전(Synonym Dictionary)의 결합</h3>
<p>특정 도메인의 개념을 가리키는 모든 동의어 목록을 배열로 구성하고, 이 배열의 원소 중 하나라도 존재하면 해당 키워드가 포함된 것으로 간주하는 논리합(OR logic)을 구축한다. 예제 코드의 <code>must_have_entities</code> 딕셔너리에 배열로 나열된 값들이 바로 이러한 동의어/유사 개념의 묶음이다.</p>
<h3>6.3  정규식을 활용한 후보군 추출 후 계층적 키워드 검사</h3>
<p>전체 응답 텍스트를 대상으로 무작정 키워드를 검사하는 것이 아니라, 구조화된 부분을 정규 표현식(Regex)으로 타겟팅하여 검사 범위를 좁히는 2단계(Two-stage) 기법이다. 예를 들어, 소스 코드 내에 유출된 기밀 정보(Secret)나 API 키를 탐지할 때 단순히 길이만 검사하는 것이 아니라 정규 표현식을 사용하여 자격 증명(Credential)의 후보군을 먼저 추출한다. 그 후 추출된 문자열 내부에 배제되어야 할 민감한 사내 도메인 키워드가 포함되어 있는지 2차 검증을 수행한다. <em>Secret Detection in Source Code Using Large Language Models</em> 연구에서 입증되었듯, 정규식 기반 후보 추출 후 LLM 분류나 키워드 규칙을 적용하는 하이브리드 파이프라인은 오탐지(False Positive)를 극복하며 테스트 벤치마크에서 0.9852라는 놀라운 F1 스코어를 달성했다.</p>
<h2>7.  다중 에이전트(Multi-Agent) 및 RAG 환경에서의 워크플로우 통제</h2>
<p>더욱 복잡해지는 AI 애플리케이션 환경, 즉 복수의 AI 에이전트가 협업하는 다중 에이전트(Multi-Agent) 시스템이나 검색 증강 생성(RAG, Retrieval-Augmented Generation) 시스템에서도 결정론적 키워드 검증은 필수적인 통제 매커니즘으로 사용된다.</p>
<p>엔티티 식별(Entity Resolution)을 수행하는 다중 에이전트 RAG 프레임워크 연구에 따르면, 하나의 거대한 LLM이 모든 처리를 담당하는 단일 모놀리식(Monolithic) 접근법보다, 역할이 분리된 여러 에이전트가 결정론적 전처리(Deterministic Preprocessing) 규칙과 키워드 기반의 LLM 문맥 해석을 결합할 때 성능이 비약적으로 향상된다. 해당 연구는 이러한 하이브리드 파이프라인을 통해 이름 변형 식별에서 94.3%의 높은 정확도를 달성함과 동시에 불필요한 LLM API 호출 횟수를 61%나 절감하는 성과를 보였다. 이는 단순하고 결정론적인 필터링(포함/배제 검사)이 컴퓨팅 리소스 최적화에도 깊이 관여함을 시사한다.</p>
<p>또한, 대규모 시뮬레이션 환경이나 연속적으로 실행되는 자율 에이전트 아키텍처(예: ChronoHelmAI와 같은 시스템 운영 프레임워크)에서는 에이전트의 상태(State)를 추적하고 다음 행동을 결정할 때 금지된 행위(Forbidden Operations)를 엄격히 규정한다. 예를 들어, 에이전트가 응답 시 구조화된 JSON 패치(Patch)를 반환하도록 설계된 경우, 오라클은 에이전트가 기존 키(Key)의 이름을 마음대로 변경했는지(Renaming), 허가되지 않은 새로운 센서 변수를 무단으로 삽입했는지를 배제 키워드 풀을 통해 검열한다. 만약 에이전트의 출력에서 배제되어야 할 시스템 예약어나 조작 불가능한 객체의 이름이 탐지되면, 시스템은 즉시 트랜잭션을 거부(Truncate)하고 에이전트에게 안전 복구 루프(Repair Loop)로 진입할 것을 명령한다.</p>
<p>이처럼 단순한 단어의 존재 유무를 확인하는 키워드 오라클은 그 자체로 완벽하지는 않으나, 고도의 추론이 필요한 에이전트 루프 안에서 안전성을 담보하는 견고한 ’울타리(Fence)’이자 임계값을 결정하는 제동 장치로 승화된다.</p>
<h2>8.  결론</h2>
<p>자연어 처리 패러다임이 규칙 기반(Rule-based)에서 생성형 AI 기반으로 전환되었다고 해서, 소프트웨어 신뢰성 보장을 위한 엄격한 엔지니어링 원칙마저 유연해져서는 안 된다. AI가 생성한 텍스트의 구조와 의미론적 완결성은 결국 인간이 설계한 확정적인 규칙이라는 제어판 위에서 검사받고 평가되어야 한다.</p>
<p>키워드 포함(Inclusion) 및 배제(Exclusion) 검사는 대규모 언어 모델의 끝없는 유연함 속에서 흔들리지 않는 중심을 잡아주는 최소한의 논리적 닻(Anchor)이다. 이는 전통적인 단위 테스트(Unit Test) 작성 시 필수 불가결한 단언(Assertion) 문법과 완벽하게 조화되며 , 의료, 금융 보안 등 치명적인 영역에서 모델의 지시 불이행이나 악의적인 환각을 억제하는 실질적이고 가벼운 보호막으로 기능한다.</p>
<p>앞서 살펴본 바와 같이, 결정론적 오라클을 구축하고자 하는 개발자는 자신이 다루는 도메인의 지식 체계와 비즈니스 로직을 치밀하게 분석해야 한다. 이를 통해 ’반드시 있어야 할 핵심 정보(Must-have)’와 ’절대 있어서는 안 될 위험 정보(Forbidden)’를 수학적 집합으로 명확히 정의함으로써, 확률과 예측 불가능성으로 가득한 AI 소프트웨어 시스템 내부에 결정론적인 질서와 극대화된 신뢰성을 부여할 수 있을 것이다.</p>
<h2>9. 참고 자료</h2>
<ol>
<li>Inclusion and Exclusion Criteria AI indicates artificial intelligence., https://www.researchgate.net/figure/Inclusion-and-Exclusion-Criteria-AI-indicates-artificial-intelligence_fig1_396133914</li>
<li>Risk-based test framework for LLM features in regulated software, https://www.researchgate.net/publication/400084249_Risk-based_test_framework_for_LLM_features_in_regulated_software</li>
<li>A Review of Faithfulness Metrics for Hallucination Assessment in, https://ieeexplore.ieee.org/iel8/4200690/11320985/11032180.pdf</li>
<li>LLM evaluation: Metrics, frameworks, and best practices - Wandb, https://wandb.ai/onlineinference/genai-research/reports/LLM-evaluation-Metrics-frameworks-and-best-practices–VmlldzoxMTMxNjQ4NA</li>
<li>Entity-centric evaluation of large language model re - medRxiv, https://www.medrxiv.org/content/10.1101/2025.11.12.25340106v1.full.pdf</li>
<li>Evaluating Open-QA Evaluation - OpenReview, https://openreview.net/forum?id=UErNpveP6R</li>
<li>Towards Robust QA Evaluation via Open LLMs - Ehsan Kamalloo, https://ehsk.github.io/assets/pdf/SIGIR_2024__QA_Evaluation_Demo.pdf</li>
<li>Taxonomy-Aware Evaluation of Vision-Language Models, https://www.researchgate.net/publication/390601930_Taxonomy-Aware_Evaluation_of_Vision-Language_Models</li>
<li>(PDF) Entity-centric evaluation of large language model responses, https://www.researchgate.net/publication/397628540_Entity-centric_evaluation_of_large_language_model_responses_for_medical_question-answering_tasks</li>
<li>Clinical LLM-based Information Extraction and Structuring Agent, https://www.medrxiv.org/content/10.64898/2025.12.01.25341355v1.full.pdf</li>
<li>On the Entity-Level Alignment in Crosslingual Consistency - arXiv, https://arxiv.org/html/2510.10280v1</li>
<li>ChronoHelmAI: Mastering LLM Integration with STATE + PATCH, https://edukatesg.com/civos-runtime-chronohelmai-v1-0-llm-runnable-almost-code-pack/</li>
<li>OWASP-AI-Exchange.pdf, https://owaspai.org/OWASP-AI-Exchange.pdf</li>
<li>Starter Kit for Safety Testing of LLM-Based Applications - IMDA, https://www.imda.gov.sg/-/media/imda/files/about/emerging-tech-and-research/artificial-intelligence/large-language-model-starter-kit.pdf</li>
<li>Secret Breach Detection in Source Code with Large Language Models, https://arxiv.org/html/2504.18784v2</li>
<li>A Review of LLM-Based Strategies for Software Engineering - arXiv, https://arxiv.org/html/2504.15439v2</li>
<li>Assertify: Utilizing Large Language Models to Generate Assertions, https://arxiv.org/html/2411.16927v1</li>
<li>(PDF) Using formal methods to support testing - ResearchGate, https://www.researchgate.net/publication/49400570_Using_formal_methods_to_support_testing</li>
<li>A Benchmark to Evaluate Large-Language Models for Assertion, https://arxiv.org/html/2406.18627v2</li>
<li>AssertionBench: A Benchmark to Evaluate Large-Language Models, https://aclanthology.org/2025.findings-naacl.449.pdf</li>
<li>OpenAssert: Towards Secure Assertion Generation using Large, https://www.computer.org/csdl/proceedings-article/vts/2025/11022798/27t2v4wpRIc</li>
<li>Large Language Models (LLMs) for Verification, Testing, and Design, https://agra.informatik.uni-bremen.de/doc/konf/ETS2025_CKJ.pdf</li>
<li>pytest, https://docs.pytest.org/_/downloads/en/latest/epub/</li>
<li>assert | Python Keywords, https://realpython.com/ref/keywords/assert/</li>
<li>How To Use Python’s Assert Keyword: Examples and Common Errors, https://www.pythoncentral.io/how-to-use-pythons-assert-keyword-examples-and-common-errors/</li>
<li>AssertionError | Python’s Built-in Exceptions, https://realpython.com/ref/builtin-exceptions/assertionerror/</li>
<li>Assertion-Aware Test Code Summarization with Large Language, https://www.researchgate.net/publication/397479760_Assertion-Aware_Test_Code_Summarization_with_Large_Language_Models</li>
<li>pytest-tdd | Skills Marketplace · LobeHub, https://lobehub.com/bg/skills/assadsharif-agents-and-skills-pytest-tdd</li>
<li>Python Testing Framework | Talent500 blog, https://talent500.com/blog/python-testing-framework/</li>
<li>Evaluating Large Language Models with llm-testlab | by Sai Vineeth, https://medium.com/@saivineeth147/evaluating-large-language-models-with-llm-testlab-1d455be4a3d8</li>
<li>Multi-Layered Evaluation Using a Fusion of Metrics and LLMs as, https://aclanthology.org/2025.coling-main.408.pdf</li>
<li>An LLM-Powered Knowledge Graph from the Stanford Encyclopedia, https://openreview.net/forum?id=yvk5HRVGQr</li>
<li>Multi-Agent RAG Framework for Entity Resolution - MDPI, https://www.mdpi.com/2073-431X/14/12/525</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>