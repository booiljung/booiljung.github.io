<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.2.3 출력 포맷 및 구문 분석(Parsing) 가능성 검증: XML, JSON, Markdown</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.2.3 출력 포맷 및 구문 분석(Parsing) 가능성 검증: XML, JSON, Markdown</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">소프트웨어 공학 (Software Engineering)</a> / <a href="../../index.html">오라클: AI 주도 개발을 위한 해답</a> / <a href="../index.html">Chapter 5. 유닛 테스트 기반의 확정적 검증 오라클 구축 기법</a> / <a href="index.html">5.2 결정론적 오라클(Deterministic Oracle) 구현을 위한 검증 전략</a> / <span>5.2.3 출력 포맷 및 구문 분석(Parsing) 가능성 검증: XML, JSON, Markdown</span></nav>
                </div>
            </header>
            <article>
                <h1>5.2.3 출력 포맷 및 구문 분석(Parsing) 가능성 검증: XML, JSON, Markdown</h1>
<p>대형 언어 모델(LLM)은 본질적으로 비결정론적(Nondeterministic)인 텍스트 생성기이다. 모델은 방대한 데이터 코퍼스(Corpus)에서 학습된 가중치에 기반하여 주어진 문맥에 이어질 다음 토큰(Token)의 확률 분포를 계산할 뿐, 자신이 생성하는 텍스트가 소프트웨어 시스템에서 요구하는 엄격한 구문(Syntax) 규칙이나 데이터 스키마를 준수하는지 스스로 보장하는 메커니즘을 내장하고 있지 않다. 인간 사용자와의 자연어 대화에서는 이러한 유연성이 장점으로 작용하지만, 생성된 결과를 API의 응답으로 사용하거나 데이터베이스에 적재하고, 다른 자율 에이전트(Autonomous Agent)의 입력값으로 전달해야 하는 자동화된 소프트웨어 개발 및 테스트 파이프라인에서는 치명적인 결함으로 작용한다.</p>
<p>전통적인 소프트웨어 테스트에서 오라클(Oracle)은 주어진 입력에 대해 시스템이 반환해야 할 ’정확한 예상 결과’를 의미한다. 그러나 확률론적 모델을 다룰 때, 입력 프롬프트에 대해 모델이 뱉어낼 텍스트를 정확한 문자열 단위로 예측하는 것은 불가능에 가깝다. 이 지점에서 AI 소프트웨어 엔지니어링의 핵심적인 테스트 전략이 등장한다. 바로 모델의 출력 내용(Content) 자체의 절대적 진위를 판별하기 이전에, 그 출력을 담고 있는 <strong>컨테이너(출력 포맷)의 구조적 무결성을 결정론적으로 검증하는 것</strong>이다.</p>
<p>이러한 구조적 검증을 수행하는 가장 강력하고 확정적인 오라클이 바로 **구문 분석기(Parser)**이다. 구문 분석기는 유한 상태 기계(Finite State Machine, FSM)와 정규 문법(Regular Grammar) 또는 문맥 자유 문법(Context-Free Grammar)에 기반하여 작동하므로, 입력된 문자열이 정해진 규칙에 부합하는지 여부를 100%의 정확도로 판별해 낸다. 즉, “파서가 오류 없이 이 텍스트를 파싱했는가?“라는 질문은 비결정론적인 AI의 세계에서 가장 확실하고 이견의 여지가 없는 통과/실패(Pass/Fail)의 오라클을 제공한다.</p>
<p>이 절에서는 현대 소프트웨어 아키텍처에서 가장 널리 사용되는 세 가지 데이터 표현 포맷인 JSON, XML, Markdown을 중심으로, LLM 출력의 구문 분석 가능성을 검증하고 이를 견고한 테스트 오라클로 활용하는 심층적인 기법과 이론적 배경을 탐구한다.</p>
<hr />
<h3>0.1  구조화된 출력(Structured Output) 처리의 3대 장애물과 비용적 관점</h3>
<p>LLM의 확률적 텍스트 생성 특성으로 인해 파서 기반의 오라클을 구축할 때 마주하게 되는 근본적인 장애물은 크게 세 가지로 분류된다.</p>
<p>첫째, **포맷의 불일치(Formatting Inconsistency)**이다. LLM은 명시적으로 “오직 JSON으로만 응답하라“는 엄격한 시스템 프롬프트를 받더라도, 대화형 인공지능으로 미세 조정(Instruction-Tuning)된 본성으로 인해 “Here is the JSON you requested:“와 같은 불필요한 서론(Conversational filler)을 덧붙이거나, 마크다운 코드 펜스(Code Fences, <code>json... </code>)로 데이터를 감싸는 경향을 자주 보인다. 이러한 잉여 텍스트는 표준 파서(Standard Parser)의 유한 상태 기계 작동을 즉각적으로 중단시켜 <code>SyntaxError</code>를 유발한다.</p>
<p>둘째, <strong>스키마 드리프트(Schema Drift)</strong> 현상이다. LLM은 문맥상 유용하다고 판단되는 필드를 임의로 추가하거나, 명시된 키(Key)의 이름을 변형(예: 스키마에 정의된 <code>summary</code>를 <code>article_summary</code>로 무단 변경)하며, 때로는 중첩된(Nested) 데이터 구조를 단일 평면(Flat) 구조로 무시해 버리는 창의성을 발휘한다. 이는 구문 분석에는 성공하더라도 이후의 비즈니스 로직을 처리하는 객체 매핑 단계에서 치명적인 런타임 오류를 발생시킨다.</p>
<p>셋째, **타입 불일치(Type Inconsistency)**이다. 정수형(Integer) 배열이 요구되는 필드에 단일 문자열(String)을 반환하거나, 부울(Boolean) 값이 들어가야 할 곳에 “Yes“나 “High“와 같은 문자열을 삽입하고, 예상치 못한 <code>null</code> 값을 할당하는 행위이다.</p>
<p>이러한 구조적 장애물은 단순한 버그를 넘어 심각한 운영 비용(Operational Cost) 문제를 야기한다. 애플리케이션이 파싱에 실패한 응답을 복구하기 위해 LLM API를 여러 번 재호출(Retry)하게 되면, 지연 시간(Latency)이 급증하고 토큰(Token) 소비량이 배가된다. 평균적으로 파싱 가능한 출력을 얻기 위해 세 번의 시도가 필요한 시스템은 API 비용과 응답 시간을 정확히 세 배로 증가시킨다. 따라서 이러한 오류를 조기에 차단하고 검증하는 오라클 시스템은 엔터프라이즈 AI 시스템 구축에 있어 경제적 타당성을 확보하는 핵심 기술이다.</p>
<hr />
<h3>0.2  JSON: 기계 판독 가능한 데이터 계약과 다계층 검증 오라클</h3>
<p>JSON(JavaScript Object Notation)은 현재 AI 에이전트 간의 통신, 웹 API 응답 생성, 문서 데이터 추출 파이프라인에서 가장 압도적으로 선호되는 데이터 교환 표준이다. 텍스트 기반의 모호한 의사소통을 명확하고 기계 판독 가능한 “데이터 계약(Data Contract)“으로 변환함으로써, LLM을 창의적인 작가에서 정밀한 데이터 프로세서로 탈바꿈시킨다. JSON 기반의 출력 검증 오라클은 시스템의 요구사항에 따라 크게 3개의 계층(Layer)으로 설계된다.</p>
<h4>0.2.1  1계층 오라클: 구문적 유효성(Syntactic Validity) 검증</h4>
<p>가장 기초적인 유닛 테스트 오라클은 언어의 표준 JSON 파서(예: Python의 <code>json.loads()</code>, JavaScript의 <code>JSON.parse()</code>)가 LLM이 생성한 문자열을 에러 없이 메모리 상의 객체(Dictionary 또는 Object)로 변환할 수 있는지를 확인하는 것이다. LLM이 텍스트 포맷을 망가뜨리는 주요 원인은 누락된 대괄호, 컬렉션의 마지막 항목에 불필요하게 추가된 후행 쉼표(Trailing comma), 그리고 제대로 이스케이프되지 않은 따옴표 등이다.</p>
<p>하지만 파서를 오라클로 사용하기 전에, 포맷 불일치 문제를 해결하기 위한 ’전처리(Pre-processing) 정제 파이프라인’을 구성하는 것이 필수적이다. 파서 자체가 오작동하는 것이 아니라 입력값에 섞인 노이즈 때문이라면, 정규 표현식(Regular Expression)을 활용하여 순수한 JSON 문자열만을 추출해야 한다.</p>
<p>다음은 테스트 프레임워크 내에서 LLM 출력을 정제하고 1계층 오라클을 통과시키는 전형적인 로직이다.</p>
<pre><code class="language-JavaScript">// LLM 응답에서 순수 JSON을 추출하고 파싱을 시도하는 오라클 로직 (JavaScript 기반 예시)
function jsonParsingOracle(llm_response) {
    let output = llm_response;
    
// 1. 마크다운 코드 블록 래퍼 제거 (```json... ```)
    output = output.replace(/^```(?:json|markdown)?\n?/, "").replace(/\n?```$/, "");
    
    // 2. 일반적인 대화형 접두사 및 노이즈 텍스트 제거
    output = output.replace(/^(Here is the JSON:|Here is your output:)\s*/i, "");
    
    try {
        // 오라클 단언(Assertion): 파싱 시도
        const parsedObject = JSON.parse(output); 
        return { success: true, data: parsedObject };
    } catch (error) {
        // 파싱 실패 시 오라클은 즉각적으로 테스트 실패를 반환
        return { success: false, error: error.message };
    }
}
</code></pre>
<p>이러한 1계층 오라클은 LLM의 환각(Hallucination)으로 인한 구문 오류를 즉각적으로 포착하여, 잘못된 데이터가 다운스트림 파이프라인으로 흘러가는 것을 원천적으로 차단한다.</p>
<h4>0.2.2  2계층 오라클: 의미론적 스키마 정합성(Semantic Schema Consistency) 보장</h4>
<p>단순히 구문적으로 올바른 JSON 문자열을 생성했다는 사실만으로는 비즈니스 로직의 안전성을 보장할 수 없다. 파싱된 객체는 사전에 시스템 간에 합의된 데이터 구조, 즉 JSON Schema와 정확히 일치해야 한다. 이를 자동화된 오라클로 구현하기 위해 Python 생태계의 <code>Pydantic</code>이나 TypeScript의 <code>Zod</code>와 같은 데이터 유효성 검사(Data validation) 라이브러리가 적극 도입되고 있다.</p>
<p>이러한 라이브러리들은 LLM의 출력 결과물에 필수 키워드가 모두 존재하는지, 배열의 길이가 적절한지, 필드의 데이터 타입이 정확히 일치하는지 심층적으로 확인한다. 만약 LLM이 <code>age</code> 필드에 숫자 <code>25</code> 대신 문자열 <code>"twenty-five"</code>를 반환한다면, 파이단틱(Pydantic) 기반의 오라클은 결정론적인 <code>ValidationError</code>를 발생시켜 테스트를 실패로 처리한다.</p>
<p>이러한 스키마 기반 검증 시스템은 프롬프트 엔지니어링 도구와 결합하여 더욱 강력해진다. 예를 들어 <code>Instructor</code>나 <code>LangChain</code>과 같은 프레임워크는 Pydantic으로 정의된 클래스 모델을 읽어들여, 이를 자동으로 JSON Schema 문법으로 변환한 뒤 시스템 프롬프트에 주입한다. 이는 LLM에게 기대하는 데이터 형태의 명세(Specification)를 가장 수학적이고 명확한 방식으로 전달하는 기법이다.</p>
<h4>0.2.3  3계층 오라클: 문법 제약(Grammar-Constrained) 디코딩 메커니즘</h4>
<p>최근 AI 모델 개발사(OpenAI, Anthropic 등)와 서빙 프레임워크(vLLM 등)는 오라클의 역할을 ’출력 이후의 사후 검증(Posterior Validation)’에서 ’출력 생성 과정의 사전 제약(Prior Constraint)’으로 끌어올리는 혁신적인 기능을 제공하고 있다. 대표적으로 JSON Mode와 강제 구조화 출력(Structured Outputs) 기능이 이에 해당한다.</p>
<p>이 기술의 핵심은 언어 모델의 디코딩(Decoding) 단계에 유한 상태 기계(FSM)를 결합하는 것이다. 모델이 다음 토큰의 확률을 계산할 때, 제약된 문법 엔진이 현재 상태에서 허용되는 토큰들의 집합을 실시간으로 계산한다. 만약 모델이 출력하려는 토큰이 JSON 문법이나 개발자가 제공한 JSON Schema를 위반하는 토큰(예: 닫는 따옴표가 와야 할 자리에 알파벳이 오는 경우)이라면, 해당 토큰의 생성 확률(Logit)을 마스킹(Masking)하여 강제로 음의 무한대(<span class="math math-inline">-\infty</span>)로 만들어버린다.</p>
<p>결과적으로 모델은 문법적으로 유효한 토큰들 중에서만 선택을 강제받게 되며, 파싱 오류 확률은 사실상 0%에 수렴하게 된다. 테스트 오라클 관점에서 볼 때, 이는 인프라스트럭처 레벨에서 확정성을 보장해 주는 강력한 안전망이 구축되었음을 의미한다.</p>
<h4>0.2.4  JSON 출력 일관성 평가 지표: STED (Semantic Tree Edit Distance)</h4>
<p>테스트 프레임워크에서 회귀 테스트(Regression Test)를 수행하거나, 여러 LLM 모델 간의 구조화된 데이터 생성 능력을 평가할 때, 기존의 자연어 처리 평가지표(예: BLEU, ROUGE)나 단순한 문자열 비교(String Matching) 알고리즘을 사용하는 것은 매우 부적절하다.</p>
<p>JSON은 태생적으로 키(Key)의 순서가 무의미한 연관 배열(Associative Array) 구조이다. <code>{"name": "Alice", "age": 30}</code>과 <code>{"age": 30, "name": "Alice"}</code>는 컴퓨터 과학적으로 완벽히 동일한 객체임에도 불구하고, 단순한 정규 표현식이나 BERTScore와 같이 위치에 민감한 임베딩(Position-sensitive embeddings)을 사용하는 지표는 이를 “구조가 훼손된 실패한 출력“으로 오판(False Negative)하는 치명적인 약점을 지닌다.</p>
<p>이러한 평가의 모순을 해결하기 위해 학계에서는 <em>STED and Consistency Scoring: A Framework for Evaluating LLM Structured Output Reliability</em> 와 같은 논문에서 제안된 <strong>STED (Semantic Tree Edit Distance)</strong> 프레임워크를 테스트 오라클의 평가 지표로 채택하고 있다. STED는 JSON, XML, HTML과 같은 구조화된 포맷을 평면적인 텍스트가 아닌 계층적인 ‘트리(Tree)’ 구조로 인식한다.</p>
<p>알고리즘의 동작 방식은 다음과 같다. 먼저, 골든 샘플(Golden Sample, 정답 JSON)과 LLM이 생성한 출력 JSON을 각각 트리 <span class="math math-inline">T_1 = (V_1, E_1)</span> 와 <span class="math math-inline">T_2 = (V_2, E_2)</span> 로 변환한다. 트리의 각 노드 <span class="math math-inline">v \in V</span> 는 타입(객체, 배열, 문자열, 숫자 등), 라벨(키 이름), 값(실제 데이터), 그리고 경로(Path) 정보를 포함한다. 그 후 두 트리 간의 편집 거리(Tree Edit Distance)를 계산한다.</p>
<p>두 트리 사이의 거리를 측정하는 함수 <span class="math math-inline">d(T_1, T_2)</span> 는 트리 <span class="math math-inline">T_1</span> 을 <span class="math math-inline">T_2</span> 로 변환하기 위해 필요한 일련의 연산(삽입, 삭제, 대체) 비용의 최솟값으로 정의되며, 다음과 같은 수식으로 단순화할 수 있다.<br />
<span class="math math-display">
d(T_1, T_2) = \min \sum \text{cost}(\text{edit\_operations})
</span><br />
여기서 STED의 핵심적인 혁신은 형제 노드(Siblings) 간의 순서 재배열(Reordering)에 대한 비용을 0으로 처리한다는 점이다. 반면, 데이터의 타입이 변형되거나(예: 문자열이 배열로 변경), 키(Key)의 계층적 깊이가 달라지는 등 스키마의 근본적인 구조를 파괴하는 치명적인 에러에 대해서는 막대한 페널티(비용)를 부여한다.</p>
<p>실험적 연구에 따르면, STED 기반의 오라클은 키의 순서만 바뀐 의미론적 동치(Semantic equivalents) 상황에서 0.86 이상의 높은 유사도를 도출해 내며 정상 처리하는 반면, 구조적 파탄이 일어난 출력에 대해서는 단호하게 0.0을 반환하여 완벽한 변별력을 입증했다. STED와 같이 구조와 의미를 동시에 이해하는 메트릭을 유닛 테스트 프레임워크의 오라클로 통합하면, 무해한 변형과 파이프라인을 붕괴시키는 치명적 구조 위반을 정확히 구별해 내는 지능적인 검증 시스템을 완성할 수 있다.</p>
<hr />
<h3>0.3  XML: 엄격한 정형성(Well-formedness)과 계층 구조 검증</h3>
<p>JSON이 최신 웹 API와 에이전트 오케스트레이션 워크플로우를 장악했다면, XML(eXtensible Markup Language)은 학술 데이터, B2B 데이터 연동 시스템, 공공 및 정부 데이터, 그리고 Java 환경의 레거시(Legacy) 엔터프라이즈 시스템에서 여전히 핵심적인 데이터 교환 포맷으로 군림하고 있다. XML은 JSON에 비해 훨씬 장황하고(Verbose) 엄격하며 복잡한 문법 규칙을 가진다. 역설적으로 이러한 엄격성은 소프트웨어 테스트 관점에서 볼 때, 파서가 더욱 깐깐하고 뚫기 어려운 강력한 형태의 결정론적 오라클로 기능할 수 있음을 의미한다.</p>
<h4>0.3.1  XML 정형성(Well-formedness)을 통한 1차 검증</h4>
<p>XML의 가장 기본이 되는 개념은 **정형성(Well-formedness)**이다. XML 표준 명세에 따르면, 문서 내에 단 하나의 태그라도 올바르게 닫히지 않았거나(Unclosed tag), 태그의 중첩 순서가 엇갈리거나, 문서의 최상단에 루트(Root) 요소가 두 개 이상 존재하거나, 속성값에 따옴표가 누락된 경우, 해당 문서는 ’정형(Well-formed)’되지 않은 것으로 간주된다. 이러한 경우 표준 XML 파서(Parser)는 오류를 묵인하고 넘어가려는 시도 없이, 마주치는 즉시 치명적 오류(Fatal Error)를 발생시키며 구문 분석을 전면 중단한다.</p>
<p>따라서 AI 소프트웨어 개발 과정에서, DOM(Document Object Model)이나 SAX(Simple API for XML) 파서를 사용해 LLM의 XML 출력을 단순히 로드(Load)하는 동작 그 자체만으로도 완벽하고 결정론적인 1차 유닛 테스트 오라클이 성립된다.</p>
<p>DOM API는 XML 문서 전체를 파싱하여 메모리 상에 트리 구조를 구축하므로, 문서의 구조 전체를 탐색하고 조작하는 테스트 시나리오에 적합하다. 반면 SAX API는 XML 문서를 이벤트 스트림으로 처리하여 순차적으로 읽어들이기 때문에, LLM이 반환하는 방대한 양의 데이터를 메모리 오버헤드 없이 신속하게 문법만 검증해야 할 때 유용하게 활용된다.</p>
<pre><code class="language-Python"># 를 참고한 Python 기반의 XML 정형성 구문 분석 오라클 예제
import xml.etree.ElementTree as ET

def oracle_xml_well_formedness(llm_xml_output: str) -&gt; bool:
    try:
        # 파싱 시도: LLM 출력이 Well-formed 조건을 단 하나라도 어기면 즉시 ParseError 발생
        tree = ET.fromstring(llm_xml_output) 
        return True # 오라클 검증 통과
    except ET.ParseError as e:
        # 파싱 실패: LLM이 문법에 맞지 않는 텍스트를 생성했음을 결정론적으로 판별
        print(f"XML Parsing Failed: {e}")
        return False
</code></pre>
<p>(주의: 실제 프로덕션 환경에서 LLM 출력을 XML 파서로 검증할 때는, 잠재적인 보안 취약점인 XXE(XML External Entity) 공격을 방지하기 위해 신뢰할 수 없는 외부 엔티티 해결을 비활성화하는 <code>defusedxml</code>과 같은 안전한 라이브러리를 사용해야 한다.)</p>
<h4>0.3.2  네임스페이스(Namespace)와 XPath를 이용한 2차 구조 검증</h4>
<p>LLM이 정형화된(Well-formed) XML을 생성하는 데 성공했다 하더라도, 그것이 시스템이 기대하는 비즈니스 데이터의 스키마 구조(DTD 또는 XSD)와 정확히 일치하는지 확인해야 한다. XML 파서를 오라클로 사용할 때의 가장 강력한 무기는 <strong>XPath(XML Path Language)</strong> 쿼리를 통해 특정 노드나 속성의 존재 여부와 계층 관계를 수학적으로 단언(Assert)할 수 있다는 점이다.</p>
<p>특히 XML 네임스페이스(Namespace)의 처리는 LLM이 가장 빈번하게 범하는 논리적 환각(Hallucination) 영역 중 하나이다. LLM은 문서 앞부분에 네임스페이스 URI를 선언해 놓고도 하위 태그에서 접두사(Prefix)를 임의로 누락하거나, 존재하지 않는 가상의 네임스페이스를 지어내 태그에 붙이는 실수를 자주 저지른다. 이러한 경우 문서는 정형적일지 몰라도, 네임스페이스 기반의 XPath 쿼리를 실행하는 다운스트림 시스템에서는 해당 데이터를 찾을 수 없어 심각한 장애가 발생한다.</p>
<p>테스트 오라클은 이를 검증하기 위해, 파서의 검색 함수에 명시적인 네임스페이스 딕셔너리를 강제로 주입하여 유효성을 판별한다. 예를 들어 Python의 <code>xml.etree.ElementTree</code>를 사용할 경우, <code>findall()</code> 함수에 <code>namespaces = {'owl': 'http://www.w3.org/2002/07/owl#'}</code>와 같이 허용된 네임스페이스 맵을 전달함으로써, LLM이 올바른 URI 공간 내에 필수 태그를 정확히 생성했는지 확정적으로 검증할 수 있다.</p>
<h4>0.3.3  문법 제약 상호작용(Grammar-Constrained Interaction)과 수학적 수렴 보장</h4>
<p>최근 학술 연구에서는 단순한 프롬프트 엔지니어링이나 사후 오라클 검증만으로 XML의 복잡한 정형성을 확보하는 것의 한계를 극복하기 위해, 디코딩(Decoding) 단계에 깊숙이 개입하는 이론적 접근이 활발히 시도되고 있다. 대표적으로 <em>XML Prompting as Grammar-Constrained Interaction</em> 논문 등에서 제안된 ‘문맥 자유 문법(Context-Free Grammars, CFG) 기반의 제약된 디코딩’ 기법이다.</p>
<p>이 기법은 XML 스키마를 표현하는 CFG 마스크(Mask)를 생성하여, LLM의 디코딩 과정에 적용한다. 모델이 텍스트를 생성하는 각 샘플링 단계마다, 파서의 상태(State)와 호환되지 않는 유효하지 않은 토큰(Terminal)들로 향하는 전이(Transition) 확률을 차단한다. 논문에 증명된 바에 따르면, 제약된 디코딩이 XML 스키마 문법 <span class="math math-inline">G</span> 에 정렬되고 시작 기호(Start symbol)가 문서(Document)로 설정된다면, 생성되는 모든 출력은 예외 없이 <span class="math math-inline">G</span> 에 대해 잘 형성(Well-formed)되고 유효(Valid)하다는 것이 수학적으로 보장(Proposition 2: Well-formedness)된다.</p>
<p>이러한 시스템이 도입되면 파서 기반의 오라클은 더 이상 실패를 잡아내는 ’사후 검열관’의 역할에 머무르지 않는다. 오히려 AI 모델과 인간(또는 외부 검증기)이 다중 계층(Multi-layer) 프로토콜을 통해 “계획 <span class="math math-inline">\rightarrow</span> 검증 <span class="math math-inline">\rightarrow</span> 수정“을 반복하며 최종적인 안전 상태(Safety invariant)에 도달하도록 강제하는, 거대한 ‘고정점 반복 연산(Fixed-Point Iteration)’ 시스템의 핵심 제어 장치로 그 위상이 격상된다.</p>
<hr />
<h3>0.4  Markdown: 인간-기계 하이브리드 포맷과 AST(Abstract Syntax Tree) 검증</h3>
<p>JSON과 XML이 기계 대 기계 간의 엄격한 데이터 통신과 시스템 연동을 위한 규격이라면, <strong>Markdown</strong>은 인간의 시각적 가독성(Readability)과 기계의 파싱 용이성을 동시에 달성하기 위해 설계된 경량 마크업 언어이다. 최근의 고성능 LLM들은 깃허브(GitHub)의 코드 리포지토리, Stack Overflow, 블로그, 학술 웹 문서 등 방대한 양의 Markdown 포맷 데이터로 사전 학습(Pre-training)되었기 때문에, JSON처럼 강제적인 문법 구조에 얽매이도록 지시받지 않고도 지극히 자연스럽고 유려하게 양질의 구조화된 Markdown 문서를 생성해내는 데 탁월한 능력을 보여준다.</p>
<p>실제로 문서를 분석하고 요약하는 작업이나, 복잡한 표를 추출하고, 소프트웨어 문서를 자동 생성하는 파이프라인에서 Markdown은 가장 이상적인 중간 표현(Intermediate Representation) 형태로 자리 잡았다. LLM에게 복잡한 구조를 지시할 때, “JSON 포맷으로 출력하라“고 지시하는 것보다 “Markdown 제목, 목록, 표를 활용하여 출력하라“고 지시할 때, 구조를 유지하면서도 내용의 깊이와 논리 전개가 더 우수한 결과를 도출한다는 연구 결과(StructEval 벤치마크 등)도 존재한다.</p>
<p>그러나 소프트웨어 테스트 오라클을 구축하는 관점에서 볼 때, Markdown은 가장 까다롭고 난해한 대상 중 하나이다. 그 이유는 Markdown의 파싱 엔진들이 본질적으로 ’관대함(Forgiveness)’을 전제로 설계되었기 때문이다. JSON이나 XML은 괄호 하나만 빠져도 치명적 에러를 내뿜으며 파싱을 거부하지만, Markdown 파서들은 문법에 다소 맞지 않더라도 오류를 내지 않고 텍스트를 평문으로 취급하거나 어떻게든 HTML로 렌더링(Rendering)하여 결과를 반환해 버린다. 이로 인해 파서의 작동 실패 여부로 통과/실패를 결정짓는 단순한 오라클 전략은 Markdown 환경에서 무용지물이 된다.</p>
<p>또한 단순한 문자열 매칭(String Matching)이나 정규 표현식(Regex)을 사용하여 Markdown의 논리적 구조를 테스트하려는 시도 역시 극도로 취약하다. 예를 들어 정규식을 통해 “특정 코드 블록이 존재하는가?“를 검증하려 할 때, 들여쓰기(Indentation)된 코드 블록인지, 아니면 중첩된 목록(Nested list) 내부에 포함된 일반 텍스트인지 정규식만으로는 문맥을 파악하기 불가능에 가깝다. Markdown은 이전 단계의 파싱 결과가 다음 줄의 해석에 영향을 미치는 맥락 의존적인 구조를 가지고 있기 때문이다.</p>
<h4>0.4.1  AST(Abstract Syntax Tree) 파서를 활용한 결정론적 구조 오라클</h4>
<p>이러한 한계를 극복하고 Markdown 생성 결과물의 신뢰성을 검증하는 유일하고도 확정적인 오라클 구축 방법은, 고성능 Markdown 파서를 사용하여 텍스트를 **추상 구문 트리(AST, Abstract Syntax Tree)**로 변환한 후, 메모리 상에 구축된 그 트리 구조를 직접 순회(Traversal)하며 검사하는 것이다.</p>
<p>Python 생태계에서는 <code>Mistune</code> 라이브러리가, JavaScript/Node.js 환경에서는 <code>markdown-it</code> 라이브러리가 단순히 HTML을 생성하는 것을 넘어 텍스트를 완전한 AST 객체로 추출해내는 기능을 완벽하게 지원한다. 테스트 코드는 LLM이 무작위로 출력한 평면적인 문자열을 이러한 라이브러리를 통해 구조적인 트리로 파싱한 뒤, 특정 유형의 노드(예: Heading, Table, List, Fenced Code Block)가 예상한 계층 위치와 명세된 개수만큼 정확히 존재하는지 확정적으로 단언(Assert)할 수 있다.</p>
<p>데이터 변환 과정을 살펴보면, 파서는 평면적인 텍스트 문서 블록을 입력받아 계층적 트리 구조로 재구성한다. 최상단에 루트(Root) 노드가 생성되고, 그 아래에 제목(Heading level 1), 본문(Paragraph), 목록(List), 그리고 목록의 자식 노드로서 리스트 아이템(List Item)과 코드 블록(CodeBlock) 등이 가지를 뻗어나가는 형태가 된다.</p>
<p>테스트 환경에서 이를 활용한 오라클 단언 로직은 정규식을 완전히 배제하고 오직 논리적 노드의 속성만을 검사한다.</p>
<pre><code class="language-Python"># [28, 30, 31]의 개념과 Mistune 라이브러리를 응용한 Markdown AST 기반 테스트 오라클 논리 구조
import mistune

def verify_markdown_structure_oracle(llm_md_output: str) -&gt; bool:
    # 1. Mistune을 사용하여 LLM의 평면적 Markdown 텍스트를 AST 트리 객체로 파싱
    markdown_parser = mistune.create_markdown(renderer=mistune.AstRenderer())
    ast_nodes = markdown_parser(llm_md_output)
    
    # 오라클 단언(Assertion) 1: 문서의 논리적 최상단(첫 번째 노드)은 반드시 제목(Heading Level 1)이어야 함
    if not ast_nodes or ast_nodes['type']!= 'heading' or ast_nodes['level']!= 1:
        return False
        
    # 오라클 단언 2: 보고서 본문에 데이터를 요약한 테이블(표) 노드가 최소 1개 이상 존재해야 함
    has_table_node = any(node['type'] == 'table' for node in ast_nodes)
    if not has_table_node:
        return False
        
    # 오라클 검증 통과: 정형화된 구조적 명세를 완벽히 준수함
    return True
</code></pre>
<p>이 AST 기반 오라클 방식의 가장 큰 강점은 견고함이다. 비결정론적인 LLM이 기분에 따라 생성한 텍스트의 길이가 달라지거나, 불필요한 줄바꿈을 추가하거나, 띄어쓰기 패턴을 변형하더라도 파서는 문서의 ’논리적인 뼈대(구조)’를 동일한 트리의 형태로 일관되게 파악해 낸다. 이를 통해 “순서 없는 목록(Unordered List) 내부에 반드시 실행 가능한 파이썬 코드 블록이 포함되어 있는가?“와 같은 고차원적이고 세밀한 구조적 검증을 오류 없이 확정적으로 수행할 수 있다.</p>
<h4>0.4.2  구분자(Delimiter) 기반의 부분 구조 추출 및 혼합 포맷 파싱</h4>
<p>실제 엔터프라이즈 환경의 요구사항은 단일 포맷의 출력을 넘어선다. 복잡한 에이전트 워크플로우에서는 종종 LLM에게 “문서의 상세한 요약은 이모지 표제와 중첩된 표를 포함한 리치 마크다운(Rich Markdown)으로 작성하고, 핵심 메타데이터는 JSON 객체로 배열하여 반환하라“는 형태의 하이브리드(Hybrid) 출력을 요구하게 된다.</p>
<p>문제는 이러한 혼합 출력 시나리오에서 출력 파서(Output Parser)가 빈번하게 고장(Parse Failure)을 일으킨다는 점이다. LLM이 마크다운 섹션을 작성하면서 백틱(`), 이중 따옴표, 중괄호, 이스케이프가 필요한 특수 기호들을 무작위로 섞어 쓰게 되면, 이것이 JSON 파서의 경계를 침범하여 전체 문서의 파싱 규칙을 위반하는 현상이 발생한다. 최신 구조화 출력(Structured Outputs) 기법을 도입하더라도 10건 중 1~2건의 파싱 실패가 지속적으로 발생하여 파이프라인의 신뢰성을 훼손하는 사례가 다수 보고되었다.</p>
<p>이러한 고질적인 문제를 해결하고 100%에 가까운 신뢰성을 확보하기 위한 실전 오라클 전략으로 <strong>구분자 기반 추출(Delimiter-based Extraction)</strong> 기법이 널리 채택되고 있다. 이 방식은 파서의 로직을 단순화하기 위해 입력 데이터 자체를 물리적으로 격리하는 접근법이다.</p>
<p>개발자는 프롬프트를 통해 LLM에게 결과물의 각 섹션을 시스템 내에서 절대 충돌하지 않는 고유한 커스텀 태그(예: <code>===MD_SUMMARY_START===</code> 및 <code>===MD_SUMMARY_END===</code>)로 감싸도록 엄격히 지시한다. 이후 유닛 테스트와 애플리케이션 계층에서는 1차적으로 정규식 기반의 분리 파서를 통해 문서 내의 다른 모든 노이즈 텍스트를 무시하고 오직 구분자 내부의 텍스트 덩어리만을 추출한다. 그리고 추출된 리치 마크다운 텍스트는 AST 파서(Mistune)에, 메타데이터 텍스트는 JSON 파서에 각각 독립적으로 넘겨 검증과 파싱을 수행한다.</p>
<p>이러한 구분자 기반 접근법은 이스케이핑 지옥(Escaping Hell)의 함정을 우회하면서, 마크다운 노드 내부에서 모델이 어떠한 특수 기호를 사용하더라도 파서가 망가지지 않도록 보장한다. 이는 포맷 파싱의 성공률을 극적으로 끌어올려, LLM 기반 시스템이 무인 자동화 환경에서 중단 없이 동작하도록 만드는 매우 강력하고 실용적인 소프트웨어 엔지니어링 설계 패턴이다.</p>
<hr />
<h3>0.5  출력 포맷별 오라클 구축 전략 비교 및 벤치마킹</h3>
<p>앞서 살펴본 바와 같이, 세 가지 주요 출력 포맷은 각각의 언어적 특성에 따라 파서 오라클을 구축하는 전략과 난이도, 그리고 검증의 확정성 수준이 다르게 나타난다. 이를 종합적으로 비교하면 다음과 같다.</p>
<table><thead><tr><th><strong>출력 포맷</strong></th><th><strong>문법의 엄격성 수준</strong></th><th><strong>오라클 검증의 핵심 메커니즘</strong></th><th><strong>주요 활용 라이브러리 및 도구</strong></th><th><strong>LLM 출력 준수 난이도 및 특징</strong></th></tr></thead><tbody>
<tr><td><strong>JSON</strong></td><td>높음 (엄격함)</td><td>구문적 유효성 파싱 및 스키마 검사기(Schema Validator)를 통한 의미론적 정합성 강제</td><td>Pydantic, Zod, 표준 <code>json</code> 라이브러리, JSON Mode</td><td>낮음. 프레임워크 지원이 강력하며 강제 구조화(Structured Outputs) API 적용 시 위반 확률 거의 없음.</td></tr>
<tr><td><strong>XML</strong></td><td>매우 높음 (극도로 엄격함)</td><td>정형성(Well-formedness) 예외 처리 모니터링 및 XPath를 활용한 계층 구조 단언(Assertion)</td><td><code>xml.etree.ElementTree</code>, DOM/SAX 파서</td><td>높음. 닫힌 태그 누락이나 네임스페이스(Namespace) 환각 등 사소한 오류로 파싱 전체가 붕괴되기 쉬움.</td></tr>
<tr><td><strong>Markdown</strong></td><td>낮음 (관대함)</td><td>AST(Abstract Syntax Tree) 생성 후 트리 탐색을 통한 특정 논리적 요소(노드) 존재 확인</td><td>Mistune (Python), markdown-it (JS)</td><td>매우 낮음. 자연어 생성 모델의 특성에 가장 잘 부합하여 유창하고 구조화된 결과물을 자연스럽게 생성해 냄.</td></tr>
</tbody></table>
<p>오라클의 퀄리티와 파이프라인의 안전성을 종합적으로 평가하기 위해서는 모델 자체의 구조화 출력 능력을 객관적으로 진단하는 벤치마크 지표의 활용도 중요하다. 최근 도입된 <strong>StructEval</strong>과 같은 종합 평가 벤치마크 프레임워크는 단순히 JSON에 그치지 않고 XML, YAML, Markdown, CSV, HTML, React 등 무려 18가지 이상의 다양한 구조화 포맷에 대해 LLM의 생성 능력을 체계적으로 측정한다. 이 벤치마크는 생성된 출력이 원본 자연어의 의미를 담고 있는지를 넘어, 실제 공식 파서의 문법적 유효성(Syntactic validity) 검사를 통과하고 지정된 계층적 구조 규격(Structural correctness)을 100% 만족하는지를 철저히 검증한다.</p>
<p>이러한 평가 과정에서 흥미로운 사실이 발견되는데, Cleanlab의 “Structured Outputs Benchmark” 연구에서 지적된 바와 같이, 기존 공개 데이터셋에 포함된 인간 작업자의 정답지(Ground-truth) 자체가 사람이 수작업으로 입력하는 과정에서 잦은 스키마 위반과 포맷 오류를 포함하고 있다는 점이다. 즉, 비결정론적 AI 모델의 구조화 능력을 테스트하기 위해 또 다른 불완전한 객체인 인간이 작성한 예상 출력 텍스트를 비교 기준으로 삼는 것은 오류의 악순환을 초래한다.</p>
<p>따라서 견고한 AI 유닛 테스트 환경에서는 문자열 매칭 기반의 낡은 정답지를 전면 폐기해야 한다. 그 대신, **“해당 데이터 규격의 공식 파서(Official Parser) 및 스키마 유효성 검사기가 이 출력을 로드할 때 어떠한 예외(Exception)도 던지지 않는가?”**라는 절대적이고 결정론적인 기준을 테스트의 유일한 오라클로 채택해야 한다. 기계가 해석 가능한 포맷의 진위는 오직 기계적인 파서만이 오류 없이 판별할 수 있다.</p>
<hr />
<h3>0.6  파서 기반의 오라클과 자가 치유(Self-Healing) 파이프라인 구축</h3>
<p>단일 구문 분석기를 이용해 오류를 찾아내고 예외를 발생시키는 오라클 검증이 시스템의 결함을 ’정확하게 진단’하는 정적(Static) 방어선에 그친다면, 현대적인 AI 개발 프레임워크들은 여기서 한 걸음 더 나아가 파싱 실패(Oracle Failure)라는 확실한 피드백을 시스템을 스스로 복구하기 위한 핵심 트리거(Trigger)로 활용한다. 이는 <strong>자가 치유(Self-healing)</strong> 파이프라인 메커니즘으로 불리며, LangChain, LlamaIndex, Instructor 등 주요 최신 구조화 프레임워크들의 출력 파서(Output Parser) 모듈 내부에 핵심 설계 패턴으로 자리 잡고 있다.</p>
<p>이러한 자가 치유 파이프라인의 아키텍처는 오라클을 능동적인 에이전트의 피드백 루프로 통합한다.</p>
<ol>
<li><strong>최초 생성(Initial Generation):</strong> 시스템은 LLM에게 프롬프트와 함께 기대하는 구조화 스키마(예: Pydantic 모델)를 전달하여 데이터 생성을 요구한다.</li>
<li><strong>오라클 검증(Deterministic Oracle Validation):</strong> 반환된 응답을 파서 엔진에 입력한다. 만약 LLM이 마크다운 래퍼를 잘못 처리하거나 타입 규칙을 위반했다면, 파싱이나 스키마 검증 과정에서 결정론적인 <code>Exception</code>이 발생한다.</li>
<li><strong>오류 역전파 및 자가 교정(Error Backpropagation &amp; Self-Healing):</strong> 테스트 프레임워크는 단순히 실패를 보고하고 종료하는 대신, 파서가 반환한 극도로 구체적이고 기술적인 에러 메시지(예: <code>json.decoder.JSONDecodeError: Expecting ',' delimiter: line 4 column 1 (char 83)</code>)를 원문 텍스트와 함께 캡처한다. 이 오류 로그 자체를 새로운 프롬프트의 컨텍스트로 구성하여, “이전 시도에서 당신이 생성한 텍스트가 4번째 줄에서 쉼표 누락으로 파싱에 실패했다. 내용을 바꾸지 말고 문법 구조만 올바르게 수정하여 다시 반환하라“는 지시를 내려 재시도(Reprompt)를 수행한다.</li>
</ol>
<p>대부분의 우수한 LLM은 명확한 파서의 오류 메시지가 주어졌을 때 스스로의 포맷 실수를 즉각적으로 교정(Self-correction)할 수 있는 뛰어난 문맥 이해 능력을 갖추고 있다. 이처럼 파서 오라클은 시스템의 붕괴를 막는 최후의 수동적 방어막 역할을 넘어서, 시스템의 출력 품질을 최종적으로 100% 정합성에 도달할 때까지 끊임없이 조율하는 지능적이고 능동적인 피드백 루프의 핵심 엔진으로 진화하게 된다.</p>
<p>결론적으로, 확률에 기반한 비결정론적 언어 모델을 기업 수준의 중단 없는 소프트웨어 파이프라인에 통합하기 위해서는 필연적으로 오라클 패러다임의 전환이 요구된다. XML, JSON, Markdown의 엄격한 구문 규칙과 AST(추상 구문 트리)의 논리적 계층 구조를 활용하는 파서 엔진들은, AI의 끝없는 창의성을 실전 애플리케이션이 요구하는 단호하고 결정론적인 신뢰의 영역으로 안전하게 가두어 두는 가장 완벽한 수학적 장치이다.</p>
<h2>1. 참고 자료</h2>
<ol>
<li>LLM Output Parsing and Structured Generation Guide - Tetrate, https://tetrate.io/learn/ai/llm-output-parsing-structured-generation</li>
<li>How Output Parsers Save Your LLM From Formatting Disaster - Dev.to, https://dev.to/alex_aslam/taming-the-chaos-how-output-parsers-save-your-llm-from-formatting-disaster-120o</li>
<li>Generating Structured Output with LLMs (Part 1) - Ankur Singh, https://ankur-singh.github.io/blog/structured-output</li>
<li>JSON prompting for LLMs - IBM Developer, https://developer.ibm.com/articles/json-prompting-llms/</li>
<li>Automating Unit and Integration Testing with Partial Oracles, https://homes.cs.washington.edu/~rjust/publ/partial_oracles_sqj_2011.pdf</li>
<li>Testing AI Systems: Handling the Test Oracle Problem, https://dev.to/qa-leaders/testing-ai-systems-handling-the-test-oracle-problem-3038</li>
<li>If you’re facing issues parsing JSON LLM outputs in backend, try this., https://www.reddit.com/r/Backend/comments/1ou602v/if_youre_facing_issues_parsing_json_llm_outputs/</li>
<li>Get consistent, well-formatted Markdown/JSON outputs from LLMs, https://community.n8n.io/t/get-consistent-well-formatted-markdown-json-outputs-from-llms/80749</li>
<li>Configure structured output for LLMs - Anyscale Docs, https://docs.anyscale.com/llm/serving/structured-output</li>
<li>Guiding LLMs The Right Way: Fast, Non-Invasive Constrained, https://openreview.net/pdf?id=pXaEYzrFae</li>
<li>LLM-as-a-Judge: automated evaluation of search query parsing, https://pmc.ncbi.nlm.nih.gov/articles/PMC12319771/</li>
<li>A Framework for Evaluating LLM Structured Output Reliability - arXiv, https://arxiv.org/html/2512.23712v1</li>
<li>A Framework for Evaluating LLM Structured Output Reliability - arXiv, https://arxiv.org/abs/2512.23712</li>
<li>A Framework for Evaluating LLM Structured Output Reliability, https://openreview.net/pdf?id=rSCV1hTZvF</li>
<li>12 XML Parsing for Java - Oracle Help Center, https://docs.oracle.com/en/database/oracle/oracle-database/26/adxdk/XML-parsing-for-Java.html</li>
<li>XQuery 3.0: An XML Query Language - W3C, https://www.w3.org/TR/xquery-30/</li>
<li>How can I see what’s wrong with an XML without looking at the data, https://stackoverflow.com/questions/52316448/how-can-i-see-whats-wrong-with-an-xml-without-looking-at-the-data-in-that-xml</li>
<li>Potential XXE attack - Datadog Docs, https://docs.datadoghq.com/security/code_security/static_analysis/static_analysis_rules/python-security/xxe-injection/</li>
<li>Benchmarking the Robustness of Agentic Systems to Adversarially, https://arxiv.org/pdf/2508.16481</li>
<li>Parsing XML with namespace in Python via ‘ElementTree’, https://stackoverflow.com/questions/14853243/parsing-xml-with-namespace-in-python-via-elementtree</li>
<li>XML Prompting as Grammar-Constrained Interaction: Fixed-Point, https://www.researchgate.net/publication/395402491_XML_Prompting_as_Grammar-Constrained_Interaction_Fixed-Point_Semantics_Convergence_Guarantees_and_Human-AI_Protocols</li>
<li>Structured Outputs: Making LLMs Reliable for Document Processing, https://generative-ai-newsroom.com/structured-outputs-making-llms-reliable-for-document-processing-c3b6b2baed36</li>
<li>Boosting AI Performance: The Power of LLM-Friendly Content in, https://developer.webex.com/blog/boosting-ai-performance-the-power-of-llm-friendly-content-in-markdown</li>
<li>Improving Legal Document Understanding Through Explicit Text, https://arxiv.org/html/2505.12837v1</li>
<li>Docling AI: A Complete Guide to Parsing - Codecademy, https://www.codecademy.com/article/docling-ai-a-complete-guide-to-parsing</li>
<li>StructEval: Benchmarking LLMs’ Capabilities to Generate Structural, https://arxiv.org/html/2505.20139v2</li>
<li>Skip processing fenced code blocks when processing Markdown, https://stackoverflow.com/questions/62405972/skip-processing-fenced-code-blocks-when-processing-markdown-files-line-by-line</li>
<li>Evaluating Responses - ChainForge Documentation, https://chainforge.ai/docs/evaluation/</li>
<li>BubuAnabelas/awesome-markdown: :memo - GitHub, https://github.com/BubuAnabelas/awesome-markdown</li>
<li>Personal Blog in 100 lines of Python Code | by Vighnesh SK - Medium, https://medium.com/@viggyvig/personal-blog-in-100-lines-of-python-code-42fc5cdd532e</li>
<li>LLM Structured Output Benchmarks are Riddled with Mistakes, https://cleanlab.ai/blog/structured-output-benchmark/</li>
<li>A Small Experiment with Web Scraping Using LLMs - PYC, https://pycx.dev/post/llm-scrape/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>