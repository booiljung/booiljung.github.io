<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2020년 3월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2020년 3월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2020년 AI 및 로봇 연구 동향</a> / <span>2020년 3월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2020년 3월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2020년 3월, AI 연구의 변곡점</h2>
<p>2020년 3월은 COVID-19 팬데믹이라는 전 지구적 위기 속에서 인공지능(AI) 기술의 역할과 방향성이 재조명된 중요한 시기였다. 본 보고서는 이 시점을 전후하여 발표된 AI 및 로봇 분야의 핵심 연구들을 심층 분석함으로써, 당시의 기술적 성취를 기록하고 미래 연구 방향에 대한 통찰을 제공하고자 한다. 팬데믹은 AI 연구에 두 가지 상반된 영향을 미쳤다. 한편으로는 AlphaFold 사례처럼 AI를 활용한 보건 위기 대응 연구를 촉진했으며 1, 다른 한편으로는 원격 근무 및 가상 학회 체제로의 전환을 강제하며 연구개발의 방법론 자체에 변화를 가져왔다.5</p>
<p>이러한 배경 속에서 대규모 컴퓨팅 자원을 보유한 거대 연구소(DeepMind, Google Brain, FAIR 등)의 영향력은 더욱 공고해졌으며, 연구의 핵심 화두는 단순히 ’성능’을 넘어 ‘효율성’, ‘일반성’, ‘해석 가능성’, 그리고 ’사회적 기여’로 확장되었다. 전례 없는 팬데믹의 발생은 바이러스 구조 규명과 같은 시급한 과학적 난제를 제시했고 1, 딥마인드와 같은 연구소는 자신들의 핵심 기술을 이 문제에 신속하게 적용하여 AI가 인류의 보편적 문제 해결에 직접 기여할 수 있음을 입증했다.1 동시에, ’더 큰 모델이 더 나은 성능을 낸다’는 기존 패러다임은 자원적 한계에 부딪히며, ICLR 2020에서 나타난 바와 같이 ’어떻게 더 효율적으로 학습하고 추론할 것인가’에 대한 연구를 가속하는 계기가 되었다.7 결과적으로, 팬데믹은 AI 연구의 응용 범위를 확장하고 사회적 책무를 부각시키는 동시에, 기존 기술의 내재적 한계를 극복하려는 연구 동향을 더욱 강화하는 ’시험대’이자 ‘가속기’ 역할을 동시에 수행했다.</p>
<p><strong>표 1: 2020년 3월 주요 AI 및 로봇 연구 요약</strong></p>
<table><thead><tr><th>연구 주제</th><th>발표 기관/학회</th><th>핵심 기여</th><th>관련 분야</th></tr></thead><tbody>
<tr><td><strong>AlphaFold COVID-19 단백질 구조 예측</strong></td><td>DeepMind</td><td>AI를 활용한 신종 바이러스 단백질 구조 신속 예측 및 공개</td><td>계산 생물학, AI for Science</td></tr>
<tr><td><strong>Agent57</strong></td><td>DeepMind</td><td>모든 Atari 57 게임에서 인간 수준을 능가한 최초의 강화학습 에이전트</td><td>심층 강화학습, 메타 학습</td></tr>
<tr><td><strong>AutoML-Zero</strong></td><td>Google Brain</td><td>기본 연산만으로 머신러닝 알고리즘을 자동 생성하는 프레임워크</td><td>AutoML, 진화 알고리즘</td></tr>
<tr><td><strong>자기-해석 가능 에이전트</strong></td><td>Google Brain</td><td>자기 주의와 신경 진화를 결합하여 해석 가능하고 효율적인 에이전트 구현</td><td>강화학습, 해석 가능한 AI</td></tr>
<tr><td><strong>ELECTRA, ALBERT, Reformer</strong></td><td>ICLR 2020</td><td>거대 언어 모델의 데이터, 파라미터, 계산 효율성을 혁신</td><td>자연어 처리(NLP)</td></tr>
<tr><td><strong>SwAV (Self-Supervised Learning)</strong></td><td>Facebook AI Research</td><td>온라인 클러스터링 기반의 효율적인 자가-지도 학습 방법론 제시</td><td>컴퓨터 비전, 자가-지도 학습</td></tr>
<tr><td><strong>강인한 공간 인식 (GNC)</strong></td><td>ICRA 2020</td><td>높은 아웃라이어 비율에서도 강인한 3D 공간 인식 알고리즘 개발</td><td>로봇 비전, 강인한 최적화</td></tr>
<tr><td><strong>미분 가능한 SLAM (gradSLAM)</strong></td><td>ICRA 2020</td><td>SLAM 시스템의 종단간 학습을 가능하게 하는 미분 가능한 프레임워크</td><td>로보틱스, SLAM</td></tr>
<tr><td><strong>선호도 기반 외골격 보행 최적화</strong></td><td>ICRA 2020</td><td>사용자의 주관적 선호도를 직접 학습하여 외골격 로봇 제어를 개인화</td><td>인간-로봇 상호작용(HRI)</td></tr>
</tbody></table>
<h2>2.  딥마인드(DeepMind)의 약진: 생명 과학과 강화학습의 한계를 넘어서</h2>
<h3>2.1  AlphaFold와 COVID-19: AI, 생명의 비밀을 풀다</h3>
<p>2020년 3월 5일, 딥마인드는 자사의 단백질 구조 예측 시스템 ’AlphaFold’의 최신 버전을 사용하여 COVID-19를 유발하는 SARS-CoV-2 바이러스와 관련된 미규명 단백질들의 3차원 구조 예측 결과를 전격 공개했다.1 이는 단순한 기술적 성과 발표를 넘어, AI 연구의 패러다임을 ’경쟁’에서 ’협력’으로, ’이론’에서 ’실천’으로 전환시킨 전략적 행보였다.</p>
<p>기술적 핵심은 AlphaFold의 ‘free-modelling’ 능력에 있다. 이는 유사한 서열을 가진 단백질의 실험적 구조 데이터(템플릿)가 없는 경우에도 아미노산 서열만으로 구조를 예측하는 것을 의미한다.3 신종 바이러스인 SARS-CoV-2의 경우 관련된 템플릿이 부족했기 때문에 이 능력이 결정적으로 중요했다. AlphaFold는 딥러닝 신경망을 통해 아미노산 간의 거리와 각도를 예측하고, 경사 하강법(gradient descent)으로 점수를 매겨 3D 구조를 생성하는 방식을 사용한다.8 초기 공개된 단백질에는 막 단백질(membrane protein), nsp2, nsp4, nsp6, 파파인 유사 단백질 분해효소(Papain-like proteinase) 등이 포함되었다.4 이들은 당시 치료제 개발의 주된 표적은 아니었으나, 바이러스의 작동 기전을 이해하는 데 중요한 단서를 제공했다.3</p>
<p>이 연구의 학술적, 사회적 의의는 막대하다. 실험적으로 수개월 이상 소요될 단백질 구조 규명 작업을 획기적으로 단축시켰으며 4, 예측 결과를 오픈 라이선스로 신속하게 공개함으로써 전 세계 연구 커뮤니티가 팬데믹에 공동으로 대응할 수 있는 중요한 과학적 자원을 제공했다.3 딥마인드는 AlphaGo를 통해 AI의 경쟁적 우월성을 입증하며 명성을 얻었으나 9, COVID-19라는 예상치 못한 변수는 그들에게 AlphaFold의 기술력을 ’사회적 기여’라는 새로운 차원에서 증명할 기회를 제공했다. 검증되지 않은 예측 결과라는 위험을 감수하고 신속하게 데이터를 공개하는 ‘과학적 협력’ 모델을 택한 이 결정은 4, AI에 대한 대중의 인식을 긍정적으로 전환하고 AI 연구의 윤리적 방향성을 제시했으며, 궁극적으로 딥마인드를 인류의 난제를 해결하는 선도적 연구 그룹으로 각인시키는 효과를 낳았다.</p>
<h3>2.2  Agent57: 범용 인공지능을 향한 새로운 이정표</h3>
<p>기존 심층 강화학습(RL) 에이전트들은 아타리 57개 게임(Atari57) 벤치마크에서 평균적으로는 높은 점수를 기록했으나, ’몬테주마의 복수(Montezuma’s Revenge)’와 같은 어려운 탐험(hard exploration) 문제나 ’스키(Skiing)’와 같은 장기적 신용 할당(long-term credit assignment) 문제에서는 인간 수준에 미치지 못하는 한계를 보였다.10 Agent57의 목표는 이 모든 57개 게임에서 일관되게 인간 벤치마크를 능가하는 최초의 단일 에이전트를 개발하는 것이었다.10 Agent57의 성공은 ’최고의 단일 전략’을 찾는 것에서 ’상황에 맞는 최적의 전략을 선택하는 능력’을 학습하는 것으로 강화학습의 패러다임을 전환시켰다는 점에서 중요한 의미를 가진다.</p>
<p>Agent57은 ‘Never Give Up (NGU)’ 에이전트를 기반으로 세 가지 핵심적인 개선을 이루었다.10 첫째, **적응형 메타 컨트롤러(Adaptive Meta-Controller)**를 도입했다. 이는 탐험적인 정책부터 순수하게 착취적인 정책까지 다양한 스펙트럼의 정책 군을 학습하고, 학습 과정 동안 어떤 정책을 우선적으로 사용할지 동적으로 선택하는 적응형 메셔니즘이다.10 이 ‘전략 선택’ 문제는 비정상적 다중 슬롯머신(non-stationary multi-armed bandit) 문제로 모델링되며, 슬라이딩 윈도우 UCB(Upper Confidence Bound) 알고리즘을 통해 에피소드 보상을 최대화하는 방향으로 정책(탐험률 <span class="math math-inline">\beta</span>와 할인율 <span class="math math-inline">\gamma</span>의 조합)을 선택한다.12 이는 에이전트가 자신의 학습 상태를 ’메타 인지’하고, 현재 가장 필요한 학습 전략(예: 초기에는 탐험, 후기에는 착취)에 자원을 동적으로 할당하는 것과 같다.</p>
<p>둘째, **상태-가치 함수 파라미터화(State-Action Value Function Parameterization)**를 개선했다. 외재적 보상(extrinsic reward)과 내재적 보상(intrinsic reward)의 기여도를 분리하여 가치 함수를 모델링함으로써, 다양한 보상 스케일 환경에서도 학습 안정성을 크게 향상시켰다.12 셋째, <strong>장기 신용 할당 문제</strong>를 개선하기 위해 BPTT(Backprop Through Time) 윈도우를 기존 R2D2 모델보다 두 배로 늘려, 시간적으로 멀리 떨어진 행동과 보상 간의 인과 관계를 더 효과적으로 학습할 수 있도록 했다.12</p>
<p>이러한 혁신을 통해 Agent57은 780억 프레임의 학습 끝에 마지막 남은 게임이었던 ’스키’에서 인간 점수를 넘어서며, Atari57 전체 게임에서 인간 벤치마크를 능가한 최초의 에이전트가 되었다.12 이는 단일 알고리즘의 혁신을 넘어, 고정된 하이퍼파라미터에 의존하는 대신 환경과 학습 단계에 맞춰 동적으로 탐험과 착취의 균형을 조절하는 ‘학습하는 방법을 학습하는’ 메타 학습적 접근법의 유효성을 입증한 것으로, 더 일반적이고 강인한 RL 에이전트로 나아가는 중요한 방향을 제시했다.</p>
<h2>3.  구글 브레인(Google Brain)의 근본적 탐구: 자동화와 해석 가능성을 향하여</h2>
<h3>3.1  AutoML-Zero: 알고리즘을 발명하는 AI</h3>
<p>2020년 3월 발표된 AutoML-Zero는 AI 연구의 대상을 ’모델’에서 ‘모델을 만드는 과정(알고리즘)’ 자체로 확장함으로써, AI에 의한 과학적 발견의 새로운 지평을 열었다. 기존 AutoML이 인간이 설계한 거대한 탐색 공간 내에서 최적의 조합을 찾는 데 중점을 둔 반면, AutoML-Zero는 기본적인 수학적 연산(덧셈, 뺄셈, 행렬곱 등)만을 조합하여 완전한 머신러닝 알고리즘을 ’진화’시키는 것을 목표로 한다.17</p>
<p>기술적 핵심은 진화 알고리즘(evolutionary algorithm)에 있다. 알고리즘 집합을 유지하며 ’설정-예측-학습’이라는 세 가지 주요 구성 요소를 갖는 후보 알고리즘을 생성 및 평가한다. 돌연변이(mutation), 교차(crossover)와 같은 연산을 통해 더 나은 성능의 알고리즘을 점진적으로 탐색하며, 이 과정에서 경사 하강법이나 역전파와 같은 복잡한 개념을 재발견하기도 한다.17</p>
<p>실제로 AutoML-Zero는 인간의 사전 지식 없이도 간단한 분류 문제에 대해 선형 회귀, 2계층 신경망과 같은 고전적인 알고리즘을 스스로 발견해냈다. 비록 발견된 알고리즘이 기존의 것을 뛰어넘지는 못했지만, 이 ‘과정’ 자체는 AI가 인간의 지식 체계를 재구성하고 확장할 수 있는 잠재력을 보여준다. 이는 머신러닝 연구의 자동화 가능성을 탐구한 근본적인 연구로, 인간 연구자의 직관과 편향에서 벗어난 새로운 형태의 알고리즘 발견 가능성을 제시했다는 점에서 의의가 크다.</p>
<h3>3.2  자기-해석 가능 에이전트 (Neuroevolution of Self-Interpretable Agents)</h3>
<p>2020년 3월, 구글 브레인 연구팀은 ‘주의력 결핍 실명(inattentional blindness)’ 현상에 착안하여, 자기 주의(self-attention) 메커니즘을 통해 입력의 극히 일부에만 집중하도록 강제된 강화학습 에이전트를 제안했다.18 이 연구는 ’제약’이 때로는 성능 저하 요인이 아니라, 오히려 효율성과 일반화를 이끄는 강력한 ’귀납적 편향(inductive bias)’이 될 수 있음을 증명했다.</p>
<p>기술적 핵심은 세 가지로 요약된다. 첫째, **자기 주의 병목(Self-Attention Bottleneck)**이다. 에이전트는 전체 시각 입력 대신, 자기 주의 모듈이 선택한 소수의 이미지 패치(patch)만을 입력으로 받아 정책을 결정한다. 이 주의 분포 자체가 에이전트의 의사결정 과정을 시각적으로 설명하는 ’해석’이 된다.18 둘째, **신경 진화(Neuroevolution)**를 사용했다. 자기 주의 메커니즘은 미분 불가능한 연산을 포함할 수 있어 경사 기반 학습이 어렵다. 연구팀은 이를 해결하기 위해 진화 전략(evolution strategies)과 같은 신경 진화 기법을 사용하여 에이전트의 파라미터를 직접 최적화했다.18 셋째, <strong>간접 인코딩(Indirect Encoding)</strong> 개념을 활용했다. 자기 주의는 소수의 키(key)-쿼리(query) 파라미터로부터 거대한 암묵적 가중치 행렬을 생성하는 ’간접 인코딩’의 한 형태로 볼 수 있다. 이는 <span class="math math-inline">\mathcal{O}(n^2)</span> 크기의 가중치 행렬을 <span class="math math-inline">\mathcal{O}(d)</span> (n≫d)개의 파라미터로 표현하여 극적인 파라미터 효율성을 가능하게 한다.19</p>
<p>이러한 접근법을 통해, 에이전트는 기존 방법 대비 1000배 이상 적은 파라미터(4000개 미만)로 CarRacing, DoomTakeCover와 같은 어려운 비전 기반 RL 태스크를 해결했다.18 또한, 배경색 변화 등 학습 환경과 다른 테스트 환경에서도 강인한 일반화 성능을 보였다.20 의도적으로 설계된 정보 병목 현상은 모델의 해석 가능성을 확보하는 수단을 넘어, 모델이 태스크의 본질과 관련된 ’가장 중요한 정보’를 선택하도록 강제함으로써 더 효율적이고 강인한 표상을 학습하도록 유도하는 핵심 메커니즘으로 작용했다. 이는 성능, 효율성, 해석 가능성이라는 세 가지 목표를 동시에 달성할 수 있음을 보여준 중요한 연구이다.</p>
<h2>4.  패러다임의 진화: 주요 학회에서 드러난 핵심 연구 동향</h2>
<h3>4.1  자연어 처리의 효율성 혁명 (ICLR 2020)</h3>
<p>BERT 이후 거대 언어 모델(LLM)의 규모 경쟁이 심화되면서 막대한 계산 비용과 데이터 요구량이 한계로 지적되었다. ICLR 2020에서는 이러한 LLM의 ’효율성’을 개선하려는 연구가 주류를 이루었으며 7, 이는 ’규모의 확장’에서 ’규모의 효율화’로 무게 중심이 이동하는 명백한 전환점을 보여주었다. 이는 단순히 기존 모델을 경량화하는 것을 넘어, 사전 학습 방식, 모델 아키텍처, 핵심 연산 등 다각적인 차원에서 효율성을 재정의하려는 시도였다.</p>
<p><strong>ELECTRA</strong>는 기존의 Masked Language Model (MLM)이 전체 토큰의 15%만 학습하는 비효율성을 지적하고, ’대체 토큰 탐지(Replaced Token Detection)’라는 새로운 사전 학습 과제를 제안했다.7 작은 생성자(Generator)가 일부 토큰을 그럴듯한 가짜 토큰으로 바꾸면, 판별자(Discriminator)는 모든 토큰에 대해 진짜인지 가짜인지를 예측한다. 이 방식은 모든 입력 토큰에서 학습 신호를 얻어 데이터 효율성을 극대화했다. 핵심 손실 함수는 생성자의 MLM 손실과 판별자의 이진 분류 손실의 조합으로 표현된다.24</p>
<p><span class="math math-display">
\min_{\boldsymbol{\theta}_{\text{G}},\boldsymbol{\theta}_{\text{D}}} \sum_{\mathbf{x} \in \mathbf{X}} \mathbf{L}_{\text{MLM}}(\mathbf{x}, \boldsymbol{\theta}_{\text{G}}) + \lambda \mathbf{L}_{\text{Disc}}(\mathbf{x}, \boldsymbol{\theta}_{\text{D}})
</span><br />
<strong>ALBERT</strong>는 ’A Lite BERT’라는 이름처럼, 두 가지 주요 기법으로 BERT의 파라미터 효율성을 높였다.7 첫째, ’교차-레이어 파라미터 공유(Cross-layer parameter sharing)’를 통해 모든 트랜스포머 레이어가 동일한 파라미터를 공유하여 모델 크기를 대폭 줄였다. 둘째, ’임베딩 파라미터 인수분해(Factorized embedding parameterization)’를 통해 거대한 어휘 임베딩 행렬을 두 개의 작은 행렬로 분해했다. 이를 통해 BERT-large보다 18배 적은 파라미터로 더 나은 성능을 달성했다.</p>
<p><strong>Reformer</strong>는 트랜스포머가 긴 시퀀스를 처리할 때 발생하는 <span class="math math-inline">O(L^2)</span>의 메모리 및 계산 복잡도 문제를 해결했다.7 이를 위해 ’지역 민감 해싱(Locality-Sensitive Hashing, LSH) 어텐션’을 사용하여 전체 어텐션 계산을 근사했고, ’가역 잔차 네트워크(Reversible Residual Networks)’를 도입하여 학습 시 중간 활성화 값을 저장할 필요를 없애 메모리 사용량을 획기적으로 줄였다.</p>
<p>이러한 연구들은 NLP 커뮤니티가 ’성능’이라는 단일 목표에서 벗어나, ’성능-효율성 트레이드오프’라는 다차원적 목표 공간을 탐색하기 시작했음을 의미한다. 이는 이후 DistilBERT, TinyBERT 등 경량 모델의 대중화를 이끌었고, LLM을 실제 산업 환경에 적용 가능하게 만드는 기반 기술이 되었다.</p>
<h3>4.2  로보틱스의 강인함과 지능 (ICRA 2020)</h3>
<p>ICRA 2020은 COVID-19로 인해 가상으로 개최되었음에도 불구하고 25, 로봇이 불확실하고 동적인 실제 환경에서 강인하게 작동하기 위한 핵심 기술들을 선보였다. 이 학회의 주요 연구들은 로보틱스가 이상적인 실험실 환경을 넘어, 아웃라이어가 만연하고, 시스템 모델이 불완전하며, 인간과 긴밀히 상호작용해야 하는 ’현실 세계의 복잡성’을 정면으로 마주하고 있음을 보여준다. 각각 ‘데이터’, ‘모델’, ’목표’의 불완전성이라는 로보틱스의 근본적인 문제에 대한 2020년 시점의 가장 진보된 해법들을 제시하며, 강인하고(robust), 적응적이며(adaptive), 인간 친화적인(human-centric) 로봇 기술로의 발전을 이끌었다.</p>
<h4>4.2.1  강인한 공간 인식 (Robust Spatial Perception)</h4>
<p>“Graduated Non-Convexity for Robust Spatial Perception: From Non-Minimal Solvers to Global Outlier Rejection” 논문은 ICRA 2020 로봇 비전 부문 최우수 논문상을 수상했으며 27, 센서 데이터의 ‘불완전성’(아웃라이어) 문제에 대한 강인한 해법을 제시했다. 로봇 인식 문제에서 아웃라이어는 치명적인 오류를 유발하는데, 기존의 비-최소 솔버(non-minimal solver)는 아웃라이어에 취약하고 RANSAC과 같은 방법은 최적성을 보장하지 않는다. 이 연구는 점진적 비볼록(Graduated Non-Convexity, GNC) 기법을 사용하여 이 문제를 해결했다. GNC는 Black-Rangarajan 쌍대성을 활용하여, 처음에는 풀기 쉬운 볼록 함수(convex function)로 최적화를 시작하고 점진적으로 원래의 비볼록(non-convex) 강인한 비용 함수에 가깝게 변형시켜 가며 해를 찾는다. 이를 통해 초기값 없이도 70-80%의 높은 아웃라이어 비율에서도 강인한 해를 찾을 수 있었다.28</p>
<h4>4.2.2  미분 가능한 SLAM (Differentiable SLAM)</h4>
<p>“gradSLAM: Dense SLAM meets Automatic Differentiation” 논문은 시스템 모델의 ’불완전성’을 데이터 기반 학습으로 보완할 수 있는 길을 열었다.32 전통적인 SLAM 시스템은 데이터 연관, 최적화 등 여러 비-미분 가능한 모듈로 구성되어 종단간(end-to-end) 학습이 불가능했다. gradSLAM은 PyTorch와 같은 자동 미분 프레임워크를 활용하여 SLAM 파이프라인의 핵심 구성 요소들(예: ICP, 표면 융합, 광선 투사)을 모두 미분 가능하게 재설계했다. 이를 통해 3D 지도 생성 결과로부터 입력 이미지 픽셀까지 역전파가 가능해져, SLAM 시스템 전체를 데이터 기반으로 학습하고 최적화할 수 있는 새로운 길을 열었다.33 이는 전통적인 모델 기반 접근법과 최신 딥러닝 접근법의 융합을 상징한다.</p>
<h4>4.2.3  인간 중심 로보틱스 (Human-in-the-Loop Robotics)</h4>
<p>“Preference-Based Learning for Exoskeleton Gait Optimization” 논문은 ICRA 2020 최우수 컨퍼런스 논문상을 수상했으며 27, 최적화 목표의 ‘불완전성’(정량화하기 어려운 인간의 주관성)을 인간-루프 학습으로 해결했다. 외골격 로봇의 보행 패턴을 최적화할 때, ’에너지 효율’과 같은 정량적 지표만으로는 사용자의 ’편안함’이나 ’안정감’과 같은 주관적 만족도를 포착하기 어렵다. 이 연구는 사용자의 선호도(preference)를 직접 학습에 활용하는 CoSpar (Coactive-Sparse) 알고리즘을 제안했다. 시스템이 제시하는 두 가지 보행 패턴 중 사용자가 더 선호하는 쪽을 선택하는 방식(pairwise comparison)으로 데이터를 수집하고, 베이지안 최적화(Bayesian optimization)를 통해 사용자의 잠재적 선호도 함수(latent utility function)를 모델링하여 최적의 보행 파라미터를 찾아간다.36</p>
<h2>5.  자가-지도 학습(Self-Supervised Learning)의 부상: FAIR의 SwAV</h2>
<p>2020년 전후, AI 커뮤니티는 막대한 양의 레이블링된 데이터에 대한 의존도를 줄이기 위한 대안으로 자가-지도 학습(SSL)에 주목했다. NLP 분야에서 BERT의 성공 이후, 컴퓨터 비전 분야에서도 SSL이 지도 학습을 뛰어넘을 수 있을지에 대한 기대가 고조되었다.40 이 흐름 속에서 Facebook AI Research(FAIR)가 발표한 SwAV는 SSL 연구에서 ’무엇을 비교할 것인가’에 대한 관점을 ’개별 인스턴스’에서 ’개념적 군집(클러스터)’으로 전환시켜 중요한 진전을 이루었다.</p>
<p>SwAV(Unsupervised Learning of Visual Features by Contrasting Cluster Assignments)는 레이블 없는 이미지로부터 시각적 특징을 학습하는 효율적인 SSL 방법론이다.39 기존의 대조 학습(contrastive learning) 방법들은 한 이미지의 다른 증강(augmentation) 버전들을 서로 ’positive pair’로, 다른 이미지들을 ’negative pair’로 설정하고, positive pair의 특징 벡터는 가깝게, negative pair는 멀게 학습했다. 이 방식은 많은 수의 negative pair를 필요로 하여 계산 비용이 높았다. SwAV는 이 패러다임을 전환했다.39</p>
<p>SwAV의 기술적 핵심은 <strong>’Swapped Prediction’과 온라인 클러스터링</strong>에 있다. 특징 벡터를 직접 비교하는 대신, 현재 배치(batch) 내의 특징들을 몇 개의 프로토타입(prototype) 벡터로 온라인 클러스터링하여 ’코드(code)’를 할당한다. 그리고 한 증강 이미지의 특징 벡터(<span class="math math-inline">z_s</span>)를 이용해 다른 증강 이미지의 코드(<span class="math math-inline">q_t</span>)를 예측하도록 학습한다. 손실 함수는 두 예측 방향의 손실을 합산하는 형태(<span class="math math-inline">\mathcal{L}(z_t, z_s) = l(z_t, q_s) + l(z_s, q_t)</span>)로 구성된다.39 이 ’엇갈린 예측’은 쌍으로 비교할 필요 없이 군집 할당의 일관성을 강제하는 효율적인 방법을 제공한다. 이는 “이미지 A의 한 버전이 ‘고양이’ 클러스터에 속한다면, 이미지 A의 다른 버전도 ‘고양이’ 클러스터에 속한다고 예측할 수 있어야 한다“는 일관성 제약을 부과하는 것과 같다. 이 방식은 더 높은 수준의 의미론적(semantic) 표상을 학습하도록 유도하며, 인스턴스 수준의 구별보다 더 효율적이고 일반화에 유리한 학습 목표를 제공했다.</p>
<p>SwAV는 대규모 메모리 뱅크나 모멘텀 인코더 없이도 SOTA 성능을 달성했으며, 특히 Multi-crop 증강 기법과 결합하여 ImageNet에서 지도 학습에 근접하는 성능을 보였다. SwAV의 성공을 바탕으로, FAIR는 10억 개의 무작위 인스타그램 이미지로 학습한 SEER(SElf-supERvised) 모델을 구축하여 SSL의 확장성을 증명했다. SEER는 ImageNet에서 84.2%의 Top-1 정확도를 달성하며 당시 최고의 SSL 모델 성능을 경신했다.42 이는 비전 분야에서 SSL이 지도 학습의 강력한 대안이 될 수 있음을 입증한 중요한 성과이다.</p>
<h2>6. 결론: 2020년 3월이 남긴 유산과 미래 전망</h2>
<p>2020년 3월을 기점으로 AI 및 로봇 연구는 팬데믹이라는 특수한 상황 속에서 기술의 사회적 책무를 증명하는 동시에, 내부적으로는 효율성, 일반성, 해석 가능성, 강인성이라는 내실을 다지는 중요한 변곡점을 맞았다. 이 시기에 발표된 주요 성과들은 AI 기술의 다차원적 발전을 통합적으로 보여준다.</p>
<ul>
<li>
<p><strong>범용성(Generality):</strong> Agent57은 다양한 환경에 적응하는 능력을, AutoML-Zero는 알고리즘 자체의 보편적 생성을 탐구하며 범용 AI를 향한 각기 다른 경로를 제시했다.</p>
</li>
<li>
<p><strong>효율성(Efficiency):</strong> ICLR 2020의 NLP 연구들은 거대 모델의 실용성을, SwAV는 데이터 레이블링의 비효율성을 극복하는 길을 제시하며 AI 기술의 접근성을 높였다.</p>
</li>
<li>
<p><strong>해석 가능성 및 강인성(Interpretability &amp; Robustness):</strong> 구글의 자기-해석 가능 에이전트와 ICRA의 GNC 연구는 AI 시스템의 신뢰성을 높이는 핵심 기술을 선보이며, AI가 현실 세계의 복잡성과 불확실성에 대처할 수 있는 능력을 강화했다.</p>
</li>
<li>
<p><strong>사회적 기여(Social Impact):</strong> AlphaFold의 COVID-19 단백질 구조 예측과 선호도 기반 외골격 로봇 연구는 AI가 인류의 건강과 삶의 질 향상에 직접 기여할 수 있는 구체적인 사례를 보여주었다.</p>
</li>
</ul>
<p>이 시기의 연구들은 이후 AI 분야의 주요 흐름을 형성했다. 효율적인 트랜스포머 아키텍처 연구는 LLM의 폭발적 성장을 이끌었고, 자가-지도 학습은 파운데이션 모델(foundation model)의 기반이 되었다. 또한, AI의 윤리 및 사회적 영향에 대한 논의가 본격화되며 44, 기술 개발과 함께 책임감 있는 AI 거버넌스의 중요성이 대두되었다. 2020년 3월의 성과들은 AI가 가능성의 시대를 지나 실용성과 책임의 시대로 접어들었음을 알리는 명백한 신호탄이었다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>AI and control of Covid-19 coronavirus - Artificial Intelligence - The Council of Europe, https://www.coe.int/en/web/artificial-intelligence/ai-and-control-of-covid-19-coronavirus</li>
<li>Month: March 2020 - Synced Review, https://syncedreview.com/2020/03/</li>
<li>Crick scientists support DeepMind’s effort to make COVID-19 data available, https://www.crick.ac.uk/news/2020-03-05_crick-scientists-support-deepminds-effort-to-make-covid-19-data-available</li>
<li>Google DeepMind Releases Structure Predictions for Coronavirus …, https://syncedreview.com/2020/03/05/google-deepmind-releases-structure-predictions-for-coronavirus-linked-proteins/</li>
<li>Top AI Conferences of 2020 - Ai4, https://ai4.io/blog/2020/03/11/top-20-ai-conferences-of-2020/</li>
<li>ICLR 2020, https://iclr.cc/virtual_2020/</li>
<li>The Best NLP Papers From ICLR 2020 - TOPBOTS, https://www.topbots.com/best-nlp-papers-from-iclr-2020/</li>
<li>AlphaFold Algorithm Predicts COVID-19 Protein Structures - InfoQ, https://www.infoq.com/news/2020/03/deepmind-covid-19/</li>
<li>Our AI journey and milestones - Google AI, https://ai.google/our-ai-journey/</li>
<li>Agent57: Outperforming the human Atari benchmark - Google …, https://deepmind.google/discover/blog/agent57-outperforming-the-human-atari-benchmark/</li>
<li>[2003.13350] Agent57: Outperforming the Atari Human Benchmark : r/MachineLearning - Reddit, https://www.reddit.com/r/MachineLearning/comments/fsbi38/200313350_agent57_outperforming_the_atari_human/</li>
<li>Agent57: Outperforming the Atari Human Benchmark, http://proceedings.mlr.press/v119/badia20a/badia20a.pdf</li>
<li>Google DeepMind - Wikipedia, https://en.wikipedia.org/wiki/Google_DeepMind</li>
<li>[2003.13350] Agent57: Outperforming the Atari Human Benchmark - arXiv, https://arxiv.org/abs/2003.13350</li>
<li>[2209.07550] Human-level Atari 200x faster - arXiv, https://arxiv.org/abs/2209.07550</li>
<li>DeepMind’s MEME Agent Achieves Human-level Atari Game Performance 200x Faster Than Agent57 - Synced Review, https://syncedreview.com/2022/09/21/deepminds-meme-agent-achieves-human-level-atari-game-performance-200x-faster-than-agent57/</li>
<li>Interesting AI papers published in 2020 - DataScienceCentral.com, https://www.datasciencecentral.com/ii2020/</li>
<li>Google Introduces Neuroevolution for Self-Interpretable Agents - Synced Review, https://syncedreview.com/2020/03/23/google-introduces-neuroevolution-for-self-interpretable-agents/</li>
<li>Deep Neuroevolution of Self-Interpretable Agents, https://attentionagent.github.io/</li>
<li>Neuroevolution of Self-Interpretable Agents - Google Research, https://research.google/pubs/neuroevolution-of-self-interpretable-agents/</li>
<li>Neuroevolution of self-interpretable agents | Request PDF - ResearchGate, https://www.researchgate.net/publication/342536989_Neuroevolution_of_self-interpretable_agents</li>
<li>Paper Digest: ICLR 2020 Highlights, https://www.paperdigest.org/2019/12/iclr-2020-highlights/</li>
<li>[D] What are your favorite papers from ICLR 2020? + a list of our picks by domain. - Reddit, https://www.reddit.com/r/MachineLearning/comments/gn6j0m/d_what_are_your_favorite_papers_from_iclr_2020_a/</li>
<li>ELECTRA: PRE-TRAINING TEXT ENCODERS - OpenReview, https://openreview.net/pdf?id=r1xMH1BtvB</li>
<li>2020 IEEE International Conference on Robotics and Automation - ICRA 2020, https://ewh.ieee.org/soc/ras/conf/fullysponsored/icra/ICRA2020/www.icra2020.org/index.html</li>
<li>ICRA 2020 : IEEE International Conference on Robotics and Automation - Accepted Papers, Deadline, Impact Factor &amp; Score 2025 | Research.com, https://research.com/conference/icra-2020</li>
<li>[R] A List of Best Papers from Top AI Conferences in 2020 - Reddit, https://www.reddit.com/r/MachineLearning/comments/knai5q/r_a_list_of_best_papers_from_top_ai_conferences/</li>
<li>(PDF) Graduated Non-Convexity for Robust Spatial Perception …, https://www.researchgate.net/publication/338588927_Graduated_Non-Convexity_for_Robust_Spatial_Perception_From_Non-Minimal_Solvers_to_Global_Outlier_Rejection</li>
<li>[1909.08605] Graduated Non-Convexity for Robust Spatial Perception: From Non-Minimal Solvers to Global Outlier Rejection - arXiv, https://arxiv.org/abs/1909.08605</li>
<li>MIT Open Access Articles Graduated Non-Convexity for Robust Spatial Perception, https://dspace.mit.edu/bitstream/handle/1721.1/136232/1909.08605.pdf?sequence=2&amp;isAllowed=y</li>
<li>@lucacarlone1 - GitHub Pages, https://advmlincv.github.io/cvpr21-tutorial/slides/lecture9.pdf</li>
<li>PaoPaoRobot/ICRA2020-paper-list - GitHub, https://github.com/PaoPaoRobot/ICRA2020-paper-list</li>
<li>gradslam: About, https://gradslam.github.io/</li>
<li>IRCA Best Paper Awards - Information Science and Technology - Caltech, https://ist.caltech.edu/news/irca-best-paper-awards</li>
<li>Preference-Based Learning for Exoskeleton Gait Optimization - BibBase, https://bibbase.org/network/publication/tucker-novoseller-kann-sui-yue-burdick-ames-preferencebasedlearningforexoskeletongaitoptimization-2020</li>
<li>Preference-Based Learning for User-Guided HZD Gait Generation on Bipedal Walking Robots - ResearchGate, https://www.researchgate.net/publication/355435395_Preference-Based_Learning_for_User-Guided_HZD_Gait_Generation_on_Bipedal_Walking_Robots</li>
<li>[PDF] Preference-Based Learning for Exoskeleton Gait Optimization | Semantic Scholar, https://www.semanticscholar.org/paper/Preference-Based-Learning-for-Exoskeleton-Gait-Tucker-Novoseller/216366d3a1c32f641f9002ff422c5068040c455c</li>
<li>(PDF) Preference-Based Learning for Exoskeleton Gait Optimization, https://www.researchgate.net/publication/338492982_Preference-Based_Learning_for_Exoskeleton_Gait_Optimization</li>
<li>facebookresearch/swav: PyTorch implementation of SwAV … - GitHub, https://github.com/facebookresearch/swav</li>
<li>Self-Supervised Learning (SSL): Future of Scalable, Multimodal, and AI - E-SPIN Group, https://www.e-spincorp.com/self-supervised-learning-ai-future/</li>
<li>Self-supervised learning: The dark matter of intelligence - AI at Meta, https://ai.meta.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/</li>
<li>Brief Review — SEER: Self-supervised Pretraining of Visual Features in the Wild, https://sh-tsang.medium.com/brief-review-seer-self-supervised-pretraining-of-visual-features-in-the-wild-d1d4837ec05c</li>
<li>SEER 10B: Better, fairer computer vision through self-supervised learning on diverse datasets - Meta AI, https://ai.meta.com/blog/seer-10b-better-fairer-computer-vision-through-self-supervised-learning-training-on-diverse-datasets/</li>
<li>The ethics of artificial intelligence: Issues and initiatives - European Parliament, https://www.europarl.europa.eu/RegData/etudes/STUD/2020/634452/EPRS_STU(2020)634452_EN.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>