<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2020년 2월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2020년 2월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2020년 AI 및 로봇 연구 동향</a> / <span>2020년 2월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2020년 2월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2020년 2월, AI 연구의 변곡점</h2>
<p>2020년 2월은 인공지능(AI) 및 로봇 공학 분야에서 중요한 변곡점을 나타내는 시기였다. 이 시기는 거대 언어 모델(LLM)의 내부 작동 원리에 대한 심도 있는 탐구가 이루어지고, 비지도 학습(Unsupervised Learning) 패러다임이 시각적 표현 학습 분야에서 새로운 지평을 여는 등, 학계의 연구 방향성에 있어 중요한 전환이 이루어졌음을 시사한다. 본 보고서는 이 시기의 핵심적인 학술적 성과와 기술적 동향을 심층적으로 분석하고자 한다.</p>
<p>이 시기의 주요 동향은 몇 가지 핵심적인 사건과 연구 발표로 요약될 수 있다. 첫째, 뉴욕에서 개최된 제34회 AAAI 인공지능 학회(AAAI-2020)는 전 세계 연구자들이 모여 최신 연구 성과를 공유하는 핵심적인 학술적 구심점 역할을 했다.1 둘째, Google 연구팀이 발표한 SimCLR 논문은 레이블이 없는 데이터로부터 유의미한 시각적 특징을 학습하는 대조 학습(Contrastive Learning) 방법론을 제시하며 컴퓨터 비전 분야의 비지도 학습 연구에 결정적인 이정표를 세웠다.2 셋째, “BERTology” 서베이 논문은 자연어 처리(NLP) 분야의 근간이 된 BERT 모델의 내부 작동 방식과 언어적 지식 습득 과정을 종합적으로 분석하여, ’블랙박스’로 여겨지던 거대 모델에 대한 과학적 이해를 촉진했다.3 마지막으로, 자율주행, 로봇 조작, 인간-로봇 상호작용 등 다양한 로봇 공학 분야에서 실제 환경의 복잡성을 해결하기 위한 데이터 기반 접근법과 생체모방 기술이 주목받았다.4</p>
<p>본 보고서는 AAAI-2020 학회의 주요 동향을 시작으로, 당시 발표된 가장 영향력 있는 두 편의 AI 논문을 심층 분석하고, 로봇 공학의 세부 분야별 주요 연구 동향을 조망한다. 마지막으로, 이러한 기술 발전이 산업 및 사회에 미치는 영향을 고찰하며 마무리한다.</p>
<h2>2.  제34회 AAAI 인공지능 학회(AAAI-20) 주요 동향</h2>
<h3>2.1  AAAI-2020 개요 및 학술적 위상</h3>
<p>제34회 AAAI 인공지능 학회는 2020년 2월 7일부터 12일까지 미국 뉴욕의 힐튼 뉴욕 미드타운에서 개최되었다.1 Francesca Rossi (IBM Research)가 총괄 의장을, Vincent Conitzer (Duke University)와 Fei Sha (Google Research 및 University of Southern California)가 프로그램 공동 의장을 맡아 행사를 이끌었다.1 AAAI 학회는 AI 분야의 이론 및 응용 연구를 촉진하고, 전 세계의 연구자, 실무자, 과학자, 엔지니어 간의 지적 교류를 활성화하는 것을 핵심 목표로 삼는다.1</p>
<p>특히 이번 학회에서는 2018년 ACM 튜링상 수상자인 Yann LeCun, Geoffrey Hinton, Yoshua Bengio의 특별 강연 및 패널 세션이 열려 큰 주목을 받았다.1 딥러닝 분야를 개척한 세 거장이 한자리에 모여 해당 분야의 과거, 현재, 그리고 미래에 대한 심도 있는 논의를 펼친 이 행사는, 당시 AI 연구의 주류로서 딥러닝이 차지하는 압도적인 위치와 이들의 학술적 영향력을 상징적으로 보여주는 사건이었다.</p>
<h3>2.2  주요 기술 트랙 및 연구 경향</h3>
<p>AAAI-2020은 총 7개의 주요 기술 트랙과 더불어 학생 트랙, 특별 프로그램 등 다채로운 세션으로 구성되어 AI의 광범위한 스펙트럼을 포괄적으로 다루었다.7 각 트랙에서는 주목할 만한 연구 경향이 나타났다.</p>
<p><strong>게임 AI 및 인터랙티브 디지털 엔터테인먼트 (AIIDE):</strong> 게임 환경은 복잡한 규칙과 동적인 상호작용을 탐구할 수 있는 이상적인 AI 연구 테스트베드로 자리매김했다. 발표된 연구들은 강화학습을 이용한 절차적 콘텐츠 생성(PCGRL), 게임 레벨과 플레이 에이전트를 동시에 생성하는 기법, 그리고 트랜스포머 모델을 활용하여 단어 연상 게임 ’Codenames’를 플레이하는 에이전트 개발 등 다岐한 주제를 포함했다.8 이러한 연구들은 AI가 단순히 주어진 게임을 잘하는 것을 넘어, 창의적인 콘텐츠를 생성하고 여러 게임에 걸쳐 일반화될 수 있는 능력을 갖추도록 하는 데 초점을 맞추고 있다. 이는 게임 환경이 일반 인공지능(AGI) 연구에 중요한 기여를 할 수 있음을 시사한다.</p>
<p><strong>웹 및 소셜 미디어 (ICWSM):</strong> AI 기술은 디지털 사회의 복잡한 현상을 분석하고 당면 과제를 해결하는 데 핵심적인 도구로 활용되었다. 소셜 미디어의 방대한 데이터를 활용한 가짜 뉴스 탐지, 온라인 커뮤니티의 배타성 형성 과정 분석, 그리고 Apple News와 같은 뉴스 큐레이션 시스템의 알고리즘적 편향성을 감사(Auditing)하는 연구 등이 활발히 진행되었다.9 이는 AI 연구의 범위가 순수한 기술 개발을 넘어, 기술이 사회에 미치는 영향을 비판적으로 성찰하고 사회적 책임을 다루는 방향으로 확장되고 있음을 명확히 보여준다.</p>
<h3>2.3  동반 개최 행사를 통해 본 AI 연구의 확장</h3>
<p>AAAI-2020은 핵심 학술대회와 더불어 여러 동반 행사를 개최함으로써 AI 연구의 다각적인 발전을 도모했다.</p>
<ul>
<li>
<p><strong>IAAI-20 (혁신적 AI 응용 학회):</strong> 이 학회는 학술적 성과를 넘어, 실제 산업 현장에 성공적으로 배포되어 측정 가능한 이점을 창출한 AI 응용 사례 연구에 초점을 맞췄다.6 이는 학계의 이론적 연구와 산업 현장의 실용적 요구 사이의 간극을 줄이고, AI 기술의 실질적인 가치를 입증하려는 커뮤니티의 노력을 반영한다.</p>
</li>
<li>
<p><strong>AIES-20 (AI, 윤리, 사회 학회):</strong> AAAI와 ACM이 공동으로 2월 7일부터 8일까지 주최한 이 학회는 AI 기술이 야기하는 윤리적, 사회적 함의에 대한 깊이 있는 논의의 장을 마련했다.11 기술의 발전 속도에 발맞춰 윤리적 가이드라인과 사회적 합의를 형성하는 것이 시급한 과제임을 인식하고, 이를 학문적 의제로 본격화했다는 점에서 큰 의미를 가진다.</p>
</li>
</ul>
<p>AAAI-2020이 핵심 기술 트랙(이론)과 함께 IAAI(응용), AIES(윤리/사회)를 같은 장소에서 비중 있게 다룬 것은 2020년 당시 AI 연구 커뮤니티의 중요한 패러다임 변화를 보여주는 구조적 증거이다. 이는 연구자들이 단순히 더 강력하고 효율적인 알고리즘을 개발하는 것을 넘어, ’이 기술을 어떻게 실제 문제에 효과적으로 적용할 것인가(IAAI)’와 ’그 적용이 사회에 어떤 윤리적, 사회적 영향을 미칠 것인가(AIES)’라는 질문을 동시에 중요하게 다루기 시작했음을 의미한다. AI 기술이 점차 성숙기에 접어들면서 그 막대한 영향력에 대한 책임 있는 고찰이 연구의 필수적인 부분으로 자리 잡고 있음을 시사하는 중요한 흐름이라 할 수 있다.</p>
<p>Table 1: AAAI-2020 및 주요 동반 개최 행사 개요:</p>
<table><thead><tr><th>구분</th><th>행사명 (영문 약칭)</th><th>핵심 주제</th><th>2020년 개최 정보</th><th>성격</th></tr></thead><tbody>
<tr><td><strong>메인 학회</strong></td><td><strong>AAAI-20</strong></td><td>인공지능 전반의 이론 및 응용 연구</td><td>2월 7일-12일, 미국 뉴욕</td><td>34회차 메인 컨퍼런스</td></tr>
<tr><td><strong>동반 개최</strong></td><td><strong>IAAI-20</strong></td><td>실제 산업에 적용된 혁신적인 AI 응용 사례</td><td>2월 9일-11일, 미국 뉴욕</td><td>AAAI-20과 동일 장소에서 개최</td></tr>
<tr><td><strong>동반 개최</strong></td><td><strong>AIES-20</strong></td><td>AI 기술의 윤리적, 법적, 사회적 영향</td><td>2월 7일-8일, 미국 뉴욕</td><td>AAAI-20과 동일 장소에서 개최</td></tr>
<tr><td><strong>연계 학회</strong></td><td><strong>AIIDE-20</strong></td><td>게임 및 인터랙티브 디지털 엔터테인먼트를 위한 AI</td><td>10월 19일-23일, 온라인 개최</td><td>AAAI가 후원하는 독립 학회</td></tr>
<tr><td><strong>연계 학회</strong></td><td><strong>ICWSM-20</strong></td><td>웹 및 소셜 미디어 분석을 위한 계산적 접근</td><td>6월 8일-11일, 온라인 개최</td><td>AAAI가 후원하는 독립 학회</td></tr>
</tbody></table>
<h2>3.  2020년 2월 주요 AI 연구 논문 심층 분석</h2>
<p>2020년 2월은 AI 분야의 패러다임을 바꾼 두 편의 중요한 논문이 발표된 시기이다. 하나는 컴퓨터 비전 분야에서 자기 지도 학습의 새로운 가능성을 연 SimCLR이며, 다른 하나는 거대 언어 모델 BERT에 대한 깊이 있는 이해를 제공한 “BERTology 입문“이다.</p>
<h3>3.1  시각적 표현 학습의 새로운 지평: SimCLR</h3>
<ul>
<li>
<p><strong>논문 정보:</strong> “A Simple Framework for Contrastive Learning of Visual Representations”, Ting Chen 외 (Google Research), 2020년 2월 13일 arXiv 제출.2</p>
</li>
<li>
<p><strong>핵심 개념: 대조 학습 기반 자기 지도 학습:</strong> SimCLR은 레이블이 없는 방대한 이미지 데이터로부터 유용한 시각적 표현(representation)을 학습하기 위한 프레임워크를 제안한다.12 핵심 아이디어는 동일한 이미지에 서로 다른 데이터 증강(augmentation)을 적용하여 생성된 ’긍정 쌍(positive pair)’의 표현은 잠재 공간(latent space)에서 가깝게 만들고, 다른 이미지로부터 생성된 ’부정 쌍(negative pair)’의 표현은 멀게 만드는 것이다.13</p>
</li>
<li>
<p><strong>SimCLR 프레임워크 상세 분석:</strong></p>
</li>
</ul>
<ol>
<li>
<p><strong>데이터 증강 (Data Augmentation):</strong> 하나의 이미지를 무작위 자르기, 색상 왜곡, 가우시안 블러 등을 조합하여 두 개의 증강된 이미지(<span class="math math-inline">\tilde{x}_i</span>, <span class="math math-inline">\tilde{x}_j</span>)를 생성한다. 이 두 이미지가 긍정 쌍이 된다. 이 연구는 특히 ’데이터 증강 기법의 정교한 조합’이 효과적인 표현 학습에 결정적임을 실험적으로 밝혔다.2</p>
</li>
<li>
<p><strong>기반 인코더 (Base Encoder, <span class="math math-inline">f(\cdot)</span>):</strong> ResNet과 같은 CNN 아키텍처를 사용하여 각 증강 이미지로부터 표현 벡터(<span class="math math-inline">h_i = f(\tilde{x}_i)</span>)를 추출한다.13</p>
</li>
<li>
<p><strong>투영 헤드 (Projection Head, <span class="math math-inline">g(\cdot)</span>):</strong> 인코더 위에 추가된 작은 다층 퍼셉트론(MLP) 네트워크로, 표현 벡터 <span class="math math-inline">h_i</span>를 대조 손실이 계산되는 더 낮은 차원의 잠재 공간으로 투영하여 <span class="math math-inline">z_i = g(h_i)</span>를 생성한다. 학습이 완료된 후에는 이 투영 헤드를 버리고 인코더 <span class="math math-inline">f(\cdot)</span>와 표현 <span class="math math-inline">h</span>만을 다운스트림 작업에 사용한다. 이 비선형 변환을 추가하는 것이 표현의 질을 크게 향상시킨다는 점이 이 논문의 핵심 발견 중 하나다.2</p>
</li>
</ol>
<ul>
<li>
<p><strong>NT-Xent 손실 함수 (Normalized Temperature-Scaled Cross-Entropy Loss):</strong> SimCLR이 제안한 손실 함수로, 미니배치 내의 한 긍정 쌍 <span class="math math-inline">(i, j)</span>에 대한 손실은 다음과 같이 정의된다.<br />
<span class="math math-display">
\ell_{i,j} = - \log \frac{\exp(\text{sim}(z_i, z_j)/\tau)}{\sum_{k=1}^{2N} \mathbf{1}_{[k \neq i]} \exp(\text{sim}(z_i, z_k)/\tau)}
</span><br />
여기서 <span class="math math-inline">\text{sim}(u, v)</span>는 코사인 유사도, <span class="math math-inline">\tau</span>는 온도(temperature) 하이퍼파라미터, <span class="math math-inline">2N</span>은 미니배치 크기 <span class="math math-inline">N</span>에 대해 생성된 총 증강 이미지 수이다.13 이 수식의 분자는 긍정 쌍 간의 유사도를 최대화하고, 분모는 해당 이미지를 제외한 배치 내 모든 다른 이미지(부정 쌍)와의 유사도를 최소화하는 역할을 수행한다.</p>
</li>
<li>
<p><strong>기술적 의의 및 영향:</strong> SimCLR은 메모리 뱅크나 특별한 아키텍처 없이 기존의 대조 학습 프레임워크를 크게 단순화하면서도 뛰어난 성능을 달성했다.2 더 중요한 것은, ImageNet 데이터셋에서 지도 학습으로 훈련된 ResNet-50과 동등한 성능을 비지도 학습만으로 달성함으로써, 자기 지도 학습이 대규모 데이터셋에서 지도 학습을 따라잡을 수 있는 가능성을 명확히 입증했다는 점이다.2 이는 막대한 비용이 드는 데이터 레이블링 문제를 해결할 수 있는 중요한 돌파구로 평가받는다.</p>
</li>
</ul>
<h3>3.2  BERT 심층 탐구: “BERTology 입문”</h3>
<ul>
<li>
<p><strong>논문 정보:</strong> “A Primer in BERTology: What we know about how BERT works”, Anna Rogers 외, 2020년 2월 arXiv 제출.14 이 논문은 새로운 모델을 제안하는 것이 아니라, 150편 이상의 선행 연구를 종합하여 BERT의 작동 원리에 대한 당시까지의 이해를 집대성한 중요한 서베이 논문이다.3</p>
</li>
<li>
<p><strong>BERT 아키텍처:</strong> BERT는 트랜스포머(Transformer)의 인코더 구조를 여러 층으로 쌓은 형태이다.17 각 인코더는 멀티-헤드 셀프-어텐션(Multi-Head Self-Attention) 메커니즘과 피드포워드 신경망으로 구성된다. 셀프-어텐션은 문장 내 단어들 간의 상호 관계를 가중치로 학습하여 문맥을 깊이 있게 이해하는 핵심적인 역할을 한다.18</p>
</li>
<li>
<p><strong>사전 학습 (Pre-training) 방법론:</strong> BERT는 위키피디아와 같은 대규모 텍스트 코퍼스를 사용하여 두 가지 비지도 학습 과제를 통해 ’언어 자체’의 구조와 패턴을 학습한다.18</p>
</li>
</ul>
<ol>
<li>
<p><strong>Masked Language Model (MLM):</strong> 문장의 일부 단어를 무작위로 `` 토큰으로 바꾼 뒤, 주변 문맥 전체(왼쪽과 오른쪽 모두)를 이용하여 원래 단어를 예측하는 과제이다.17 이를 통해 BERT는 이전 모델들이 구현하기 어려웠던 깊은 양방향 문맥(deeply bidirectional context)을 효과적으로 학습할 수 있다.</p>
</li>
<li>
<p><strong>Next Sentence Prediction (NSP):</strong> 두 문장이 주어졌을 때, 두 번째 문장이 첫 번째 문장 바로 다음에 자연스럽게 이어지는 문장인지 여부를 예측하는 과제이다.17 이를 통해 단어 수준을 넘어 문장 간의 논리적 관계를 이해하는 능력을 학습한다.</p>
</li>
</ol>
<ul>
<li>
<p><strong>BERT가 학습하는 언어학적 지식:</strong></p>
</li>
<li>
<p><strong>구문론적 지식 (Syntactic Knowledge):</strong> BERT의 내부 임베딩은 품사(POS), 구문 구조, 단어 간의 의존 관계 등 정교한 구문 정보를 풍부하게 인코딩한다. 특히, 일부 어텐션 헤드는 동사와 목적어 관계와 같은 특정 구문 관계에 특화된 패턴을 보이는 것으로 나타났다.17 이는 BERT가 단순히 단어의 나열이 아닌, 문장의 위계적 구조를 학습하고 있음을 시사한다.</p>
</li>
<li>
<p><strong>의미론적 지식 (Semantic Knowledge):</strong> BERT는 문맥에 따라 단어의 의미를 다르게 표현함으로써 다의어(polysemy) 문제를 효과적으로 해결한다.17 또한, “오바마의 직업은 __이다“와 같은 프롬프트를 통해 모델이 상당한 양의 사실적 지식(factual knowledge)을 내재하고 있음이 밝혀졌다.3</p>
</li>
<li>
<p><strong>기술적 의의 및 영향:</strong> “BERTology” 논문은 NLP 커뮤니티가 단순히 성능이 높은 모델을 사용하는 것을 넘어, 모델의 내부 작동 방식을 과학적으로 분석하고 이해하려는 중요한 학문적 흐름을 형성했음을 보여준다. 이는 모델의 신뢰성, 해석 가능성(interpretability), 그리고 잠재적 편향(bias) 문제 해결을 위한 필수적인 기초를 제공했다는 점에서 큰 의의를 가진다.</p>
</li>
</ul>
<p>이 두 연구는 AI 연구의 중요한 전환을 상징한다. SimCLR 논문이 데이터 증강, 투영 헤드 등 각 구성 요소가 최종 성능에 미치는 영향을 체계적으로 분석하는 ’Ablation Study’를 매우 비중 있게 다루었고 13, “BERTology” 논문 자체가 BERT라는 모델을 과학적 분석의 대상으로 삼은 연구들을 집대성한 것 3은, AI 연구가 단순히 성능 수치를 높이는 경쟁(benchmark chasing)에서 벗어나, 모델의 어떤 요소가 왜 성능에 기여하는지, 그리고 모델이 학습 과정에서 무엇을 ’이해’하게 되는지를 규명하려는 과학적 탐구 단계로 진입했음을 보여준다.</p>
<p>Table 2: SimCLR 프레임워크 핵심 구성 요소:</p>
<table><thead><tr><th>구성 요소</th><th>주요 역할 및 설명</th></tr></thead><tbody>
<tr><td><strong>데이터 증강 (Data Augmentation)</strong></td><td>동일한 이미지로부터 무작위 자르기, 색상 왜곡 등을 통해 두 개의 서로 다른 ’뷰(view)’를 생성합니다. 이 두 이미지가 서로를 끌어당겨야 할 **긍정 쌍(positive pair)**이 된다.</td></tr>
<tr><td><strong>기반 인코더 (Base Encoder, f(⋅))</strong></td><td>ResNet과 같은 CNN 아키텍처를 사용하여 증강된 이미지로부터 시각적 특징을 추출하는 **표현 벡터(hi)**를 생성한다.</td></tr>
<tr><td><strong>투영 헤드 (Projection Head, g(⋅))</strong></td><td>인코더 위에 추가된 작은 신경망(MLP)으로, 표현 벡터(hi)를 <strong>대조 손실(contrastive loss)이 계산되는 더 낮은 차원의 공간</strong>으로 투영(zi)합니다. 학습이 끝난 후에는 이 부분은 버려진다.</td></tr>
<tr><td><strong>대조 손실 함수 (Contrastive Loss Function)</strong></td><td><strong>NT-Xent 손실</strong>을 사용합니다. 잠재 공간에서 긍정 쌍(zi,zj)의 유사도는 최대화하고, 미니배치 내 다른 모든 이미지(부정 쌍)와의 유사도는 최소화하도록 모델을 학습시킨다.</td></tr>
</tbody></table>
<h2>4.  로봇 공학 분야 연구 동향</h2>
<p>2020년 2월 로봇 공학 분야에서는 비정형적이고 불확실한 실제 환경에 ’적응’하는 능력을 구현하기 위한 연구들이 두각을 나타냈다. 이는 조작, 자율주행, 인간-로봇 상호작용 등 여러 세부 분야에서 공통적으로 관찰되는 핵심적인 흐름이었다.</p>
<h3>4.1  조작(Manipulation) 기술의 진화: 소프트 로보틱스와 생체모방</h3>
<p>하버드대 연구팀은 문어 팔의 구조와 흡착판(sucker)을 모방한 혁신적인 소프트 로봇 팔을 개발하여 큰 주목을 받았다.5 이 로봇은 유연하고 끝으로 갈수록 가늘어지는(tapered) 구조를 가지며, 표면에 진공을 생성하여 작동하는 다수의 흡착판을 갖추고 있다. 실험을 통해 이 로봇 팔은 얇은 플라스틱 시트, 깨지기 쉬운 계란, 심지어 살아있는 게와 같이 형태와 재질이 매우 다양한 물체들을 안정적으로 파지하고 조작할 수 있음을 성공적으로 입증했다.5</p>
<p>이 연구의 핵심적인 의의는 자연계 생물의 구조와 작동 원리를 모방하는 생체모방(Biomimicry) 접근법이 비정형적이고 예측 불가능한 환경에서 로봇의 조작 능력을 획기적으로 향상시킬 수 있음을 보여준 데 있다. 특히, 기존의 단단한 그리퍼(gripper)로는 다루기 힘든 부드럽거나 깨지기 쉬운 물체를 다루는 데 있어 소프트 로보틱스의 무한한 잠재력을 명확히 제시했다.5 이와 더불어, 비정형 환경에서의 자율 조작 기술 19이나 우주 공간에서의 객체 포획 및 조작 20 등, 로봇 조작 기술의 적용 범위가 통제된 공장 환경을 넘어 일상생활, 나아가 우주와 같은 극한 환경으로 빠르게 확장되고 있었다.</p>
<h3>4.2  자율주행 기술: 데이터 기반 접근법과 산업 동향</h3>
<p>자율주행 분야에서는 실제 도로에서 수집된 방대한 데이터를 기반으로 주행 능력을 학습하는 접근법이 활발히 연구되었다. 대표적으로, Waymo가 공개한 대규모 자율주행 데이터셋(Waymo Open Dataset)을 활용하여, LSTM 기반의 딥러닝 모델로 Waymo 차량의 주행 정책을 모방하려는 연구가 발표되었다.4 이는 전문가 운전자나 고도로 정교한 자율주행 시스템의 행동을 데이터로부터 직접 학습하는 ‘행동 복제(Behavioral Cloning)’ 접근법의 유효성을 탐구한 것이다.</p>
<p>이러한 연구는 자율주행 시스템의 핵심인 주행 정책이 대부분 기업의 독점 기술로 분류되어 접근이 어려운 상황에서, 공개된 데이터를 통해 그 정책을 역으로 추정하려는 시도라는 점에서 중요한 의미를 가진다.4 이처럼 데이터 기반으로 학습된 모델은 복잡한 실제 주행 시나리오를 시뮬레이션하고, 다양한 교통 참여자 간의 상호작용을 연구하는 데 귀중한 자산이 될 수 있다. 한편, 기술 개발과 함께 안전성 확보를 위한 제도적 기반 마련 노력도 병행되었다. 당시 미국 교통부(U.S. DOT)는 자율주행 시스템(ADS)의 안전 프레임워크 마련을 위한 규제 활동을 시작했으며 21, SAE(국제자동차기술자협회)가 정의한 자율주행 레벨(0~5)은 기술의 발달 단계를 정의하는 산업 표준으로 널리 사용되었다.22</p>
<h3>4.3  인간-로봇 상호작용(HRI)과 공유 자율성</h3>
<p>인간-로봇 상호작용(HRI) 분야에서는 ‘공유 자율성(Shared Autonomy)’ 개념이 핵심적인 연구 주제로 부상했다. 이는 인간의 완전한 원격 조작(teleoperation)과 로봇의 완전한 자율성(full autonomy) 사이의 최적의 균형점을 찾는 것을 목표로 한다. 즉, 인간의 높은 수준의 상황 판단력과 창의성을 로봇의 정밀하고 반복적인 실행 능력과 결합하여 전체 시스템의 성능과 안전성을 극대화하는 것이다.23</p>
<p>구체적인 연구로서, 로봇의 자율 항법 및 장애물 회피 능력을 기본으로 활용하면서, 사용자가 웹 인터페이스를 통해 직관적인 ‘point-and-click’ 방식으로 목표를 지정하거나 필요시 수동으로 개입할 수 있는 시스템이 제안되었다.23 이러한 접근은 조작자의 인지 부하(cognitive load)를 줄이고, 로봇 제어에 대한 전문 지식이 없는 사용자도 쉽게 로봇과 상호작용할 수 있도록 하는 데 초점을 맞춘다. 더 나아가, 로봇이 인간의 의도를 파악하고 때로는 인간의 비효율적인 지시에 의도적으로 순응하여 장기적인 신뢰를 쌓는 ‘상호 적응(Mutual Adaptation)’ 개념이 제안되었다.23 이는 HRI가 단순한 명령-수행 관계를 넘어, 인간과 로봇이 서로를 이해하고 학습하며 적응해 나가는 협력적 파트너십으로 발전해야 함을 시사한다.</p>
<p>이러한 로봇 공학의 세 분야에서 공통적으로 나타나는 흐름은, 로봇 공학의 중심 과제가 정해진 명령을 정밀하게 수행하는 ‘통제(control)’ 중심의 패러다임에서, 예측 불가능한 실제 세계의 복잡성에 유연하게 대처하는 ‘적응(adaptation)’ 중심의 패러다임으로 이동하고 있음을 명확하게 보여준다. 과거 로봇 공학의 발전이 주로 기구학, 동역학 등 기계공학적 측면에 의존했다면, 2020년 2월의 연구들은 AI와 데이터가 로봇의 ’지능’을 구현하는 핵심 동력임을 증명한다. Waymo 연구는 방대한 데이터가 로봇의 ’경험’이 되어 주행 능력을 형성하고 4, 공유 자율성 연구는 AI 계획(planning) 알고리즘이 로봇의 ‘판단’ 능력을 제공하며 23, 소프트 로봇 연구는 AI 기반 제어기가 복잡한 신체(soft body)를 다루는 ’운동 지능’을 가능하게 한다. 즉, AI는 로봇의 ‘뇌’ 역할을 하며, 로봇 공학은 AI 기술의 가장 중요한 ‘체화(embodiment)’ 분야가 되고 있음을 알 수 있다.</p>
<h2>5.  AI 기술의 응용 및 사회적 영향</h2>
<p>2020년 2월, AI 기술은 학술적 발전을 넘어 의료, 노동 등 사회 전반에 걸쳐 실질적인 변화를 이끌어내기 시작했다. 특히 인간의 전문성을 대체하는 것이 아닌, ’증강’시키는 방향으로의 응용이 두드러졌다.</p>
<h3>5.1  전문 분야로의 확장: 의료 AI와 로봇 수술</h3>
<p>의료 분야는 AI 기술이 가장 활발하게 적용되는 전문 영역 중 하나였다. 세계적인 의료기기 기업 Medtronic은 2020년 2월 13일, AI 기반 수술 분석 및 의사결정 지원 기술을 보유한 영국 스타트업 Digital Surgery를 인수했다고 발표했다.24 이와 동시에 런던에 위치한 자사의 AI 및 로봇 수술 R&amp;D 센터의 규모를 두 배로 확장할 계획을 밝히며 해당 분야에 대한 공격적인 투자를 예고했다.24</p>
<p>이러한 움직임은 AI 기술이 로봇 수술 플랫폼과 결합하여 의료 서비스의 패러다임을 바꾸고 있음을 보여준다. AI는 수술 중 발생하는 방대한 데이터를 실시간으로 분석하여 외과의사에게 중요한 정보를 제공하고, 잠재적 위험을 경고하며, 최적의 의사결정을 지원한다. 또한, 원격 수술(telesurgery) 기술과 결합하여 지리적 제약 없이 최고의 의료 서비스를 제공할 수 있는 가능성을 열었다.24 이는 AI가 더 이상 의료 영상 판독과 같은 진단 보조 도구에 머무르지 않고, 수술이라는 가장 전문적이고 능동적인 의료 행위에 직접적으로 관여하며 의료의 정밀성과 효율성을 한 단계 끌어올리고 있음을 의미한다.</p>
<h3>5.2  노동의 미래: 대체에서 협력으로</h3>
<p>AI의 발전이 대량 실업을 유발할 것이라는 사회적 우려가 팽배했던 가운데, 2020년 발표된 MIT의 ‘미래의 일(Work of the Future)’ 연구 보고서는 이에 대한 균형 잡힌 시각을 제시했다.25 보고서는 AI로 인해 일부 직무가 자동화되는 것은 불가피하지만, 과거 증기기관이나 컴퓨터와 같은 모든 노동 절약 기술이 그랬듯이 AI 역시 궁극적으로는 새로운 산업과 직업을 창출하여 사라지는 일자리보다 더 많은 일자리를 만들어낼 것이라고 전망했다.</p>
<p>특히 보고서는 미래의 가장 유망한 AI 활용 방식으로 ’초지능(Superminds)’이라는 패러다임을 강조했다.25 이는 ’인간을 대체하는 컴퓨터’가 아니라, ‘인간과 컴퓨터가 긴밀하게 협력하여 기존에는 불가능했던 인지적, 물리적 과업을 함께 수행하는’ 모델을 의미한다. 이러한 관점은 AI를 인간 능력의 ’증강(augmentation)’을 위한 강력한 도구로 바라보는 시각의 전환을 요구한다.</p>
<p>Medtronic의 로봇 수술 AI가 외과의사를 ’대체’하는 것이 아니라, 더 나은 결정을 내리도록 ’지원’하고 능력을 ’증강’하는 데 초점을 맞추는 것 24과 MIT 보고서가 노동 시장 전체로 이러한 ‘증강’ 패러다임을 확장하여 ‘초지능’ 개념을 제시한 것 25은 중요한 공통점을 가진다. 2020년 2월은 AI 기술의 사회적 수용성과 실질적 가치가 ’완전 자율’이라는 이상적 목표뿐만 아니라, 인간 전문가의 능력을 극대화하는 ’지능형 증강’이라는 현실적이고 건설적인 경로를 통해 실현되고 있음을 보여주는 중요한 시점이었다.</p>
<h2>6. 결론: 종합 및 전망</h2>
<p>2020년 2월은 AI 및 로봇 공학 분야가 양적 성장을 넘어 질적 성숙과 자기 성찰의 단계로 접어들었음을 알리는 중요한 신호탄과 같은 시기였다. 이 시기의 주요 연구 동향을 종합하면 다음과 같은 네 가지 핵심적인 흐름을 발견할 수 있다.</p>
<ol>
<li>
<p><strong>자기 지도 학습의 부상:</strong> SimCLR의 등장은 레이블 없는 데이터의 막대한 가치를 극대화하는 방법을 제시하며, 데이터 중심 AI(Data-Centric AI) 시대로의 전환을 가속화했다.</p>
</li>
<li>
<p><strong>거대 모델에 대한 과학적 탐구:</strong> “BERTology“는 모델의 성능을 넘어 그 내부 작동 원리를 이해하려는 학계의 노력이 본격화되었음을 알렸다. 이는 AI의 신뢰성과 안전성 확보를 위한 필수적인 단계이다.</p>
</li>
<li>
<p><strong>로봇 공학의 실세계 지능 구현:</strong> 로봇 공학은 AI 기술을 적극적으로 수용하여, 통제된 실험실 환경을 벗어나 복잡하고 불확실한 실제 환경에 ’적응’하는 지능을 구현하는 방향으로 나아가고 있었다.</p>
</li>
<li>
<p><strong>인간-AI 협력 패러다임의 확산:</strong> 의료, 노동 등 다양한 분야에서 AI를 인간의 대체재가 아닌, 인간의 능력을 증강시키는 협력적 파트너로 인식하는 경향이 뚜렷해졌다.</p>
</li>
</ol>
<p>2020년 2월에 나타난 이러한 흐름들은 이후 AI 및 로봇 공학 분야의 연구 개발 방향에 지대한 영향을 미쳤다. SimCLR과 같은 자기 지도 학습 방법론은 이후 CLIP, DINO 등 멀티모달(multi-modal) 및 비전 트랜스포머 연구의 견고한 기틀이 되었다. BERT에 대한 깊은 이해는 더 효율적이고 제어 가능한 거대 언어 모델(예: GPT-3 이후의 모델들) 개발의 밑거름이 되었다. 로봇 공학은 AI와의 융합을 더욱 가속화하여, 오늘날 우리가 목도하는 체화된 AI(Embodied AI) 연구의 부흥을 이끌었다. 결론적으로, 2020년 2월은 AI 연구가 새로운 기술적 지평을 열었을 뿐만 아니라, 그 기술을 어떻게 이해하고, 어떻게 현실 세계에 적용하며, 어떻게 인간과 조화를 이룰 것인가에 대한 깊은 성찰을 시작한 중요한 전환점이었다고 평가할 수 있다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>AAAI 2020 Conference - The Association for the Advancement of Artificial Intelligence, https://aaai.org/conference/aaai/aaai-20/</li>
<li>A Simple Framework for Contrastive Learning of Visual Representations - arXiv, https://arxiv.org/abs/2002.05709</li>
<li>A Primer in BERTology: What we know about how BERT works - ResearchGate, https://www.researchgate.net/publication/339551169_A_Primer_in_BERTology_What_we_know_about_how_BERT_works</li>
<li>An LSTM-Based Autonomous Driving Model Using a Waymo Open …, https://www.mdpi.com/2076-3417/10/6/2046</li>
<li>Octopus-inspired robot can grip, move, and manipulate a wide …, https://www.sciencedaily.com/releases/2020/02/200227144222.htm</li>
<li>AAAI Conference and Symposium Proceedings, https://aaai.org/aaai-publications/aaai-conference-proceedings/</li>
<li>Proceedings of the AAAI Conference on Artificial Intelligence, 34 …, https://aaai.org/proceeding/aaai-34-2020/</li>
<li>Vol. 16 No. 1 (2020): Sixteenth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, https://aaai.org/proceeding/vol-16-no-1-2020-sixteenth-aaai-conference-on-artificial-intelligence-and-interactive-digital-entertainment/</li>
<li>Vol. 14 (2020): Fourteenth International AAAI Conference on Web and Social Media, https://ojs.aaai.org/index.php/ICWSM/issue/view/262</li>
<li>Thirty-Second Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-20) - AAAI, https://aaai.org/conference/aaai/aaai-20/iaai20/</li>
<li>Artificial Intelligence, Ethics, and Society - Aies Conference, https://www.aies-conference.com/2020/index.html</li>
<li>A Simple Framework for Contrastive Learning of Visual Representations - ResearchGate, https://www.researchgate.net/publication/339251894_A_Simple_Framework_for_Contrastive_Learning_of_Visual_Representations</li>
<li>A Simple Framework for Contrastive Learning of Visual …, https://proceedings.mlr.press/v119/chen20j/chen20j.pdf</li>
<li>[P] Top 10 arXiv papers in 2020 according to metacurate.io : r/MachineLearning - Reddit, https://www.reddit.com/r/MachineLearning/comments/koee07/p_top_10_arxiv_papers_in_2020_according_to/</li>
<li>A Primer in BERTology: What we know about how BERT works - BibSonomy, https://www.bibsonomy.org/bibtex/13fd0ebec97225101647108f7d48eb13b/bechr7</li>
<li>A Primer in BERTology: What We Know About How BERT Works - SciSpace, https://scispace.com/papers/a-primer-in-bertology-what-we-know-about-how-bert-works-2v8af1zw7o</li>
<li>A Primer in BERTology: What we know about how BERT works, https://arxiv.org/abs/2002.12327</li>
<li>A Primer in BERTology: What We Know About How Bert Works | Hacker News, https://news.ycombinator.com/item?id=25043280</li>
<li>Development of a Mobile Autonomous Manipulation Robot for Non-Structured Environments, https://www.researchgate.net/publication/339594515_Development_of_a_Mobile_Autonomous_Manipulation_Robot_for_Non-Structured_Environments</li>
<li>Robotic Manipulation and Capture in Space: A Survey - PMC - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC8326842/</li>
<li>Automated Vehicles - Comprehensive Plan - Department of Transportation, https://www.transportation.gov/sites/dot.gov/files/2021-01/USDOT_AVCP.pdf</li>
<li>2020 Autonomous Vehicle Technology Report - Wevolver, https://www.wevolver.com/article/2020.autonomous.vehicle.technology.report</li>
<li>Shared Autonomy in Web-based Human Robot Interaction, https://arxiv.org/pdf/1912.10274</li>
<li>Medtronic to double the size of its London center for AI, robotic surgery - Fierce Biotech, https://www.fiercebiotech.com/medtech/medtronic-doubles-size-its-london-center-ai-and-robotic-surgery</li>
<li>artificial intelligence and - MIT Work of the Future, https://workofthefuture-taskforce.mit.edu/document/2020-research-brief-malone-rus-laubacher-2/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>