<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2009년 4분기 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2009년 4분기 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2009년 AI 및 로봇 연구 동향</a> / <span>2009년 4분기 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2009년 4분기 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 전환기의 기술 지형</h2>
<p>2009년 4분기는 인공지능(AI) 역사에서 중대한 변곡점으로 기록된다. 이 시기는 딥러닝이라는 새로운 패러다임이 기존의 강력한 통계적 학습 방법론과 치열하게 경쟁하며 그 가능성을 입증하기 시작한 결정적 순간이었다. 당시의 기술 지형은 단일 패러다임이 지배하는 시대가 아니었다. 여러 강력한 연구 흐름이 공존하며 각자의 정점을 향해 나아가던 ’다극화된 기술 정점(Multipolar Technological Apex)’의 시대였다. 딥러닝의 부상, 수작업 특징(hand-crafted features)에 기반한 정교한 통계 모델의 성공, 그리고 물리적 관찰에 기반한 우아한 사전 확률(prior)의 발견이 동시다발적으로 일어났다. 본 보고서는 이 전환기의 기술 지형을 심도 있게 분석하고, 후속 10년의 연구 방향을 결정지은 핵심 발표들을 조명한다.</p>
<p>해당 분기에는 AI 및 로봇공학 분야의 최상위 학술회의가 집중적으로 개최되었다. 이 보고서는 다음 학회들을 중심으로 주요 연구 성과를 분석한다.</p>
<ul>
<li><strong>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2009):</strong> 2009년 10월 11일부터 15일까지 미국 세인트루이스에서 개최되었다.1 로봇 지능, 제어, 인식 분야의 핵심 연구가 발표되었다.</li>
<li><strong>IEEE 12th International Conference on Computer Vision (ICCV 2009):</strong> 2009년 9월 27일부터 10월 4일까지 일본 교토에서 개최되었다.3 컴퓨터 비전 분야의 근본적인 문제들에 대한 최신 해결책이 제시되었다. 비록 4분기 직전에 시작되었으나, 주요 발표와 영향력은 4분기 내내 이어졌으므로 분석에 포함한다.</li>
<li><strong>Conference on Neural Information Processing Systems (NeurIPS/NIPS 2009):</strong> 제23회 연례 학회로, 2009년 12월 7일부터 12일까지 캐나다 밴쿠버와 휘슬러에서 개최되었다.5 머신러닝, 신경과학, 인지과학의 경계를 넘나드는 가장 영향력 있는 연구들이 발표된 장이었다.</li>
</ul>
<p>이러한 학술적 성과 외에도, 2009년은 구글의 자율주행 자동차 프로젝트가 공식적으로 시작된 해이기도 하다.7 이는 AI 연구가 실제 산업에 미칠 파괴적 영향력을 예고하는 중요한 사건이었다. 또한, 로봇 운영체제(Robot Operating System, ROS)가 초기 버전을 넘어 학계에 본격적으로 소개되던 시점으로, 로봇 개발의 표준화 및 가속화 기반이 마련되고 있었다.9 이 시점의 세 가지 주요 성과—데이터로부터 계층적 특징을 자동으로 학습하려는 딥러닝, 전문가의 지식으로 정교한 통계 모델을 설계하려는 고전적 머신러닝, 그리고 문제의 물리적 본질을 파고들어 간단한 해법을 찾으려는 물리 기반 비전—는 서로 다른 철학에 기반하고 있었다. 이들이 한 시점에 공존하며 각자의 영역에서 최고 수준의 성과를 냈다는 사실은, 당시 AI 분야가 하나의 정답을 향해 수렴하기보다는 여러 경로를 통해 동시에 발전하고 있었음을 시사한다. 이는 곧이어 닥칠 딥러닝 혁명 직전의 마지막 ’춘추전국시대’와 같았다.</p>
<table><thead><tr><th>학회명 (Acronym)</th><th>전체 명칭</th><th>개최 기간</th><th>개최 장소</th><th>주요 주제</th></tr></thead><tbody>
<tr><td>IROS 2009</td><td>IEEE/RSJ International Conference on Intelligent Robots and Systems</td><td>2009.10.11-15</td><td>미국, 세인트루이스 1</td><td>지능형 로봇, 동적 제어, SLAM, 인간-로봇 상호작용</td></tr>
<tr><td>ICCV 2009</td><td>IEEE 12th International Conference on Computer Vision</td><td>2009.09.27-10.04</td><td>일본, 교토 3</td><td>객체 검출, 이미지 복원, 3D 비전, 통계적 모델링</td></tr>
<tr><td>NeurIPS 2009</td><td>23rd Conference on Neural Information Processing Systems</td><td>2009.12.07-12</td><td>캐나다, 밴쿠버 5</td><td>딥러닝, 확률 모델, 커널 방법론, 강화학습, 뇌과학</td></tr>
</tbody></table>
<h2>2.  딥러닝과 비지도 특징 학습의 부상</h2>
<p>2009년의 딥러닝 연구는 ’어떻게 학습시킬 것인가’라는 근본적인 질문과 ’실제로 우수한가’라는 실용적인 질문에 동시에 답하는 이중적 과제를 수행하고 있었다. 학습 전략 자체를 탐구하며 사전학습의 효과를 이론적으로 검증하는 연구와, 구체적인 벤치마크에서 기존 강자들과의 성능을 직접 비교하며 실용적 우수성을 입증하려는 연구가 동시에 진행되었다. 이 두 흐름은 분리된 것이 아니라 상호보완적이었다. 실용적인 성공 사례는 사전학습 전략의 정당성을 강화했고, 학습 전략에 대한 더 깊은 이해는 더 나은 모델의 설계와 성공으로 이어졌다. 이 선순환 구조가 2012년 AlexNet의 결정적 성공으로 가는 발판을 마련했다.</p>
<h3>2.1  심층 신경망 학습 전략의 확립: 탐욕적 계층별 사전학습의 역할</h3>
<p>2009년 이전, 심층 신경망은 다층의 비선형성을 통해 복잡한 함수를 효율적으로 표현할 잠재력을 가졌음에도 불구하고, 기울기 소실(vanishing gradient) 문제 등으로 인해 안정적인 학습이 매우 어려웠다.11 무작위로 초기화된 가중치에서 시작하는 전통적인 경사 하강법은 3개 이상의 은닉층을 가진 네트워크에서 좋지 않은 국소 최저점(local minimum)에 빠지는 경향이 있었다.</p>
<p>이 문제의 핵심 해결책으로 Geoffrey Hinton 등이 2006년에 제안한 심층 신뢰 신경망(Deep Belief Network, DBN)과 제한된 볼츠만 머신(Restricted Boltzmann Machine, RBM)을 이용한 **탐욕적 계층별 비지도 사전학습(greedy layer-wise unsupervised pre-training)**이 부상했다.12 이 전략은 각 계층을 순차적으로 RBM으로 간주하여 레이블 없는 데이터로 비지도 학습을 수행하고, 이렇게 얻어진 가중치를 초기값으로 사용하여 전체 네트워크를 지도 방식으로 미세 조정(fine-tuning)하는 2단계 학습 방식이다.14</p>
<p>2009년 Journal of Machine Learning Research (JMLR)에 발표된 Hugo Larochelle, Yoshua Bengio 등의 논문 “Exploring Strategies for Training Deep Neural Networks“는 이 전략의 성공 요인을 심층적으로 분석했다.15 이 연구는 비지도 사전학습이 단순히 좋은 초기값을 찾아주는 것을 넘어, 다음과 같은 두 가지 중요한 역할을 수행함을 실험적으로 입증했다 11:</p>
<ol>
<li><strong>최적화 보조 (Optimization Aid):</strong> 사전학습은 가중치를 좋은 국소 최저점 근처의 영역으로 초기화하여, 후속 지도 학습이 더 나은 해를 찾도록 돕는다.</li>
<li><strong>정규화 효과 (Regularization Effect):</strong> 사전학습은 암묵적으로 일종의 정규화(regularization)로 작용하여 더 나은 일반화 성능을 유도한다. 또한, 입력 데이터의 고수준 추상화를 담은 분산 표현(distributed representation)을 학습하도록 장려한다.</li>
</ol>
<p>이 분석은 딥러닝 학습의 성공이 단순한 최적화 기법의 개선이 아니라, 데이터의 내재적 구조를 잘 포착하는 ’좋은 표현’을 학습하는 과정과 밀접하게 연관되어 있음을 명확히 했다.</p>
<h3>2.2  응용 사례 분석: 3D 객체 인식을 위한 심층 신뢰 신경망 (DBN)</h3>
<p>NeurIPS 2009에서 Vinod Nair와 Geoffrey Hinton이 발표한 “3D Object Recognition with Deep Belief Nets“는 DBN의 실제적 성능을 고난도 벤치마크에서 입증한 대표적 사례다.18 이 연구는 딥러닝이 단순한 학문적 호기심을 넘어, 기존의 강력한 방법론들과 경쟁할 수 있는 실용적 도구임을 보여주었다.</p>
<p>이 연구의 핵심적인 기여는 DBN의 최상위 계층에 기존 RBM 대신 새로운 **3차 볼츠만 머신(third-order Boltzmann machine)**을 도입한 것이다.14 이 모델의 에너지 함수는 다음과 같이 정의된다:<br />
<span class="math math-display">
E(v, h, l) = - \sum_{i,j,k} W_{ijk}v_ih_jl_k
</span><br />
여기서 <span class="math math-inline">v</span>는 가시 유닛(최상위 특징), <span class="math math-inline">h</span>는 은닉 유닛, <span class="math math-inline">l</span>은 클래스 레이블을 나타낸다. 이 구조에서 클래스 레이블(<span class="math math-inline">l</span>)은 가시 유닛과 은닉 유닛 간의 상호작용을 직접적으로 조절(multiplicatively modulate)하는 역할을 한다.20 이는 각 클래스에 특화된 특징 표현을 학습할 수 있게 하여, 외형이 크게 다른 다양한 3D 객체 클래스들을 효과적으로 모델링하는 데 기여했다.</p>
<p>이 모델은 3D 객체 인식 벤치마크인 NORB 데이터셋에서 평가되었다. 그 결과는 매우 인상적이었다 19:</p>
<ul>
<li><strong>성능:</strong> 6.5%의 오류율을 기록하여, 당시 강력한 경쟁자였던 서포트 벡터 머신(SVM)의 11.6%를 크게 능가했다. 이는 변환 불변성(translation invariance)이라는 강력한 사전 지식이 내장된 합성곱 신경망(CNN)의 최고 성능(5.9%)에 근접한 수치였다.</li>
<li><strong>준지도 학습 (Semi-Supervised Learning):</strong> DBN의 진정한 강점인 준지도 학습 능력을 입증하기 위해, 기존 학습 이미지에 작은 평행 이동을 가하여 생성한 레이블 없는 데이터를 추가로 학습에 사용했다. 그 결과, 오류율은 **5.2%**로 감소하여 당시 NORB 데이터셋에서 최고 성능(state-of-the-art)을 달성했다.</li>
</ul>
<p>이 결과는 딥러닝이 레이블이 부족한 상황에서도 대량의 비지도 데이터를 활용하여 표현력을 향상시킬 수 있음을 명확히 보여주었다.</p>
<h3>2.3  음성 및 오디오 분야에서의 초기 딥러닝 적용</h3>
<p>2009년은 딥러닝이 시각 데이터를 넘어 음성 및 오디오 분야로 그 영향력을 확장하기 시작한 시기이기도 했다. NeurIPS 2009에서 개최된 “Deep Learning for Speech Recognition and Related Applications” 워크숍은 음성 인식 분야가 수십 년간 지배적이었던 은닉 마르코프 모델(Hidden Markov Model, HMM)의 한계를 인식하고, 음성 생성 과정의 다양한 변동성을 더 잘 모델링할 수 있는 심층 아키텍처로의 전환을 적극적으로 모색하고 있었음을 보여준다.21</p>
<p>이러한 흐름 속에서 구체적인 연구 성과들이 발표되었다. Lee 등의 연구 “Unsupervised feature learning for audio classification using convolutional deep belief networks“는 합성곱 DBN(CDBN)을 오디오 데이터에 적용하여 비지도 방식으로 특징을 학습했다.22 중요한 발견은 이렇게 학습된 특징들이 음성학의 기본 단위인 음소(phone/phoneme)와 같은 의미 있는 구조에 해당한다는 점이었다. 이는 딥러닝이 시각 데이터뿐만 아니라 복잡한 시계열 데이터에서도 유용한 계층적 특징을 자동으로 추출할 수 있음을 시사했다.</p>
<p>이 외에도 화자 인식(Speaker Recognition) 문제에 변분 베이즈 추론(variational Bayesian inference)을 결합하여 잡음에 강인한 시스템을 만들려는 시도 23나, 오류 정정 출력 부호(Error-Correcting Output Codes, ECOC)를 학습하여 다수의 음성 레이블 간의 유사성을 모델링하려는 연구 24 등, 음성 분야 전반에 걸쳐 새로운 머신러닝 기법들이 활발히 탐구되며 딥러닝 도입의 기반을 다지고 있었다.</p>
<h2>3.  확률 모델 및 통계적 학습의 진보</h2>
<p>2009년의 통계적 학습 연구는 단순히 성능을 높이는 것을 넘어, 모델의 신뢰성과 적용 가능성을 근본적으로 재고하려는 움직임을 보였다. 이는 ’모델의 평가’와 ’모델의 가정’이라는 두 가지 근본적인 측면에서 패러다임의 전환을 모색하는 것이었다. “우리가 모델을 제대로 평가하고 있는가?”, “우리의 모델이 현실 세계에 대해 타당한 가정을 하고 있는가?” 라는 질문들이 제기되었다. 이는 AI 연구가 성숙해지면서 나타나는 필연적인 과정으로, 모델의 성능 수치를 넘어 그 본질과 한계를 이해하려는 깊이 있는 탐구의 시작을 알렸다.</p>
<h3>3.1  토픽 모델의 재해석: 인간 중심 평가의 필요성</h3>
<p>NeurIPS 2009 최우수 논문상(Outstanding Paper Award) 수상작인 Jonathan Chang 등의 “Reading Tea Leaves: How Humans Interpret Topic Models“는 토픽 모델링 분야의 평가 방식에 근본적인 질문을 던졌다.25 당시 토픽 모델의 성능은 주로 보유 데이터(held-out data)에 대한 가능도(likelihood)나 이를 기반으로 한 퍼플렉시티(perplexity)와 같은 통계적 지표로 측정되었다. 그러나 연구자들은 이러한 지표가 모델이 생성한 토픽의 ’의미적 일관성’이나 ’해석 가능성’을 제대로 반영하는지에 대한 깊은 의문을 품고 있었다.27</p>
<p>이 논문은 이러한 문제의식을 바탕으로 두 가지 새로운 인간 기반 평가 방법을 제안했다 27:</p>
<ol>
<li><strong>단어 침입 (Word Intrusion):</strong> 이 방법은 토픽의 의미적 일관성을 측정한다. 평가자에게 특정 토픽에서 가장 확률이 높은 단어 5개와, 해당 토픽에서는 확률이 낮지만 다른 토픽에서는 확률이 높은 ‘침입자’ 단어 1개를 섞어 제시한다. 평가자가 이 침입자 단어를 얼마나 잘 식별하는지를 측정한다. 토픽의 단어들이 의미적으로 일관된 그룹을 형성한다면 침입자를 쉽게 찾아낼 수 있을 것이다.</li>
<li><strong>토픽 침입 (Topic Intrusion):</strong> 이 방법은 문서-토픽 할당의 적절성을 평가한다. 평가자에게 특정 문서의 제목과 일부 내용을 보여주고, 해당 문서에 할당된 확률이 가장 높은 토픽 3개와 임의로 선택된 ‘침입자’ 토픽 1개를 제시한다. 평가자가 문서의 내용과 관련 없는 침입자 토픽을 얼마나 잘 식별하는지를 측정한다.</li>
</ol>
<p>대규모 사용자 연구를 통해 얻은 결과는 충격적이었다. <strong>퍼플렉시티가 더 좋은(낮은) 모델이 오히려 인간이 해석하기에 더 어려운, 즉 의미적으로 덜 일관된 토픽을 생성하는 경향</strong>이 뚜렷하게 나타났다.26 이 발견은 통계적 모델의 적합도와 인간의 인지적 해석 가능성 사이에 심각한 괴리가 존재함을 정량적으로 입증한 최초의 연구 중 하나였다. 이는 이후 자연어 처리(NLP) 분야에서 모델을 평가할 때 통계적 지표뿐만 아니라 인간 중심의 질적 평가를 병행하는 문화가 자리 잡는 데 결정적인 영향을 미쳤다.</p>
<h3>3.2  커널 방법론의 이론적 확장: MMD와 분류 가능성</h3>
<p>Bharath Sriperumbudur 등이 발표한 “Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions“는 커널 방법을 이용한 확률 분포 비교에 대한 세 가지 중요한 이론적 결과를 제시하며, 해당 분야의 이론적 기반을 크게 확장했다.25</p>
<p>이 논문의 세 가지 핵심 기여는 다음과 같다 29:</p>
<ol>
<li><strong>MMD와 분류기 리스크의 등가성:</strong> 두 확률 분포 간의 거리인 **최대 평균 불일치(Maximum Mean Discrepancy, MMD)**가, 해당 분포들을 분류하는 최적 커널 분류기의 리스크(risk)와 수학적으로 동일함을 증명했다. 이는 분포 간의 통계적 거리가 곧 ’두 분포를 얼마나 쉽게 분류할 수 있는가’라는 실용적 문제와 직결됨을 의미한다. MMD라는 추상적인 측정치에 강력한 실용적 해석을 부여한 것이다.</li>
<li><strong>특성 커널(Characteristic Kernel)의 확장:</strong> MMD가 진정한 거리 함수(metric)의 조건을 만족하려면(즉, MMD가 0일 때 두 분포가 동일해야 함), 사용되는 커널이 ’특성 커널’이어야 한다. 이 연구는 특성 커널의 개념을 모든 **‘엄격한 양의 정부호 커널(strictly positive definite kernel)’**로 확장했다. 이로써 가우시안 커널과 같은 전통적인 이동 불변 커널뿐만 아니라, 더 넓은 범위의 커널들이 분포를 고유하게 표현할 수 있음을 이론적으로 보장했다.</li>
<li><strong>일반화된 MMD (Generalized MMD):</strong> 단일 커널이 아닌, 여러 커널의 집합인 **커널 ‘군(family of kernels)’**에 대한 MMD를 새롭게 정의했다. 예를 들어, 여러 대역폭(bandwidth)을 가진 가우시안 커널들 중에서 최적의 MMD 값을 찾는 방식으로 정의된다. 이는 커널 파라미터 선택이라는 어려운 문제를 MMD 프레임워크 내에서 자연스럽게 해결하는 방법을 제시한 것으로, 이론과 실제 사이의 간극을 좁히는 중요한 진전이었다.</li>
</ol>
<h3>3.3  강화학습을 위한 베이즈 비모수적 접근법: iPOMDP</h3>
<p>Finale Doshi-Velez의 “The Infinite Partially Observable Markov Decision Process“는 부분 관찰 마르코프 결정 과정(Partially Observable Markov Decision Process, POMDP)의 근본적인 한계를 극복하기 위한 새로운 모델을 제안했다.30 전통적인 POMDP는 에이전트가 활동하는 세계의 상태(state) 개수를 미리 알고 있어야 한다는 비현실적인 가정을 전제로 한다.31</p>
<p>이 연구는 이러한 한계를 극복하기 위해 베이즈 비모수적(Bayesian nonparametric) 접근법을 도입하여, 상태 공간의 크기를 미리 정하지 않는 **무한 POMDP(infinite POMDP, iPOMDP)**를 정의했다.31 iPOMDP의 핵심 가정은 다음과 같다 33:</p>
<ul>
<li>에이전트가 탐험할 수 있는 잠재적 상태의 수는 무한하다.</li>
<li>에이전트는 경험을 통해 새로운 상태를 발견하며, 모델은 오직 에이전트가 ‘방문한’ 상태들만 명시적으로 모델링한다.</li>
<li>모델의 복잡성은 에이전트의 경험이 쌓임에 따라 동적으로 증가한다.</li>
</ul>
<p>이러한 접근법은 무한 은닉 마르코프 모델(infinite Hidden Markov Model, iHMM)의 아이디어를 강화학습 프레임워크로 성공적으로 확장한 것이다.34 iPOMDP는 에이전트가 초기에 간단한 환경 모델로 시작하여, 미지의 환경을 탐험하며 점진적으로 더 복잡하고 정교한 모델을 구축해나가는 유연한 프레임워크를 제공했다. 이는 강화학습 에이전트가 현실 세계와 같이 구조가 알려지지 않은 환경을 학습하는 방식에 대한 보다 현실적인 모델링을 가능하게 했다.</p>
<h2>4.  컴퓨터 비전의 최신 기술 동향</h2>
<p>2009년 컴퓨터 비전 분야는 ’복잡성’에 대한 상반된 두 가지 접근법이 공존하며 최고의 성과를 내고 있었다. 하나는 객체 자체가 가진 내재적 복잡성(형태, 시점, 종류의 다양성)에 맞서기 위해, 정교하고 복잡한 모델을 점진적으로 구축하는 ‘상향식(Bottom-up)’ 접근법이었다. 다른 하나는 안개 제거와 같이 복잡해 보이는 현상 전체를 관통하는 하나의 단순하고 강력한 원리(prior)를 발견하여 문제를 해결하는 ‘하향식(Top-down)’ 접근법이었다. 이 두 철학의 성공적인 공존은 당시 비전 연구의 풍부함과 다양성을 증명한다.</p>
<h3>4.1  PASCAL VOC 챌린지와 변형 가능 부분 모델(DPM)의 정점</h3>
<p>PASCAL Visual Object Classes (VOC) 챌린지는 현실적인 장면에 포함된 다양한 객체를 인식하는 능력을 평가하는 당시 가장 권위 있는 벤치마크였다.35 2009년 챌린지는 사람, 동물, 차량, 실내 물품 등 20개의 객체 클래스에 대해 분류, 검출, 분할 등의 과제를 포함했다.35</p>
<p>이 챌린지에서 Felzenszwalb 등의 “Object Detection with Discriminatively Trained Part-Based Models“에서 제안된 **변형 가능 부분 모델(Deformable Part Model, DPM)**이 압도적인 성능을 보이며 객체 검출 분야의 최강자로 군림했다.37 DPM은 객체를 하나의 강체 템플릿이 아닌, 여러 부분의 조합으로 모델링하는 정교한 통계 모델이다.39 그 구조는 다음과 같다:</p>
<ul>
<li><strong>루트 필터 (Root Filter):</strong> 객체 전체의 거친 외형을 저해상도에서 포착하는 필터.</li>
<li><strong>부분 필터 (Part Filters):</strong> 루트 필터보다 2배 높은 해상도에서 객체의 세부적인 부분을 포착하는 여러 개의 필터. 이를 통해 다중 스케일의 시각적 외형을 모델링한다.</li>
<li><strong>공간 모델 (Spatial Model):</strong> 각 부분 필터가 루트 필터에 대해 가질 수 있는 상대적 위치를 벌점(cost)으로 모델링한다. 이는 마치 스프링처럼 작용하여 객체의 형태 변화(deformation)를 유연하게 허용한다.</li>
</ul>
<p>DPM 학습의 가장 큰 난제는 학습 데이터에 객체의 전체 바운딩 박스만 주어지고 각 부분의 정확한 위치는 주어지지 않는다는 점이었다. 따라서 부분들의 위치는 **잠재 변수(latent variable)**로 취급되어야 했다. 이를 해결하기 위해 저자들은 **잠재적 SVM (Latent SVM, LSVM)**이라는 새로운 학습 프레임워크를 제안했다.39 LSVM은 준볼록(semi-convex) 최적화 문제로, 다음과 같은 두 단계를 반복하여 학습을 수행한다 39:</p>
<ol>
<li>양성 예제(positive examples)에 대해 현재 모델 파라미터를 기준으로 최적의 부분 위치(잠재 변수 값)를 추정하여 고정한다.</li>
<li>잠재 변수가 고정된 상태에서, 표준적인 SVM과 동일한 볼록(convex) 최적화 문제를 풀어 모델 파라미터를 갱신한다.</li>
</ol>
<p>또한, 단일 DPM으로는 표현하기 어려운 다양한 형태의 객체(예: 옆모습 자전거와 앞모습 자전거)를 모델링하기 위해, 여러 DPM 컴포넌트의 **혼합 모델(mixture model)**을 사용하여 표현력을 극대화했다.39 DPM은 딥러닝이 부상하기 전, 수작업 특징(HOG)과 정교한 통계 모델링이 결합하여 이룰 수 있는 성취의 정점을 보여준 사례로 평가받는다.</p>
<h3>4.2  이미지 복원을 위한 새로운 사전 확률: 다크 채널 사전(Dark Channel Prior)</h3>
<p>ICCV 2009에서 발표되어 큰 반향을 일으킨 Kaiming He 등의 “Single Image Haze Removal using Dark Channel Prior“는 단일 이미지에서 안개를 제거하는 문제에 대한 획기적인 해법을 제시했다.41 이 방법은 복잡한 학습 과정 없이, 간단한 물리적, 통계적 관찰만으로 매우 어려운 역문제(inverse problem)를 효과적으로 해결했다.</p>
<p>이 연구의 핵심 아이디어는 **다크 채널 사전(Dark Channel Prior)**이라는 새로운 통계적 관찰에 기반한다. 저자들은 안개가 없는 실외 이미지를 분석한 결과, 하늘 영역을 제외한 대부분의 국소 패치(local patch) 내에는 <strong>적어도 하나의 색상 채널(R, G, B)에서 매우 낮은 강도(intensity)를 갖는 픽셀이 반드시 존재한다</strong>는 사실을 발견했다.43 이러한 ’어두운 픽셀’은 주로 그림자, 채도가 높은 물체(예: 녹색 식물), 또는 본래 어두운 물체(예: 어두운 나무줄기) 등에 의해 발생한다.</p>
<p>이 사전 확률을 이용한 안개 제거 과정은 다음과 같다 43:</p>
<ol>
<li>
<p>안개 낀 이미지의 형성 모델은 일반적으로 다음과 같이 표현된다:<br />
<span class="math math-display">
I(x) = J(x)t(x) + A(1 - t(x))
</span><br />
여기서 <span class="math math-inline">I</span>는 관측된 안개 이미지, <span class="math math-inline">J</span>는 복원하고자 하는 원본 이미지, <span class="math math-inline">A</span>는 전역 대기광(global atmospheric light), <span class="math math-inline">t</span>는 빛의 투과율(transmission)이다.</p>
</li>
<li>
<p>다크 채널 사전에 따르면, 원본 이미지 <span class="math math-inline">J</span>의 다크 채널 값(<span class="math math-inline">J_{dark}</span>)은 거의 0에 가깝다. (<span class="math math-inline">J_{dark}(x) = \min_{c \in \{r,g,b\}} (\min_{y \in \Omega(x)} J^c(y)) \approx 0</span>). 안개 낀 이미지에서 이 ‘어두워야 할’ 픽셀들의 밝기는 대부분 대기광 <span class="math math-inline">A</span>에 의해 발생한다.</p>
</li>
<li>
<p>이 원리를 이용하면, 안개 낀 이미지 <span class="math math-inline">I</span>의 다크 채널로부터 빛의 투과율 <span class="math math-inline">t(x)</span>를 직접적으로 추정할 수 있다. 구체적인 추정식은 다음과 같다:<br />
<span class="math math-display">
\tilde{t}(x) = 1 - \min_{c} \left( \min_{y \in \Omega(x)} \frac{I^c(y)}{A^c} \right)
</span></p>
</li>
<li>
<p>추정된 투과율 <span class="math math-inline">\tilde{t}(x)</span>와 대기광 <span class="math math-inline">A</span>를 이용해 첫 번째 식을 <span class="math math-inline">J(x)</span>에 대해 정리하면 안개가 제거된 이미지를 복원할 수 있다.</p>
</li>
</ol>
<p>이 방법은 인간의 통찰력과 도메인 지식이 얼마나 강력한 도구가 될 수 있는지를 보여주는 대표적인 사례로, 딥러닝 기반 접근법이 대세가 되기 전까지 안개 제거 분야의 표준적인 방법론으로 자리 잡았다.</p>
<h2>5.  로봇공학의 핵심 발전 동향</h2>
<p>2009년 로봇공학 연구는 ’현실 세계에서의 실용적 자율성’이라는 목표를 달성하기 위해 하드웨어(동적 제어), 소프트웨어(ROS), 그리고 이론(정보 공간)이라는 세 가지 축이 동시에 발전하는 양상을 보였다. 뛰어난 동적 제어 알고리즘은 불확실한 환경을 다룰 수 있는 강인한 계획 이론을 필요로 하며, 이 둘 모두를 효율적으로 개발하고 통합하기 위해서는 표준화된 플랫폼이 필수적이다. 2009년 로봇공학계는 실용적 자율성이라는 공동의 목표를 향해 이 세 가지 핵심 요소가 함께 성숙해가는 중요한 단계에 있었다.</p>
<h3>5.1  휴머노이드 로봇의 동적 보행 능력: HRP-2 사례</h3>
<p>IEEE Transactions on Robotics에 발표된 Olivier Stasse 등의 “Strategies for Humanoid Robots to Dynamically Walk Over Large Obstacles“는 휴머노이드 로봇 HRP-2가 큰 장애물을 동적으로 넘어가는 완전한 솔루션을 제안하여, 휴머노이드의 이동 능력에 대한 기대를 한 단계 끌어올렸다.44</p>
<p>이전의 연구들은 로봇의 무게중심(Center of Mass, CoM)이 항상 지지 다각형(support polygon) 내에 머무는 <strong>준정적(quasi-static) 안정성</strong>에 기반했다.46 이 방식은 안정성을 보장하지만, 움직임이 극도로 느려져 비현실적이라는 한계가 있었다. 반면, 이 연구는 로봇의 동역학을 적극적으로 활용하여 **영 모멘트 점(Zero Moment Point, ZMP)**을 안정성 기준으로 사용하는 <strong>동적 보행</strong>을 구현했다.47 ZMP 기준을 사용하면 로봇의 무게중심이 지지 다각형을 벗어날 수 있어 훨씬 더 빠르고 자연스러운 움직임이 가능하다.</p>
<p>이러한 접근법의 전환은 놀라운 성능 향상으로 이어졌다. 아래 표는 동적 보행과 준정적 보행의 성능을 직접적으로 비교한 것이다.</p>
<table><thead><tr><th>비교 항목</th><th>동적 보행 (Dynamic Walking - Stasse et al., 2009)</th><th>준정적 보행 (Quasi-Static Walking - Prior Work)</th></tr></thead><tbody>
<tr><td><strong>안정성 기준</strong></td><td>영 모멘트 점 (ZMP)</td><td>무게중심(CoM)의 지지 다각형 내 위치</td></tr>
<tr><td><strong>15cm 장애물 통과 시간</strong></td><td><strong>4초</strong> 44</td><td>40초 44</td></tr>
<tr><td><strong>최대 장애물 높이 (실험)</strong></td><td>15cm (다리 길이의 21%) 44</td><td>15cm 44</td></tr>
<tr><td><strong>최대 장애물 높이 (시뮬레이션)</strong></td><td>25cm (다리 길이의 35%) 44</td><td>명시된 바 없음</td></tr>
<tr><td><strong>보행 연속성</strong></td><td>정지 없이 연속 보행 가능 44</td><td>장애물 앞에서 정지 후 느린 동작 수행 46</td></tr>
<tr><td><strong>이중 지지 구간</strong></td><td>매우 짧음 44</td><td>CoM 이동을 위해 긴 구간 필요 47</td></tr>
</tbody></table>
<p>표에서 볼 수 있듯이, 15cm 높이의 동일한 장애물을 넘는 데 걸리는 시간이 <strong>40초에서 4초로 10배 단축</strong>되었다.44 또한, 시뮬레이션에서는 로봇 다리 길이의 35%에 달하는 25cm 높이의 장애물까지 극복할 수 있음을 보여주었다. 이 연구는 충돌 회피, 관절 한계, 안정성, 충격 완화 등을 모두 고려한 통합적인 계획 기법을 통해 휴머노이드 로봇이 인간과 유사한 환경에서 실용적으로 작동할 수 있는 가능성을 제시했다.</p>
<h3>5.2  불확실성의 재정의: 정보 공간에서의 계획</h3>
<p>IROS 2009에서 Steven LaValle이 진행한 “Filtering and Planning in Information Spaces” 튜토리얼은 로봇이 불확실성을 다루는 방식에 대한 근본적인 패러다임 전환을 제안했다.49 전통적인 로봇 공학은 불확실성을 다루기 위해 칼만 필터나 베이즈 필터와 같은 정교한 확률 모델을 사용하지만, 이는 엄청난 모델링 부담과 계산 비용을 야기한다.</p>
<p>LaValle은 이러한 모델링 부담을 회피하거나 최소화하는 새로운 접근법을 제시했다. 그의 접근법의 핵심 아이디어는 ’작업 수행에 필요한 최소한의 정보가 무엇인가’를 먼저 분석하고, 그 정보만을 추출할 수 있는 **최소한의 센서(minimalist sensors)**와 **조합 필터(combinatorial filters)**를 설계하는 것이다.49 이 프레임워크에서 로봇은 물리적 상태 공간(state space)이 아닌, 센서 관측을 통해 얻을 수 있는 정보의 집합인 **정보 공간(information space)**에서 계획을 수행한다. 예를 들어, 로봇이 방 안의 특정 물체를 찾아야 할 때, 로봇의 정확한 <span class="math math-inline">(x, y, \theta)</span> 좌표를 추정하는 대신, ‘물체가 시야에 있는가/없는가’ 또는 ’물체가 내 왼쪽에 있는가/오른쪽에 있는가’와 같은 이산적인 정보 상태만을 고려하여 계획을 수립할 수 있다. 이는 확률 모델을 도입하기 전에 문제 자체를 기하학적, 조합적으로 단순화하는 강력한 방법을 제공했다.</p>
<h3>5.3  로봇 개발 생태계의 태동: 로봇 운영체제(ROS)</h3>
<p>2009년은 로봇 개발의 패러다임을 바꾼 **로봇 운영체제(Robot Operating System, ROS)**가 학계에 본격적으로 알려지기 시작한 중요한 해였다. 2007년 Willow Garage에서 시작되어 11월 7일 첫 코드가 커밋된 ROS는 9, 2009년 5월 ICRA에서 첫 공식 논문이 발표되면서 학술 커뮤니티의 주목을 받기 시작했다.10</p>
<p>ROS의 비전은 “로봇계의 리눅스(Linux for robotics)“가 되는 것이었다.9 이는 로봇 응용 프로그램 개발에 필요한 공통적인 기능들—하드웨어 추상화, 저수준 장치 제어, 프로세스 간 메시지 전달, 패키지 관리 등—을 표준화된 라이브러리와 도구 모음으로 제공하는 것을 목표로 했다.50 2009년 당시 ROS는 아직 초기 단계였지만, 그 잠재력은 명확했다. IROS와 같은 학회에서 발표되는 수많은 선진적인 알고리즘들이 더 이상 개별 연구실의 고립된 코드 뭉치로 남지 않고, 서로 공유되고 통합될 수 있는 공통의 플랫폼을 제공할 것이라는 기대를 모았다. 이는 이후 10년간 로봇 연구 개발의 속도를 폭발적으로 가속화하고, 학계와 산업계 전반에 걸쳐 협업을 촉진하는 결정적인 기반이 되었다.</p>
<h2>6. 결론: 혁명의 기로에 선 분야</h2>
<p>2009년 4분기는 AI 및 로봇공학 분야가 거대한 전환을 앞둔 ’폭풍 전야’와 같은 시기였다. 한편에서는 DPM과 같은 고도로 정교화된 전통적 통계 모델이 정점을 찍으며 최고의 성능을 과시했고, 다른 한편에서는 DBN과 같은 딥러닝 모델이 어려운 벤치마크에서 그 잠재력을 입증하며 조용히 부상하고 있었다.</p>
<p>이 시기의 연구들은 ’지식 기반 공학(knowledge-driven engineering)’과 ‘데이터 기반 학습(data-driven learning)’ 사이의 팽팽한 긴장을 명확히 보여준다. DPM과 다크 채널 사전은 인간의 통찰력과 도메인 지식이 정교하게 녹아든 전자의 대표 주자였다. 이들은 문제의 구조를 깊이 이해하고, 그에 맞는 정교한 모델이나 우아한 물리적 원리를 설계함으로써 성공을 거두었다. 반면, DBN은 데이터로부터 직접 계층적 표현을 학습하는 후자의 가능성을 예고했다. 이는 인간의 사전 지식 개입을 최소화하고, 대규모 데이터와 계산 능력을 통해 문제의 본질을 스스로 파악하려는 새로운 철학의 시작이었다.</p>
<p>NeurIPS에서 발표된 딥러닝 연구들, 특히 NORB 데이터셋에서의 성공은 이후 2012년 ImageNet 챌린지에서 AlexNet이 일으킬 혁명의 명백한 서곡이었다. 동시에, “Reading Tea Leaves“와 같은 연구는 성능 지표를 넘어 ’해석 가능성’과 ’신뢰성’이라는, 오늘날 AI가 직면한 가장 중요한 화두를 이미 10여 년 전에 제기하고 있었다. 로봇공학 분야 역시 동적 제어 기술의 성숙, 불확실성에 대한 새로운 이론적 접근, 그리고 ROS라는 표준화된 개발 플랫폼의 등장을 통해 더욱 복잡하고 실용적인 자율 시스템으로 나아갈 준비를 마쳤다.</p>
<p>결국 2009년 4분기는 과거의 성취가 최고조에 달함과 동시에 미래의 혁명이 싹트고 있던, AI와 로봇공학 역사에서 매우 중요한 시점이었다. 이 시기에 제시된 다양한 아이디어와 치열한 경쟁은 이후 10년을 정의하고, 현재 우리가 경험하고 있는 AI 시대의 기술적, 철학적 토대를 마련했다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>www.openresearch.org, <a href="https://www.openresearch.org/wiki/IROS_2009#:~:text=The%202009%20IEEE%2FRSJ%20International,October%2011%20to%2015%2C%202009.">https://www.openresearch.org/wiki/IROS_2009#:~:text=The%202009%20IEEE%2FRSJ%20International,October%2011%20to%2015%2C%202009.</a></li>
<li>International Conference on Intelligent Robots and Systems - Wikipedia, https://en.wikipedia.org/wiki/International_Conference_on_Intelligent_Robots_and_Systems</li>
<li>IEEE 12th International Conference on Computer Vision, ICCV 2009, Kyoto, Japan, September 27 - DBLP, https://dblp.org/rec/conf/iccv/2009</li>
<li>International Conference on Computer Vision - Wikipedia, https://en.wikipedia.org/wiki/International_Conference_on_Computer_Vision</li>
<li>neurips.cc, <a href="https://neurips.cc/Conferences/2009/Dates#:~:text=The%20Twenty-Third%20annual%20conference,Hilton%20Whistler%20Resort%20and%20Spa.">https://neurips.cc/Conferences/2009/Dates#:~:text=The%20Twenty%2DThird%20annual%20conference,Hilton%20Whistler%20Resort%20and%20Spa.</a></li>
<li>2009 Dates and Deadlines - NeurIPS 2025, https://neurips.cc/Conferences/2009/Dates</li>
<li>Waymo - Wikipedia, https://en.wikipedia.org/wiki/Waymo</li>
<li>How Google’s Self-Driving Car Will Change Everything - Investopedia, https://www.investopedia.com/articles/investing/052014/how-googles-selfdriving-car-will-change-everything.asp</li>
<li>Robot Operating System - Wikipedia, https://en.wikipedia.org/wiki/Robot_Operating_System</li>
<li>The rise of the Robot Operating System - Red Hat, https://www.redhat.com/en/blog/rise-robot-operating-system</li>
<li>Exploring Strategies for Training Deep Neural Networks - Journal of Machine Learning Research, https://jmlr.org/papers/volume10/larochelle09a/larochelle09a.pdf</li>
<li>(PDF) A fast learning algorithm for deep belief nets (2006) | Geoffrey E. Hinton - SciSpace, https://scispace.com/papers/a-fast-learning-algorithm-for-deep-belief-nets-1hjmir8y1f</li>
<li>A Fast Learning Algorithm for Deep Belief Nets - ResearchGate, https://www.researchgate.net/publication/7017915_A_Fast_Learning_Algorithm_for_Deep_Belief_Nets</li>
<li>3D Object Recognition with Deep Belief Nets - ResearchGate, https://www.researchgate.net/publication/221620477_3D_Object_Recognition_with_Deep_Belief_Nets</li>
<li>Exploring Strategies for Training Deep Neural Networks, https://www.jmlr.org/papers/v10/larochelle09a.html</li>
<li>JMLR Volume 10 - Journal of Machine Learning Research, http://jmlr.org/beta/papers/v10/</li>
<li>Exploring Strategies for Training Deep Neural Networks - ResearchGate, https://www.researchgate.net/publication/200744481_Exploring_Strategies_for_Training_Deep_Neural_Networks</li>
<li>NeurIPS 2009 Accepted Paper List - Paper Copilot, https://papercopilot.com/paper-list/neurips-paper-list/neurips-2009-paper-list/</li>
<li>3D Object Recognition with Deep Belief Nets - NIPS, https://papers.nips.cc/paper/3872-3d-object-recognition-with-deep-belief-nets</li>
<li>3D Object Recognition with Deep Belief Nets - Department of …, https://www.cs.toronto.edu/~hinton/absps/vinodNORB.pdf</li>
<li>Deep Learning for Speech Recognition and Related Applications - NeurIPS 2025, https://neurips.cc/virtual/2009/workshop/1512</li>
<li>Unsupervised feature learning for audio classification using … - NIPS, https://proceedings.neurips.cc/paper/2009/hash/a113c1ecd3cace2237256f4c712f61b5-Abstract.html</li>
<li>NIPS Demonstration Robust Speaker Recognition Using Approximate Bayesian Inference, https://neurips.cc/virtual/2009/demonstration/1532</li>
<li>NIPS Poster Learning Label Embeddings for Nearest-Neighbor Multi-class Classification with an Application to Speech Recognition - NeurIPS 2025, https://neurips.cc/virtual/2009/poster/1630</li>
<li>Awards - NeurIPS 2025, https://neurips.cc/Conferences/2009/Awards</li>
<li>Reading Tea Leaves: How Humans Interpret Topic Models - NIPS, https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models</li>
<li>Reading Tea Leaves: How Humans Interpret Topic Models - NIPS, http://papers.neurips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf</li>
<li>Reading Tea Leaves: How Humans Interpret Topic Models, https://courses.grainger.illinois.edu/cs598jhm/sp2013/Slides/Lecture10.pdf</li>
<li>Kernel Choice and Classifiability for RKHS Embeddings of … - NIPS, https://papers.nips.cc/paper/3750-kernel-choice-and-classifiability-for-rkhs-embeddings-of-probability-distributions</li>
<li>NIPS 2009 Papers - NeurIPS 2025, https://nips.cc/virtual/2009/papers.html</li>
<li>The Infinite Partially Observable Markov Decision Process - NIPS, https://papers.nips.cc/paper/3780-the-infinite-partially-observable-markov-decision-process</li>
<li>(PDF) The Infinite Partially Observable Markov Decision Process - ResearchGate, https://www.researchgate.net/publication/221619206_The_Infinite_Partially_Observable_Markov_Decision_Process</li>
<li>The Infinite Partially Observable Markov Decision Process - Semantic Scholar, https://pdfs.semanticscholar.org/bc1c/f776de0d5421ebaaef5d95c48fdab14dec98.pdf</li>
<li>The Infinite Partially Observable Markov Decision Process - MLG Cambridge, https://mlg.eng.cam.ac.uk/pub/pdf/Dos09b.pdf</li>
<li>Visual Object Classes Challenge 2009 | Knowledge 4 All …, https://k4all.org/project/visual-object-classes-challenge-2009/</li>
<li>The PASCAL Visual Object Classes (VOC) Challenge - Informatics Homepages Server, https://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf</li>
<li>Deformable Part Models with Individual Part Scaling - Infoscience, https://infoscience.epfl.ch/server/api/core/bitstreams/b14675cc-6985-44f6-a40f-72638efc1bf7/content</li>
<li>A Discriminatively Trained, Multiscale, Deformable Part Model - CMU School of Computer Science, https://www.cs.cmu.edu/~deva/papers/latent.pdf</li>
<li>Object Detection with Discriminatively Trained Part Based Models, https://cs.brown.edu/people/pfelzens/papers/lsvm-pami.pdf</li>
<li>Object Detection with Discriminatively Trained Part-Based Models - ResearchGate, https://www.researchgate.net/publication/45200127_Object_Detection_with_Discriminatively_Trained_Part-Based_Models</li>
<li>‪Kaiming He‬ - ‪Google Scholar‬, https://scholar.google.com/citations?user=DhtAFkwAAAAJ&amp;hl=en</li>
<li>[PDF] Single image haze removal using dark channel prior - Semantic Scholar, https://www.semanticscholar.org/paper/Single-image-haze-removal-using-dark-channel-prior-He-Sun/5585ecdf5d39c9f0ae0f12f89fab426f92baed68</li>
<li>Single Image Haze Removal Using Dark Channel Prior - Kaiming He, https://projectsweb.cs.washington.edu/research/insects/CVPR2009/award/hazeremv_drkchnl.pdf</li>
<li>(PDF) Strategies for Humanoid Robots to Dynamically Walk Over …, https://www.researchgate.net/publication/224442049_Strategies_for_Humanoid_Robots_to_Dynamically_Walk_Over_Large_Obstacles</li>
<li>3D Vision-Based Local Path Planning System of a Humanoid Robot, https://koreascience.kr/article/JAKO201319850773038.page</li>
<li>Dynamically Stepping Over Obstacles by the Humanoid Robot HRP-2, https://homepages.laas.fr/ostasse/DynamicStepOver.pdf</li>
<li>Mobility of Humanoid Robots: Stepping over Large Obstacles Dynamically - ResearchGate, https://www.researchgate.net/publication/224677037_Mobility_of_Humanoid_Robots_Stepping_over_Large_Obstacles_Dynamically</li>
<li>Stability and Dynamic Walk Control of Humanoid Robot for Robot Soccer Player - MDPI, https://www.mdpi.com/2075-1702/10/6/463</li>
<li>IROS 2009 Tutorial - Steven M. LaValle, http://msl.cs.uiuc.edu/~lavalle/iros09/</li>
<li>What Is The Robot Operating System? - Formant, https://formant.io/resources/glossary/robot-operating-system/</li>
<li>Robot Operating System • What is it? • Brief History • Key ROS Concepts: Nodes &amp; Publishers, http://robotics.caltech.edu/wiki/images/0/03/ROS_intro.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>