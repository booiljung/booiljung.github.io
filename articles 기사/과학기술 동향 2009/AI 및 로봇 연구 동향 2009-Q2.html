<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2009년 2분기 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2009년 2분기 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2009년 AI 및 로봇 연구 동향</a> / <span>2009년 2분기 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2009년 2분기 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 새로운 10년을 앞둔 AI와 로봇 공학</h2>
<p>2009년은 인공지능(AI)과 로봇 공학 분야가 중대한 패러다임 전환을 목전에 둔 시기였다. 2000년대 후반의 기술적 지형은 SIFT(Scale-Invariant Feature Transform)와 같은 특징점 기술과 통계적 학습 방법론이 성숙기에 접어들며, 객체 인식, 장면 이해, 로봇 내비게이션 등 다양한 분야에서 안정적인 성능을 보여주고 있었다. 그러나 이러한 방법론들은 데이터의 규모와 복잡성이 증가함에 따라 표현력과 확장성의 한계에 직면하고 있었다. 학계는 기존의 정교한 모델링 방식만으로는 현실 세계의 무한한 복잡성을 포착하기 어렵다는 공감대를 형성하기 시작했으며, 이는 새로운 돌파구에 대한 강렬한 요구로 이어졌다.1</p>
<p>본 보고서는 이러한 기술적 전환기에 해당하는 2009년 2분기에 개최된 세 개의 최고 수준 학회—IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE International Conference on Robotics and Automation (ICRA), International Conference on Autonomous Agents and Multiagent Systems (AAMAS)—에서 발표된 주요 연구들을 심층적으로 분석한다. 이 시기에 발표된 연구들은 단순한 점진적 개선을 넘어, 이후 10년간 AI 및 로봇 공학의 연구 방향을 근본적으로 바꾼 세 가지 핵심적인 패러다임의 전환을 예고했다.</p>
<p>첫째, <strong>물리적 세계에 대한 깊은 이해와 대규모 데이터 기반의 통계적 사전 확률(prior)의 결합</strong>이다. 이는 복잡하고 불확실한 현실 세계의 문제를 해결하기 위해, 수학적 모델에 데이터로부터 발견한 강력한 통계적 통찰을 통합하는 접근법이다. 둘째, **대규모 데이터를 통한 지식의 비모수적 전이(nonparametric transfer)**이다. 이는 명시적인 모델을 학습하는 대신, 방대한 데이터베이스 자체를 지식의 원천으로 삼아 유사 사례를 검색하고 그 정보를 현재 문제에 적용하는 방식이다. 셋째, <strong>개방형 표준 플랫폼을 통한 연구 생태계의 구축</strong>이다. 이는 파편화된 연구 개발 환경을 극복하고, 전 세계 연구자들이 협력하고 결과를 공유할 수 있는 공통의 소프트웨어 기반을 마련하려는 시도이다.</p>
<p>본 보고서는 이 세 가지 전환점을 축으로 하여 CVPR, ICRA, AAMAS 2009에서 발표된 가장 영향력 있는 연구들을 상세히 해부하고, 각 연구의 방법론적 독창성과 기술적 기여, 그리고 이들이 서로 어떻게 연결되어 현재의 AI 시대를 열었는지를 규명하고자 한다. 이를 통해 2009년 2분기가 AI 및 로봇 공학 역사에서 단순한 한 시점이 아니라, 미래를 향한 결정적인 변곡점이었음을 논증할 것이다.</p>
<h2>2.  컴퓨터 비전의 새로운 지평 - CVPR 2009</h2>
<p>CVPR 2009는 컴퓨터 비전 분야가 전통적인 기하학 기반 모델링과 통계적 학습의 한계를 인식하고, 대규모 데이터와 물리적 현실에 대한 깊은 통찰을 통합하는 새로운 연구 방향을 모색하기 시작한 중요한 분기점이었다. 이 시기에 발표된 연구들은 이후 딥러닝 시대의 도래를 예비하는 철학적, 방법론적 토대를 마련했다. 본 장에서는 CVPR 2009에서 최우수 논문상, 최우수 학생 논문상 등을 수상하며 당대 최고의 연구로 공인받은 세 편의 기념비적인 논문을 통해 이러한 패러다임의 변화를 심층적으로 분석한다.2 이 연구들은 각각 데이터 기반의 통찰, 데이터 기반의 모델, 그리고 데이터 인프라라는 측면에서 컴퓨터 비전의 미래를 제시했다.</p>
<h3>2.1  물리 법칙과 통계적 통찰의 결합: 단일 영상 안개 제거를 위한 다크 채널 사전 확률 (Single Image Haze Removal Using Dark Channel Prior)</h3>
<p>단일 이미지로부터 안개나 연무를 제거하는 작업은 컴퓨터 비전 분야의 고전적인 난제 중 하나이다. 이는 깊이 정보가 소실된 2차원 이미지로부터 대기 중의 빛(airlight)과 장면의 원래 색상 및 반사율(scene radiance)을 분리해야 하는 본질적인 비결정성(ill-posed) 문제이기 때문이다. Kaiming He 연구팀의 논문이 발표되기 이전, 이 문제를 해결하려는 대부분의 시도는 여러 장의 이미지를 사용하거나, 안개의 농도에 대한 추가적인 정보를 요구하는 등 제약이 많은 방식에 의존했다.4</p>
<h4>2.1.1 문제 정의 및 기존 접근법의 한계</h4>
<p>안개 낀 이미지가 형성되는 물리적 과정은 대기 산란 모델(atmospheric scattering model)로 잘 알려져 있다. 이 모델은 컴퓨터 그래픽스와 컴퓨터 비전 분야에서 널리 사용되며, 다음과 같은 수식으로 표현된다.4<br />
<span class="math math-display">
I(x) = J(x)t(x) + A(1 - t(x))
</span><br />
여기서 <span class="math math-inline">I(x)</span>는 카메라에 관측된 이미지의 픽셀 <span class="math math-inline">x</span>에서의 강도(intensity)이며, <span class="math math-inline">J(x)</span>는 우리가 복원하고자 하는 실제 장면의 색상(scene radiance)이다. <span class="math math-inline">A</span>는 전역 대기광(global atmospheric light)으로, 보통 하늘의 색과 유사하며 장면 전체에서 균일하다고 가정된다. <span class="math math-inline">t(x)</span>는 매질 투과율(medium transmission)로, 장면의 한 지점에서 나온 빛이 산란되지 않고 카메라에 도달하는 비율을 나타낸다. 투과율 <span class="math math-inline">t(x)</span>는 카메라와 장면 속 객체 사이의 거리에 지수적으로 반비례하므로, 깊이 정보와 밀접한 관련이 있다. 안개 제거의 목표는 주어진 입력 이미지 <span class="math math-inline">I</span>로부터 <span class="math math-inline">J</span>, <span class="math math-inline">A</span>, <span class="math math-inline">t</span>를 모두 추정하는 것이다. 하지만 단일 이미지에서는 미지수가 방정식의 수보다 많아 이 문제를 직접 풀 수 없다.</p>
<h4>2.1.2 핵심 방법론 - 물리 모델과 통계적 발견</h4>
<p>Kaiming He 연구팀은 이 비결정성 문제를 해결하기 위해, 물리 모델에 강력한 통계적 사전 확률(statistical prior)을 결합하는 혁신적인 접근법을 제시했다. 그들이 발견한 사전 확률이 바로 ’다크 채널 사전 확률(Dark Channel Prior)’이다.</p>
<ul>
<li>
<p><strong>다크 채널 사전 확률 (Dark Channel Prior):</strong> 이 사전 확률은 수천 장의 안개 없는 실외 이미지를 통계적으로 분석한 결과로부터 도출된 경험적 관찰에 기반한다. 그 핵심 내용은 “하늘 영역을 제외한 대부분의 안개 없는 실외 이미지의 지역 패치(local patch)에는, 적어도 하나의 색상 채널(R, G, B)에서 매우 낮은 강도(intensity)를 갖는 픽셀이 반드시 존재한다“는 것이다.4 예를 들어, 녹색 식물의 잎은 R과 B 채널에서 낮은 값을 가지며, 다채로운 자동차 표면이라도 그림자가 지는 부분은 특정 채널에서 매우 어두운 값을 갖는다.</p>
</li>
<li>
<p><strong>수학적 정의:</strong> 이 관찰을 수학적으로 형식화하기 위해, 연구팀은 ’다크 채널’이라는 개념을 정의했다. 어떤 이미지 <span class="math math-inline">J</span>의 다크 채널 <span class="math math-inline">J^{\text{dark}}</span>는 각 픽셀 <span class="math math-inline">x</span>를 중심으로 하는 특정 크기의 윈도우 <span class="math math-inline">\Omega(x)</span> 내에서, 모든 색상 채널 c에 걸쳐 가장 작은 강도 값을 취한 것으로 정의된다.</p>
<p><span class="math math-display">
J^{\text{dark}}(x) = \min_{y \in \Omega(x)} \left( \min_{c \in \{r,g,b\}} J^c(y) \right)
</span></p>
</li>
</ul>
<p>다크 채널 사전 확률에 따르면, 안개가 없는 실외 이미지 <span class="math math-inline">J</span>의 경우, 그 다크 채널 <span class="math math-inline">J^{\text{dark}}</span>의 값은 대부분의 픽셀에서 0에 매우 가깝게 나타난다 (<span class="math math-inline">J^{\text{dark}} \rightarrow 0</span>).</p>
<h4>2.1.3 안개 제거 알고리즘</h4>
<p>이 강력한 사전 확률은 안개 제거 문제를 푸는 결정적인 열쇠가 된다. 알고리즘은 다음의 단계로 진행된다.</p>
<ol>
<li>
<p><strong>대기광 <span class="math math-inline">A</span> 추정:</strong> 안개 낀 이미지에서 가장 안개가 짙은 부분은 대기광 <span class="math math-inline">A</span>와 가장 유사한 색을 띤다. 연구팀은 다크 채널 이미지에서 상위 0.1%의 밝기를 갖는 픽셀들을 후보로 선택하고, 이 후보 픽셀들 중에서 원본 이미지 <span class="math math-inline">I</span>에서 가장 밝은 값을 갖는 픽셀의 색상을 <span class="math math-inline">A</span>로 추정했다.</p>
</li>
<li>
<p><strong>투과율 <span class="math math-inline">t(x)</span> 추정:</strong> 안개 영상 모델의 양변을 <span class="math math-inline">A^c</span>로 나누고, 윈도우 내에서 최솟값 연산을 취한 후 다크 채널 사전 확률(<span class="math math-inline">J^{\text{dark}} \rightarrow 0</span>)을 적용하면, 투과율 <span class="math math-inline">\tilde{t}(x)</span>의 초기 추정치를 다음과 같이 얻을 수 있다.</p>
<p><span class="math math-display">
\tilde{t}(x) = 1 - \min_{y \in \Omega(x)} \left( \min_{c} \frac{I^c(y)}{A^c} \right)
</span></p>
</li>
</ol>
<p>이 식은 안개가 짙을수록(즉, 이미지의 다크 채널이 밝을수록) 투과율이 낮아진다는 직관과 일치한다. 또한, 원근감을 보존하기 위해 상수 <span class="math math-inline">\omega \in (0, 1]</span>를 도입하여 약간의 안개를 남겨두는 기법도 적용했다.</p>
<ol start="3">
<li>
<p><strong>투과율 맵 정제:</strong> 초기 투과율 맵 <span class="math math-inline">\tilde{t}(x)</span>는 윈도우 연산으로 인해 블록 형태의 경계가 나타나는 문제가 있다. 이를 해결하고 객체의 경계와 일치하는 정교한 투과율 맵을 얻기 위해 소프트 매팅(soft matting) 기법을 적용하여 최종 투과율 맵 <span class="math math-inline">t(x)</span>를 얻는다.4</p>
</li>
<li>
<p><strong>장면 복원:</strong> 추정된 대기광 <span class="math math-inline">A</span>와 정제된 투과율 맵 <span class="math math-inline">t(x)</span>를 원래의 안개 영상 모델에 대입하여 최종적으로 안개가 제거된 이미지 <span class="math math-inline">J(x)</span>를 복원한다.</p>
<p><span class="math math-display">
J(x) = \frac{I(x) - A}{\max(t(x), t_0)} + A
</span></p>
</li>
</ol>
<p>여기서 <span class="math math-inline">t_0</span>는 투과율이 0에 가까워져 노이즈가 증폭되는 것을 막기 위한 하한값이다.</p>
<h4>2.1.4 학문적 의의 및 영향</h4>
<p>이 연구는 CVPR 2009 최우수 논문상(Best Paper Award)을 수상했으며 2, 그 영향력은 학계를 넘어 산업계에까지 광범위하게 미쳤다. 이 방법의 가장 큰 의의는 복잡한 물리 현상을 해결하기 위해, 데이터에 기반한 강력한 통계적 사전 확률을 성공적으로 도입했다는 점이다. 이는 물리 모델의 엄밀함과 데이터 기반 통찰의 강력함을 결합한 대표적인 사례로, 이후 컴퓨터 비전 및 계산 사진학(computational photography) 분야에서 수많은 후속 연구를 촉발시켰다.6 특히, 문제 해결을 위해 대규모 데이터로부터 보편적인 통계적 규칙성을 발견하고 이를 활용한다는 철학은, 이후 딥러닝 시대의 데이터 중심 연구 방법론과 그 맥을 같이 한다. 이 연구는 단일 이미지만으로 깊이 맵(depth map)까지 추정할 수 있는 가능성을 보여주며, 2D 이미지로부터 3D 정보를 복원하는 연구에도 큰 영감을 주었다.</p>
<h3>2.2  데이터 기반 장면 이해: 밀집 정렬을 통한 비모수적 레이블 전송 (Nonparametric Scene Parsing: Label Transfer via Dense Scene Alignment)</h3>
<p>장면 이해(scene parsing) 또는 의미론적 분할(semantic segmentation)은 이미지의 모든 픽셀을 ‘하늘’, ‘도로’, ‘건물’, ‘사람’ 등과 같은 의미 있는 카테고리로 분류하는 컴퓨터 비전의 핵심 과제이다. 2009년 이전, 이 문제에 대한 지배적인 접근법은 각 객체 카테고리에 대한 정교한 파라메트릭 모델(parametric model)을 학습하는 것이었다. 예를 들어, 특정 객체의 형태, 질감, 색상 분포 등을 통계적으로 모델링하고, 이를 기반으로 분류기를 학습시키는 방식이었다. 그러나 이러한 파라메트릭 접근법은 새로운 객체 카테고리가 추가될 때마다 전체 모델을 다시 학습해야 하는 등 확장성에 근본적인 한계를 가지고 있었다.9</p>
<p>Ce Liu 연구팀은 이러한 패러다임에 도전하며, 대규모 주석 데이터베이스를 명시적인 모델 학습 없이 직접 활용하는 혁신적인 비모수적(nonparametric) 접근법을 제안했다. 그들의 핵심 아이디어는 ’학습을 통한 인식’이 아닌 ’매칭을 통한 인식’이었다.</p>
<h4>2.2.1 핵심 방법론 - 레이블 전송 파이프라인</h4>
<p>이 연구에서 제안한 시스템은 입력 이미지(query image)가 주어졌을 때, 방대한 양의 레이블링된 이미지 데이터베이스에서 가장 유사한 이미지를 찾아내고, 그 이미지의 주석(label)을 입력 이미지에 ’전송(transfer)’하는 방식으로 동작한다. 이 파이프라인은 크게 세 단계로 구성된다.</p>
<ol>
<li><strong>장면 검색 (Scene Retrieval):</strong> 첫 단계는 입력 이미지와 전체적인 장면 구성이 유사한 후보 이미지들을 데이터베이스에서 찾는 것이다. 이를 위해 이미지의 전역적인 공간 구조 정보를 요약하는 GIST 특징을 사용하여 1차적으로 유사한 이미지들을 빠르게 검색한다.9</li>
<li><strong>밀집 장면 정렬 (Dense Scene Alignment):</strong> 다음으로, 검색된 후보 이미지들과 입력 이미지 간의 픽셀 단위 대응 관계를 설정한다. 이 과정이 이 방법론의 핵심 기술이며, 이를 위해 SIFT Flow 알고리즘을 사용한다.9 SIFT Flow는 전통적인 광학 흐름(optical flow) 알고리즘을 확장한 것으로, 두 이미지 간의 SIFT 특징 기술자(descriptor)의 유사성을 기반으로 조밀한(dense) 변위 벡터 필드를 계산한다. 이는 단순히 몇 개의 특징점을 매칭하는 것을 넘어, 한 이미지의 모든 픽셀이 다른 이미지의 어느 픽셀에 해당하는지를 찾아내는 과정이다. 이 정렬 과정을 통해 얻은 매칭 에너지(matching energy)를 기준으로 후보 이미지들의 순위를 재조정하여 가장 정합이 잘 되는 상위 이미지들을 선택한다.</li>
<li><strong>레이블 전송 및 통합 (Label Transfer and Integration):</strong> 마지막으로, SIFT Flow를 통해 계산된 조밀한 대응 관계를 바탕으로, 선택된 후보 이미지들의 픽셀별 주석(레이블)을 입력 이미지로 그대로 옮겨온다.9 여러 후보 이미지로부터 각기 다른 레이블이 전송될 수 있으므로, 이들을 통합하여 최종적인 장면 분할 결과를 만들어내는 과정이 필요하다. 이를 위해 연구팀은 마르코프 랜덤 필드(MRF) 모델을 도입했다. MRF의 에너지 함수는 각 픽셀에 특정 레이블이 할당될 확률을 모델링하며, 다음과 같은 세 가지 요소를 종합적으로 고려한다 11:</li>
</ol>
<ul>
<li><strong>가능도(Likelihood):</strong> SIFT Flow 정렬 결과에 기반하여, 전송된 레이블이 얼마나 신뢰할 수 있는지를 평가한다.</li>
<li><strong>사전 확률(Prior):</strong> 특정 객체 카테고리가 장면에 나타날 확률(예: 하늘은 이미지 상단에 나타날 확률이 높음)을 반영한다.</li>
<li><strong>평활도(Smoothness):</strong> 인접한 픽셀들은 같은 레이블을 가질 가능성이 높다는 공간적 일관성 제약을 부여한다.</li>
</ul>
<p>이 에너지 함수를 최소화하는 레이블 할당을 찾음으로써, 최종적으로 공간적으로 일관되고 신뢰도 높은 장면 분할 결과를 얻는다. 에너지 함수의 형태는 다음과 같이 표현될 수 있다.<br />
<span class="math math-display">
-\log P(c|I, \dots) = \sum_p \psi(c(p); \dots) + \alpha \sum_p \lambda(c(p)) + \beta \sum_{\{p,q\} \in \mathcal{E}} \phi(c(p), c(q); I) + \log Z
</span><br />
여기서 <span class="math math-inline">c</span>는 레이블 맵, <span class="math math-inline">I</span>는 이미지이며, <span class="math math-inline">\psi</span>, <span class="math math-inline">\lambda</span>, <span class="math math-inline">\phi</span>는 각각 가능도, 사전 확률, 평활도 항을 나타낸다.</p>
<h4>2.2.2 학문적 의의 및 영향</h4>
<p>이 연구는 CVPR 2009 최우수 학생 논문상(Best Student Paper Award)을 수상하며 그 독창성과 잠재력을 인정받았다.2 이 방법론의 가장 큰 의의는 컴퓨터 비전 문제 해결의 패러다임을 ’모델 중심’에서 ’데이터 중심’으로 전환하는 가능성을 명확히 제시했다는 점이다. 복잡한 모델을 설계하고 학습하는 대신, 방대한 양의 ’지식’이 담긴 데이터베이스를 구축하고, 주어진 문제와 가장 관련 있는 지식을 효율적으로 ’검색하고 정렬’하여 문제를 해결하는 방식은 매우 강력했다.</p>
<p>이러한 비모수적 접근법은 대규모 데이터셋의 중요성을 다시 한번 부각시켰으며, k-최근접 이웃(k-NN)과 같은 고전적인 알고리즘이 대규모 데이터와 결합될 때 얼마나 강력한 성능을 발휘할 수 있는지를 보여주었다.10 또한, 검색 및 정렬 과정에서 장면의 전체적인 맥락(context)이 자연스럽게 고려된다는 장점도 있었다. 이 연구는 이후 이미지 기반 렌더링, 스타일 전송(style transfer), 그리고 다양한 비모수적 생성 모델 연구에 큰 영감을 주었으며, 데이터가 곧 모델이 될 수 있다는 아이디어는 현대 AI 연구의 근간을 이루는 중요한 철학적 토대가 되었다.</p>
<h3>2.3  딥러닝 시대를 연 초석: 대규모 계층적 이미지 데이터베이스, ImageNet</h3>
<p>2009년, 컴퓨터 비전 연구는 심각한 ’데이터 기근’에 시달리고 있었다. 당시 연구자들은 주로 PASCAL VOC나 Caltech-101/256과 같은 데이터셋을 사용했는데, 이들은 수십에서 수백 개의 카테고리와 수천에서 수만 장의 이미지를 포함하는 수준이었다.13 이러한 제한된 규모의 데이터셋은 개발된 알고리즘의 일반화 성능을 평가하고 개선하는 데 근본적인 한계로 작용했다. 모델이 학습 데이터에 과적합(overfitting)되기 쉬웠고, 실세계의 다양성을 제대로 반영하지 못했다.</p>
<p>이러한 배경 속에서 Jia Deng, Li Fei-Fei 연구팀이 CVPR 2009에서 포스터로 발표한 “ImageNet“은 컴퓨터 비전 연구의 지형을 완전히 바꾸어 놓은 혁명적인 프로젝트였다. ImageNet은 단순히 이미지의 양을 늘리는 것을 넘어, 데이터의 ’규모’와 ‘구조’ 모두에서 전례 없는 혁신을 이루었다.</p>
<h4>2.3.1 핵심 방법론 - 규모와 구조의 혁신</h4>
<p>ImageNet의 설계 철학은 두 가지 핵심 요소에 기반한다.</p>
<ol>
<li><strong>WordNet과의 연동을 통한 의미론적 계층 구조:</strong> ImageNet은 단순한 이미지의 나열이 아니다. 연구팀은 프린스턴 대학에서 개발한 대규모 영어 어휘 데이터베이스인 ’WordNet’을 그 구조적 뼈대로 사용했다.14 WordNet에서 유의어 집합을 의미하는 ’신셋(synset)’은 하나의 개념 단위를 나타낸다. ImageNet은 WordNet의 명사 계층 구조를 그대로 가져와, 각 신셋에 해당하는 수백에서 수천 장의 이미지를 체계적으로 할당했다. 이로 인해 ImageNet의 데이터는 단순한 카테고리 분류를 넘어, ’푸들’은 ’개’의 일종이고, ’개’는 ’포유류’에 속하며, ’포유류’는 ’동물’이라는 의미론적 상하위 관계를 내포하게 되었다. 이러한 계층적 구조는 모델이 보다 풍부한 시각적 개념을 학습하고 일반화하는 데 결정적인 역할을 했다.</li>
<li><strong>대규모 크라우드소싱을 통한 데이터 수집 및 정제:</strong> 수천만 장의 이미지를 수집하고, 각 이미지가 해당 신셋의 의미와 일치하는지 검증하는 작업은 소수의 연구 인력만으로는 불가능했다. 연구팀은 이 문제를 해결하기 위해 당시로서는 획기적인 방법인 아마존 메커니컬 터크(Amazon Mechanical Turk)라는 온라인 크라우드소싱 플랫폼을 적극적으로 활용했다.14 전 세계의 온라인 작업자들에게 이미지 검색 및 검증 작업을 분산하여 할당함으로써, 저비용으로 빠르고 정확하게 대규모 데이터셋을 구축할 수 있었다. 이 방법론은 이후 대규모 데이터셋 구축의 표준적인 방식으로 자리 잡았다.</li>
</ol>
<h4>2.3.2 규모와 영향</h4>
<p>CVPR 2009 발표 당시, ImageNet은 포유류, 차량, 가구 등 12개의 하위 트리에 걸쳐 총 5,247개의 신셋과 320만 개의 정제된 이미지를 포함하고 있었다. 이는 당시 존재하던 어떤 이미지 데이터셋과도 비교할 수 없는 압도적인 규모였다.16 프로젝트의 최종 목표는 WordNet의 약 8만 개 신셋 대부분을 이미지로 채워, 총 수천만 장 규모의 데이터베이스를 구축하는 것이었다.</p>
<p>ImageNet의 등장은 컴퓨터 비전 커뮤니티에 거대한 충격을 주었고, 이후 연구의 방향을 완전히 바꾸어 놓았다. 특히, 2010년부터 매년 개최된 ’ImageNet Large Scale Visual Recognition Challenge (ILSVRC)’는 전 세계 연구팀들이 자신들의 알고리즘 성능을 겨루는 경연장이 되었다. 그리고 2012년, 제프리 힌튼 연구팀의 AlexNet이 이 대회에서 합성곱 신경망(Convolutional Neural Network, CNN), 즉 딥러닝 모델을 사용하여 기존의 모든 기록을 압도적인 차이로 경신하는 사건이 발생했다.1 이는 딥러닝 혁명의 신호탄이었으며, ImageNet이라는 대규모의 고품질 데이터셋이 없었다면 불가능했을 성과였다.16 ImageNet은 데이터에 굶주려 있던 딥러닝 알고리즘에 풍부한 ’연료’를 공급함으로써 그 잠재력을 폭발시키는 결정적인 기폭제 역할을 한 것이다.</p>
<h3>2.4 제1부 종합 분석</h3>
<p>2009년 CVPR에서 발표된 이 세 가지 핵심 연구는 표면적으로는 각각 안개 제거, 장면 이해, 데이터셋 구축이라는 다른 주제를 다루고 있지만, 그 기저에는 컴퓨터 비전의 패러다임을 ’모델 중심’에서 ’데이터 중심’으로 전환시키는 거대한 흐름이 공통적으로 흐르고 있다. 이들의 관계는 우연이 아니라, 당시 학계가 공통적으로 직면했던 모델 표현력의 한계에 대한 다각적인 모색의 필연적인 결과로 해석될 수 있다.</p>
<p>첫째, Kaiming He의 ‘Dark Channel Prior’ 연구는 물리 모델의 불확실성을 ’자연 영상의 통계적 사전 확률’이라는 데이터 기반의 통찰로 돌파했다. 여기서 데이터는 기존 모델의 부족한 부분을 보완하고 완성하는 강력한 ‘보조재’ 역할을 수행했다.2 이는 데이터로부터 일반화된 지식을 추출하여 모델에 통합하는 방식의 유효성을 입증했다.</p>
<p>둘째, Ce Liu의 ‘Label Transfer’ 연구는 한 걸음 더 나아가, 대규모 데이터베이스 자체가 정교한 ’모델’이 될 수 있다는 가능성을 제시했다. 수많은 파라미터를 학습하는 대신, 데이터베이스에서 직접 지식을 ’검색하고 전송’하는 방식을 통해 복잡한 장면 이해 문제를 해결함으로써, 데이터의 역할을 보조재에서 핵심 동력으로 격상시켰다.2</p>
<p>마지막으로, Jia Deng과 Li Fei-Fei의 ImageNet은 이러한 데이터 중심 접근법들이 필요로 하는 필수적인 ’연료’이자 ’인프라’를 제공했다. 이는 미래의 데이터-탐욕적(data-hungry) 모델, 즉 딥러닝의 등장을 위한 무대를 마련하는 결정적인 단계였다.16</p>
<p>결론적으로, 이 세 연구는 독립적으로 진행되었음에도 불구하고, 결과적으로는 ‘데이터 기반 통찰’, ‘데이터 기반 모델’, ’데이터 인프라’라는 세 가지 측면을 각각 대표하며 컴퓨터 비전의 새로운 시대를 여는 서곡을 함께 연주했다. 아래 표는 이 세 가지 핵심 연구의 기여를 요약한 것이다.</p>
<p>Table 1: CVPR 2009 주요 논문 요약</p>
<table><thead><tr><th>논문명 (Paper Title)</th><th>핵심 문제 (Core Problem)</th><th>핵심 아이디어 및 방법론 (Key Idea &amp; Methodology)</th><th>학문적 의의 및 영향 (Academic Significance &amp; Impact)</th></tr></thead><tbody>
<tr><td><strong>Single Image Haze Removal Using Dark Channel Prior</strong></td><td>단일 이미지 안개 제거</td><td>물리 모델의 한계를 극복하기 위해 ’어두운 채널 사전 확률(Dark Channel Prior)’이라는 자연 영상의 통계적 특성을 발견하고 이를 활용함.</td><td><strong>데이터 기반 통찰 (Data-driven Insight):</strong> 데이터에서 발견한 통계적 규칙으로 기존 모델을 보완하고 완성할 수 있음을 증명함. 데이터가 강력한 ‘보조재’ 역할을 함.</td></tr>
<tr><td><strong>Nonparametric Scene Parsing: Label Transfer via Dense Scene Alignment</strong></td><td>장면 이해 (Scene Parsing) / 의미론적 분할 (Semantic Segmentation)</td><td>대규모 데이터베이스에서 유사 이미지를 검색하고, SIFT Flow를 이용한 ’밀집 장면 정렬’을 통해 픽셀 단위로 레이블을 전송하는 비모수적(nonparametric) 접근법을 제안함.</td><td><strong>데이터 기반 모델 (Data-driven Model):</strong> 데이터베이스 자체가 정교한 모델이 될 수 있음을 제시함. 패러다임을 ’모델 중심’에서 ’데이터 중심’으로 전환시켰다.</td></tr>
<tr><td><strong>ImageNet: A Large-Scale Hierarchical Image Database</strong></td><td>컴퓨터 비전 연구의 데이터 부족 문제 (Data Scarcity)</td><td>WordNet과 연동하여 의미론적 계층 구조를 갖추고, 크라우드소싱을 통해 수백만 장의 이미지를 수집 및 정제하여 전례 없는 규모의 데이터셋을 구축함.</td><td><strong>데이터 인프라 (Data Infrastructure):</strong> 딥러닝과 같은 데이터-탐욕적(data-hungry) 모델의 등장을 위한 필수 ’연료’와 ’인프라’를 제공함. 딥러닝 혁명의 기폭제가 됨.</td></tr>
</tbody></table>
<h2>3.  로봇 공학의 기반 구축 - ICRA 2009</h2>
<p>ICRA 2009는 로봇 공학 연구가 개별적인 하드웨어 제작이나 특정 알고리즘 개발을 넘어, 연구 개발의 효율성과 재사용성을 극대화하는 ’플랫폼’과 ’표준화’에 대한 논의를 본격화한 중요한 전환점이었다. 이 시기에는 특히 오픈소스 소프트웨어 프레임워크의 등장이 두드러졌으며, 이는 전 세계 로봇 공학 커뮤니티의 협업 방식을 근본적으로 바꾸는 계기가 되었다. 동시에, 고가의 센서에 의존하지 않고 저비용의 상용 센서를 창의적으로 활용하여 로봇의 핵심 기능(예: 위치 인식, 지도 작성)을 구현하려는 노력 또한 활발하게 이루어졌다. 이러한 흐름은 로봇 공학의 진입 장벽을 낮추고 대중화를 가속화하는 데 결정적인 역할을 했다.20</p>
<h3>3.1  표준화와 협업의 시작: 로봇 운영체제(ROS)의 등장</h3>
<p>ROS(Robot Operating System)가 등장하기 이전, 로봇 소프트웨어 개발 환경은 극심한 파편화 상태에 있었다. 각 연구실이나 기업은 저마다 독자적인 통신 미들웨어와 소프트웨어 아키텍처를 개발하여 사용했다. 이는 하드웨어 드라이버, 제어 알고리즘, 고수준 인지 모듈 등 소프트웨어 구성 요소의 재사용을 거의 불가능하게 만들었으며, 연구자들은 새로운 로봇 프로젝트를 시작할 때마다 바퀴를 재발명하는 비효율을 감수해야 했다. 이러한 환경은 로봇 공학 커뮤니티 전체의 발전을 저해하는 심각한 병목 현상이었다.22</p>
<h4>3.1.1 ROS의 아키텍처와 설계 철학</h4>
<p>이러한 문제를 해결하기 위해 스탠퍼드 대학과 윌로우 개러지(Willow Garage)에서 개발하여 ICRA 2009 워크숍에서 공식적으로 발표한 ROS는 로봇 소프트웨어 개발의 새로운 표준을 제시했다. ROS는 전통적인 의미의 운영체제(예: Linux, Windows)가 아니라, 이기종 운영체제 위에서 동작하는 다양한 로봇 응용 프로그램(프로세스)들이 서로 원활하게 통신할 수 있도록 지원하는 미들웨어 프레임워크이다.21</p>
<p>ROS의 아키텍처는 다음과 같은 핵심 개념들을 기반으로 한다.</p>
<ul>
<li><strong>마스터 (Master):</strong> ROS 시스템 전체의 네임서버 역할을 하는 핵심 프로세스(roscore). 각 노드가 자신을 등록하고, 다른 노드의 정보를 조회할 수 있도록 하여 P2P 통신을 중개한다.</li>
<li><strong>노드 (Node):</strong> 계산을 수행하는 최소 단위의 실행 가능한 프로세스이다. 예를 들어, 카메라 드라이버, 모터 제어기, 경로 계획 알고리즘 등은 각각 독립된 노드로 실행된다. 이러한 세분화된 모듈성은 시스템의 안정성과 유지보수성을 높인다.</li>
<li><strong>메시지 (Message)와 토픽 (Topic):</strong> 노드 간의 비동기식 데이터 통신은 ‘발행-구독(publish-subscribe)’ 모델을 통해 이루어진다. 데이터(메시지)를 보내는 노드는 특정 이름의 채널(토픽)에 데이터를 발행하고, 데이터를 필요로 하는 노드는 해당 토픽을 구독한다. 이 방식은 노드 간의 의존성을 제거하여 유연하고 확장 가능한 시스템을 구축하게 한다.</li>
<li><strong>서비스 (Service):</strong> 동기식 양방향 통신이 필요한 경우(예: 특정 계산을 요청하고 그 결과를 받아야 할 때)를 위해 서비스 모델을 제공한다. 이는 원격 프로시저 호출(RPC)과 유사하게 동작한다.</li>
</ul>
<p>이러한 아키텍처는 다음과 같은 명확한 설계 철학에 의해 뒷받침된다.22</p>
<ul>
<li><strong>P2P 통신:</strong> 마스터는 노드 간의 초기 연결 설정에만 관여하며, 실제 데이터는 노드 간에 직접(P2P) 전송된다. 이는 중앙 서버의 병목 현상을 방지하고 시스템 전체의 통신 효율을 높인다.</li>
<li><strong>언어 중립성:</strong> C++, Python, LISP 등 다양한 프로그래밍 언어를 지원하여, 개발자가 각 작업에 가장 적합한 언어를 선택할 수 있는 유연성을 제공한다.</li>
<li><strong>경량성 (Thin):</strong> ROS 자체는 통신 기능에 집중하고, 복잡한 알고리즘이나 드라이버는 ROS에 의존하지 않는 독립적인 라이브러리로 개발하도록 권장한다. 이는 코드의 재사용성과 이식성을 극대화한다.</li>
<li><strong>오픈소스:</strong> BSD 라이선스를 채택하여 학술 연구뿐만 아니라 상업적 활용에도 제약이 없도록 했다. 이는 광범위한 개발자 커뮤니티의 참여를 유도하는 결정적인 요인이었다.</li>
</ul>
<p>Table 2: ROS 핵심 아키텍처 구성 요소</p>
<table><thead><tr><th><strong>구성 요소</strong></th><th><strong>주요 기능 및 설명</strong></th></tr></thead><tbody>
<tr><td><strong>마스터 (Master)</strong></td><td>노드 정보 등록 및 조회를 통해 노드 간 통신을 중개하는 네임서버 (roscore)</td></tr>
<tr><td><strong>노드 (Node)</strong></td><td>계산을 수행하는 최소 단위의 실행 가능한 프로세스 (예: 센서 드라이버, 제어 알고리즘)</td></tr>
<tr><td><strong>토픽 (Topic)</strong></td><td>‘발행-구독’ 모델에서 메시지가 전달되는 통로 역할을 하는 명명된 채널</td></tr>
<tr><td><strong>메시지 (Message)</strong></td><td>토픽을 통해 노드 간에 주고받는 구조화된 데이터</td></tr>
<tr><td><strong>서비스 (Service)</strong></td><td>요청과 응답이 한 쌍으로 이루어지는 동기식 양방향 통신 방식 (RPC와 유사)</td></tr>
</tbody></table>
<h4>3.1.2 영향 및 의의</h4>
<p>ICRA 2009에서의 발표를 기점으로 ROS는 로봇 공학 연구 및 개발의 사실상 표준(de facto standard)으로 빠르게 자리 잡았다. ROS의 등장은 전 세계 연구자들이 하드웨어 드라이버, 내비게이션 스택, 조작 알고리즘, 시뮬레이션 도구 등을 쉽게 공유하고 재사용할 수 있는 거대한 생태계를 탄생시켰다.21 이는 개별 연구의 수준을 넘어 커뮤니티 전체의 개발 속도를 비약적으로 향상시켰으며, 로봇 공학 분야의 진입 장벽을 크게 낮추는 데 기여했다.</p>
<h3>3.2  자율 이동 로봇의 핵심 기술: SLAM 연구 동향</h3>
<p>자율 이동 로봇이 미지의 환경을 탐색하기 위한 핵심 기술은 동시적 위치 추정 및 지도 작성(Simultaneous Localization and Mapping, SLAM)이다. ICRA 2009 당시 SLAM 연구는 확장 칼만 필터(EKF-SLAM)나 파티클 필터를 기반으로 한 확률론적 접근법이 주류를 이루고 있었다. 연구자들의 주된 관심사는 대규모 환경에서 계산 복잡도를 줄이고, 장기간 탐사 시 누적되는 오차를 어떻게 효과적으로 보정할 것인가에 있었다. 또한, 레이저 스캐너, 카메라, 관성 측정 장치(IMU) 등 다양한 센서 정보를 통합하여 SLAM의 강건성(robustness)을 높이려는 시도도 활발했다.20</p>
<h4>3.2.1 사례 연구 - “Range-only SLAM with a mobile robot and a Wireless Sensor Networks”</h4>
<p>이러한 연구 흐름 속에서, Emanuele Menegatti 연구팀의 논문은 SLAM의 접근성을 높이는 중요한 방향을 제시했다. 그들의 연구는 고가의 정밀 센서 대신, 저렴하고 널리 보급된 무선 센서 네트워크(WSN)를 SLAM에 활용하는 독창적인 아이디어에 기반한다.25</p>
<ul>
<li><strong>핵심 아이디어:</strong> 이 연구의 목표는 고가의 레이저 스캐너(LIDAR) 없이, 환경에 미리 설치된 WSN 노드들이 발신하는 무선 신호의 세기 지표(Received Signal Strength Indicator, RSSI)만을 이용하여 로봇의 위치를 추정하고 동시에 WSN 노드들의 위치를 지도로 작성하는 것이다. RSSI 값은 신호의 거리에 따라 감쇠하는 특성이 있으므로, 이를 거리 측정(range) 정보로 활용할 수 있다.</li>
<li><strong>기술적 도전과 해결책:</strong> 가장 큰 기술적 난관은 RSSI 신호가 다중 경로 페이딩(multipath fading)이나 장애물로 인해 매우 큰 노이즈를 포함하며 변동성이 극심하다는 점이다. 단일 측정값만으로는 신뢰할 수 있는 거리 정보를 얻기 어렵다. 연구팀은 이 문제를 해결하기 위해 두 가지 전략을 사용했다. 첫째, 로봇이 이동하면서 시간의 흐름에 따라 여러 노드로부터 수집한 불확실한 RSSI 측정값들을 통계적으로 통합하기 위해 확장 칼만 필터(EKF) 기반의 SLAM 알고리즘을 적용했다. EKF는 로봇의 움직임(오도메트리)과 RSSI 기반 거리 측정을 융합하여 로봇의 위치와 WSN 노드의 위치를 점진적으로 보정해나간다. 둘째, 수신된 RSSI 신호에 간단한 전처리 필터를 적용하여 급격한 변동을 완화하고 보다 안정적인 측정값을 필터에 입력하도록 했다.25</li>
<li><strong>의의:</strong> 실험 결과, WSN 노드의 초기 위치를 전혀 모르는 상태에서도 평균 1m 미만의 위치 추정 오차를 달성할 수 있음을 보여주었다. 이 연구는 고가의 센서 없이도 상대적으로 저렴한 인프라를 활용하여 로봇의 핵심 기능인 SLAM을 구현할 수 있다는 가능성을 입증했다. 이는 자원의 제약이 심한 환경이나 비용에 민감한 응용 분야에서 로봇 기술의 실용성을 높이는 중요한 방향을 제시했으며, ‘자원의 제약’ 속에서 실용적인 해법을 찾으려는 당시 로봇 공학계의 중요한 연구 흐름을 잘 보여준다.27</li>
</ul>
<h3>3.3 제2부 종합 분석</h3>
<p>ICRA 2009에서 나타난 두 가지 주요 흐름, 즉 ROS의 등장과 저비용 센서를 활용한 SLAM 연구는 로봇 공학의 ’민주화(democratization)’를 위한 두 개의 핵심적인 축을 형성했다. 이 두 흐름은 표면적으로는 무관해 보이지만, 실제로는 로봇 공학의 발전을 가속화하는 데 있어 강력한 시너지를 창출했다.</p>
<p>첫째, ROS는 ’소프트웨어의 민주화’를 이끌었다. 오픈소스 표준 플랫폼을 제공함으로써, 연구자들은 더 이상 값비싼 독점 소프트웨어를 구매하거나 각자의 프로젝트마다 통신 프레임워크를 밑바닥부터 개발하는 수고를 할 필요가 없어졌다. 이는 소프트웨어 개발의 장벽을 극적으로 낮추었고, 누구나 복잡한 로봇 시스템을 보다 쉽게 구축하고 실험할 수 있는 길을 열었다.22</p>
<p>둘째, Range-only SLAM과 같은 연구는 ’하드웨어의 민주화’를 향한 중요한 발걸음이었다. 고가의 LiDAR 센서는 당시 로봇 연구의 비용을 증가시키는 주된 요인 중 하나였다. 저렴한 WSN 노드나 일반 카메라와 같은 상용 센서를 사용하여 로봇의 핵심 기능을 구현하려는 시도는 하드웨어 비용의 장벽을 낮추어, 더 많은 연구 그룹과 개발자들이 로봇 공학 분야에 진입할 수 있도록 만들었다.25</p>
<p>이 두 가지 흐름은 서로를 강화하는 관계에 있다. 저렴한 하드웨어로 로봇을 제작하더라도, 그것을 구동할 안정적이고 기능이 풍부한 소프트웨어가 없다면 무용지물이다. 반대로, 아무리 강력한 소프트웨어 플랫폼이 존재하더라도, 이를 실행할 하드웨어가 너무 비싸다면 소수의 부유한 연구 그룹만이 혜택을 누릴 수 있다. ICRA 2009에서는 바로 이 두 가지 필수적인 요소가 동시에 제시되었다. ROS가 소프트웨어의 장벽을 허물고, 저비용 센서 연구가 하드웨어의 장벽을 낮춤으로써, 이후 10년간 로봇 커뮤니티가 폭발적으로 성장하고 혁신을 가속화할 수 있는 근본적인 토대가 마련되었다.</p>
<h2>4.  자율 에이전트와 다중 에이전트 시스템 - AAMAS 2009</h2>
<p>AAMAS 2009는 개별 에이전트의 합리적인 의사결정 모델을 넘어, 다수의 자율적인 에이전트가 상호작용하며 형성하는 ’사회’의 복잡한 동역학을 이해하고 설계하려는 시도가 두드러진 학회였다. 이 시기의 연구들은 경제학, 게임 이론, 사회과학 등 인접 학문의 이론적 도구들을 적극적으로 도입하여 다중 에이전트 시스템(Multi-Agent System, MAS)을 보다 엄밀한 수학적 틀 안에서 분석하려는 경향을 보였다. 이는 MAS 분야의 이론적 깊이를 더하고, 보다 예측 가능하고 안정적인 인공 사회를 설계하기 위한 중요한 지적 기반을 마련하는 과정이었다.28</p>
<h3>4.1  에이전트 사회의 질서와 영향력: 규범 시스템 내에서의 권력 분석 (Power in Normative Systems)</h3>
<p>다수의 자율적인 에이전트가 공존하는 시스템에서 질서를 유지하고 공동의 목표를 달성하기 위해서는 개별 에이전트의 행동을 조율할 메커니즘이 필요하다. 이를 위해 널리 연구되는 개념이 바로 ‘규범(norms)’ 또는 ’사회적 법칙(social laws)’이다. 규범은 에이전트가 특정 상황에서 어떤 행동을 해야 하거나(의무), 해서는 안 되는지(금지)를 명시하는 규칙의 집합이다. 그러나 단순히 규칙을 만드는 것만으로는 충분하지 않다. 잘 설계되지 않은 규범 시스템은 특정 에이전트에게 과도한 영향력을 집중시켜 시스템 전체를 불안정하게 만들거나, 예상치 못한 부작용을 낳을 수 있다.29</p>
<h4>4.1.1 연구의 배경 및 목표</h4>
<p>Thomas Ågotnes 연구팀의 논문 “Power in Normative Systems“는 바로 이 문제에 주목했다. 이 연구의 핵심 목표는 특정 규범 시스템 하에서 각 에이전트가 시스템 전체의 결과에 미치는 영향력, 즉 ’권력(power)’을 어떻게 정량적으로 측정하고 분석할 수 있는지에 대한 방법론을 제시하는 것이었다. 연구팀은 이러한 분석을 통해 시스템의 잠재적인 병목 현상이나 단일 실패 지점(single points of failure)을 사전에 식별하고, 권력이 보다 균등하게 분배된 안정적이고 견고한 규범 시스템을 설계하고자 했다.29</p>
<h4>4.1.2 핵심 방법론 - 투표 이론의 접목</h4>
<p>이 연구의 가장 독창적인 기여는 정치학 및 게임 이론의 한 분야인 투표 이론(voting theory)에서 발전된 개념을 MAS 분석에 도입한 것이다. 구체적으로, 그들은 유권자의 영향력을 측정하기 위해 고안된 ‘권력 지수(power indices)’, 특히 라이오넬 펜로즈와 존 반자프에 의해 제안된 ’반자프 지수(Banzhaf index)’를 규범 시스템 분석의 핵심 도구로 활용했다.29</p>
<ul>
<li><strong>반자프 지수를 이용한 권력 측정:</strong> 반자프 지수의 기본 아이디어는 어떤 참여자가 연합의 승패를 결정짓는 ‘결정적인(pivotal)’ 투표를 얼마나 자주 행사하는지를 측정하는 것이다. 연구팀은 이 아이디어를 규범 시스템에 다음과 같이 적용했다. 시스템의 목표 달성 여부가 ‘성공’ 또는 ’실패’로 결정된다고 가정하자. 이때, 한 에이전트가 특정 규범을 준수할지 위반할지를 선택하는 것을 투표 행위로 간주할 수 있다. 만약 어떤 에이전트의 선택(규범 준수 vs. 위반)이 다른 모든 에이전트의 선택이 고정된 상태에서 시스템 전체의 결과를 ’실패’에서 ’성공’으로, 또는 ’성공’에서 ’실패’로 바꿀 수 있다면, 그 에이전트는 해당 상황에서 ’결정적’인 역할을 한 것이다. 한 에이전트의 반자프 권력 지수는 이러한 결정적인 상황의 총 수를 기반으로 계산된다. 이 지수가 높을수록 해당 에이전트는 시스템 전체에 더 큰 영향력을 행사하는 것으로 해석할 수 있다.</li>
</ul>
<h4>4.1.3 주요 결과 - 계산 복잡도 분석</h4>
<p>연구팀은 이 방법론의 이론적 특성을 규명하기 위해 권력 지수를 계산하는 문제의 계산 복잡도(computational complexity)를 분석했다.</p>
<ul>
<li><strong>#P-complete 증명:</strong> 그들은 일반적인 규범 시스템에서 반자프 지수를 정확하게 계산하는 문제가 ’#P-complete(샵-P 완전)’라는 것을 수학적으로 증명했다.29 #P는 경우의 수를 세는 계수 문제(counting problem)의 복잡도 종류이며, #P-complete는 #P에 속하는 문제 중 가장 어려운 문제들의 집합을 의미한다. 이는 NP-complete보다도 훨씬 더 어려운 문제로, 사실상 다항 시간 내에 정확한 해를 구하는 효율적인 알고리즘이 존재하지 않음을 시사한다. 이 결과는 규범 시스템 내의 권력 분석이 이론적으로 매우 어려운 문제임을 보여주는 중요한 이론적 성과이다.</li>
<li>** tractable sub-cases 탐색:** 동시에 연구팀은 문제의 실용성을 포기하지 않았다. 그들은 규범 시스템의 구조에 특정 제약을 가할 경우, 권력 지수를 다항 시간 내에 효율적으로 계산할 수 있는 특별한 경우들이 존재함을 보였다.29 이는 복잡한 이론적 문제를 실제 시스템 설계에 적용할 수 있는 길을 열어준 중요한 분석이다.</li>
</ul>
<h4>4.1.4 학문적 의의</h4>
<p>AAMAS 2009 최우수 논문상(Best Paper Award)을 수상한 이 연구는 29, 사회과학의 추상적인 개념인 ’권력’을 다중 에이전트 시스템이라는 공학적 대상에 성공적으로 접목하여 정량적으로 분석할 수 있는 새로운 이론적 도구를 제공했다는 점에서 높은 평가를 받았다. 이 연구는 에이전트 시스템 설계를 단순히 ’개별 에이전트의 규칙을 나열하는 것’에서, 규칙들이 상호작용하여 만들어내는 ’시스템 수준의 거시적 속성(예: 영향력의 분배)을 설계하는 것’으로 관점을 한 단계 끌어올렸다. 이는 보다 예측 가능하고, 안정적이며, 의도한 대로 동작하는 인공 사회를 구축하기 위한 중요한 이론적 기여였다.32</p>
<h3>4.2 제3부 종합 분석</h3>
<p>AAMAS 2009에서 발표된 “Power in Normative Systems“는 당시의 다중 에이전트 시스템 연구의 지평을 넓힌 수작일 뿐만 아니라, 10여 년이 지난 현재의 관점에서 재조명할 때 더욱 깊은 의미를 갖는다. 이 연구의 근본적인 문제의식과 접근법은 현대 AI 안전성(AI Safety) 및 AI 정렬(AI Alignment) 연구가 다루는 핵심적인 질문들과 철학적으로 깊이 연결되어 있기 때문이다.</p>
<p>현대 AI 안전성 연구의 핵심 질문 중 하나는 “우리가 설계한 규칙 체계(예: 강화학습의 보상 함수)가 개발자의 의도와는 다른, 예상치 못한 부정적인 결과를 낳지 않을 것이라고 어떻게 보장할 수 있는가?“이다. 이는 고도로 복잡한 시스템에서 국소적인 규칙(local rules)이 어떻게 예측 불가능한 거시적 행동(emergent behavior)으로 이어지는지에 대한 근본적인 탐구이다.</p>
<p>“Power in Normative Systems” 연구는 이 거대한 질문을 “우리가 설계한 규범 시스템이 특정 에이전트에게 과도한 영향력을 부여함으로써 시스템 전체를 취약하게 만들거나, 공정성을 해치지는 않는가?“라는 구체적이고 분석 가능한 형태로 제시했다.29 여기서 ’권력’을 정량화하고 그 분배 구조를 수학적으로 분석하는 것은, 설계된 시스템의 잠재적 취약점과 의도치 않은 결과를 사전에 형식적(formal)으로 검증하려는 시도이다. 이는 인공적으로 만들어진 규칙(규범) 하에서 자율적인 에이전트들의 상호작용이 만들어내는 시스템 수준의 거시적 속성(권력 분배)을 예측하고 제어하려는 노력이다.</p>
<p>비록 사용된 용어와 기술적 맥락은 다르지만, 이 연구의 근본적인 목표—인공적인 규칙 체계가 바람직하고 안정적인 시스템 수준의 속성을 갖도록 보장하는 것—는 오늘날 AI 정렬 연구가 추구하는 핵심 목표와 정확히 일치한다. AI 정렬은 강력한 AI 시스템이 인간의 가치 및 의도와 일치하도록 행동하게 만드는 것을 목표로 하며, 이를 위해서는 AI의 행동을 지배하는 내부 규칙(또는 학습 목표)이 시스템 전체 수준에서 바람직한 결과로 이어질 것임을 보장해야 한다. 따라서 AAMAS 2009의 이 연구는, AI 시스템을 개별 지능 단위가 아닌 하나의 ’사회적 시스템’으로 간주하고, 그 시스템의 안정성과 견고성을 수학적으로 분석하려 했던 선구적인 시도로 재평가될 수 있다.</p>
<h2>5. 결론: 2009년의 유산과 미래 전망</h2>
<p>2009년 2분기에 컴퓨터 비전, 로봇 공학, 다중 에이전트 시스템 분야의 최고 학회들에서 발표된 주요 연구들은 각기 다른 영역에서 진행되었음에도 불구하고, 시대를 관통하는 몇 가지 거대한 흐름을 공통적으로 보여준다. 본 보고서는 이 흐름을 <strong>‘규모의 확장(Scaling)’, ‘추상화 수준의 향상(Abstraction)’, ‘접근성의 확대(Democratization)’</strong> 라는 세 가지 키워드로 요약하고자 한다. 이 세 가지 동력은 서로 맞물리며 이후 10년간 AI 기술의 폭발적인 성장을 이끌었고, 현재 우리가 경험하고 있는 AI 혁명의 근간을 이루었다.</p>
<p>첫째, <strong>규모의 확장</strong>은 2009년 연구들의 가장 두드러진 특징이다. CVPR에서 발표된 ImageNet은 데이터의 규모를 이전과 비교할 수 없는 수준으로 확장함으로써, 데이터-탐욕적인 딥러닝 모델이 잠재력을 발휘할 수 있는 토양을 마련했다.16 이는 단순히 양적인 팽창을 넘어, 컴퓨터 비전 연구의 패러다임을 모델 중심에서 데이터 중심으로 전환시키는 질적인 변화를 촉발했다. 한편, ICRA에서 등장한 ROS는 협업의 규모를 확장했다. 파편화된 개발 환경을 표준화된 오픈소스 플랫폼으로 통합함으로써, 전 세계 수많은 연구자와 개발자가 지식과 코드를 공유하며 거대한 로봇 시스템을 함께 구축할 수 있는 생태계를 창조했다.22</p>
<p>둘째, <strong>추상화 수준의 향상</strong>은 문제에 대한 더 깊은 이해를 추구하는 지적 성숙을 의미한다. CVPR의 ‘Dark Channel Prior’ 연구는 이미지 픽셀의 물리적 형성 과정과 대규모 자연 영상의 통계적 속성을 연결함으로써, 안개라는 복잡한 물리 현상에 대한 높은 수준의 추상적 이해를 모델에 통합했다.4 AAMAS의 ‘Power in Normative Systems’ 연구는 개별 에이전트의 행동 규칙을 넘어, 그 규칙들이 상호작용하여 만들어내는 ’권력’이라는 사회적 속성을 분석했다.29 이는 시스템을 더 높은 추상화 수준에서 이해하고 설계하려는 시도로, 현대 AI 안전성 연구의 철학적 선구자로 볼 수 있다.</p>
<p>셋째, <strong>접근성의 확대</strong>는 첨단 기술의 혜택을 더 넓은 커뮤니티로 확산시키려는 노력을 반영한다. ROS는 값비싼 독점 소프트웨어 없이도 누구나 복잡한 로봇을 개발할 수 있는 길을 열어 소프트웨어의 장벽을 허물었다.22 동시에, 저비용 WSN을 활용한 SLAM 연구는 고가의 센서 없이도 로봇의 핵심 기능을 구현할 수 있는 가능성을 보여주며 하드웨어의 비용 장벽을 낮추려는 노력을 대표했다.25 이러한 기술적, 비용적 장벽의 해체는 로봇 공학 연구의 저변을 넓히고 혁신의 속도를 가속화하는 결정적인 계기가 되었다.</p>
<p>2009년에 뿌려진 이 씨앗들은 2010년대 내내 무성하게 자라나 AI 기술의 풍경을 완전히 바꾸어 놓았다. ImageNet은 딥러닝 혁명을 촉발했고, 그 결과 탄생한 모델들은 이제 우리 삶의 모든 영역에 스며들고 있다. ROS는 학술 연구용 로봇을 넘어 자율주행차, 산업용 로봇, 심지어 화성 탐사 로버에 이르기까지 수많은 실제 로봇 시스템의 핵심 기반이 되었다. 데이터 중심의 사고방식, 오픈소스 협업 문화, 그리고 시스템의 안정성에 대한 깊은 고찰은 오늘날 AI 및 로봇 공학 연구의 표준으로 확고히 자리 잡았다.</p>
<p>결론적으로, 2009년 2분기는 단순한 과거의 한 시점이 아니다. 그것은 현재 우리가 서 있는 기술 지형을 형성하고 미래의 가능성을 잉태한, 명백한 역사적 변곡점이었다. 이 시기의 연구들을 깊이 이해하는 것은 현재 AI 기술의 근원을 파악하고, 다가올 미래의 기술적 변혁을 전망하는 데 있어 필수적인 지적 여정이라 할 수 있다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>What are the most interesting CVPR 2016 papers and why? - Quora, https://www.quora.com/What-are-the-most-interesting-CVPR-2016-papers-and-why</li>
<li>Paper Awards Session - CVPR 2009: IEEE Computer Society Conference on Computer Vision and Pattern Recognition, http://tab.computer.org/pamitc/archive/cvpr2009/paper-awards-session.html</li>
<li>Computer Vision Awards, https://www.thecvf.com/?page_id=413</li>
<li>Single Image Haze Removal Using Dark Channel Prior - Kaiming He, https://projectsweb.cs.washington.edu/research/insects/CVPR2009/award/hazeremv_drkchnl.pdf</li>
<li>Single Image Haze Removal Using Dark Channel Prior - MMLab, http://mmlab.ie.cuhk.edu.hk/2011/Haze.pdf</li>
<li>[PDF] Single image haze removal using dark channel prior - Semantic Scholar, https://www.semanticscholar.org/paper/Single-image-haze-removal-using-dark-channel-prior-He-Sun/5585ecdf5d39c9f0ae0f12f89fab426f92baed68</li>
<li>Single Image Haze Removal Using Dark Channel Prior - ResearchGate, https://www.researchgate.net/publication/46158497_Single_Image_Haze_Removal_Using_Dark_Channel_Prior</li>
<li>(PDF) Single image haze removal using dark channel prior (2009) | Kaiming He - SciSpace, https://scispace.com/papers/single-image-haze-removal-using-dark-channel-prior-3dtwr76de5?citations_page=46</li>
<li>Nonparametric Scene Parsing via Label Transfer - People | MIT CSAIL, https://people.csail.mit.edu/celiu/pdfs/LabelTransferTPAMI.pdf</li>
<li>Nonparametric scene parsing: Label transfer via dense scene alignment - Semantic Scholar, https://www.semanticscholar.org/paper/Nonparametric-scene-parsing%3A-Label-transfer-via-Liu-Yuen/ef2448cf2eae2bc2fc1d83f1da0fbaba188ecec7</li>
<li>Nonparametric Scene Parsing: Label Transfer via Dense Scene Alignment - People | MIT CSAIL, https://people.csail.mit.edu/torralba/publications/siftFlowCVPR.pdf</li>
<li>Scene Parsing With Integration of Parametric and Non-Parametric Models - Nanyang Technological University, https://www.ntu.edu.sg/docs/librariesprovider106/publications/video-analytics/scene-parsing-with-integration-of-parametric-and-non-parametric-models.pdf?sfvrsn=e2a8cd51_2</li>
<li>[PDF] ImageNet: A large-scale hierarchical image database - Semantic Scholar, https://www.semanticscholar.org/paper/ImageNet%3A-A-large-scale-hierarchical-image-database-Deng-Dong/d2c733e34d48784a37d717fe43d9e93277a8c53e</li>
<li>(PDF) ImageNet: a Large-Scale Hierarchical Image Database - ResearchGate, https://www.researchgate.net/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database</li>
<li>ImageNet, https://www.image-net.org/</li>
<li>ImageNet: A Large-Scale Hierarchical Image Database - Jia Deng …, https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf</li>
<li>Top 539 papers presented at Computer Vision and Pattern Recognition in 2009 - SciSpace, https://scispace.com/conferences/computer-vision-and-pattern-recognition-18ykss65/2009</li>
<li>Deng, J., Dong, W., Socher, R., et al. (2009) ImageNet A Large-Scale Hierarchical Image Database. 2009 IEEE Conference on Computer Vision and Pattern Recognition, Miami, 20-25 June 2009, 248-255. - References - Scirp.org., https://www.scirp.org/reference/referencespapers?referenceid=2975125</li>
<li>ImageNet: Constructing a large-scale image database - ResearchGate, https://www.researchgate.net/publication/245626699_ImageNet_Constructing_a_large-scale_image_database</li>
<li>2009 IEEE International Conference on Robotics and Automation …, https://researchr.org/publication/icra-2009</li>
<li>ROS: an open-source Robot Operating System - ResearchGate, https://www.researchgate.net/publication/233881999_ROS_an_open-source_Robot_Operating_System</li>
<li>ROS: an open-source Robot Operating System - Stanford AI Lab, http://ai.stanford.edu/~mquigley/papers/icra2009-ros.pdf</li>
<li>[PDF] ROS: an open-source Robot Operating System - Semantic Scholar, https://www.semanticscholar.org/paper/ROS%3A-an-open-source-Robot-Operating-System-Quigley/d45eaee8b2e047306329e5dbfc954e6dd318ca1e</li>
<li>IEEE International Conference on Robotics and Automation 2009 (5 papers + 2 presentations) - The Rawseeds Project, http://www.rawseeds.org/home/2009/10/12/ieee-international-conference-on-robotics-and-automation-2009-4-papers/</li>
<li>Range-only SLAM with a Mobile Robot and a Wireless Sensor Networks - dei.unipd, http://www.dei.unipd.it/~emg/PAPERS/emgICRA09-NEW.pdf</li>
<li>Range-only SLAM with a mobile robot and a Wireless Sensor Networks - ResearchGate, https://www.researchgate.net/publication/221070934_Range-only_SLAM_with_a_mobile_robot_and_a_Wireless_Sensor_Networks</li>
<li>(PDF) Range-only SLAM for robots operating cooperatively with sensor networks, https://www.researchgate.net/publication/224635142_Range-only_SLAM_for_robots_operating_cooperatively_with_sensor_networks</li>
<li>aamas awards 2009 - IFAAMAS, https://www.ifaamas.org/Proceedings/aamas09/Resources/AWARDS_2009.html</li>
<li>Latest News - Computer Science, https://www.csc.liv.ac.uk/~trp/Latest_News/Entries/2009/5/18_Liverpool_wins_AAMAS_Best_Paper_Award_for_2nd_Year_Running.html</li>
<li>A Norms as a Basis for Governing Sociotechnical Systems - computer science at N.C. State, https://www.csc2.ncsu.edu/faculty/mpsingh/papers/mas/TIST-13-governance.pdf</li>
<li>A Review of Norms and Normative Multiagent Systems - PMC - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC4119705/</li>
<li>Computational Models for Normative Multi-Agent Systems - DROPS - Schloss Dagstuhl, https://drops.dagstuhl.de/storage/02dagstuhl-follow-ups/dfu-vol004/DFU.Vol4.12111.71/DFU.Vol4.12111.71.pdf</li>
<li>A categorization of simulation works on norms - DROPS - Schloss Dagstuhl, https://drops.dagstuhl.de/storage/16dagstuhl-seminar-proceedings/dsp-vol09121/DagSemProc.09121.3/DagSemProc.09121.3.pdf</li>
<li>(PDF) Normative Multi-Agent Systems - ResearchGate, https://www.researchgate.net/publication/269574070_Normative_Multi-Agent_Systems</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>