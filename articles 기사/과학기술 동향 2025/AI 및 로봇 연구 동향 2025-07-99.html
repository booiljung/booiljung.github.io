<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2025년 7월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2025년 7월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2025년 AI 및 로봇 연구 동향</a> / <span>2025년 7월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2025년 7월 AI 및 로봇 연구 동향</h1>
<h2>1.  2025년 7월 AI 연구 지형도와 핵심 패러다임</h2>
<p>2025년 7월은 인공지능(AI) 연구 분야에서 중요한 분기점으로 기록된다. 이 시기는 기계학습(ML)과 자연어 처리(NLP) 분야의 양대 최고 학회인 International Conference on Machine Learning (ICML)과 Annual Meeting of the Association for Computational Linguistics (ACL)가 연이어 개최되면서, 전 세계 연구자들이 핵심적인 과학적, 기술적 성과를 집약적으로 발표하는 장이 되었다. 본 보고서는 이 두 학회에서 발표된 주요 연구들을 단순 요약하는 것을 넘어, 그 이면에 흐르는 심층적인 동향과 함의를 분석적으로 종합하는 것을 목표로 한다.</p>
<p>ICML 2025는 7월 13일부터 19일까지 캐나다 밴쿠버에서 개최되어 기계학습 분야 전문가들을 위한 최고의 학술 교류의 장으로서의 위상을 재확인했다.1 뒤이어 ACL 2025는 7월 27일부터 8월 1일까지 오스트리아 비엔나에서 열려 계산 언어학 및 자연어 처리 분야의 최신 연구 동향을 선도했다.5 두 학회의 시기적 근접성은 핵심 기계학습 커뮤니티와 자연어 처리 커뮤니티 간의 아이디어 상호 교류 및 융합을 관찰할 수 있는 독특한 기회를 제공한다.</p>
<p>이 기간 발표된 연구들은 AI 분야를 관통하는 세 가지 핵심 패러다임의 심화를 명확히 보여준다. 첫째, 단순히 경험적 확장에 의존하던 것에서 벗어나 파운데이션 모델의 내부 작동 원리를 엄밀하게 탐구하는 <strong>이론적 기반의 심화</strong>가 이루어졌다. 둘째, 거대 모델의 막대한 연산 비용 문제를 극복하기 위한 하드웨어 인지적 알고리즘 설계 등 <strong>효율성 및 통합 설계(Co-design)에 대한 요구</strong>가 절실해졌다. 마지막으로, AI 윤리에 대한 담론이 추상적 원칙을 넘어 상황 인지적 프레임워크로 구체화되는 <strong>사회-기술적 정렬(Socio-Technical Alignment)의 고도화</strong>가 중요한 흐름으로 자리 잡았다.</p>
<p>특히, ACL의 특별 주제인 “NLP 모델의 일반화(Generalization of NLP Models)” 5와 ICML에서 중점적으로 다뤄진 확산 모델, 최적화, 강화학습 등 핵심 기계학습 이론 7은 별개의 흐름이 아니라 동일한 문제의 양면을 보여준다. NLP의 일반화 문제는 근본적으로 기계학습의 문제이며, 이는 두 분야의 전통적인 경계가 허물어지고 있음을 시사한다. 즉, NLP 커뮤니티(ACL)가 제기한 문제들을 핵심 기계학습 커뮤니티(ICML)가 개발하고 정제한 근본적인 도구와 이론으로 해결하려는 시도가 2025년 7월의 연구 지형도를 형성하는 핵심 동력이라 할 수 있다.</p>
<table><thead><tr><th>컨퍼런스명</th><th>개최 기간</th><th>개최지</th><th>주요 연구 분야</th><th>특별 주제</th></tr></thead><tbody>
<tr><td><strong>ICML 2025</strong></td><td>2025년 7월 13일 – 19일</td><td>밴쿠버, 캐나다</td><td>기계학습, 인공지능, 통계, 데이터 과학, 로보틱스</td><td>특정 주제 없음 (확산 모델, 최적화 등 핵심 ML 원리 집중)</td></tr>
<tr><td><strong>ACL 2025</strong></td><td>2025년 7월 27일 – 8월 1일</td><td>비엔나, 오스트리아</td><td>계산 언어학, 자연어 처리</td><td>NLP 모델의 일반화 (Generalization of NLP Models)</td></tr>
</tbody></table>
<h2>2.  ICML 2025 심층 분석: 기계학습의 근본 원리 탐구와 응용의 확장</h2>
<h3>2.1  컨퍼런스 동향: 확산 모델, 최적화, 그리고 로보틱스의 최전선</h3>
<p>ICML 2025는 3,300편 이상의 논문이 채택되며 거대 언어 모델, 확산 모델, 로보틱스와 같은 최첨단 분야에 대한 높은 연구 집중도를 보였다.9 학회 논문 모집 공고에서부터 딥러닝, 생성 모델, 최적화, 강화학습, 로보틱스 응용 분야가 핵심 주제로 명시되었으며 7, 채택된 논문들은 이러한 경향을 뚜렷하게 반영했다.2</p>
<p>주요 동향은 확산 모델의 성숙화로 요약할 수 있다. 단순히 모델의 성능을 과시하는 단계를 넘어, 조합성(compositionality)이나 토큰 순서 결정과 같은 내부 메커니즘에 대한 깊이 있는 이론적 분석이 주를 이루었다.11 또한, 로보틱스 분야로의 응용이 확장되어, SE(3)-등변 확산 정책(SE(3)-Equivariant diffusion policy)과 같은 연구는 물리적 세계와의 상호작용을 위한 모델의 기하학적 이해를 한 단계 끌어올렸다.2 이와 동시에, 기존 모델의 규모를 키우는 것만으로는 불충분하다는 인식 하에, 보다 근본적인 알고리즘 개선을 위한 최적화 이론 연구가 다시금 주목받았다. 이는 AI 분야가 양적 팽창을 넘어 질적 심화의 단계로 진입하고 있음을 시사한다.</p>
<h3>2.2  최우수 논문 분석: 기술적 난제 해결과 사회적 가치 창출</h3>
<p>ICML 2025 최우수 논문(Outstanding Paper Award) 수상작들은 현대 기계학습 커뮤니티가 가장 중요하게 여기는 가치가 무엇인지를 명확히 보여준다. 수상작들은 각각 근본 이론, 알고리즘 혁신, 사회적 영향이라는 세 가지 측면에서 최고의 성취를 대변하며, AI 연구의 다각적인 발전 방향을 제시한다.</p>
<table><thead><tr><th>논문 제목</th><th>저자</th><th>핵심 기여</th></tr></thead><tbody>
<tr><td><em>Score Matching with Missing Data</em></td><td>Givens, Liu, and Reeve</td><td>불완전한 데이터 환경에서 스코어 기반 생성 모델을 학습할 수 있는 ‘마지널 스코어 매칭’ 방법론 제시</td></tr>
<tr><td><em>Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions</em></td><td>Kim, Shah, et al.</td><td>마스크드 확산 모델의 추론 시 토큰 생성 순서를 동적으로 결정하는 전략을 통해 성능을 극대화하는 방법론 제시</td></tr>
<tr><td><em>The Value of Prediction in Identifying the Worst-Off</em></td><td>Fischer Abaigar, Kern, and Perdomo</td><td>공공 정책에서 예측 모델의 정확도 향상과 행정 역량 확대 간의 사회적 효용을 정량적으로 분석하는 프레임워크 제시</td></tr>
</tbody></table>
<h4>2.2.1  Score Matching with Missing Data: 불완전 데이터 환경에서의 생성 모델링 패러다임 재정의</h4>
<p>본 연구는 현실 세계의 데이터가 종종 불완전하거나 손상되어 있다는 근본적인 문제에 주목한다.12 확산 모델의 이론적 기반이 되는 스코어 매칭(Score Matching)은 완전한 데이터가 주어졌을 때 데이터 분포의 로그 확률 밀도 함수의 그래디언트, 즉 스코어 함수(<span class="math math-inline">\nabla_x \log p(x)</span>)를 학습하는 기법이다. 그러나 기존 방식은 데이터 일부가 누락된 경우 적용하기 어려웠다.13</p>
<p>이 논문은 ’마지널 스코어 매칭(marginal score matching)’이라는 혁신적인 개념을 제안하여 이 한계를 극복한다.12 이는 누락된 데이터를 주변화(marginalize out)하거나 적극적으로 대체(impute)하여 관측된 데이터만으로도 전체 데이터의 스코어 함수를 효과적으로 학습하도록 목적 함수를 재설계한 것이다.15 구체적으로, 저차원 데이터에 강점을 보이는 중요도 가중(Importance Weighting, IW) 방식과 고차원 데이터에 효과적인 변분(variational) 방식을 함께 제안하여 문제의 특성에 따라 유연하게 적용할 수 있도록 했다.14</p>
<p>이 연구의 의의는 스코어 기반 생성 모델 이론과 실제 응용 사이의 간극을 메웠다는 데 있다. 노이즈가 낀 이미지나 손상된 유전체 데이터와 같이 불완전한 데이터가 만연한 현실 문제에 확산 모델을 직접 적용할 수 있는 견고한 이론적 토대를 마련한 것이다.12</p>
<h4>2.2.2  Train for the Worst, Plan for the Best: 마스크드 확산 모델의 동적 추론 전략과 잠재력 극대화</h4>
<p>이 연구는 순차적으로 토큰을 생성하는 자기회귀 모델(Autoregressive Models, ARM)과 임의의 위치의 토큰을 예측하는 마스크드 확산 모델(Masked Diffusion Models, MDM)의 장단점을 심도 있게 분석했다.17 MDM은 학습 과정에서 임의의 마스크를 채워야 하므로 ARM보다 훨씬 복잡하고 어려운 문제를 풀어야 한다. 논문은 MDM의 학습 손실 함수가 사실상 가능한 모든 순열 <span class="math math-inline">\pi</span>에 대한 자기회귀 손실의 평균과 같다는 것을 수학적으로 보였다.<br />
<span class="math math-display">
\mathcal{L}_{\pi}(\theta) = -\mathbb{E}_{x_0 \sim p_{\text{data}}} \left[ \sum_{i=0}^{L-1} \log p_{\theta}(x_0^{\pi(i)} \vert x_0^{\{\pi(j)\}_{j&gt;i}}) \right]
</span><br />
이러한 복잡한 학습 과정이 오히려 모델의 강건성(robustness)을 높이는 특징이 된다. 본 연구의 핵심은 MDM이 추론 시 어떤 순서로든 토큰을 생성할 수 있다는 유연성을 극대화하는 ’적응형 추론 전략’을 제안한 것이다.19 모델이 가장 확신을 가지는 토큰부터 순차적으로 예측하도록 유도함으로써, 학습 과정에서 어려움을 겪었던 문제들을 회피하고 쉬운 경로를 통해 정답을 찾아가게 만든다. 이 간단한 전략을 통해 스도쿠 퍼즐 풀이 정확도를 7% 미만에서 약 90%까지 극적으로 향상시켰다.17</p>
<p>이 연구는 추론 과정이 고정된 절차가 아니라 전략적인 탐색 과정이 될 수 있음을 보여주었다. 이는 정해진 순서가 없는 복잡한 추론 문제 해결에 있어 ARM의 한계를 뛰어넘는 새로운 가능성을 제시한다.20</p>
<h4>2.2.3  The Value of Prediction in Identifying the Worst-Off: 공공 정책에서의 예측 모델링의 사회적 효용성 재고찰</h4>
<p>본 연구는 공공 정책 분야에서 AI를 활용할 때, 모델의 예측 정확도를 높이는 것만이 항상 최선은 아니라는 도발적인 질문을 던진다.21 사회적 취약 계층을 식별하고 지원하는 문제에서, 한정된 자원을 ’더 정확한 예측 모델 개발’에 투입할 것인지, 아니면 ’더 많은 사람을 심사하는 행정 역량 확대’에 투입할 것인지의 트레이드오프를 분석한다.23</p>
<p>연구의 핵심은 **예측-접근 비율(Prediction-Access Ratio, PAR)**이라는 새로운 지표다. 이는 행정 역량(접근성) 확대의 한계 효용을 예측 정확도 개선의 한계 효용으로 나눈 값으로, 다음과 같이 정의된다.25<br />
<span class="math math-display">
\text{PAR} = \frac{\text{Marginal Value of Expanding Access}}{\text{Marginal Value of Better Prediction}}
</span><br />
논문의 핵심 발견은 예측 정확도 개선이 ’첫 마일과 마지막 마일(first and last-mile)’에서 가장 가치가 크다는 것이다. 즉, 예측 모델이 거의 무작위 수준으로 부정확하거나 거의 완벽에 가까울 때 정확도 개선의 효과가 극대화된다. 반면, 대부분의 시스템이 위치한 중간 수준의 정확도 구간에서는 더 많은 사람을 심사하도록 행정 역량을 확대하는 것이 사회 전체의 효용을 높이는 데 더 효과적이다.23 이때 시스템의 가치는 <span class="math math-inline">V(\alpha, f; \beta) = \text{Pr}_D</span>로 정의되며, <span class="math math-inline">\alpha</span>는 심사 예산, <span class="math math-inline">\beta</span>는 실제 취약 계층 비율을 의미한다.</p>
<p>이 연구는 AI의 사회적 책무에 대한 논의를 한 단계 격상시켰다. 기술적 성능 지표에 매몰되지 않고, 시스템 전체의 효과성과 공정성이라는 사회-기술적 관점에서 자원 배분의 원칙을 제시하는 정량적 프레임워크를 제공했다는 점에서 큰 의의를 가진다.24</p>
<h3>2.3  주요 연구 분야별 핵심 발표</h3>
<p>최우수 논문 외에도 ICML 2025에서는 파운데이션 모델의 미래를 조망할 수 있는 다양한 연구가 발표되었다.</p>
<ul>
<li><strong>차세대 파운데이션 모델 아키텍처:</strong> 기존의 트랜스포머 구조를 넘어 특정 데이터 유형에 최적화된 모델들이 다수 제안되었다. 관계형 데이터베이스를 위한 그래프 중심 파운데이션 모델(“Griffin”) 2, 시계열 예측의 효율성을 높이는 웨이블릿 기반 토큰화 기법 2, 그리고 고품질 이미지 생성에서 확산 모델에 필적하는 성능을 보인 정규화 흐름(Normalizing Flows) 기반의 “TarFlow” 아키텍처 11 등이 대표적이다. 이는 범용 모델의 시대를 지나, 각 데이터의 고유한 특성(inductive bias)을 반영한 특화된 파운데이션 모델 생태계가 부상하고 있음을 보여준다.</li>
<li><strong>로봇공학 및 물리적 상호작용을 위한 강화학습:</strong> 로봇 조작을 위한 정책 학습 연구가 한층 더 정교해졌다. 특히 “구면 푸리에 공간에서의 SE(3)-등변 확산 정책” 2 연구는 3차원 공간에서의 회전과 이동을 일관성 있게 처리하는 등변성(equivariance)을 모델에 내재하여 물리적 상호작용의 정확성과 안정성을 크게 향상시켰다. 이는 딥러닝에 기하학적 원리를 깊이 통합하려는 연구 흐름을 보여주는 중요한 사례다.</li>
</ul>
<h2>3.  ACL 2025 심층 분석: 거대 언어 모델의 내재적 특성과 한계 규명</h2>
<h3>3.1  컨퍼런스 동향: 모델 일반화와 다문화 세계 속의 NLP</h3>
<p>ACL 2025의 특별 주제는 “NLP 모델의 일반화“였으며 5, 자매 학회인 NAACL 2025의 주제는 “다문화 세계 속의 NLP“였다.27 이는 NLP 커뮤니티의 관심사가 ’더 큰 모델’을 만드는 것에서 벗어나, 이미 만들어진 거대 모델들이 학습 데이터 분포를 벗어난 환경에서 얼마나 강건하고 신뢰성 있게 작동하는지, 그리고 다양한 문화적 맥락을 얼마나 잘 이해하고 존중하는지를 평가하고 개선하는 방향으로 이동하고 있음을 명확히 보여준다. 즉, NLP 분야는 양적 팽창 이후 나타나는 2차적 문제들(일반화, 편향, 실패 모드)을 해결하기 위한 자기 성찰과 엄밀한 평가의 시기에 접어들었다.</p>
<h3>3.2  최우수 논문 분석: 얼라인먼트, 공정성, 효율성에 대한 근본적 통찰</h3>
<p>ACL 2025 최우수 논문(Best Paper)들은 거대 언어 모델이 직면한 가장 시급하고 근본적인 네 가지 문제—얼라인먼트의 한계, 공정성의 재정의, 연산 효율성, 그리고 인지적 편향—에 대한 깊이 있는 통찰을 제공한다. 이 연구들은 개별적인 성과를 넘어, LLM의 현주소와 미래 과제를 종합적으로 조망하는 이정표 역할을 한다.</p>
<table><thead><tr><th>논문 제목</th><th>저자</th><th>핵심 기여</th></tr></thead><tbody>
<tr><td><em>Language Models Resist Alignment: Evidence From Data Compression</em></td><td>Ji, Wang, et al.</td><td>데이터 압축 이론을 통해 LLM이 사전학습 분포로 회귀하려는 내재적 ’탄성’을 가지며, 이로 인해 얼라인먼트에 저항함을 규명</td></tr>
<tr><td><em>Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs</em></td><td>Wang, Phan, et al.</td><td>기존의 ‘차이 무시’ 공정성 패러다임을 비판하고, 상황에 맞는 ’차이 인지’가 진정한 공정성에 필수적임을 주장하며 새로운 평가 지표 제시</td></tr>
<tr><td><em>Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</em></td><td>Yuan, Gao, et al.</td><td>하드웨어 구조에 최적화된 네이티브 희소 어텐션(NSA)을 제안하여, 장문 맥락 처리의 속도를 획기적으로 개선하고 실용성을 확보</td></tr>
<tr><td><em>A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive</em></td><td>Sivaprasad, Kaushik, et al.</td><td>LLM의 응답 생성이 데이터의 통계적 분포(기술적)뿐만 아니라 내재된 이상적 가치(규범적)에 의해 편향됨을 인지과학적 틀로 설명</td></tr>
</tbody></table>
<h4>3.2.1  Language Models Resist Alignment: Evidence From Data Compression: 데이터 압축 이론으로 규명한 얼라인먼트의 내재적 한계</h4>
<p>이 연구는 잘 정렬(align)된 LLM조차 쉽게 그 상태가 무너지는 현상의 근본 원인을 탐구한다.29 논문은 LLM이 사전학습 데이터 분포로 되돌아가려는 내재적 ’탄성(elasticity)’을 가지고 있으며, 이 때문에 얼라인먼트에 저항한다는 새로운 이론을 제시한다.30 이 현상을 분석하기 위해 정보 이론의 ‘데이터 압축’ 개념을 도입했는데, 모델 학습은 데이터를 효율적으로 압축하는 과정과 동일하다는 원리를 이용한 것이다.</p>
<p>이론적 분석을 통해, 소량의 데이터로 진행되는 미세조정(fine-tuning)이 대규모 데이터로 수행된 사전학습의 영향력을 뒤집기 어렵다는 것을 정량적으로 증명했다.30 특히 모델의 크기가 크고 사전학습 데이터가 많을수록 이러한 탄성이 더 강하게 나타남을 실험적으로 확인했다.31</p>
<p>이 연구는 AI 안전성 분야에 중대한 함의를 던진다. 얼라인먼트가 영구적인 상태가 아니라, 모델의 강력한 사전 분포에 맞서 끊임없이 유지해야 하는 불안정한 상태일 수 있음을 시사하기 때문이다. 이는 장기적인 AI 안전성 확보가 훨씬 더 어려운 과제임을 보여주는 근본적인 증거라 할 수 있다.29</p>
<h4>3.2.2  Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs: ’차이 인지’를 통한 공정성 패러다임의 전환</h4>
<p>본 연구는 기존 AI 공정성 연구의 주류였던 ‘차이 무시(difference-unaware)’ 또는 ‘색맹(color-blind)’ 접근법에 근본적인 문제를 제기한다.29 저자들은 법률, 의료 등 많은 현실 세계의 문제에서 특정 집단 간의 차이를 무시하는 것이 오히려 불공정을 야기하며, 상황에 맞는 차등적 대우가 진정한 공정성을 위해 필수적이라고 주장한다.35</p>
<p>이를 위해 **차이 인지(Difference Awareness, DiffAware)**와 **맥락 인지(Contextual Awareness, CtxtAware)**라는 새로운 개념을 도입했다. DiffAware는 모델이 집단 간의 의미 있는 차이를 인식하는 능력을, CtxtAware는 그러한 차이를 언제, 어떻게 적용해야 하는지를 판단하는 능력을 측정한다. 또한, 사실 기반의 ‘기술적(descriptive)’ 벤치마크와 가치 기반의 ‘규범적(normative)’ 벤치마크를 구분하여 보다 정교한 평가가 가능하도록 16,000개의 질문으로 구성된 벤치마크를 구축했다.34</p>
<p>이 연구는 AI 공정성 담론의 성숙을 보여주는 중요한 이정표다. 단순한 수학적 평등 개념을 넘어, 복잡한 사회적, 법적 규범을 이해하고 적용할 수 있는 고차원적인 공정성 개념으로의 전환을 이끌었다는 점에서 그 의의가 크다.</p>
<h4>3.2.3  Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention: 하드웨어-소프트웨어 통합 설계를 통한 장문 맥락 처리 혁신</h4>
<p>이 논문은 LLM의 컨텍스트 길이를 제한하는 핵심 병목 현상인 어텐션 메커니즘의 제곱에 비례하는 연산량 문제(‘O(n2)‘)를 정면으로 다룬다.29 표준 어텐션 수식은 다음과 같다.<br />
<span class="math math-display">
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
</span><br />
이 문제를 해결하기 위해 **네이티브 희소 어텐션(Native Sparse Attention, NSA)**을 제안했다.38 NSA는 전체 토큰을 계산하는 대신, 계층적 전략(전역적 압축, 핵심 토큰 선택, 지역적 슬라이딩 윈도우)을 통해 계산에 필요한 핵심 키-밸류 쌍(<span class="math math-inline">\tilde{K}_t, \tilde{V}_t</span>)만을 동적으로 선택한다.39</p>
<p>NSA의 가장 큰 혁신은 알고리즘을 하드웨어(예: GPU의 텐서 코어)의 작동 방식에 맞춰 공동 설계(co-design)했다는 점이다. 이를 통해 이론적인 연산량 감소를 실제 지연 시간(latency) 단축으로 효과적으로 전환시켰다. 그 결과, 64k 길이의 컨텍스트 처리에서 디코딩 속도를 11.6배 향상시키면서도, 성능은 기존의 전체 어텐션(full attention)과 대등하거나 그 이상을 기록했다.37</p>
<p>이 연구는 AI 분야의 미래 혁신이 알고리즘이나 아키텍처 개선만으로는 불충분하며, 하드웨어와의 긴밀한 통합 설계가 필수적임을 보여주는 대표적인 사례다. NSA는 실질적으로 사용 가능한 초장문(ultra-long context) 모델로 나아가는 현실적인 경로를 제시했다.41</p>
<h4>3.2.4  A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive: LLM 응답 생성의 기술적(Descriptive) 및 규범적(Prescriptive) 이중 메커니즘</h4>
<p>이 연구는 LLM의 응답 생성 과정을 인간의 의사 결정 과정과 유사한 인지과학적 틀로 설명하는 새로운 이론을 제시한다.29 논문은 LLM이 단순히 학습 데이터의 통계적 분포를 재현하는 <strong>기술적(descriptive) 요소</strong>뿐만 아니라, 데이터로부터 암묵적으로 학습한 ‘이상적’ 또는 ‘바람직한’ 가치 판단, 즉 <strong>규범적(prescriptive) 요소</strong>에 의해 응답이 결정된다고 주장한다.43</p>
<p>연구진은 사전학습의 영향을 배제하기 위해 새로운 가상의 개념을 이용한 통제된 실험을 설계했다. 실험 결과, LLM의 응답 샘플(<span class="math math-inline">S(C)</span>)은 데이터의 통계적 평균(<span class="math math-inline">C\mu</span>)에서 벗어나 규범적으로 이상적인 방향으로 체계적으로 편향되는 현상을 발견했다.44</p>
<p>이 연구는 LLM을 순수한 통계적 기계로 보는 관점에서 벗어나, 데이터에 내재된 가치를 학습하고 이를 바탕으로 스스로 판단을 내리는 주체로 이해해야 한다는 중요한 관점을 제공한다. 이는 모델이 명시적인 지시와는 다른, 자신만의 ‘바람직한’ 방향으로 응답을 유도할 수 있음을 의미하며, AI 얼라인먼트 연구에 새로운 과제를 제기한다.</p>
<h3>3.3  주요 연구 분야별 핵심 발표</h3>
<p>최우수 논문 외에도 ACL 2025에서는 LLM의 한계를 명확히 하고 보다 엄밀하게 평가하려는 연구 흐름이 두드러졌다.</p>
<ul>
<li><strong>LLM의 환각, 편향, 안전성 평가 프레임워크:</strong> 기존의 MMLU와 같은 범용 벤치마크를 넘어, 특정 실패 모드를 정밀하게 측정하기 위한 전문 벤치마크들이 대거 등장했다. 환각 현상을 유형별로 분석하는 ‘HalluLens’ 46, 전자상거래 환경에서의 복합 과제 수행 능력을 평가하는 ‘EcomScriptBench’ 47, 그리고 공정성, 추론, 안전성 등을 다각도로 측정하는 다양한 프레임워크들이 발표되었다.49 이는 AI 분야가 모델의 능력을 과시하는 단계를 지나, 신뢰성을 확보하기 위한 엄격한 검증의 단계로 성숙하고 있음을 보여준다.</li>
</ul>
<h2>4.  종합 분석 및 하반기 연구 전망</h2>
<h3>4.1 종합 분석: 이론, 효율성, 책임의 융합</h3>
<p>2025년 7월, ICML과 ACL에서 발표된 연구들은 AI 분야의 세 가지 핵심 축—이론적 깊이, 공학적 효율성, 사회적 책임—이 서로 긴밀하게 융합되고 있음을 보여준다. ICML의 <em>Train for the Worst</em> 논문에서 제시된 전략적 추론 아이디어는 ACL의 <em>Native Sparse Attention</em>과 같은 효율적인 추론 메커니즘을 통해 현실화될 수 있다. 또한, ICML의 <em>Value of Prediction</em>이 제시한 거시적 사회-기술 프레임워크는 ACL의 <em>Difference Awareness</em>가 다루는 미시적 공정성 문제에 대한 상위 수준의 의사결정 근거를 제공한다.</p>
<p>ACL의 최우수 논문들은 ’얼라인먼트’가 얼마나 어려운 과제인지를 다각도에서 입증한다. <em>Resist Alignment</em> 연구는 얼라인먼트가 모델의 내재적 특성에 의해 저항받는 불안정한 상태임을 이론적으로 밝혔고, <em>Difference Awareness</em> 연구는 순진한 방식의 정렬이 오히려 해가 될 수 있음을 보였다. <em>Response Sampling</em> 연구는 모델이 인간의 의도와 다른 자신만의 규범적 목표를 가질 수 있음을 드러냈다. 이들을 종합하면, 견고하고 안정적인 얼라인먼트를 달성하는 데에는 막대한 ’얼라인먼트 세금(Alignment Tax)’이 부과되며, 이는 일회성 해결이 아닌 지속적인 완화와 신중한 시스템 설계가 필요한 문제임을 시사한다.</p>
<h3>4.2 하반기 연구 전망</h3>
<p>상기 분석을 바탕으로 2025년 하반기 이후 AI 연구는 다음 세 가지 방향으로 심화될 것으로 전망된다.</p>
<ol>
<li><strong>’전략적 AI(Strategic AI)’의 부상:</strong> 모델이 단순히 정해진 절차에 따라 결과를 생성하는 것을 넘어, 스스로의 연산 과정이나 추론 경로를 전략적으로 계획하고 최적화하는 연구가 본격화될 것이다. 이는 <em>Train for the Worst</em> 논문에서 제시된 동적 추론 아이디어의 연장선에 있다.</li>
<li><strong>’AI 경제학(AI Economics)’의 공식화:</strong> <em>Value of Prediction</em> 연구에서 보인 정량적 자원 배분 접근법이 AI 시스템 배포의 다른 영역으로 확장될 것이다. 이는 AI 시스템의 개발, 배포, 유지보수에 따르는 비용과 사회적 효용을 체계적으로 분석하는 새로운 융합 연구 분야의 등장을 예고한다.</li>
<li><strong>안전성-효율성 트레이드오프(Safety-Efficiency Trade-off) 심화:</strong> <em>Native Sparse Attention</em>과 같은 기술로 모델의 효율성이 높아짐에 따라, 최적화 과정에서 기존의 얼라인먼트가 손상될 수 있는 새로운 안전성 취약점이 나타날 수 있다. <em>Resist Alignment</em> 이론과 결합하여, 효율화된 모델이 안전성을 유지하는지에 대한 연구가 핵심 과제로 부상할 것이다.</li>
</ol>
<h3>4.3 결론</h3>
<p>2025년 7월은 단일한 혁신이 아닌, 다각적이고 심층적인 진보가 이루어진 시기였다. AI 연구 커뮤니티는 파운데이션 모델의 이론적 토대를 공고히 하는 동시에, 이를 현실에 적용하기 위한 공학적 제약을 극복하고, 나아가 기술이 사회에 미치는 영향을 성찰하며 책임 있는 방향을 정립하려는 노력을 동시에 경주했다. 이론, 공학, 사회적 책임의 세 축이 조화롭게 발전하는 이러한 흐름은 향후 AI 기술의 지속 가능한 발전을 위한 초석이 될 것이다.</p>
<h2>5. 참고 자료</h2>
<ol>
<li>International Conference on Machine Learning (ICML) 2025 - Vancouver Convention Centre, https://www.vancouverconventioncentre.com/events/international-conference-on-machine-learning-icml-2025</li>
<li>ICML 2025 - Amazon Science, https://www.amazon.science/conferences-and-events/icml-2025</li>
<li>2025 Dates and Deadlines - ICML 2025, https://icml.cc/Conferences/2025/Dates</li>
<li>ICML 2025, https://icml.cc/</li>
<li>Main Conference - ACL 2025, https://2025.aclweb.org/calls/main_conference_papers/</li>
<li>ACL 2025: The 63rd Annual Meeting of the Association for …, https://2025.aclweb.org/</li>
<li>ICML 2025 Call for Papers, https://icml.cc/Conferences/2025/CallForPapers</li>
<li>DmitryRyumin/ICML-2025-Papers - GitHub, https://github.com/DmitryRyumin/ICML-2025-Papers</li>
<li>ICML 2025: Key Ideas on LLMs, Human-AI Alignment, and More - Two Sigma, https://www.twosigma.com/articles/icml-2025-key-ideas-on-llms-human-ai-alignment-and-more/</li>
<li>ICML 2025 Papers, https://icml.cc/virtual/2025/papers.html</li>
<li>Apple Machine Learning Research at ICML 2025, https://machinelearning.apple.com/research/icml-2025</li>
<li>2025: Bristol Mathematicians Win Outstanding Paper Award at Top AI Conference | School of Mathematics, https://www.bristol.ac.uk/maths/news/2025/bristol-mathematicians-win-outstanding-paper-award-at-top-ai-conference.html</li>
<li>Score Matching with Missing Data | OpenReview, https://openreview.net/forum?id=mBstuGUaXo</li>
<li>ICML Poster Score Matching with Missing Data, https://icml.cc/virtual/2025/poster/44169</li>
<li>Score Matching With Missing Data - arXiv, https://arxiv.org/pdf/2506.00557</li>
<li>Score Matching with Missing Data - University of Bristol Research Portal, https://research-information.bris.ac.uk/en/publications/score-matching-with-missing-data</li>
<li>Kempner Institute Collaborators Win Outstanding Paper Award at ICML 2025, https://kempnerinstitute.harvard.edu/news/kempner-institute-researchers-win-outstanding-paper-award-at-icml-2025/</li>
<li>Train for the Worst, Plan for the Best: Understanding Token … - arXiv, https://arxiv.org/pdf/2502.06768</li>
<li>Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions, https://icml.cc/virtual/2025/poster/45990</li>
<li>Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions, https://www.youtube.com/watch?v=GmhAbsPOuk4</li>
<li>Outstanding Paper Award at ICML 2025 for relAI paper - - Konrad Zuse School of Excellence in reliable AI, https://zuseschoolrelai.de/outstanding-paper-award-at-icml-2025-for-relai-paper/</li>
<li>Outstanding Paper Award at ICML 2025 for MCML Researchers, https://mcml.ai/news/2025-07-18-fischer-abaigar-icml/</li>
<li>When smarter isn’t better: rethinking AI in public services (discussion of a research paper) : r/learnmachinelearning - Reddit, https://www.reddit.com/r/learnmachinelearning/comments/1nr1oyy/when_smarter_isnt_better_rethinking_ai_in_public/</li>
<li>The Value of Prediction in Identifying the Worst-Off | OpenReview, https://openreview.net/forum?id=26JsumCG0z</li>
<li>The Value of Prediction in Identifying the Worst-Off - OpenReview, https://openreview.net/pdf?id=26JsumCG0z</li>
<li>The Value of Prediction in Identifying the Worst-Off - arXiv, <a href="https://arxiv.org/pdf/2501.19334">https://arxiv.org/pdf/2501.19334?</a></li>
<li>[NAACL 2025] Second Call for Main Conference Papers | ACL Member Portal, https://www.aclweb.org/portal/content/naacl-2025-second-call-main-conference-papers</li>
<li>Second Call for Main Conference Papers - NAACL-HLT 2025, https://2025.naacl.org/calls/papers/</li>
<li>DeepSeek’s Liang Wenfeng &amp; Peking University’s Yang Yaodong’s Team Win Best Paper Award at ACL 2025 with NSA Paper - 36氪, https://eu.36kr.com/en/p/3401632759482502</li>
<li>Language Models Resist Alignment: Evidence From Data Compression - arXiv, https://arxiv.org/html/2406.06144v5</li>
<li>Language Models Resist Alignment: Evidence From Data … - arXiv, https://arxiv.org/pdf/2406.06144</li>
<li>Language Models Resist Alignment: Evidence From Data Compression - arXiv, https://arxiv.org/html/2406.06144v3</li>
<li>Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs | PDF | Stereotypes | Bias - Scribd, https://www.scribd.com/document/905382595/Fairness-through-Difference-Awareness-Measuring-Desired-Group-Discrimination-in-LLMs</li>
<li>Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs - arXiv, https://arxiv.org/html/2502.01926v1</li>
<li>Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs, https://reglab.stanford.edu/publications/fairness-through-difference-awareness-measuring-desired-group-discrimination-in-llms/</li>
<li>Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs, https://chatpaper.com/paper/175737</li>
<li>Hardware-Aligned and Natively Trainable Sparse Attention - arXiv, https://arxiv.org/html/2502.11089v1</li>
<li>Hardware-Aligned and Natively Trainable Sparse Attention - arXiv, https://arxiv.org/abs/2502.11089</li>
<li>Hardware-Aligned and Natively Trainable Sparse Attention - ACL Anthology, https://aclanthology.org/2025.acl-long.1126.pdf</li>
<li>Hardware-Aligned and Natively Trainable Sparse Attention - Hugging Face, https://huggingface.co/papers/2502.11089</li>
<li>Deepseek just won the best paper award at ACL 2025 with a breakthrough innovation in long context, a model using this might come soon : r/LocalLLaMA - Reddit, https://www.reddit.com/r/LocalLLaMA/comments/1mdn6dp/deepseek_just_won_the_best_paper_award_at_acl/</li>
<li>PR-534: A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive, https://www.youtube.com/watch?v=BTX4TO9bZ18</li>
<li>A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive - arXiv, https://arxiv.org/html/2402.11005v4</li>
<li>A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive - arXiv, https://www.arxiv.org/pdf/2402.11005</li>
<li>A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive - ChatPaper, https://chatpaper.com/paper/176850</li>
<li>Paper Digest: ACL 2025 Papers &amp; Highlights, https://www.paperdigest.org/2025/07/acl-2025-papers-highlights/</li>
<li>ACL.2025 - Long Papers | Cool Papers - Immersive Paper Discovery, <a href="https://papers.cool/venue/ACL.2025?group=Long+Papers">https://papers.cool/venue/ACL.2025?group=Long%20Papers</a></li>
<li>Accepted Main Conference Papers - ACL 2025, https://2025.aclweb.org/program/main_papers/</li>
<li>Accepted Findings Papers - ACL 2025, https://2025.aclweb.org/program/find_papers/</li>
<li>Findings of the Association for Computational Linguistics (2025) - ACL Anthology, https://aclanthology.org/events/findings-2025/</li>
<li>Annual Meeting of the Association for Computational Linguistics (2025) - ACL Anthology, https://aclanthology.org/events/acl-2025/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>