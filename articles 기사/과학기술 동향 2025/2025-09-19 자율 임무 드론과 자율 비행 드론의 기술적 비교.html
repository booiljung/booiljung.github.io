<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:자율 임무 드론과 자율 비행 드론의 기술적 비교</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>자율 임무 드론과 자율 비행 드론의 기술적 비교</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2025년 AI 및 로봇 연구 동향</a> / <span>자율 임무 드론과 자율 비행 드론의 기술적 비교</span></nav>
                </div>
            </header>
            <article>
                <h1>자율 임무 드론과 자율 비행 드론의 기술적 비교</h1>
<h2>1.  자율 비행과 자율 임무의 근본적 차이</h2>
<p>드론, 즉 무인 항공기(Unmanned Aerial Vehicle, UAV) 기술의 발전은 항공, 물류, 국방, 농업 등 다양한 산업 분야에서 혁신을 주도하고 있다. 특히 ’자율성(Autonomy)’의 개념이 드론에 접목되면서, 인간의 직접적인 개입 없이 복잡한 작업을 수행하는 시스템의 등장이 가시화되고 있다. 그러나 기술 발전의 이면에는 ’자율 비행 드론(Autonomous Flight Drone)’과 ’자율 임무 드론(Autonomous Mission Drone)’이라는 두 용어가 명확한 구분 없이 혼용되는 문제가 존재한다.1 이러한 용어의 혼재는 기술의 본질을 흐리고, 시스템의 실제 역량과 잠재력을 정확히 평가하는 데 장애물로 작용한다. 본 보고서는 이 두 개념을 명확히 구분할 수 있는 체계적인 프레임워크와 기술적 기준을 제시함으로써, 자율 드론 기술의 현주소를 정확히 진단하고 미래 발전 방향을 조망하는 것을 목표로 한다.</p>
<h3>1.1 개념 정의: ’이동(How to fly)’과 ’과업(What to do)’의 자율성</h3>
<p>자율 비행 드론과 자율 임무 드론을 구분하는 가장 근본적인 기준은 시스템이 해결하고자 하는 핵심 질문에 있다. 하나는 ’어떻게 비행할 것인가’에, 다른 하나는 ’무엇을 할 것인가’에 초점을 맞춘다.</p>
<p><strong>자율 비행 드론 (Autonomous Flight Drone):</strong> 이 유형의 드론은 주로 ’이동의 자율성’에 중점을 둔다. 핵심 역량은 사전에 정의된 경로(pre-programmed flight plans)나 웨이포인트(waypoint)를 따라 안정적으로 비행하고, 비행 중 마주치는 장애물을 회피하는 능력에 있다.1 즉, 자율 비행 드론의 주된 관심사는 ‘어떻게’ 목표 지점까지 안전하고 효율적으로 도달할 것인가이다. 이는 GPS 모듈, 자동조종장치(Autopilot System), 그리고 기본적인 센서를 기반으로 사전에 설정된 지시를 충실히 이행하는 ’자동화(Automation)’의 개념에 가깝다.1 비행 계획 수립, 이륙, 경로 비행, 착륙 등 일련의 비행 절차를 자동화하여 조종사의 부담을 경감시키는 것이 주목적이다.</p>
<p><strong>자율 임무 드론 (Autonomous Mission Drone):</strong> 반면, 자율 임무 드론은 ’과업의 자율성’을 추구한다. 비행은 단순히 임무 수행을 위한 수단일 뿐, 시스템의 핵심 역량은 주어진 상위 목표(high-level mission)를 달성하기 위해 스스로 환경을 인식하고, 상황을 판단하며, 동적으로 행동을 결정하는 능력에 있다.1 예를 들어, ‘실종자를 수색하라’ 또는 ’교량의 균열을 찾아내라’와 같은 추상적인 명령을 이해하고, 이를 달성하기 위한 구체적인 비행 경로와 행동 계획(예: 특정 지역 집중 탐색, 의심 지점 근접 촬영)을 스스로 수립하고 실행한다. 이는 인공지능(AI), 컴퓨터 비전, 정교한 알고리즘을 통해 실시간 데이터를 분석하고 비판적인 의사결정을 내리는 진정한 의미의 ‘자율성(Autonomy)’ 개념에 해당한다.4 록히드 마틴(Lockheed Martin)과 같은 국방 기업이 임무의 작전 효율성 극대화와 인적 자원의 안전 확보를 위해 자율 시스템을 배치하는 맥락에서 이러한 개념은 더욱 명확히 드러난다.3</p>
<h3>1.2 문제 제기: 기술 발전과 용어의 혼재</h3>
<p>최근 기술 발전으로 인해 단순 경로 비행 드론에도 AI 기반의 장애물 회피 기능이 추가되면서 두 용어의 경계가 점차 모호해지고 있다.1 경로 비행 중 예기치 않은 장애물을 회피하는 행위는 일종의 실시간 의사결정으로 볼 수 있기 때문이다. 그러나 이러한 기능은 대부분 비행의 ’안전성’을 확보하기 위한 보조 수단에 머무르며, 임무 목표 자체를 동적으로 변경하거나 새로운 과업을 생성하지는 않는다.</p>
<p>이처럼 ’자동화’와 ’자율성’의 철학적 차이가 두 드론 유형을 가르는 핵심 기준이 된다. 자동화는 정해진 규칙에 따른 반복 수행(rule-based execution)에 초점을 맞추는 반면, 자율성은 목표 달성을 위한 능동적 문제 해결(goal-oriented problem solving)을 지향한다. 따라서 ’자율 비행 드론’은 고도화된 ’자동화’의 산물로, ’자율 임무 드론’은 진정한 의미의 ’자율성’을 지향하는 시스템으로 재정의할 수 있다. 이 철학적 구분은 두 시스템이 요구하는 기술 스택, 의사결정 구조, 그리고 응용 분야의 근본적인 차이를 파생시키는 원인이 된다. 본 보고서는 이러한 관점을 바탕으로 두 개념을 심층적으로 해부하고 분석할 것이다.</p>
<h2>2.  드론 자율성 단계별 분석: 비행 자동화에서 임무 자율성까지</h2>
<p>드론의 자율성 수준을 체계적으로 분류하고 ’자율 비행’과 ’자율 임무’의 개념을 명확히 위치시키기 위해, 자동차 산업에서 널리 통용되는 미국 자동차 기술자 협회(Society of Automotive Engineers, SAE)의 J3016 표준을 참조 모델로 도입할 수 있다.6 이 표준은 시스템과 인간의 역할 분담을 기준으로 자율성을 0부터 5까지 총 6단계로 정의하며, 이는 드론의 자율성을 평가하는 데에도 매우 유용한 프레임워크를 제공한다.9 실제로 엑사인(Exyn)과 같은 드론 기술 기업들은 SAE 레벨을 참고하여 자체적인 드론 자율성 기준을 수립하고 있다.11 본 분석에서는 SAE 표준의 핵심 개념인 ’운전 주체’와 ’운용 설계 범위(Operational Design Domain, ODD)’를 드론의 ‘비행 및 임무 수행’ 맥락에 맞게 재해석하여 적용한다.</p>
<h3>2.1 자율 비행과 자율 임무의 단계별 매핑</h3>
<p>드론의 자율성은 단순히 비행을 자동화하는 수준에서 시작하여, 복잡한 임무를 스스로 계획하고 완수하는 수준으로 진화한다. 이 스펙트럼 위에서 자율 비행 드론은 주로 레벨 2-3에, 자율 임무 드론은 레벨 4 이상에 해당한다.</p>
<ul>
<li>
<p><strong>레벨 0 (비자동화 - No Automation):</strong> 인간 조종사가 모든 비행 제어(자세, 고도, 속도, 방향)를 수동으로 수행한다. 시스템은 경고 기능 외에는 비행에 개입하지 않는다.7</p>
</li>
<li>
<p><strong>레벨 1 (조종사 보조 - Driver Assistance):</strong> 시스템이 조향(방향) 또는 가감속(고도/속도) 중 하나의 기능만을 자동화하여 조종사를 보조한다. 고도 유지(Altitude Hold)나 크루즈 컨트롤 기능이 대표적인 예이다.7</p>
</li>
<li>
<p><strong>레벨 2 (부분 자동화 - Partial Automation):</strong> 시스템이 조향과 가감속을 동시에 제어한다. GPS 좌표를 따라 순차적으로 비행하는 웨이포인트(Waypoint) 비행이 이 단계의 전형적인 사례다. 시스템이 비행의 많은 부분을 담당하지만, 조종사는 주변 환경을 지속적으로 감시하고 언제든 개입할 준비를 해야 할 책임이 있다.7 대부분의 상업용 ’자율 비행 드론’이 이 수준에 해당한다.</p>
</li>
<li>
<p><strong>레벨 3 (조건부 자율 비행 - Conditional Automation):</strong> 시스템이 특정 조건(ODD) 내에서 비행의 모든 측면을 주도하고, 장애물 감지 및 회피와 같은 동적인 상황에 대응한다.4 하지만 시스템이 자신의 한계(예: GPS 신호 손실, 악천후)에 도달하거나 긴급 상황이 발생하면 조종사에게 제어권 전환을 명확히 요구한다. 조종사는 시스템의 요구에 즉각적으로 응답할 준비가 되어 있어야 한다.7 이 단계는 고도화된 ’자율 비행 드론’의 지향점이며, 자율 임무로 넘어가는 과도기적 단계로 볼 수 있다.</p>
</li>
<li>
<p><strong>레벨 4 (고등 자율 임무 - High Automation):</strong> 시스템이 특정 ODD(예: 특정 농장, 검사 대상 교량, GPS가 차단된 실내) 내에서는 조종사의 개입 없이 스스로 임무 목표를 설정하고 완수한다.10 시스템은 비상 상황이 발생하더라도 스스로 안전하게 대처(예: 안전 지점으로 복귀, 비상 착륙)할 수 있다. 인간의 역할은 더 이상 비행의 ’감독자’가 아니라, 임무의 전반적인 진행 상황을 모니터링하고 결과를 확인하는 ’관리자’로 전환된다. 이것이 진정한 ’자율 임무 드론’의 시작점이다.</p>
</li>
<li>
<p><strong>레벨 5 (완전 자율 임무 - Full Automation):</strong> 시스템이 ODD의 제약 없이, 인간이 운전할 수 있는 모든 환경과 조건에서 어떠한 개입도 없이 임무를 시작하고 완수할 수 있는 궁극적인 단계이다.7 이는 현재 기술 수준에서는 개념적 목표에 가깝다.</p>
</li>
</ul>
<h3>2.2 [표 1] 드론 자율성 단계별 정의 및 특징</h3>
<p>SAE 레벨을 드론에 적용하여 ’자율 비행’과 ’자율 임무’가 자율성 스펙트럼의 어느 위치에 해당하는지를 명확하게 시각화하고, 각 단계의 핵심적인 차이를 아래 표와 같이 비교할 수 있다.</p>
<table><thead><tr><th>자율성 레벨</th><th>명칭</th><th>주요 과업 (비행 vs 임무)</th><th>시스템의 역할</th><th>인간의 역할</th><th>핵심 기술</th><th>대표 사례</th></tr></thead><tbody>
<tr><td><strong>레벨 0</strong></td><td>비자동화</td><td>비행</td><td>경고 및 정보 제공</td><td>모든 동적 비행 과업 수행</td><td>기본 센서</td><td>수동 조종 RC 드론</td></tr>
<tr><td><strong>레벨 1</strong></td><td>조종사 보조</td><td>비행</td><td>조향 <strong>또는</strong> 가감속 제어</td><td>모든 동적 비행 과업 수행</td><td>고도 유지 센서, 크루즈 컨트롤</td><td>고도 유지 기능이 있는 드론</td></tr>
<tr><td><strong>레벨 2</strong></td><td>부분 자동화</td><td>비행</td><td>조향 <strong>그리고</strong> 가감속 제어</td><td>주변 환경 감시 및 개입 준비</td><td>GPS, 자동조종장치, 웨이포인트 내비게이션</td><td>GPS 경로 비행 드론, 자동 귀환(RTH)</td></tr>
<tr><td><strong>레벨 3</strong></td><td>조건부 자율 비행</td><td><strong>고도화된 비행</strong></td><td>ODD 내 모든 비행 과업 수행, 장애물 회피</td><td>시스템의 개입 요청 시 즉각 대응</td><td>충돌 방지 센서 (LiDAR, Vision), 기본 AI</td><td>장애물 회피 기능이 탑재된 촬영/측량 드론</td></tr>
<tr><td><strong>레벨 4</strong></td><td>고등 자율 임무</td><td><strong>임무</strong></td><td>ODD 내 임무 계획, 수행, 비상 대응</td><td>임무 감독 및 결과 확인 (개입 불필요)</td><td>SLAM, 컴퓨터 비전, 센서 융합, 온보드 AI</td><td>실내 자율 검사 드론, AI 기반 수색 구조 드론</td></tr>
<tr><td><strong>레벨 5</strong></td><td>완전 자율 임무</td><td><strong>임무</strong></td><td>ODD 제한 없이 모든 임무 수행</td><td>목적지 설정 및 시스템 활성화</td><td>고도화된 AI, 범용 인공지능(AGI)</td><td>(개념적) 모든 환경에서 작동하는 자율 배송/정찰 드론</td></tr>
</tbody></table>
<p>이 표는 레벨 3과 레벨 4 사이의 질적인 도약을 명확히 보여준다. 레벨 3까지의 시스템 역할이 ’사전에 계획된 경로 비행’에 머무는 반면, 레벨 4부터는 ’동적인 임무 계획 및 수행’으로 확장된다. 마찬가지로 인간의 역할도 레벨 3에서는 ’개입을 준비하는 대기자’이지만, 레벨 4에서는 ’결과를 확인하는 관리자’로 변화한다. 이러한 역할의 전환이야말로 자율 비행과 자율 임무를 가르는 결정적인 분기점이다.</p>
<h2>3.  자율 비행의 핵심 기술: 안정성과 경로 탐색의 메커니즘</h2>
<p>자율 비행 드론의 핵심은 주어진 경로를 따라 안정적으로 기동하고, 장애물을 피해 효율적으로 목표 지점에 도달하는 능력에 있다. 이러한 능력은 수십 년간 발전해 온 고전적인 제어 이론과 컴퓨터 과학의 탐색 알고리즘에 깊이 뿌리내리고 있다. 이 기술들은 드론이 외부 환경의 불확실성 속에서도 예측 가능한 행동을 하도록 만드는 기반을 제공한다.</p>
<h3>3.1 안정적 기동의 원리: PID(비례-적분-미분) 제어기</h3>
<p>드론이 공중에서 안정적인 자세를 유지하고, 원하는 고도와 위치를 정확히 지킬 수 있는 것은 PID(Proportional-Integral-Derivative) 제어기 덕분이다.12 PID 제어는 드론의 두뇌라 할 수 있는 비행 제어 컴퓨터(Flight Controller)의 핵심 알고리즘으로, 목표 상태(Setpoint, 예: 수평 자세)와 센서로 측정한 현재 상태(Input, 예: 기울어진 자세) 사이의 오차(Error)를 지속적으로 계산하여 이를 보정하기 위한 제어 신호를 생성한다.12</p>
<h4>3.1.1 수학적 원리</h4>
<p>PID 제어기의 출력 <code>u(t)</code>는 비례항(P), 적분항(I), 미분항(D)의 합으로 계산된다. 연속 시간(Continuous-time) 시스템에서 PID 제어 법칙은 다음과 같은 미적분 방정식으로 표현된다.14</p>
<p>코드 스니펫</p>
<pre><code>u(t) = K_p e(t) + K_i \int_0^t e(\tau)d\tau + K_d \frac{de(t)}{dt}
</code></pre>
<p>여기서 각 변수는 다음과 같다.</p>
<ul>
<li>
<p><code>u(t)</code>: 시간 <code>t</code>에서의 제어 출력 (예: 모터에 전달되는 신호)</p>
</li>
<li>
<p><code>e(t)</code>: 시간 <code>t</code>에서의 오차 (<code>Setpoint - Input</code>)</p>
</li>
<li>
<p><code>K_p</code>: 비례 이득(Proportional Gain)</p>
</li>
<li>
<p><code>K_i</code>: 적분 이득(Integral Gain)</p>
</li>
<li>
<p><code>K_d</code>: 미분 이득(Derivative Gain)</p>
</li>
</ul>
<p>실제 드론과 같은 디지털 시스템에서는 이 연속 시간 방정식을 이산 시간(Discrete-time) 형태로 변환하여 사용한다. 샘플링 시간 <code>h</code>를 고려한 이산 시간 PID 제어기는 여러 근사 방법(예: 후진 오일러 근사)을 통해 유도될 수 있으며, 그중 위치 형식 알고리즘(positional algorithm)은 다음과 같이 표현될 수 있다.17</p>
<p>코드 스니펫</p>
<pre><code>u(t_k) = u(t_{k-1}) + K_p [e(t_k) - e(t_{k-1})] + \frac{K_p h}{T_i} e(t_k) + \frac{K_p T_d}{h} [e_f(t_k) - 2e_f(t_{k-1}) + e_f(t_{k-2})]
</code></pre>
<h4>3.1.2 각 항의 역할</h4>
<p>PID 제어기의 세 항은 각각 과거, 현재, 미래의 오차 정보를 활용하여 정교한 제어를 수행한다.13</p>
<ul>
<li>
<p><strong>P (비례, Proportional) 제어:</strong> ’현재’의 오차 크기에 비례하여 제어 출력을 결정한다. 오차가 크면 강하게, 작으면 약하게 반응하여 시스템을 목표 값으로 신속하게 유도한다.14 하지만 비례 제어만으로는 외력(예: 바람)에 의해 발생하는 정상상태 오차(steady-state error)를 완전히 제거하기 어렵다.</p>
</li>
<li>
<p><strong>I (적분, Integral) 제어:</strong> ’과거’의 오차를 시간의 흐름에 따라 누적(적분)하여 제어 출력에 반영한다. 이 누적된 오차 값은 아주 작은 정상상태 오차라도 시간이 지나면 큰 제어 신호로 증폭시켜 결국 오차를 0으로 수렴시키는 역할을 한다.13 그러나 과도하게 사용될 경우, 시스템이 목표 값을 지나치는 오버슛(overshoot)을 유발하거나 진동을 발생시켜 불안정하게 만들 수 있다.</p>
</li>
<li>
<p><strong>D (미분, Derivative) 제어:</strong> 오차의 변화율, 즉 ’미래’의 오차를 예측하여 제어에 반영한다. 오차가 급격하게 변하는 상황(예: 목표 값에 빠르게 접근할 때)에서 제동(damping)을 걸어 오버슛을 억제하고 시스템의 안정성을 향상시킨다.13 이는 시스템의 반응을 부드럽게 만들어 진동을 줄이는 역할을 한다.</p>
</li>
</ul>
<p>이 세 가지 이득 값(<code>K_p, K_i, K_d</code>)을 드론의 기체 특성(무게, 크기, 모터 성능 등)에 맞게 최적으로 조정하는 과정을 ’튜닝(tuning)’이라고 하며, 이는 안정적인 비행 성능을 확보하는 데 결정적인 과정이다.13</p>
<h3>3.2 최적 경로 탐색: A* (A-Star) 알고리즘</h3>
<p>자율 비행 드론이 출발지에서 목적지까지, 또는 여러 경유지(waypoint)를 거쳐 비행할 때 가장 효율적인 경로를 계획하기 위해 A* (A-Star) 알고리즘이 널리 사용된다. A*는 그래프 탐색 알고리즘의 일종으로, 알려진 장애물들을 피해 최단 경로를 찾는 데 매우 효과적이다.21</p>
<h4>3.2.1 비용 함수</h4>
<p>A* 알고리즘의 핵심은 각 탐색 지점(노드 <code>n</code>)의 가치를 평가하는 비용 함수 <code>f(n)</code>에 있다. 이 함수는 과거의 비용과 미래의 추정 비용을 합산하여 가장 유망한 경로를 예측한다.21</p>
<p>코드 스니펫</p>
<pre><code>f(n) = g(n) + h(n)
</code></pre>
<ul>
<li>
<p><code>g(n)</code>: <strong>과거 비용 (Actual Cost)</strong>. 시작 노드로부터 현재 노드 <code>n</code>까지 이동하는 데 소요된 실제 비용(거리, 시간 등)이다. 이 값은 이미 지나온 경로이므로 정확하게 계산된다. 이는 다익스트라(Dijkstra) 알고리즘의 개념을 계승한 부분으로, 현재까지의 최단 경로를 보장하는 역할을 한다.22</p>
</li>
<li>
<p><code>h(n)</code>: <strong>미래 추정 비용 (Heuristic Cost)</strong>. 현재 노드 <code>n</code>에서 최종 목표 노드까지 도달하는 데 필요할 것으로 ’추정’되는 비용이다. 이 휴리스틱(heuristic) 함수는 문제의 특성에 맞게 설계되며, 알고리즘의 성능을 좌우하는 핵심 요소다.24 예를 들어, 지도상의 경로 탐색에서는 장애물을 고려하지 않은 직선거리인 유클리드 거리(Euclidean distance)나 격자 형태 맵에서의 맨해튼 거리(Manhattan distance)가 주로 사용된다.23</p>
</li>
</ul>
<h4>3.2.2 탐색 과정</h4>
<p>A* 알고리즘은 탐색할 노드들의 목록(Open List)에서 <code>f(n)</code> 값이 가장 작은 노드를 선택하여 탐색을 확장해 나간다.24</p>
<p><code>g(n)</code>을 통해 불필요하게 먼 길을 돌아가는 것을 방지하고, <code>h(n)</code>을 통해 목표 지점 방향으로 탐색을 유도함으로써, 전체 맵을 모두 탐색하지 않고도 효율적으로 최적의 경로를 찾아낼 수 있다.</p>
<p>이처럼 자율 비행의 핵심 기술인 PID 제어와 A* 알고리즘은 ‘정해진 세계(Defined World)’ 모델을 전제로 작동한다. PID 제어는 드론의 동역학 모델이 주어져야 최적의 튜닝이 가능하며, A* 알고리즘은 사전에 완성된 지도와 장애물 정보가 있어야 최적 경로를 계산할 수 있다. 이는 자율 비행 드론이 근본적으로 ‘닫힌 세계 가정(Closed-World Assumption)’ 하에서 운용됨을 시사한다. 즉, 사전에 알지 못했던 환경의 변화나 복잡한 임무 요구사항에 능동적으로 대처하는 데에는 본질적인 한계가 존재한다. 바로 이 지점에서, 미지의 환경을 스스로 탐험하고 이해하며 임무를 수행하는 자율 임무 기술 스택의 필요성이 대두된다.</p>
<h2>4.  자율 임무 수행을 위한 기술 스택: 인식, 판단, 그리고 실행</h2>
<p>자율 비행 드론이 ’닫힌 세계’의 제약을 갖는 반면, 자율 임무 드론은 예측 불가능하고 동적으로 변화하는 ’열린 세계(Open World)’에 대응하도록 설계된다. 이를 위해 자율 임무 드론은 단순히 비행하는 것을 넘어, 주변 환경을 실시간으로 ’인식(Perception)’하고, 수집된 정보를 바탕으로 ’판단(Decision-Making)’하며, 결정된 사항을 정밀하게 ’실행(Action)’하는 유기적인 순환 루프(Loop)를 구축해야 한다. 이 순환 루프를 구현하는 것이 바로 자율 임무 기술 스택의 핵심이다.</p>
<h3>4.1 환경 인식(Perception): ’보는 것’을 넘어 ‘이해하는’ 단계</h3>
<p>자율 임무의 첫걸음은 드론이 자신의 주변 환경을 인간처럼, 혹은 그 이상으로 정밀하게 이해하는 것이다. 이를 위해 다양한 센서와 첨단 AI 기술이 동원된다.</p>
<ul>
<li>
<p><strong>컴퓨터 비전 (Computer Vision):</strong> 카메라를 통해 입력된 시각 데이터를 AI 모델로 분석하여 의미 있는 정보로 변환하는 기술이다.30 이는 단순히 이미지를 기록하는 것을 넘어, 이미지 속 객체를 탐지하고(예: 사람, 차량, 건물 식별), 특정 객체를 지속적으로 추적하며, 나아가 이미지의 모든 픽셀을 도로, 식생, 수역 등 특정 클래스로 분류하는 시맨틱 세분화(Semantic Segmentation)까지 포함한다.30 예를 들어, 아마존 프라임 에어(Amazon Prime Air)의 배송 드론은 컴퓨터 비전을 통해 정원에 있는 아이나 동물을 식별하고 안전한 착륙 지점을 찾으며, 안두릴 인더스트리(Anduril Industries)의 군용 드론은 적대적 환경에서 특정 표적을 식별하고 추적하는 데 이 기술을 활용한다.32</p>
</li>
<li>
<p><strong>LiDAR 및 3D 매핑:</strong> 라이다(LiDAR, Light Detection and Ranging) 센서는 레이저 펄스를 발사하고 그 빛이 반사되어 돌아오는 시간을 측정하여 주변 환경과의 거리를 극도로 정밀하게 계산한다.30 수집된 수백만 개의 거리 데이터는 3차원 점군(Point Cloud)을 형성하여 주변 지형과 구조물에 대한 정밀한 3D 지도를 실시간으로 생성한다. 이는 정밀한 장애물 회피와 복잡한 구조물의 형상을 파악하는 데 필수적이다.34</p>
</li>
<li>
<p><strong>센서 융합 (Sensor Fusion):</strong> 어떠한 단일 센서도 모든 환경에서 완벽할 수는 없다. 카메라는 풍부한 색상과 질감 정보를 제공하지만 조명 변화나 악천후에 취약하고, LiDAR는 정확한 거리 정보를 제공하지만 색상 정보를 얻을 수 없으며 가격이 비싸다. IMU(Inertial Measurement Unit)는 드론의 가속도와 각속도를 측정하여 움직임을 추정하지만 시간이 지남에 따라 오차가 누적된다. 센서 융합은 이처럼 각기 다른 특성을 가진 이종(heterogeneous) 센서들의 데이터를 통합하여 상호 보완함으로써, 어떤 환경에서도 강건하고(robust) 신뢰성 있는 인식 결과를 도출하는 기술이다.34</p>
</li>
</ul>
<h3>4.2 위치 추정 및 지도 작성(Localization &amp; Mapping): SLAM</h3>
<p>자율 임무 드론이 GPS 신호가 닿지 않는 실내나 미지의 환경(예: 붕괴된 건물 내부, 깊은 숲속)에서 활동하기 위해서는 자신의 위치를 파악하고 동시에 주변 지도를 그려나가는 능력이 필수적이다. 이 문제를 해결하는 핵심 기술이 바로 **SLAM(Simultaneous Localization and Mapping, 동시적 위치 추정 및 지도 작성)**이다.33</p>
<ul>
<li>
<p><strong>원리:</strong> SLAM은 드론에 장착된 센서(카메라, LiDAR 등)로부터 들어오는 데이터를 기반으로, 이전에 관측했던 특징점(landmark)들을 다시 인식하여 자신의 상대적인 위치 변화를 추정하고, 동시에 새로운 환경 정보를 지도에 추가해 나가는 재귀적인 프로세스다.</p>
</li>
<li>
<p><strong>종류:</strong></p>
</li>
<li>
<p><strong>Visual SLAM (vSLAM):</strong> 카메라를 주 센서로 사용하여 환경의 시각적 특징점을 기반으로 위치를 추정하고 지도를 작성한다. 저렴하고 풍부한 정보를 얻을 수 있는 장점이 있지만, 조명 변화가 심하거나 특징이 없는 벽면 같은 환경에서는 성능이 저하될 수 있다.36</p>
</li>
<li>
<p><strong>LiDAR SLAM:</strong> LiDAR를 주 센서로 사용하여 점군 데이터를 정합(registration)하는 방식으로 위치를 추정한다. 매우 정밀하고 조명 변화에 강하지만, 센서가 고가이고 텍스처 정보가 부족하여 특징점이 유사한 긴 복도 등에서는 루프 폐쇄(Loop Closure, 출발점으로 돌아왔을 때 이를 인식하는 것)에 어려움을 겪을 수 있다.34</p>
</li>
<li>
<p><strong>Multi-Sensor Fusion SLAM:</strong> 카메라, LiDAR, IMU 등 여러 센서 데이터를 융합하여 SLAM을 수행하는 가장 진보된 방식이다. 각 센서의 장점을 취하고 단점을 보완하여 가장 강건하고 정밀한 결과를 제공한다. RTAB-Map과 같은 오픈소스 패키지들이 이러한 다중 센서 융합 SLAM을 지원하며, 복잡한 실내 환경 탐사에 성공적으로 적용되고 있다.37</p>
</li>
</ul>
<h3>4.3 의사결정(Decision-Making): AI 기반의 동적 과업 수행</h3>
<p>인식 기술을 통해 환경과 자신의 상태를 파악했다면, 다음 단계는 ’그래서 무엇을 할 것인가’를 결정하는 것이다. 자율 임무 드론의 의사결정 시스템은 사전에 프로그래밍된 단순한 규칙을 넘어, 임무의 목표와 현재 상황을 종합적으로 고려하여 최적의 행동을 선택한다.</p>
<ul>
<li>
<p><strong>자율성 스택 (Autonomy Stack):</strong> 이는 인식, 판단, 제어 기능을 통합한 하나의 거대한 소프트웨어 아키텍처다.33 사우스웨스트 연구소(SwRI)가 개발한 자율성 스택은 SLAM, 탐사 알고리즘, 의사결정 로직, 자동 조종, 컴퓨터 비전 분석 모듈을 유기적으로 결합하여, 인간이 접근하기 어려운 위험한 환경에서 방사능 물질 탐지와 같은 복잡한 임무를 자율적으로 수행한다.33</p>
</li>
<li>
<p><strong>동적 경로 재계획 및 과업 수행 로직:</strong> A* 알고리즘이 정적인 지도에서 최적 경로를 찾는다면, 자율 임무 드론은 SLAM으로 실시간 생성되는 동적인 지도 위에서 예상치 못한 장애물(예: 움직이는 구조대원)이나 변화하는 임무 조건(예: 새로운 화재 지점 발생)에 맞춰 경로를 끊임없이 수정해야 한다. 더 나아가, ‘특정 색상의 옷을 입은 사람을 찾으면 근접하여 신원을 확인하라’ 또는 ’교량의 균열이 5mm 이상으로 판단되면 상세 이미지를 3장 촬영하고 즉시 관제 센터로 전송하라’와 같은 복잡하고 조건적인 임무를 수행하기 위해 의사결정 트리(Decision Tree), 행동 트리(Behavior Tree), 혹은 강화학습(Reinforcement Learning)으로 훈련된 AI 모델이 사용된다.</p>
</li>
</ul>
<p>결론적으로, 자율 임무 기술 스택은 ’열린 세계’에 대응하기 위한 ’인식-판단-행동’의 순환 루프를 구축하는 과정이다. 자율 비행 기술의 ‘닫힌 세계’ 한계를 극복하기 위해, 드론은 SLAM과 센서 융합을 통해 미지의 환경 정보를 스스로 수집하고(인식), 수집된 정보를 임무 목표라는 맥락 속에서 AI로 해석하여 ’지금 무엇을 해야 하는가’를 결정하며(판단), 결정된 행동을 PID 제어기와 같은 저수준 제어기를 통해 물리적으로 실행한다(행동). 이 세 단계는 지속적으로 순환하며 예측 불가능한 환경 변화에 적응하고 궁극적으로 임무를 완수해 나간다. 따라서 자율 임무 드론의 핵심은 개별 기술의 성능이 아닌, 이 순환 루프를 얼마나 빠르고, 정확하며, 강건하게 구축하는가라는 시스템 아키텍처의 문제로 귀결된다.</p>
<h2>5.  활용 사례를 통한 비교 분석: 정밀 농업에서 수색 구조까지</h2>
<p>자율 비행 드론과 자율 임무 드론의 개념적, 기술적 차이는 실제 활용 사례를 통해 가장 명확하게 드러난다. 자율 비행 드론은 주로 예측 가능하고 구조화된 환경에서 인간의 작업을 자동화하여 효율성과 정밀도를 극대화하는 데 사용되는 반면, 자율 임무 드론은 인간의 접근이 어렵거나 위험한 비구조적 환경에서 복잡한 과업을 자율적으로 수행하는 데 그 가치가 있다.</p>
<h3>5.1 자율 비행 드론의 주요 활용 분야: 효율성과 정밀도의 극대화</h3>
<p>자율 비행 드론의 활용은 대부분 사전에 계획된 경로를 정밀하게 비행하는 능력에 기반한다.</p>
<ul>
<li>
<p><strong>정밀 농업 (Precision Agriculture):</strong> 농업 분야는 자율 비행 드론의 가장 대표적인 활용처다. 드론은 사전에 생성된 농경지 지도나 설정된 비행 경로를 따라 비료, 농약, 종자 등을 정확하게 살포한다.41 이는 고령화로 인한 농촌 노동력 부족 문제를 해결하고, 사람이 직접 농약에 노출되는 위험을 줄여준다.43 또한, 필요한 지역에만 정밀하게 살포함으로써 농약 및 비료 사용량을 최대 50%까지 절감하고, 수질 및 토양 오염을 방지하는 등 환경 보호에도 기여한다.44 다중 스펙트럼(Multispectral) 카메라를 장착한 드론은 작물의 생육 상태를 나타내는 식생 지수(NDVI 등)를 측정하여 지도로 만들고, 농부는 이 데이터를 분석하여 특정 구역에 대한 처방(예: 추가 비료 살포)을 내릴 수 있다.42 이 과정에서 비행 자체는 자동화되어 있지만, 데이터를 분석하고 다음 작업을 계획하는 의사결정은 여전히 인간의 개입을 필요로 하는 경우가 많다.</p>
</li>
<li>
<p><strong>매핑 및 측량:</strong> 광활한 지역이나 접근이 어려운 지형을 대상으로 정해진 격자무늬 경로를 따라 비행하며 수백, 수천 장의 고해상도 항공 이미지를 촬영한다. 이 이미지들은 후처리 소프트웨어를 통해 정사사진(Orthophoto), 디지털 표면 모델(DSM), 3D 모델 등으로 변환되어 건설 현장의 공정 관리, 지적 측량, 재해 지역 피해 규모 산정 등에 활용된다.1 이 작업의 핵심은 ‘빠짐없이, 일정한 간격으로’ 비행하는 것으로, 자율 비행 기술의 정밀성과 반복 수행 능력이 극대화되는 분야다.</p>
</li>
</ul>
<h3>5.2 자율 임무 드론의 주요 활용 분야: 인간의 접근이 어렵거나 위험한 환경에서의 임무 수행</h3>
<p>자율 임무 드론은 예측 불가능한 상황에서 실시간으로 판단하고 대응하는 능력을 바탕으로 새로운 가치를 창출한다.</p>
<ul>
<li>
<p><strong>수색 및 구조 (Search &amp; Rescue):</strong> 재난 현장은 자율 임무 드론의 역량이 가장 절실히 요구되는 곳이다. 열화상 카메라와 AI 컴퓨터 비전을 탑재한 드론은 광범위한 산악 지대나 붕괴된 건물 잔해 속에서 조난자의 미세한 열 신호(heat signature)를 실시간으로 탐지할 수 있다.48 특히, 울산소방본부가 시연한 ’AI 기반 드론 인명구조·수색 시스템’은 자율 임무의 전형적인 사례를 보여준다. 이 시스템은 단순히 정해진 경로를 비행하는 것을 넘어, 지형 및 기후 데이터를 분석하여 최적의 수색 경로를 동적으로 ’추천’하고, 드론이 촬영하는 영상을 실시간으로 분석하여 조난자로 의심되는 객체를 ’자동으로 탐지’하여 구조대의 골든타임 확보에 기여한다.51</p>
</li>
<li>
<p><strong>인프라 검사:</strong> 발전소, 교량, 송전탑, 풍력 터빈 블레이드와 같은 거대하고 복잡한 구조물을 검사하는 작업은 위험하고 많은 시간이 소요된다. 자율 임무 드론은 이러한 구조물의 표면을 따라 자율적으로 비행하며 SLAM 기술로 정밀한 3D 모델을 생성하고, 고해상도 카메라와 컴퓨터 비전 알고리즘을 이용해 균열, 부식, 볼트 풀림과 같은 결함을 자동으로 탐지하고 그 위치를 정확히 기록한다.1 이는 검사의 정확성과 안전성을 획기적으로 향상시킨다.</p>
</li>
<li>
<p><strong>군사 및 국방:</strong> GPS 신호가 교란되거나 차단되는 적대적 환경에서 정찰, 감시, 표적 식별 및 추적과 같은 동적인 임무를 수행하는 것은 자율 임무 드론의 핵심 응용 분야다.1 안두릴(Anduril)의 드론은 온보드 AI를 사용하여 다른 아군 시스템과 실시간으로 통신하고 협력하며, 인간의 개입 없이 자율적으로 임무를 완수하도록 설계되었다.32</p>
</li>
<li>
<p><strong>자율 배송:</strong> 아마존 프라임 에어의 MK30 드론은 복잡한 도심 및 교외 환경에서 예측 불가능한 장애물(예: 전선, 나뭇가지, 날아다니는 새)을 실시간으로 감지하고 회피하며 최종 목적지의 안전한 착륙 지점까지 스스로 찾아 소포를 배송한다.32 이는 단순한 지점 간 이동을 넘어, 동적인 환경 변화에 대응하는 고도의 자율 임무 수행 능력을 요구한다.</p>
</li>
</ul>
<h3>5.3 [표 2] 자율 비행 드론과 자율 임무 드론의 핵심 특성 비교</h3>
<p>두 드론 유형의 본질적인 차이를 다각도에서 명확하게 대비시키면 아래 표와 같다. 이 표는 본 보고서에서 논의된 핵심 내용을 한눈에 파악할 수 있도록 요약한다.</p>
<table><thead><tr><th>구분</th><th>자율 비행 드론</th><th>자율 임무 드론</th></tr></thead><tbody>
<tr><td><strong>핵심 질문</strong></td><td>어떻게 날 것인가? (How to fly?)</td><td>무엇을 할 것인가? (What to do?)</td></tr>
<tr><td><strong>의사결정 주체</strong></td><td>사전 프로그래밍된 로직, 자동조종장치</td><td>온보드 AI, 실시간 추론 엔진</td></tr>
<tr><td><strong>주된 운용 환경</strong></td><td>구조화된 환경, 예측 가능한 시나리오 (농경지, 측량 구역)</td><td>비구조적 환경, 예측 불가능한 시나리오 (재난 현장, 실내, 적대 지역)</td></tr>
<tr><td><strong>핵심 기술 스택</strong></td><td>GPS, IMU, 자동조종장치, PID 제어, A* 경로 계획</td><td>SLAM, 컴퓨터 비전, LiDAR, 다중 센서 융합, 동적 경로 재계획, AI</td></tr>
<tr><td><strong>자율성 수준 (SAE)</strong></td><td>레벨 2 ~ 3 (부분/조건부 자동화)</td><td>레벨 4 ~ 5 (고등/완전 자율성)</td></tr>
<tr><td><strong>주요 응용 분야</strong></td><td>정밀 농업, 매핑 및 측량, 항공 촬영</td><td>수색 및 구조, 인프라 검사, 군사 정찰, 자율 배송</td></tr>
<tr><td><strong>데이터 처리 방식</strong></td><td>데이터 수집 후 후처리(Post-processing) 및 인간 분석</td><td>실시간 온보드 처리(On-board processing) 및 자율 판단</td></tr>
</tbody></table>
<p>이러한 비교를 통해, 자율 비행 드론과 자율 임무 드론은 단순히 자율성 수준의 높고 낮음으로 구분되는 상하 관계가 아니라, 각기 다른 목적과 기능에 따라 분화된 별개의 시스템이라는 점이 명확해진다. 자율 비행이 ’효율성’을 위한 도구라면, 자율 임무는 ’가능성’을 확장하는 도구라 할 수 있다.</p>
<h2>6.  결론: 기술 융합과 완전 자율 임무 드론의 도래</h2>
<p>본 보고서는 ’자율 비행 드론’과 ’자율 임무 드론’의 개념적, 기술적, 그리고 응용적 차이를 심층적으로 분석했다. 분석을 통해 두 시스템이 해결하고자 하는 근본적인 질문, 즉 ’어떻게 날 것인가’와 ’무엇을 할 것인가’의 차이에서 비롯된 기술 스택과 자율성 수준의 명확한 분기점을 확인했다.</p>
<h3>6.1 핵심 내용 요약</h3>
<p><strong>자율 비행 드론</strong>은 ’이동’의 문제에 대한 고도화된 자동화 솔루션이다. PID 제어기와 같은 고전 제어 이론과 A*와 같은 경로 탐색 알고리즘에 기반하여, 사전에 정의된 ’닫힌 세계’에서 안정적이고 효율적인 비행을 수행한다. 이 시스템의 가치는 정밀 농업, 측량, 매핑과 같이 구조화된 환경에서 인간의 반복적인 작업을 대체하여 생산성을 극대화하는 데 있다.</p>
<p>반면, <strong>자율 임무 드론</strong>은 ’과업’의 문제에 대한 지능형 자율 시스템이다. SLAM, 컴퓨터 비전, 센서 융합, AI 기반 의사결정으로 구성된 ’인식-판단-행동’의 순환 루프를 통해, 예측 불가능한 ’열린 세계’에 능동적으로 적응하며 복잡한 목표를 달성한다. 이 시스템은 수색 구조, 위험 시설 검사, 국방 등 인간이 직접 수행하기 어렵거나 불가능한 영역에서 새로운 가능성을 열어준다.</p>
<h3>6.2 미래 전망: 기술 융합과 진화</h3>
<p>현재의 ‘자율 비행’ 기술은 ’자율 임무’를 실현하기 위한 필수적인 기반 기술이다. 안정적인 비행 제어와 경로 추종 능력 없이는 어떠한 고차원적인 임무도 수행할 수 없기 때문이다. 미래의 드론 기술은 이 두 영역의 경계를 허물며 융합하는 방향으로 진화할 것이다.</p>
<ul>
<li>
<p><strong>엣지 컴퓨팅(Edge Computing)의 발전:</strong> 강력한 온보드 프로세서의 등장은 드론이 클라우드의 도움 없이 자체적으로 SLAM, 실시간 객체 탐지, 상황 판단 등 복잡한 AI 연산을 수행하는 것을 가능하게 할 것이다.36 이는 통신 음영 지역에서의 완전한 자율 임무 수행 능력을 보장한다.</p>
</li>
<li>
<p><strong>차세대 통신 기술(5G/6G):</strong> 초고속, 초저지연 통신은 드론이 방대한 센서 데이터를 실시간으로 클라우드 AI 플랫폼에 전송하여 더 정교한 분석과 판단을 지원받게 할 것이다. 또한, 이는 여러 드론이 서로 협력하여 임무를 수행하는 군집 임무(Swarm Missions)를 실현하는 핵심 기반이 될 것이다.</p>
</li>
</ul>
<p>궁극적으로 ’자율 비행’과 ’자율 임무’의 구분은 점차 희미해질 것이다. 미래의 모든 드론은 일정 수준의 자율 비행 능력을 기본으로 탑재하고, 그 위에 수행하고자 하는 임무의 복잡도에 따라 다양한 수준의 자율 임무 스택을 선택적으로 탑재하는 모듈형 아키텍처로 발전할 가능성이 높다.</p>
<h3>6.3 완전 자율 임무 드론의 도래와 새로운 과제</h3>
<p>레벨 5 수준의 완전 자율 임무 드론의 도래는 단순한 기술적 진보를 넘어, 사회 전반에 걸친 패러다임 전환을 의미한다.4 이러한 시스템은 인간의 개입 없이 스스로 판단하고 행동할 수 있는 능력을 갖추게 되며, 이는 기술적 문제를 넘어서는 심각한 사회적, 윤리적, 법규적 합의를 요구한다. 예를 들어, 군사 작전 중인 자율 임무 드론이 내리는 치명적인 결정의 책임은 누구에게 있는가? 재난 현장에서 여러 조난자 중 구조의 우선순위를 스스로 판단할 때 어떤 윤리적 기준을 따라야 하는가? 자율 시스템의 오작동으로 인한 사고 발생 시, 그 법적 책임은 제조사, 소프트웨어 개발자, 운영자 중 누가 져야 하는가?</p>
<p>이러한 질문들에 대한 사회적 논의와 제도적 기반 마련이 기술의 발전 속도를 따라가지 못할 경우, 이는 완전 자율 임무 드론의 상용화를 가로막는 가장 큰 병목 현상이 될 것이다. 따라서 미래 자율 드론 시대를 준비하기 위해서는 기술 개발과 더불어, 기술이 사회에 미칠 영향을 예측하고 이에 대한 규범과 제도를 수립하는 노력이 병행되어야 한다. 기술의 진정한 가치는 그것이 인간 사회와 조화롭게 융합될 때 비로소 완성될 수 있다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>The Ultimate Guide to Autonomous Drones: Benefits, Applications, and Top Models - JOUAV, https://www.jouav.com/blog/autonomous-drones.html</li>
<li>Drone Autonomous Flight - Grupo UAS, https://grupo-uas.com/en/autonomous-flight-drones-what-are-they/</li>
<li>Autonomous and Unmanned Systems | Lockheed Martin, https://www.lockheedmartin.com/en-us/capabilities/autonomous-unmanned-systems.html</li>
<li>Autonomous Aerial Vehicles &amp; Drones | UAVs for Autonomous Flight, https://www.unmannedsystemstechnology.com/expo/autonomous-aerial-vehicles/</li>
<li>Unmanned aerial vehicle - Wikipedia, https://en.wikipedia.org/wiki/Unmanned_aerial_vehicle</li>
<li>드론 타고 출근하는 세상 올까, https://www.kdrm.kr/news/articleView.html?idxno=499470</li>
<li>6단계의 자율주행 레벨 설명 | korean - Wandb, https://wandb.ai/wandb_fc/korean/reports/6—Vmlldzo3MTU2NzI4</li>
<li>꿈의 자율주행, 자율주행차의 각 단계별 차이를 알려드립니다! - NVIDIA Blog Korea, https://blogs.nvidia.co.kr/blog/whats-difference-level-2-level-5-autonomy/</li>
<li>당신이 잘못 알고 있는 자율주행의 핵심 개념 - 바이라인네트워크, https://byline.network/2022/09/5-124/</li>
<li>레벨4 자율주행차 시대 막 오른다 - 지디넷코리아, https://zdnet.co.kr/view/?no=20250823160904</li>
<li>美 엑사인, ‘레벨 4A’ 자율성 갖춘 드론 기술 개발 - 로봇신문, https://www.irobotnews.com/news/articleView.html?idxno=24731</li>
<li>PID 제어기 원리 - velog, <a href="https://prod.velog.io/@dosigner/PID-%EC%A0%9C%EC%96%B4%EA%B8%B0-%EC%9B%90%EB%A6%AC">https://prod.velog.io/@dosigner/PID-%EC%A0%9C%EC%96%B4%EA%B8%B0-%EC%9B%90%EB%A6%AC</a></li>
<li>PID 제어기 - 위키백과, 우리 모두의 백과사전, <a href="https://ko.wikipedia.org/wiki/PID_%EC%A0%9C%EC%96%B4%EA%B8%B0">https://ko.wikipedia.org/wiki/PID_%EC%A0%9C%EC%96%B4%EA%B8%B0</a></li>
<li>PID 제어를 이용한 드론의 위치 제어 - Do IT - 티스토리, https://dank-code.tistory.com/23</li>
<li>[ZMR250] 5. 기체 PID 제어하기 - Dongglee - 티스토리, https://chigun.tistory.com/30</li>
<li>Proportional–integral–derivative controller - Wikipedia, <a href="https://en.wikipedia.org/wiki/Proportional%E2%80%93integral%E2%80%93derivative_controller">https://en.wikipedia.org/wiki/Proportional%E2%80%93integral%E2%80%93derivative_controller</a></li>
<li>Discrete-time PID Controller Implementation - Scilab, https://www.scilab.org/discrete-time-pid-controller-implementation</li>
<li>3.4 Discretizing a PID controller - TechTeach, https://techteach.no/fag/sesm3401/h08/pid_diskret/tidsdiskret_pid_reg.pdf</li>
<li>[로봇공학] PID 제어 (Proportional-Integral-Differential control) - For a better world - 티스토리, https://roytravel.tistory.com/403</li>
<li>지글로 니콜스(Ziegler-Nichols)방법으로 드론 PID 튜닝하는 과정 - mj_devlog - 티스토리, <a href="https://alswo471.tistory.com/entry/%EC%A7%80%EA%B8%80%EB%A1%9C-%EB%8B%88%EC%BD%9C%EC%8A%A4Ziegler-Nichols%EB%B0%A9%EB%B2%95%EC%9C%BC%EB%A1%9C-%EB%93%9C%EB%A1%A0-PID-%ED%8A%9C%EB%8B%9D%ED%95%98%EB%8A%94-%EA%B3%BC%EC%A0%95">https://alswo471.tistory.com/entry/%EC%A7%80%EA%B8%80%EB%A1%9C-%EB%8B%88%EC%BD%9C%EC%8A%A4Ziegler-Nichols%EB%B0%A9%EB%B2%95%EC%9C%BC%EB%A1%9C-%EB%93%9C%EB%A1%A0-PID-%ED%8A%9C%EB%8B%9D%ED%95%98%EB%8A%94-%EA%B3%BC%EC%A0%95</a></li>
<li>en.wikipedia.org, <a href="https://en.wikipedia.org/wiki/A*_search_algorithm#:~:text=Specifically%2C%20A*%20selects%20the%20path,heuristic%20function%20is%20problem-specific.">https://en.wikipedia.org/wiki/A*_search_algorithm#:~:text=Specifically%2C%20A*%20selects%20the%20path,heuristic%20function%20is%20problem%2Dspecific.</a></li>
<li>The A* Algorithm: A Complete Guide - DataCamp, https://www.datacamp.com/tutorial/a-star-algorithm</li>
<li>A* Algorithm: A Comprehensive Guide - Simplilearn.com, https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/a-star-algorithm</li>
<li>A* 탐색 알고리즘 - CodeSnap, https://codesnapmag.hashnode.dev/a-star-algorithm</li>
<li>[인공지능]탐색(Search) - AI/Engineering - 티스토리, <a href="https://ralp0217.tistory.com/entry/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%ED%83%90%EC%83%89Search">https://ralp0217.tistory.com/entry/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%ED%83%90%EC%83%89Search</a></li>
<li>[23-01/인공지능] 문제해결 및 탐색전략 - 2, https://kne-coding.tistory.com/199</li>
<li>Algorithm A* is a best-first search algorithm that relies on an open list and a closed list to find a path that is both optimal and complete towards the goal. It works by combining the benefits of the uniform-cost search and greedy search algorithms. A* makes use of both elements by including two separate path finding functions in its algorithm that take into account the cost from the root node to the current node and estimates the path cost from the current node to the goal node. - Stanford Computer Science, https://cs.stanford.edu/people/eroberts/courses/soco/projects/2003-04/intelligent-search/astar.html</li>
<li>Heuristics - Stanford CS Theory, http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html</li>
<li>[Algorithm] A* 알고리즘 : 최단 경로 탐색, https://kangworld.tistory.com/61</li>
<li>Unitlab AI의 드론 산업 솔루션 – 항공 영상 분석, 객체 추적, 지형 인식 등을 위한 고정밀 데이터 주석 자동화 플랫폼., https://unitlab.ai/ko-kr/solutions/drones</li>
<li>비전 AI 완벽 가이드: 이미지 인식부터 구글 비전까지 모든 것 - 한국딥러닝, https://www.koreadeep.com/blog/vision-ai-guide</li>
<li>AI 드론: 실제 컴퓨터 비전 애플리케이션 - Ultralytics, https://www.ultralytics.com/ko/blog/computer-vision-applications-ai-drone-uav-operations</li>
<li>HYUNDAI NGV - 현대엔지비, http://www.hyundai-ngv.com/information/mobilitytrend_view.do?bbsIdx=349</li>
<li>A Review of Research on SLAM Technology Based on the Fusion of LiDAR and Vision, https://www.mdpi.com/1424-8220/25/5/1447</li>
<li>[논문]드론 자율비행 기술 동향 - 한국과학기술정보연구원, https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=JAKO202153150644135</li>
<li>Drone Autonomous Visual SLAM - Meegle, https://www.meegle.com/en_us/topics/autonomous-drones/drone-autonomous-visual-slam</li>
<li>Sensor Fusion for Autonomous Indoor UAV Navigation in Confined Spaces - arXiv, https://arxiv.org/html/2410.20599v1</li>
<li>What Is SLAM (Simultaneous Localization and Mapping)? - MATLAB &amp; Simulink, https://www.mathworks.com/discovery/slam.html</li>
<li>Simultaneous localization and mapping - Wikipedia, https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping</li>
<li>Simultaneous Localization and Mapping (SLAM) and Data Fusion in Unmanned Aerial Vehicles: Recent Advances and Challenges - ResearchGate, https://www.researchgate.net/publication/359593476_Simultaneous_Localization_and_Mapping_SLAM_and_Data_Fusion_in_Unmanned_Aerial_Vehicles_Recent_Advances_and_Challenges</li>
<li>농업 지원에 대한 AI 도입 활용 사례 7선 - IRS글로벌, https://www.irsglobal.com/bbs/rwdboard/20036</li>
<li>ICT 기술을 적용한 다목적 정밀농업용 자율비행 드론 플랫폼 연구 - KISS, https://kiss.kstudy.com/Detail/Ar?key=3834687</li>
<li>드론의 농업적 활용 - 농촌진흥청, https://www.rda.go.kr/middlePopOpenPopNongsaroDBView.do?no=1404&amp;sj</li>
<li>스마트 농업의 드론 기술과 정밀 농업의 결합, https://idea-hub.co.kr/44</li>
<li>(PDF) Precision Farming with Drone Sprayers: A Review of Auto Navigation and Vision-Based Optimization - ResearchGate, https://www.researchgate.net/publication/391519617_Precision_Farming_with_Drone_Sprayers_A_Review_of_Auto_Navigation_and_Vision-Based_Optimization</li>
<li>Drone Spraying: Boost Yields With UAV Survey &amp; GenAI Apps - Farmonaut, https://farmonaut.com/precision-farming/drone-spraying-7-shocking-ways-it-grows-your-yields</li>
<li>Drone-assisted agronomy: Monitoring, spraying and precision application in the field, https://www.agronomyjournals.com/archives/2025/vol8issue6/PartI/8-6-102-805.pdf</li>
<li>구조 서비스 - DJI, https://enterprise.dji.com/kr/public-safety/rescue-services</li>
<li>Drone Thermal Imaging for Inspections - UAVSphere, https://www.uavsphere.com/post/drone-thermal-imaging-for-inspections</li>
<li>DEVELOPMENT OF UAVs/DRONES EQUIPPED WITH THERMAL SENSORS FOR THE SEARCH OF INDIVIDUALS LOST UNDER RUBBLE DUE TO EARTHQUAKE COLLA, https://www.icas.org/icas_archive/icas2024/data/papers/icas2024_1093_paper.pdf</li>
<li>AI 드론으로 실시간 인명 수색·구조…“골든타임 확보” - 재난사고뉴스 …, <a href="https://www.nfa.go.kr/nfa/news/disasterNews/?boardId=bbs_0000000000001896&amp;mode=view&amp;cntId=222646&amp;category&amp;pageIdx=3">https://www.nfa.go.kr/nfa/news/disasterNews/?boardId=bbs_0000000000001896&amp;mode=view&amp;cntId=222646&amp;category=&amp;pageIdx=3</a></li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>