<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2025년 11월 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2025년 11월 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2025년 AI 및 로봇 연구 동향</a> / <span>2025년 11월 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2025년 11월 로봇 연구 동향</h1>
<h2>1.  서론: 로봇 공학의 새로운 패러다임, 물리적 지능의 구체화</h2>
<p>2025년 11월은 로봇 공학 역사에서 중요한 분기점으로 기록될 전망이다. 서울에서 공동 개최된 **CoRL 2025 (Conference on Robot Learning)**와 <strong>Humanoids 2025</strong>는 전 세계 로봇 연구자들의 이목을 집중시켰으며, <em>Science Robotics</em>, <em>IEEE Transactions on Robotics (T-RO)</em> 등 주요 학술지를 통해 발표된 연구들은 로봇이 단순한 자동화 기계에서 ’물리적 지능(Physical Intelligence)’을 갖춘 에이전트로 진화하고 있음을 증명했다.1</p>
<p>과거의 로봇 연구가 특정 작업에 국한된 제어 알고리즘이나 제한된 환경에서의 인식 기술에 머물렀다면, 이번 11월에 발표된 연구들은 **파운데이션 모델(Foundation Models)**의 로봇 적용, <strong>동적 환경에서의 적응형 제어</strong>, 그리고 <strong>대규모 산업 현장에서의 실증</strong>이라는 세 가지 거대한 흐름을 형성하고 있다. 특히 Amazon Robotics가 공개한 대규모 다중 에이전트 모델은 로봇 데이터 학습의 규모를 인터넷 스케일로 확장하려는 시도를 보여주며, Figure AI와 BMW의 협력 사례는 휴머노이드 로봇이 실험실을 벗어나 실제 제조 라인(Brownfield)에서 인간과 협업할 수 있는 수준에 도달했음을 수치적으로 입증했다.</p>
<p>본 보고서는 2025년 11월에 발표된 핵심적인 학술 논문과 산업계의 기술적 성과를 심층적으로 분석한다. 각 장에서는 연구의 배경과 방법론, 수학적 원리, 그리고 이것이 로봇 생태계에 미칠 파급 효과를 상세히 기술한다. 모든 분석은 공개된 연구 자료와 논문에 기반하며, 기술적 깊이를 확보하기 위해 관련 수식과 아키텍처를 구체적으로 논한다.</p>
<h2>2.  파운데이션 모델과 다중 에이전트 시스템의 진화</h2>
<p>로봇 공학에서 ’파운데이션 모델’의 도입은 오랫동안 논의되어 온 주제이나, 2025년 11월 Amazon Robotics가 발표한 연구는 그 실체를 명확히 보여준 사례로 평가받는다. 수십만 대의 로봇이 실시간으로 상호작용하는 물류 환경은 기존의 중앙 집중식 경로 계획 알고리즘의 한계를 시험하는 무대였으며, 이를 해결하기 위한 데이터 기반의 접근법은 향후 자율주행 차량 군집 제어와 스마트 시티 운영에 중요한 이론적 토대를 제공한다.</p>
<h3>2.1  DeepFleet: 대규모 로봇 군집을 위한 파운데이션 모델</h3>
<p>Amazon Robotics의 연구진이 발표한 **“DeepFleet: Multi-Agent Foundation Models for Mobile Robots”**는 전 세계 Amazon 풀필먼트 센터(Fulfillment Center)와 분류 센터(Sortation Center)에서 수집된 수백만 시간 분량의 로봇 이동 데이터를 활용하여 구축된 모델이다.4 이 연구의 핵심은 로봇의 위치, 목표, 상호작용 데이터를 학습하여 미래의 교통 흐름을 예측하고, 이를 통해 최적의 경로 조정과 혼잡 관리를 수행하는 것이다.</p>
<h4>2.1.1  네 가지 아키텍처의 설계 공간 탐색</h4>
<p>연구진은 다중 에이전트 모델링을 위해 서로 다른 귀납적 편향(Inductive Bias)을 가진 네 가지 아키텍처를 설계하고 비교 분석했다. 이는 로봇 제어 문제를 해결하는 데 있어 ’어떤 정보 표현(Representation)이 가장 효율적인가’에 대한 근본적인 질문을 던진다.</p>
<table><thead><tr><th style="text-align: left">모델 명칭 (Architecture)</th><th style="text-align: left">핵심 기술 (Core Tech)</th><th style="text-align: left">입력 데이터 표현 (Input Representation)</th><th style="text-align: left">특징 및 장점</th></tr></thead><tbody>
<tr><td style="text-align: left">Robot-Centric (RC)</td><td style="text-align: left">Autoregressive Decision Transformer</td><td style="text-align: left">개별 로봇 중심의 이웃 상태 (Local Neighborhood)</td><td style="text-align: left">로봇 자신의 과거 상태와 주변 이웃 로봇 정보를 토큰화. 회전 및 평행 이동 불변성(Invariant)을 가지며 파라미터 효율성이 높음.</td></tr>
<tr><td style="text-align: left">Robot-Floor (RF)</td><td style="text-align: left">Transformer (Cross-Attention)</td><td style="text-align: left">로봇 특징 + 바닥(Floor) 특징</td><td style="text-align: left">로봇 토큰과 바닥 토큰 간의 교차 주의 메커니즘을 사용하여 전역적 맥락과 지역적 정보를 결합.</td></tr>
<tr><td style="text-align: left">Image-Floor (IF)</td><td style="text-align: left">CNN Encoder + Transformer</td><td style="text-align: left">다중 채널 이미지 (Grid Image)</td><td style="text-align: left">전체 바닥을 이미지 그리드로 변환하여 CNN으로 인코딩. 시공간적 패턴을 이미지 처리 방식으로 접근하나 통신 지연에 취약할 수 있음.</td></tr>
<tr><td style="text-align: left">Graph-Floor (GF)</td><td style="text-align: left">Graph Neural Network (GNN)</td><td style="text-align: left">공간 그래프 (Spatial Graph)</td><td style="text-align: left">로봇 간의 관계와 공간적 위상을 그래프로 모델링. 시간적 주의 메커니즘을 결합하여 동적 관계 학습에 유리함.</td></tr>
</tbody></table>
<p>4</p>
<h4>2.1.2  Robot-Centric (RC) 모델의 수학적 구조</h4>
<p>가장 우수한 성능을 보인 <strong>Robot-Centric (RC)</strong> 모델은 결정 트랜스포머(Decision Transformer) 구조를 기반으로 한다. 이 모델은 로봇 <span class="math math-inline">i</span>의 시점(Ego-centric view)에서 주변 환경을 관찰하고 다음 행동을 예측한다.</p>
<p>예측 목표(Forecasting Objective)는 과거 윈도우 <span class="math math-inline">K</span> 동안의 관측 시퀀스 <span class="math math-inline">S_{t-K:t}</span>와 행동 시퀀스 <span class="math math-inline">A_{t-K:t-1}</span>가 주어졌을 때, 미래의 행동 분포를 추정하는 것이다. RC 모델의 손실 함수(Loss Function)는 에이전트 모델링 손실(Agent Modeling Loss, <span class="math math-inline">L_{AM}</span>)로 정의되며, 이는 관측 재구성 오차와 행동 예측 오차의 합으로 표현된다.5</p>
<p><span class="math math-display">
L_{AM} = L_{MSE}(\hat{o}_{-1, m_t}, o_{-1, m_t}) + \frac{1}{N-1} \sum_{i=0}^{N-1} L_{CE}(\hat{a}_{i, m_t}, a_{i, m_t})
</span><br />
여기서:</p>
<ul>
<li><span class="math math-inline">L_{MSE}</span>는 주변 환경 관측값(예: 이웃 로봇의 위치)의 재구성 오차(Mean Squared Error)를 의미한다.</li>
<li><span class="math math-inline">L_{CE}</span>는 다음 행동 <span class="math math-inline">a_{i, m_t}</span>에 대한 교차 엔트로피(Cross-Entropy) 오차이다. 로봇의 행동 공간은 이산화(Discrete)되어 있거나, 가속도/회전각 등의 연속 공간일 수 있으며, 이 연구에서는 물류 로봇의 특성상 이동 명령을 분류 문제로 접근하거나 궤적의 근사치를 추정한다.</li>
</ul>
<h4>2.1.3  연구 결과 및 시사점</h4>
<p>실험 결과, <strong>Robot-Centric (RC)</strong> 모델과 <strong>Graph-Floor (GF)</strong> 모델이 Image-Floor (IF) 모델보다 우수한 성능을 보였다. 이는 다음과 같은 중요한 통찰을 제공한다:</p>
<ol>
<li><strong>비동기성의 수용:</strong> 실제 로봇 시스템은 통신 지연으로 인해 모든 로봇의 상태를 완벽하게 동기화하여 ’스냅샷’을 찍기 어렵다. RC와 GF 모델은 개별 로봇이 비동기적으로 수집한 정보를 바탕으로 추론하므로 현실적인 배포 환경에 더 적합하다.4</li>
<li><strong>파라미터 효율성:</strong> RC 모델은 약 9,700만(97M) 개의 파라미터만으로도 9억(900M) 개 이상의 파라미터를 가진 IF 모델과 대등하거나 더 나은 성능을 보였다. 이는 로봇 간의 상호작용이 국소적(Local) 범위에서 주로 결정된다는 물리적 특성을 모델 구조에 잘 반영했기 때문이다.5</li>
<li><strong>데이터 확장성:</strong> 데이터셋의 크기를 늘릴수록 RC 모델의 성능 향상 폭이 두드러졌다. 이는 자율주행 차량이나 드론 스웜과 같이 개체 수가 무한히 늘어날 수 있는 시스템에서 에이전트 중심의 분산 처리 방식이 확장성(Scalability) 측면에서 유리함을 시사한다.4</li>
</ol>
<p>DeepFleet 연구는 로봇 공학에서 ’데이터의 양’이 어떻게 ’질적 전환’을 가져오는지를 보여주는 사례로, 향후 로봇 관제 시스템이 규칙 기반(Rule-based)에서 학습 기반(Learning-based)으로 전환되는 기폭제가 될 것이다.</p>
<h2>3.  동적 비정형 환경에서의 강건한 제어와 인식</h2>
<p>비정형 환경, 즉 장애물이 움직이거나 예측 불가능한 변화가 발생하는 공간에서의 로봇 제어는 여전히 난제로 남아있다. 11월에는 이러한 문제를 해결하기 위해 전통적인 인식 파이프라인을 우회하거나, 복잡한 비선형 역학을 선형화하여 해결하는 획기적인 연구들이 발표되었다.</p>
<h3>3.1  NavRL: 인식과 제어의 통합</h3>
<p>드론과 같은 고속 이동체가 복잡한 환경(Cluttered Environment)을 비행할 때, 기존의 ‘감지(Detection) <span class="math math-inline">\rightarrow</span> 추적(Tracking) <span class="math math-inline">\rightarrow</span> 예측(Prediction) <span class="math math-inline">\rightarrow</span> 계획(Planning)’ 파이프라인은 연산 지연(Latency)과 누적 오차 문제를 야기한다. <strong>“Flow-Aided Flight Through Dynamic Clutters From Point To Motion”</strong> (IEEE Robotics and Automation Letters 수락) 논문은 이러한 단계를 과감히 생략하고, 센서 데이터로부터 제어 명령을 직접 생성하는 End-to-End 강화학습 접근법을 제안했다.8</p>
<h4>3.1.1  Point-to-Motion 알고리즘</h4>
<p>이 연구의 핵심은 LiDAR 점군(Point Cloud) 데이터를 효율적으로 압축하여 상황을 인지하는 두 가지 표현법에 있다.</p>
<ol>
<li><strong>Distance Map (<span class="math math-inline">D</span>):</strong> 원시 점군 데이터를 인코딩하여 생성한 저해상도 깊이 지도이다. 이는 정적 장애물의 형상을 파악하는 데 사용되며, 계산 비용이 매우 낮다.</li>
<li><strong>Point Flow (<span class="math math-inline">F</span>):</strong> 연속된 프레임 간의 점군 변화를 추적하여 환경 내의 ’움직임’을 벡터 필드 형태로 추출한 것이다. 이는 명시적으로 물체를 식별(Object Recognition)하지 않고도, 어떤 영역이 ’위험하게 다가오는지’를 인지하게 한다.9</li>
</ol>
<h4>3.1.2  상대 운동 변조 거리 필드 (Relative Motion Modulated Distance Field)</h4>
<p>연구진은 강화학습 에이전트가 동적 장애물을 효과적으로 회피하도록 유도하기 위해, 물리적 직관을 반영한 새로운 거리 필드 개념을 도입했다. 장애물과 드론 사이의 상대적인 운동 관계를 수식화하여 위험도에 가중치를 부여하는 방식이다.</p>
<p>장애물의 위치 <span class="math math-inline">p_{dobs}</span>, 속도 <span class="math math-inline">v_{dobs}</span>와 드론의 위치 <span class="math math-inline">p</span>, 속도 <span class="math math-inline">v</span>가 주어졌을 때, 충돌 위협을 나타내는 각도 <span class="math math-inline">\theta</span>는 다음과 같이 정의된다 10:<br />
<span class="math math-display">
\theta = \cos^{-1} \left( \frac{(p - p_{dobs}) \cdot (v_{dobs} - v)}{\Vert p - p_{dobs} \Vert \Vert v_{dobs} - v \Vert} \right)
</span><br />
이 각도 <span class="math math-inline">\theta</span>를 이용하여 거리 필드를 변조하는 계수 <span class="math math-inline">k</span>를 설정한다. 드론이 장애물의 진행 경로상에 위치할수록(즉, <span class="math math-inline">\theta</span>가 작을수록) 더 높은 페널티를 부여한다.</p>
<p><span class="math math-display">
k_v = \Vert v_{dobs} - v \Vert, \quad k_{\theta} = 1 - \frac{2\theta}{\pi}
</span><br />
이 수식은 드론이 단순히 장애물과의 유클리드 거리만을 유지하는 것이 아니라, 상대 속도 벡터를 고려하여 미래의 충돌 가능성이 높은 영역을 사전에 회피하도록 학습시킨다. 실험 결과, 이 시스템은 33개의 동적 장애물이 존재하는 고밀도 환경에서도 높은 생존율을 보였으며, 복잡한 연산 없이도 ’반사 신경’과 같은 회피 기동을 구현했다.10</p>
<h3>3.2  Koopman Operator: 접촉 역학의 전역 선형화</h3>
<p>로봇이 걷거나 물체를 조작할 때 발생하는 ’접촉(Contact)’은 시스템의 동역학을 불연속적이고 비선형적으로 만든다. 이를 제어하기 위해 기존에는 복잡한 비선형 최적화(Nonlinear Optimization)를 수행해야 했으나, 계산 비용이 높고 수렴을 보장하기 어려웠다. <strong>“Koopman global linearization of contact dynamics for robot locomotion and manipulation enables elaborate control”</strong> 논문은 이러한 비선형 시스템을 선형 시스템처럼 다룰 수 있게 하는 수학적 돌파구를 제시했다.12</p>
<h4>3.2.1  Control-Coherent Koopman (CCK) 모델링</h4>
<p>Koopman 연산자 이론은 비선형 시스템의 상태 <span class="math math-inline">x</span>를 관측 함수 <span class="math math-inline">g(x)</span>를 통해 무한 차원의 힐베르트 공간(Hilbert Space)으로 들어올려(Lift), 그 공간에서의 시간 발전(Evolution)이 선형 연산자에 의해 기술되도록 하는 이론이다. 하지만 기존 이론은 제어 입력 <span class="math math-inline">u</span>가 있는 시스템(Non-autonomous system)에 적용하기 어려웠다.</p>
<p>이 연구는 제어 입력이 구동기(Actuator) 역학에 선형적으로 작용한다는 물리적 특성에 착안하여 <strong>Control-Coherent Koopman (CCK)</strong> 모델을 제안했다. 시스템 상태를 구동기 상태 <span class="math math-inline">p_t</span>와 부하 상태 <span class="math math-inline">q_t</span>로 분리하면 다음과 같다:</p>
<p><span class="math math-display">
\begin{aligned} p_{t+1} &amp;= f_p(p_t, q_t) + B_p u_t \\ q_{t+1} &amp;= f_q(p_t, q_t) \end{aligned}
</span><br />
이러한 구조적 특성을 활용하면, 제어 입력에 대한 근사 없이도 다음과 같은 전역 선형 모델(Global Linear Model)을 유도할 수 있다.13</p>
<p><span class="math math-display">
z_{t+1} = A z_t + B u_t
</span><br />
여기서 <span class="math math-inline">z_t</span>는 리프팅된 고차원 상태 벡터이다.</p>
<h4>3.2.2  제어 이론적 의의</h4>
<p>이 방법론은 비볼록(Non-convex) 문제였던 접촉 제어 문제를 볼록(Convex) 모델 예측 제어(MPC) 문제로 변환시킨다. 이는 수학적으로 유일한 해(Global Optimum)를 보장하며, 실시간 제어가 가능함을 의미한다. 연구진은 이를 통해 로봇 팔이 물체를 밀거나(Pushing), 튕기거나(Shoving), 드리블하는 등의 고난도 조작 작업을 수행할 수 있음을 입증했다. 이는 딥러닝과 같은 블랙박스 모델에 의존하지 않고도, 해석 가능한(Explainable) 제어 이론을 통해 복잡한 물리적 상호작용을 제어할 수 있는 가능성을 열었다.15</p>
<h2>4.  언어 모델과 로봇 계획의 안전성 확보</h2>
<p>거대 언어 모델(LLM)은 로봇에게 자연어 명령을 이해하고 복잡한 작업을 계획(Planning)할 수 있는 능력을 부여했다. 그러나 LLM 특유의 ‘환각(Hallucination)’ 현상은 물리적 세계에서 작동하는 로봇에게 치명적인 안전사고를 유발할 수 있다. 11월 발표된 <strong>CoFineLLM</strong> 연구는 이 문제를 통계적 기법으로 해결하려는 시도이다.</p>
<h3>4.1  CoFineLLM: 등각 예측을 통한 신뢰성 확보</h3>
<p><strong>“CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning”</strong> 논문은 등각 예측(Conformal Prediction, CP) 기법을 LLM 파인튜닝 과정에 통합했다.16 등각 예측은 모델의 출력에 대해 특정 확률(예: 95%)로 정답을 포함하는 예측 집합(Prediction Set)을 생성하는 기법이다.</p>
<p>기존의 CP 적용 방식은 모델 학습이 완료된 후 후처리(Post-processing) 단계에서만 적용되었기에, 예측 집합의 크기가 지나치게 커지는(예: 가능한 모든 행동을 포함해버리는) 문제가 있었다. 예측 집합이 너무 크면 로봇은 결정을 내리지 못하고 사람에게 도움을 요청해야 하므로 자율성이 저하된다.</p>
<h4>4.1.1  CP-Aware Loss Function</h4>
<p>CoFineLLM은 학습 단계에서부터 예측 집합의 크기를 줄이도록 유도하는 손실 함수를 설계했다.</p>
<p><span class="math math-display">
\mathcal{L}(\theta, \delta) = \mathcal{L}_{base}(\theta) + \lambda \mathbb{E}_{(l, y) \sim \mathcal{D}} [\psi(p_\theta(y \vert l), \delta)]
</span></p>
<ul>
<li><span class="math math-inline">\mathcal{L}_{base}(\theta)</span>: 기본적인 언어 모델링 손실 함수.</li>
<li><span class="math math-inline">\lambda</span>: 페널티 가중치.</li>
<li><span class="math math-inline">\psi</span>: 예측 집합의 효율성을 측정하는 함수. 모델이 정답 행동 <span class="math math-inline">y</span>에 대해 임계값 <span class="math math-inline">\delta</span> 이상의 확신을 갖도록 유도한다.18</li>
</ul>
<h4>4.1.2  연구의 파급 효과</h4>
<p>이 연구는 로봇이 “모르겠다“라고 말해야 할 때와 “확신한다“라고 말할 때를 수학적으로 구분하게 해 준다. 실험 결과, CoFineLLM은 분포 이탈(Out-of-Distribution) 시나리오에서도 높은 성공률을 보였으며, 사람의 개입 빈도를 획기적으로 줄였다. 이는 LLM 기반 로봇이 가정이나 병원과 같이 안전이 중요한 환경에 진출하기 위한 필수적인 안전장치 기술로 평가된다.17</p>
<h2>5.  산업용 및 의료용 로봇의 정밀 제어 기술</h2>
<p>학술적 이론뿐만 아니라, 실제 산업 현장과 의료 현장에 즉시 적용 가능한 실용적인 제어 기술들도 다수 발표되었다.</p>
<h3>5.1  곡률 반경 기반 S-Curve 궤적 계획</h3>
<p>제조용 로봇 팔이 고속으로 움직일 때, 경로의 곡률(Curvature)이 큰 지점에서는 원심력으로 인해 진동이나 오차가 발생하기 쉽다. <em>Robotics</em> (MDPI) 11월호에 게재된 **“S-Curve Trajectory Planning for Industrial Robots Based on Curvature Radius”**는 이러한 문제를 해결하기 위한 알고리즘을 제안했다.20</p>
<p>이 연구는 경로의 기하학적 정보(곡률 반경)를 기반으로 속도 프로파일을 능동적으로 조절한다. 핵심 제약 조건은 다음과 같다:</p>
<ol>
<li>가속도 제약: <span class="math math-inline">\vert a(t) \vert \le a_{max}</span></li>
<li>저크(Jerk, 가속도 변화율) 제약: <span class="math math-inline">\vert j(t) \vert \le j_{max}</span></li>
<li>곡률 기반 속도 보정: <span class="math math-inline">v_{SPCorr}(s)</span></li>
</ol>
<p>알고리즘은 곡선 구간에 진입하기 전에 필요한 감속 거리 <span class="math math-inline">\Delta s</span>를 해석적으로 계산하여 미리 속도를 줄인다. 이는 레이저 절단, 디스펜싱(Dispensing), 정밀 용접과 같이 경로 추종 정확도가 품질을 결정하는 공정에서 생산 속도를 유지하면서도 품질 불량을 줄이는 데 기여한다.20</p>
<h3>5.2  토크 제한을 고려한 어드미턴스 제어</h3>
<p>협동 로봇(Cobot)은 사람과 접촉할 때 유연하게 반응해야 한다. *IEEE Transactions on Robotics (T-RO)*에 발표된 **“Torque-Bounded Task-Space Admittance Control for Redundant Manipulators”**는 여유 자유도(Redundant DoF)를 가진 로봇의 안전성을 높이는 기술이다.22</p>
<p>이 연구는 태스크 공간(Task Space)에서 작업을 수행하면서도, 관절 토크가 하드웨어의 물리적 한계를 초과하지 않도록 영공간(Null-space) 제어를 수행한다. 7자유도 Kinova Gen3 로봇을 이용한 실험에서, 로봇 팔이 완전히 펴진 특이점(Singularity) 상태에서도 불안정해지지 않고 안전하게 동작함을 증명했다. 이는 로봇과 작업자가 같은 공간을 공유하는 스마트 팩토리 환경에서 필수적인 기술이다.</p>
<h3>5.3  의료 로봇: S4RoboFormer 및 자기 제어</h3>
<p>의료 분야에서는 수술 로봇의 시각 지능을 높이는 연구가 주목받았다. <strong>S4RoboFormer</strong>는 수술 도구 분할(Segmentation)을 위해 픽셀 단위의 정밀 라벨링 대신, 스크리블(Scribble, 대략적인 선 긋기) 형태의 약지도 학습(Weakly-Supervised Learning)을 활용한다. 이는 의료 데이터 구축 비용을 획기적으로 낮출 수 있는 기술이다.24</p>
<p>또한, 캡슐 내시경과 같은 마이크로 로봇을 제어하기 위한 <strong>하이브리드 자기 구동(Hybrid-driven) 전략</strong>이 발표되었다. 영구 자석 액추에이터(ActPM)로 중력을 보상하여 로봇을 띄우고, 전자기 시스템(EMS)으로 정밀 제어하는 방식이다. 이를 통해 기존 전자기 코일 방식의 고질적인 문제인 발열과 전력 소모를 줄이면서도 정밀한 제어가 가능해졌다.25</p>
<h2>6.  산업 동향: 휴머노이드 로봇의 실질적 가치 입증</h2>
<p>2025년 11월은 휴머노이드 로봇이 연구개발(R&amp;D) 단계를 넘어 실제 산업 현장(Brownfield)에서 경제적 가치를 창출할 수 있음을 증명한 달이다.</p>
<h3>6.1  Figure AI와 BMW의 기념비적 성과</h3>
<p>Figure AI는 자사의 휴머노이드 로봇 <strong>Figure 02</strong>가 미국 스파르탄버그(Spartanburg) BMW 공장에서 달성한 운영 데이터를 공개했다. 이 데이터는 휴머노이드 로봇의 상용화 가능성에 대한 회의론을 불식시키는 강력한 증거가 되었다.26</p>
<table><thead><tr><th style="text-align: left">성과 지표 (Metric)</th><th style="text-align: left">수치 (Value)</th><th style="text-align: left">상세 내용 (Details)</th></tr></thead><tbody>
<tr><td style="text-align: left">총 운영 기간</td><td style="text-align: left">11개월</td><td style="text-align: left">초기 테스트 및 최적화 기간 포함</td></tr>
<tr><td style="text-align: left">누적 작업 시간</td><td style="text-align: left">1,250시간 이상</td><td style="text-align: left">월요일~금요일, 하루 10시간 교대 근무(Shift) 소화</td></tr>
<tr><td style="text-align: left">작업 물량</td><td style="text-align: left">90,000개 부품</td><td style="text-align: left">차체 섀시(Chassis) 조립을 위한 판금 부품 로딩</td></tr>
<tr><td style="text-align: left">생산 기여</td><td style="text-align: left">BMW X3 30,000대</td><td style="text-align: left">실제 양산 차량 생산에 직접 기여</td></tr>
<tr><td style="text-align: left">인간 개입률</td><td style="text-align: left">Zero (목표 달성)</td><td style="text-align: left">자율 동작 중 인간의 수정이나 재부팅 없이 연속 가동</td></tr>
</tbody></table>
<p>특히 ’판금 부품 삽입’은 0.1mm ~ 5mm 이내의 공차를 요구하는 정밀 작업이며, 이를 하루 10시간 동안 수행했다는 것은 로봇의 인식 정밀도뿐만 아니라 관절의 내구성, 배터리 관리, 열 제어 기술이 완성 단계에 이르렀음을 의미한다.</p>
<h3>6.2  Tesla Optimus와 Boston Dynamics의 행보</h3>
<p>Tesla는 Optimus 로봇의 양산 준비에 박차를 가하고 있다. 11월 업데이트를 통해 Tesla 차량 디스플레이에 Optimus를 통합하는 등 생태계 확장을 시도하고 있으며, 엘론 머스크는 2026년 양산, 2030년 연간 100만 대 생산 목표를 재확인했다.28 최근 공개된 영상에서는 Optimus가 사람의 원격 조종 데이터를 학습하여 자율적으로 작업을 수행하는 과정을 보여주며, Tesla의 자율주행 기술(FSD)이 로봇의 시각 운동 제어(Visuomotor Control)로 전이되고 있음을 강조했다.</p>
<p>Boston Dynamics는 산업용 소프트웨어 기업 IFS와의 파트너십을 통해 4족 보행 로봇 Spot을 자산 관리 솔루션의 일부로 편입시켰다.30 이는 로봇을 단품으로 판매하는 것을 넘어, 공장의 예지 보전(Predictive Maintenance) 데이터를 수집하는 IoT 센서 플랫폼으로 활용하려는 전략이다.</p>
<h3>6.3  1X Neo와 소비자용 휴머노이드</h3>
<p>노르웨이의 1X Technologies는 가정용 휴머노이드 <strong>Neo</strong>의 예약 주문을 시작하며 소비자 시장을 겨냥했다. 가격은 약 2만 달러(약 2,800만 원)대로 책정되었으며, 이는 휴머노이드 로봇이 자동차 한 대 가격으로 가정에 보급될 수 있는 시대를 예고한다.32</p>
<h2>7.  주요 컨퍼런스 및 학술 행사 동향</h2>
<p>11월은 로봇 학계의 주요 행사들이 집중된 시기였다.</p>
<ul>
<li><strong>CoRL 2025 (Conference on Robot Learning):</strong> 9월 말 서울에서 개최된 이래 11월까지 그 영향력이 이어지고 있다. 로봇 학습(Robot Learning) 분야의 최고 권위 학회로서, 올해는 시뮬레이션-리얼 전이(Sim-to-Real), 파운데이션 모델, 모방 학습(Imitation Learning)이 주요 주제로 다뤄졌다.1</li>
<li><strong>Humanoids 2025:</strong> CoRL과 서울 COEX에서 공동 개최(Co-located)되었다. 휴머노이드 로봇의 기구학적 설계와 제어, 그리고 인간과의 상호작용(HRI)이 집중적으로 논의되었으며, 한국 로봇 연구의 위상을 높이는 계기가 되었다.2</li>
<li><strong>IROS 2025 (International Conference on Intelligent Robots and Systems):</strong> 중국 항저우에서 10월 말 개최되어 11월까지 논의가 지속되었다. 세계 최대 규모의 로봇 학회 중 하나로, 지능형 로봇 시스템 전반에 걸친 방대한 연구가 발표되었다.36</li>
</ul>
<h2>8.  결론: 로봇 공학의 미래 전망</h2>
<p>2025년 11월의 연구 성과들을 종합해 볼 때, 로봇 공학은 **‘데이터(Data)’, ‘수학(Math)’, ‘실증(Real-world)’**이라는 세 가지 키워드로 요약될 수 있는 새로운 국면에 진입했다.</p>
<ol>
<li><strong>데이터의 규모가 지능을 만든다:</strong> Amazon의 DeepFleet 연구는 로봇 데이터의 규모가 커질수록 단순한 경로 계획을 넘어선 고차원적인 군집 지능이 창발됨을 보여주었다. 이는 향후 로봇 연구가 개별 알고리즘 개발에서 대규모 데이터셋 구축 및 학습 파이프라인 설계로 이동할 것임을 시사한다.</li>
<li><strong>수학적 엄밀성이 안전을 보장한다:</strong> Koopman Operator 이론과 CoFineLLM 연구는 AI의 불확실성을 수학적으로 제어하려는 노력의 결실이다. 이러한 기술들은 로봇이 인간의 생활 공간으로 들어오기 위한 필수 조건인 ’안전성 보증(Safety Guarantee)’을 가능하게 한다.</li>
<li><strong>실증이 가치를 증명한다:</strong> BMW 공장에서의 Figure 02 운영 결과는 휴머노이드 로봇이 더 이상 미래의 기술이 아니라, 당장 오늘날의 노동력 부족 문제를 해결할 수 있는 현실적인 대안임을 입증했다.</li>
</ol>
<p>결론적으로 2025년은 로봇 공학이 ’가능성 탐색’의 시기를 지나 ’본격적인 확산’의 시기로 넘어가는 원년으로 기록될 것이다. 연구자들은 더 거대한 모델과 더 정교한 제어 이론을 탐구할 것이며, 산업계는 이를 바탕으로 물리적 세계를 혁신하는 애플리케이션을 쏟아낼 것으로 전망된다.</p>
<h2>9. 참고 자료</h2>
<ol>
<li>CoRL 2025, https://www.corl.org/</li>
<li>Humanoids 2025 conference, https://2025humanoids.org/</li>
<li>Robotics Breakthroughs: 29 Papers from Nov 8, 2025 - YouTube, https://www.youtube.com/watch?v=-vbT2qCSIQE</li>
<li>[2508.08574] DeepFleet: Multi-Agent Foundation Models for Mobile Robots - arXiv, https://arxiv.org/abs/2508.08574</li>
<li>DeepFleet: Multi-Agent Foundation Models for Mobile Robots - arXiv, https://arxiv.org/html/2508.08574</li>
<li>DeepFleet: Multi-Agent Foundation Models for Mobile Robots - arXiv, https://arxiv.org/html/2508.08574v1</li>
<li>TransAM: Transformer-Based Agent Modeling for Multi-Agent Systems via Local Trajectory Encoding, https://rlj.cs.umass.edu/2025/papers/RLJ_RLC_2025_275.pdf</li>
<li>[2511.16372] Flow-Aided Flight Through Dynamic Clutters From Point To Motion - arXiv, https://arxiv.org/abs/2511.16372</li>
<li>Flow-Aided Flight Through Dynamic Clutters From Point To Motion - arXiv, https://arxiv.org/html/2511.16372v1</li>
<li>Flow-Aided Flight Through Dynamic Clutters From Point to Motion - IEEE Xplore, https://ieeexplore.ieee.org/iel8/7083369/11250609/11248899.pdf</li>
<li>Flow-Aided Flight Through Dynamic Clutters From Point To Motion - ResearchGate, https://www.researchgate.net/publication/397823894_Flow-Aided_Flight_Through_Dynamic_Clutters_From_Point_To_Motion</li>
<li>koopman operator theory: fundamentals, approximations and applications 2 - UNIRI, https://uniri.hr/wp-content/uploads/2025/09/10_9_Koopman_program_4_9_2025.pdf</li>
<li>Title Authors Affiliations Abstract Introduction - arXiv, https://arxiv.org/abs/2511.06515</li>
<li>Koopman Control Factorization: Data-Driven Convex Controller Design for a Class of Nonlinear Systems - arXiv, https://arxiv.org/html/2510.05359v1</li>
<li>Koopman global linearization of contact dynamics for robot locomotion and manipulation enables elaborate control - arXiv, https://arxiv.org/pdf/2511.06515</li>
<li>CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning - arXiv, https://arxiv.org/abs/2511.06575</li>
<li>CoFineLLM: Conformal Finetuning of Large Language Models for Language-Instructed Robot Planning - arXiv, https://arxiv.org/html/2511.06575v1</li>
<li>(PDF) CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning, https://www.researchgate.net/publication/397479786_CoFineLLM_Conformal_Finetuning_of_LLMs_for_Language-Instructed_Robot_Planning</li>
<li>CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning, https://www.alphaxiv.org/overview/2511.06575v1</li>
<li>S-Curve Trajectory Planning for Industrial Robots Based on … - MDPI, https://www.mdpi.com/2218-6581/14/11/155</li>
<li>Robotics, Volume 14, Issue 11 (November 2025) – 24 articles - MDPI, https://www.mdpi.com/2218-6581/14/11</li>
<li>Torque-Bounded Task-Space Admittance Control for Redundant Manipulators | Jxiv, JSTプレプリントサーバ, https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/1075</li>
<li>Torque-Bounded Task-Space Admittance Control for Redundant Manipulators | Request PDF - ResearchGate, https://www.researchgate.net/publication/397359454_Torque-Bounded_Task-Space_Admittance_Control_for_Redundant_Manipulators</li>
<li>S4RoboFormer: Scribble-Supervised Surgical Robotic Segmentation Transformer via Augmented Consistency Training - IEEE Xplore, https://ieeexplore.ieee.org/document/11145188/</li>
<li>Collaborative Magnetic Manipulation by Robotically Actuated Permanent Magnet and Multiple Electromagnets | IEEE Journals &amp; Magazine | IEEE Xplore, https://ieeexplore.ieee.org/document/11193692/</li>
<li>F.02 Contributed to the Production of 30,000 Cars at BMW - Figure AI, https://www.figure.ai/news/production-at-bmw</li>
<li>Humanoid Robots Complete Trial Project at BMW Assembly Plant, https://www.assemblymag.com/articles/99678-humanoid-robots-complete-trial-project-at-bmw-assembly-plant</li>
<li>Tesla rolls out the 2025 Holiday Update (2025.44.25.1), new features and release notes, https://www.teslaoracle.com/2025/12/09/tesla-rolls-out-the-2025-holiday-update-2025-44-25-1-new-features-and-release-notes/</li>
<li>Elon Musk gives update on Tesla Optimus progress - Teslarati, https://www.teslarati.com/elon-musk-gives-update-tesla-optimus-progress/</li>
<li>IFS and Boston Dynamics Collaboration Combines the Power of Robotics with Agentic AI to Transform Field Operations, https://www.ifs.com/news/corporate/ifs-and-boston-dynamics-robotics-and-agentic-ai-for-field-operations</li>
<li>Boston Dynamics &amp; Analog Partner to Deploy Spot Robots in UAE - Bots &amp; Drones Asia, https://botsanddrones.asia/news/f/boston-dynamics-analog-partner-to-deploy-spot-robots-in-uae</li>
<li>NEO humanoid designed for household use, available for preorder - The Robot Report, https://www.therobotreport.com/1x-announces-pre-order-launch-neo-humanoid-robot/</li>
<li>The Maker of the $20K Neo Robot Has a Deal for 10,000 of Its Humanoids - CNET, https://www.cnet.com/tech/services-and-software/1x-neo-robot-eqt-partnership-general-purpose-humanoid/</li>
<li>Stanford AI Lab Papers and Talks at CoRL 2025 | SAIL Blog, https://ai.stanford.edu/blog/corl-2025/</li>
<li>The IEEE-RAS International Conference on Humanoid Robots, organized by the RAS Technical Committee on Humanoid Robotics, is a unique conference dedicated to this growing field and has consistently offered valuable opportunities for focused discussions on humanoid robotics. The conference is held annually, rotating between the Americas, Europe, and Asia. This year marks the 24th conference, which will take place in Asia, following the previous one in Europe. The Technical Committee for Humanoid Robotics plays a crucial role in advancing robotics and strengthening the technical community. - Humanoids 2025, https://2025humanoids.org/humanoids-2025/</li>
<li>IROS 2025 Program | Program at a Glance, https://ras.papercept.net/conferences/conferences/IROS25/program/IROS25_ProgramAtAGlanceWeb.html</li>
<li>IEEE/RSJ International Conference on Intelligent Robots and Systems - MassRobotics, https://www.massrobotics.org/event/ieee-rsj-international-conference-on-intelligent-robots-and-systems/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>