<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2025년 7월 AI 연구 현황</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2025년 7월 AI 연구 현황</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2025년 AI 및 로봇 연구 동향</a> / <span>2025년 7월 AI 연구 현황</span></nav>
                </div>
            </header>
            <article>
                <h1>2025년 7월 AI 연구 현황</h1>
<h2>1.  서론: 전환점에 선 2025년 여름의 인공지능 생태계</h2>
<p>2025년 7월은 인공지능(AI) 연구와 산업 역사에 있어 중대한 분기점으로 기록될 시기이다. 북미, 유럽 등지에서 동시다발적으로 개최된 주요 국제 학술대회—ICML, ACL, SIGIR—은 단순히 최신 연구 성과를 공유하는 장을 넘어, 거대 언어 모델(LLM)이 직면한 본질적인 한계들을 극복하기 위한 이론적, 기술적 돌파구를 제시하였다.1 밴쿠버의 ICML 2025, 비엔나의 ACL 2025, 그리고 파도바의 SIGIR 2025로 이어진 이 ’슈퍼 먼스(Super Month)’는 생성형 AI의 패러다임이 정적인 텍스트 생성을 넘어 동적인 문제 해결, 불확실한 환경에서의 강건한 추론, 그리고 인간과의 능동적 협업으로 진화하고 있음을 증명하였다.</p>
<p>본 보고서는 2025년 7월을 기점으로 발표된 주요 논문, 기술 발표, 그리고 산업계의 급박한 움직임을 망라하여 분석한다. 우리는 현재 AI 기술이 직면한 ‘데이터의 불완전성’, ‘추론의 비효율성’, ‘창의성의 한계’, 그리고 ’인간-AI 상호작용의 수동성’이라는 핵심 난제를 연구자들이 어떻게 해결해나가고 있는지 심층적으로 고찰한다. 또한 OpenAI, Google, Meta, Anthropic 등 빅테크 기업들이 하반기 패권 경쟁을 위해 내놓은 차세대 모델 전략을 상세히 분석하여, 학계의 이론적 성과가 어떻게 산업계의 제품으로 전이되고 있는지 그 인과관계를 규명한다.</p>
<h2>2.  ICML 2025: 기계 학습의 이론적 확장과 생성 모델의 재정의</h2>
<p>제42회 국제 기계 학습 학술대회(International Conference on Machine Learning, ICML 2025)는 2025년 7월 13일부터 19일까지 캐나다 밴쿠버에서 개최되었다.1 이번 학회는 AI 모델의 ’기초 체력’이라 할 수 있는 학습 이론의 재정립에 집중하였으며, 특히 데이터가 없거나(missing), 순서가 뒤섞인(unordered) 극한의 상황에서도 작동하는 강건한 생성 모델론이 주류를 이루었다.</p>
<h3>2.1  수동적 응답기에서 능동적 협력자로: CollabLLM</h3>
<p>기존의 대화형 AI 시스템은 사용자의 입력(Query)에 대해 즉각적인 정답을 내놓는 데 최적화되어 있었다. 그러나 사용자의 의도가 불명확하거나 목표가 복잡한 경우, 이러한 ‘즉답형’ 방식은 비효율적인 다중 턴(multi-turn) 대화를 유발하고 결과적으로 사용자 만족도를 저하시키는 원인이 되었다. ICML 2025에서 Outstanding Paper로 선정된 논문 **“CollabLLM: From Passive Responders to Active Collaborators”**는 이러한 패러다임을 전복시켰다.5</p>
<h4>2.1.1  문제 정의 및 이론적 배경</h4>
<p>연구진은 현재의 LLM이 ’수동적 응답자(Passive Responder)’에 머물러 있다고 진단했다. 사용자가 모호한 지시를 내렸을 때, 모델은 스스로 가정을 세워 답변을 생성해버리는 경향이 있으며, 이는 잦은 오류와 수정(correction) 과정을 초래한다. 이를 해결하기 위해 저자들은 모델을 **‘능동적 협력자(Active Collaborator)’**로 재정의하고, 단일 턴의 보상이 아닌 대화 전체의 장기적 가치를 극대화하는 새로운 목적 함수를 제안하였다.7</p>
<p>이 연구의 핵심 기여는 <strong>Multiturn-aware Reward (MR)</strong> 메커니즘의 도입이다. 기존의 강화 학습(RLHF)이 개별 응답의 품질에 집중했다면, MR은 현재의 응답이 미래의 대화 흐름에 미치는 인과적 영향(causal effect)을 명시적으로 모델링한다.</p>
<p>[수식 1] Multiturn-aware Reward (MR) 정의<br />
<span class="math math-display">
MR(m_j \vert t^h_j, g) = \mathbb{E}_{t^f_j \sim P(t^f_j \vert t_{1:j})} R^*(t_{1:j} \cup t^f_j \vert g)
</span><br />
여기서 <code>m_j</code>는 <span class="math math-inline">j</span>번째 턴에서의 모델 응답, <code>t^h_j</code>는 현재까지의 대화 기록(history), <code>g</code>는 사용자의 잠재적 목표를 의미한다. 핵심은 <code>t^f_j</code>로 표현되는 미래의 대화 궤적(future trajectory)이다. 모델은 자신의 현재 발화가 미래에 어떤 대화 경로를 만들어낼지 시뮬레이션하고, 그 경로들의 가치 총합인 <code>R^*</code>의 기댓값을 최대화하는 방향으로 행동을 결정한다.6</p>
<h4>2.1.2  협업 시뮬레이션(Collaborative Simulation)과 데이터 생성</h4>
<p>이론적 보상 함수를 실제 학습 파이프라인에 적용하기 위해, 연구진은 <strong>협업 시뮬레이션(Collaborative Simulation)</strong> 방법론을 고안했다. 이는 모델이 생성한 응답에 대해 가상의 사용자(User Simulator)가 어떻게 반응할지를 예측하고, 이를 통해 미래 대화 경로를 전방 탐색(forward sampling)하는 과정이다.</p>
<ol>
<li><strong>사용자 시뮬레이터:</strong> 다양한 페르소나와 불명확한 의도를 가진 사용자를 시뮬레이션하여, 모델이 ‘질문하기(Clarification)’, ‘제안하기(Suggestion)’, ‘정보 제공하기(Information)’ 등 다양한 전략을 탐색하도록 유도한다.</li>
<li><strong>보상 평가:</strong> 시뮬레이션된 대화가 끝난 후, 목표 달성 여부(성공/실패)와 대화의 효율성(턴 수, 토큰 수)을 기반으로 보상을 책정한다.</li>
<li><strong>정책 최적화:</strong> 산출된 MR을 기반으로 DPO(Direct Preference Optimization) 또는 PPO 방식을 사용하여 모델을 미세 조정한다.8</li>
</ol>
<h4>2.1.3  실험 결과 및 산업적 함의</h4>
<p>CollabLLM은 201명의 인간 평가자를 대상으로 한 대규모 사용자 연구에서 기존의 베이스라인 모델(Llama-3.1-8B 기반) 대비 획기적인 성능 향상을 입증했다.5</p>
<p><strong>표 1: CollabLLM과 기존 모델의 사용자 경험 비교</strong></p>
<table><thead><tr><th><strong>평가 지표</strong></th><th><strong>CollabLLM 개선율</strong></th><th><strong>의미 및 해석</strong></th></tr></thead><tbody>
<tr><td><strong>사용자 만족도</strong></td><td>+17.6%</td><td>모델이 능동적으로 문제를 정의하고 해결책을 제시함에 따라 사용자의 신뢰도 상승</td></tr>
<tr><td><strong>작업 소요 시간</strong></td><td>-10.4%</td><td>불필요한 시행착오를 줄이고 핵심 질문을 통해 지름길(shortcut)을 찾아냄</td></tr>
<tr><td><strong>상호작용성(Interactivity)</strong></td><td>+46.3%</td><td>단방향 정보 제공이 아닌 양방향 소통의 빈도와 질이 대폭 개선됨</td></tr>
</tbody></table>
<p>이 연구는 향후 ‘AI 에이전트’ 개발의 표준이 될 가능성이 높다. 특히 고객 상담, 의료 진단, 법률 자문과 같이 초기 정보가 불완전한 상황에서 AI가 전문가처럼 역질문을 통해 정보를 구체화해 나가는 프로세스에 직접적으로 적용될 수 있다.</p>
<h3>2.2  결측 데이터 학습의 난제 해결: Score Matching with Missing Data</h3>
<p>현실 세계, 특히 의료나 금융 분야의 데이터는 결측치(missing value)가 빈번하게 발생한다. 기존의 생성 모델들은 데이터가 완전하다는 비현실적인 가정하에 설계되었거나, 결측치를 임의로 채워 넣는(imputation) 전처리 과정에 의존해야 했다. ICML 2025에서 주목받은 <strong>“Score Matching with Missing Data”</strong> 연구는 이러한 관행을 깨고, 불완전한 데이터 자체로 생성 모델을 학습시키는 이론적 토대를 마련했다.5</p>
<h4>2.2.1  Score Matching의 확장</h4>
<p>점수 매칭(Score Matching)은 데이터의 확률 밀도 함수(PDF) 자체를 추정하는 대신, 그 로그 밀도 함수의 기울기(Score function, <span class="math math-inline">\nabla_x \log p(x)</span>)를 학습하는 기법이다. 이 방법은 복잡한 정규화 상수(normalizing constant)를 계산할 필요가 없어 고차원 데이터 처리에 유리하다.</p>
<p>그러나 기존의 점수 매칭 목적 함수인 피셔 발산(Fisher Divergence)은 완전한 데이터 관측을 전제로 한다. 연구진은 데이터의 일부만 관측되는 상황(<span class="math math-inline">X_\Lambda</span>)에서도 작동하는 <strong>주변 점수 함수(Marginal Score Function)</strong> 개념을 도입했다.10</p>
<p>[수식 2] Marginal Score Function<br />
<span class="math math-display">
s_\lambda(x_\lambda) := \nabla_{x_\lambda} \log \int_{\mathbb{R}^{d-\vert\Lambda\vert}} q(x) dx_{-\lambda}
</span><br />
여기서 <span class="math math-inline">\lambda</span>는 관측된 변수들의 집합(인덱스)을 의미하며, 적분은 관측되지 않은 변수들(<span class="math math-inline">-\lambda</span>)에 대해 수행된다. 연구진은 이를 바탕으로 결측 데이터에 특화된 새로운 목적 함수를 유도하였다.</p>
<p>[수식 3] Missing Data Score Matching Objective<br />
$$<br />
J(\theta) = \mathbb{E} \left[ 2 \nabla_{X_\Lambda} \cdot s_{\Lambda;\theta}(X_\Lambda) + \lVert s_{\Lambda;\theta}(X_\Lambda) \rVert^2 \right]</p>
<p>$$<br />
이 목적 함수는 관측된 데이터의 주변 분포(marginal distribution)가 가지는 기하학적 정보만을 이용하여 전체 데이터 분포의 점수 함수를 학습하도록 유도한다.</p>
<h4>2.2.2  기술적 혁신과 실험적 검증</h4>
<p>이 연구의 가장 큰 기여는 결측 데이터 처리를 위한 복잡한 대체 기법(예: EM 알고리즘, 다중 대체) 없이, 점수 매칭의 목적 함수를 수정하는 것만으로도 일관된(consistent) 추정량을 얻을 수 있음을 수학적으로 증명했다는 점이다.11</p>
<p>실험적으로는 가우시안 그래픽 모델(Gaussian Graphical Model) 추정 작업과 실제 데이터셋에 대한 실험에서 기존의 최고 성능 모델(SOTA)들을 압도하는 결과를 보여주었다. 특히 결측 비율이 높은 고차원 데이터에서 모델의 강건성(robustness)이 두드러졌다. 이는 향후 확산 모델(Diffusion Model)을 활용한 데이터 복원이나, 희귀 질환 데이터와 같이 본질적으로 결측이 많은 과학 데이터 분석에 핵심적인 알고리즘으로 자리 잡을 전망이다.</p>
<h3>2.3  생성 순서의 자유: Masked Diffusion Models (MDM)</h3>
<p>생성형 AI의 주류인 자기회귀 모델(Autoregressive Model, ARM)은 왼쪽에서 오른쪽(Left-to-Right)으로 토큰을 순차적으로 생성한다. 이는 텍스트 생성에는 효과적이지만, 이미지나 분자 구조와 같이 순서가 중요하지 않거나 전역적인 구조(global structure)를 먼저 파악해야 하는 데이터에는 비효율적이다. <strong>“Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions”</strong> 논문은 이러한 ARM의 한계를 극복하기 위한 대안으로 마스크 확산 모델(Masked Diffusion Model, MDM)을 심층 분석하였다.5</p>
<h4>2.3.1  학습의 고통: Train for the Worst</h4>
<p>연구진은 MDM과 ARM의 근본적인 차이를 ‘학습 복잡성’ 관점에서 규명했다. ARM은 고정된 하나의 순서만 학습하면 되지만, MDM은 임의의 순서로 마스킹된 토큰을 복원해야 하므로 학습 과정에서 다루어야 할 문제 공간(problem space)이 기하급수적으로 넓다.</p>
<p>[수식 4] MDM Loss와 Order Agnostic Training<br />
<span class="math math-display">
\mathcal{L}(x_{1:L}) = - \mathbb{E}_{\pi} \left[ \sum_{i} \log p(x_{\pi(i)} \vert x_{\pi(&lt;i)}; \theta) \right]
</span><br />
위 수식은 MDM의 손실 함수가 사실상 모든 가능한 순열(permutation, <span class="math math-inline">\pi</span>)에 대한 자기회귀 모델의 손실 함수의 기댓값과 동치임을 보여준다.13 즉, MDM은 ‘가장 어려운(Worst)’ 상황, 즉 모든 가능한 생성 순서를 학습해야 하는 부담을 안고 있다. 이는 동일한 데이터셋에 대해 MDM이 ARM보다 수렴 속도가 느리고 더 많은 연산 자원을 필요로 하는 원인이 된다.</p>
<h4>2.3.2  추론의 해방: Plan for the Best</h4>
<p>그러나 이러한 학습의 고통은 추론 시점의 유연성으로 보상받는다. 연구진은 ‘적응형 추론(Adaptive Inference)’ 전략을 통해 MDM이 ARM을 능가할 수 있음을 보였다. MDM은 고정된 순서를 따를 필요 없이, <strong>‘가장 확신이 높은(Plan for the Best)’</strong> 토큰부터 먼저 생성할 수 있다.</p>
<ul>
<li><strong>Easy-First Generation:</strong> 문맥상 명확한 단어나 구조를 먼저 생성하여, 불확실한 부분을 채울 때 더 강력한 힌트(Conditioning)를 제공한다.</li>
<li><strong>논리 퍼즐 및 복합 추론:</strong> 순차적 사고로는 풀기 어려운 문제(예: 제약 조건 충족 문제)에서 MDM은 전역적인 제약을 먼저 고려하고 세부 사항을 채우는 방식으로 ARM보다 우수한 성능을 발휘한다.12</li>
</ul>
<p>이 연구는 단순히 모델 성능을 비교하는 것을 넘어, 생성형 AI의 ’순서(Ordering)’라는 근본적인 제약을 재고하게 함으로써, 향후 비선형적 사고를 요하는 AI 추론 시스템의 설계에 중요한 지침을 제공한다.</p>
<h3>2.4  창의성의 한계 돌파: Next-Token Prediction을 넘어서</h3>
<p>Google DeepMind와 CMU 연구진이 발표한 **“Roll the dice &amp; look before you leap: Going beyond the creative limits of next-token prediction”**은 현재 LLM의 지배적인 패러다임인 ’다음 토큰 예측(Next-Token Prediction)’이 창의적 문제 해결에 본질적인 한계가 있음을 지적했다.5</p>
<p>이 연구는 ‘개방형(Open-ended)’ 작업에서 단순히 확률적으로 가장 높은 단어를 선택하거나 무작위성을 부여(Temperature sampling)하는 것만으로는 진정한 창의성을 발휘할 수 없음을 실험적으로 증명했다. 대신, 연구진은 ‘주사위를 굴리고(Roll the dice) 뛰기 전에 살피는(Look before you leap)’ 전략, 즉 <strong>생성 후 평가(Generate-then-Evaluate)</strong> 방식의 필요성을 역설했다. 이는 모델 내부에서 여러 가설을 생성한 뒤, 자체적인 비평가(Critic) 모듈을 통해 최적의 안을 선택하는 시스템 2(System 2)적 사고방식의 도입을 의미하며, 2025년 하반기 ‘추론형 모델(Reasoning Models)’ 트렌드의 이론적 근거가 되었다.</p>
<h2>3.  ACL 2025: 언어 모델의 대동여지도와 평가 방법론의 혁신</h2>
<p>제63회 연례 계산 언어학 학술대회(ACL 2025)는 7월 27일부터 8월 1일까지 오스트리아 비엔나에서 개최되었다.2 이번 ACL은 수천 개로 폭증한 LLM들을 체계적으로 이해하고 평가하기 위한 거시적 관점의 연구들이 주목받았다.</p>
<h3>3.1  언어 모델의 지도화: Log-Likelihood Vector</h3>
<p>Outstanding Paper로 선정된 **“Mapping 1,000+ Language Models via the Log-Likelihood Vector”**는 현존하는 1,000개 이상의 언어 모델을 단일한 벡터 공간에 매핑하여 시각화하는 방법론을 제안했다.16</p>
<h4>3.1.1  방법론: 확률 분포 공간의 기하학</h4>
<p>연구진은 모델의 가중치(weight)나 아키텍처를 직접 비교하는 대신, 모델이 텍스트에 부여하는 ’확률’에 주목했다. 미리 정의된 대규모 텍스트 집합 <span class="math math-inline">D = {x_1,..., x_N}</span>에 대해, 각 모델 <span class="math math-inline">p_i</span>가 출력하는 로그 우도(Log-Likelihood)를 벡터화하였다.</p>
<p>[수식 5] Log-Likelihood Vector<br />
<span class="math math-display">
\ell_i = (\log p_i(x_1), \dots, \log p_i(x_N))^\top
</span><br />
이 벡터들을 중심화(Double Centering)하여 차원을 축소하면, 각 모델은 고차원 공간상의 한 점(좌표)으로 표현된다. 연구진은 이 공간에서 두 모델 간의 유클리드 거리 제곱이 두 모델의 확률 분포 간의 **쿨백-라이블러 발산(KL Divergence)**과 근사적으로 비례함을 수학적으로 증명했다.</p>
<p>[수식 6] 거리와 KL Divergence의 관계<br />
<span class="math math-display">
\lVert q_i - q_j \rVert^2 \approx 2N \cdot KL(p_i, p_j)
</span></p>
<h4>3.1.2  모델 지도의 활용성</h4>
<p>이 ’모델 지도(Model Map)’는 복잡한 AI 생태계를 조망하는 강력한 도구가 된다.</p>
<ul>
<li><strong>계보 분석:</strong> 특정 베이스 모델(예: Llama 3)에서 파생된 튜닝 모델들이 원본 주변에 어떻게 군집을 이루는지 시각적으로 확인할 수 있다.</li>
<li><strong>성능 예측:</strong> 지도 상의 위치(좌표)만을 이용하여 새로운 모델의 벤치마크 성능을 높은 정확도로 예측할 수 있다.17</li>
<li><strong>데이터 오염 탐지:</strong> 학습 데이터가 겹치거나 특정 데이터셋에 과적합된 모델들을 이상치(Outlier)로 식별해낼 수 있다.</li>
</ul>
<h3>3.2  효율성과 사회적 영향</h3>
<p>ACL 2025에서는 모델의 경량화와 사회적 책임에 관한 연구들도 다수 발표되었다.</p>
<ul>
<li><strong>MaCP (Minimal Adaptation via Hierarchical Cosine Projection):</strong> 수십억 파라미터의 LLM을 단 몇 킬로바이트(KB)의 가중치만으로 미세 조정(Fine-tuning)할 수 있는 기술로, 디바이스 온 AI의 가능성을 열었다.19</li>
<li><strong>HalluLens:</strong> LLM의 고질병인 환각(Hallucination) 현상을 체계적으로 유발하고 탐지하는 벤치마크로, 팩트 체킹 능력 평가의 새로운 표준을 제시했다.20</li>
<li><strong>HateDay:</strong> 8개 국어로 된 트위터(X) 데이터를 하루 동안 전수 수집하여 혐오 표현의 실태를 분석한 연구로, 영어 중심의 안전성 필터가 다국어 환경에서는 무력할 수 있음을 경고했다.19</li>
</ul>
<h2>4.  SIGIR 2025: 검색 증강 생성(RAG)의 속도 혁명</h2>
<p>제48회 국제 ACM SIGIR 학술대회는 7월 13일부터 18일까지 이탈리아 파도바에서 열렸다.21 이번 학회의 화두는 단연 <strong>RAG(Retrieval-Augmented Generation)</strong> 시스템의 효율화였다. 생성 모델의 환각을 줄이기 위해 외부 지식을 검색하는 과정이 필수적인데, 이 검색 단계가 전체 시스템의 병목이 되고 있었기 때문이다.</p>
<h3>4.1  초고속 다중 벡터 검색 엔진: WARP</h3>
<p>**“WARP: An Efficient Engine for Multi-Vector Retrieval”**은 기존 검색 엔진 대비 수십 배 빠른 속도를 달성하여 학계의 이목을 집중시켰다.22</p>
<h4>4.1.1  다중 벡터 검색의 딜레마</h4>
<p>ColBERT와 같은 다중 벡터(Multi-Vector) 모델은 문서를 하나의 벡터가 아닌 여러 개의 토큰 벡터로 표현하여 검색 정확도가 매우 높다. 그러나 모든 쿼리 토큰과 모든 문서 토큰 간의 상호작용(MaxSim)을 계산해야 하므로 연산 비용이 막대하다. 기존의 XTR이나 PLAID 엔진은 이를 최적화하려 했으나 여전히 실시간 서비스에는 부담이 되었다.</p>
<h4>4.1.2  WARP의 핵심 기술: WARPSELECT</h4>
<p>WARP 팀은 <strong>WARPSELECT</strong>라는 혁신적인 알고리즘을 제안했다. 이 알고리즘의 핵심 아이디어는 ’완벽한 계산을 포기하고 똑똑하게 추정하는 것’이다.</p>
<ol>
<li><strong>결측 유사도 대체(Imputation):</strong> 검색 후보군(Candidate Generation) 단계에서 계산되지 않은(missing) 토큰 간의 유사도를 0으로 처리하지 않고, 클러스터의 통계적 특성을 이용하여 정교하게 추정값을 채워 넣는다.</li>
<li><strong>통합 파이프라인:</strong> 벡터의 압축 해제(Decompression)와 점수 계산(Scoring) 단계를 하나의 커널로 통합하여 메모리 접근을 최소화했다.</li>
<li><strong>성능:</strong> 실험 결과, WARP는 Google DeepMind의 XTR 참조 구현체 대비 <strong>41배</strong>, 기존 최고 속도 엔진인 PLAID 대비 <strong>3배</strong> 이상의 속도 향상을 기록했다. 그러면서도 검색 품질(Hit Rate) 저하는 거의 발생하지 않았다.23</li>
</ol>
<p><strong>표 2: WARP와 기존 검색 엔진 성능 비교 (LoTTE 데이터셋 기준)</strong></p>
<table><thead><tr><th><strong>검색 엔진</strong></th><th><strong>Latency (ms)</strong></th><th><strong>Speedup (vs XTR)</strong></th><th><strong>비고</strong></th></tr></thead><tbody>
<tr><td><strong>XTR (Reference)</strong></td><td>~400</td><td>1x</td><td>정확도는 높으나 매우 느림</td></tr>
<tr><td><strong>PLAID</strong></td><td>~50</td><td>8x</td><td>CPU 최적화, 압축 해제 병목 존재</td></tr>
<tr><td><strong>WARP</strong></td><td><strong>~10</strong></td><td><strong>41x</strong></td><td>GPU 가속 및 WARPSELECT 알고리즘 적용</td></tr>
</tbody></table>
<p>이 기술은 RAG 시스템이 사용자의 질문에 대해 수백 밀리초(ms) 이내에 수천 개의 문서를 검색하고 답변을 생성할 수 있게 하는 인프라적 기반이 된다.</p>
<h2>5.  2025년 7월 산업계 동향: 모델 전쟁의 2막, ’에이전트’와 ‘효율성’</h2>
<p>학계가 이론적 난제를 해결하는 동안, 산업계는 이 기술들을 제품화하여 시장을 선점하기 위한 치열한 전쟁을 벌였다. 2025년 7월은 주요 빅테크 기업들이 하반기 대형 모델 출시를 앞두고 전초전을 치르는 시기였다.</p>
<h3>5.1  OpenAI: GPT-5 출시 임박과 전략 변화</h3>
<p>2025년 7월, OpenAI는 차세대 플래그십 모델인 <strong>GPT-5</strong>의 출시(8월 7일 예정)를 앞두고 긴장감이 최고조에 달했다.24</p>
<ul>
<li><strong>GPT-5의 특징:</strong> GPT-5는 기존의 ’챗봇’을 넘어선 ‘자율 에이전트’ 기능을 전면에 내세웠다. 텍스트, 이미지, 음성, 비디오를 단일 모델로 처리하는 <strong>네이티브 멀티모달(Native Multimodal)</strong> 아키텍처를 채택했으며, 사용자의 개입 없이도 스스로 계획을 수립하고 도구를 사용하여 작업을 수행하는 능력이 대폭 강화되었다.</li>
<li><strong>모델 다변화:</strong> 단일 거대 모델 전략에서 벗어나, 용도에 따라 <code>gpt-5</code> (고성능/추론), <code>gpt-5-mini</code> (비용 효율성), <code>gpt-5-nano</code> (온디바이스)로 라인업을 세분화했다. 이는 기업 고객들의 비용 부담을 줄이고 AI 도입 장벽을 낮추기 위한 포석이다.24</li>
<li><strong>내부 동향:</strong> ‘Code Red’ 상황 속에서 안전성 테스트(Red Teaming)가 강화되었으며, 7월 중 일부 사용자에게 광고가 노출되는 해프닝이 발생하여 수익 모델 다각화에 대한 압박을 시사하기도 했다.26</li>
</ul>
<h3>5.2  Meta: Llama 4 생태계의 확산과 오픈 소스 패권</h3>
<p>Meta는 2025년 4월에 공개한 <strong>Llama 4</strong> 시리즈(Scout, Maverick)를 통해 오픈 소스 진영의 맹주 자리를 굳건히 했다. 7월은 이 모델들이 개발자 생태계에 깊이 뿌리내리는 시기였다.27</p>
<ul>
<li><strong>Llama 4 Scout (17B):</strong> 170억 파라미터의 비교적 작은 크기임에도 불구하고, 16회의 전문가 혼합(MoE) 학습을 통해 GPT-4급 성능을 보여주며 ’개인용 AI’의 가능성을 열었다. 특히 1,000만 토큰(10M context length)이라는 압도적인 문맥 처리 능력은 개인의 전체 디지털 기록을 처리할 수 있는 수준이다.27</li>
<li><strong>차기작 Behemoth:</strong> 8월 말 출시 예정인 2조(2T) 파라미터 규모의 초대형 모델 ’Behemoth’에 대한 루머가 확산되며, 오픈 소스 모델이 클로즈드 소스(Closed source) 모델을 성능 면에서도 압도할 수 있을지에 대한 기대감이 고조되었다.29</li>
</ul>
<h3>5.3  Google: Gemini 2.5의 전방위 공세</h3>
<p>Google은 <strong>Gemini 2.5</strong> 시리즈를 통해 모바일, 웹, 기업용 클라우드 시장을 동시에 공략했다.</p>
<ul>
<li><strong>Gemini 2.5 Flash-Lite (7월 22일 출시):</strong> 극단적인 경량화를 통해 속도와 비용 효율성을 잡은 모델로, OpenAI의 GPT-4o-mini에 대한 직접적인 대응이다.30</li>
<li><strong>Veo 3 (7월 31일 프리뷰):</strong> 비디오 생성 모델인 Veo 3는 텍스트 명령만으로 고해상도 영상을 생성하며, 멀티모달 생성 시장에서의 경쟁력을 과시했다.31</li>
<li><strong>3.0을 향한 여정:</strong> 하반기 출시될 Gemini 3.0 Pro는 ‘희소 전문가 혼합(Sparse MoE)’ 구조를 통해 추론 능력을 비약적으로 향상시킬 것으로 예고되었다.32</li>
</ul>
<h3>5.4  Anthropic: Claude 4의 에이전트 혁명</h3>
<p>Anthropic의 <strong>Claude 4</strong>는 ’가장 똑똑한 모델’이라는 포지셔닝을 넘어 ’가장 일 잘하는 모델’로 진화했다.33</p>
<ul>
<li><strong>장기 지평 자율성(Long-horizon Autonomy):</strong> Claude 4는 최대 7시간 동안 사람의 개입 없이 코딩, 데이터 분석 등의 복잡한 작업을 자율적으로 수행할 수 있다. 이는 에이전트가 중간에 길을 잃지 않고(context loss) 목표를 완수할 수 있는 능력이 획기적으로 개선되었음을 의미한다.</li>
<li><strong>Opus 4.1:</strong> 8월 초 출시 예정인 Opus 4.1은 이러한 에이전트 능력을 더욱 강화하여, 소프트웨어 엔지니어링 벤치마크(SWE-bench)에서 인간 엔지니어 수준에 근접한 성능을 보일 것으로 기대된다.34</li>
</ul>
<h2>6.  결론 및 미래 전망: AI의 ’실용성’과 ‘신뢰성’ 시대로의 진입</h2>
<p>2025년 7월의 연구 성과와 산업 동향을 종합해볼 때, AI 기술은 ’신기함(Novelty)’을 보여주던 시기를 지나, 실질적인 가치를 창출하는 ’실용성(Utility)’과 믿고 맡길 수 있는 ’신뢰성(Reliability)’의 단계로 진입하고 있다.</p>
<p><strong>첫째, AI는 더 이상 수동적인 도구가 아니다.</strong> ICML의 CollabLLM과 산업계의 자율 에이전트(GPT-5, Claude 4)는 AI가 사용자의 의도를 파악하고, 부족한 정보를 능동적으로 요구하며, 장기적인 목표를 달성하기 위해 스스로 계획을 수립하는 파트너로 진화했음을 보여준다.</p>
<p><strong>둘째, 효율성은 성능만큼이나 중요한 지표가 되었다.</strong> SIGIR의 WARP 엔진과 Google의 Gemini Flash-Lite 모델은 AI의 연산 비용을 획기적으로 낮추려는 노력이 하드웨어와 소프트웨어 양측에서 극한으로 이루어지고 있음을 시사한다. 이는 AI가 고가의 서버를 넘어 우리 손안의 디바이스(On-device AI)로 들어오는 기폭제가 될 것이다.</p>
<p><strong>셋째, 데이터의 한계를 이론으로 극복하고 있다.</strong> 결측 데이터에 대한 Score Matching이나 순서 없는 학습을 위한 Masked Diffusion 연구는, 더 이상 깨끗한 빅데이터에만 의존하지 않고 현실의 불완전한 데이터로부터 지식을 추출해내는 강건한 AI의 등장을 예고한다.</p>
<p>다가올 2025년 하반기, 우리는 이러한 기술적 진보들이 결합된 제품들을 목격하게 될 것이다. GPT-5와 Gemini 3.0의 정면 대결, 그리고 오픈 소스 Llama 4의 저변 확대는 AI가 연구실을 벗어나 전 산업의 업무 방식을 재편하는 거대한 파도가 될 것이다. 연구자와 기업 리더들은 이 변화의 맥락을 정확히 이해하고, 각자의 도메인에서 AI를 어떻게 ’협력자’로 받아들일지 구체적인 전략을 수립해야 할 시점이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>12월 14, 2025에 액세스, [https://icml.cc/Conferences/2025/Dates#:<sub>:text=ICML%202025%20Meeting%20Dates,at%20the%20Vancouver%20Convention%20Center.](https://icml.cc/Conferences/2025/Dates#:</sub>:text=ICML 2025 Meeting Dates, <a href="https://icml.cc/Conferences/2025/Dates#:~:text=ICML%202025%20Meeting%20Dates,at%20the%20Vancouver%20Convention%20Center.">https://icml.cc/Conferences/2025/Dates#:~:text=ICML%202025%20Meeting%20Dates,at%20the%20Vancouver%20Convention%20Center.</a></li>
<li>12월 14, 2025에 액세스, [https://2025.aclweb.org/#:<sub>:text=Welcome!,27%20to%20August%201st%2C%202025.](https://2025.aclweb.org/#:</sub>:text=Welcome!, <a href="https://2025.aclweb.org/#:~:text=Welcome!,27%20to%20August%201st%2C%202025.">https://2025.aclweb.org/#:~:text=Welcome!,27%20to%20August%201st%2C%202025.</a></li>
<li>SIGIR 2025, Padua, 13-18 July | Home, https://sigir2025.dei.unipd.it/</li>
<li>2025 Dates and Deadlines - ICML 2026, https://icml.cc/Conferences/2025/Dates</li>
<li>ICML 2025 Awards, https://icml.cc/virtual/2025/awards_detail</li>
<li>CollabLLM: From Passive Responders to Active Collaborators, https://cs.stanford.edu/~shirwu/files/collabllm_v1.pdf</li>
<li>CollabLLM: From Passive Responders to Active Collaborators - arXiv, https://arxiv.org/html/2502.00640</li>
<li>CollabLLM: From Passive Responders to Active Collaborators - arXiv, https://arxiv.org/html/2502.00640v1</li>
<li>CollabLLM: From Passive Responders to Active Collaborators - arXiv, https://arxiv.org/html/2502.00640v3</li>
<li>Score Matching With Missing Data - arXiv, https://arxiv.org/pdf/2506.00557</li>
<li>Score Matching with Missing Data | OpenReview, https://openreview.net/forum?id=mBstuGUaXo</li>
<li>Understanding Token Ordering in Masked Diffusions - arXiv, https://arxiv.org/pdf/2502.06768</li>
<li>Masked Diffusion Models are Secretly Learned-Order … - arXiv, https://arxiv.org/html/2511.19152</li>
<li>Train for the Worst, Plan for the Best: Understanding Token Ordering …, https://arxiv.org/abs/2502.06768</li>
<li>Going beyond the creative limits of next-token prediction - arXiv, https://arxiv.org/abs/2504.15266</li>
<li>ACL2025 Outstanding Paper Award (Second Report … - Riken AIp, https://aip.riken.jp/news/acl2025outstanding-paper-award-second-report/</li>
<li>Mapping 1,000+ Language Models via the Log-Likelihood Vector, https://arxiv.org/html/2502.16173v1</li>
<li>Mapping 1,000+ Language Models via the Log-Likelihood Vector, https://aclanthology.org/2025.acl-long.1584.pdf</li>
<li>Record Breaking ACL 2025 Crowns Four Game-Changing Papers …, https://forum.cspaper.org/topic/116/record-breaking-acl-2025-crowns-four-game-changing-papers-on-speed-fairness-safety-for-next-gen-llms-and-beyond</li>
<li>Paper Digest: ACL 2025 Papers &amp; Highlights, https://www.paperdigest.org/2025/07/acl-2025-papers-highlights/</li>
<li>12월 14, 2025에 액세스, https://sigir2025.dei.unipd.it/detailed-program</li>
<li>An Efficient Engine for Multi-Vector Retrieval - WARP - arXiv, https://arxiv.org/pdf/2501.17788</li>
<li>[2501.17788] WARP: An Efficient Engine for Multi-Vector Retrieval, https://arxiv.org/abs/2501.17788</li>
<li>Everything you should know about GPT-5 [September 2025] - Botpress, https://botpress.com/blog/everything-you-should-know-about-gpt-5</li>
<li>When Will ChatGPT-5 Be Released? (July 2025 Update), https://dev.to/cryptosandy/when-will-chatgpt-5-be-released-july-2025-update-43om</li>
<li>‘No ads on ChatGPT’, says OpenAI VP Nick Turley: ‘Any screenshots you’ve seen are …’, https://timesofindia.indiatimes.com/technology/tech-news/no-ads-on-chatgpt-says-openai-vp-nick-turley-any-screenshots-youve-seen-are-/articleshow/125830010.cms</li>
<li>meta-llama/Llama-4-Scout-17B-16E - Hugging Face, https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E</li>
<li>Llama (language model) - Wikipedia, https://en.wikipedia.org/wiki/Llama_(language_model)</li>
<li>Llama 4’s 2T Behemoth: The Reality for Open-Source AI in 2025, https://skywork.ai/blog/llama-4-behemoth-open-source-2025/</li>
<li>Gemini deprecations | Gemini API - Google AI for Developers, https://ai.google.dev/gemini-api/docs/deprecations</li>
<li>Release notes | Gemini API - Google AI for Developers, https://ai.google.dev/gemini-api/docs/changelog</li>
<li>Gemini (language model) - Wikipedia, https://en.wikipedia.org/wiki/Gemini_(language_model)</li>
<li>Claude 4 Features in 2025 - Binary Verse AI, https://binaryverseai.com/claude-4-features-2025/</li>
<li>Claude Opus 4.1 - Anthropic, https://www.anthropic.com/news/claude-opus-4-1</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>