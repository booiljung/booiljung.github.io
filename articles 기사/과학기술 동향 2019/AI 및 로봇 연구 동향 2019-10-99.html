<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2019년 10월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2019년 10월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2019년 AI 및 로봇 연구 동향</a> / <span>2019년 10월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2019년 10월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2019년, AI 연구의 변곡점 - 거대 담론과 미시적 혁신의 조우</h2>
<p>2019년 하반기는 인공지능(AI) 기술이 단순한 알고리즘의 성능 개선을 넘어 국가 경쟁력의 핵심 의제로 부상하며 지정학적 차원의 경쟁을 촉발한 중대한 시기였다. 미국과 중국을 중심으로 한 기술 패권 경쟁이 심화하는 가운데, 각국은 AI 기술의 미래를 자국의 비전에 맞게 설계하려는 거시적 전략을 쏟아내기 시작했다.1 이러한 거대 담론의 형성 이면에서는, 학계가 데이터 활용 방식과 학습 패러다임 자체에 대한 근본적인 질문을 던지는 미시적 혁신을 주도하고 있었다. 이 시기는 AI 연구의 초점이 순수한 기술적 성능 향상, 즉 ’어떻게(How)’의 문제를 넘어, 기술의 안전성, 윤리, 그리고 사회적 활용이라는 ’왜(Why)’와 ’무엇을 위해(For What)’라는 본질적인 질문으로 확장되는 중요한 변곡점이었다.</p>
<p>미국은 ‘AI 이니셔티브’ 행정명령을 통해 R&amp;D 투자를 확대하고, 10월에는 ’국가 AI R&amp;D 전략계획’을 발표하며 AI 기술의 안전성과 윤리적 책임을 강조하는 규범적 리더십을 공고히 하려 했다.1 이에 맞서 중국은 대규모 투자를 바탕으로 데이터 인프라와 기술 표준을 선점하여 장기적인 기술 자립 생태계를 구축하는 데 주력했다.2 이러한 글로벌 경쟁 구도 속에서 대한민국은 ’AI R&amp;D 그랜드 챌린지’와 ’제3차 지능형 로봇 기본계획’을 통해 사회문제 해결과 핵심 산업 경쟁력 강화라는 실용적 목표에 집중하는 추격 전략을 본격화했다.4</p>
<p>이러한 지정학적, 정책적 배경 속에서 2019년 10월을 전후하여 개최된 세계 최고 수준의 학술대회들은 기술 패러다임의 전환을 이끌 중요한 연구 성과들을 배출했다. 서울에서 열린 컴퓨터 비전 분야의 ICCV(International Conference on Computer Vision), 마카오에서 개최된 지능형 로봇 시스템 분야의 IROS(IEEE/RSJ International Conference on Intelligent Robots and Systems), 그리고 오사카에서 열린 로봇 학습 분야의 CoRL(Conference on Robot Learning)은 각각의 영역에서 AI 기술의 새로운 가능성과 방향을 제시했다.6 예를 들어, 미국의 국가 전략이 AI의 ’안전성’과 ’프라이버시’를 강조하는 동안, ICCV에서는 ’프라이버시 보존 이미지 쿼리’와 같은 연구가 발표되며 사회적 요구에 기술적으로 응답하는 모습을 보였다.1 또한, 한국이 ’재난 시 인명구조’라는 공공의 목표를 R&amp;D 챌린지의 주제로 설정한 것은, AI 기술을 사회 안전망 강화의 핵심 도구로 인식하기 시작했음을 보여주는 상징적인 사건이었다.4</p>
<p>본 보고서는 이처럼 복잡하게 얽힌 국가 전략과 최첨단 학술 연구를 씨실과 날실로 엮어, 2019년 10월 당시 AI 및 로봇 기술의 지형도를 입체적으로 재구성하는 것을 목표로 한다. 주요국의 국가 전략이 어떻게 기술 연구의 방향성에 영향을 미쳤는지, 그리고 동시에 학계의 근본적인 기술 돌파구가 어떻게 미래 산업과 사회의 모습을 재편할 가능성을 내포하고 있었는지를 심층적으로 분석하고, 이를 바탕으로 미래 기술의 방향성을 전망하고자 한다.</p>
<h2>2.  AI 패권 경쟁: 주요국의 2019년 국가 전략 동향</h2>
<p>2019년 10월을 기점으로 미국, 대한민국, 중국 3국이 발표하고 추진한 AI 및 로봇 관련 국가 전략은 각국의 상이한 지정학적 위치, 기술적 역량, 그리고 사회경제적 목표를 반영하며 뚜렷한 차별점을 드러냈다. 미국은 규범과 윤리를 앞세운 ’책임 있는 혁신’을 통해 글로벌 리더십을 유지하려 했고, 중국은 미국의 기술 압박 속에서 데이터 인프라와 표준을 장악하여 장기적인 기술 자립을 꾀했다. 한편, 한국은 제한된 자원을 효율적으로 활용하기 위해 사회문제 해결과 같은 특정 분야에 집중하는 실용적인 추격 전략을 선택했다. 이는 AI라는 새로운 기술 패러다임을 자국의 철학과 상황에 맞게 어떻게 수용하고 발전시킬 것인가에 대한 서로 다른 국가적 비전의 표출이었다.</p>
<h3>2.1  미국의 AI 이니셔티브: ’책임 있는 혁신’을 통한 리더십 강화</h3>
<p>2019년 10월 발표된 미국의 ’국가 AI R&amp;D 전략계획(The National Artificial Intelligence Research &amp; Development Strategic Plan)’은 AI 기술의 무분별한 개발이 아닌, 통제되고 책임 있는 방식으로의 발전을 유도하여 글로벌 리더십을 유지하려는 의도를 명확히 보여준다.1 이 전략은 기술적 우위 확보를 넘어, AI 기술이 가져올 사회적, 윤리적 문제에 선제적으로 대응하고 국제 규범 형성을 주도하려는 ‘소프트 파워’ 전략의 일환으로 해석된다.</p>
<p>주요 내용은 다음과 같다.</p>
<ul>
<li>
<p><strong>안전성 및 보안 의무화:</strong> 국가 안보에 중대한 위험을 초래할 수 있는 기반 모델(foundation model) 개발 기업이 서비스 공개 전, 연방 정부에 안전성 테스트 결과를 공유하도록 의무화했다. 이는 AI 기술의 잠재적 위험을 더 이상 개별 기업의 책임으로만 두지 않고 국가 차원에서 관리하겠다는 강력한 신호이다. 또한, AI 생성 콘텐츠에 대한 인증 및 ‘전자 워터마크’ 가이드라인 제정을 통해 정보 생태계의 신뢰성을 확보하려는 노력을 포함했다.1</p>
</li>
<li>
<p><strong>윤리 및 공정성 확보:</strong> AI 알고리즘에 의한 차별이나 편견을 예방하기 위한 명확한 기준 수립을 강조했다. 특히 의료, 사회 보장 프로그램 등 민감한 공공 영역에서 AI 활용이 차별을 조장하지 않도록 하는 최종 규칙을 발표하며 기술의 공적 책임을 명시했다. 이는 AI 기술이 사회적 약자에게 불이익을 주지 않도록 하는 제도적 장치를 마련하는 데 중점을 둔 것이다.1</p>
</li>
<li>
<p><strong>혁신 생태계 조성:</strong> 보조금 확대를 통해 의료 및 기후 변화와 같은 난제 해결을 위한 AI 연구를 촉진하는 동시에, 중소 개발자와 기업에게도 기회가 주어지는 공정하고 개방된 경쟁적인 AI 생태계 마련을 목표로 삼았다. 이는 소수 거대 기업의 기술 독점을 방지하고 혁신의 저변을 넓혀 국가 전체의 AI 역량을 강화하려는 전략이다.1</p>
</li>
<li>
<p><strong>글로벌 표준 선점:</strong> 글로벌 파트너와 협력하여 중요한 AI 표준 개발과 적용을 가속화하고 상호 운용성을 확보하려 했다. 이는 미국의 기술적 우위를 국제 표준으로 확립함으로써, 향후 AI 시장에서 자국의 영향력을 유지하고 기술 규범 형성에서도 리더십을 확보하려는 장기적 포석이다.1</p>
</li>
</ul>
<h3>2.2  대한민국의 추격 전략: ’선택과 집중’을 통한 실용적 도약</h3>
<p>대한민국은 미국과 중국의 전방위적 투자와는 다른 접근법을 취했다. 제한된 자원을 효율적으로 활용하기 위해, 사회적 파급 효과가 크고 기술적 난이도가 높은 특정 문제에 R&amp;D 역량을 집중하는 ‘챌린지’ 방식과 구체적인 산업 육성 계획을 병행하여 실용적인 성과를 창출하는 데 주력했다. 이는 전면전보다는 특정 전선에서 승리하려는 ‘선택과 집중’ 전략으로, R&amp;D 효율성을 극대화하려는 의도가 엿보인다.</p>
<ul>
<li>
<p><strong>AI R&amp;D 그랜드 챌린지:</strong> 미국 국방고등연구계획국(DARPA)의 성공 모델을 벤치마킹하여, ’복합 재난상황에서 골든타임 내에 신속하게 인명을 구조하라’는 구체적이고 도전적인 목표를 제시했다.4 이는 단순히 기술 개발에 그치지 않고, 국민 안전이라는 사회적 가치와 R&amp;D를 직접 연계하여 연구의 방향성과 목적성을 명확히 한 것이 특징이다. 2019년 대회는 ’드론을 활용한 기본 인지지능 SW 기술 개발’을 과제로, 상황인지, 문자인지, 청각인지, 제어지능 등 4개의 개별 기술 트랙으로 시작하여, 향후 이들을 통합하여 복합적인 문제 해결 능력을 검증하는 다단계 방식으로 설계되었다. 개발된 소프트웨어는 공개하여 지속적인 성과 확산을 유도하는 계획도 포함되었다.4</p>
</li>
<li>
<p><strong>제3차 지능형 로봇 기본계획:</strong> AI 기술을 로봇이라는 물리적 실체와 결합하여 가시적인 경제적 성과로 연결하려는 의도를 명확히 했다. ‘제조 로봇 확대 보급’, ‘4대 서비스 로봇(돌봄, 의료, 물류, 웨어러블) 집중 육성’, ’로봇산업 생태계 강화’라는 3대 추진 과제를 통해 구체적인 산업 성장 목표를 제시하며 ’로봇산업 글로벌 4대 강국 도약’을 비전으로 삼았다.5 특히, 협동 로봇 안전인증 제도 개선과 같은 규제 혁신 노력을 병행하여 로봇 산업 발전에 저해가 되는 요소를 해결하고, 로봇규제혁신센터를 구축·운영하여 현장의 목소리를 반영하려 했다.5 이는 당시 한국의 산업용 로봇 설치 대수가 전년 대비 감소하는 등 어려운 상황을 타개하기 위한 정책적 의지가 반영된 결과이기도 하다.5</p>
</li>
</ul>
<h3>2.3  중국의 기술 자립: ’인프라와 표준’을 통한 내실 다지기</h3>
<p>2019년 10월, 미 상무부가 중국의 AI 스타트업들을 제재 목록에 올리는 등 미국의 기술 통제가 본격화되자, 중국은 단기적인 성과보다는 장기적인 기술 자립을 위한 기반 다지기에 집중하는 모습을 보였다.2 특히 AI 개발의 핵심 자원인 데이터와 향후 시장의 규칙이 될 기술 표준을 국가 차원에서 전략적으로 관리하고 통제하려는 의도가 뚜렷하게 나타났다.</p>
<ul>
<li>
<p><strong>데이터 인프라 확충:</strong> ‘동수서산(東數西算) 프로젝트’ 개념을 구체화하며 국가적 차원의 데이터 활용 효율성을 극대화하려 했다. 이는 데이터 수요가 많은 동부 지역의 데이터를 실시간으로 처리하고, 이를 서부 지역의 데이터 센터에 저장 및 백업하는 국가적 컴퓨팅 네트워크 구상이다.3 이는 방대한 데이터를 AI 개발의 핵심 동력으로 삼고, 이를 국가가 전략적으로 통제하겠다는 의미를 내포한다.</p>
</li>
<li>
<p><strong>산업 표준화 주도:</strong> ’국가 AI 산업 종합 표준화 시스템 건설 가이드’를 통해 거대언어모델(LLM) 등 핵심 기술 분야에서 자국의 표준을 수립하고, 이를 국제 표준으로 확장하려는 시도를 공식화했다.3 이는 단순히 기술을 개발하는 것을 넘어, 기술이 통용되는 ‘규칙’ 자체를 설계함으로써 향후 AI 시장에서 중국의 기술적 영향력을 확보하기 위한 장기적 포석이다.</p>
</li>
<li>
<p><strong>미국 제재에 대한 맞대응:</strong> 미국의 기술 수출통제에 대응하여 자국의 수출통제 조치를 강화하고, AI 반도체 등 핵심 공급망의 자립을 위한 노력을 가속화했다.3 이는 외부 압력에 흔들리지 않는 독자적인 AI 산업 생태계를 구축하려는 강력한 의지의 표현이다.</p>
</li>
</ul>
<p>이러한 3국의 차별화된 전략은 아래 표로 요약할 수 있다.</p>
<table><thead><tr><th>구분</th><th>미국</th><th>대한민국</th><th>중국</th></tr></thead><tbody>
<tr><td><strong>전략 명칭/기조</strong></td><td>국가 AI R&amp;D 전략계획</td><td>AI R&amp;D 그랜드 챌린지, 제3차 지능형 로봇 기본계획</td><td>국가 AI 산업 종합 표준화 시스템 건설 가이드 등</td></tr>
<tr><td><strong>핵심 비전</strong></td><td>책임 있는 혁신을 통한 글로벌 리더십 유지</td><td>선택과 집중을 통한 실용적 기술 강국 도약</td><td>기술 자립을 통한 AI 패권 확보</td></tr>
<tr><td><strong>중점 추진 분야</strong></td><td><strong>R&amp;D:</strong> 의료, 기후변화 등 난제 해결 <strong>산업:</strong> 공정하고 개방된 생태계 조성 <strong>인프라:</strong> 개인정보보호 기술 지원 <strong>규제/윤리:</strong> 안전성, 프라이버시, 공정성 의무화 및 가이드라인 제시</td><td><strong>R&amp;D:</strong> 재난구조 등 사회문제 해결형 챌린지 <strong>산업:</strong> 제조 로봇 보급, 4대 서비스 로봇 집중 육성 <strong>인프라:</strong> 공개 SW를 통한 성과 확산 <strong>규제/윤리:</strong> 협동 로봇 안전인증 등 규제 혁신</td><td><strong>R&amp;D:</strong> AI 반도체 등 핵심 기술 자립 <strong>산업:</strong> 산업별 데이터 표준화 <strong>인프라:</strong> ‘동수서산’ 등 국가 데이터 센터 구축 <strong>규제/윤리:</strong> 자국 기술 표준 수립 및 국제 표준화</td></tr>
<tr><td><strong>주요 정책</strong></td><td>- AI 안전성 테스트 결과 공유 의무화<br>- AI 차별 방지 기준 수립<br>- 글로벌 AI 표준 개발 주도</td><td>- DARPA 방식 챌린지 R&amp;D 추진<br>- 로봇 산업 육성을 위한 3대 추진과제 발표<br>- 로봇규제혁신센터 운영</td><td>- ‘동수서산’ 프로젝트 추진<br>- LLM 등 기술 표준 수립<br>- 미국의 기술 통제에 대한 맞대응 조치</td></tr>
<tr><td><strong>관련 자료</strong></td><td>1</td><td>4</td><td>2</td></tr>
</tbody></table>
<h2>3.  컴퓨터 비전의 새로운 지평: ICCV 2019 주요 연구 심층 분석</h2>
<p>2019년 10월 27일부터 11월 2일까지 서울 코엑스에서 개최된 제17회 국제 컴퓨터 비전 학회(ICCV 2019)는 컴퓨터 비전 분야의 새로운 방향을 제시하는 중요한 이정표였다. 2017년 대비 두 배 증가한 4,303편의 논문이 제출되고 7,000명 이상이 등록하는 등 양적으로 크게 성장했으며, 질적으로도 기존의 패러다임을 넘어서는 혁신적인 연구들이 다수 발표되었다.6 특히, 학회 최고 영예인 최우수 논문상(Marr Prize)을 수상한 ’SinGAN’은 대규모 데이터셋에 의존하던 생성 모델의 한계를 극복하는 새로운 가능성을 제시하며 학계에 큰 반향을 일으켰다.10 이와 더불어, AI 모델의 개발 효율성을 극대화하고 프라이버시와 같은 사회적 책임을 고려하는 연구들도 주목받으며, 컴퓨터 비전 연구가 기술적 성숙을 넘어 실용성과 사회적 가치를 포괄하는 단계로 진입하고 있음을 보여주었다.</p>
<h3>3.1  최우수 논문(Marr Prize) 분석: SinGAN - 단일 이미지 기반 생성 모델의 혁신</h3>
<p>기존의 생성적 적대 신경망(GAN) 연구는 수만 장에 달하는 대규모 데이터셋을 학습하여 특정 클래스(예: 사람 얼굴, 고양이)의 공통된 특징을 포착하고 새로운 이미지를 생성하는 데 초점을 맞추어 왔다. 그러나 SinGAN은 이러한 ‘Big Data’ 패러다임에서 벗어나, 단 한 장의 자연 이미지에 내재된 풍부한 정보, 즉 ’Deep Data’를 활용하는 혁신적인 접근법을 제시했다.</p>
<ul>
<li>
<p><strong>연구 목표:</strong> SinGAN의 핵심 목표는 대규모 데이터셋 없이, 단 한 장의 자연 이미지(a single natural image)에 내재된 내부 패치 통계(internal distribution of patches)를 학습하여, 원본의 시각적 콘텐츠와 구조는 유지하면서도 다양하고 새로운 객체 구성을 갖는 고품질 이미지를 생성하는 비조건부 생성 모델(unconditional generative model)을 개발하는 것이었다.12 이는 데이터 수집이 어렵거나 불가능한 전문 분야(의료 영상, 위성 사진, 예술 작품 등)에서도 생성 모델을 활용할 수 있는 길을 여는 것을 의미한다.</p>
</li>
<li>
<p><strong>방법론 및 모델 구조:</strong> SinGAN의 핵심은 이미지의 구조를 다양한 스케일에서 계층적으로 학습하는 것이다. 이를 위해 ’다중 스케일 GAN 피라미드(Pyramid of fully convolutional GANs)’라는 독창적인 구조를 제안했다.15</p>
</li>
<li>
<p><strong>계층적 학습 구조:</strong> 모델은 원본 이미지를 점진적으로 다운샘플링한 이미지 피라미드 <code>{$x_0, x_1,..., x_N$}</code>를 생성한다. 각 스케일 <span class="math math-inline">n</span>에는 해당 이미지 <span class="math math-inline">x_n</span>의 패치 분포를 학습하는 생성자(<span class="math math-inline">G_n</span>)와 판별자(<span class="math math-inline">D_n</span>) 쌍이 존재한다. 학습은 가장 거친(coarsest) 스케일 <span class="math math-inline">N</span>에서 시작하여 가장 미세한(finest) 스케일 <code>0</code>으로 순차적으로 진행된다.16</p>
</li>
<li>
<p><strong>생성 과정:</strong> 이미지 생성은 가장 거친 스케일 <span class="math math-inline">N</span>에서 시작된다. <span class="math math-inline">G_N</span>은 순수한 공간적 노이즈맵(<span class="math math-inline">z_N</span>)을 입력받아 저해상도 이미지 샘플 <span class="math math-inline">\tilde{x}_N</span>을 생성한다. 이후 각 스케일 <span class="math math-inline">n</span>의 생성자 <span class="math math-inline">G_n</span>은 이전 스케일의 생성 결과(<span class="math math-inline">\tilde{x}_{n+1}</span>)를 업샘플링한 것과 새로운 노이즈맵(<span class="math math-inline">z_n</span>)을 함께 입력받아 더 높은 해상도의 이미지 <span class="math math-inline">\tilde{x}_n</span>을 생성한다. 이 과정에서 <span class="math math-inline">G_n</span>은 이전 스케일에서 포착하지 못한 세부적인 디테일과 텍스처를 추가하는 역할을 한다.16</p>
</li>
<li>
<p><strong>네트워크 아키텍처:</strong> 각 생성자 <span class="math math-inline">G_n</span>과 판별자 <span class="math math-inline">D_n</span>은 5개의 Conv-BatchNorm-LeakyReLU 블록으로 구성된 완전 컨볼루션 네트워크(FCN) 구조를 가진다. 이를 통해 생성자는 입력 이미지의 크기에 구애받지 않고 동작할 수 있다. 특히 생성자는 잔차 학습(residual learning) 방식을 사용하여, 업샘플링된 이전 스케일 이미지에 세부 묘사를 더하는 잔차 이미지를 학습한다.16 이 구조 덕분에 각 스케일의 생성자와 판별자는 동일한 크기의 수용장(receptive field)을 가지게 되며, 거친 스케일에서는 이미지의 전역적인 구조(객체 배치 등)를, 미세한 스케일에서는 지역적인 텍스처를 효과적으로 학습할 수 있다.17</p>
</li>
<li>
<p><strong>핵심 수식 분석:</strong> SinGAN의 학습 과정은 각 스케일에서 적대적 손실과 재구성 손실을 함께 최적화하는 방식으로 이루어진다.</p>
</li>
<li>
<p><strong>적대적 손실 (<span class="math math-inline">\mathcal{L}_{\text{adv}}</span>):</strong> 학습 안정성을 높이기 위해 WGAN-GP(Wasserstein GAN with Gradient Penalty) 손실 함수를 사용한다. 각 스케일 <span class="math math-inline">n</span>에서 판별자 <span class="math math-inline">D_n</span>은 실제 이미지 <span class="math math-inline">x_n</span>의 패치와 생성된 이미지 <span class="math math-inline">\tilde{x}_n</span>의 패치를 구별하도록 학습되고, 생성자 <span class="math math-inline">G_n</span>은 <span class="math math-inline">D_n</span>을 속이도록 학습된다. 이를 통해 생성된 이미지 패치의 분포가 실제 이미지 패치의 분포에 가까워지도록 유도한다.<br />
<span class="math math-display">
  \min_{G_n} \max_{D_n} \mathcal{L}_{\text{adv}}(G_n, D_n) = \mathbb{E}_{x \sim p_{\text{data}}(x_n)} - \mathbb{E}_{z \sim p_z} - \lambda \mathbb{E}_{\hat{x} \sim p_{\hat{x}}}
</span></p>
</li>
<li>
<p><strong>재구성 손실 (<span class="math math-inline">\mathcal{L}_{\text{rec}}</span>):</strong> SinGAN이 paint-to-image, super-resolution 등 다양한 이미지 조작 작업에 활용될 수 있도록, 특정 노이즈맵 집합(<span class="math math-inline">z^*</span>)이 주어졌을 때는 원본 이미지 <span class="math math-inline">x_n</span>을 완벽하게 재구성하도록 하는 손실 항을 추가한다. 이는 생성자가 입력 노이즈를 무시하지 않고 의미 있는 정보를 학습하도록 강제하는 중요한 역할을 한다.17</p>
<p><span class="math math-display">
\mathcal{L}_{\text{rec}} = \Vert G_n(z_n^*, (\tilde{x}_{n+1}^*)\uparrow^r) - x_n \Vert^2
</span></p>
</li>
<li>
<p><strong>전체 목적 함수:</strong> 최종적으로 생성자 <span class="math math-inline">G_n</span>은 적대적 손실과 재구성 손실의 가중 합을 최소화하는 방향으로 학습된다. 재구성 손실의 가중치 <span class="math math-inline">\alpha</span>는 다양한 이미지 조작 응용에서 중요한 하이퍼파라미터로 작용한다.</p>
<p><span class="math math-display">
G_n^* = \arg \min_{G_n} \mathcal{L}_{\text{adv}}(G_n, D_n) + \alpha \mathcal{L}_{\text{rec}}
</span></p>
</li>
<li>
<p><strong>저자 및 소속:</strong> 이 혁신적인 연구는 이스라엘 공과대학교(Technion)의 Tamar Rott Shaham과 Tomer Michaeli, 그리고 구글 리서치(Google Research)의 Tali Dekel에 의해 수행되었다.12</p>
</li>
<li>
<p><strong>의의 및 파급 효과:</strong> SinGAN의 등장은 AI 연구 커뮤니티에 ’데이터 효율성’이라는 새로운 화두를 던졌다. AI 모델의 성능이 반드시 데이터의 양에 비례하는 것은 아니며, 단일 데이터 소스에 담긴 깊이 있는 정보를 어떻게 효과적으로 활용하는지가 중요할 수 있음을 입증했다. 이는 AI 모델의 규모가 기하급수적으로 커지면서 발생하는 막대한 데이터 수집 비용과 계산 자원 소모, 그리고 환경 문제에 대한 학계의 선제적인 고민을 반영한다. SinGAN의 성공은 향후 데이터 증강, 개인화된 콘텐츠 생성, 이상 탐지 등 다양한 응용 분야로의 확장을 촉진하는 기폭제가 되었다.</p>
</li>
</ul>
<h3>3.2  주요 발표 동향: 효율성과 사회적 책임</h3>
<p>ICCV 2019에서는 SinGAN 외에도 AI 기술의 실용성을 높이고 사회적 책임을 다하려는 연구들이 주목받았다.</p>
<ul>
<li>
<p><strong>FPNAS (Fast and Practical Neural Architecture Search):</strong> 신경망 아키텍처 탐색(NAS)은 높은 성능의 모델을 자동으로 설계할 수 있지만, 막대한 계산 자원을 요구하여 실용성이 떨어진다는 비판을 받아왔다. FPNAS는 이러한 한계를 극복하고자 했다. 기존 NAS 방식들이 작은 셀(cell) 구조를 탐색하여 이를 반복적으로 쌓는 방식을 취한 것과 달리, FPNAS는 전체 네트워크 아키텍처를 직접 탐색하여 블록의 다양성을 보장했다. 이를 통해 CIFAR-10 데이터셋에서 SOTA(State-of-the-Art) 수준의 성능을 달성하면서도, 소요된 계산 시간은 단 20 GPU 시간에 불과했다.18 이는 수천 GPU 시간을 요구하던 이전 연구들과 비교할 때 획기적인 발전으로, NAS 기술의 실용성을 한 단계 끌어올려 더 많은 연구 그룹이 고성능 모델 아키텍처를 자체적으로 개발할 수 있는 가능성을 열었다.</p>
</li>
<li>
<p><strong>Privacy Preserving Image Queries for Camera Localization:</strong> 증강현실(AR)이나 로보틱스 응용이 확산되면서, 사용자의 이미지를 클라우드 서버로 전송하여 위치를 추정하는 서비스가 보편화되고 있다. 그러나 이는 심각한 프라이버시 침해 우려를 낳는다. 이 연구는 이러한 문제에 대한 기술적 해결책을 제시했다. 사용자의 프라이버시를 보호하기 위해, 쿼리 이미지의 2D 특징점(feature points)을 그대로 전송하는 대신, 각 특징점을 통과하는 무작위 방향의 2D 선(line)으로 대체하여 서버에 전송하는 기법을 제안했다.9 이 방법은 원본 이미지의 내용을 효과적으로 숨기면서도, 6자유도(6-DOF) 카메라 포즈 추정에 필요한 충분한 기하학적 제약 정보를 유지한다. 이는 기술 발전과 프라이버시 보호라는 두 가지 상충될 수 있는 가치를 동시에 추구하는 연구 방향을 제시했다는 점에서 큰 의미를 가진다. 이는 1장에서 살펴본 미국의 ‘프라이버시 보호’ 강화 정책과도 그 맥을 같이 한다.1</p>
</li>
</ul>
<p>이러한 연구들은 2019년 컴퓨터 비전 분야의 연구 방향이 무한한 자원을 가정하는 ’규모의 경쟁’에서, 제한된 자원 하에서 효율성을 극대화하고 사회적 책임을 다하는 ’지능의 경쟁’으로 전환되고 있음을 시사한다.</p>
<h2>4.  지능형 로봇 시스템의 진화: IROS 2019 핵심 연구 동향</h2>
<p>2019년 11월 4일부터 8일까지 마카오에서 개최된 IROS(IEEE/RSJ International Conference on Intelligent Robots and Systems)는 ’사람을 연결하는 로봇(Robots Connecting People)’이라는 주제 아래 로봇 공학의 최신 성과를 공유하는 장이었다.7 53개국에서 2,513편의 논문이 제출되는 등 로봇 분야 최대 규모의 학회로서의 위상을 재확인했으며, 특히 AI 기술을 로봇의 물리적 실행과 결합하여 현실 세계의 불확실성에 대응하려는 연구들이 두각을 나타냈다.7 최우수 논문으로 선정된 ‘동적 환경에서의 반응형 조작 계획’ 연구는 전통적인 로봇 제어 이론과 최신 강화학습을 성공적으로 융합하여, 예측 불가능한 환경에서 로봇이 어떻게 지능적으로 동작해야 하는지에 대한 새로운 해법을 제시했다.19 이는 AI의 ’지능(뇌)’과 로봇의 ’물리적 실행(몸)’이 어떻게 효과적으로 결합될 수 있는지를 보여주는 상징적인 성과였다.</p>
<h3>4.1  최우수 논문 분석: 동적 환경에서의 반응형 조작 계획 (Planning Reactive Manipulation in Dynamic Environments)</h3>
<p>공장 자동화나 물류 시스템에서 로봇은 대부분 고정된 환경에서 사전에 프로그래밍된 동작을 반복적으로 수행한다. 그러나 로봇이 가정이나 재난 현장과 같이 구조화되지 않고 끊임없이 변하는 동적 환경에서 인간과 함께 작업하기 위해서는, 실시간으로 상황을 판단하고 자신의 움직임을 즉각적으로 재계획하는 능력이 필수적이다. 이 연구는 바로 이 문제에 대한 해법을 제시했다.</p>
<ul>
<li>
<p><strong>연구 목표:</strong> 이 연구의 핵심 목표는 컨베이어 벨트나 사람의 움직임과 같이 환경이 실시간으로 변하는 동적 환경(dynamic environments)에서, 로봇이 물체와 접촉하고 분리하는 복잡한 조작(manipulation) 작업을 실패 없이 수행할 수 있는 반응형 피드백 플래너(reactive feedback planner)를 개발하는 것이었다.20 기존의 샘플링 기반 플래너들은 계획 수립에 비결정적인 시간이 소요되어 실시간 대응에 한계가 있었기 때문에, 이를 극복하는 것이 중요한 과제였다.</p>
</li>
<li>
<p><strong>방법론 및 알고리즘:</strong> 연구진은 전통적인 제어 이론과 최신 머신러닝 기법을 결합한 독창적인 하이브리드 접근법을 제안했다. 이는 복잡한 문제를 효율적으로 해결하기 위해 고수준의 추상적 결정과 저수준의 물리적 제어를 계층적으로 분리하면서도 유기적으로 연결하는 구조이다.</p>
</li>
</ul>
<ol>
<li>
<p><strong>제약 기반 컨트롤러 (Constraint-based Controllers):</strong> 먼저, 로봇의 조작 작업을 기구학적 제약(예: 충돌 회피), 동역학적 제약(예: 관절 속도 제한), 작업 관련 제약(예: 그리퍼가 물체를 잡고 있어야 함) 등 다양한 제약 조건의 집합으로 수학적으로 모델링한다. 그리고 이 제약들을 만족시키는 여러 개의 저수준(low-level) 피드백 컨트롤러들을 자동으로 생성한다. 이 컨트롤러들은 고주파수(high-frequency)로 동작하며 로봇의 관절 가속도를 직접 제어하여 물리적 움직임을 안정적으로 수행한다.20</p>
</li>
<li>
<p><strong>강화학습 에이전트 (Reinforcement Learning Agent):</strong> 어떤 상황에서 어떤 제약 기반 컨트롤러를 활성화할지를 결정하는 고수준(high-level) 정책을 심층 강화학습(Deep Reinforcement Learning)을 통해 학습한다. 이 RL 에이전트는 저주파수(low-frequency)로 동작하며, 현재 상태를 관찰하고 장기적인 보상을 최대화하는 방향으로 최적의 컨트롤러를 선택하는 ‘스위칭 제어(switching-control)’ 역할을 수행한다. 즉, RL 에이전트는 ’무엇을 할지’를 결정하고, 선택된 제약 기반 컨트롤러는 ’어떻게 할지’를 실행하는 구조이다.20</p>
</li>
</ol>
<ul>
<li>
<p><strong>핵심 수식 분석:</strong> 이 연구는 조작 작업을 이산적인 모드(<span class="math math-inline">\sigma \in \Sigma</span>)에 따라 달라지는 제약된 운동으로 모델링한다. 각 모드는 시스템의 접촉 상태와 같은 질적 상태를 나타낸다.</p>
</li>
<li>
<p><strong>제약된 운동 모델링:</strong> 시스템의 상태(위치 <span class="math math-inline">\mathbf{q}</span>, 시간 <span class="math math-inline">t</span>)에 대한 제약은 다음과 같은 부등식으로 표현된다. 등식 제약은 두 개의 반대 부호 부등식으로 표현 가능하다.</p>
<p><span class="math math-display">
f_\sigma (\mathbf{q}, t) \le 0  \quad (\text{Configuration constraints})
</span></p>
</li>
</ul>
<p>속도에 대한 제약 역시 유사하게 정의된다.</p>
<p><span class="math math-display">
\frac{d}{dt} v_\sigma (\mathbf{q}, t) \le 0 \quad (\text{Velocity constraints})
</span></p>
<ul>
<li>
<p><strong>컨트롤러:</strong> RL 에이전트가 선택하는 각 행동은 시스템의 목표 가속도 <span class="math math-inline">\ddot{\mathbf{q}}</span>를 결정하는 제어 법칙 <span class="math math-inline">k(\mathbf{s})</span>에 해당하며, 여기서 <span class="math math-inline">\mathbf{s} = (\mathbf{q}, \dot{\mathbf{q}}, t)</span>는 시스템의 전체 상태를 나타낸다.20</p>
<p><span class="math math-display">
\ddot{\mathbf{q}} = k(\mathbf{s})
</span></p>
</li>
<li>
<p><strong>실험 및 결과:</strong> 제안된 접근법의 견고성(robustness)을 평가하기 위해, 연구진은 이중 팔 로봇(DUAL), 델타 로봇(DELTA), PR2 로봇을 이용한 시뮬레이션에서 ’방해받는 실행(disturbed execution)’이라는 가혹한 테스트를 수행했다. 이는 계획된 경로의 중간 지점에서 실행을 시작하게 하여 예기치 않은 상황에 대한 대처 능력을 평가하는 방식이다. 실험 결과, 특히 복잡한 동작이 요구되는 이중 팔 로봇(DUAL) 작업에서, 기존 제약 기반 플래너의 평균 성공률은 11%에 불과했지만, 제안된 RL 기반 접근법은 98.1%라는 압도적으로 높은 성공률을 기록했다.20 이는 RL 에이전트가 다양한 상황에 대처하는 일반화된 정책을 학습했음을 의미한다.</p>
</li>
<li>
<p><strong>저자 및 소속:</strong> 이 연구는 독일의 지멘스 중앙기술연구소(Siemens Corporate Technology) 소속의 Philipp S. Schmitt, Florian Wirnshofer, Kai M. Wurm, Georg v. Wichert와 프라이부르크 대학교(University of Freiburg)의 Wolfram Burgard 교수가 공동으로 수행했다.20</p>
</li>
<li>
<p><strong>의의 및 파급 효과:</strong> 이 연구는 로봇 공학의 전통적인 강점인 정밀한 제어 이론과 AI의 최신 기술인 강화학습을 성공적으로 결합하여, 두 분야의 시너지를 입증한 중요한 사례이다. 이는 예측 불가능성이 높은 실제 환경, 즉 스마트 팩토리, 가정, 재난 현장 등에서 로봇이 인간과 안전하게 협력하고 복잡한 작업을 자율적으로 수행하기 위한 핵심 기술적 토대를 마련했다.</p>
</li>
</ul>
<h3>4.2  로봇 기술 동향: 이동성, 감지, 상호작용의 확장</h3>
<p>IROS 2019에서는 최우수 논문 외에도 로봇이 인간의 활동 영역과 극한 환경으로 활동 범위를 넓히기 위한 다양한 기술들이 발표되었다.</p>
<ul>
<li>
<p><strong>이동성 및 탐색 기술의 진화:</strong> 로봇의 활동 영역을 확장하기 위한 연구가 활발히 진행되었다. 소나, 비전, 관성, 깊이 센서를 통합하여 수중 환경을 3D로 재구성하고 탐색하는 SLAM 시스템(SVIn2)이 발표되어 주목받았다.19 또한, 강철 다리를 오르는 로봇이나 다족 보행으로 수직 벽을 오르는 로봇 등 인간이 접근하기 어려운 극한 환경에서의 이동성을 확보하려는 연구들도 다수 발표되었다.19</p>
</li>
<li>
<p><strong>사회적 상호작용 및 서비스 로봇:</strong> ’사람을 연결하는 로봇’이라는 학회 주제에 걸맞게, 인간과의 상호작용(HRI) 및 서비스 분야 연구가 큰 비중을 차지했다. 인간의 시선과 주의를 이해하고 이에 반응하는 로봇(Responsive Joint Attention in Human-Robot Interaction), 다양한 얼굴 표정을 인식하여 감정을 파악하는 로봇 등 사회적 지능을 갖춘 로봇 기술이 소개되었다.19 또한, AI 기술을 활용하여 노인이나 환자를 위한 말벗, 긴급 호출, 모니터링 기능을 제공하는 인공지능 돌보미 서비스 로봇이나, 척추측만증 진단을 위한 로봇 초음파 내비게이션 기술 등 의료 및 복지 분야에서의 구체적인 응용 사례들이 발표되었다.21</p>
</li>
</ul>
<p>이러한 연구 동향은 AI와 로보틱스가 더 이상 별개의 학문이 아니라, 물리 세계의 복잡한 문제를 해결하기 위해 반드시 융합되어야 하는 단일 분야로 진화하고 있음을 명확히 보여준다. 한국의 ’AI 그랜드 챌린지’에서 ‘상황인지’, ’청각인지’와 같은 AI 인식 기술과 ’제어지능’이라는 로봇 동작 기술을 결합하여 ’드론의 자율비행’이라는 물리적 과제를 해결하도록 설계한 점은, 이러한 글로벌 기술 트렌드를 정책적으로 반영한 시의적절한 사례로 평가할 수 있다.4</p>
<h2>5.  로봇 학습의 도약: CoRL 2019의 모방 및 강화 학습 연구</h2>
<p>2019년 10월 30일부터 11월 1일까지 일본 오사카에서 개최된 로봇 학습 학회(CoRL, Conference on Robot Learning)는 로봇 공학과 머신러닝의 교차점에서 가장 빠르게 성장하는 핵심 학회 중 하나이다.23 CoRL 2019에서는 로봇이 인간의 시연(demonstration)이나 피드백을 통해 복잡한 기술을 학습하는 모방 학습(Imitation Learning) 및 강화 학습(Reinforcement Learning) 분야에서 중요한 이론적, 방법론적 진전이 있었다. 특히, 기존 모방 학습의 근본적인 한계로 여겨졌던 ’시연자의 능력을 뛰어넘을 수 없는 문제’를 해결하기 위한 혁신적인 아이디어가 제시되어 큰 주목을 받았다. 이는 로봇이 불완전한 데이터로부터 더 나은 지식을 스스로 ’외삽(extrapolate)’해내는 방법을 제시함으로써, 모방 학습의 실용적 적용 범위를 크게 확장하는 계기가 되었다.</p>
<h3>5.1  시연자를 넘어서는 모방 학습: D-REX 심층 분석</h3>
<p>모방 학습은 로봇에게 복잡한 작업을 가르치는 직관적이고 강력한 방법이지만, 학습된 정책의 성능이 전문가 시연의 품질에 의해 상한이 결정된다는 명백한 한계를 가지고 있었다. 즉, 로봇은 시연자가 보여준 것 이상으로 잘할 수 없으며, 심지어 시연자의 실수까지 그대로 학습할 수 있다. ‘D-REX’ 연구는 이러한 한계를 정면으로 돌파하고자 했다.</p>
<ul>
<li>
<p><strong>연구 목표:</strong> 이 연구의 핵심 목표는 외부의 명시적인 보상 신호나 인간의 추가적인 피드백(예: “이 행동이 더 좋다”) 없이, 주어진 불완전하거나 차선일 수 있는(suboptimal) 시연 데이터만으로 시연자보다 더 나은(better-than-demonstrator) 성능을 내는 정책을 학습하는 것이었다.24 이는 전문가 데이터 확보가 비싸거나 어려운 현실 세계의 많은 문제에 AI를 적용할 때, 보다 적은 비용으로 고성능의 에이전트를 학습시킬 수 있는 길을 여는 것을 목표로 한다.</p>
</li>
<li>
<p><strong>핵심 아이디어 및 방법론:</strong> D-REX(Disturbance-based Reward Extrapolation)의 가장 독창적인 아이디어는 ’자동으로 순위화된 시연 생성(Automatically-Ranked Demonstrations)’이라는 개념이다.27 인간이 직접 “A가 B보다 낫다“고 평가해주는 대신, 기계가 스스로 성능이 다른 여러 버전의 시연을 만들어내고 그들 간의 순위를 추론하는 방식이다.</p>
</li>
</ul>
<ol>
<li>
<p><strong>행동 복제 (Behavioral Cloning):</strong> 먼저, 주어진 시연 데이터(<span class="math math-inline">\mathcal{D}</span>)를 사용하여 시연자의 정책을 모사하는 초기 정책(<span class="math math-inline">\pi_{BC}</span>)을 지도 학습 방식으로 학습한다.</p>
</li>
<li>
<p><strong>잡음 주입을 통한 궤적 생성:</strong> 학습된 정책 <span class="math math-inline">\pi_{BC}</span>에 다양한 수준의 무작위 잡음(noise)을 주입하여 여러 개의 궤적(trajectories)을 생성한다. 직관적으로, 잡음이 적게 주입된 궤적은 원본 시연과 유사하여 성능이 높고, 잡음이 많이 주입된 궤적은 행동의 일관성이 떨어져 성능이 낮을 것이라는 합리적인 가정을 기반으로 한다.</p>
</li>
<li>
<p><strong>자동 순위화:</strong> 생성된 궤적들을 주입된 잡음의 수준에 따라 자동으로 순위화한다. 예를 들어, 잡음이 없는 원본 시연 궤적이 가장 높은 순위를 가지며, 잡음 수준이 높아질수록 순위가 낮아진다. 이 과정은 인간의 수고스럽고 주관적일 수 있는 순위 평가 작업을 완전히 자동화한다.25</p>
</li>
<li>
<p><strong>역강화학습 (Inverse Reinforcement Learning):</strong> 자동으로 생성된 순위 정보를 사용하여 보상 함수(reward function)를 학습한다. T-REX와 같은 기존의 순위 기반 IRL 알고리즘을 활용하여, 더 높은 순위의 궤적이 더 높은 누적 보상을 갖도록 하는 보상 함수를 신경망으로 추론한다.25 이 과정에서 보상 함수는 단순히 시연을 모방하는 것을 넘어, 무엇이 ‘좋은’ 행동인지를 더 근본적으로 학습하게 된다.</p>
</li>
<li>
<p><strong>강화학습 (Reinforcement Learning):</strong> 마지막으로, 추론된 보상 함수를 목표(objective)로 삼아 이를 최적화하는 새로운 정책(<span class="math math-inline">\pi^*</span>)을 심층 강화학습 알고리즘(예: PPO)을 통해 학습한다. 이 정책은 시연 데이터에 명시적으로 나타나지 않은 더 나은 행동을 탐색하여 시연자의 원래 성능을 뛰어넘을 수 있다.</p>
</li>
</ol>
<ul>
<li>
<p><strong>이론적 기여:</strong> D-REX는 방법론 제시에 그치지 않고, 왜 시연에 대한 선호도(순위) 정보가 보상 함수 추정의 모호성(ambiguity)을 줄여 시연자보다 나은 성능을 가능하게 하는지에 대한 이론적 분석과 충분조건(sufficient condition)을 제시하여 연구의 타당성을 뒷받침했다.24</p>
</li>
<li>
<p><strong>핵심 수식:</strong> 순위 기반 보상 학습의 목적은 순위가 매겨진 궤적 쌍(<span class="math math-inline">(\tau_i, \tau_j)</span>)에 대해, <span class="math math-inline">\tau_i \succ \tau_j</span> (<span class="math math-inline">\tau_i</span>가 <span class="math math-inline">\tau_j</span>보다 선호됨)일 확률을 최대화하는 보상 함수 <span class="math math-inline">\hat{R}_\theta</span>를 찾는 것이다. 이는 궤적의 누적 보상이 선호도 순서와 일치하도록 하는 방향으로 보상 함수를 학습하는 것을 의미하며, 일반적으로 다음과 같은 로그-우도(log-likelihood) 손실 함수를 최소화하는 방식으로 이루어진다:</p>
<p><span class="math math-display">
\mathcal{L}(\theta) = -\sum_{(\tau_i, \tau_j) \in \mathcal{D}_{\text{ranked}}} \log \left( \frac{\exp(\sum_{s_t \in \tau_i} \hat{R}_\theta(s_t))}{\exp(\sum_{s_t \in \tau_i} \hat{R}_\theta(s_t)) + \exp(\sum_{s_t \in \tau_j} \hat{R}_\theta(s_t))} \right)
</span><br />
여기서 <span class="math math-inline">\hat{R}_\theta</span>는 파라미터 <span class="math math-inline">\theta</span>를 갖는 신경망으로 표현된 보상 함수이며, <span class="math math-inline">\mathcal{D}_{\text{ranked}}</span>는 순위가 매겨진 궤적 쌍의 집합이다.</p>
</li>
<li>
<p><strong>저자 및 소속:</strong> 이 연구는 당시 텍사스 대학교 오스틴(University of Texas at Austin) 소속의 Daniel S. Brown, Wonjoon Goo, Scott Niekum에 의해 수행되었다.25</p>
</li>
<li>
<p><strong>의의 및 파급 효과:</strong> D-REX는 시연 데이터를 모방해야 할 ’절대적인 정답’으로 간주하던 기존의 관점에서 벗어나, 더 나은 해답을 찾아가기 위한 ’방향성을 가진 단서’로 재해석하는 중요한 관점의 전환을 이루었다. 잡음을 통해 의도적으로 ‘더 나쁜’ 예시를 생성하고, 이를 통해 ‘더 좋은’ 방향이 무엇인지를 역으로 추론하는 방식은, 데이터의 절대적인 질보다 데이터 간의 ’상대적 관계’가 때로는 더 중요한 정보일 수 있음을 보여준다. 이는 마치 학생이 불완전한 교사의 풀이를 보고, 그 풀이의 어떤 부분이 핵심 원리이고 어떤 부분이 실수인지를 스스로 추론하여 더 나은 풀이법을 찾아내는 고차원적인 학습 과정과 유사하다. 이 연구는 이후 불완전한 데이터로부터 학습하는 다양한 연구에 영감을 주었다.</p>
</li>
</ul>
<h2>6. 결론: 2019년 연구 성과의 통합적 분석 및 2020년 전망</h2>
<p>2019년 10월을 전후한 시점의 AI 및 로봇 분야는 국가적 차원의 전략적 경쟁과 학문적 영역에서의 근본적인 기술 혁신이 서로 영향을 주고받으며 역동적으로 발전하는 모습을 보여주었다. 본 보고서에서 분석한 주요국의 국가 전략과 세계 최고 수준 학회에서 발표된 핵심 연구들은 개별적으로도 중요하지만, 이들을 통합적으로 조망할 때 2019년이 AI 기술 발전의 중요한 변곡점이었음을 더욱 명확히 알 수 있다.</p>
<h3>6.1 통합적 분석: 정책과 연구, 그리고 현실 세계의 제약을 넘어서</h3>
<p>첫째, <strong>정책과 연구의 상호작용</strong>이 뚜렷하게 나타났다. 1장에서 분석한 국가 전략과 2-4장에서 분석한 학술적 성과는 서로 긴밀하게 연결되어 있다. 미국의 ‘AI 안전성’ 및 ‘프라이버시 보호’ 강조는 1 ICCV에서 발표된 ‘프라이버시 보존 이미지 쿼리’ 연구와 9 같은 사회적 책임을 고려한 기술 개발로 이어졌다. 또한, 한국의 ’재난 대응’이라는 구체적인 사회문제 해결형 R&amp;D 챌린지는 4 IROS에서 발표된 ‘동적 환경에서의 반응형 로봇 조작’ 연구가 19 지향해야 할 실용적 목표가 될 수 있음을 시사한다. 이는 국가 정책이 연구 개발의 방향성을 제시하고, 학술 연구는 정책 목표를 달성하기 위한 기술적 해법을 제공하는 선순환 구조의 가능성을 보여준다.</p>
<p>둘째, 2019년 10월의 <strong>핵심 기술 돌파구들은 공통적으로 ’현실 세계의 제약과 불확실성 극복’이라는 거대한 흐름</strong> 속에 위치한다. 본 보고서에서 심층 분석한 세 가지 핵심 연구는 각각 다른 형태의 제약을 극복하려는 시도였다.</p>
<ul>
<li>
<p><strong>SinGAN (ICCV 2019 Best Paper):</strong> 대규모 데이터셋이라는 ’데이터의 제약’을 극복하고, 단 한 장의 이미지로부터 무한한 창조의 가능성을 열었다.</p>
</li>
<li>
<p><strong>Planning Reactive Manipulation (IROS 2019 Best Paper):</strong> 정적이고 예측 가능한 환경이라는 ’물리적 환경의 제약’을 극복하고, 실시간으로 변화하는 동적 세계와의 상호작용을 가능하게 했다.</p>
</li>
<li>
<p><strong>D-REX (CoRL 2019):</strong> 완벽한 전문가 시연이라는 ’지식의 제약’을 극복하고, 불완전한 정보로부터 더 나은 지혜를 외삽하는 방법을 제시했다.</p>
</li>
</ul>
<p>이 세 연구는 AI가 이상적이고 통제된 가상 환경에서 벗어나, 데이터가 부족하고, 환경이 끊임없이 변하며, 제공되는 지식이 불완전한 ’현실 세계’의 문제들을 해결하기 위한 기술적 성숙을 이루기 시작했음을 보여주는 중요한 증거이다.</p>
<table><thead><tr><th>학회</th><th>논문명</th><th>핵심 문제 (극복 대상)</th><th>제안 방법론</th><th>기술적 기여 및 파급 효과</th></tr></thead><tbody>
<tr><td><strong>ICCV 2019</strong></td><td>SinGAN: Learning a Generative Model From a Single Natural Image</td><td><strong>데이터 제약:</strong> 대규모 데이터셋 없이 이미지 생성</td><td>다중 스케일 GAN 피라미드 구조</td><td>’Big Data’에서 ’Deep Data’로의 패러다임 전환 제시. 데이터 수집이 어려운 분야로 생성 모델 응용 확장.</td></tr>
<tr><td><strong>IROS 2019</strong></td><td>Planning Reactive Manipulation in Dynamic Environments</td><td><strong>물리적 환경 제약:</strong> 동적이고 예측 불가능한 환경에서의 로봇 조작</td><td>제약 기반 컨트롤러와 강화학습 에이전트를 결합한 하이브리드 제어</td><td>전통적 제어 이론과 최신 AI의 성공적 융합. 실제 환경에서의 로봇 자율성 및 견고성 증대.</td></tr>
<tr><td><strong>CoRL 2019</strong></td><td>Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations</td><td><strong>지식의 제약:</strong> 불완전한(suboptimal) 시연 데이터로부터 학습</td><td>잡음 주입을 통한 자동 순위화 궤적 생성 및 순위 기반 역강화학습 (D-REX)</td><td>시연자의 성능을 뛰어넘는 모방 학습 최초 구현. 불완전한 데이터로부터 지식 외삽(extrapolation) 가능성 입증.</td></tr>
</tbody></table>
<h3>6.2 년 및 미래 전망</h3>
<p>2019년 10월에 나타난 이러한 기술적, 정책적 흐름을 바탕으로, 2020년 이후의 AI 및 로봇 분야는 다음과 같은 방향으로 발전할 것으로 전망된다.</p>
<ul>
<li>
<p><strong>초거대 모델과 데이터 효율성의 공존:</strong> 2020년 GPT-3의 등장을 기점으로 AI 모델의 규모는 더욱 커질 것이다. 그러나 동시에 SinGAN과 D-REX에서 시작된 데이터 효율성, 소수 데이터 학습(few-shot learning), 자기지도학습(self-supervised learning)에 대한 연구 역시 AI의 또 다른 중요한 축으로 발전하며, 막대한 자원을 투입하기 어려운 다양한 산업 및 연구 분야에서 AI의 민주화를 이끌 것이다.</p>
</li>
<li>
<p><strong>AI의 물리 세계 접목 가속화:</strong> IROS에서 보여준 AI와 로보틱스의 융합은 더욱 가속화될 것이다. 자율주행, 스마트 팩토리, 물류 로봇, 서비스 로봇 등 물리적 세계와 직접 상호작용하는 AI 응용 분야가 본격적으로 성장하며, 이는 산업 생산성을 높이고 인간의 삶의 질을 향상시키는 데 기여할 것이다. 산업 재해 감소와 같은 긍정적 효과도 기대된다.30</p>
</li>
<li>
<p><strong>신뢰할 수 있는 AI (Trustworthy AI)의 부상:</strong> 2019년 각국 국가 전략에서 공통적으로 강조된 안전성, 공정성, 프라이버시, 투명성 문제는 2020년 이후 AI 연구의 핵심 주제로 확고히 자리 잡을 것이다. 설명가능 AI(XAI), 공정성 및 편향성 완화, 적대적 공격에 대한 견고성(robustness) 확보, 데이터 프라이버시 보호 기술에 대한 연구가 학계와 산업계 모두에서 주류가 될 것으로 예측된다.</p>
</li>
</ul>
<p>결론적으로, 2019년 10월은 AI 기술이 양적 성장을 넘어 질적 전환을 시작한 시기였다. 기술 패권 경쟁이라는 거시적 동력과 현실 세계의 제약을 극복하려는 미시적 혁신이 맞물리면서, AI는 더 지능적이고, 더 효율적이며, 더 책임감 있는 방향으로의 진화를 시작했다. 이 시기에 뿌려진 씨앗들은 이후 AI 기술의 지형을 근본적으로 바꾸는 중요한 밑거름이 되었다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>미국의 인공지능(AI) 정책․전략 현황과 변화 방향, https://www.nia.or.kr/common/board/Download.do?bcIdx=27248&amp;cbIdx=82618&amp;fileNo=1</li>
<li>[AI 10대 뉴스] 2019년은 첫째도, 둘째도, 셋째도 AI - IT조선, https://it.chosun.com/news/articleView.html?idxno=2019123001634</li>
<li>인공지능을 둘러싼 미·중 전략 경쟁과 우리의 대응 방향 - 대외경제정책연구원, https://www.kiep.go.kr/galleryDownload.es?bid=0002&amp;list_no=11759&amp;seq=1</li>
<li>2019년 인공지능(AI) 그랜드 챌린지의 서막이 열린다, https://www.korea.kr/goNews/resources/attaches/2019.01/02/5c293a06a4d4aa22feba5e3ce0f2336e.pdf</li>
<li>2019년 로보월드 특집호, http://www.irobotnews.com/event/image/dn_20191008.pdf</li>
<li>ICCV 2019, https://iccv2019.thecvf.com/</li>
<li>IROS 2019 - Macau, https://www.iros2019.org/</li>
<li>CoRL_2019 - Paper Submission - CoRL 2019, https://2019.corl.org/home/paper-submission</li>
<li>Privacy Preserving Image Queries for Camera Localization - ICCV 2019 Open Access Repository, https://openaccess.thecvf.com/content_ICCV_2019/html/Speciale_Privacy_Preserving_Image_Queries_for_Camera_Localization_ICCV_2019_paper.html</li>
<li>Best paper award (Marr prize) - ICCV 2019, https://iccv2019.thecvf.com/program/main_conference</li>
<li>ICCV Paper Awards - IEEE Computer Society Technical Committee on Pattern Analysis and Machine Intelligence, https://tc.computer.org/tcpami/awards/iccv-paper-awards/</li>
<li>Shaham SinGAN Learning A Generative Model From A Single Natural Image ICCV 2019 Paper PDF - Scribd, https://www.scribd.com/document/434279384/Shaham-SinGAN-Learning-a-Generative-Model-From-a-Single-Natural-Image-ICCV-2019-paper-pdf</li>
<li>Paper page - SinGAN: Learning a Generative Model from a Single Natural Image, https://huggingface.co/papers/1905.01164</li>
<li>SinGAN: Learning a Generative Model from a Single Natural Image - Tamar Rott Shaham, https://tamarott.github.io/SinGAN.htm</li>
<li>ICCV 2019 Best Papers Announced - Synced Review, https://syncedreview.com/2019/10/29/iccv-2019-best-papers-announced/</li>
<li>SinGAN: Learning a Generative Model From a … - CVF Open Access, https://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf</li>
<li>An In-Depth Look at SinGAN | by Yilin (Jim) Shi | Medium, https://macjim.medium.com/a-in-depth-look-at-singan-bec2a2bd6e84</li>
<li>Fast and Practical Neural Architecture Search - ICCV 2019 Open Access Repository, https://openaccess.thecvf.com/content_ICCV_2019/html/Cui_Fast_and_Practical_Neural_Architecture_Search_ICCV_2019_paper.html</li>
<li>Best Paper Award - IROS 2019 - Macau, https://www.iros2019.org/awards</li>
<li>Planning Reactive Manipulation in Dynamic Environments, http://ais.informatik.uni-freiburg.de/publications/papers/schmitt19iros.pdf</li>
<li>로봇신문 ‘2019 올해의 대한민국 로봇기업’ 선정, https://www.irobotnews.com/news/articleView.html?idxno=18999</li>
<li>Finalist of Best Poster Paper Award, https://research.polyu.edu.hk/files/21611344/IROS_workshop_award_2019_4.pdf</li>
<li>Volume 100: Conference on Robot Learning, 30-1 November 2019, https://proceedings.mlr.press/v100/</li>
<li>[1907.03976] Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations - arXiv, https://arxiv.org/abs/1907.03976</li>
<li>Better-than-Demonstrator Imitation Learning via Automatically …, https://proceedings.mlr.press/v100/brown20a/brown20a.pdf</li>
<li>Ranking-Based Reward Extrapolation without Rankings - arXiv, https://www.arxiv.org/pdf/1907.03976v2</li>
<li>dsbrown1331/CoRL2019-DREX: Code and project page for D-REX algorithm from the paper “Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations” presented at CoRL 2019. - GitHub, https://github.com/dsbrown1331/CoRL2019-DREX</li>
<li>D-REX Project Page | Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations - Daniel Brown, https://dsbrown1331.github.io/CoRL2019-DREX/</li>
<li>[PDF] Better-than-Demonstrator Imitation Learning via Automatically-Ranked … - Semantic Scholar, https://www.semanticscholar.org/paper/Better-than-Demonstrator-Imitation-Learning-via-Brown-Goo/9e13129b14166291892ce0b3a0ee90c02dc7625f</li>
<li>로봇 도입 확대로 2010∼2019년 재해근로자 4만1천명 줄었다 - 연합뉴스, https://www.yna.co.kr/view/AKR20230227056500002</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>