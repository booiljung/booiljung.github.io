<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2019년 11월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2019년 11월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2019년 AI 및 로봇 연구 동향</a> / <span>2019년 11월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2019년 11월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2019년 11월, AI 연구의 변곡점</h2>
<p>2019년 11월은 인공지능(AI) 분야가 중대한 변곡점을 맞이한 시점이었다. BERT와 같은 거대 언어 모델의 성공으로 딥러닝 기술의 잠재력이 입증되었으나, 동시에 이들 모델의 막대한 계산 및 메모리 요구사항은 새로운 연구 방향에 대한 고민을 촉발했다.1 학계와 산업계는 단순히 모델의 크기를 키우는 ‘스케일업(scale-up)’ 경쟁을 넘어, 아키텍처의 근본적인 효율성과 그 이론적 토대를 탐구하는 방향으로 나아가고 있었다.</p>
<p>이러한 기술적 전환기에 AI 및 로봇 공학 분야의 최고 권위 학회인 신경정보처리시스템학회(NeurIPS)와 로봇학습학회(CoRL)의 발표 예정 논문들이 공개되었다. NeurIPS는 알고리즘, AutoML, 메타 학습 등 AI의 근간을 이루는 광범위한 주제를 다루며 3, CoRL은 모방 학습, 강화 학습, 제어 등 로봇 지능의 핵심 응용 분야에 집중하는 학회다.4 따라서 2019년 11월에 공개된 이들 학회의 채택 논문 목록은 당시 해당 분야의 가장 첨예한 연구 방향과 미래를 가늠할 수 있는 중요한 지표였다.4</p>
<p>본 보고서는 2019년 11월에 발표된 주요 연구들을 심층적으로 분석하여 당시 AI 및 로봇 공학 분야의 핵심적인 기술적 진보와 그 의미를 조망하고자 한다. 1부에서는 NeurIPS 2019에서 제시된 심층 신경망 아키텍처의 패러다임 전환을 분석하고, 2부에서는 CoRL 2019를 중심으로 로봇 학습의 이론적 진보를 탐구한다. 마지막으로 3부에서는 개별 연구를 넘어 당시의 광범위한 기술 트렌드와 사회적 영향을 종합적으로 조망함으로써, 2019년 11월이 AI 및 로봇 공학 분야의 발전에 어떤 이정표를 세웠는지 심층적으로 분석한다.</p>
<h2>2. 부: 심층 신경망 아키텍처의 패러다임 전환: NeurIPS 2019 주요 연구</h2>
<p>NeurIPS 2019에서는 기존 딥러닝 모델의 구조적 한계를 극복하고 새로운 설계 철학을 제시한 혁신적인 연구들이 다수 발표되었다. 특히 모델의 깊이와 파라미터 활용 방식에 대한 근본적인 재해석을 통해 효율성과 성능을 동시에 추구하는 흐름이 두드러졌다.</p>
<h3>2.1  무한 깊이 신경망의 구현: 심층 평형 모델 (Deep Equilibrium Models, DEQ)</h3>
<p>Shaojie Bai, J. Zico Kolter, Vladlen Koltun이 발표한 ’심층 평형 모델(DEQ)’은 신경망의 ’깊이’라는 개념에 대한 기존의 통념을 완전히 뒤집은 혁신적인 연구다.2 이 모델은 유한한 수의 레이어를 순차적으로 쌓는 명시적(explicit) 깊이 개념에서 벗어나, 신경망의 순전파 과정을 특정 비선형 변환의 평형점(equilibrium point) 또는 고정점(fixed point)을 찾는 문제로 재정의했다.7</p>
<p>DEQ의 방법론적 핵심은 가중치가 묶인(weight-tied) 무한 깊이의 신경망과 등가적인 표현을, 실제로는 반복적인 레이어 계산 없이 달성하는 데 있다. 이는 Broyden 방법과 같은 블랙박스 근 찾기(root-finding) 알고리즘을 사용하여 평형점 <span class="math math-inline">z^*</span>를 직접 계산함으로써 이루어진다. 즉, DEQ는 <span class="math math-inline">z^* = f_{\theta}(z^*, x)</span>라는 방정식을 만족하는 해 <span class="math math-inline">z^*</span>를 효율적으로 찾아낸다.7</p>
<p>이 접근법의 가장 큰 장점은 역전파 과정에서 발현된다. DEQ는 암시적 함수 정리(Implicit Function Theorem)를 활용하여 평형점에서의 그래디언트를 중간 활성화 값의 저장 없이 해석적으로 계산할 수 있다. 이로 인해 이론적으로는 무한한 깊이를 가지면서도, 훈련 과정에서는 단일 레이어에 해당하는 상수 메모리(<span class="math math-inline">O(1)</span> memory)만을 요구하는 경이로운 효율성을 달성한다.7 그래디언트 계산은 다음 수식으로 표현된다.</p>
<p><span class="math math-display">
\frac{\partial L}{\partial \theta} = \frac{\partial L}{\partial z^*} \left( I - \frac{\partial f_{\theta}}{\partial z^*} \right)^{-1} \frac{\partial f_{\theta}(z^*, x)}{\partial \theta}
</span><br />
DEQ는 WikiText-103과 같은 대규모 언어 모델링 태스크에서 유사한 파라미터 수를 가진 기존 최첨단 모델(예: Transformer)의 성능을 능가함을 보이며, 단순한 이론적 제안을 넘어 실제 문제에서도 효과적임을 입증했다.6 이 연구는 이후 다중 스케일 DEQ(MDEQ), 리아푸노프 안정 DEQ(LyaDEQ) 등 다양한 후속 연구를 촉발하며 ’암시적 레이어(implicit layer)’라는 새로운 연구 분야를 개척하는 데 결정적인 역할을 했다.10</p>
<p>DEQ는 단순히 메모리 효율적인 아키텍처를 제안한 것을 넘어, 심층 신경망을 ’유한한 레이어의 집합’이 아닌 ’평형을 찾아가는 동적 시스템(dynamical system)’으로 바라보는 근본적인 관점의 전환을 제시했다. DEQ의 핵심 수식 <span class="math math-inline">z^* = f_{\theta}(z^*, x)</span>는 동적 시스템 이론에서 고정점을 정의하는 방정식과 형태가 동일하다.7 이는 딥러닝 모델의 작동 방식을 이산적인 레이어 통과가 아닌, 연속적인 상태 수렴 과정으로 해석할 수 있는 길을 열어준다. 이러한 관점의 변화는 제어 이론, 동적 시스템 이론 등 다른 과학 분야의 성숙한 분석 도구들을 딥러닝에 접목할 수 있는 이론적 토대를 마련했으며, 실제로 DEQ 발표 이후 안정성 문제를 다루기 위해 리아푸노프 안정성 이론을 적용한 LyaDEQ와 같은 후속 연구가 등장했다는 사실이 이를 방증한다.12 따라서 2019년 11월 DEQ의 등장은, 딥러닝 아키텍처 설계가 ’구조 공학’에서 ’시스템 모델링’으로 한 단계 발전할 가능성을 연 중대한 사건으로 평가할 수 있다.</p>
<table><thead><tr><th>특징 (Feature)</th><th>전통적 심층 신경망 (예: ResNet)</th><th>심층 평형 모델 (DEQ)</th></tr></thead><tbody>
<tr><td><strong>구조 (Structure)</strong></td><td>명시적 깊이 (Explicit Depth): <span class="math math-inline">L</span>개의 레이어 스택</td><td>암시적 깊이 (Implicit Depth): 단일 변환 <span class="math math-inline">f_{\theta}</span></td></tr>
<tr><td><strong>순전파 (Forward Pass)</strong></td><td><span class="math math-inline">z_{[i+1]} = f_i(z_{[i]}, x)</span>를 <span class="math math-inline">L</span>번 반복</td><td><span class="math math-inline">z^* = f_{\theta}(z^*, x)</span>의 평형점 <span class="math math-inline">z^*</span>를 근 찾기 알고리즘으로 계산</td></tr>
<tr><td><strong>역전파 (Backward Pass)</strong></td><td>모든 중간 활성화 값 <span class="math math-inline">z_{}...z_{[L-1]}</span> 저장 필요</td><td>암시적 함수 정리를 통해 해석적으로 그래디언트 계산</td></tr>
<tr><td><strong>메모리 복잡도 (Memory)</strong></td><td><span class="math math-inline">O(L)</span> (깊이에 비례)</td><td><span class="math math-inline">O(1)</span> (깊이와 무관하게 상수)</td></tr>
<tr><td><strong>핵심 개념 (Core Concept)</strong></td><td>표현 학습을 위한 계층적 변환</td><td>동적 시스템의 평형점 탐색</td></tr>
</tbody></table>
<h3>2.2  추론 효율성 극대화를 위한 동적 접근: 조건부 매개변수화 합성곱 (CondConv)</h3>
<p>Brandon Yang, Gabriel Bender, Quoc V. Le, Jiquan Ngiam이 발표한 ’조건부 매개변수화 합성곱(CondConv)’은 모든 입력 데이터에 동일한 정적(static) 필터를 적용하는 기존 합성곱 신경망(CNN)의 기본 패러다임에 도전한 연구다.5 CondConv는 각 입력 예시에 따라 동적으로 특화된 합성곱 커널을 생성하여 모델의 표현력과 추론 효율성 간의 균형을 획기적으로 개선했다.1</p>
<p>CondConv의 핵심 아이디어는 <span class="math math-inline">n</span>개의 ‘전문가 커널(expert kernels)’ <span class="math math-inline">W_1,..., W_n</span>을 미리 정의하고, 입력 <span class="math math-inline">x</span>가 주어지면 라우팅 함수(routing function)를 통해 각 전문가의 가중치 <span class="math math-inline">\alpha_1,..., \alpha_n</span>을 계산하는 것이다. 최종적으로 사용되는 커널은 이들의 가중합인 <span class="math math-inline">(\alpha_1 \cdot W_1 +... + \alpha_n \cdot W_n)</span>으로 결정된다.1 이때 라우팅 함수는 전역 평균 풀링(Global Average Pooling), 완전 연결 레이어, 시그모이드(Sigmoid) 함수로 구성되어 계산 비용이 매우 낮다.13</p>
<p>이 방식은 <span class="math math-inline">n</span>개의 독립적인 합성곱 결과를 가중합하는 전문가 혼합(Mixture of Experts, MoE) 방식과 수학적으로는 등가이지만, <span class="math math-inline">n</span>번의 값비싼 합성곱 연산을 단 한 번으로 줄여 계산 효율성을 크게 높였다는 점에서 차별화된다.1 최종 커널 생성 수식은 다음과 같다.</p>
<p><span class="math math-display">
\text{Output}(x) = \sigma((\alpha_1 \cdot W_1 + \ldots + \alpha_n \cdot W_n) * x)
</span><br />
CondConv는 EfficientNet-B0에 적용되었을 때, 매우 적은 연산량(413M Multiply-Adds) 증가만으로 ImageNet 분류 정확도를 77.2%에서 78.3%로 끌어올리는 인상적인 결과를 보였다.1 이는 모델 용량(capacity)을 늘리는 새로운 차원을 제시한 것으로, 이후 DyConv, ODConv 등 다양한 동적 컨볼루션 연구 흐름을 촉발시키는 계기가 되었다.15</p>
<p>CondConv는 ’파라미터 공유(parameter sharing)’라는 CNN의 근본적인 성공 원칙을 ’조건부 파라미터 공유’라는 개념으로 확장한 것으로 해석할 수 있다. 전통적인 CNN은 이미지의 위치에 상관없이 동일한 커널(파라미터)을 공유하여 효율적으로 특징을 추출한다. CondConv는 이 원칙을 완전히 버리지 않고, <span class="math math-inline">n</span>개의 전문가 커널은 여전히 모든 데이터에 대해 공유되도록 유지한다.1 하지만 이 커널들을 ’어떻게 조합할지’를 입력마다 다르게 결정함으로써, 최종적으로 적용되는 ’유효 커널(effective kernel)’은 입력에 종속되게 만든다. 이는 완전한 파라미터 공유와 각 입력마다 완전히 다른 파라미터를 사용하는 것 사이의 현명한 절충안이다. 즉, ’전역적(global) 지식’을 담은 전문가 풀을 유지하면서 ’지역적(local)’인 입력 정보에 맞춰 이를 활용하는 방식이다. 이러한 ‘조건부 전문화’ 개념은 이후 대규모 언어 모델에서 특정 토큰이나 작업에 따라 다른 전문가 네트워크를 활성화하는 희소 전문가 혼합(Sparse MoE) 아키텍처의 철학과 맥을 같이 한다. 따라서 CondConv는 2019년 당시, 거대 모델의 효율성과 표현력을 동시에 잡기 위한 ’동적 계산’이라는 거대한 흐름의 중요한 초기 신호탄이었다.</p>
<table><thead><tr><th>아키텍처 (Architecture)</th><th>기준 성능 (Baseline)</th><th>CondConv (n=8) 적용</th><th>연산량 증가 (MAdds)</th></tr></thead><tbody>
<tr><td><strong>커널 생성 수식</strong></td><td><span class="math math-inline">W_{\text{static}}</span></td><td><span class="math math-inline">W_{\text{dynamic}} = \sum \alpha_i(x) \cdot W_i</span></td><td><span class="math math-inline">r(x) = \text{Sigmoid}(\text{GAP}(x)R)</span></td></tr>
<tr><td>MobileNetV2 (1.0x)</td><td>71.6%</td><td><strong>74.6%</strong></td><td>301M → 329M (+9.3%)</td></tr>
<tr><td>ResNet-50</td><td>77.7%</td><td><strong>78.6%</strong></td><td>4093M → 4213M (+2.9%)</td></tr>
<tr><td>EfficientNet-B0</td><td>77.2%</td><td><strong>78.3%</strong></td><td>391M → 413M (+5.6%)</td></tr>
</tbody></table>
<h3>2.3  기타 핵심 연구 동향: 메타 학습, 적대적 강건성, 그리고 언어 이해</h3>
<p>NeurIPS 2019에서는 아키텍처 혁신 외에도 다양한 분야에서 중요한 연구들이 발표되었다.</p>
<ul>
<li>
<p><strong>메타 학습 (Meta-Learning)</strong>: 소수의 데이터만으로 새로운 작업에 빠르게 적응하는 능력을 목표로 하는 메타 학습은 당시 주요 연구 주제 중 하나였다.3 “Multimodal Model-Agnostic Meta-Learning“과 같은 연구는 다양한 양식(modality)의 데이터를 활용하여 메타 학습의 성능을 높이는 방법을 모색했으며, 이는 소량 데이터 학습(few-shot learning)의 실용성을 한 단계 끌어올리는 데 기여했다.5</p>
</li>
<li>
<p><strong>적대적 강건성 (Adversarial Robustness)</strong>: 딥러닝 모델이 인간이 인지하기 어려운 미세한 입력 교란에 취약하다는 문제가 지속적으로 제기되면서, 이에 대한 방어 기법 연구가 활발히 진행되었다. “Metric Learning for Adversarial Robustness“는 적대적 예시를 잘 구분할 수 있는 특징 공간(feature space)을 학습하는 새로운 접근법을 제시하며, 모델의 신뢰도를 높이기 위한 근본적인 해결책을 모색했다.5</p>
</li>
<li>
<p><strong>SuperGLUE 벤치마크</strong>: 자연어 처리(NLP) 분야에서는 모델의 일반적인 언어 이해 능력을 보다 엄격하게 평가하기 위한 “SuperGLUE” 벤치마크가 발표되었다.5 이는 기존 GLUE 벤치마크보다 더 어렵고 다양한 태스크로 구성되어, 이후 대규모 언어 모델들의 성능 경쟁을 촉진하고 연구 방향을 제시하는 중요한 이정표가 되었다.</p>
</li>
</ul>
<h2>3. 부: 로봇 지능의 진화: CoRL 2019 및 관련 로보틱스 연구</h2>
<p>로봇이 복잡하고 동적인 현실 세계와 상호작용하며 지능적으로 학습하는 방법에 대한 연구는 로봇 공학의 핵심 과제다. CoRL 2019와 동시기에 발표된 주요 arXiv 논문들은 모방 학습의 이론적 토대를 재정립하고, 강화 학습의 현실 적용성을 높이는 등 이 분야의 중요한 진전을 이루었다.</p>
<h3>3.1  모방 학습의 통합적 프레임워크: 발산 최소화 관점 (A Divergence Minimization Perspective)</h3>
<p>Seyed Kamyar Seyed Ghasemipour 등이 발표한 “A Divergence Minimization Perspective on Imitation Learning Methods“는 CoRL 2019 최고 논문상(Best Paper Award)을 수상하며 학계의 큰 주목을 받았다.18 이 연구는 행동 복제(Behavioral Cloning, BC), 생성적 적대 모방 학습(GAIL), Adversarial Inverse RL(AIRL) 등 이전까지 개별적으로 발전해 온 모방 학습(Imitation Learning, IL) 알고리즘들을 ’확률 분포 간의 f-발산(f-divergence) 최소화’라는 단일한 이론적 프레임워크로 통합했다는 점에서 그 의의가 매우 크다.19</p>
<p>저자들은 AIRL을 일반화한 f-MAX 알고리즘을 제안하고, 이를 통해 기존 알고리즘들이 본질적으로 어떤 종류의 발산을 최소화하는지 명확히 규명했다.19 예를 들어, 표준 BC는 전문가 정책과 학습자 정책 간의 순방향 KL-발산(forward KL-divergence)을, AIRL은 상태-행동 분포 간의 역방향 KL-발산(reverse KL-divergence)을 최소화하는 것과 수학적으로 등가임을 보였다.19</p>
<p>더 나아가, 심층적인 실험을 통해 역강화학습(IRL) 계열 방법론이 BC보다 우수한 성능을 보이는 핵심적인 이유가 단순히 상태-행동(state-action) 분포를 모방하기 때문이 아니라, 더 넓은 범위의 ’상태 주변 분포(state-marginal distribution)’를 일치시키기 때문임을 결정적으로 밝혔다.19 이는 로봇이 단순히 전문가의 특정 ’행동’을 따라하는 것을 넘어, 전문가가 도달하는 다양한 ’상태’를 경험하도록 유도하는 것이 일반화 성능 향상에 훨씬 중요하다는 깊은 통찰을 제공한다.</p>
<p>이 연구는 모방 학습 연구의 방향을 ’새로운 알고리즘의 발명’에서 ’목표 분포와 발산 척도의 올바른 선택’이라는 보다 근본적인 문제로 전환시켰다. 이전까지 IL 연구는 GAIL, AIRL 등 새로운 알고리즘을 제안하고 경험적으로 성능을 비교하는 데 집중하는 경향이 있었다.21 그러나 이 논문은 이들 알고리즘이 사실상 동일한 상위 프레임워크(f-divergence minimization) 내에서 다른 ‘하이퍼파라미터’(즉, 발산의 종류)를 선택한 것에 불과함을 보였다.19 이는 연구자들에게 새로운 알고리즘을 만들기 전에 “우리가 해결하려는 문제의 본질이 무엇인가?“를 먼저 묻게 만든다. 예를 들어, 전문가의 행동이 여러 가지 뚜렷한 방식(multi-modal)으로 나타난다면, 평균적인 행동을 학습하는 순방향 KL(BC)보다는 특정 모드를 집중적으로 학습하는 역방향 KL(AIRL)이 더 적합할 수 있다는 이론적 근거를 제공한다.21 결과적으로, 이 연구는 향후 IL 연구가 단순히 성능을 높이는 것을 넘어, 원하는 로봇 행동의 특성(예: 다양성, 정확성)에 맞춰 적절한 수학적 목적 함수를 설계하는, 보다 원칙에 입각한(principled) 접근법을 취하도록 유도했다.</p>
<table><thead><tr><th>방법 (Method)</th><th>최적화 목적 함수 (Optimized Objective - Minimization View)</th><th>분포 유형 (Distribution Type)</th><th>발산 종류 (Divergence Type)</th><th>핵심 특징 (Key Trait)</th></tr></thead><tbody>
<tr><td><strong>행동 복제 (BC)</strong></td><td><span class="math math-inline">E_{p_{\text{exp}}(s)}[KL(\pi_{\text{exp}}(a \vert s) \Vert \pi(a \vert s))]</span></td><td>정책 (Policy)</td><td>순방향 KL (Forward KL)</td><td>Mass-covering, 평균적 행동 모방</td></tr>
<tr><td><strong>GAIL</strong></td><td><span class="math math-inline">D_{JS}(p_{\pi}(s, a) \Vert p_{\text{exp}}(s, a))</span></td><td>상태-행동 (State-Action)</td><td>Jensen-Shannon</td><td>분포의 중심을 맞추려는 경향</td></tr>
<tr><td><strong>AIRL</strong></td><td><span class="math math-inline">KL(p_{\pi}(s, a) \Vert p_{\text{exp}}(s, a))</span></td><td>상태-행동 (State-Action)</td><td>역방향 KL (Reverse KL)</td><td>Mode-seeking, 전문가 행동 집중</td></tr>
<tr><td><strong>f-MAX (본 연구)</strong></td><td><span class="math math-inline">D_f(p_{\pi}(s, a) \Vert p_{\text{exp}}(s, a))</span></td><td>상태-행동 (State-Action)</td><td>일반화된 f-Divergence</td><td>모든 IL을 통합하는 프레임워크</td></tr>
</tbody></table>
<h3>3.2  현실과 가상의 연결: Embodied AI를 위한 Habitat 플랫폼</h3>
<p>Manolis Savva 등이 발표한 Habitat은 가상 환경 속에서 로봇(embodied agent)을 효율적으로 훈련시키기 위한 고성능 오픈소스 플랫폼이다.23 이는 Embodied AI 연구의 고질적인 문제였던 느린 시뮬레이션 속도와 표준화된 실험 환경의 부재를 해결하기 위해 개발되었다. Habitat은 초고속 3D 시뮬레이터인</p>
<p><strong>Habitat-Sim</strong>과 AI 알고리즘 개발을 위한 라이브러리인 <strong>Habitat-API</strong>로 구성된다.23 특히 Habitat-Sim은 단일 GPU에서 초당 수천 프레임(fps), 다중 프로세스 환경에서는 10,000fps 이상의 렌더링 속도를 달성하여, 기존 시뮬레이터보다 월등히 빠른 학습을 가능하게 한다.23</p>
<p>이 플랫폼의 압도적인 효율성은 이전에는 불가능했던 대규모 실험을 가능하게 했다. 저자들은 이를 활용해 ‘목표 지점 탐색(point-goal navigation)’ 태스크에서 학습 기반 접근법과 전통적인 SLAM(동시적 위치추정 및 지도작성) 접근법을 비교했다. 이전 연구보다 10배 이상 많은 경험 데이터(수억 프레임)로 학습시킨 결과, 기존의 통념과 달리 <strong>학습 기반 접근법이 SLAM의 성능을 능가</strong>한다는 새로운 결론을 이끌어냈다.23 이는 Embodied AI 연구에서 대규모 데이터 기반 학습의 중요성을 명확히 보여준 사례다.</p>
<h3>3.3  강화학습 기반 로봇 제어의 실용적 발전</h3>
<p>강화학습을 실제 로봇에 적용하기 위한 실용적인 연구들도 다수 발표되었다.</p>
<ul>
<li>
<p><strong>Robo-PlaNet</strong>: 모델 기반 강화학습 알고리즘인 PlaNet을 실제 로봇에 적용할 때 발생하는 긴 훈련 시간과 로봇 유휴(idle) 문제를 해결하기 위해 제안되었다.24 데이터 수집(roller process)과 모델 학습(learner process)을 비동기적으로 병렬 처리함으로써, 동일한 시간 내에 더 높은 성능을 달성하고 실제 로봇의 가동률을 극대화했다.24 이는 강화학습의 현실 적용 가능성을 높인 중요한 공학적 기여다.</p>
</li>
<li>
<p><strong>IRIS (Implicit Reinforcement without Interaction at Scale)</strong>: 크라우드소싱을 통해 수집된 대규모의, 그리고 최적이 아닌(suboptimal) 오프라인 로봇 조작 데이터로부터 상호작용 없이 유용한 제어 정책을 학습하는 프레임워크를 제안했다.25 이는 목표에 도달하기 위한 저수준 제어기와 목표를 설정하는 고수준 선택 메커니즘을 분리하여, 다양한 시연 데이터의 장점만을 조합해 성공률을 높이는 독창적인 접근법을 제시했다.</p>
</li>
</ul>
<p>이 외에도 인간-로봇 상호작용(HRI)에서 신뢰도와 인지 부하의 관계를 탐구하거나 26, 자율주행을 위한 AI 행동 중재 모델을 제안하는 등 27 다양한 응용 연구가 발표되어 로봇 지능의 저변을 넓혔다.</p>
<h2>4. 부: 2019년 11월 AI 및 로봇 기술의 광범위한 동향과 사회적 영향</h2>
<p>개별 연구 발표를 넘어, 2019년 11월을 전후하여 논의된 AI 및 로봇 기술의 거시적 트렌드와 이것이 사회에 미치는 영향을 종합적으로 분석하는 것은 당시 기술의 현주소를 이해하는 데 필수적이다.</p>
<h3>4.1  기술 동향: 엣지 컴퓨팅, 협동 로봇, 그리고 개방형 표준</h3>
<p>2019년 말, AI 및 로봇 기술은 몇 가지 뚜렷한 방향으로 발전하고 있었다.</p>
<ul>
<li>
<p><strong>로봇과 엣지 컴퓨팅의 결합</strong>: 중앙 클라우드 서버에 대한 의존도를 줄이고 로봇 자체에서 실시간으로 데이터를 처리하는 ’엣지 컴퓨팅’이 중요한 트렌드로 부상했다.28 이는 로봇의 반응 속도를 높이고 통신 대역폭 부담을 줄여 자율성을 향상시키는 핵심 기술로 인식되었다.</p>
</li>
<li>
<p><strong>협동 로봇(Cobots)의 확산</strong>: 인간의 일자리를 대체하는 대신, 인간과 같은 공간에서 협력하여 생산성을 높이는 협동 로봇이 산업 현장에 점차 확산되었다.28 이는 로봇 기술이 인간 노동을 보조하고 위험한 작업을 대신하는 긍정적인 측면을 부각시켰다.</p>
</li>
<li>
<p><strong>개방형 표준의 중요성</strong>: 로봇 기술의 대중화를 위해서는 하드웨어와 소프트웨어 전반에 걸친 개방형 표준이 필수적이라는 인식이 확산되었다.28 이는 개발 생태계를 활성화하고 다양한 로봇 시스템 간의 상호운용성을 보장하기 위한 전제 조건으로 논의되었다.</p>
</li>
</ul>
<h3>4.2  사회적 영향: 기회와 도전의 공존</h3>
<p>AI와 로봇 기술의 발전은 사회 전반에 걸쳐 기회와 도전을 동시에 제시했다.</p>
<ul>
<li>
<p><strong>산업 전반의 변화</strong>: AI와 로봇 기술은 제조업, 물류, 의료, 농업 등 거의 모든 산업 분야를 변화시킬 잠재력을 가진 것으로 평가되었다.29 특히 의료 분야에서는 AI를 통한 빠르고 정확한 진단, 로봇을 이용한 최소 침습 수술 등이 긍정적인 영향으로 주목받았다.29</p>
</li>
<li>
<p><strong>고용 시장에 대한 우려</strong>: 기술 발전의 이면에는 자동화로 인한 대규모 일자리 대체와 부의 불평등 심화에 대한 사회적 우려가 공존했다.29 특히 이전의 자동화가 주로 저임금, 반복 업무에 영향을 미쳤다면, 2019년의 AI 기술은 분석, 예측 등 고임금 화이트칼라 직업군에도 상당한 영향을 미칠 수 있다는 분석이 제기되었다.33</p>
</li>
<li>
<p><strong>인간-AI 관계의 재정립</strong>: 기술이 발전함에 따라, 인간과 AI/로봇이 어떻게 조화롭게 공존할 것인가에 대한 사회적, 철학적 논의가 활발해졌다. 이는 기술 개발이 단순히 성능 향상을 넘어, 인간의 삶의 질을 높이고 사회적 가치를 창출하는 방향으로 나아가야 한다는 공감대를 형성했다.29</p>
</li>
</ul>
<h2>5. 결론: 새로운 10년을 앞둔 AI와 로봇 공학의 현주소</h2>
<p>본 보고서에서 분석한 바와 같이, 2019년 11월은 AI 및 로봇 공학 분야에서 중요한 이론적, 구조적 진보가 이루어진 시기였다. NeurIPS 2019에서 발표된 DEQ와 CondConv는 신경망 아키텍처 설계에 있어 각각 ’암시적 깊이’와 ’동적 계산’이라는 새로운 방향을 제시했으며, CoRL 2019에서 주목받은 ‘발산 최소화’ 프레임워크는 로봇 모방 학습에 깊은 이론적 통찰을 제공했다.</p>
<p>이러한 연구들의 장기적 영향은 지대했다. DEQ가 제시한 암시적 레이어 개념은 이후 신경망의 안정성과 메모리 문제를 다루는 연구의 중요한 토대가 되었다. CondConv가 개척한 동적 컨볼루션은 거대 모델의 효율성을 높이는 핵심 아이디어로 발전했다. 또한, 모방 학습에 대한 통합적 이해는 보다 원칙에 입각한 로봇 학습 알고리즘 설계를 가능하게 했다.</p>
<p>현재 시점에서 돌이켜보면, 2019년 11월에 나타난 이러한 연구들은 2020년대 AI 기술 폭발의 씨앗이 되었다. 당시의 고민이었던 모델의 효율성, 이론적 견고성, 그리고 현실 세계와의 상호작용 문제는 현재의 대규모 언어 모델(LLM)과 범용 로봇 에이전트 개발에 이르기까지 여전히 핵심적인 연구 주제로 남아있다. 결국 이 시점의 연구 성과들은 AI와 로봇 공학이 양적 팽창을 넘어 질적 성숙으로 나아가는 중요한 변곡점을 마련했다고 평가할 수 있다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>CondConv: Conditionally Parameterized Convolutions for Efficient Inference - SciSpace, https://scispace.com/pdf/condconv-conditionally-parameterized-convolutions-for-30nfo8b7iv.pdf</li>
<li>Deep Equilibrium Models - NIPS, https://papers.nips.cc/paper/8358-deep-equilibrium-models</li>
<li>NIPS 2019 Subject Areas - NeurIPS 2025, https://neurips.cc/Conferences/2019/PaperInformation/SubjectAreas</li>
<li>CoRL_2019 - Paper Submission - CoRL 2019, https://2019.corl.org/home/paper-submission</li>
<li>NeurIPS 2019 Papers with Code/Data - Paper Digest, https://www.paperdigest.org/2019/11/neurips-2019-papers-with-code-data/</li>
<li>Deep Equilibrium Models, https://arxiv.org/abs/1909.01377</li>
<li>Deep Equilibrium Models - arXiv, https://arxiv.org/pdf/1909.01377</li>
<li>TorchDEQ: A Library for Deep Equilibrium Models - arXiv, https://arxiv.org/pdf/2310.18605</li>
<li>Reversible Deep Equilibrium Models - arXiv, https://arxiv.org/html/2509.12917v1</li>
<li>Multiscale Deep Equilibrium Models, https://proceedings.neurips.cc/paper/2020/file/3812f9a59b634c2a9c574610eaba5bed-Paper.pdf</li>
<li>Deep Equilibrium Models for Snapshot Compressive Imaging | Proceedings of the AAAI Conference on Artificial Intelligence, https://ojs.aaai.org/index.php/AAAI/article/view/25475</li>
<li>Lyapunov-Stable Deep Equilibrium Models | Proceedings of the AAAI Conference on Artificial Intelligence, https://ojs.aaai.org/index.php/AAAI/article/view/29044</li>
<li>CondConv: Conditionally Parameterized Convolutions for Efficient …, https://arxiv.org/abs/1904.04971</li>
<li>CondConv: Conditionally Parameterized Convolutions for Efficient Inference - ar5iv - arXiv, https://ar5iv.labs.arxiv.org/html/1904.04971</li>
<li>A lightweight adaptive image deblurring framework using dynamic convolutional neural networks - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC12474894/</li>
<li>OMNI-DIMENSIONAL DYNAMIC CONVOLUTION - OpenReview, https://openreview.net/pdf?id=DmpCfq6Mg39</li>
<li>KernelWarehouse: Rethinking the Design of Dynamic Convolution - arXiv, https://arxiv.org/html/2406.07879v1</li>
<li>Seyed Kamyar Seyed Ghasemipour - Department of Computer Science, University of Toronto, https://www.cs.utoronto.ca/~kamyar/</li>
<li>A Divergence Minimization Perspective on Imitation Learning Methods, https://arxiv.org/abs/1911.02256</li>
<li>A Divergence Minimization Perspective on Imitation Learning Methods - Proceedings of Machine Learning Research, http://proceedings.mlr.press/v100/ghasemipour20a/ghasemipour20a.pdf</li>
<li>A Divergence Minimization Perspective on Imitation Learning Methods - ResearchGate, https://www.researchgate.net/publication/337074870_A_Divergence_Minimization_Perspective_on_Imitation_Learning_Methods</li>
<li>Supervised Fine-Tuning as Inverse Reinforcement Learning - alphaXiv, https://www.alphaxiv.org/overview/2403.12017</li>
<li>Habitat: A Platform for Embodied AI Research, https://arxiv.org/abs/1904.01201</li>
<li>Robo-PlaNet: Learning to Poke in a Day, https://arxiv.org/abs/1911.03594</li>
<li>[1911.05321] IRIS: Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data - arXiv, <a href="https://arxiv.org/abs/1911.05321?utm_campaign=The+Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8nr_so6-DXb7QiJi3S0pvS0nJf6k9g7nuPpF_OyZCCtztHCg_Wcj1Fkwp5DRZLh0uY9uH7">https://arxiv.org/abs/1911.05321?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8nr_so6-DXb7QiJi3S0pvS0nJf6k9g7nuPpF_OyZCCtztHCg_Wcj1Fkwp5DRZLh0uY9uH7</a></li>
<li>[1909.05160] Trust and Cognitive Load During Human-Robot Interaction - arXiv, https://arxiv.org/abs/1909.05160</li>
<li>[1909.09418] AIBA: An AI Model for Behavior Arbitration in Autonomous Driving - arXiv, https://arxiv.org/abs/1909.09418</li>
<li>5 Massive Robotics Trends | Bernard Marr, https://bernardmarr.com/5-massive-robotics-trends-in-2019/</li>
<li>The impact of artificial intelligence on human society and bioethics - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC7605294/</li>
<li>Intelligent Robotics—A Systematic Review of Emerging Technologies and Trends - MDPI, https://www.mdpi.com/2079-9292/13/3/542</li>
<li>International Federation of Robotics, https://ifr.org/</li>
<li>Growth trends for selected occupations considered at risk from automation, https://www.bls.gov/opub/mlr/2022/article/growth-trends-for-selected-occupations-considered-at-risk-from-automation.htm</li>
<li>WHAT JOBS ARE AFFECTED BY AI? - Brookings Institution, https://www.brookings.edu/wp-content/uploads/2019/11/2019.11.20_BrookingsMetro_What-jobs-are-affected-by-AI_Report_Muro-Whiton-Maxim.pdf</li>
<li>Robots trends and megatrends: artificial intelligence and the society - Emerald Publishing, https://www.emerald.com/ir/article/51/1/117/1215428/Robots-trends-and-megatrends-artificial</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>