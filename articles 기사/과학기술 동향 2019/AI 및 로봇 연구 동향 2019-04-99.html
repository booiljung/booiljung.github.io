<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2019년 4월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2019년 4월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2019년 AI 및 로봇 연구 동향</a> / <span>2019년 4월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2019년 4월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2019년, 인공지능 연구의 변곡점</h2>
<p>2019년 4월은 인공지능(AI) 연구 분야에서 중요한 변곡점으로 기록된다. 이 시기는 대규모 딥러닝 모델의 성공이 확고히 자리 잡은 가운데, 그 이면에 존재하는 효율성, 해석 가능성, 그리고 견고성에 대한 근본적인 질문들이 학계와 산업계 전반에 걸쳐 시급한 과제로 부상하던 때였다. 한편에서는 강화학습과 같은 분야에서 전례 없는 규모의 계산을 통해 인간의 능력을 뛰어넘으려는 시도가 이루어졌고, 다른 한편에서는 신경망의 본질을 이해하고 더 효율적인 구조를 찾으려는 근원적인 탐구가 활발히 진행되었다. 이러한 거대 규모로의 확장과 근본 원리에 대한 탐구라는 두 가지 흐름의 긴장과 상호작용이 이 시기 연구의 핵심적인 특징을 형성했다.</p>
<p>이러한 지적 역동성은 당시에 개최되었거나 주요 결과물이 발표된 세계 최고 수준의 학술대회를 통해 명확히 드러났다. 학습 표현에 관한 국제 학회(International Conference on Learning Representations, ICLR), 인공지능 및 통계에 관한 국제 학회(International Conference on Artificial Intelligence and Statistics, AISTATS), 그리고 IEEE 국제 로봇공학 및 자동화 학회(IEEE International Conference on Robotics and Automation, ICRA) 등은 이 시기의 가장 중요한 연구 성과들이 발표되는 핵심적인 장이었다.1 본 보고서는 이들 주요 학회와 더불어, 가장 최신의 연구가 공개되는 arXiv 프리프린트 서버의 발표 내용을 종합하여 2019년 4월의 AI 및 로봇공학 연구 지형을 심층적으로 분석하고자 한다.</p>
<p>보고서는 먼저 근본적인 AI 및 기계학습(ML) 분야의 핵심 연구들을 분석하고, 이어서 로봇공학의 주요 응용 분야에서 나타난 기술적 진보를 탐구한다. 마지막으로, 이러한 기술 발전과 병행하여 중요성이 커지고 있는 윤리적, 사회적 논의를 조망하며 2019년 4월이 AI 연구의 미래에 남긴 유산과 과제를 종합적으로 고찰한다.</p>
<table><thead><tr><th>학회명</th><th>개최 시기</th><th>개최지</th><th>주요 연구 분야</th></tr></thead><tbody>
<tr><td>AISTATS 2019</td><td>2019년 4월 16-18일</td><td>일본 오키나와 나하</td><td>인공지능, 기계학습, 통계학의 교차 분야</td></tr>
<tr><td>AITP 2019</td><td>2019년 4월 7-12일</td><td>오스트리아 오버구르글</td><td>인공지능과 정리 증명(Theorem Proving)</td></tr>
<tr><td>AICAAM 2019</td><td>2019년 4월 26-27일</td><td>인도 벵갈루루</td><td>인공지능 및 기계학습의 혁신적 아이디어 및 응용</td></tr>
<tr><td>ICCAR 2019</td><td>2019년 4월 19-22일</td><td>중국 베이징</td><td>제어 및 자동화, 로봇공학</td></tr>
<tr><td>ER(ZR) 2019</td><td>2019년 4월 17-20일</td><td>러시아 쿠르스크</td><td>전기기계 및 로봇공학</td></tr>
</tbody></table>
<h2>2.  주요 AI/ML 학회 동향 및 핵심 연구 심층 분석</h2>
<p>2019년 4월을 전후하여 발표된 주요 AI 및 기계학습 학회의 연구들은 기존 패러다임에 도전하거나 새로운 개념적 틀을 제시하는 데 중점을 두었다. 특히 ICLR과 AISTATS에서는 신경망의 내재적 속성을 탐구하고 통계적 엄밀성을 강화하려는 노력이 두드러졌다.</p>
<h3>2.1  ICLR 2019: 신경망의 근본적 이해를 향한 도약</h3>
<p>ICLR 2019에서는 신경망의 작동 원리와 구조에 대한 깊이 있는 탐구를 시도한 두 편의 논문이 최우수 논문상(Best Paper Award)을 공동 수상하며 학계의 큰 주목을 받았다.7 이 연구들은 단순히 성능을 개선하는 것을 넘어, 신경망이 어떻게 학습하고 정보를 표현하는지에 대한 근본적인 통찰을 제공했다.</p>
<h4>2.1.1  심층 분석: “The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks”</h4>
<p>이 논문은 거대하고 밀집된(dense) 신경망의 성공이 과잉 매개변수화(overparameterization) 덕분이라는 당시의 지배적인 통념에 정면으로 도전했다.8 연구진은 무작위로 초기화된 대규모 신경망 안에, 전체 네트워크와 비슷하거나 더 나은 성능을 달성할 수 있는 작은 부분망(subnetwork), 이른바 ’당첨 티켓(winning tickets)’이 숨겨져 있다는 혁명적인 가설을 제시했다.10</p>
<p>방법론: 반복적 크기 프루닝 (Iterative Magnitude Pruning, IMP)</p>
<p>’당첨 티켓’을 찾는 방법론으로 제안된 IMP 알고리즘의 과정은 다음과 같다.10</p>
<ol>
<li>
<p>신경망 <span class="math math-inline">f(x; \theta_0)</span>를 무작위로 초기화한다.</p>
</li>
<li>
<p>네트워크를 수렴할 때까지 학습시켜 최종 매개변수 <span class="math math-inline">\theta_j</span>​를 얻는다.</p>
</li>
<li>
<p>학습된 매개변수 <span class="math math-inline">\theta_j</span> 중에서 크기(magnitude)가 가장 작은 <span class="math math-inline">p%</span>를 프루닝(제거)하여, 남길 가중치를 표시하는 마스크(mask) m을 생성한다.</p>
</li>
<li>
<p>프루닝 후 남은 가중치들을 원래의 초기값 θ0​로 되돌려 ‘당첨 티켓’ <span class="math math-inline">f(x; m \odot \theta_0)</span>을 완성한다.</p>
</li>
</ol>
<p>주요 결과 및 의의</p>
<p>연구진은 MNIST와 CIFAR10 데이터셋을 사용한 실험에서, 원래 네트워크 매개변수의 10-20%에 불과한 ’당첨 티켓’이 전체 네트워크와 동등한 성능에 도달함을 입증했다. 놀랍게도, 이 작은 부분망들은 종종 더 빠르게 학습하고 더 높은 최종 정확도를 기록하기도 했다.9 이는 성공적인 딥러닝의 핵심이 단순히 많은 매개변수가 아니라, 학습에 유리한 특정 초기값과 연결 구조의 ’조합’에 있음을 시사한다. 즉, ’당첨 티켓’은 초기화라는 복권 추첨에서 당첨된, 학습에 특히 효과적인 구조를 가진 부분망인 것이다.</p>
<h4>2.1.2  심층 분석: “Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks”</h4>
<p>이 연구는 자연어가 가진 본질적인 계층적, 트리(tree) 구조를 순환 신경망(RNN)이 더 효과적으로 학습할 수 있도록 새로운 유도 편향(inductive bias)을 제안했다.12 이는 기존의 표준 LSTM이 언어를 단순히 순차적인 데이터로 처리하던 방식에서 벗어나, 언어의 구조적 특성을 모델 아키텍처에 내장하려는 중요한 시도였다.</p>
<p>방법론: ON-LSTM (Ordered Neurons LSTM)</p>
<p>연구진은 ON-LSTM이라는 새로운 아키텍처를 제안했다. 이 모델의 핵심 아이디어는 은닉 상태(hidden state)의 뉴런들을 ’순서화(ordering)’하는 것이다.14</p>
<ol>
<li>
<p><strong>뉴런 순서화</strong>: 고순위 뉴런은 문장 전체와 같은 더 큰 언어적 구성 요소를, 저순위 뉴런은 구나 단어 같은 더 작은 중첩된 구성 요소를 처리하도록 역할을 분담한다.</p>
</li>
<li>
<p><strong><code>cumax()</code> 활성화 함수</strong>: <code>softmax</code> 함수의 누적 합으로 정의되는 새로운 활성화 함수 <code>cumax()</code>를 도입했다. 이 함수는 ’마스터 게이트’를 생성하여, 고순위 뉴런의 정보가 업데이트(삭제)될 때 그보다 낮은 순위의 모든 뉴런 정보도 함께 업데이트되도록 강제한다. 이는 마치 언어에서 상위 구문 구조가 닫힐 때 하위 구조도 함께 닫히는 원리와 유사하다.13</p>
</li>
</ol>
<p>주요 결과 및 의의</p>
<p>ON-LSTM은 별도의 구문 분석 정보 없이 오직 언어 모델링 목적 함수만으로 학습했음에도 불구하고, 비지도 구문 분석(unsupervised constituency parsing) 과제에서 뛰어난 성능을 보였다.12 이는 모델이 데이터만으로 언어의 잠재적인 통사 구조를 성공적으로 추론해냈음을 의미한다. 또한, 장거리 문법적 일치(long-term syntactic agreement)가 중요한 과제에서도 기존 모델들을 능가하는 성능을 보여, 제안된 구조적 편향의 효과를 입증했다.15</p>
<p>이 두 ICLR 최우수 논문은 서로 다른 영역을 다루면서도 ’더 적은 것이 더 많다(Less is More)’는 공통된 철학을 제시한다. ’로터리 티켓 가설’은 거대한 네트워크에서 핵심적인 희소 부분망을 찾아 효율성을 추구하고, ’순서 있는 뉴런’은 문제의 본질(언어의 계층 구조)에 맞는 구조적 제약을 가함으로써 학습 효율과 성능을 동시에 높인다. 이는 2019년 당시 딥러닝 연구가 단순히 모델의 크기를 키우는 경쟁을 넘어, 보다 근본적이고 효율적인 구조를 탐색하는 방향으로 성숙해지고 있었음을 보여주는 중요한 증거이다.</p>
<h3>2.2  AISTATS 2019: 통계적 기계학습의 정교화</h3>
<p>AISTATS 2019에서는 기계학습 방법론을 계산적으로 더 효율적이게 만들고 이론적으로 더 견고한 기반 위에 올려놓으려는 연구들이 주목할 만한 논문(Notable Paper)으로 선정되었다. 이는 딥러닝의 경험적 성공을 통계학의 엄밀함과 결합하려는 시도의 일환으로 해석될 수 있다.</p>
<h4>2.2.1  분석: “A Swiss Army Infinitesimal Jackknife”</h4>
<p>이 논문은 교차 검증(cross-validation)이나 부트스트랩(bootstrap)과 같이 계산 비용이 매우 높은 리샘플링(resampling) 기법들을 근사하는 실용적이고 이론적으로도 타당한 방법을 제시했다.16 연구진은 통계학 문헌에서 주로 이론적 도구로 사용되던 ’무한소 잭나이프(Infinitesimal Jackknife, IJ)’를 대규모 기계학습 문제에 적용 가능한 도구로 되살렸다.19</p>
<p>방법론: 선형 근사(Linear Approximation)</p>
<p>핵심 아이디어는 모델의 매개변수 θ가 데이터 가중치 w의 작은 변화에 어떻게 반응하는지를 1차 테일러 근사, 즉 선형 근사를 통해 예측하는 것이다.19 이를 통해 매번 새로운 데이터 샘플에 대해 모델을 재학습시키는 대신, 한 번의 미분 계산으로 리샘플링의 효과를 근사할 수 있다. 이는 현대적인 자동 미분(automatic differentiation) 도구를 활용하여 효율적으로 수행될 수 있다. 핵심 근사식은 다음과 같다:</p>
<p><span class="math math-display">
\hat{\theta}(w) \approx \hat{\theta}(\mathbf{1}) + (w - \mathbf{1})^T \cdot \left. \frac{d\hat{\theta}(w)}{dw^T} \right|_{w=\mathbf{1}}
</span></p>
<p>의의</p>
<p>이 연구는 대규모 모델과 데이터셋에 대한 모델 검증 및 불확실성 정량화의 계산 비용을 극적으로 줄일 수 있는 길을 열었다.20 이를 통해 더 많은 연구자와 실무자들이 통계적으로 견고한 모델 평가를 수행할 수 있게 되었다.</p>
<h4>2.2.2  분석: “Deep Learning with Differential Gaussian Process Flows”</h4>
<p>이 논문은 딥러닝의 이산적인(discrete) 레이어 구조를 확률적 미분 방정식(Stochastic Differential Equation, SDE)에 의해 제어되는 연속적인 시간 변환(continuous-time transformation)으로 대체하는 새로운 패러다임을 제안했다.17 이는 딥러닝을 확률적 동역학 시스템의 틀 안에서 우아하게 재해석한 것이다.24</p>
<p>방법론: DiffGP (Differential Gaussian Process)</p>
<p>DiffGP 모델은 입력 데이터 x를 시간 t에 따라 ‘흐르게’ 하는 벡터 필드를 학습한다. 이 흐름은 최종 시간 T에 도달하여 변환된 데이터 <span class="math math-inline">x(T)</span>를 생성하고, 이를 예측에 사용한다. 이 벡터 필드 자체는 가우시안 프로세스(Gaussian Process, GP)로 모델링되어 불확실성을 원리적으로 다룰 수 있게 한다.24 핵심 SDE는 다음과 같다:</p>
<p><span class="math math-display">
dx_t = \mu(x_t)dt + \sqrt{\Sigma(x_t)}dW_t
</span></p>
<p>여기서 드리프트(drift) <span class="math math-inline">\mu</span>와 확산(diffusion) <span class="math math-inline">\Sigma</span>는 GP에 의해 결정된다.</p>
<p>의의</p>
<p>이 접근법은 딥러닝의 ’깊이’를 통합 시간 T라는 새로운 개념으로 해석할 수 있게 하며, 기존의 심층 신경망에 비해 더 해석 가능하고 불확실성을 잘 표현하는 대안을 제시했다. 실험 결과, 심층 GP(Deep GPs)나 베이즈 신경망(Bayesian Neural Networks)에 비해 우수한 성능을 보였다.23</p>
<p>AISTATS의 주목할 만한 논문들은 딥러닝의 실용적 성공과 통계적 엄밀성 사이의 간극을 메우려는 학계의 강력한 의지를 보여준다. IJ 논문은 거대 모델의 ‘평가’ 문제를, DiffGP 논문은 모델 ’자체’를 통계학의 검증된 틀로 재구성하는 문제를 다룬다. 이는 AI 기술이 의학, 금융 등 신뢰성이 중요한 고위험 분야에 적용되기 위해 반드시 필요한 과정이며, 2019년 당시 이러한 논의가 활발히 진행되고 있었음을 보여준다.</p>
<table><thead><tr><th>논문 제목</th><th>학회</th><th>수상</th><th>핵심 기여</th><th>주요 방법론 혁신</th></tr></thead><tbody>
<tr><td>The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks</td><td>ICLR 2019</td><td>최우수 논문</td><td>대규모 신경망 내 학습 가능한 희소 부분망(“당첨 티켓”)의 존재 증명</td><td>반복적 크기 프루닝(IMP) 및 초기값 되돌리기</td></tr>
<tr><td>Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks</td><td>ICLR 2019</td><td>최우수 논문</td><td>RNN에 언어의 계층적 구조를 모델링하기 위한 유도 편향 도입</td><td>뉴런 순서화 및 <code>cumax()</code> 활성화 함수를 통한 ON-LSTM 아키텍처</td></tr>
<tr><td>A Swiss Army Infinitesimal Jackknife</td><td>AISTATS 2019</td><td>주목할 만한 논문</td><td>고비용 리샘플링 기법(예: 교차 검증)의 빠르고 정확한 근사 방법 제시</td><td>무한소 잭나이프(IJ)를 활용한 파라미터 변화의 선형 근사</td></tr>
<tr><td>Deep Learning with Differential Gaussian Process Flows</td><td>AISTATS 2019</td><td>주목할 만한 논문</td><td>이산적 레이어를 SDE 기반 연속 시간 변환으로 대체하는 새로운 딥러닝 패러다임 제시</td><td>가우시안 프로세스로 벡터 필드를 모델링하는 차분 GP(DiffGP)</td></tr>
</tbody></table>
<h2>3.  로봇공학의 진화: 실제 세계 적용을 위한 핵심 기술 동향</h2>
<p>2019년 4월의 로봇공학 연구는 근본적인 AI/ML 이론의 발전을 물리적 시스템에 적용하여 실제 세계의 복잡성과 불확실성을 극복하려는 노력에 초점을 맞추었다. 특히 ICRA 2019를 중심으로 자율주행, 로봇 조작, 인간-로봇 상호작용 분야에서 의미 있는 기술적 진보가 이루어졌다.</p>
<h3>3.1  자율주행 기술의 발전</h3>
<p>이 시기 자율주행 연구는 단순한 객체 인식을 넘어, 복잡한 상호작용 시나리오를 예측하고 악천후와 같은 비정상적인 환경에 강건하게 대처하는 방향으로 나아가고 있었다.26</p>
<p>예측 및 계획 기술</p>
<p>ICRA 2019에서 발표된 “Egocentric Vision-based Future Vehicle Localization for Intelligent Driving Assistance Systems“는 주목할 만한 연구였다.28 이 연구의 독창성은 자율주행차의 1인칭 시점(egocentric view)을 사용하여 다른 차량의 미래 경로뿐만 아니라 ’크기(scale)’까지 예측했다는 점에 있다. 이미지 상의 크기 변화는 대상과의 거리 및 방향에 대한 중요한 정보를 담고 있기 때문이다. 연구진은 다중 스트림 RNN(multi-stream RNN) 아키텍처를 사용하여 위치, 광학 흐름(optical flow), 그리고 자차의 예상 움직임(ego-motion) 정보를 효과적으로 융합하는 방법론을 제시했다.29</p>
<p>센서 융합 및 강건성</p>
<p>옥스포드 로보틱스 연구소(Oxford Robotics Institute)는 레이더와 카메라 데이터를 융합하여 원거리 차량을 탐지하는 연구와, 생성적 적대 신경망(GAN)을 이용해 카메라 이미지의 빗방울을 제거하는 ‘de-raining’ 기술을 발표했다.27 이는 악천후와 같은 열악한 환경에서도 안정적인 인지 성능을 확보하기 위한 필수적인 연구 방향을 제시한다.</p>
<p>학습 기반 제어</p>
<p>영국의 스타트업 Wayve가 발표한 “Learning to Drive in a Day“는 강화학습을 실제 차량 주행에 적용한 선구적인 사례로 평가받는다.27 이 연구는 운전자의 개입(disengagement)을 부정적 보상 신호로 사용하여, 별도의 복잡한 보상 설계 없이도 차선 유지와 같은 기본적인 주행 정책을 학습시킬 수 있음을 보여주었다. 이는 복잡한 실제 환경에서 종단간 학습(end-to-end learning)의 가능성을 탐색한 중요한 단계였다.</p>
<h3>3.2  로봇 조작(Manipulation)의 정교화</h3>
<p>로봇 조작 분야의 연구는 로봇이 보다 정교하고 강건하게 물리적 세계와 상호작용할 수 있도록 하는 데 집중되었다. 특히 학습 기반 접근법과 촉각 센싱 기술의 결합이 핵심적인 흐름을 형성했다.</p>
<p>촉각 기반 힘 추정</p>
<p>ICRA 2019 최우수 조작 논문상 최종 후보에 오른 “Robust Learning of Tactile Force Estimation through Robot Interaction“은 이 분야의 대표적인 연구다.30 기존의 촉각 힘 추정 모델이 특정 과제에만 국한되거나 부정확했던 문제를 해결하기 위해, 연구진은 ‘일반화 가능한(generalizable)’ 힘 추정 모델을 학습시키는 데 성공했다.34 이를 위해 (1) 힘-토크 센서에 단단히 고정된 촉각 센서, (2) 로봇이 센서가 부착된 공과 상호작용하는 상황, (3) 평면 위에서 물체를 미는 상황 등 세 가지의 다양한 데이터 수집 환경을 구축하여 총 14만 개의 대규모 데이터셋을 확보했다.33 또한, 촉각 신호의 공간적 정보를 효과적으로 처리하기 위해 3D 복셀 그리드(voxel grid) 형태의 새로운 입력 방식을 신경망에 적용했다. 그 결과, 힘의 방향 예측에서 각도 오차를 66%, 힘의 크기 예측에서 오차를 93% 개선하는 성과를 거두었다.35</p>
<h3>3.3  인간-로봇 상호작용(HRI)의 확장</h3>
<p>HRI 연구는 일대일 상호작용을 넘어, 여러 사람이 포함된 그룹 환경으로 그 범위를 확장하고 있었다. 이는 사회적 항법(social navigation), 그룹 역학(group dynamics)의 이해, 그리고 로봇에 대한 사회적 수용성 등 새로운 도전 과제들을 제기했다.36</p>
<p>그룹 HRI 연구 동향</p>
<p>2019년 4월에 발표된 리뷰 논문 “Group Human-Robot Interaction: A Review“는 당시 그룹 HRI 분야의 연구 현황을 체계적으로 정리했다.36 이 논문은 그룹 HRI의 주요 연구 주제로 사회적 현상 모델링, 사회적 존재감(social presence) 유지, 다수와의 상호작용으로의 확장, 그룹 구성원으로서의 로봇 역할, 사회적 수용성 확보 등을 꼽았다.</p>
<p>핵심 도전 과제: 이론과 실제의 불일치</p>
<p>이 리뷰는 한 가지 중요한 도전 과제를 지적했는데, 바로 인간 사회 심리학(social psychology) 연구 결과가 인간-로봇 상호작용 환경에 그대로 적용되지 않는 ’불연속성(discontinuity)’이 존재한다는 점이다.36 예를 들어, 그룹 크기 증가가 인간 집단에 미치는 영향과 로봇이 포함된 집단에 미치는 영향이 다를 수 있다. 이는 인간이 로봇을 인식하고 상호작용하는 방식에 고유한 특성이 있음을 시사하며, 그룹 HRI를 위한 새로운 이론적 모델과 실험 방법론의 필요성을 제기한다.</p>
<p>이 시기 로봇공학 연구 전반에 걸쳐 나타나는 두 가지 중요한 흐름이 있다. 첫째는 <strong>‘Sim-to-Real-to-Sim’ 피드백 루프의 형성</strong>이다. 과거에는 시뮬레이션에서 학습한 모델을 실제 로봇으로 옮기는 ’Sim-to-Real’이 주된 방향이었다면, 이제는 실제 세계의 데이터를 활용해 더 정교한 시뮬레이터를 만들고(예: 자율주행의 적대적 시나리오 생성 27), 실제 상호작용을 통해 얻은 모델을 다시 시뮬레이션에서 분석·개선하는 양방향의 순환적 개발 과정이 자리 잡고 있었다. 이는 시뮬레이션이 더 이상 현실의 저렴한 대체재가 아니라, 상호보완적인 핵심 개발 도구로 진화했음을 보여준다.</p>
<p>둘째는 <strong>상호작용 데이터의 중요성 부각</strong>이다. 자율주행, 로봇 조작, HRI 등 모든 분야에서 성공적인 연구는 양질의 대규모 상호작용 데이터를 기반으로 했다. 자율주행 연구팀은 새로운 데이터셋(HEV-I)을 직접 구축했고 29, 로봇 조작 연구는 다양한 환경에서 수집한 방대한 촉각 데이터셋 덕분에 성공할 수 있었다.34 이는 2019년 로봇공학의 발전이 알고리즘 설계뿐만 아니라, 데이터 수집 전략 및 엔지니어링 역량에 크게 의존하게 되었음을 명확히 보여준다.</p>
<table><thead><tr><th>응용 분야</th><th>대표 논문</th><th>핵심 기여</th><th>중요성</th></tr></thead><tbody>
<tr><td><strong>자율주행</strong></td><td>Egocentric Vision-based Future Vehicle Localization for Intelligent Driving Assistance Systems</td><td>1인칭 시점 영상과 자차 움직임 정보를 활용한 타 차량의 미래 위치 및 크기 동시 예측</td><td>복잡한 교차로 환경에서의 예측 정확도를 높여 ADAS 및 자율주행의 안전성 강화</td></tr>
<tr><td><strong>로봇 조작</strong></td><td>Robust Learning of Tactile Force Estimation through Robot Interaction</td><td>다양한 상호작용 데이터를 학습하여 일반화 성능이 뛰어난 촉각 기반 힘 추정 모델 개발</td><td>로봇이 미세한 힘을 감지하고 제어하는 능력을 향상시켜 정교한 조작 작업의 기반 마련</td></tr>
<tr><td><strong>인간-로봇 상호작용</strong></td><td>Group Human-Robot Interaction: A Review</td><td>그룹 HRI 분야의 연구 동향을 종합하고, 인간 사회 심리학 이론과의 불일치라는 핵심 도전 과제 제시</td><td>일대다 상호작용 연구의 현주소를 진단하고 향후 연구 방향을 제시하는 이론적 토대 제공</td></tr>
</tbody></table>
<h2>4.  arXiv를 통해 본 2019년 4월의 주요 연구 흐름</h2>
<p>arXiv 프리프린트 서버는 동료 심사를 거치기 전의 최신 연구들이 가장 먼저 공개되는 곳으로, 2019년 4월 당시 학계의 가장 뜨거운 연구 흐름을 실시간으로 파악할 수 있는 중요한 창구였다. 이 시기 arXiv에 발표된 연구들은 컴퓨터 비전, 강화학습, 자연어 처리 등 여러 분야에서 새로운 패러다임을 제시했다.</p>
<h3>4.1  컴퓨터 비전: 객체 탐지의 새로운 패러다임, CenterNet</h3>
<p>2019년 4월 16일 arXiv에 공개된 “Objects as Points” (CenterNet)는 객체 탐지(object detection) 분야에 큰 반향을 일으켰다.37</p>
<p>핵심 기여: 단순함의 미학</p>
<p>당시 객체 탐지 분야는 수천 개의 잠재적 경계 상자(bounding box) 후보군을 생성하고 분류하는 앵커 기반(anchor-based) 방식이 지배적이었다.38 CenterNet은 이러한 복잡한 파이프라인을 근본적으로 단순화했다. 객체를 경계 상자가 아닌, 상자의 중심점(center point)이라는 단 하나의 점으로 모델링한 것이다. 크기, 3D 위치, 방향 등 객체의 다른 모든 속성은 중심점 위치의 이미지 특징(feature)으로부터 직접 회귀(regression) 방식으로 예측된다.37</p>
<p>방법론</p>
<p>CenterNet은 표준적인 키포인트(keypoint) 추정 네트워크를 사용하여 객체 중심점들의 히트맵(heatmap)을 생성한다. 히트맵에서 국소 최댓값(peak)으로 나타나는 각 점에 대해, 해당 위치에서 객체의 너비와 높이를 예측하는 방식이다. 이 앵커-프리(anchor-free), 단일 단계(one-stage) 접근법은 Faster R-CNN이나 YOLOv3와 같은 경쟁 모델들보다 훨씬 간단하고, 빠르며, 메모리 효율적이다.</p>
<p>의의</p>
<p>CenterNet은 복잡한 후처리 과정인 비최대 억제(Non-Maximum Suppression, NMS)의 필요성을 크게 줄여, 종단간 미분 가능한 더 단순한 탐지 모델의 가능성을 열었다. MS COCO 데이터셋에서 당시 최고의 속도-정확도 균형을 달성하며, 객체 탐지 연구에 새롭고 우아한 방향을 제시했다.37 이는 복잡한 다단계 파이프라인이 지배하던 분야에서, 문제 자체를 재정의하는 ’단순화’가 얼마나 강력한 혁신을 이끌 수 있는지를 보여준 사례다.</p>
<h3>4.2  강화학습: OpenAI Five의 Dota 2 정복</h3>
<p>2019년 4월 13일, OpenAI의 AI 시스템 ’OpenAI Five’가 세계적인 e스포츠 게임인 Dota 2에서 당시 세계 챔피언 팀을 꺾는 역사적인 사건이 있었다. 이 성과를 기술한 논문 “Dota 2 with Large Scale Deep Reinforcement Learning“은 이후 arXiv를 통해 공개되었다.39</p>
<p>핵심 기여: 복잡성의 정복</p>
<p>이 사건은 심층 강화학습이 바둑과 같은 게임을 넘어, 방대한 상태-행동 공간, 긴 시간 지평(long time horizons), 그리고 불완전한 정보라는 훨씬 더 복잡한 문제들을 해결할 수 있음을 증명한 기념비적인 성과였다.39</p>
<p>방법론: 압도적인 규모의 학습</p>
<p>OpenAI Five의 성공은 압도적인 규모의 학습을 통해 가능했다. 2초마다 약 200만 프레임의 데이터를 처리하는 분산 학습 시스템을 구축하여, 10개월 동안 자기 자신과의 대결(self-play)을 통해 인간으로 치면 수천 년에 해당하는 게임 경험을 축적했다. 핵심 학습 알고리즘으로는 Proximal Policy Optimization (PPO)이 사용되었다.</p>
<p>의의</p>
<p>이 성과는 대규모 강화학습을 복잡한 실제 문제에 적용할 수 있다는 강력한 개념 증명(proof-of-concept)이 되었다. 동시에 이는 알고리즘의 잠재력뿐만 아니라, 이를 실현하기 위해 필요한 막대한 계산 자원의 중요성을 부각시켰다.</p>
<h3>4.3  자연어 처리: 다국어 번역의 진일보</h3>
<p>ICLR 2019에서 발표되었지만 arXiv를 통해서도 널리 알려진 “Multilingual Neural Machine Translation with Knowledge Distillation“은 다국어 번역 시스템의 효율성과 성능을 동시에 잡는 실용적인 해법을 제시했다.40</p>
<p>핵심 기여: 지식 증류를 통한 효율적 다국어 모델 구축</p>
<p>단일 다국어 번역 모델이 각 언어 쌍에 특화된 개별 모델보다 성능이 떨어지는 고질적인 문제를 ‘지식 증류(knowledge distillation)’ 기법으로 해결했다.</p>
<p>방법론</p>
<p>먼저 각 언어 쌍에 대해 고성능의 개별 ‘교사(teacher)’ 모델들을 학습시킨다. 그 후, 단일 다국어 ‘학생(student)’ 모델이 정답 데이터뿐만 아니라, 이 전문가 교사 모델들의 출력 확률 분포를 모방하도록 학습시킨다. 이를 통해 개별 모델들이 가진 특화된 지식이 효율적인 단일 다국어 모델로 효과적으로 이전된다.40</p>
<p>의의</p>
<p>이 연구는 고품질의 효율적인 다국어 시스템을 구축하는 실용적인 길을 열었다. 한 실험에서는 파라미터 수가 44분의 1에 불과한 단일 모델이 44개의 개별 모델들과 동등하거나 더 나은 성능을 달성함을 보여주었다.40 이는 전 세계의 다양한 언어에 대한 번역 서비스를 확장하는 데 있어 매우 중요한 기술적 진보였다.</p>
<p>OpenAI Five와 다국어 번역 연구는 ’규모(scale)’라는 개념이 가진 두 가지 얼굴을 극명하게 보여준다. OpenAI Five는 전례 없는 계산 자원이라는 ’물리적 규모’를 통해 문제를 해결하는 접근법을 대표한다. 반면, 다국어 번역 연구는 다수의 전문화된 지식을 하나의 소형 모델로 압축하는 ’효율성의 규모’를 달성하는 방법을 보여준다. 전자가 소수의 거대 연구소만이 가능한 길이라면, 후자는 더 넓은 연구 커뮤니티가 지속 가능하게 추구할 수 있는 발전 방향을 제시한다. 2019년 4월은 이 두 가지 상반된 ‘규모의 확장’ 방식이 모두 강력한 힘을 발휘하고 있음을 보여준 시기였다.</p>
<h2>5.  기술과 사회: AI 및 로봇의 윤리적, 사회적 고찰</h2>
<p>AI 기술이 기하급수적으로 발전함에 따라, 2019년 4월에는 기술 커뮤니티와 정책 입안자들 사이에서 안전성, 윤리, 그리고 사회적 영향에 대한 논의가 본격적으로 확산되었다. 이는 기술 발전이 사회적 준비 상태와 보조를 맞추어야 한다는 인식이 커지고 있음을 반영한다.</p>
<h3>5.1  정책적 관점: 헬스케어 로봇의 기회와 도전</h3>
<p>2019년 4월 유럽 의회(European Parliament)는 “의료 분야의 로봇: 해결책인가, 문제인가?(Robots in healthcare: a solution or a problem?)“라는 제목의 심층 분석 보고서를 발표했다.41</p>
<p>주요 내용</p>
<p>이 보고서는 약국 재고 관리와 같은 후방 업무부터 반자율적 수술 보조 로봇에 이르기까지, 의료 분야에서 AI와 로봇의 다양한 적용 사례를 조망했다. 그러나 기술 자체보다 더 중요하게 다룬 것은 정책적 도전 과제들이었다. 보고서는 데이터 보호 및 프라이버시, 윤리적 평가와 책임 소재, 그리고 로봇 기술의 검증 및 인증을 위한 복잡한 규제 환경을 핵심 쟁점으로 지목했다.41</p>
<p>의의</p>
<p>주요 정부 기관에서 이러한 보고서가 발간되었다는 사실 자체가 AI와 로봇이 더 이상 순수한 기술적 관심사를 넘어, 주류 정책 논의의 대상이 되었음을 의미한다. 이는 기술 전문가, 윤리학자, 법률가, 그리고 정책 입안자 간의 학제간 협력이 시급함을 보여주는 명백한 신호였다.</p>
<h3>5.2  학술적 논의: 신뢰, 편향, 그리고 안전성</h3>
<p>학계에서도 AI 시스템의 사회적 측면에 대한 논의가 활발히 이루어졌다. 과학 저널 <em>American Scientist</em>에 실린 “신뢰와 편향(Trust and Bias in Robots)” 기사와 펜실베이니아 대학(Penn Engineering)의 AI 취약점 연구는 이러한 흐름을 잘 보여준다.42</p>
<p>신뢰와 과신(Overtrust)</p>
<p>연구에 따르면, 인간은 로봇을 다른 인간과 유사한 방식으로 신뢰하는 경향이 있으며, 이로 인해 기술의 위험성을 과소평가하는 ‘과신’ 현상이 발생할 수 있다.43 이는 특히 치료 환경에서 로봇과 상호작용하는 아동이나 노인과 같은 취약 계층에게 심각한 문제를 야기할 수 있다.</p>
<p>내재된 편향(Inherent Bias)</p>
<p>학습 데이터와 알고리즘에 내재된 편향이 심각한 결과를 초래할 수 있다는 점도 주요 쟁점이었다. 예를 들어, 자율주행차의 컴퓨터 비전 시스템이나 안면 인식 시스템이 특정 인종의 피부색에 대해 다른 정확도를 보이는 사례는 안전과 공정성 측면에서 큰 위험을 내포하고 있다.43</p>
<p>안전과 보안</p>
<p>’AI 레드팀(AI red teaming)’에 대한 연구는 AI 기반 로봇을 실제 환경에 배포하기 전에 보안 취약점을 사전에 식별하고 해결하는 것의 중요성을 강조했다.42 LLM으로 제어되는 로봇 시스템에 대한 ‘탈옥(jailbreak)’ 공격의 발견은 안전성이 결코 나중에 고려될 수 있는 부가적인 요소가 아님을 분명히 했다.</p>
<p>1장에서 3장까지 살펴본 눈부신 기술적 진보와 4장에서 논의된 사회적 담론 사이에는 명백한 시차가 존재한다. 2019년 당시 연구자들은 복잡한 게임에서 인간을 이기고, 스스로 운전하며, 여러 언어를 이해하는 시스템을 만들어내고 있었다. 반면, 이러한 시스템을 법적, 윤리적, 사회적으로 관리하기 위한 프레임워크는 아직 문제점을 식별하고 질문을 제기하는 초기 단계에 머물러 있었다. 유럽 의회 보고서는 ’도전 과제’를 개괄하는 분석이었고, “신뢰와 편향“에 대한 논의는 ’열린 질문’에 대한 탐구였다.41</p>
<p>이러한 기술 발전 속도와 사회적 준비 상태 사이의 ’준비성 격차(readiness gap)’는 강력한 기술이 사회가 이를 책임감 있게 관리할 규범, 법률, 그리고 안전장치를 마련하기 전에 개발되고 있음을 의미한다. 이는 향후 몇 년간 AI 연구 커뮤니티가 사회의 다른 부문과 훨씬 더 깊고 선제적으로 협력하여 이 격차를 해소하는 것이 중요한 과제가 될 것임을 예고했다.</p>
<h2>6. 결론: 2019년 4월이 남긴 유산과 미래 전망</h2>
<p>2019년 4월은 AI 및 로봇공학 연구의 역사에서 중요한 분기점이었다. 이 시기에 발표된 연구들은 이후 수년간의 기술 발전 방향을 결정짓는 핵심적인 아이디어와 성과들을 담고 있었다. 본 보고서에서 분석한 주요 동향을 종합하면 다음과 같은 세 가지 핵심 흐름으로 요약할 수 있다.</p>
<ol>
<li>
<p><strong>규모와 효율성의 이중주</strong>: 한편에서는 OpenAI Five와 같이 막대한 계산 자원을 투입하여 문제의 복잡성을 정면으로 돌파하는 ’규모의 힘’이 증명되었다. 다른 한편에서는 ‘로터리 티켓 가설’, ‘순서 있는 뉴런’, ’CenterNet’과 같이, 더 작고, 더 구조화되고, 더 효율적인 모델을 통해 문제의 본질에 접근하려는 ’효율성의 추구’가 중요한 연구 방향으로 자리 잡았다. 이 두 가지 상반된 접근법은 AI 연구의 발전을 이끄는 양대 축으로서 기능하기 시작했다.</p>
</li>
<li>
<p><strong>로봇공학 학습의 성숙</strong>: 로봇공학 분야는 순수 이론이나 모델 기반 접근에서 벗어나, 실제 세계와의 풍부한 상호작용 데이터를 기반으로 하는 강건한 데이터 주도 학습 방법론으로 명확히 전환되었다. 자율주행, 로봇 조작, HRI 등 모든 분야에서 고품질의 대규모 데이터셋 구축이 성공적인 연구의 전제 조건이 되었으며, 이는 로봇공학이 알고리즘뿐만 아니라 데이터 엔지니어링의 영역으로 확장되고 있음을 보여주었다.</p>
</li>
<li>
<p><strong>책임감 있는 AI의 부상</strong>: 기술적 성취가 사회에 미치는 영향이 가시화되면서, 안전, 윤리, 편향, 거버넌스에 대한 논의가 더 이상 부차적인 과제가 아닌, 연구 개발의 핵심적인 부분으로 인식되기 시작했다. 정책 기관과 학계의 논의는 기술 발전이 사회적 수용성과 제도적 틀 안에서 이루어져야 한다는 공감대가 형성되고 있음을 시사했다.</p>
</li>
</ol>
<p>2019년 4월의 연구들은 미래를 향한 씨앗을 뿌렸다. ’로터리 티켓 가설’은 신경망 프루닝과 효율적 학습에 대한 새로운 연구 물결을 일으켰다. OpenAI Five의 성공은 대규모 강화학습에 대한 투자를 가속화했으며, 이는 오늘날 거대 언어 모델(LLM)의 강화학습 기반 미세조정(fine-tuning) 기술의 토대가 되었다. 또한, 당시 시작된 정책 및 윤리 논의는 현재 활발히 진행 중인 AI 규제 법안과 가이드라인의 초석을 다졌다.</p>
<p>결론적으로, 2019년 4월은 AI가 순수한 기술적 탐구를 넘어 사회 전반에 깊숙이 뿌리내리기 시작한 전환기였다. 이 시기에 제시된 질문들, 즉 ‘어떻게 더 효율적으로 학습할 것인가?’, ‘어떻게 실제 세계와 더 잘 상호작용할 것인가?’, 그리고 ’어떻게 더 책임감 있게 기술을 개발할 것인가?’는 오늘날까지도 AI 및 로봇공학 연구의 가장 중요한 화두로 남아 있다. 앞으로의 연구는 보다 일반화 가능한 유도 편향의 탐색, 진정한 다중 모드(multi-modal) 로봇 시스템의 개발, 그리고 검증 가능하게 안전하고 공정한 AI의 구현이라는 방향으로 나아갈 것이며, 그 뿌리는 2019년 4월의 지적 유산에 깊이 닿아 있을 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>
<p>The 22nd International Conference on Artificial Intelligence and Statistics - AIStat, https://aistats.org/aistats2019/</p>
</li>
<li>
<p>ICCAR 2019 | Beijing, China - International Conference on Control, Automation and Robotics, https://www.iccar.org/2019.html</p>
</li>
<li>
<p>International Conference on Robotics and Automation, ICRA 2019, Montreal, QC, Canada, May 20-24, 2019 - researchr publication, https://researchr.org/publication/icra-2019</p>
</li>
<li>
<p>Best Paper Award - ICLR 2026, https://iclr.cc/Conferences/2019/Awards</p>
</li>
<li>
<p>The Lottery Ticket Hypothesis - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/the-lottery-ticket-hypothesis/</p>
</li>
<li>
<p>ICLR 2019 | MILA, Microsoft, and MIT Share Best Paper Honours | by Synced - Medium, https://medium.com/syncedreview/iclr-2019-mila-microsoft-and-mit-share-best-paper-honours-440675d5773e</p>
</li>
<li>
<p>MIT Open Access Articles The lottery ticket … - DSpace@MIT, https://dspace.mit.edu/bitstream/handle/1721.1/129953/1803.03635.pdf?sequence=2</p>
</li>
<li>
<p>The Lottery Ticket Hypothesis: A Survey - Robert Tjarko Lange, https://roberttlange.com/posts/2020/06/lottery-ticket-hypothesis/</p>
</li>
<li>
<p>Brief Report: Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks - Microsoft Research, https://www.microsoft.com/en-us/research/publication/brief-report-ordered-neurons-integrating-tree-structures-into-recurrent-neural-networks/</p>
</li>
<li>
<p>Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks - OpenReview, https://openreview.net/forum?id=B1l6qiR5F7</p>
</li>
<li>
<p>ORDERED NEURONS: INTEGRATING TREE … - OpenReview, https://openreview.net/pdf?id=B1l6qiR5F7</p>
</li>
<li>
<p>Ordered Neurons: Integrating Tree Structures Into Recurrent Neural Networks, https://cs.uwaterloo.ca/~mli/Niknamian.pdf</p>
</li>
<li>
<p>“A Swiss Army Infinitesimal Jackknife” paper wins “Notable Paper Award” at the 2019 Artificial Intelligence and Statistics (AISTATS) conference - Berkeley RISE Lab, https://rise.cs.berkeley.edu/blog/a-swiss-army-infinitesimal-jackknife-paper-wins-notable-paper-award-at-the-2019-artificial-intelligence-and-statistics-aistats-conference/</p>
</li>
<li>
<p>Program Co-chairs - AIStat, https://aistats.org/aistats2019/0-AISTATS2019-opening.pdf</p>
</li>
<li>
<p>Paper awards| Artificial Intelligence and Statistics Conference - AIStat, https://aistats.org/aistats2019/awards.html</p>
</li>
<li>
<p>A Swiss Army Infinitesimal Jackknife - Proceedings of Machine …, http://proceedings.mlr.press/v89/giordano19a/giordano19a.pdf</p>
</li>
<li>
<p>MIT Open Access Articles A Swiss army infinitesimal jackknife, https://dspace.mit.edu/bitstream/handle/1721.1/128774/1806.00550.pdf?sequence=2&amp;isAllowed=y</p>
</li>
<li>
<p>1월 1, 1970에 액세스, https://cogsci.yale.edu/sites/default/files/2019ThesisWisowaty.pdf</p>
</li>
<li>
<p>AISTATS’19 - Rencontre SciDoLySE, https://scidolyse.ens-lyon.fr/sites/default/files/2019-05/back_aistats_0.pdf</p>
</li>
<li>
<p>FCAI team’s Award Winning Research at AISTATS 2019, https://fcai.fi/news/2019/4/24/fcai-researchers-award-winning-research-at-aistats-2019</p>
</li>
<li>
<p>Deep learning with differential Gaussian process flows, http://proceedings.mlr.press/v89/hegde19a/hegde19a.pdf</p>
</li>
<li>
<p>Supplementary material for deep learning with differential Gaussian process flows, http://proceedings.mlr.press/v89/hegde19a/hegde19a-supp.pdf</p>
</li>
<li>
<p>A Comprehensive Review of Autonomous Driving Algorithms: Tackling Adverse Weather Conditions, Unpredictable Traffic Violations, Blind Spot Monitoring, and Emergency Maneuvers - MDPI, https://www.mdpi.com/1999-4893/17/11/526</p>
</li>
<li>
<p>Self-driving Research in Review: ICRA 2019 Digest | by Woven Planet Level 5, https://wovenplanetlevel5.medium.com/self-driving-research-in-review-icra-2019-digest-e914405fe598</p>
</li>
<li>
<p>Egocentric Vision-based Future Vehicle Localization for Intelligent Driving Assistance Systems - Honda Research Institute, https://usa.honda-ri.com/filter-projects/-/asset_publisher/OEpov0TwVreT/content/icra-2019-hevi</p>
</li>
<li>
<p>Egocentric Vision-Based Future Vehicle Localization for Intelligent …, http://vision.soic.indiana.edu/papers/futurevehicle2019icra.pdf</p>
</li>
<li>
<p>news_archive [LL4MA lab], https://robot-learning.cs.utah.edu/news_archive</p>
</li>
<li>
<p>Byron Boots - University of Washington - CSE Home, https://homes.cs.washington.edu/~bboots/</p>
</li>
<li>
<p>[1810.06187] Robust Learning of Tactile Force Estimation through Robot Interaction - arXiv, https://arxiv.org/abs/1810.06187</p>
</li>
<li>
<p>(PDF) Robust Learning of Tactile Force Estimation through Robot …, https://www.researchgate.net/publication/328303954_Robust_Learning_of_Tactile_Force_Estimation_through_Robot_Interaction</p>
</li>
<li>
<p>Robust Learning of Tactile Force Estimation through Robot Interaction - arXiv, https://arxiv.org/pdf/1810.06187</p>
</li>
<li>
<p>(PDF) Robust Learning of Tactile Force Estimation through Robot Interaction, https://www.researchgate.net/publication/335138839_Robust_Learning_of_Tactile_Force_Estimation_through_Robot_Interaction</p>
</li>
<li>
<p>Group Human-Robot Interaction: A Review - Cognitive Science, https://cogsci.yale.edu/sites/default/files/files/2019ThesisWisowaty.pdf</p>
</li>
<li>
<p>[1904.07850] Objects as Points - arXiv, https://arxiv.org/abs/1904.07850</p>
</li>
<li>
<p>(PDF) Object Detection in 20 Years: A Survey - ResearchGate, https://www.researchgate.net/publication/333077580_Object_Detection_in_20_Years_A_Survey</p>
</li>
<li>
<p>[1912.06680] Dota 2 with Large Scale Deep Reinforcement Learning - arXiv, https://arxiv.org/abs/1912.06680</p>
</li>
<li>
<p>Multilingual Neural Machine Translation with Knowledge Distillation, http://arxiv.org/pdf/1902.10461</p>
</li>
<li>
<p>Robots in healthcare: a solution or a problem? - European Parliament, https://www.europarl.europa.eu/RegData/etudes/IDAN/2019/638391/IPOL_IDA(2019)638391_EN.pdf</p>
</li>
<li>
<p>Penn Engineering Research Discovers Critical Vulnerabilities in AI-Enabled Robots to Increase Safety and Security, https://blog.seas.upenn.edu/penn-engineering-research-discovers-critical-vulnerabilities-in-ai-enabled-robots-to-increase-safety-and-security/</p>
</li>
<li>
<p>Trust and Bias in Robots | American Scientist, https://www.americanscientist.org/article/trust-and-bias-in-robots# 2019년 5월 AI 및 로봇 분야 주요 연구 동향 심층 분석 보고서</p>
</li>
</ol>
<h2>8. 서론: 2019년 5월, AI와 로봇 연구의 분기점</h2>
<p>2019년 5월은 인공지능(AI)과 로보틱스 분야에서 단순한 점진적 발전을 넘어, 기존 패러다임에 대한 근본적인 질문을 던지고 새로운 방향성을 제시한 중요한 분기점으로 기록된다. 이 시기 학계에서는 모델의 성능을 극대화하는 것을 넘어 <strong>효율성(Efficiency)</strong>, <strong>일반화(Generalization)</strong>, 그리고 **신뢰성(Reliability)**이라는 세 가지 키워드가 핵심 주제로 부상하였다.1</p>
<p>본 보고서는 당대 최고의 학회로 꼽히는 ICLR(International Conference on Learning Representations) 2019와 ICRA(IEEE International Conference on Robotics and Automation) 2019를 중심으로 이러한 변화의 양상을 심층적으로 분석한다.4 ICLR 2019에서는 신경망의 내부 작동 원리를 파헤쳐 훈련 및 추론의 효율성을 극대화하려는 시도가 두드러졌으며, 이는 “복권 가설(The Lottery Ticket Hypothesis)“과 “미분 가능한 아키텍처 탐색(DARTS)“과 같은 혁신적인 연구로 구체화되었다.5 동시에 ICRA 2019에서는 로봇이 복잡하고 불확실한 현실 세계에서 인간과 안전하게 상호작용하고 협업하기 위한 자율성과 강건성(robustness) 확보 연구가 핵심을 이루었다.7 이 두 학회에서 발표된 연구들은 AI와 로보틱스가 각자의 영역에서 깊이를 더하는 동시에, 서로에게 새로운 과제를 제시하며 융합하는 양상을 명확히 보여주었다.</p>
<h2>9.  학습 표현의 재정의 - ICLR 2019 핵심 연구 분석</h2>
<p>ICLR 2019는 딥러닝 모델의 성능을 단순히 높이는 것을 넘어, ’어떻게 더 효율적으로, 더 잘 일반화되도록, 그리고 더 구조적으로 만들 것인가’에 대한 근본적인 탐구가 이루어진 학술의 장이었다.4 본 장에서는 그 중심에 있었던 네 가지 핵심 연구를 집중적으로 분석하여 당대 AI 연구의 패러다임 변화를 조명한다.</p>
<h3>9.1  최우수 논문 심층 분석: 신경망의 효율성과 구조에 대한 새로운 통찰</h3>
<p>ICLR 2019 최우수 논문상은 신경망의 근본적인 속성과 구조에 대한 깊이 있는 탐구를 통해 효율성을 극대화하려는 두 편의 연구에 공동으로 수여되었다.11 이는 AI 연구 커뮤니티의 관심이 단순히 더 큰 모델을 통한 성능 향상에서 모델의 본질적인 이해와 최적화로 이동하고 있음을 시사한다.</p>
<h4>9.1.1  “복권 가설 (The Lottery Ticket Hypothesis)”: 신경망 가지치기의 새로운 지평</h4>
<p>Jonathan Frankle과 Michael Carbin이 제안한 “복권 가설“은 신경망의 과대 매개변수화(overparameterization)와 가지치기(pruning)에 대한 기존의 통념을 뒤흔드는 혁신적인 관점을 제시하였다.11</p>
<ul>
<li>
<p><strong>가설의 정의</strong>: “복권 가설“은 무작위로 초기화된 거대하고 밀집된(dense) 신경망 내부에 특별한 하위 네트워크(subnetwork)가 존재한다고 주장한다. “당첨 티켓(winning ticket)“이라 불리는 이 하위 네트워크는, 전체 네트워크와 동일한 초기 가중치를 유지한 채 단독으로 훈련될 경우, 더 적은 반복만으로도 전체 네트워크와 동등하거나 더 나은 성능에 도달할 수 있다.12 이는 성공적인 훈련이 좋은 초기화 값의 ’조합’에 크게 의존하며, 큰 네트워크는 이러한 ’당첨 티켓’을 포함할 확률이 더 높다는 것을 의미한다.13</p>
</li>
<li>
<p><strong>“당첨 티켓” 발견 알고리즘</strong>: 연구진은 “당첨 티켓“을 찾기 위해 **반복적 크기 기반 가지치기(Iterative Magnitude Pruning, IMP)**라는 알고리즘을 사용하였다. 이 과정은 다음과 같은 단계로 이루어진다.12</p>
</li>
</ul>
<ol>
<li>
<p>신경망 <span class="math math-inline">f(x; \theta_0)</span>을 무작위로 초기화한다.</p>
</li>
<li>
<p>네트워크를 수렴할 때까지 훈련하여 가중치 <span class="math math-inline">\theta_j</span>를 얻는다.</p>
</li>
<li>
<p><span class="math math-inline">\theta_j</span>에서 크기(magnitude)가 가장 작은 가중치 일부를 가지치기(prune)한다.</p>
</li>
<li>
<p>가지치기 후 남은 가중치들을 원래의 초기값 <span class="math math-inline">\theta_0</span>으로 되돌린다(rewind).</p>
</li>
<li>
<p>원하는 희소성(sparsity) 수준에 도달할 때까지 2-4단계를 반복한다.</p>
</li>
</ol>
<p>여기서 핵심은 단순히 가지치기된 구조를 새로 초기화하는 것이 아니라, 원래의 “운 좋은” 초기값으로 ‘되돌리는’ 것이다. 이 ‘되돌리기’ 과정이 없다면 하위 네트워크의 성능은 급격히 저하된다.13</p>
<ul>
<li><strong>실험 결과 및 의의</strong>: MNIST와 CIFAR10 데이터셋을 사용한 실험에서, 원본 네트워크 크기의 10-20%에 불과한 희소성을 가진 “당첨 티켓“이 원본 네트워크의 성능을 능가하는 현상이 일관되게 발견되었다.12 이 발견은 ’일단 큰 모델을 훈련시킨 후 압축해야 한다’는 기존의 패러다임을 정면으로 반박한다. 대신, ’과대 매개변수화는 좋은 초기값을 가진 하위 네트워크를 찾을 확률을 높이기 위한 탐색 과정’이라는 새로운 해석을 제시하며, 신경망 훈련과 아키텍처 설계에 대한 근본적인 이해를 바꾸는 계기를 마련하였다.15</li>
</ul>
<h4>9.1.2  “정렬된 뉴런 (Ordered Neurons)”: 순환 신경망에 계층 구조 통합</h4>
<p>자연어는 단어, 구(phrase), 절(clause) 등이 중첩된 계층적 구조를 갖는다. 그러나 표준 LSTM(Long Short-Term Memory)과 같은 순환 신경망(RNN)은 본질적으로 순차적인 데이터 처리에 특화되어 있어 이러한 계층 구조를 명시적으로 모델링하는 데 한계가 있었다. Yikang Shen 등이 발표한 “Ordered Neurons“는 이 문제에 대한 독창적인 해법을 제시하였다.22</p>
<ul>
<li>
<p><strong>핵심 아이디어: Ordered Neurons</strong>: 이 연구는 LSTM의 은닉 상태 뉴런들을 가상으로 ’정렬(ordering)’하고, 새로운 귀납적 편향(inductive bias)을 도입한다. 이 편향은 상위 뉴런(high-ranking neurons)이 문장 전체의 문맥과 같은 장기적 정보를, 하위 뉴런(low-ranking neurons)이 현재 단어와 같은 단기적 정보를 처리하도록 유도한다. 핵심 규칙은 ’상위 뉴런의 정보가 지워지면(업데이트되면), 그보다 하위에 있는 모든 뉴런의 정보도 반드시 함께 지워져야 한다’는 것이다.22</p>
</li>
<li>
<p><strong>구조적 게이팅과 <code>cumax()</code> 활성화 함수</strong>: 이 아이디어를 구현하기 위해 ’마스터 게이트(master gates)’라는 새로운 게이팅 메커니즘과 <code>cumax()</code>라는 활성화 함수가 도입되었다.12</p>
</li>
<li>
<p><code>cumax()</code> 함수는 이름에서 알 수 있듯, <code>softmax</code> 함수의 누적 합(cumulative sum)으로 정의된다. 입력 벡터 <code>z</code>에 대해 <code>cumax()</code>의 <span class="math math-inline">i</span>-번째 원소는 <code>softmax</code> 결과의 첫 번째 원소부터 <span class="math math-inline">i</span>-번째 원소까지의 합이다.</p>
<pre><code>$$
\text{cumax}(z)_i = \sum_{j=1}^{i} \text{softmax}(z)_j
</code></pre>
</li>
</ul>
<p>$$</p>
<p>이 함수는 항상 단조 증가하며 `` 범위의 값을 갖는 벡터를 출력한다.</p>
<ul>
<li>
<p>모델은 <code>cumax()</code> 함수를 통해 마스터 forget 게이트 <span class="math math-inline">\tilde{f}_t</span>와 마스터 input 게이트 <span class="math math-inline">\tilde{i}_t</span>를 계산한다.</p>
<pre><code>$$
\tilde{f}_t = \text{cumax}(\text{logit}_{\tilde{f}_t})
</code></pre>
</li>
</ul>
<p>$$</p>
<p>이 마스터 게이트들은 기존 LSTM의 셀 상태 업데이트 공식 <span class="math math-inline">c_t = f_t \odot c_{t-1} + i_t \odot \hat{c}_t</span>에 추가적으로 곱해져(<span class="math math-inline">c_t = \tilde{f}_t \odot (f_t \odot c_{t-1}) + \tilde{i}_t \odot (i_t \odot \hat{c}_t)</span>), 뉴런의 순서에 따른 연쇄적인 정보 업데이트를 강제한다. 즉, <span class="math math-inline">\tilde{f}_t</span>의 특정 원소가 <span class="math math-inline">0</span>에 가까워지면(정보를 잊으면) 그보다 하위의 모든 원소들도 0에 가까워지게 된다.26</p>
<ul>
<li><strong>성과</strong>: 이러한 구조적 편향을 가진 ON-LSTM(Ordered Neurons LSTM)은 언어 모델링, 비지도 구문 분석(unsupervised parsing), 논리적 추론 등 다양한 과제에서 표준 LSTM보다 뛰어난 성능을 보였다. 특히 문법적으로 먼 거리에 있는 단어 간의 의존성(long-term dependency)을 더 잘 포착하는 능력을 보여주었는데, 이는 모델이 내부적으로 언어의 계층 구조를 학습한 결과로 해석된다.12</li>
</ul>
<h3>9.2  생성 모델의 비약적 도약: BigGAN과 고충실도 이미지 합성</h3>
<p>2019년 이전까지 생성적 적대 신경망(GAN)은 고해상도의 다양한 이미지를 안정적으로 생성하는 데 어려움을 겪고 있었다.27 ICLR 2019에서 발표된 BigGAN은 전례 없는 규모의 훈련과 몇 가지 핵심 기술을 통해 이 한계를 돌파하며 생성 모델 연구에 큰 획을 그었다.29</p>
<ul>
<li>
<p><strong>대규모 훈련(Large Scale Training)의 힘</strong>: BigGAN 성공의 핵심 동력은 ’규모’에 있었다. 연구진은 이전 SOTA 모델 대비 2배에서 4배 더 많은 매개변수와 8배 더 큰 배치 사이즈를 사용하여 모델을 훈련했다.28 이처럼 방대한 계산 자원을 투입한 대규모 훈련은 모델이 ImageNet과 같이 복잡하고 다양한 데이터 분포를 더 효과적으로 학습할 수 있게 만들었다.32</p>
</li>
<li>
<p><strong>핵심 기술 상세 분석</strong>:</p>
</li>
<li>
<p><strong>대규모 배치(Large Batch Size)</strong>: 배치 사이즈를 크게 늘리는 것은 훈련 안정성을 극적으로 향상시켰다. 각 배치에 더 많은 데이터 모드(mode)가 포함됨으로써, 생성자(Generator)와 판별자(Discriminator)가 더 안정적이고 유의미한 그래디언트를 얻을 수 있었다.28</p>
</li>
<li>
<p><strong>직교 정규화(Orthogonal Regularization)</strong>: 생성자의 가중치 행렬이 직교성(orthogonality)을 갖도록 제약하는 정규화 기법을 적용했다. 이는 가중치 행렬의 특이값(singular values) 분포를 제어하여 그래디언트 폭발이나 소실을 막고, 훈련 과정 전체의 불안정성을 완화하는 데 결정적인 역할을 했다.27</p>
</li>
<li>
<p><strong>절단 기법(The Truncation Trick)</strong>: BigGAN은 이미지 생성 품질을 제어하는 독창적인 방법을 제시했다. 훈련 시에는 표준 정규분포(<span class="math math-inline">N(0, I)</span>)에서 잠재 벡터 <span class="math math-inline">z</span>를 샘플링하지만, 추론(이미지 생성) 시에는 특정 임계값(threshold)을 벗어나는 값을 잘라낸 ‘절단된(truncated)’ 분포에서 샘플링한다. 이 기법을 통해 생성되는 이미지의 **품질(fidelity)**과 <strong>다양성(variety)</strong> 사이의 균형을 사용자가 직접 조절할 수 있게 되었다. 임계값을 낮추면 품질은 높아지지만 다양성은 줄어들고, 높이면 그 반대가 된다.27</p>
</li>
<li>
<p><strong>성과</strong>: 이 기술들의 조합을 통해 BigGAN은 ImageNet 128x128 해상도에서 당시 최고 기록이었던 Inception Score(IS)를 52.52에서 166.5로, Fréchet Inception Distance(FID)를 18.65에서 7.4로 대폭 개선하며 새로운 SOTA를 달성했다.28 이는 대규모 컴퓨팅 자원과 정교한 정규화 기법의 결합이 생성 모델의 한계를 돌파할 수 있음을 보여준 기념비적인 성과였다.</p>
</li>
</ul>
<h3>9.3  신경망 아키텍처 탐색(NAS)의 패러다임 전환: DARTS</h3>
<p>최적의 신경망 아키텍처를 자동으로 찾는 신경망 아키텍처 탐색(NAS)은 2019년 이전까지 막대한 계산 비용이 가장 큰 장벽이었다. 강화학습이나 진화 알고리즘 기반의 방법들은 최적의 구조를 찾기 위해 수백 GPU 일이 소요되었다.35 ICLR 2019에서 발표된 DARTS(Differentiable Architecture Search)는 이 문제를 해결하며 NAS 연구의 대중화를 이끌었다.38</p>
<ul>
<li>
<p><strong>DARTS의 혁신: 미분 가능한 탐색</strong>: DARTS의 가장 큰 혁신은 아키텍처 탐색이라는 이산적인(discrete) 문제를 미분 가능한 연속적인(continuous) 문제로 전환한 것이다. 이를 통해 그래디언트 기반 최적화가 가능해졌고, 탐색 비용을 기존 대비 수백 배 절감할 수 있었다.35</p>
</li>
<li>
<p><strong>핵심 방법론 분석</strong>:</p>
</li>
<li>
<p><strong>연속적 완화(Continuous Relaxation)</strong>: DARTS는 특정 연산자(예: 3x3 convolution, max pooling)를 선택하는 이산적인 결정 대신, 가능한 모든 연산자들의 가중합(weighted sum)으로 연산을 정의한다. 각 연산자의 중요도를 나타내는 가중치 <span class="math math-inline">\alpha</span>는 <code>softmax</code> 함수를 통해 정규화되며, 이 <span class="math math-inline">\alpha</span>가 바로 학습을 통해 최적화할 아키텍처 매개변수가 된다. 노드 <span class="math math-inline">(i, j)</span> 사이의 혼합 연산 <span class="math math-inline">\bar{o}^{(i,j)}</span>는 다음과 같이 표현된다.35</p>
<pre><code>$$
\bar{o}^{(i,j)}(x) = \sum_{o \in \mathcal{O}} \frac{\exp(\alpha_{o}^{(i,j)})}{\sum_{o' \in \mathcal{O}} \exp(\alpha_{o'}^{(i,j)})} o(x)
</code></pre>
</li>
</ul>
<p>$$</p>
<p>탐색이 완료된 후에는 각 연결에서 가장 높은 <span class="math math-inline">\alpha</span> 값을 가진 연산자 하나만 선택하여 최종 아키텍처를 구성한다.</p>
<ul>
<li>
<p><strong>이중 수준 최적화(Bi-level Optimization)</strong>: DARTS는 네트워크 가중치 <span class="math math-inline">w</span>와 아키텍처 매개변수 <span class="math math-inline">\alpha</span>를 동시에 최적화하기 위해 이중 수준 최적화 프레임워크를 사용한다. 외부 루프에서는 검증 데이터 손실(<span class="math math-inline">\mathcal{L}_{val}</span>)을 최소화하도록 <span class="math math-inline">\alpha</span>를 업데이트하고, 내부 루프에서는 훈련 데이터 손실(<span class="math math-inline">\mathcal{L}_{train}</span>)을 최소화하도록 <span class="math math-inline">w</span>를 업데이트한다. 이 관계는 다음과 같이 수식화된다.35</p>
<pre><code>$$
\min_{\alpha} \mathcal{L}_{val}(w^*(\alpha), \alpha) \quad \text{s.t.} \quad w^*(\alpha) = \text{argmin}_w \mathcal{L}_{train}(w, \alpha)
</code></pre>
</li>
</ul>
<p>$$</p>
<ul>
<li><strong>영향 및 후속 연구</strong>: DARTS는 NAS 연구의 진입 장벽을 극적으로 낮추며 관련 연구의 폭발적인 증가를 이끌었다.42 그러나 탐색 과정에서 파라미터가 없는 연산(예: skip-connection)이 과도하게 선택되는 편향 문제와 최종 성능이 불안정한 ‘성능 붕괴(performance collapse)’ 현상이 발견되었다.37 이러한 문제점을 해결하기 위해 P-DARTS, RobustDARTS 등 수많은 후속 연구가 등장하며 DARTS는 미분 기반 NAS 연구의 중요한 시발점이자 비교 기준으로 자리 잡았다.41</li>
</ul>
<h3>9.4  범용 자연어 이해의 표준 정립: GLUE 벤치마크</h3>
<p>2019년 이전의 자연어 처리(NLP) 연구는 개별 태스크별로 모델을 평가하는 경향이 강했다. 이로 인해 특정 데이터셋에만 과적합된 모델이 양산되었고, 모델의 범용적인 언어 이해 능력을 종합적으로 측정할 표준이 부재했다.47 GLUE(General Language Understanding Evaluation) 벤치마크는 이러한 문제의식에서 출발하여 NLU 연구의 새로운 표준을 제시했다.48</p>
<ul>
<li>
<p><strong>GLUE의 구성</strong>: GLUE는 기존에 널리 사용되던 9개의 자연어 이해(NLU) 태스크를 모아 구성한 종합 벤치마크이다. 이 태스크들은 문법성 판단, 감성 분석, 문장 유사도 측정, 자연어 추론 등 다양한 언어 능력을 요구하며, 데이터셋의 크기, 장르, 난이도 또한 다채롭다.48</p>
</li>
<li>
<p><strong>GLUE의 목표와 영향</strong>: GLUE의 핵심 목표는 단일 태스크가 아닌, 여러 태스크에 걸쳐 언어 지식을 공유하고 전이하는(transfer learning) 범용 NLU 시스템 개발을 촉진하는 것이었다.48 공개된 리더보드는 연구자들 간의 건전한 경쟁을 유도했고, 특히 BERT와 같은 대규모 사전 훈련 언어 모델(PLM)의 성능을 입증하는 표준 무대가 되었다.52 GLUE는 NLU 연구의 평가 방식을 표준화하고, 모델의 일반화 성능을 중시하는 연구 문화를 정착시키는 데 결정적인 역할을 했다.</p>
</li>
<li>
<p><strong>한계와 발전</strong>: BERT와 같은 모델들이 등장하며 GLUE 벤치마크의 여러 태스크에서 인간의 성능을 빠르게 넘어서자, 벤치마크의 변별력이 떨어진다는 지적이 제기되었다. 이는 더 어렵고 복잡한 추론 능력을 요구하는 태스크들로 구성된 후속 벤치마크인 SuperGLUE의 등장을 이끌었다. 이처럼 GLUE는 NLU 모델 평가의 표준을 제시했을 뿐만 아니라, 학계의 발전에 따라 스스로 진화하는 벤치마크의 역할 모델이 되었다.47</p>
</li>
</ul>
<table><thead><tr><th>과제명</th><th>유형</th><th>평가 지표</th><th>훈련 데이터 크기</th></tr></thead><tbody>
<tr><td>CoLA</td><td>단일 문장 (문법성 판단)</td><td>Matthews corr</td><td>8.5k</td></tr>
<tr><td>SST-2</td><td>단일 문장 (감성 분석)</td><td>Accuracy</td><td>67k</td></tr>
<tr><td>MRPC</td><td>문장 쌍 (의미 동일성)</td><td>Accuracy/F1</td><td>3.7k</td></tr>
<tr><td>QQP</td><td>문장 쌍 (의미 동일성)</td><td>Accuracy/F1</td><td>364k</td></tr>
<tr><td>STS-B</td><td>문장 쌍 (의미 유사도)</td><td>Pearson/Spearman corr</td><td>7k</td></tr>
<tr><td>MNLI</td><td>문장 쌍 (자연어 추론)</td><td>Accuracy (matched/mismatched)</td><td>393k</td></tr>
<tr><td>QNLI</td><td>문장 쌍 (자연어 추론)</td><td>Accuracy</td><td>105k</td></tr>
<tr><td>RTE</td><td>문장 쌍 (자연어 추론)</td><td>Accuracy</td><td>2.5k</td></tr>
<tr><td>WNLI</td><td>문장 쌍 (자연어 추론)</td><td>Accuracy</td><td>635</td></tr>
</tbody></table>
<p>동시에 GLUE 벤치마크의 등장은 ’범용적 언어 능력’이라는 추상적 목표를 측정 가능한 지표로 만들려는 시도였다는 점에서 중요한 의미를 갖는다. BERT와 같은 강력한 사전 훈련 모델이 등장하면서, 이들의 진정한 언어 이해 능력을 평가할 표준화된 잣대가 필요해졌고, GLUE가 그 역할을 성공적으로 수행했다. 이는 NLP 연구의 방향을 ’모델 개발’에서 ’모델 평가 및 분석’으로 확장시키는 계기가 되었다. GLUE는 모델의 강점뿐만 아니라 약점과 편향을 분석하는 연구를 촉진했으며, 이후 SuperGLUE, Big-Bench 등 더 복잡하고 다각적인 벤치마크의 개발로 이어지는 토대를 마련했다.</p>
<h2>10.  현실 세계로의 확장 - ICRA 2019 로보틱스 연구 동향</h2>
<p>ICRA 2019에서는 로봇이 통제된 실험실 환경을 넘어 예측 불가능하고 동적인 현실 세계에서 인간과 공존하며 복잡한 임무를 수행하기 위한 핵심 기술들이 집중적으로 조명되었다.7 본 장에서는 인지, 협응, 지각 능력이라는 세 가지 축을 중심으로, 로보틱스 연구가 어떻게 AI 기술을 융합하여 현실 세계의 난관을 극복하려 했는지 분석한다.</p>
<h3>10.1  인지 로보틱스와 인간-로봇 상호작용의 고도화</h3>
<p>로봇이 인간의 작업 공간에 들어오면서, 단순히 정해진 동작을 반복하는 것을 넘어 인간의 의도를 파악하고 예측 불가능한 상황에 대처하는 ‘인지’ 능력이 중요해졌다. ICRA 2019에서는 이러한 인간-로봇 상호작용(HRI)의 신뢰성을 높이기 위한 연구가 주목받았다.</p>
<ul>
<li>
<p><strong>최우수 논문 분석: “Efficient Symbolic Reactive Synthesis for Finite-Horizon Tasks”</strong>: 라이스 대학 Kavraki 그룹의 이 연구는 인간-로봇 협업의 신뢰성을 한 단계 끌어올린 성과로 평가받는다.7</p>
</li>
<li>
<p><strong>연구 목표</strong>: 인간과 로봇이 조립 작업을 함께 수행하는 시나리오에서, 인간이 비협조적이거나 심지어 방해하는 행동을 하더라도 로봇이 반드시 주어진 시간 내에 임무를 완수할 수 있는 ’필승 전략(winning strategy)’을 사전에 계산하는 것을 목표로 한다.7</p>
</li>
<li>
<p><strong>핵심 기술</strong>: 이를 위해 연구진은 ’기호적 반응형 합성(Symbolic Reactive Synthesis)’이라는 형식 검증(formal methods) 기술을 사용했다. 이 접근법은 로봇의 행동, 인간의 가능한 모든 행동, 그리고 환경 변화를 기호적 논리식으로 모델링한다. 그 후, 이 모델상에서 목표를 항상 만족시키는 로봇의 제어 정책(전략)을 수학적으로 합성한다.</p>
</li>
<li>
<p><strong>기여</strong>: 기존 반응형 합성 기술은 상태 공간의 크기가 커지면 계산량이 폭발적으로 증가하는 확장성 문제가 있었다. 이 논문은 문제의 명세(specification)와 물리적 도메인 지식을 분리하고, 도메인을 ’이진 결정 다이어그램(Binary Decision Diagrams, BDD)’이라는 효율적인 자료구조로 표현함으로써 계산 성능을 지수적으로 향상시켰다. 이는 로봇의 행동에 ’수학적 보증’을 부여하려는 시도라는 점에서 큰 의의를 가지며, 로보틱스와 형식 검증이라는 두 컴퓨터 과학 분야를 성공적으로 융합한 사례이다.7</p>
</li>
</ul>
<h3>10.2  다중 로봇 시스템의 협응과 자율 항법</h3>
<p>단일 로봇을 넘어 여러 로봇이 협력하여 임무를 수행하는 다중 로봇 시스템은 물류, 탐사, 농업 등 다양한 분야에서 활용 가능성이 크다. ICRA 2019에서는 다수의 로봇이 충돌 없이 효율적으로 움직이기 위한 경로 계획 및 자율 항법 기술이 비중 있게 다뤄졌다.</p>
<ul>
<li>
<p><strong>분산 모델 예측 제어(DMPC) 기반 다중 에이전트 경로 생성</strong>: 논문 “Trajectory Generation for Multiagent Point-To-Point Transitions via Distributed Model Predictive Control“은 수십 대의 드론과 같은 다중 에이전트가 충돌 없이 각자의 목표 지점으로 빠르고 효율적으로 이동하는 경로를 생성하는 새로운 알고리즘을 제시했다.56</p>
</li>
<li>
<p>이 알고리즘은 각 에이전트가 자신의 미래 경로를 예측하고, 이 정보를 이웃 에이전트와 공유하여 잠재적인 충돌을 미리 감지하고 회피하는 ’분산 모델 예측 제어(DMPC)’에 기반한다.</p>
</li>
<li>
<p>기존 DMPC는 충돌을 원천적으로 방지하기 위해 에이전트의 움직임에 강한 제약을 가하여 계산이 복잡했다. 이 연구는 충돌 제약 조건을 완화하여 ‘필요할 때만’ 강제하는 방식으로 접근법을 수정함으로써, 계획의 최적성을 거의 해치지 않으면서도 계산 시간을 이전 방식 대비 85% 이상 단축하는 데 성공했다.56</p>
</li>
<li>
<p><strong>SLAM 기술 동향</strong>: 로봇이 미지의 환경에서 자신의 위치를 파악하고 동시에 지도를 작성하는 SLAM(Simultaneous Localization and Mapping) 기술은 자율 항법의 근간이다. ICRA 2019에서는 SLAM 기술의 정확성, 속도, 강건성을 높이기 위한 다양한 연구가 발표되었다.57</p>
</li>
<li>
<p><strong>FMD Stereo SLAM</strong>: 다중 시점 기하학(MVG) 기반의 특징점 방식과 픽셀 밝기 정보를 직접 사용하는 직접법(Direct Formulation)의 장점을 융합하여 정확도와 속도를 모두 개선한 스테레오 SLAM이다.</p>
</li>
<li>
<p><strong>GEN-SLAM</strong>: 생성 모델(Generative Model)을 활용하여 불확실성을 더 잘 다루는 단안(Monocular) SLAM 기법이다.</p>
</li>
<li>
<p>RESLAM: 이미지의 엣지(edge) 정보를 적극적으로 활용하여 조명 변화나 특징이 부족한 환경에서도 강건하게 작동하는 실시간 SLAM 시스템이다.</p>
</li>
</ul>
<p>이러한 연구들은 SLAM 기술이 더욱 다양한 센서와 알고리즘을 융합하며, 현실 세계의 까다로운 환경에 대응하는 방향으로 발전하고 있음을 보여준다.</p>
<h3>10.3  로봇 지각 능력의 발전: 데이터셋과 강화학습</h3>
<p>로봇이 자율적으로 작업을 수행하기 위해서는 주변 환경을 정확하게 ‘보고’ 이해하는 지각 능력이 필수적이다. ICRA 2019에서는 로봇 지각 알고리즘의 발전을 촉진하는 고품질 데이터셋과, 시뮬레이션 학습의 한계를 극복하려는 강화학습 연구가 주목받았다.</p>
<ul>
<li>
<p><strong>다중 모션 추정을 위한 데이터셋: Oxford Multimotion Dataset (OMD)</strong>: 로봇이 정적인 환경뿐만 아니라, 여러 객체가 동시에 움직이는 동적인 환경을 이해하기 위해서는 장면 내의 ‘모든’ 움직임을 추정하는 ‘다중 모션 추정(multimotion estimation)’ 기술이 필요하다. OMD는 이러한 연구를 위해 공개된 대규모 벤치마크 데이터셋이다.58</p>
</li>
<li>
<p>이 데이터셋은 스테레오 카메라, RGB-D 카메라, 관성 측정 장치(IMU) 등 다양한 센서 데이터와 함께, Vicon 모션 캡처 시스템을 통해 얻은 모든 움직이는 객체의 정확한 3차원 위치와 자세(ground truth) 정보를 포함한다. 총 80분이 넘는 분량으로 구성되어 있으며, 간단한 움직임부터 복잡한 가림(occlusion) 현상까지 다양한 시나리오를 제공한다.58</p>
</li>
<li>
<p>OMD와 같은 고품질 데이터셋의 등장은 관련 알고리즘의 성능을 정량적으로 비교하고 공정하게 평가할 수 있는 기반을 제공함으로써, 데이터 기반 로봇 지각 연구의 발전을 가속화하는 데 결정적인 역할을 한다.</p>
</li>
<li>
<p><strong>Sim-to-Real 격차 해소를 위한 강화학습</strong>: 강화학습은 로봇이 시행착오를 통해 복잡한 기술을 스스로 학습하게 하는 강력한 도구이지만, 현실 세계에서 직접 학습하는 것은 시간과 비용이 많이 들고 위험하다. 따라서 대부분의 연구는 시뮬레이션에서 정책을 학습한 후 실제 로봇으로 옮기는 ‘Sim-to-Real’ 접근법을 택한다. 그러나 시뮬레이션과 현실 세계의 물리적 차이, 즉 ’현실 격차(reality gap)’로 인해 시뮬레이션에서 학습한 정책이 현실에서 실패하는 경우가 많다.3</p>
</li>
<li>
<p><strong>NVIDIA의 SimOpt 연구</strong>: 이 문제를 해결하기 위해 NVIDIA는 ICRA 2019에서 ’SimOpt’라는 새로운 접근법을 제시했다. 이는 소수의 실제 로봇 실행 데이터를 사용하여 시뮬레이션의 물리 파라미터(예: 마찰 계수, 질량, 탄성)를 자동으로 조정하는 방식이다. 이를 통해 시뮬레이션 환경을 현실과 점진적으로 유사하게 만들어, 정책 이전(policy transfer)의 성공률을 크게 높였다.3</p>
</li>
<li>
<p><strong>인간처럼 주변 환경 추론 AI</strong>: 텍사스 오스틴 대학의 연구진은 재난 구조 로봇과 같이 시간이 촉박한 상황에서 빠른 상황 인식을 위한 AI 에이전트를 개발했다. 이 에이전트는 강화학습을 통해 ’어디를 봐야 가장 많은 정보를 얻을 수 있는지’를 스스로 학습한다. 그 결과, 전체 360도 환경의 20% 미만을 차지하는 몇 번의 ’흘긋 보기(glimpses)’만으로 전체 환경을 높은 정확도로 추론해낼 수 있었다.59</p>
</li>
</ul>
<p>또한, Sim-to-real 연구와 OMD 같은 현실 기반 데이터셋 구축 노력은 로봇 연구의 중심이 순수한 알고리즘 개발에서 ’현실 세계와의 상호작용’을 통한 학습으로 이동하고 있음을 명확히 보여준다. 시뮬레이션은 더 이상 이상적인 학습 공간이 아니라, 현실 데이터를 통해 ‘보정되어야 할’ 대상이 되었고, 복잡한 현실 세계의 동역학을 담은 데이터셋이 있어야만 알고리즘의 실제 성능을 검증할 수 있다는 인식이 확산되었다. 이는 데이터 중심 AI의 패러다임이 로보틱스에 본격적으로 적용되고 있음을 의미하며, 로봇의 성능이 알고리즘의 우수성뿐만 아니라, 얼마나 현실과 유사한 환경에서 양질의 데이터를 통해 학습하고 검증되었는지에 따라 결정될 것임을 예고한다. 이러한 변화는 강화학습과 로봇 공학의 상호 발전적인 관계를 더욱 공고히 하는 중요한 계기가 되었다.60</p>
<h2>11. 결론: 융합과 심화 - 2019년 5월 연구가 제시하는 미래</h2>
<p>2019년 5월, ICLR과 ICRA를 통해 발표된 연구들은 AI와 로보틱스 분야가 중요한 전환점을 맞이했음을 분명히 보여주었다. ICLR 2019에서는 AI 모델의 내부 구조와 학습 원리를 깊이 파고드는 ’심화’의 흐름이, ICRA 2019에서는 AI 기술을 현실 세계의 물리적 에이전트에 적용하여 신뢰성을 확보하려는 ’융합’의 흐름이 두드러졌다.</p>
<p>ICLR에서 제시된 ’복권 가설’과 ’DARTS’는 AI 연구가 무한한 자원을 가정한 성능 경쟁을 넘어, ’효율성’이라는 현실적 제약을 해결하려는 방향으로 나아가고 있음을 상징한다. 이는 한정된 계산 능력과 에너지를 가진 로봇이 다양한 상황에 대처해야 하는 로보틱스의 근본적인 과제에 대한 중요한 해답을 제공한다. 또한, ‘GLUE’ 벤치마크가 촉발한 ’일반화’에 대한 논의는 단일 작업에 특화된 로봇을 넘어, 다양한 임무를 수행할 수 있는 범용 로봇 개발의 필요성과 맞닿아 있다.</p>
<p>반대로, ICRA에서 강조된 ’신뢰성’과 ’강건성’은 AI 분야에 새로운 도전 과제를 제시한다. 기호적 합성을 통한 ‘보증된 자율성’ 확보 노력은 AI 모델의 예측 불가능성과 취약성을 극복하고 안전이 필수적인 영역으로 나아가기 위한 방향을 제시한다. 또한, Sim-to-Real 연구에서 나타난 현실 세계와의 상호작용을 통한 학습 패러다임은 AI가 가상 세계를 넘어 물리적 현실과 상호작용하며 학습하는 ’체화된 AI(Embodied AI)’로 발전해야 함을 역설한다.</p>
<p>결론적으로 2019년 5월의 연구들은 AI와 로보틱스가 서로에게 영감을 주며 발전하는 공생 관계에 있음을 명확히 보여주었다. AI의 효율성과 일반화 연구는 로봇의 지능을 한 단계 끌어올릴 잠재력을, 로보틱스의 신뢰성과 강건성 연구는 AI가 현실 세계에서 책임감 있는 역할을 수행하기 위한 길을 제시하고 있다. 앞으로의 연구는 학습 기반 AI의 유연성과 형식적 방법론의 신뢰성을 결합하고, 방대한 시뮬레이션과 정교한 현실 데이터를 넘나들며 학습하는 더욱 지능적이고 강건한 시스템을 향해 나아갈 것이며, 2019년 5월은 그 중요한 시작점으로 기억될 것이다.</p>
<h2>12. 참고 자료</h2>
<ol>
<li>Improving Reproducibility in Machine Learning Research(A Report from the NeurIPS 2019 Reproducibility Program), https://jmlr.org/papers/v22/20-303.html</li>
<li>Improving Reproducibility in Machine Learning Research(A Report from the NeurIPS 2019 Reproducibility Program), https://jmlr2020.csail.mit.edu/papers/volume22/20-303/20-303.pdf</li>
<li>NVIDIA Unveils New Reinforcement Learning Research at ICRA 2019, https://developer.nvidia.com/blog/nvidia-research-at-icra-2019/</li>
<li>Deadlines for the major conferences of robotics, computer vision, and machine learning. - GitHub, https://github.com/xahidbuffon/conference-deadlines</li>
<li>ICLR 2019 most cited papers - Ludovic Arnold, https://ludovicarnold.com/iclr-2019-most-cited-papers/</li>
<li>7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019 - researchr publication, https://researchr.org/publication/iclr-2019</li>
<li>Kavraki Group wins best paper award at ICRA 2019 | Computer …, https://csweb.rice.edu/news/kavraki-group-wins-best-paper-award-icra-2019</li>
<li>ICRA 2019 : IEEE International Conference on Robotics and Automation - Accepted Papers, Deadline, Impact Factor &amp; Score 2025 | Research.com, https://research.com/conference/icra-2019-2</li>
<li>ICRA 2019 : IEEE International Conference on Robotics and Automation - Accepted Papers, Deadline, Impact Factor &amp; Score 2025 | Research.com, https://research.com/conference/icra-2019-3</li>
<li>ICLR 2019 Conference - OpenReview, https://openreview.net/group?id=ICLR.cc/2019/Conference</li>
<li>Best Paper Award - ICLR 2026, https://iclr.cc/Conferences/2019/Awards</li>
<li>Decoding the Best Papers from ICLR 2019 - Neural Networks are Here to Rule, https://www.analyticsvidhya.com/blog/2019/05/best-papers-iclr-2019/</li>
<li>(Open Access) The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks (2018) | Jonathan Frankle | 1511 Citations - SciSpace, https://scispace.com/papers/the-lottery-ticket-hypothesis-finding-sparse-trainable-1s8pjdso3i</li>
<li>The Lottery Ticket Hypothesis: Training Pruned Neural Networks - ResearchGate, https://www.researchgate.net/publication/323694313_The_Lottery_Ticket_Hypothesis_Training_Pruned_Neural_Networks</li>
<li>Saga of the Lottery Ticket Hypothesis - Cameron R. Wolfe, https://cameronrwolfe.me/blog/lottery-ticket-hypothesis</li>
<li>A Survey of Lottery Ticket Hypothesis - arXiv, https://arxiv.org/html/2403.04861v1</li>
<li>arXiv:2104.11832v2 [cs.CV] 14 Dec 2021, https://arxiv.org/pdf/2104.11832</li>
<li>[PDF] The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks | Semantic Scholar, https://www.semanticscholar.org/paper/The-Lottery-Ticket-Hypothesis%3A-Finding-Sparse%2C-Frankle-Carbin/21937ecd9d66567184b83eca3d3e09eb4e6fbd60</li>
<li>The lottery ticket hypothesis: Finding sparse, trainable neural networks, https://arxiv.org/abs/1803.03635</li>
<li>Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity on Pruned Neural Networks - NIPS, https://proceedings.neurips.cc/paper/2021/file/15f99f2165aa8c86c9dface16fefd281-Paper.pdf</li>
<li>The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks | OpenReview, https://openreview.net/forum?id=rJl-b3RcF7</li>
<li>Brief Report: Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks - Microsoft Research, https://www.microsoft.com/en-us/research/publication/brief-report-ordered-neurons-integrating-tree-structures-into-recurrent-neural-networks/</li>
<li>Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks | Request PDF - ResearchGate, https://www.researchgate.net/publication/328474608_Ordered_Neurons_Integrating_Tree_Structures_into_Recurrent_Neural_Networks</li>
<li>Ordered Neurons: Integrating Tree Structures Into Recurrent Neural Networks, https://cs.uwaterloo.ca/~mli/Niknamian.pdf</li>
<li>Ordered Neurons: Integrating Tree Structures into Recurrent Neural …, https://arxiv.org/pdf/1810.09536</li>
<li>ORDERED NEURONS: INTEGRATING TREE STRUCTURES INTO RECURRENT NEURAL NETWORKS - OpenReview, https://openreview.net/pdf?id=B1l6qiR5F7</li>
<li>Large Scale GAN Training for High Fidelity Natural Image Synthesis - Deep learning travels, https://lyusungwon.github.io/studies/2019/01/08/biggan/</li>
<li>Large Scale GAN Training for High Fidelity Natural Image Synthesis, https://arxiv.org/pdf/1809.11096</li>
<li>Large Scale GAN Training for High Fidelity Natural Image Synthesis - SciSpace, https://scispace.com/papers/large-scale-gan-training-for-high-fidelity-natural-image-30zbv31llw</li>
<li>Large Scale GAN Training for High Fidelity Natural Image Synthesis | Request PDF, https://www.researchgate.net/publication/327980061_Large_Scale_GAN_Training_for_High_Fidelity_Natural_Image_Synthesis</li>
<li>BigGAN: Advances, Applications, and Challenges in Generative Image Processing, https://www.researchgate.net/publication/391690866_BigGAN_Advances_Applications_and_Challenges_in_Generative_Image_Processing</li>
<li>Controlling BigGAN Image Generation with a Segmentation Network | Request PDF - ResearchGate, https://www.researchgate.net/publication/355174006_Controlling_BigGAN_Image_Generation_with_a_Segmentation_Network</li>
<li>not-so-BigGAN: Generating High-Fidelity Images on a Small Compute Budget | Request PDF - ResearchGate, https://www.researchgate.net/publication/344180438_not-so-BigGAN_Generating_High-Fidelity_Images_on_a_Small_Compute_Budget</li>
<li>Large Scale GAN Training for High Fidelity Natural Image Synthesis - OpenReview, https://openreview.net/forum?id=B1xsqj09Fm</li>
<li>DARTS (Differentiable ARchiTecture Search) - Systems for Scalable Machine Learning, <a href="https://fid3024.github.io/papers/2019%20-%20DARTS:%20Differentable%20Architecture%20Search.pdf">https://fid3024.github.io/papers/2019%20-%20DARTS:%20Differentable%20Architecture%20Search.pdf</a></li>
<li>arXiv:1806.09055v2 [cs.LG] 23 Apr 2019, https://arxiv.org/abs/1806.09055</li>
<li>OStr-DARTS: Differentiable Neural Architecture Search based on Operation Strength - arXiv, https://arxiv.org/html/2409.14433v1</li>
<li>quark0/darts: Differentiable architecture search for convolutional and recurrent networks - GitHub, https://github.com/quark0/darts</li>
<li>DARTS: Differentiable Architecture Search - OpenReview, https://openreview.net/forum?id=S1eYHoC5FX</li>
<li>ZARTS: On Zero-order Optimization for Neural Architecture Search, https://papers.neurips.cc/paper_files/paper/2022/file/53f2c82c6b165a963b353194113ee71e-Paper-Conference.pdf</li>
<li>Neural architecture search - Wikipedia, https://en.wikipedia.org/wiki/Neural_architecture_search</li>
<li>HPE-DARTS: Hybrid Pruning and Proxy Evaluation in Differentiable Architecture Search - SciTePress, https://www.scitepress.org/Papers/2025/131487/131487.pdf</li>
<li>[2312.14200] Efficient Architecture Search via Bi-level Data Pruning - arXiv, https://arxiv.org/abs/2312.14200</li>
<li>UNDERSTANDING AND ROBUSTIFYING DIFFERENTIABLE ARCHITECTURE SEARCH - Machine Learning Lab, https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/20-ICLR-RobustDARTS.pdf</li>
<li>[2504.16306] Regularizing Differentiable Architecture Search with Smooth Activation - arXiv, https://arxiv.org/abs/2504.16306</li>
<li>Semantic-DARTS: Elevating Semantic Learning for Mobile Differentiable Architecture Search - University of Waterloo, https://uwaterloo.ca/scholar/sites/ca.scholar/files/sshen/files/guo2025semantic.pdf</li>
<li>GLUE: Evaluating The Performance of NLP Models | by Tanisha.Digital | Gen AI Adventures, https://medium.com/gen-ai-adventures/glue-evaluating-the-performance-of-nlp-models-d68dc3d43f10</li>
<li>GLUE: A MULTI-TASK BENCHMARK AND ANALYSIS PLATFORM FOR NATURAL LANGUAGE UNDERSTAND - OpenReview, https://openreview.net/pdf?id=rJ4km2R5t7</li>
<li>What is the GLUE Benchmark? - Code Labs Academy, https://codelabsacademy.com/en/blog/what-is-the-glue-benchmark/</li>
<li>[1804.07461] GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding - ar5iv, https://ar5iv.labs.arxiv.org/html/1804.07461</li>
<li>GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding, https://arxiv.org/abs/1804.07461</li>
<li>What is GLUE (General Language Understanding Evaluation)? - H2O.ai, https://h2o.ai/wiki/glue/</li>
<li>SuperGLUE: Benchmarking Advanced NLP Models - Zilliz, https://zilliz.com/glossary/superglue</li>
<li>Benchmark of LLMs (Part 1): Glue &amp; SuperGLUE, Adversarial NLI, Big Bench - Medium, https://medium.com/@myschang/benchmark-of-llms-part-1-glue-superglue-adversarial-nli-big-bench-8d1aed6bae12</li>
<li>ICRA 2019 - YouTube, https://www.youtube.com/playlist?list=PL9Hnb9qlvGkSsLHpCgLKu64Aff48w7ohZ</li>
<li>ICRA 2019 | Dynamic Systems Lab | Prof. Angela Schoellig, https://www.dynsyslab.org/icra-2019/</li>
<li>International Conference on Robotics and Automation, ICRA 2019 …, https://researchr.org/publication/icra-2019</li>
<li>ESP @ ICRA 2019 - Estimation, Search, and Planning (ESP …, https://robotic-esp.com/news/2019_05_22_icra19</li>
<li>New AI sees like a human, filling in the blanks | ScienceDaily, https://www.sciencedaily.com/releases/2019/05/190515144017.htm</li>
<li>Reinforcement Learning in Robotics: A Survey, https://www.ri.cmu.edu/pub_files/2013/7/Kober_IJRR_2013.pdf</li>
<li>Reinforcement Learning for Robotics: Challenges and Applications - ResearchGate, https://www.researchgate.net/publication/389905019_Reinforcement_Learning_for_Robotics_Challenges_and_Applications</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>