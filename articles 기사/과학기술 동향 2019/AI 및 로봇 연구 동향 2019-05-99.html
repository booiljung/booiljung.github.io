<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2019년 5월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2019년 5월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2019년 AI 및 로봇 연구 동향</a> / <span>2019년 5월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2019년 5월 AI 및 로봇 연구 동향</h1>
<h2>1.  서론</h2>
<p>2019년 5월은 인공지능 및 로봇 연구 분야에서 이론적 심화와 실제적 적용의 확장이 동시에 폭발적으로 이루어진 결정적 시기였다. 한편에서는 거대 언어 모델과 같은 스케일의 패러다임이 부상했고, 다른 한편에서는 신경망의 근본적인 속성을 탐구하여 효율성을 극대화하려는 노력이 결실을 보았다. 동시에, 로보틱스 분야에서는 학습 기반의 접근법이 실제 물리 환경과의 복잡한 상호작용 문제를 해결하는 데 핵심적인 역할을 하기 시작했다. 본 보고서는 ICLR, ICRA 등 최고 수준의 학회를 중심으로 발표된 핵심 연구들과 OpenAI, DeepMind와 같은 선도적 연구 그룹의 발표를 심층 분석하여, 이 시기의 기술적 성취를 조망하고 그 근저에 흐르는 거시적 동향과 미래 연구에 대한 함의를 도출하고자 한다.1</p>
<p>이 시기의 연구들은 ‘자율 시스템의 부상’, ‘인간-기계 협업 모델의 진화’, ’엣지 컴퓨팅의 확산’이라는 세 가지 핵심 기술 트렌드와 맞물려 진행되었다. 자율 시스템은 파일럿 프로젝트를 넘어 실제 물류, 동적 환경 항법 등 실용적인 응용으로 확장되었고 1, 협동로봇(Cobot)의 등장은 인간 대체가 아닌 증강(augmentation)이라는 새로운 협업 패러다임을 제시했다.1 또한, 클라우드 중심의 연산에서 벗어나 AI 기능을 내장한 스마트 센서를 활용하는 엣지 컴퓨팅이 로보틱스의 핵심 플랫폼으로 부상했다.2 2019년 AI 로보틱스 시장은 이미 23억 달러 규모로 평가되었으며, 머신러닝 방법론의 발전이 성장을 견인할 것으로 예측되었다.3 이러한 기술적, 산업적 배경 속에서, 5월에 개최된 주요 학회들은 미래 기술의 방향성을 제시하는 중요한 이정표가 되었다.</p>
<p>본 보고서는 2장과 3장에서 각각 ICLR 2019와 ICRA 2019에서 발표된 최우수 논문 및 주요 연구를 심층 분석한다. 4장에서는 OpenAI와 DeepMind의 혁신적인 연구 성과를 다룬다. 마지막으로 5장에서는 이러한 개별 연구들을 종합하여 2019년 5월의 AI 및 로봇 기술 지형을 거시적으로 분석하고 미래 전망을 제시한다.</p>
<h2>2.  ICLR 2019: 표현 학습과 신경망의 근본적 탐구</h2>
<h3>2.1 개요</h3>
<p>2019년 5월 6일부터 9일까지 미국 뉴올리언스에서 개최된 제7회 International Conference on Learning Representations (ICLR)는 딥러닝의 근간을 이루는 표현 학습 이론과 신경망 아키텍처에 대한 심도 깊은 논의의 장이었다.4 특히, 최우수 논문으로 선정된 두 편의 연구는 각각 순환 신경망의 구조적 편향과 신경망 가지치기의 본질에 대한 새로운 통찰을 제시하며 학계에 큰 반향을 일으켰다.</p>
<h3>2.2 최우수 논문 심층 분석</h3>
<h4>2.2.1  순서 있는 뉴런 (Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks)</h4>
<p>자연어는 단어가 구(phrase)를 이루고, 구가 절(clause)을 형성하는 등 본질적으로 계층적인 트리 구조를 가진다. 그러나 순차적 데이터 처리에 특화된 표준 Long Short-Term Memory (LSTM)와 같은 순환 신경망(RNN)은 이러한 구조를 명시적으로 모델링하는 데 한계가 있었다.7 이 연구는 이러한 한계를 극복하기 위해 ’순서 있는 뉴런 LSTM(ON-LSTM)’이라는 새로운 아키텍처를 제안했다.10</p>
<p>핵심 방법론은 LSTM의 뉴런(셀 상태)에 순서를 부여하고, ’마스터 게이트(master gates)’를 통해 상위 뉴런의 정보가 하위 뉴런보다 더 오래 유지되도록 강제하는 귀납적 편향(inductive bias)을 추가한 것이다.9 이는 언어의 구성 요소가 중첩되는 방식, 즉 상위 구성 요소(예: 절)가 닫힐 때 그 안의 모든 하위 구성 요소(예: 구)도 함께 닫혀야 하는 원리를 모방한다. 고순위 뉴런은 장기적인 정보(예: 문장 전체의 문맥)를, 저순위 뉴런은 단기적인 정보(예: 현재 단어)를 저장하도록 유도된다.8</p>
<p>이러한 계층적 업데이트 메커니즘을 구현하기 위해, 연구진은 새로운 활성화 함수인 <code>cumax()</code>(cumulative softmax)를 도입했다.9</p>
<p><code>cumax()</code> 함수는 마스터 게이트 값의 단조 증가 속성을 보장하여, 게이트 벡터의 값이 0에서 1로 단조롭게 증가하도록 만든다. 이로 인해 특정 뉴런이 업데이트될 때 그보다 순서가 낮은 모든 뉴런이 함께 업데이트되는 것이 가능해진다.9</p>
<p>ON-LSTM은 언어 모델링, 비지도 구문 분석(unsupervised parsing), 통사적 평가, 논리적 추론 등 네 가지 과제에서 우수한 성능을 보였다. 특히 주목할 점은, 별도의 구문 분석 정보를 사용하지 않고 오직 언어 모델링 훈련만으로 문장의 잠재적인 트리 구조를 성공적으로 학습했다는 것이다.7 이는 신경망 아키텍처 설계에 있어 도메인 지식(언어의 계층 구조)을 어떻게 효과적으로 통합할 수 있는지에 대한 중요한 선례를 남겼으며, 표현 학습 연구에 새로운 방향을 제시했다.10</p>
<h4>2.2.2  복권 가설 (The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks)</h4>
<p>신경망 가지치기(pruning)를 통해 훈련된 네트워크의 파라미터를 90% 이상 제거해도 정확도 손실이 거의 없다는 것은 잘 알려진 사실이었다. 하지만 이렇게 찾은 희소한(sparse) 아키텍처를 처음부터(from scratch) 훈련시키면 오히려 성능이 저하되는 현상이 관찰되었고, 이는 ’왜 더 작은 네트워크를 처음부터 잘 훈련시킬 수 없는가?’라는 근본적인 질문으로 이어졌다.14</p>
<p>이 연구는 이 질문에 대한 답으로 “복권 가설(The Lottery Ticket Hypothesis)“을 제시했다. 이 가설의 핵심은 “무작위로 초기화된 조밀한(dense) 신경망은, 독립적으로 훈련될 때 원래 네트워크와 비슷한 반복 횟수 내에 비슷한 정확도에 도달하는 ’당첨된 복권(winning tickets)’이라 불리는 서브네트워크를 포함한다“는 것이다.10 여기서 ’당첨된 복권’은 단순히 희소한 구조뿐만 아니라, 훈련을 특히 효과적으로 만드는 ’운 좋은 초기 가중치(fortuitous initializations)’를 함께 가진 서브네트워크를 의미한다.14</p>
<p>’당첨된 복권’을 찾는 알고리즘은 ’훈련-가지치기-되감기(train-prune-rewind)’의 3단계로 구성된다. 먼저 전체 네트워크를 정상적으로 훈련시킨다. 그 다음, 훈련된 가중치 중 크기(magnitude)가 가장 작은 것들을 일정 비율 제거(pruning)한다. 마지막으로, 살아남은 연결들의 가중치를 훈련 전의 초기값으로 되돌린다.11</p>
<p>MNIST 및 CIFAR10 데이터셋을 사용한 실험에서, 원본 네트워크 크기의 10-20%에 불과한 ’당첨된 복권’이 원본 네트워크보다 더 빠르게 학습하고 더 높은 테스트 정확도를 달성함을 보였다. 반면, 이 서브네트워크의 가중치를 새로운 무작위 값으로 초기화했을 때는 성능이 크게 저하되었다. 이 결과는 서브네트워크의 ’구조’뿐만 아니라 ’운 좋은 초기 가중치’가 성능의 핵심임을 강력하게 시사한다.14 이 연구는 신경망의 과잉-매개변수화(over-parameterization)가 단지 표현력을 높이는 것을 넘어, 효과적인 학습이 가능한 서브네트워크를 찾을 확률을 높이는 일종의 ‘탐색’ 메커니즘으로 작용할 수 있음을 보여주었다. 이는 네트워크 압축, 효율적인 훈련, 그리고 신경망 최적화에 대한 근본적인 이해에 큰 영향을 미쳤다.18</p>
<h3>2.3 주요 발표 동향 및 주목할 만한 연구</h3>
<p>ICLR 2019에서는 최우수 논문 외에도 딥러닝의 여러 분야에서 중요한 진전을 이룬 연구들이 다수 발표되었다.</p>
<ul>
<li>
<p><strong>생성 모델의 발전:</strong> DeepMind의 Andrew Brock 등이 발표한 “Large Scale GAN Training for High Fidelity Natural Image Synthesis” (BigGAN)는 대규모 GAN 훈련 기법을 통해 ImageNet 데이터셋에서 전례 없이 높은 품질의 이미지를 생성하는 데 성공했다. 이는 당시 최고 수준의 Inception Score (IS) 166.3과 Frechet Inception Distance (FID) 9.6을 기록하며, ’규모’의 중요성을 다시 한번 입증했다.20</p>
</li>
<li>
<p><strong>신경망 아키텍처 탐색 (NAS):</strong> “DARTS: Differentiable Architecture Search“는 아키텍처 탐색 과정을 미분 가능하게 만들어 효율성을 극대화하는 방법을 제시하며 NAS 연구의 새로운 방향을 열었다. 이 연구는 가장 많이 인용된 논문 중 하나로 기록되었다.20</p>
</li>
<li>
<p><strong>자연어 이해 벤치마크:</strong> “GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding“는 다양한 자연어 이해(NLU) 작업을 위한 표준화된 평가 플랫폼을 제공하여, 이후 BERT를 비롯한 거대 언어 모델들의 성능을 객관적으로 비교하는 기준이 되었다.20</p>
</li>
<li>
<p><strong>강화학습과 탐험:</strong> 목표 보상 없이도 효율적으로 환경을 탐험하는 능력은 범용 인공지능의 핵심 요소로 간주된다. “Exploration by random network distillation“과 “Episodic Curiosity through Reachability” 등 호기심 기반 학습(curiosity-driven learning) 연구들은 에이전트가 내재적 동기를 통해 스스로 학습 목표를 설정하고 어려운 탐험 문제를 해결할 수 있는 가능성을 보여주었다.4</p>
</li>
<li>
<p><strong>견고성과 정확도의 상충 관계:</strong> “Robustness May Be at Odds with Accuracy“는 적대적 공격에 대한 견고성을 높이는 것이 표준 테스트 정확도를 저해할 수 있다는 중요한 상충 관계(trade-off)를 이론적, 실험적으로 보여주었다. 이는 모델의 신뢰성과 성능을 동시에 고려해야 하는 현실적인 과제를 제기했다.4</p>
</li>
</ul>
<h3>2.4 표 1: ICLR 2019 최우수 논문 비교 분석</h3>
<table><thead><tr><th>특성 (Feature)</th><th>Ordered Neurons</th><th>The Lottery Ticket Hypothesis</th></tr></thead><tbody>
<tr><td><strong>핵심 문제 (Core Problem)</strong></td><td>순차 데이터 내의 잠재적 계층 구조를 RNN에 어떻게 통합하는가?</td><td>왜 과대-매개변수화된(over-parameterized) 네트워크가 더 훈련하기 쉬운가?</td></tr>
<tr><td><strong>주요 방법론 (Methodology)</strong></td><td>ON-LSTM: 뉴런 순서화, 마스터 게이트, <code>cumax()</code> 함수를 통한 귀납적 편향 도입</td><td>반복적 가지치기(Iterative Magnitude Pruning)를 통해 초기화 값을 보존한 서브네트워크(‘당첨된 복권’) 발견</td></tr>
<tr><td><strong>핵심 기여 (Key Contribution)</strong></td><td>언어의 통사적 구조를 명시적 감독 없이 학습하는 새로운 RNN 아키텍처 제시</td><td>신경망 훈련의 성공이 구조뿐만 아니라 ’운 좋은 초기화’에 크게 의존함을 증명</td></tr>
<tr><td><strong>기술적 의의 (Technical Implication)</strong></td><td>표현 학습, 언어 모델링의 구조적 개선</td><td>모델 압축, 효율적 훈련, 최적화 이론에 대한 새로운 관점 제시</td></tr>
</tbody></table>
<h3>2.5 분석</h3>
<p>ICLR 2019의 최우수 논문들은 딥러닝 연구의 두 가지 중요한 흐름을 명확히 보여준다. ’Ordered Neurons’는 언어의 계층적 구조라는 외부 지식을 모델 아키텍처에 ’귀납적 편향’으로 주입하려는 시도이다. 이는 연구자가 도메인에 대한 이해를 바탕으로 더 나은 구조를 명시적으로 ’설계’하려는 접근법을 대표한다. 반면, ’Lottery Ticket Hypothesis’는 이미 존재하는 거대 신경망 모델의 ’내재적 속성’을 파헤쳐 그 작동 원리를 이해하려는 시도이다. 이는 잘 작동하는 거대 모델의 내부를 분석하여 그 성공의 원인을 ’발견’하려는 접근법이라 할 수 있다.</p>
<p>이 두 가지 접근법은 상반되는 듯 보이지만, 실제로는 AI 기술의 성숙을 위해 상호 보완적으로 작용한다. 하나는 더 나은 구조를 설계하기 위한 원칙을 제공하고, 다른 하나는 기존 구조가 왜 잘 작동하는지에 대한 근본적인 이해를 제공한다. 이 두 연구가 동시에 최고 영예를 안았다는 사실은, 2019년 딥러닝 연구가 단순히 성능 경쟁을 넘어 모델의 내부 작동 방식과 근본적인 원리를 탐구하는 방향으로 심화되고 있었음을 시사한다. 이는 ’구조 설계’와 ’내부 원리 분석’이라는 두 가지 주요 탐구 방향이 AI 발전을 이끄는 핵심 동력임을 보여주는 것이다.</p>
<h2>3.  ICRA 2019: 물리적 세계와의 상호작용을 위한 지능</h2>
<h3>3.1 개요</h3>
<p>2019년 5월 20일부터 24일까지 캐나다 몬트리올에서 개최된 IEEE International Conference on Robotics and Automation (ICRA)는 AI 기술이 로봇의 인지, 계획, 제어 능력을 어떻게 혁신하고 있는지를 보여주는 장이었다.23 특히, 최우수 논문들은 인간-로봇 상호작용, 미세 조작, 다중 모드 감각 융합 등 로보틱스의 오랜 난제들을 해결하기 위한 정교한 학습 및 제어 기법들을 제시하며 큰 주목을 받았다.</p>
<h3>3.2 부문별 최우수 논문 심층 분석</h3>
<h4>3.2.1  인지 로보틱스 최우수 논문: “Efficient Symbolic Reactive Synthesis for Finite-Horizon Tasks”</h4>
<p>인간과 로봇이 협업하는 환경에서 가장 큰 난제 중 하나는 예측 불가능한 인간의 행동에 대응하여 로봇이 주어진 과업(예: 조립)을 ‘반드시’ 완수하도록 보장하는 전략을 생성하는 것이다.25 이 연구는 이 문제를 해결하기 위해 형식 검증(formal methods) 분야의 ‘반응 종합(reactive synthesis)’ 기법을 로보틱스에 적용했다.</p>
<p>핵심 방법론은 유한 시간 내에 완수되어야 하는 과업을 유한 경로에 대한 선형 시제 논리(Linear Temporal Logic on finite traces, LTLf)로 명세화하고, 로봇과 인간의 상호작용을 2인 게임으로 모델링하는 것이다.26 이 게임에서 로봇은 인간의 모든 가능한 행동에 대해 과업을 완수할 수 있는 ’필승 전략(winning strategy)’을 찾는 것을 목표로 한다.</p>
<p>이 논문의 핵심적인 기술적 기여는 기존의 명시적 상태(explicit state) 접근법의 한계를 극복한 것이다. 명시적 접근법은 가능한 모든 상태를 하나씩 열거하기 때문에 상태 공간 폭발 문제에 직면한다. 대신, 이 연구는 이진 결정 다이어그램(Binary Decision Diagrams, BDD)을 사용하여 도메인과 명세를 기호적(symbolic)으로 표현하고 이를 조합하는 ’구성적 접근법(compositional approach)’을 제안했다. BDD는 부울 함수를 압축적으로 표현하는 자료 구조로, 이를 통해 상태 공간을 효율적으로 다룰 수 있다. 그 결과, 이전 접근법 대비 수십 배의 속도 향상을 달성했다.25</p>
<p>이 연구는 로봇이 예측 불가능한 환경 변화에도 불구하고 과업 완수를 수학적으로 보장할 수 있는 전략을 사전에 계산함으로써, 안전성과 신뢰성이 극도로 중요한 인간-로봇 협업 분야에 이론적으로 견고한 토대를 제공했다는 점에서 큰 의의를 가진다.25</p>
<h4>3.2.2  자동화 최우수 논문: “Robotic Orientation Control of Deformable Cells”</h4>
<p>체외 수정(IVF), 세포 복제 등 생의학 분야에서 필수적인 생물학적 세포의 방향 제어는 자동화하기 매우 어려운 고도의 정밀 조작 작업이다. 세포는 매우 변형되기 쉽고 손상에 극도로 취약하기 때문이다.30 이 연구는 이러한 난제를 해결하기 위해 모델 기반의 로봇 자동화 시스템을 개발했다.</p>
<p>연구팀은 먼저 마이크로피펫으로 세포를 회전시키는 데 필요한 최소한의 힘을 결정하기 위한 ’힘 모델’을 수립했다. 그리고 이 힘 정보를 ’접촉 역학 모델’을 통해 마이크로피펫의 압입 깊이로 변환하여, 세포에 가해지는 변형을 최소화하는 최적의 조작 경로를 계획했다.31</p>
<p>시스템의 정밀도를 높이기 위해 여러 기술이 통합되었다. 먼저, 딥러닝 기반의 객체 탐지 모델을 사용하여 세포의 방향을 결정하는 기준점인 극체(polar body)를 97.6%의 높은 정확도로 탐지했다. 또한, 세포마다 다른 기계적 특성(탄성 등)의 변화를 실시간으로 보상하는 보상 제어기(compensation controller)를 설계했다. 실험 결과, 이 시스템은 최대 세포 변형을 2.7µm 이내로 제어하면서 0.7도의 높은 정밀도로 세포 방향 제어에 성공했다.30</p>
<p>이 연구는 전적으로 인간의 경험과 감각에 의존하던 섬세한 세포 조작을 정량적 모델과 정밀한 제어에 기반한 로봇 자동화로 대체했다는 점에서 큰 의미가 있다. 이는 작업의 일관성과 성공률을 획기적으로 높이고, 잠재적인 세포 손상 위험을 크게 줄여, 미세 로봇 조작 기술이 생명 공학 및 의료 분야에 미칠 막대한 잠재력을 명확히 보여준 사례다.34</p>
<h4>3.2.3  컨퍼런스 종합 최우수 논문: “Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks”</h4>
<p>페그 삽입(peg insertion)과 같이 물체와 환경 간의 복잡한 접촉이 발생하는 조작(contact-rich manipulation)은 시각과 촉각 정보의 통합이 필수적이다. 시각은 물체의 위치와 자세에 대한 정보를 제공하고, 촉각은 접촉 시 발생하는 힘과 토크에 대한 직접적인 피드백을 제공한다. 그러나 이질적인 두 감각을 효과적으로 융합하고, 이를 제어 정책 학습에 활용하는 것은 강화학습의 샘플 비효율성 문제로 인해 실제 로봇에 적용하기 매우 어려웠다.35</p>
<p>이 연구는 이 문제를 해결하기 위해 ’자기 지도 학습(self-supervision)’을 활용한 혁신적인 2단계 접근법을 제안했다.30 핵심 아이디어는 고차원의 시각(RGB 이미지) 및 촉각(힘/토크) 데이터를 저차원의 압축된 다중 모드 표현(multimodal representation)으로 먼저 학습하고, 이 표현을 사용하여 제어 정책을 효율적으로 학습하는 것이다.</p>
<p>1단계인 표현 학습 단계에서는, 로봇 스스로 레이블을 생성할 수 있는 세 가지 예측 과제를 정의한다: (1) 로봇의 다음 행동으로 인해 발생할 이미지의 변화(광학 흐름) 예측, (2) 다음 제어 주기에서 물체와 환경 간의 접촉 발생 여부 예측, (3) 시각과 촉각 데이터 스트림이 시간적으로 동기화되었는지 여부 예측. 로봇은 이러한 예측 과제를 수행하는 과정에서 별도의 인간 레이블 없이도 시각과 촉각 정보를 통합하고 행동과 관련된 유용한 특징을 추출하는 방법을 스스로 학습한다.</p>
<p>2단계인 정책 학습 단계에서는, 이렇게 사전 학습된 저차원 표현을 상태(state) 정보로 입력받아 강화학습 알고리즘(TRPO)으로 제어 정책을 학습한다. 고차원의 원시 센서 데이터 대신 잘 정제된 저차원 표현을 사용하기 때문에, 정책 학습에 필요한 데이터 양이 획기적으로 줄어든다. 이 접근법은 표현 학습과 제어 학습을 분리하고, 레이블 없는 데이터로부터 유용한 표현을 학습하는 자기 지도 방식을 통해, 실제 로봇 환경에서 강화학습의 샘플 비효율성 문제를 극복하는 효과적인 프레임워크를 제시했다. 이는 데이터 기반 로봇 학습 연구의 중요한 이정표로 평가받는다.35</p>
<h3>3.3 표 2: ICRA 2019 주요 부문별 최우수 논문 요약</h3>
<table><thead><tr><th>부문 (Category)</th><th>논문 제목 (Paper Title)</th><th>핵심 문제 (Core Problem)</th><th>접근법 (Approach)</th><th>주요 기여 (Key Contribution)</th></tr></thead><tbody>
<tr><td><strong>인지 로보틱스</strong></td><td>Efficient Symbolic Reactive Synthesis…</td><td>불확실한 인간 행동 하에서의 로봇 과업 완수 보장</td><td>형식 검증, 반응 종합, LTLf, BDD</td><td>신뢰성 높은 인간-로봇 협업을 위한 필승 전략 자동 생성</td></tr>
<tr><td><strong>자동화</strong></td><td>Robotic Orientation Control of Deformable Cells</td><td>손상에 취약한 생물학적 세포의 정밀 방향 제어</td><td>힘/접촉 역학 모델링, 경로 계획, 보상 제어</td><td>미세 변형 객체 조작의 자동화 및 정밀도 향상</td></tr>
<tr><td><strong>컨퍼런스 종합</strong></td><td>Making Sense of Vision and Touch…</td><td>접촉-다변 환경에서의 다중 모드 감각 융합 및 제어</td><td>자기 지도 표현 학습 + 강화학습</td><td>실제 로봇에서의 강화학습 샘플 효율성 문제 해결</td></tr>
</tbody></table>
<h3>3.4 분석</h3>
<p>ICRA 2019의 최우수 논문들은 로봇 지능을 구현하는 데 있어 두 가지 대조적인 철학이 공존하며 발전하고 있음을 보여준다. “Efficient Symbolic Reactive Synthesis“는 형식 검증이라는 수학적 도구를 통해 로봇의 행동 결과를 논리적으로 ‘보장된(guaranteed)’ 상태로 만들려는 시도이다. 이는 시스템의 행동을 사전에 완벽하게 예측하고 제어하려는, 엄격한 논리적 추론 기반의 접근법을 대표한다. 반면, “Making Sense of Vision and Touch“는 대규모 데이터와 자기 지도 ’학습(learning)’을 통해 복잡하고 모델링하기 어려운 물리적 상호작용 기술을 로봇이 스스로 습득하게 하는 접근법이다. 이는 데이터로부터 패턴을 발견하고 행동을 최적화하는 확률론적, 경험적 해결책을 추구한다.</p>
<p>“Robotic Orientation Control of Deformable Cells“는 이 두 접근법의 중간 지점에 위치한다고 볼 수 있다. 물리 법칙에 기반한 정교한 ’모델링’을 통해 제어의 기반을 마련하되, 딥러닝을 통해 시각적 ’인식’을 수행하고 제어기를 통해 불확실성을 ’보상’하는 하이브리드 방식을 채택했다.</p>
<p>이러한 양상은 2019년 로보틱스 분야가 단일 패러다임에 얽매이지 않고, 문제의 특성에 따라 ’엄격한 보장’을 추구하는 접근법과 ’데이터 기반 학습’을 통한 적응적 해결책을 모두 발전시키는 다각적인 성숙 단계에 진입했음을 의미한다. 즉, 로보틱스는 수학적 확실성과 경험적 학습이라는 스펙트럼의 양 끝단에서 모두 중요한 진전을 이루며 물리 세계의 복잡성에 도전하고 있었다.</p>
<h2>4.  산업계 연구소의 혁신: 규모, 일반화, 그리고 계획</h2>
<p>2019년 5월, 학계의 이론적 탐구와 병행하여 OpenAI와 DeepMind는 AI의 스케일과 범용성을 한 단계 끌어올리는 기념비적인 연구들을 발표했다. 이들의 연구는 거대 모델의 잠재력과 위험성, 그리고 환경에 대한 사전 지식 없이도 계획을 수립하는 범용 알고리즘의 가능성을 제시하며 AI 연구의 새로운 방향을 예고했다.</p>
<h3>4.1  OpenAI: GPT-2와 거대 언어 모델의 서막</h3>
<p>GPT-2는 15억 개의 파라미터를 가진 거대 트랜스포머(Transformer) 기반 언어 모델로, 40GB에 달하는 방대한 인터넷 텍스트(WebText) 데이터셋을 사용하여 훈련되었다.41 훈련 목표는 매우 단순했다: ’이전 단어들이 주어졌을 때 다음 단어를 예측’하는 비지도 학습(unsupervised learning) 방식이다.41</p>
<p>GPT-2의 핵심적인 기여는 별도의 과제별 지도 학습 없이도 번역, 질의응답, 요약 등 다양한 과제를 추가적인 훈련 없이 ’제로샷(zero-shot)’으로 수행할 수 있음을 보여준 것이다.41 이는 충분히 크고 다양한 데이터셋으로 언어 모델을 훈련시키면, 모델이 데이터에 내재된 여러 과업을 수행하는 능력을 자연스럽게 학습하게 된다는 ‘비지도 다중과제 학습(Unsupervised Multitask Learners)’ 가설을 강력하게 입증한 결과였다.41</p>
<p>OpenAI는 2019년 2월 GPT-2를 처음 발표하며 악용 가능성에 대한 우려로 전체 모델 공개를 보류하는 이례적인 결정을 내렸다.42 이후 사회적 논의를 거쳐 2019년 5월, 3억 4500만 파라미터 버전의 중간 크기 모델을 공개하는 ‘단계적 공개(staged release)’ 전략을 채택했다.42 이는 AI 기술의 사회적 영향을 고려한 책임감 있는 연구 문화를 선도하는 중요한 사례가 되었으며, AI 안전성과 윤리에 대한 논의를 본격화하는 계기가 되었다.44</p>
<p>GPT-2가 생성하는 텍스트의 놀라운 일관성과 설득력은 학계와 대중에게 큰 충격을 주었다. 가짜 뉴스 생성, 스팸, 온라인 사칭 등 악의적 사용에 대한 광범위한 논쟁을 촉발시키는 동시에 42, AI 작문 보조, 고도화된 대화형 에이전트 등 긍정적 활용 가능성도 무한히 제시했다.42</p>
<h3>4.2  DeepMind: MuZero를 통한 모델 기반 강화학습의 재정의</h3>
<p>AlphaZero와 같은 기존의 강력한 강화학습 에이전트는 바둑, 체스처럼 ‘규칙이 알려진’ 완벽한 시뮬레이터가 있는 환경에 의존한다는 명확한 한계가 있었다. 실제 세계와 같이 규칙을 모르고 시각적으로 복잡한 환경에서 어떻게 효과적으로 ’계획(planning)’할 수 있을지는 강화학습의 오랜 난제였다.45</p>
<p>MuZero는 이 문제에 대한 혁신적인 해법을 제시했다. 핵심 아이디어는 환경의 모든 세부사항(예: 바둑판의 모든 돌, 아타리 게임의 모든 픽셀)을 완벽하게 모델링하는 대신, 계획에 가장 직접적으로 관련된 세 가지 핵심 요소—<strong>가치(Value, 현재 상태가 얼마나 좋은가?)</strong>, <strong>정책(Policy, 어떤 행동이 최선인가?)</strong>, <strong>보상(Reward, 직전의 행동이 얼마나 좋았는가?)</strong>—만을 예측하는 내부 모델을 학습하는 것이다.45</p>
<p>MuZero 알고리즘은 세 개의 핵심 신경망 함수로 구성된다. 첫째, **표현 함수(Representation function, h)**는 환경의 관측(observation)을 추상적인 초기 은닉 상태(hidden state) <span class="math math-inline">s^0</span>로 변환한다. 둘째, **동역학 함수(Dynamics function, g)**는 현재 은닉 상태 <span class="math math-inline">s^{k-1}</span>와 가상의 행동 <span class="math math-inline">a^k</span>를 받아 다음 은닉 상태 <span class="math math-inline">s^k</span>와 보상 <span class="math math-inline">r^k</span>를 예측한다. 셋째, **예측 함수(Prediction function, f)**는 은닉 상태 <span class="math math-inline">s^k</span>로부터 정책 <span class="math math-inline">p^k</span>와 가치 <span class="math math-inline">v^k</span>를 예측한다. 이 학습된 모델은 몬테카를로 트리 탐색(MCTS) 내에서 미래를 시뮬레이션하고 최적의 행동을 찾는 데 사용된다.46</p>
<p>MuZero는 게임 규칙에 대한 어떠한 사전 지식 없이도 바둑, 체스, 쇼기에서 AlphaZero와 대등한 초인적인 성능을 달성했으며, 동시에 시각적으로 복잡한 57개의 아타리(Atari) 게임 스위트에서도 기존의 모든 강화학습 알고리즘을 능가하는 최고 성능을 기록했다.45 이는 환경의 완벽한 모델 없이도 강력한 계획이 가능함을 증명한 것으로, 규칙이 명확하지 않은 로보틱스나 산업 시스템과 같은 불확실하고 복잡한 실제 문제에 강화학습을 적용할 수 있는 길을 연 중요한 진전이다.45</p>
<h3>4.3 분석</h3>
<p>GPT-2와 MuZero는 ’모델’을 활용하는 방식에서 흥미로운 철학적 대조를 보인다. GPT-2는 방대한 텍스트 데이터를 학습함으로써 ‘언어’ 자체가 세계에 대한 암묵적인 모델 역할을 하도록 한다. 이는 세상의 모든 지식과 관계가 언어 구조 안에 인코딩되어 있으며, 거대 언어 모델이 이를 학습할 수 있다는 믿음에 기반한다. 즉, 세상에 대한 모든 정보를 압축한 거대한 암묵적 모델을 만드는 접근법이다.</p>
<p>반면, MuZero는 특정 과업(게임)을 해결하기 위해 필요한 ’핵심 동역학(가치, 정책, 보상)’만을 명시적으로 모델링한다. 이는 환경의 모든 복잡성을 이해하려 하기보다, 주어진 목적을 달성하는 데 필요한 최소한의 정보만을 추출하여 효율적인 동적 모델을 만드는 접근법이다.</p>
<p>이러한 차이는 범용성의 추구(GPT-2)와 특정 과업에 대한 효율적 계획(MuZero)이라는, 일반 지능에 접근하는 두 가지 다른 경로를 보여준다. 2019년 산업계 연구는 이처럼 ’스케일을 통한 범용성’과 ’효율적 계획을 위한 추상화’라는 두 가지 상이한 철학을 통해 AI의 지평을 동시에 넓히고 있었다.</p>
<h2>5.  2019년 5월 AI 및 로봇 연구 동향 종합 및 전망</h2>
<h3>5.1 종합 분석: 4대 핵심 동향</h3>
<p>2019년 5월에 발표된 주요 연구들을 종합하면, 당시 AI 및 로봇 기술을 관통하는 네 가지 핵심적인 동향을 파악할 수 있다.</p>
<ol>
<li>
<p><strong>스케일 vs. 효율성의 이중주 (The Duet of Scale vs. Efficiency):</strong> OpenAI의 GPT-2는 파라미터 스케일을 통해 전례 없는 제로샷 일반화 성능을 보여주며 ’클수록 좋다’는 패러다임을 강화했다. 동시에 ICLR의 ’복권 가설’은 거대 네트워크 안에 내재된 고효율의 희소 서브네트워크의 존재를 증명하며, 모델의 근본적인 효율성을 탐구하는 연구의 중요성을 부각시켰다. 이 두 연구는 AI 연구가 ’규모의 확장’과 ’본질의 탐구’라는 두 축을 따라 동시에 전진하고 있음을 상징적으로 보여준다.</p>
</li>
<li>
<p><strong>자기 지도 학습의 부상 (The Rise of Self-Supervised Learning):</strong> ICRA의 “Making Sense of Vision and Touch“는 로보틱스 분야에서, ICLR의 “Ordered Neurons“와 OpenAI의 GPT-2는 자연어 처리 분야에서 각각 자기 지도/비지도 학습의 위력을 입증했다. 이는 막대한 비용이 드는 수동 레이블링 데이터셋에 대한 의존도를 줄이고, 데이터 자체의 내재적 구조와 신호를 감독(supervision)으로 활용하는 패러다임이 AI 전반의 주류로 자리 잡고 있음을 시사한다.</p>
</li>
<li>
<p><strong>계획(Planning) 능력의 재조명:</strong> DeepMind의 MuZero는 환경 모델을 학습하여 계획하는 능력이 강화학습의 핵심적인 돌파구가 될 수 있음을 보여주었다. ICRA의 ‘Reactive Synthesis’ 연구 또한 로봇이 미래를 예측하고 보장된 계획을 수립하는 능력의 중요성을 강조했다. 이는 단순히 자극에 반응하는(reactive) 시스템을 넘어, 미래를 예측하고 심의(deliberate)하는 능력을 갖춘 고도화된 AI로의 발전을 의미한다.</p>
</li>
<li>
<p><strong>책임감 있는 AI (Responsible AI) 담론의 본격화:</strong> OpenAI의 GPT-2 단계적 공개 결정은 AI 기술의 잠재적 위험성을 연구 커뮤니티가 스스로 인정하고, 이에 대한 사회적 논의와 기술적 대응책 마련을 촉구한 분기점이었다. 이는 AI 연구가 순수한 기술 개발을 넘어 사회적, 윤리적 책임을 동반하는 단계로 진입했음을 알리는 신호탄이었다.42</p>
</li>
</ol>
<h3>5.2 미래 전망 및 함의</h3>
<p>2019년 5월의 연구 성과들은 향후 수년간 AI 연구의 방향을 결정짓는 중요한 씨앗이 되었다. GPT-2는 이후 폭발적으로 이어진 초거대 언어 모델(LLM) 경쟁의 서막이었으며, MuZero는 실제 세계의 복잡한 문제 해결을 위한 모델 기반 강화학습 연구를 촉진했다. ’복권 가설’은 지속적으로 신경망의 희소성과 훈련 가능성에 대한 후속 연구를 낳았고, 로보틱스 분야의 자기 지도 학습은 데이터 기반 로봇 기술의 발전을 가속화하는 핵심 동력이 되었다.</p>
<p>결론적으로, 이 시기는 AI가 이론적 성숙을 바탕으로 현실 세계의 복잡성과 불확실성에 본격적으로 도전하기 시작한 ’변곡점’으로 기록될 것이다. 규모의 힘과 효율성의 미학, 학습의 유연성과 계획의 견고함, 그리고 기술적 진보와 사회적 책임 사이의 균형을 모색하려는 노력이 이때를 기점으로 AI 연구의 핵심 화두로 자리 잡았다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>McKinsey technology trends outlook 2025, https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-top-trends-in-tech</li>
<li>5 Massive Robotics Trends | Bernard Marr, https://bernardmarr.com/5-massive-robotics-trends-in-2019/</li>
<li>Artificial Intelligence (AI) Robotics Market Report 2019-2029 - PR Newswire, https://www.prnewswire.com/news-releases/artificial-intelligence-ai-robotics-market-report-2019-2029-300798829.html</li>
<li>7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019 - researchr publication, https://researchr.org/publication/iclr-2019</li>
<li>2019 Dates and Deadlines - ICLR 2026, https://iclr.cc/Conferences/2019/Dates</li>
<li>International Conference on Learning Representations (ICLR), 2019 - ServiceNow, https://www.servicenow.com/research/event/2019-iclr.html</li>
<li>Brief Report: Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks - Microsoft Research, https://www.microsoft.com/en-us/research/publication/brief-report-ordered-neurons-integrating-tree-structures-into-recurrent-neural-networks/</li>
<li>Ordered Neurons: Integrating Tree Structures Into Recurrent Neural Networks, https://cs.uwaterloo.ca/~mli/Niknamian.pdf</li>
<li>ORDERED NEURONS: INTEGRATING TREE … - OpenReview, https://openreview.net/pdf?id=B1l6qiR5F7</li>
<li>Best Paper Award - ICLR 2026, https://iclr.cc/Conferences/2019/Awards</li>
<li>Decoding the Best Papers from ICLR 2019 - Neural Networks are Here to Rule, https://www.analyticsvidhya.com/blog/2019/05/best-papers-iclr-2019/</li>
<li>Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks - OpenReview, https://openreview.net/forum?id=B1l6qiR5F7</li>
<li>Yikang Shen: Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks (ICLR2019) - YouTube, https://www.youtube.com/watch?v=7REBftHDQOw</li>
<li>The lottery ticket hypothesis: Finding sparse, trainable neural networks, https://arxiv.org/abs/1803.03635</li>
<li>The lottery ticket hypothesis: Finding sparse, trainable neural networks, http://www.theparticle.com/cs/bc/dsci/1803.03635.pdf</li>
<li>The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks | OpenReview, https://openreview.net/forum?id=rJl-b3RcF7</li>
<li>[PDF] The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks | Semantic Scholar, https://www.semanticscholar.org/paper/The-Lottery-Ticket-Hypothesis%3A-Finding-Sparse%2C-Frankle-Carbin/21937ecd9d66567184b83eca3d3e09eb4e6fbd60</li>
<li>A Survey of Lottery Ticket Hypothesis - arXiv, https://arxiv.org/html/2403.04861v1</li>
<li>The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks. - DBLP, https://dblp.org/rec/conf/iclr/FrankleC19</li>
<li>ICLR 2019 most cited papers - Ludovic Arnold, https://ludovicarnold.com/iclr-2019-most-cited-papers/</li>
<li>ICLR 2019 Orals, https://iclr.cc/virtual/2019/events/oral</li>
<li>ICLR 2019: Our Favorite Machine Learning Talks and Papers - Two Sigma, https://www.twosigma.com/articles/iclr-2019-our-favorite-machine-learning-talks-and-papers/</li>
<li>ICRA 2019 : IEEE International Conference on Robotics and Automation - Accepted Papers, Deadline, Impact Factor &amp; Score 2025 | Research.com, https://research.com/conference/icra-2019</li>
<li>ICRA — 2019 International Conference on Robotics and Automation | Unexmin, https://www.unexmin.eu/event/icra-2019-international-conference-on-robotics-and-automation/</li>
<li>Kavraki Group wins best paper award at ICRA 2019 | Computer Science - Rice University, https://csweb.rice.edu/news/kavraki-group-wins-best-paper-award-icra-2019</li>
<li>Efficient Symbolic Reactive Synthesis for Finite … - Kavraki Lab, https://www.kavrakilab.org/publications/he2019efficient-symbolic-reactive-synthesis-for-finite-horizon-tasks.pdf</li>
<li>Efficient Symbolic Reactive Synthesis for Finite-Horizon Tasks | Request PDF, https://www.researchgate.net/publication/335143709_Efficient_Symbolic_Reactive_Synthesis_for_Finite-Horizon_Tasks</li>
<li>Hybrid Compositional Reasoning for Reactive Synthesis from Finite-Horizon Specifications - Rice University, https://www.cs.rice.edu/~sb55/Papers/AAAI20.pdf</li>
<li>[PDF] Efficient Symbolic Approaches for Quantitative Reactive Synthesis with Finite Tasks, https://www.semanticscholar.org/paper/Efficient-Symbolic-Approaches-for-Quantitative-with-Muvvala-Lahijanian/321e0c66f933abd429858e0fc1a5fb361de26bc3</li>
<li>Two best papers, four award finalists at ICRA 2019 - University of Toronto Robotics Institute, https://robotics.utoronto.ca/news/two-best-papers-four-award-finalists-at-icra-2019/</li>
<li>Robotic Orientation Control of Deformable Cells - Infovaya, https://events.infovaya.com/presentation?id=39037</li>
<li>Robotic Manipulation of Deformable Cells for Orientation Control - ResearchGate, https://www.researchgate.net/publication/336858851_Robotic_Manipulation_of_Deformable_Cells_for_Orientation_Control</li>
<li>Robotics_Institute_Yu_Sun_ICR, https://robotics.utoronto.ca/news/two-best-papers-four-award-finalists-at-icra-2019/robotics_institute_yu_sun_icra2019_award/</li>
<li>Modeling of Deformable Objects for Robotic Manipulation: A Tutorial and Review - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC7805872/</li>
<li>(PDF) Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks - ResearchGate, https://www.researchgate.net/publication/334783166_Making_Sense_of_Vision_and_Touch_Learning_Multimodal_Representations_for_Contact-Rich_Tasks</li>
<li>Making Sense of Vision and Touch: Self-Supervised Learning of …, https://arxiv.org/abs/1810.10191</li>
<li>Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks, https://rpl.cs.utexas.edu/publications/papers/lee-icra19-making.pdf</li>
<li>Robotics_Institute_Animesh_Gar, https://robotics.utoronto.ca/news/two-best-papers-four-award-finalists-at-icra-2019/robotics_institute_animesh_garg_icra2019_award/</li>
<li>Making sense of vision and touch: #ICRA2019 best paper award video and interview, https://robohub.org/making-sense-of-vision-and-touch-icra2019-best-paper-award-video-and-interview/</li>
<li>Paper Review: Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks - Isaac Kargar, https://kargarisaac.medium.com/making-sense-of-vision-and-touch-self-supervised-learning-of-multimodal-representations-for-eea5f6d74be7</li>
<li>Language Models are Unsupervised Multitask Learners | OpenAI, https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</li>
<li>Better language models and their implications - OpenAI, https://openai.com/index/better-language-models/</li>
<li>GPT-2 - Wikipedia, https://en.wikipedia.org/wiki/GPT-2</li>
<li>openai/gpt-2: Code for the paper “Language Models are Unsupervised Multitask Learners”, https://github.com/openai/gpt-2</li>
<li>MuZero: Mastering Go, chess, shogi and Atari without rules - Google DeepMind, https://deepmind.google/discover/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules/</li>
<li>DeepMind’s MuZero is One of the Most Important Deep Learning Systems Ever Created, https://www.kdnuggets.com/2021/01/deepmind-muzero-important-deep-learning-systems.html</li>
<li>[1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model, https://arxiv.org/abs/1911.08265</li>
<li>Mastering Atari, Go, Chess and Shogi by Planning with a … - arXiv, https://arxiv.org/pdf/1911.08265v1.pdf?ref=bestofml</li>
<li>Muzero Poster Neurips 2019 | PDF | Applied Mathematics - Scribd, https://www.scribd.com/document/666283739/muzero-poster-neurips-2019</li>
<li>Paper Review 2024 - MuZero: Mastering Go, chess, shogi and Atari without rules (01/50), https://medium.com/@phchen715/paper-review-2024-muzero-mastering-go-chess-shogi-and-atari-without-rules-01-50-2720b42b692e</li>
<li>Google DeepMind - Wikipedia, https://en.wikipedia.org/wiki/Google_DeepMind</li>
<li>AI Programming (IT-3105) Spring 2025 Main Project: A MuZero Knockoff, https://www.idi.ntnu.no/emner/it3105/assignments/muzero-knockoff.pdf</li>
<li>Results 2 Data Generation Reanalyze 3 Learning Ablations 1 Planning with a Learned Model MCTS in Single Player Games Motivation - Googleapis.com, https://storage.googleapis.com/deepmind-media/research/muzero_poster_neurips_2019.pdf</li>
<li>MuZero’s first step from research into the real world - Google DeepMind, https://deepmind.google/discover/blog/muzeros-first-step-from-research-into-the-real-world/</li>
<li>Demystifying MuZero Planning: Interpreting the Learned Model - arXiv, https://arxiv.org/html/2411.04580v2</li>
<li>MuZero - Wikipedia, https://en.wikipedia.org/wiki/MuZero</li>
<li>Google AI Impact Challenge names 2019 grantees, https://blog.google/outreach-initiatives/google-org/ai-impact-challenge-grantees/</li>
<li>AI and compute | OpenAI, https://openai.com/index/ai-and-compute/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>