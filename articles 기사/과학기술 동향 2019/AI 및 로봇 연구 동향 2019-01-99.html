<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2019년 1월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2019년 1월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2019년 AI 및 로봇 연구 동향</a> / <span>2019년 1월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2019년 1월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2019년 AI 연구의 서막</h2>
<p>2019년 1월은 인공지능 연구 분야에서 중요한 변곡점을 기록한 시기이다. 딥러닝의 폭발적인 성장세가 지속되는 가운데, 학계와 산업계는 단순히 더 크고 깊은 모델을 구축하는 경쟁을 넘어 그 근본적인 작동 원리와 내재적 한계에 대한 깊이 있는 성찰을 시작하였다. 이 시기의 연구들은 <strong>효율성(Efficiency)</strong>, <strong>표현력(Representation Power)</strong>, 그리고 **실세계 적용 가능성(Real-world Applicability)**이라는 세 가지 핵심 축을 중심으로 심화되는 양상을 보였다.1</p>
<p>주요 학회를 살펴보면, AAAI 2019에서는 그래프 신경망(GNN), 추천 시스템, 웹 AI와 같이 고도로 구조화된 데이터를 다루는 응용 연구가 활발히 논의되었다.3 이는 AI 기술이 점차 복잡한 실제 문제에 적용되고 있음을 방증한다. 한편, ICLR 2019에서는 신경망의 과잉 파라미터화(Overparameterization)에 대한 근본적인 질문을 던진 ’복권 가설(The Lottery Ticket Hypothesis)’과 같은 기념비적인 연구가 발표되어 학계에 큰 파장을 일으켰다.5 이러한 흐름은 AI 연구의 관심사가 성능 향상을 넘어, 모델의 본질을 이해하고 최적화하려는 방향으로 성숙하고 다각화되고 있음을 명확히 보여준다.</p>
<p>이러한 학술적 논의의 산업적 맥락을 파악하기 위해 당시 한국 로봇 산업의 현황을 살펴볼 필요가 있다. 2019년 초 발표된 통계에 따르면, 국내 로봇 산업에서 ‘로봇부품 및 소프트웨어’ 분야가 전체 사업체 수의 31.6% (1360개)를 차지하며 가장 큰 비중을 보였다.7 또한, 로봇 관련 연구소를 보유 및 운영하는 사업체는 1017개사(23.6%)에 달했으며, 중소기업의 주업종 역시 ’로봇부품 및 소프트웨어’가 32.2%로 가장 많았다.7 이는 하드웨어뿐만 아니라 로봇의 지능을 결정하는 소프트웨어와 핵심 부품 기술의 중요성이 산업 현장에서 깊이 인식되고 있었음을 시사한다. 이러한 산업적 요구는 AI 기반 로봇 제어, 지능형 소프트웨어, 그리고 효율적인 알고리즘 개발과 같은 학술 연구 방향에 중요한 동기를 부여하는 배경으로 작용하였다.</p>
<p>본 보고서는 이러한 시대적 배경 속에서 2019년 1월에 발표된 주요 연구 성과들을 심층적으로 분석하고자 한다. 보고서는 크게 세 부분으로 구성된다. 제1장에서는 신경망의 작동 원리에 대한 새로운 패러다임을 제시한 효율성 연구를, 제2장에서는 데이터의 복잡한 관계와 문맥을 포착하려는 표현 학습 연구를, 그리고 제3장에서는 시뮬레이션과 현실의 간극을 메우며 로봇 공학의 새로운 지평을 연 연구들을 집중적으로 조명할 것이다.</p>
<table><thead><tr><th><strong>분야</strong></th><th><strong>주요 연구 (논문명)</strong></th><th><strong>핵심 개념/방법론</strong></th><th><strong>주요 학회/출처</strong></th><th><strong>의의 및 영향</strong></th></tr></thead><tbody>
<tr><td><strong>신경망 효율성</strong></td><td>The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks</td><td>당첨 티켓(Winning Ticket), 반복적 크기 프루닝(IMP)</td><td>ICLR 2019</td><td>신경망 훈련 및 초기화에 대한 패러다임 전환 제시</td></tr>
<tr><td></td><td>Rethinking the value of network pruning</td><td>프루닝된 아키텍처, 무작위 초기화 학습</td><td>ICLR 2019</td><td>프루닝을 ‘아키텍처 탐색’ 관점으로 재해석</td></tr>
<tr><td><strong>표현 학습</strong></td><td>Session-Based Recommendation with Graph Neural Networks</td><td>그래프 신경망(GNN), 세션 그래프, 어텐션 네트워크</td><td>AAAI 2019</td><td>추천 시스템에 GNN을 도입하여 관계형 데이터 모델링의 새 장을 염</td></tr>
<tr><td></td><td>Context-Aware Self-Attention Networks</td><td>문맥 벡터(Context Vector), 게이팅 메커니즘</td><td>AAAI 2019</td><td>셀프 어텐션의 문맥 이해 능력을 강화하여 NLP 모델의 성능 향상</td></tr>
<tr><td><strong>로봇 공학</strong></td><td>Learning Dexterous In-Hand Manipulation</td><td>심층 강화학습(PPO), 도메인 무작위화(Domain Randomization)</td><td>arXiv</td><td>Sim-to-Real 문제 해결의 돌파구를 마련하고 로봇 손재주 학습의 새 기준 제시</td></tr>
<tr><td></td><td>Robust Recovery Controller for a Quadrupedal Robot using DRL</td><td>심층 강화학습</td><td>arXiv</td><td>동적 환경에서의 로봇 강인성(robustness) 확보</td></tr>
<tr><td></td><td>Autonomous visual inspection of large-scale infrastructures</td><td>기하학 기반 경로 계획, UWB/IMU 융합</td><td>arXiv</td><td>대규모 인프라의 자율 로봇 점검 실용화</td></tr>
</tbody></table>
<h2>2.  신경망의 본질을 향한 탐구: 효율성과 재해석</h2>
<p>2019년 초 딥러닝 커뮤니티의 가장 큰 화두 중 하나는 ‘신경망의 과잉 파라미터화(Overparameterization)’ 문제였다. 왜 수백만, 수억 개의 파라미터를 가진 거대한 네트워크가 더 적은 파라미터를 가진 네트워크보다 쉽게 학습되고 더 나은 성능을 내는가에 대한 근본적인 질문이 제기되었다. 이 장에서는 이 문제에 대해 상징적인 두 연구를 심층 분석한다. 이들은 단순히 모델을 압축하는 기술을 넘어, 신경망이 어떻게 학습되고 작동하는지에 대한 기존의 통념에 도전하며 새로운 패러다임의 가능성을 제시했다는 점에서 그 의의가 매우 크다.</p>
<h3>2.1  복권 가설: 거대 신경망에 내재된 행운의 서브네트워크</h3>
<p>Jonathan Frankle과 Michael Carbin이 ICLR 2019 최우수 논문상을 수상한 “The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks“는 딥러닝 커뮤니티에 신선한 충격을 안겨주었다.5 이 연구는 신경망 프루닝(pruning)에 대한 기존의 관점을 완전히 뒤집는 혁신적인 가설을 제시했다.</p>
<h4>2.1.1 핵심 가설 소개</h4>
<p>’복권 가설’은 다음과 같이 정의된다: 무작위로 초기화된 거대한 밀집 신경망(dense neural network) 안에는, 훈련 후 남겨진 가중치가 아닌 <strong>초기 가중치 값 그대로</strong> 독립적으로 훈련했을 때, 전체 네트워크와 비슷하거나 더 나은 성능에 도달할 수 있는 희소한 부분망(sparse subnetwork)이 존재한다.6 연구진은 이러한 특별한 부분망을 ’복권에 당첨되었다’는 의미로 **‘당첨 티켓(Winning Ticket)’**이라 명명했다.5</p>
<p>이 가설은 기존의 통념과 정면으로 배치된다. 이전까지 프루닝은 ’성능을 위해 일단 큰 모델을 훈련시킨 후, 불필요한 연결을 제거하여 압축하는 과정’으로 여겨졌다.5 그러나 복권 가설은 프루닝의 성공이 단순히 불필요한 연결을 제거하는 과정이 아니라, 오히려 거대한 초기화 상태의 네트워크 속에서 ’학습에 본질적으로 유리한 초기 조건을 가진 부분망을 발견하는 과정’일 수 있음을 시사한다. 즉, 중요한 것은 학습된 가중치가 아니라, 성공적인 학습을 가능하게 한 ’운 좋은 초기화(fortuitous initializations)’라는 것이다.6</p>
<h4>2.1.2 ‘당첨 티켓’ 식별 알고리즘</h4>
<p>논문은 ’당첨 티켓’을 식별하기 위한 구체적인 알고리즘으로 반복적 크기 프루닝(Iterative Magnitude Pruning, IMP)을 제안했다.6 그 과정은 다음과 같다.</p>
<ol>
<li>
<p>신경망 <span class="math math-inline">f(x; \theta_0)</span>를 무작위 가중치 <span class="math math-inline">\theta_0</span>로 초기화한다. 여기서 <span class="math math-inline">\theta_0 \sim \mathcal{D}_\theta</span>는 특정 분포를 따른다.</p>
</li>
<li>
<p>네트워크를 <span class="math math-inline">j</span> 이터레이션 동안 훈련하여 최적화된 파라미터 <span class="math math-inline">\theta_j</span>를 얻는다.</p>
</li>
<li>
<p><span class="math math-inline">\theta_j</span>에서 크기(magnitude)가 가장 작은 <span class="math math-inline">p%</span>의 파라미터를 프루닝하여, 살아남은 파라미터의 위치를 나타내는 이진 마스크(binary mask) <span class="math math-inline">m</span>을 생성한다.</p>
</li>
<li>
<p>마스크 <span class="math math-inline">m</span>을 사용하여 원래의 초기 가중치 <span class="math math-inline">\theta_0</span>에 적용한다. 즉, 프루닝되지 않은 가중치는 <span class="math math-inline">\theta_0</span> 값으로 되돌리고, 프루닝된 가중치는 0으로 설정한다. 이렇게 생성된 희소 네트워크 <span class="math math-inline">f(x; m \odot \theta_0)</span>가 바로 ’당첨 티켓’이다.</p>
</li>
</ol>
<p>이 과정을 여러 라운드에 걸쳐 반복적으로 수행하면(iterative pruning), 한 번에 프루닝하는 것(one-shot pruning)보다 더 작고 성능 좋은 당첨 티켓을 찾을 수 있음이 실험적으로 확인되었다.8</p>
<h4>2.1.3 실험 결과 및 분석</h4>
<p>연구진은 MNIST와 CIFAR10 데이터셋에 대해 완전 연결 신경망(Fully-connected) 및 VGG, ResNet과 같은 CNN 아키텍처를 사용하여 가설을 검증했다.6 실험 결과, 원본 네트워크 크기의 10-20% 또는 그 이하에 불과한 희소성을 가진 ’당첨 티켓’을 일관되게 발견했다.6 놀랍게도, 이렇게 발견된 당첨 티켓들은 원본 밀집 네트워크와 비교하여 더 적은 이터레이션으로 학습을 완료했으며, 종종 더 높은 테스트 정확도에 도달했다. 이는 과잉 파라미터화된 네트워크가 더 많은 ’당첨 티켓’을 포함하고 있을 가능성이 높기 때문에 훈련이 더 용이할 수 있다는 가설을 강력하게 뒷받침한다.11</p>
<h3>2.2  네트워크 프루닝의 가치에 대한 비판적 재고찰</h3>
<p>같은 해 ICLR 2019에서 발표된 “Rethinking the value of network pruning“은 복권 가설과는 또 다른 관점에서 프루닝의 본질에 대한 중요한 질문을 던졌다.12 이 연구는 프루닝의 성공 요인이 ’학습된 가중치의 계승’이 아닐 수도 있다는 도발적인 주장을 제기했다.</p>
<h4>2.2.1 새로운 관찰 결과</h4>
<p>연구진은 다양한 최신 구조화 프루닝(structured pruning) 기법들을 대상으로 실험을 수행했다. 구조화 프루닝은 개별 가중치가 아닌 필터나 채널 전체를 제거하는 방식으로, 실제 하드웨어 가속에 더 유리하다. 실험의 핵심은 두 가지 시나리오를 비교하는 것이었다.12</p>
<ol>
<li>
<p><strong>파인튜닝(Fine-tuned):</strong> 전통적인 방식. 거대 모델을 훈련시킨 후 프루닝하고, 남은 가중치를 기반으로 추가 학습(파인튜닝)을 진행한다.</p>
</li>
<li>
<p><strong>무작위 초기화 학습(Scratch-trained):</strong> 프루닝을 통해 얻은 희소 ’아키텍처’는 그대로 유지하되, 남은 가중치를 모두 버리고 새로운 무작위 값으로 초기화하여 처음부터 학습시킨다.</p>
</li>
</ol>
<p>실험 결과, 놀랍게도 대부분의 경우에서 ‘무작위 초기화 학습’ 모델이 ‘파인튜닝’ 모델과 비슷하거나 오히려 더 높은 성능을 보였다.12</p>
<h4>2.2.2 시사점</h4>
<p>이 결과는 딥러닝 커뮤니티의 기존 믿음에 큰 의문을 제기한다. 이는 대규모 모델에서 오랜 시간 학습하여 얻은 ‘중요한’ 가중치를 물려받는 것이 희소 모델의 성능에 결정적인 요소가 아닐 수 있음을 의미한다. 대신, 프루닝 과정이 찾아낸 <strong>‘효율적인 희소 아키텍처’ 그 자체가 성능의 핵심</strong>일 수 있다는 새로운 가능성을 열어준다.12</p>
<p>이러한 관점에서 프루닝은 더 이상 가중치를 ’선택’하거나 ’제거’하는 과정이 아니라, 거대한 탐색 공간 속에서 효율적인 신경망 구조를 발견하는 일종의 <strong>‘아키텍처 탐색(Architecture Search)’ 패러다임</strong>으로 재해석될 수 있다. 즉, 처음부터 거대한 모델을 훈련하는 비용을 들이지 않고도, 프루닝을 통해 효율적인 소형 아키텍처를 발견한 뒤 이를 처음부터 훈련시키는 것이 더 효과적일 수 있다는 실용적인 대안을 제시한 것이다.12</p>
<table><thead><tr><th><strong>관점</strong></th><th><strong>The Lottery Ticket Hypothesis</strong></th><th><strong>Rethinking the value of network pruning</strong></th></tr></thead><tbody>
<tr><td><strong>핵심 질문</strong></td><td>무엇이 희소 모델의 성능을 결정하는가?</td><td>무엇이 희소 모델의 성능을 결정하는가?</td></tr>
<tr><td><strong>핵심 답변</strong></td><td>‘운 좋은 초기 가중치를 보존한’ 서브네트워크 (<span class="math math-inline">m \odot \theta_0</span>)</td><td>‘프루닝으로 발견된’ 효율적인 아키텍처 (<span class="math math-inline">m</span>)</td></tr>
<tr><td><strong>방법론</strong></td><td>반복적 크기 기반 프루닝 후 초기 가중치로 리셋</td><td>다양한 구조화 프루닝 후 파인튜닝과 무작위 초기화 학습 비교</td></tr>
<tr><td><strong>주요 시사점</strong></td><td>신경망 초기화의 중요성 재조명, 훈련 가능한 희소망의 존재 증명</td><td>프루닝을 아키텍처 탐색의 한 형태로 재해석, 학습된 가중치의 보편적 유용성에 의문 제기</td></tr>
</tbody></table>
<p>이 두 연구는 표면적으로는 상충하는 것처럼 보인다. ’복권 가설’은 성공의 열쇠로 ’운 좋은 초기 가중치’를, ’프루닝 가치 재고찰’은 ’효율적인 아키텍처’를 지목하기 때문이다. 그러나 이들은 사실상 동일한 근본적 질문, 즉 ’과잉 파라미터화는 왜 효과적인가?’에 대한 답을 각기 다른 각도에서 조명하고 있다. 이들을 통합적으로 이해하면 더 큰 그림을 그릴 수 있다. 거대한 무작위 네트워크는 본질적으로 훈련에 유리한 수많은 (구조 + 초기 가중치) 조합을 품고 있는 거대한 ’실험장’과 같다. 그리고 프루닝은 이 광활한 실험장 속에서 성공적인 조합을 효율적으로 찾아내는 강력한 발견적(heuristic) 탐색 알고리즘으로 기능한다. 2019년 1월, 이 두 연구의 등장은 딥러닝 연구가 단순히 ‘어떻게(How)’ 성능을 높일 것인가를 넘어, ‘왜(Why)’ 그것이 작동하는가라는 근본적인 질문으로 나아가는 중요한 철학적 전환기였음을 상징한다.</p>
<h2>3.  표현 학습의 확장: 그래프와 문맥을 통한 데이터 이해</h2>
<p>2019년 초, 특히 AAAI 2019 학회를 중심으로 표현 학습(Representation Learning) 분야는 전통적인 순차 데이터나 격자형 데이터를 넘어, 관계형 데이터와 문맥 정보를 효과적으로 모델링하려는 시도들이 두드러졌다. 이는 인공지능이 세상을 더 깊이 이해하기 위해 데이터 이면에 숨겨진 복잡한 구조와 맥락을 파악하는 방향으로 진화하고 있음을 보여주는 중요한 흐름이다.</p>
<h3>3.1  그래프 신경망을 활용한 세션 기반 추천 시스템 (SR-GNN)</h3>
<p>추천 시스템은 현대 웹 서비스의 핵심 기술이지만, 사용자 식별 정보 없이 단발적인 상호작용 기록(세션)만을 기반으로 추천을 제공해야 하는 ’세션 기반 추천’은 매우 어려운 문제로 남아있었다. 기존의 RNN 기반 모델들은 사용자의 클릭 순서를 순차적인 정보로만 간주하여, 세션 내에 존재하는 복잡하고 비순차적인 아이템 간의 전환 관계를 포착하는 데 한계를 보였다.13</p>
<h4>3.1.1 SR-GNN 방법론</h4>
<p>AAAI 2019에서 발표된 “Session-Based Recommendation with Graph Neural Networks” (SR-GNN)는 이 문제에 대한 혁신적인 해법을 제시했다.4 이 연구는 세션 데이터를 순차적인 스트림이 아닌, 아이템 간의 관계망을 나타내는 **그래프(Graph)**로 모델링하는 새로운 패러다임을 도입했다.15</p>
<p>SR-GNN의 접근법은 다음과 같은 단계로 이루어진다 13:</p>
<ol>
<li>
<p><strong>세션 그래프 구성(Constructing Session Graphs):</strong> 모든 학습 데이터의 세션 시퀀스들을 모아 하나의 거대한 방향성 그래프(directed graph)로 구축한다. 이 그래프에서 각 고유 아이템은 노드(node)가 되고, 한 세션 내에서 아이템 <span class="math math-inline">v_i</span> 다음에 아이템 <span class="math math-inline">v_j</span>가 클릭되었다면 <span class="math math-inline">v_i</span>에서 <span class="math math-inline">v_j</span>로 향하는 엣지(edge)가 생성된다. 결과적으로, 개별 세션 시퀀스 <span class="math math-inline">s = [v_{s,1}, v_{s,2},..., v_{s,n}]</span>는 이 전체 그래프의 부분 그래프(subgraph)로 표현된다.13</p>
</li>
<li>
<p><strong>아이템 임베딩 학습(Learning Item Embeddings):</strong> Gated Graph Neural Networks (GGNN)를 사용하여 세션 그래프의 각 노드(아이템)에 대한 임베딩 벡터 <span class="math math-inline">\mathbf{v}</span>를 학습한다.15 GGNN은 각 노드가 이웃 노드들과 정보를 교환하는 과정을 반복함으로써, 단순히 순서 정보뿐만 아니라 전체 세션들의 맥락 속에서 형성된 복잡하고 구조적인 관계를 임베딩에 녹여낸다.</p>
</li>
<li>
<p><strong>세션 표현 생성(Generating Session Embeddings):</strong> 현재 세션 <span class="math math-inline">s</span>를 예측에 사용하기 위한 벡터로 표현한다. 이를 위해 두 가지 정보를 결합한다 17:</p>
</li>
</ol>
<ul>
<li>
<p><strong>지역 임베딩 (Local Embedding) <span class="math math-inline">\mathbf{s}_l</span>:</strong> 세션의 가장 마지막에 클릭된 아이템 <span class="math math-inline">v_n</span>의 임베딩 벡터 <span class="math math-inline">\mathbf{v}_n</span>을 사용하여, 사용자의 현재의 즉각적인 관심을 포착한다. 이는 <span class="math math-inline">\mathbf{s}_l = \mathbf{v}_n</span>으로 정의된다.</p>
</li>
<li>
<p><strong>전역 임베딩 (Global Embedding) <span class="math math-inline">\mathbf{s}_g</span>:</strong> 세션에 포함된 모든 아이템 <span class="math math-inline">[v_{s,1},..., v_{s,n}]</span>의 임베딩 벡터들을 소프트-어텐션(soft-attention) 메커니즘을 통해 가중 합산한다. 이는 세션 전반에 걸친 사용자의 선호도를 종합적으로 포착한다.</p>
</li>
<li>
<p>최종 세션 임베딩 <span class="math math-inline">\mathbf{s}_h</span>는 지역 임베딩과 전역 임베딩을 선형 변환 후 결합하여 생성된다: <span class="math math-inline">\mathbf{s}_h = \mathbf{W}_1 \mathbf{s}_g + \mathbf{W}_2 \mathbf{s}_l</span>.</p>
</li>
</ul>
<ol start="4">
<li><strong>추천 생성(Making Recommendation):</strong> 최종 세션 임베딩 <span class="math math-inline">\mathbf{s}_h</span>와 모든 후보 아이템들의 임베딩 <span class="math math-inline">\mathbf{v}_i</span> 간의 내적(dot product)을 계산하고, 소프트맥스(softmax) 함수를 적용하여 각 아이템이 다음 클릭으로 나타날 확률 점수 <span class="math math-inline">\hat{\mathbf{y}}_i</span>를 산출한다.</li>
</ol>
<h4>3.1.2 의의</h4>
<p>SR-GNN은 추천 시스템 분야, 특히 세션 기반 추천에 GNN을 성공적으로 도입한 선구적인 연구로 평가받는다.15 이 연구는 순차적 데이터의 이면에 숨겨진 복잡한 관계망을 포착하는 새로운 길을 열었으며, 이후 다양한 추천 시스템 연구에서 GNN을 활용하는 흐름을 촉발시켰다.</p>
<h3>3.2  문맥을 이해하는 셀프 어텐션 네트워크</h3>
<p>자연어 처리 분야에서 Transformer 모델의 등장은 혁명적이었다. 그 핵심에는 병렬 처리에 용이하고 장단기 의존성을 효과적으로 모델링하는 셀프 어텐션 네트워크(Self-Attention Network, SAN)가 있다.18 하지만 표준적인 SAN은 시퀀스 내의 두 요소(예: 단어) 간의 관계를 계산할 때, 해당 요소 쌍에만 집중할 뿐 문장 전체의 ‘문맥(context)’ 정보를 명시적으로 활용하지 않는다는 잠재적 한계를 가지고 있었다.19</p>
<h4>3.2.1 Context-Aware SAN 방법론</h4>
<p>AAAI 2019에서 발표된 “Context-Aware Self-Attention Networks“는 이러한 한계를 극복하기 위해 SAN의 핵심 연산 과정에 문맥 정보를 주입하는 방법을 제안했다.18 이 모델의 핵심 아이디어는 Query(<span class="math math-inline">\mathbf{Q}</span>)와 Key(<span class="math math-inline">\mathbf{K}</span>)를 변환하는 과정에 **문맥 벡터(Context Vector) <span class="math math-inline">\mathbf{C}</span>**를 동적으로 통합하는 것이다.</p>
<p>기존 SAN에서는 입력 임베딩 행렬 <span class="math math-inline">\mathbf{H}</span>에 가중치 행렬 <span class="math math-inline">\mathbf{W}_Q, \mathbf{W}_K</span>를 곱하여 <span class="math math-inline">\mathbf{Q}</span>와 <span class="math math-inline">\mathbf{K}</span>를 얻는다.</p>
<p><span class="math math-display">
\begin{bmatrix} \mathbf{Q} \\ \mathbf{K} \\ \mathbf{V} \end{bmatrix} = \mathbf{H} \begin{bmatrix} \mathbf{W}_Q \\ \mathbf{W}_K \\ \mathbf{W}_V \end{bmatrix}
</span><br />
제안된 모델은 여기에 문맥 벡터 <span class="math math-inline">\mathbf{C}</span>를 추가하여 문맥 인지적인(Context-Aware) <span class="math math-inline">\mathbf{Q}^b</span>와 <span class="math math-inline">\mathbf{K}^b</span>를 다음과 같이 계산한다 18:</p>
<p><span class="math math-display">
\begin{bmatrix} \mathbf{Q}^b \\ \mathbf{K}^b \end{bmatrix} = \begin{bmatrix} (1 - \lambda_Q) \mathbf{Q} \\ (1 - \lambda_K) \mathbf{K} \end{bmatrix} + \begin{bmatrix} \lambda_Q (\mathbf{C} \mathbf{U}_Q) \\ \lambda_K (\mathbf{C} \mathbf{U}_K) \end{bmatrix}
</span><br />
여기서 <span class="math math-inline">\mathbf{C}</span>는 문맥 정보를 담은 벡터로, 문장 전체 임베딩의 평균(Global Context)이나 하위 레이어들의 출력(Deep Context) 등 모델 내부의 표현을 활용하여 생성된다.18</p>
<p><span class="math math-inline">\mathbf{U}_Q, \mathbf{U}_K</span>는 학습 가능한 파라미터이며, <span class="math math-inline">\lambda_Q, \lambda_K</span>는 원본 정보와 문맥 정보의 기여도를 조절하는 게이팅(gating) 스칼라로, 이 역시 네트워크가 스스로 학습한다.</p>
<h4>3.2.2 효과</h4>
<p>이러한 구조를 통해 모델은 두 단어 간의 어텐션 가중치를 계산할 때, 단순히 두 단어 자체의 정보뿐만 아니라 문장 전체의 의미나 더 깊은 층위에서 요약된 구문론적, 의미론적 정보를 종합적으로 고려할 수 있게 된다. 그 결과, WMT14 영어-독일어 번역과 같은 고난도 기계 번역 태스크에서 상당한 성능 향상을 달성하며 제안된 방법의 효과를 입증했다.18</p>
<h3>3.3  대화형 AI의 기술적 진보: NAVER Clova 사례 연구</h3>
<p>ICLR 2019에서 네이버 클로바 팀은 대화형 AI의 실용적인 문제들을 해결하기 위한 두 가지 중요한 연구를 발표하며 기술력을 입증했다.22</p>
<ul>
<li>
<p><strong>DialogWAE:</strong> 이 연구는 AI 스피커와의 대화에서 흔히 발생하는 문제, 즉 대화의 맥락이 갑자기 끊기거나 특정 답변이 반복되는 현상을 해결하는 것을 목표로 했다.22 이를 위해 ’조건부 Wasserstein Autoencoder (DialogWAE)’라는 새로운 생성 모델을 제안했다. 이 모델은 대화의 맥락을 이해하는 동시에, 의미적으로 일관성을 유지하면서도 표현이 다양한 여러 답변을 생성할 수 있는 능력을 갖추도록 설계되었다. 이는 보다 자연스럽고 지루하지 않은 대화 경험을 제공하는 핵심 기술이다.22</p>
</li>
<li>
<p><strong>AQM (Attentive Query-in-Response Model):</strong> 이 연구는 예약, 주문, 콜센터 상담과 같이 명확한 목표를 가진 ’목적 지향 대화(task-oriented dialogue)’에 초점을 맞추었다.22 특히 시각 정보(예: 메뉴판 이미지)가 함께 주어지는 상황에서, 사용자의 다음 행동이나 의도를 예측하고, 필요한 정보를 얻기 위해 시스템이 먼저 ’질문’을 생성하는 능동적인 대화 모델을 제안했다. 근사 추론(approximate inference) 방법을 사용하여 실제 상황에 바로 적용할 수 있는 가능성을 보였다.22</p>
</li>
</ul>
<p>2019년 이전까지 딥러닝의 성공은 주로 이미지의 공간적 구조(CNN)나 텍스트의 순차적 구조(RNN/Transformer)와 같이 잘 정의된 데이터 구조에 기반했다. 그러나 2019년 1월에 발표된 이 연구들은 이러한 경계를 넘어서려는 중요한 시도를 보여준다. SR-GNN은 전자상거래 클릭 로그처럼 비정형적으로 보이는 데이터 속에 숨겨진 **‘그래프 구조’**를 발견하고 이를 GNN으로 모델링했다. 이는 표현 학습의 대상을 전통적인 유클리드 공간을 넘어 관계와 연결을 다루는 비유클리드 공간으로 확장한 것이다. 한편, Context-Aware SAN은 기존의 순차 데이터 내에서도 단순히 단어와 단어의 1:1 관계를 넘어, 문장 전체나 여러 레이어에 걸쳐 존재하는 추상적인 **‘계층적 문맥’**이라는 무형의 구조를 포착하려 했다. 이 두 흐름은 AI가 데이터를 단순히 순서나 픽셀 단위로 처리하는 것을 넘어, 그 이면에 숨겨진 **‘관계망(structure)’**과 **‘배경 정보(context)’**를 함께 학습해야 한다는 중요한 패러다임의 전환을 예고한다. 이는 이후 지식 그래프(Knowledge Graph)를 활용한 연구나, BERT 이후 세대의 문맥 기반 언어 모델들이 폭발적으로 성장하는 데 필요한 기술적, 철학적 토대를 마련한 것으로 평가할 수 있다.</p>
<h2>4.  로봇 공학의 도약: 강화학습과 자율 제어의 고도화</h2>
<p>2019년 1월, 로봇 공학 분야에서는 arXiv와 같은 프리프린트 서버를 중심으로 괄목할 만한 연구 성과들이 발표되었다. 특히, 심층 강화학습(Deep Reinforcement Learning)을 통해 시뮬레이션 환경에서 고도로 복잡한 기술을 학습하고 이를 물리적 로봇으로 성공적으로 이전하는 ‘Sim-to-Real’ 패러다임이 한층 성숙했음을 보여주는 연구들이 주목받았다. 또한, 예측 불가능한 동적 환경에서 강인하게 작동하는 자율 로봇 제어 기술의 발전도 두드러졌다.</p>
<h3>4.1  Sim-to-Real의 정점: 심층 강화학습 기반 로봇 손재주 학습</h3>
<p>OpenAI가 발표한 “Learning Dexterous In-Hand Manipulation” 연구는 2019년 초 로봇 공학계에 가장 큰 반향을 일으킨 성과 중 하나이다.24 이 연구는 24자유도(DoF)를 가진 인간형 로봇 손(Shadow Dexterous Hand)을 이용해, 사람처럼 손 안에서 블록이나 프리즘 같은 물체를 자유자재로 굴리고 방향을 바꾸는 고난도의 조작(in-hand manipulation) 기술을 학습시키는 데 성공했다.26</p>
<h4>4.1.1 Sim-to-Real 방법론</h4>
<p>이 연구의 성공은 시뮬레이션과 현실 세계 사이의 물리적 차이, 즉 ’현실 격차(reality gap)’를 극복하기 위한 정교한 Sim-to-Real 전이 전략에 기반한다.</p>
<ol>
<li>
<p><strong>대규모 병렬 시뮬레이션:</strong> Dactyl이라 불리는 이 시스템은 OpenAI Five(Dota 2 AI) 개발에 사용된 것과 동일한 범용 강화학습 알고리즘(Proximal Policy Optimization, PPO)과 대규모 분산 시스템을 활용했다.27 이를 통해 수만 년에 해당하는 방대한 경험 데이터를 시뮬레이션 환경에서 효율적으로 생성하고 학습에 사용했다.24</p>
</li>
<li>
<p><strong>도메인 무작위화 (Domain Randomization):</strong> 현실 격차를 극복하기 위한 핵심 전략으로 ’도메인 무작위화’를 광범위하게 적용했다.25 학습 과정에서 매 에피소드마다 시뮬레이션 환경의 물리 파라미터(예: 마찰 계수, 물체 질량, 중력)와 시각적 요소(예: 조명, 텍스처, 카메라 위치, 물체 외형)를 무작위로 변경했다.24 이 전략의 목표는 학습된 정책(policy)이 특정 시뮬레이션 환경에 과적합(overfitting)되는 것을 방지하고, 예측 불가능하고 다양한 현실 세계의 변화에 강인한 일반화 성능을 갖도록 만드는 것이다.</p>
</li>
</ol>
<h4>4.1.2 주요 성과 및 발견</h4>
<ul>
<li>
<p><strong>제로샷 전이(Zero-Shot Transfer):</strong> 시뮬레이션에서만 학습된 정책은 물리 로봇으로 옮겨졌을 때, 어떠한 추가적인 데이터 수집이나 미세 조정(fine-tuning) 과정 없이도 즉시 성공적으로 작동했다.27 이는 도메인 무작위화 전략의 강력한 효과를 입증한 것이다.</p>
</li>
<li>
<p><strong>인간과 유사한 행동의 창발(Emergence):</strong> 연구진은 인간의 시연 데이터를 전혀 사용하지 않았음에도 불구하고, 학습된 로봇 손이 매우 인간과 유사하고 정교한 조작 기술을 자발적으로 터득했음을 발견했다.24 예를 들어, 물체를 안정적으로 잡기 위해 여러 손가락을 협응하여 사용하는 것, 손가락을 번갈아 움직여 물체를 옮기는 ‘핑거 게이팅(finger gaiting)’, 그리고 물체를 살짝 떨어뜨렸다가 다시 잡는 방식으로 중력을 제어하여 활용하는 등 복잡한 행동이 자연스럽게 나타났다.26</p>
</li>
<li>
<p><strong>놀라운 발견(Surprising Findings):</strong> 가장 놀라운 발견 중 하나는, 로봇 손가락 끝에 부착된 촉각 센서(tactile sensing)를 전혀 사용하지 않고, 오직 세 대의 RGB 카메라로부터 얻은 시각 정보와 손가락 끝의 위치 정보만으로도 이처럼 정교한 조작이 가능했다는 점이다.27 이는 시뮬레이션에서 정확하게 모델링하기 매우 어려운 센서(촉각)에 의존하기보다, 다소 부정확하더라도 효과적으로 모델링 가능한 센서(시각)를 활용하는 것이 Sim-to-Real 문제 해결에 더 유리할 수 있다는 중요한 실마리를 제공한다.</p>
</li>
</ul>
<h3>4.2  동적 환경에서의 강인한 로봇 제어</h3>
<p>실제 환경은 예측 불가능한 상호작용과 변화로 가득 차 있다. 2019년 1월에는 이러한 동적 환경에서 로봇이 안정성과 강인성을 유지하기 위한 제어 기술 연구들이 다수 발표되었다.</p>
<ul>
<li>
<p><strong>사족보행 로봇의 회복 제어:</strong> “Robust Recovery Controller for a Quadrupedal Robot using Deep Reinforcement Learning” (arXiv:1901.08453) 연구는 외부에서 가해지는 강한 충격(예: 사람이 발로 차는 상황)에도 불구하고 사족보행 로봇이 넘어지지 않고 빠르게 균형을 회복하는 제어기를 심층 강화학습으로 개발했다.28 시뮬레이션 환경에서 다양한 방향과 세기의 외력을 무작위로 가하며 학습된 이 제어기는, 예측 불가능한 물리적 상호작용이 발생하는 실제 환경에서 로봇이 임무를 지속적으로 수행하기 위한 필수적인 강인성을 확보했다.</p>
</li>
<li>
<p><strong>이족보행 로봇의 동적 보행:</strong> “Dynamic Locomotion For Passive-Ankle Biped Robots And Humanoids Using Whole-Body Locomotion Control” (arXiv:1901.08100) 연구는 구조적으로 불안정한 로봇의 제어 문제를 다루었다.28 특히, 발목에 별도의 구동기(actuator)가 없는 수동형(passive-ankle) 이족보행 로봇은 균형을 잡기가 매우 어렵다. 연구진은 전신 제어(Whole-Body Control, WBC) 기법을 새롭게 고안하여 이 문제를 해결했다. 핵심은 발이 지면에 닿고 떨어지는 과정에서 발생하는 제어 명령의 급격한 변화(jerk)를 줄이기 위해, 접촉 상태를 엄격한 제약조건이 아닌 비용 함수(cost function)의 일부로 취급하여 완화한 것이다. 이 접근법을 통해 불규칙하고 미끄러운 지형에서도 안정적인 동적 보행을 구현하는 데 성공했다.29</p>
</li>
</ul>
<h3>4.3  자율 항공 로봇을 활용한 대규모 인프라 시각 점검</h3>
<p>로봇 기술은 위험하고 반복적인 작업을 자동화하는 데 큰 잠재력을 가지고 있다. “Autonomous visual inspection of large-scale infrastructures using aerial robots” (arXiv:1901.05510) 연구는 풍력 터빈과 같은 거대하고 접근하기 어려운 인프라를 자율 비행 드론(Micro Aerial Vehicle, MAV) 팀을 이용해 안전하고 효율적으로 점검하는 통합 프레임워크를 제안했다.30</p>
<h4>4.3.1 핵심 기술 요소</h4>
<p>제안된 프레임워크는 MAV가 온보드 컴퓨터와 센서만으로 임무를 완수하는 것을 목표로 하며, 다음과 같은 핵심 기술들로 구성된다.32</p>
<ul>
<li>
<p><strong>경로 계획(Path Planning):</strong> 점검 대상 구조물의 3D 기하학 모델을 기반으로, 카메라의 시야(Field of View)를 고려하여 모든 표면을 빠짐없이 촬영할 수 있는 최적의 비행 경로를 자동으로 생성한다(geometry-based path planner). 여러 대의 MAV를 사용할 경우, 전체 구조물을 효율적으로 분할하여 각 MAV에 할당하는 협력적 경로 계획(Collaborative Coverage Path Planner)을 수행한다.32</p>
</li>
<li>
<p><strong>정확한 위치 추정(Localization):</strong> 풍력 터빈과 같이 거대한 금속 구조물 근처에서는 GPS 신호가 다중 경로 오차로 인해 불안정해진다. 또한, 특징점이 부족한 단조로운 표면 때문에 시각 기반 위치 추정(visual odometry)도 실패하기 쉽다. 이 문제를 해결하기 위해, 구조물 주변에 설치된 초광대역(Ultra-Wideband, UWB) 센서 네트워크와 드론 내부의 관성 측정 장치(IMU)를 융합하여 정밀하고 강인한 위치 추정 능력을 확보했다.32</p>
</li>
</ul>
<h4>4.3.2 실험 결과</h4>
<p>연구진은 스웨덴의 실제 풍력 터빈 발전소에서 제안된 시스템의 성능을 검증했다. 실험 결과, 최대 13m/s의 강한 바람이 부는 악조건 속에서도 MAV가 안정적으로 자율 비행하며 터빈 타워와 블레이드에 대한 시각 점검 임무를 성공적으로 완수함을 입증했다.32 이는 대규모 인프라의 유지보수 작업을 자동화하고, 인간 작업자의 위험을 줄이며, 비용을 절감할 수 있는 실용적인 로봇 시스템의 가능성을 보여주었다.</p>
<table><thead><tr><th><strong>항목</strong></th><th><strong>Dexterous Manipulation</strong></th><th><strong>Robust Recovery</strong></th><th><strong>Dynamic Locomotion</strong></th><th><strong>Autonomous Inspection</strong></th></tr></thead><tbody>
<tr><td><strong>로봇 플랫폼</strong></td><td>Shadow Dexterous Hand (5-fingered)</td><td>사족보행 로봇</td><td>수동형 이족보행 로봇</td><td>MAV (드론)</td></tr>
<tr><td><strong>핵심 과제</strong></td><td>손가락 조작 (In-hand manipulation)</td><td>외부 충격에 대한 균형 회복</td><td>불안정 지면에서의 동적 보행</td><td>대규모 인프라 자율 점검</td></tr>
<tr><td><strong>주요 방법론</strong></td><td>심층 강화학습 (PPO) + 도메인 무작위화</td><td>심층 강화학습</td><td>전신 제어 (WBC)</td><td>기하학 기반 경로 계획 + UWB/IMU 융합</td></tr>
<tr><td><strong>핵심 성과</strong></td><td>Sim-to-Real 제로샷 전이 성공</td><td>외부 충격에 대한 강인성 확보</td><td>수동형 발목 로봇 보행 성공</td><td>실제 풍력 터빈 자율 점검 성공</td></tr>
</tbody></table>
<p>2019년 1월의 로봇 공학 연구들은 공통적으로 중요한 방향성을 제시한다. 전통적인 로봇 공학의 난제들, 예를 들어 수십 개의 관절을 가진 복잡한 하드웨어를 정밀하게 제어하는 문제, 예측 불가능한 환경 변화에 적응하는 문제, 그리고 센서의 물리적 한계를 극복하는 문제 등은 과거에는 주로 정교한 물리 모델링과 제어 이론으로 해결하려 했다. 그러나 이 시기의 연구들은 <strong>’하드웨어의 불완전성’과 ’환경의 불확실성’을 더 이상 피해야 할 대상이 아닌, 데이터 기반의 ’학습 가능한 소프트웨어’를 통해 극복해야 할 문제로 정면으로 마주하고 있다.</strong> 특히 OpenAI의 연구에서 핵심적인 역할을 한 ’도메인 무작위화’는 시뮬레이션이라는 가상 세계를 ’불완전한 현실 세계의 통계적 집합’으로 재창조함으로써, 하드웨어의 한계와 현실의 불확실성을 지능적으로 포용하는 새로운 길을 열었다. 이는 로봇 공학의 무게 중심이 정형화된 모델 기반 제어에서 유연하고 강인한 데이터 기반 학습으로 이동하는 결정적인 순간을 상징하며, 심층 강화학습이 로봇 공학의 ’하드웨어적 한계’를 ’소프트웨어적 지능’으로 극복하는 핵심 열쇠임을 명확히 보여준다.</p>
<h2>5. 결론: 2019년 AI 연구의 유산과 미래 전망</h2>
<p>2019년 1월은 인공지능 연구의 역사에서 단순한 시간의 흐름을 넘어, 새로운 질문과 가능성이 응축된 중요한 시기였다. 본 보고서에서 심층 분석한 세 가지 핵심 흐름—<strong>신경망의 내재적 원리 탐구, 데이터의 구조적·문맥적 표현 학습, 그리고 Sim-to-Real 강화학습의 실용화</strong>—은 각기 독립적인 분야의 성과처럼 보이지만, 실제로는 인공지능이라는 거대한 지향점 아래 긴밀하게 상호 연결되어 있다.</p>
<p>첫째, ’복권 가설’과 ’프루닝 가치 재고찰’로 대표되는 효율성 연구는 딥러닝의 ’블랙박스’를 열어 그 작동 원리를 이해하려는 근본적인 시도였다. 이는 단순히 모델을 작게 만드는 기술을 넘어, 왜 과잉 파라미터화가 효과적인지에 대한 통찰을 제공했다. 이러한 기초 연구의 성과는 제3장에서 다룬 로봇 공학과 직접적으로 연결된다. OpenAI의 로봇 손 제어와 같이 막대한 계산 자원을 요구하는 강화학습 모델의 훈련 비용을 절감하고, 더 효율적인 신경망 아키텍처를 탐색하는 데 중요한 이론적 기반을 제공할 수 있기 때문이다.</p>
<p>둘째, SR-GNN과 Context-Aware SAN과 같은 표현 학습 연구는 AI가 데이터를 바라보는 시각을 한 차원 높였다. 데이터는 더 이상 단순한 시퀀스나 픽셀의 나열이 아니라, 그 안에 복잡한 ’구조(structure)’와 풍부한 ’문맥(context)’을 품고 있는 정보의 집합체로 인식되기 시작했다. 이러한 관점의 전환은 로봇이 주변 환경을 더 깊이 이해하고 상호작용하는 데 필수적이다. 예를 들어, GNN을 통해 객체들 간의 관계를 파악하는 능력은 로봇이 복잡한 조작 과제를 수행하는 데, 문맥을 이해하는 능력은 인간과 로봇의 자연스러운 상호작용에 핵심적인 역할을 할 것이다.</p>
<p>셋째, OpenAI의 손 조작 연구로 대표되는 로봇 공학의 발전은 AI 연구의 궁극적인 목표 중 하나인 ’물리적 세계에서의 지능 구현’에 대한 중요한 이정표를 세웠다. 특히 Sim-to-Real 패러다임의 성공은, 위험하고 비용이 많이 드는 현실 세계의 시행착오를 안전하고 효율적인 가상 세계의 학습으로 대체할 수 있음을 증명했다. 이는 AI 연구의 성과가 디지털 공간에만 머무르지 않고, 제조업, 물류, 의료, 인프라 관리 등 현실 세계의 다양한 문제를 해결하는 실용적인 도구로 전환될 수 있음을 보여주었다.</p>
<p>2019년 1월의 연구들이 AI 기술 발전 로드맵에 미친 영향은 지대하다. ’복권 가설’은 이후 신경망 아키텍처 탐색(NAS)과 효율적인 딥러닝 연구에 새로운 영감을 주었으며, SR-GNN은 추천 시스템을 넘어 신약 개발, 교통망 분석 등 다양한 도메인에서 GNN의 활용을 촉발하는 기폭제가 되었다. OpenAI의 연구는 Sim-to-Real을 로봇 공학계의 표준 패러다임 중 하나로 확고히 정착시키는 데 결정적인 역할을 했다.</p>
<p>물론, 이 시기의 연구들은 해결 과제와 함께 새로운 질문들을 남겼다. ’당첨 티켓’을 값비싼 훈련 과정 없이 초기화 단계에서 미리 찾아낼 수 있는 방법은 무엇인가? 수십억 개의 노드를 가진 거대 그래프에 GNN을 효율적으로 적용할 수 있는 확장성 문제는 어떻게 해결할 것인가? 유체나 변형 가능한 물체와 같은 더 복잡한 물리 현상까지 포함하는 Sim-to-Real 기술은 어떻게 구현할 것인가? 이러한 질문들은 2019년 1월의 선구적인 연구들이 남긴 유산이자, 현재 그리고 미래의 AI 및 로봇 공학 커뮤니티가 풀어야 할 중요한 과제로 남아있다. 결론적으로, 2019년 1월은 AI가 자신의 잠재력을 증명하는 단계를 지나, 스스로의 본질을 성찰하고 현실 세계와의 간극을 메우기 시작한, 지적으로 매우 풍요롭고 역동적인 시대의 서막이었다고 평가할 수 있다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>AAAI 2019 Symposia - The Association for the Advancement of Artificial Intelligence, https://aaai.org/conference/spring-symposia/sss19/sss19symposia/</li>
<li>AAAI 2019 - dblp, https://dblp.org/db/conf/aaai/aaai2019</li>
<li>Vol. 33 No. 01: AAAI-19, IAAI-19, EAAI-20 | Proceedings of the AAAI …, https://ojs.aaai.org/index.php/AAAI/issue/view/246</li>
<li>Session-Based Recommendation with Graph Neural Networks | Proceedings of the AAAI Conference on Artificial Intelligence, https://ojs.aaai.org/index.php/AAAI/article/view/3804</li>
<li>ICLR 2019 참석 후기 및 단순하고 효과적인 Network Pruning 방법론을 다룬 Best Paper 리뷰, https://hoya012.github.io/blog/ICLR-2019-best-paper-review/</li>
<li>The lottery ticket hypothesis: Finding sparse, trainable neural networks, https://arxiv.org/abs/1803.03635</li>
<li>2019년 국내 로봇산업 매출 규모 9조원 달해, https://www.irobotnews.com/news/articleView.html?idxno=24227</li>
<li>MIT Open Access Articles The lottery ticket hypothesis: Finding sparse, trainable neural networks, https://dspace.mit.edu/bitstream/handle/1721.1/129953/1803.03635.pdf?sequence=2</li>
<li>A Survey of Lottery Ticket Hypothesis - arXiv, https://arxiv.org/html/2403.04861v1</li>
<li>The Lottery Ticket Hypothesis - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/the-lottery-ticket-hypothesis/</li>
<li>The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks | OpenReview, https://openreview.net/forum?id=rJl-b3RcF7</li>
<li>[논문 리뷰 - Pruning] Rethinking the value of network pruning (2019), https://je0nsye0n.tistory.com/m/62</li>
<li>Session-Based Recommendation with Graph … - AAAI Publications, https://ojs.aaai.org/index.php/AAAI/article/view/3804/3682</li>
<li>Graph Contextualized Self-Attention Network for Session-based Recommendation - IJCAI, https://www.ijcai.org/proceedings/2019/0547.pdf</li>
<li>(PDF) Session-Based Recommendation with Graph Neural Networks - ResearchGate, https://www.researchgate.net/publication/334808273_Session-Based_Recommendation_with_Graph_Neural_Networks</li>
<li>Session-based Recommendation with Graph Neural Networks - ResearchGate, https://www.researchgate.net/publication/328736932_Session-based_Recommendation_with_Graph_Neural_Networks</li>
<li>Session-based Recommendation with Graph Neural Networks - Yanqiao ZHU, https://sxkdz.github.io/files/publications/AAAI/SR-GNN/Poster.pdf</li>
<li>Context-Aware Self-Attention Networks, https://ojs.aaai.org/index.php/AAAI/article/view/3809/3687</li>
<li>(PDF) Context-Aware Self-Attention Networks - ResearchGate, https://www.researchgate.net/publication/331165370_Context-Aware_Self-Attention_Networks</li>
<li>Context-Aware Self-Attention Networks | Request PDF - ResearchGate, https://www.researchgate.net/publication/335800574_Context-Aware_Self-Attention_Networks</li>
<li>ACM, https://ojs.aaai.org/index.php/AAAI/citationstylelanguage/get/acm-sig-proceedings?submissionId=3809&amp;publicationId=2280</li>
<li>네이버, ICLR서 AI·딥러닝 논문 4건 발표 - 지디넷코리아, https://zdnet.co.kr/view/?no=20190513095950</li>
<li>네이버, <code>ICLR 2019</code>서 연구 성과 공개 - 매일경제, https://www.mk.co.kr/news/business/8811566</li>
<li>(PDF) Learning dexterous in-hand manipulation - ResearchGate, https://www.researchgate.net/publication/337345997_Learning_dexterous_in-hand_manipulation</li>
<li>Learning Dexterous In-Hand Manipulation - Matthias Plappert, https://matthiasplappert.com/publications/2018_OpenAI_Dexterous-Manipulation-v3.pdf</li>
<li>Learning dexterous in-hand manipulation - Matthias Plappert, https://matthiasplappert.com/publications/2020_OpenAI_Dexterous-Manipulation_IJRR.pdf</li>
<li>Learning dexterity | OpenAI, https://openai.com/index/learning-dexterity/</li>
<li>Robotics Jan 2019 - arXiv, http://arxiv.org/list/cs.RO/2019-01?skip=25&amp;show=500</li>
<li>Dynamic Locomotion For Passive-Ankle Biped Robots And …, https://arxiv.org/abs/1901.08100</li>
<li>[1901.05510] Autonomous visual inspection of large-scale infrastructures using aerial robots - arXiv, https://arxiv.org/abs/1901.05510</li>
<li>Autonomous visual inspection of large-scale infrastructures using aerial robots | Request PDF - ResearchGate, https://www.researchgate.net/publication/330466276_Autonomous_visual_inspection_of_large-scale_infrastructures_using_aerial_robots</li>
<li>Autonomous visual inspection of large-scale … - NDT.org, https://www.ndt.org/pub/autonomous_inspection.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>