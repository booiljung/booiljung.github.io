<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:1988년 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>1988년 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2006년 이전의 AI 및 로봇 연구 동향</a> / <span>1988년 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>1988년 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 역설의 해, 1988년 - 상업적 겨울과 학문적 봄의 교차점</h2>
<p>1988년은 인공지능(AI)의 역사에서 깊은 역설을 품은 해로 기록된다. 한편에서는 1987년 LISP 머신 시장의 붕괴와 함께 두 번째 ’AI 겨울’의 한기가 본격적으로 스며들기 시작했다.1 1980년대 초반을 풍미했던 전문가 시스템(Expert Systems)에 대한 뜨거운 기대는 ’지식 획득 병목(knowledge acquisition bottleneck)’이라는 현실의 벽에 부딪히며 급격히 냉각되었고, 이는 AI 산업 전반의 투자 위축으로 이어졌다.2 1984년, AI 분야의 거두였던 마빈 민스키(Marvin Minsky)와 로저 섕크(Roger Schank)가 예견했던 비관론의 연쇄 반응이 현실화되는 듯 보였다.1 상업적 AI의 화려했던 여름이 끝나고, 길고 혹독한 겨울이 도래하고 있었다.</p>
<p>그러나 이러한 상업적 한파의 이면에서는, 21세기 AI 혁명을 이끌 지적 대폭발이 조용히, 그러나 강력하게 일어나고 있었다. 학계는 상업적 관심이 줄어든 공백 속에서 오히려 AI의 근본적인 문제들에 다시 집중할 수 있는 기회를 맞았다.3 바로 이 해에 현대 AI를 구성하는 세 가지 핵심 패러다임—불확실성을 다루는 <strong>확률적 추론</strong>, 경험으로부터 학습하는 <strong>강화 학습</strong>, 그리고 복잡한 패턴을 인식하는 <strong>연결주의</strong>—의 이론적 기틀이 동시에 마련되었다. 유디 펄(Judea Pearl)은 확률적 추론의 새로운 시대를 열었고, 리처드 서튼(Richard Sutton)은 시간차 학습이라는 강화학습의 핵심 메커니즘을 정립했으며, 얀 르쿤(Yann LeCun)을 비롯한 연결주의 연구자들은 신경망의 실용적 가능성을 증명하며 그 이론적 토대를 공고히 했다.</p>
<p>본 보고서는 1988년을 단순한 침체기가 아닌, 낡은 패러다임의 한계가 명확해지고 새로운 패러다임이 태동한 결정적인 ’전환점(Inflection Point)’으로 규정한다. 상징주의 AI가 정교화의 정점에 달하며 스스로의 한계를 드러내는 과정, 연결주의가 이론적 엄밀함과 실용적 성공을 바탕으로 화려하게 부활하는 모습, 그리고 확률론과 강화학습이라는 새로운 지평이 열리는 순간을 심층적으로 추적한다. 이를 통해 1988년에 발표된 주요 연구들이 어떻게 상호작용하며 현대 AI 기술의 초석을 다졌는지 분석하고, AI 겨울이라는 거대한 빙하 아래에서 미래를 향한 가장 뜨거운 지적 용암이 분출하고 있었음을 명확히 밝히고자 한다.</p>
<table><thead><tr><th>분야</th><th>주요 학회/저작</th><th>핵심 주제</th><th>대표 연구</th></tr></thead><tbody>
<tr><td><strong>상징주의 AI</strong></td><td>AAAI-88</td><td>지식 표현, 정성적 추론, 계획(Planning)</td><td>B. Williams, “MINIMA” 3L. Kaelbling, “Goals as Parallel Program Specifications” 3</td></tr>
<tr><td><strong>연결주의</strong></td><td>NIPS ’88</td><td>역전파, 실세계 응용(자율주행, 문자 인식)</td><td>D. Pomerleau, “ALVINN” 4Y. LeCun, “A Theoretical Framework for Back-Propagation” 5</td></tr>
<tr><td><strong>확률적 추론</strong></td><td><em>Probabilistic Reasoning in Intelligent Systems</em> (Book)</td><td>베이지안 네트워크, 불확실성 추론</td><td>J. Pearl, Belief Propagation Algorithm 6</td></tr>
<tr><td><strong>강화 학습</strong></td><td><em>Machine Learning</em> (Journal)</td><td>시간차(TD) 학습, 예측 학습</td><td>R. Sutton, “Learning to Predict by the Methods of Temporal Differences” 8</td></tr>
<tr><td><strong>로봇 공학</strong></td><td>ICRA ’88</td><td>유연 로봇 제어, 경로 계획, 파지(Grasping)</td><td>F. Pfeiffer &amp; B. Gebler, “Dynamics and control of elastic robots” 9</td></tr>
</tbody></table>
<h2>2.  상징주의 AI의 정련과 한계</h2>
<p>1988년은 상징주의 AI가 수십 년간의 연구를 통해 지적인 성숙도의 정점에 도달했음을 보여주는 동시에, 그 내재적 한계가 뚜렷하게 드러난 시기였다. 미국 인공지능 학회(AAAI)의 연례 컨퍼런스인 AAAI-88은 이러한 양상을 가장 잘 보여주는 무대였다. 당시 학회는 과학과 공학 세션을 분리하려는 시도를 중단하고, 컴퓨터 비전, 지식 표현, 학습 등 전통적인 기술 하위 분야를 중심으로 프로그램을 재구성했다.3 이는 상징주의 패러다임 내에서 각 분야의 연구가 고도로 전문화되고 심화되었음을 시사한다. 그러나 바로 그 전문성의 심화 과정에서, 상징주의 AI가 실제 세계의 동적이고 불확실한 특성을 다루는 데 근본적인 어려움을 겪고 있다는 사실 또한 명백해지고 있었다.</p>
<h3>2.1  지식의 정교화: AAAI-88에서의 지식 표현과 추론</h3>
<p>지식 표현(Knowledge Representation, KR)은 상징주의 AI의 심장부와 같다. 1988년의 논의는 KR의 역할을 더욱 근본적으로 탐구하는 방향으로 나아갔다. 지식 표현은 단순히 정보를 저장하는 수단을 넘어, 현실 세계의 복잡한 대상을 기계 내부에서 다룰 수 있도록 대체하는 ’대리자(surrogate)’로서 기능한다.10 더 나아가, 어떤 표현 방식을 선택하는가 하는 행위 자체가 세상을 어떻게 인식하고 무엇을 중요하게 볼 것인지를 결정하는 ’존재론적 약속(ontological commitments)’이라는 철학적 고찰이 이루어졌다.10 이러한 깊이 있는 논의를 바탕으로, AAAI-88에서는 지식과 추론을 더욱 정교하게 다루려는 연구들이 주목받았다.</p>
<p>그중에서도 핵심적인 흐름은 **정성적 추론(Qualitative Reasoning)**이었다. 이는 미분방정식과 같은 정량적 수치 모델 없이, 오직 기호적 관계만을 이용해 물리적 시스템의 동작 원리를 추론하려는 시도였다. MIT의 Brian C. Williams가 발표하여 최우수 논문상을 수상한 “MINIMA: A Symbolic Approach to Qualitative Algebraic Reasoning“은 이러한 흐름의 정점에 있었다.3 이 연구는 대수적 제약 조건을 기호적으로 추론하여 시스템의 동작 가능 범위를 결정하는 방법을 제시함으로써, 복잡한 물리 시스템에 대한 인간의 상식적 추론 능력을 컴퓨터로 구현하고자 했다. 일리노이 대학의 Kenneth Forbus 역시 “Setting up Large-Scale Qualitative Models“라는 논문을 통해 대규모 시스템에 정성적 모델을 적용하는 방법론을 제시하며 이 분야의 연구를 심화시켰다.3 이 연구들은 상징주의 AI가 단순한 논리 문제를 넘어, 현실 세계의 물리적 현상을 이해하려는 야심 찬 목표를 향해 나아가고 있었음을 보여준다.</p>
<p><strong>학습 이론(Learning Theory)</strong> 분야에서도 상징주의적 접근은 중요한 성과를 냈다. 카네기 멜런 대학의 Steven Minton이 발표한 또 다른 최우수 논문상 수상작, “Qualitative Results Concerning the Utility of Explanation-Based Learning“은 설명 기반 학습(EBL)의 효용성을 분석했다.3 EBL은 소수의 예제로부터 도메인 지식을 활용하여 일반화된 규칙을 학습하는 기법으로, 기호적 지식 기반을 확장하는 핵심적인 방법론이었다. Minton의 연구는 EBL이 언제 학습 성능을 향상시키고 언제 저해하는지에 대한 이론적 기준을 제시했다. 한편, MIT의 Jonathan Amsterdam은 “Some Philosophical Problems with Formal Learning Theory“를 통해 형식 학습 이론이 가진 철학적 한계들을 지적하며, 기계 학습의 근본적인 가능성과 한계에 대한 성찰을 촉구했다.3 이처럼 AAAI-88에서는 상징주의 AI의 기술적 정교화와 함께, 그 방법론의 근본을 되묻는 깊이 있는 논의가 활발하게 이루어지고 있었다.</p>
<h3>2.2  행동의 재설계: 고전적 계획에서 반응형 시스템으로</h3>
<p>상징주의 AI의 또 다른 핵심 분야인 자동화된 계획(Automated Planning) 역시 1988년을 기점으로 중대한 패러다임 전환을 맞이하고 있었다. **고전적 계획(Classical Planning)**은 주어진 초기 상태, 목표 상태, 그리고 행동의 집합을 바탕으로 목표를 달성하기 위한 행동 순서를 탐색하는 문제로 정의된다.11 이 접근법은 세계가 정적이고(static), 완전히 관찰 가능하며(fully observable), 행동의 결과가 결정론적(deterministic)이라는 강력한 가정을 전제로 한다.12 이러한 가정은 체스나 블록 쌓기와 같은 제한된 문제에서는 유효했지만, 시시각각 변하고 예측 불가능한 실제 환경에서 동작해야 하는 로봇이나 자율 에이전트에게는 치명적인 한계였다.14</p>
<p>이러한 한계를 극복하기 위한 대안으로 **반응형 시스템(Reactive Systems)**이라는 새로운 아이디어가 부상했다. 이는 사전에 완벽한 계획을 세우기보다, 환경의 변화를 지속적으로 감지하고 그에 맞춰 즉각적으로 반응하는 데 초점을 맞추는 접근법이다.12 이 두 패러다임의 차이는 아래 표와 같이 요약될 수 있다.</p>
<table><thead><tr><th>특징</th><th>고전적 계획 (Classical Planning)</th><th>반응형 시스템 (Reactive Systems)</th></tr></thead><tbody>
<tr><td><strong>세계에 대한 가정</strong></td><td>정적, 결정론적, 완전 관찰 가능</td><td>동적, 불확실, 부분 관찰 가능</td></tr>
<tr><td><strong>지식 표현</strong></td><td>세계에 대한 완전한 기호적 모델 (예: STRIPS)</td><td>목표와 행동 간의 조건부 규칙</td></tr>
<tr><td><strong>계획 생성 방식</strong></td><td>사전 탐색 (Deliberative Search)</td><td>실시간 계산 (Real-time Computation)</td></tr>
<tr><td><strong>실행 방식</strong></td><td>계획-실행 분리 (Plan-then-Execute)</td><td>감지-행동 통합 (Sense-and-Act)</td></tr>
<tr><td><strong>대표적 연구</strong></td><td>STRIPS, TWEAK</td><td>L. Kaelbling (Gapps), R. Brooks (Subsumption Architecture)</td></tr>
</tbody></table>
<p>이러한 전환의 중심에 SRI International과 스탠포드 대학의 Leslie Pack Kaelbling이 AAAI-88에서 발표한 “Goals as Parallel Program Specifications“가 있었다.3 이 논문은 최우수 논문상 후보에 오를 만큼 큰 주목을 받았으며, 고전적 계획과 순수한 반응형 시스템 사이의 간극을 메우는 혁신적인 아이디어를 제시했다.17 Kaelbling은 <strong>Gapps</strong>라는 형식론을 제안했는데, 이는 프로그래머가 상징적인 목표 감소 규칙(symbolic goal-reduction rules)을 사용해 에이전트의 행동을 명세하면, 이를 효율적인 병렬 하드웨어 회로로 컴파일하는 방식이다.14</p>
<p>Gapps의 핵심은 계획을 ’탐색’이 아닌 ’계산’의 문제로 재정의한 데 있다. 에이전트의 목표(예: <code>maint(p)</code> - 명제 <code>p</code>를 유지하라)와 이를 달성하기 위한 하위 목표들이 논리 회로처럼 연결된다. 이 회로는 센서 입력을 받아 실시간으로 어떤 행동(예: <code>do(a)</code> - 행동 <code>a</code>를 수행하라)을 출력할지 결정한다.14 이는 세계 모델 전체를 탐색하는 대신, 현재 상황에 맞는 적절한 행동을 즉각적으로 계산해내는 방식으로, 실시간 반응성과 예측 불가능한 상황에 대한 강건함(robustness)을 확보할 수 있었다. Kaelbling의 연구는 ‘미리 생각하고 행동하는(think-then-act)’ 고전적 패러다임에서 벗어나, ‘지속적으로 감지하고 반응하는(sense-and-act)’ 새로운 패러다임으로의 전환을 이론적으로 정립했다는 점에서 중요한 의미를 가진다. 이는 로드니 브룩스(Rodney Brooks)의 ’Nouvelle AI’와 같은 포섭 구조(Subsumption Architecture)와 철학적 궤를 같이하며, 이후 지능형 로봇과 자율 에이전트 연구에 지대한 영향을 미쳤다.16</p>
<h3>2.3  전문가 시스템의 황혼과 ‘AI 겨울’</h3>
<p>상징주의 AI가 학문적으로는 정교화의 길을 걷고 있었지만, 산업계에서는 그 한계가 명확히 드러나며 혹독한 시기를 맞이하고 있었다. 1980년대 AI 붐을 이끌었던 주역은 단연 **전문가 시스템(Expert Systems)**이었다. 전문가 시스템은 특정 분야 전문가의 지식을 ‘IF-THEN’ 형태의 규칙(rule)으로 추출하여 컴퓨터에 내장함으로써, 비전문가도 전문가 수준의 문제 해결 능력을 발휘할 수 있도록 돕는 시스템이었다.2 XCON과 같은 초기 성공 사례는 기업들의 엄청난 투자를 이끌어냈고, 1985년경에는 AI 시장 규모가 10억 달러를 넘어섰다.1</p>
<p>그러나 화려한 성공 뒤에는 근본적인 문제가 도사리고 있었다. 바로 <strong>‘지식 획득 병목(Knowledge acquisition bottleneck)’</strong> 현상이다.2 전문가의 머릿속에 있는 방대하고 복잡한 지식, 특히 말로 표현하기 어려운 암묵적 지식(tacit knowledge)을 명시적인 컴퓨터 규칙으로 변환하는 작업은 상상 이상으로 어려웠다.2 지식 공학자(knowledge engineer)들은 전문가를 인터뷰하고 그들의 문제 해결 과정을 분석했지만, 전문가는 종종 자신이 무엇을 아는지, 어떻게 결정을 내리는지조차 명확히 설명하지 못했다.2 설상가상으로, 자신의 지식이 시스템으로 대체될 것을 우려한 전문가들의 비협조적인 태도도 프로젝트의 발목을 잡았다.2</p>
<p>이러한 문제로 인해 대부분의 전문가 시스템 프로젝트는 막대한 비용과 시간을 투자하고도 기대에 미치지 못하는 결과를 낳았고, 이는 AI 기술에 대한 환멸로 이어졌다. 결정타는 1987년에 발생한 <strong>LISP 머신 시장의 붕괴</strong>였다. LISP는 상징주의 AI 연구의 표준 언어였고, Symbolics와 같은 회사들은 LISP 프로그램을 효율적으로 실행하기 위한 전용 하드웨어인 LISP 머신을 판매하며 거대한 시장을 형성했다.1 하지만 Sun Microsystems와 같은 회사들이 출시한 범용 워크스테이션의 성능이 비약적으로 향상되면서, 비싼 LISP 전용 머신을 구매할 이유가 사라졌다.1 불과 1년 만에 5억 달러 규모의 산업이 증발해버린 것이다.</p>
<p>이 사건은 전문가 시스템의 실패와 맞물려 AI 산업 전체에 대한 신뢰를 무너뜨리는 기폭제가 되었다. 기업들은 AI 부서를 폐쇄했고, 정부와 투자자들은 자금 지원을 중단했다. 이로써 1987년부터 1990년대 초반까지 이어지는 두 번째 **‘AI 겨울(AI Winter)’**이 본격적으로 시작되었다.1 상징주의 AI의 황금기는 그 한계를 명백히 드러내며 막을 내리고 있었다.</p>
<h2>3.  연결주의의 귀환과 실용적 가능성의 증명</h2>
<p>상징주의 AI가 겨울을 맞이하던 1988년, 아이러니하게도 한때 ’죽은 기술’로 여겨졌던 연결주의(Connectionism)는 화려한 부활의 신호탄을 쏘아 올렸다. 1969년 민스키와 파퍼트의 저서 『Perceptrons』에 의해 이론적 한계가 지적된 이후 긴 암흑기를 거쳤던 신경망 연구는, 1980년대 중반 다층 퍼셉트론을 학습시킬 수 있는 역전파(Backpropagation) 알고리즘의 재발견과 함께 새로운 전기를 맞았다.21 1988년은 이러한 부활이 단순한 학문적 호기심을 넘어, 실세계의 복잡한 문제를 해결할 수 있는 실용적 가능성을 품고 있음을 증명한 해였다. 이 시기 연구자들은 강력해진 컴퓨터 하드웨어의 도움을 받아, 이론적 토대를 다지고 실제 응용 사례를 만들어내며 연결주의의 새로운 시대를 열었다.</p>
<h3>3.1  NIPS ’88: 부활의 신호탄</h3>
<p>1988년 미국 덴버에서 열린 제1회 **신경 정보 처리 시스템 학회(Neural Information Processing Systems, NIPS)**는 연결주의의 부활을 공식적으로 알리는 상징적인 사건이었다.22 이 학회는 신경과학, 컴퓨터 과학, 인지 과학 등 다양한 분야의 연구자들이 모여 신경망 기반의 정보 처리 모델을 논의하는 장을 마련했다. NIPS ’88에서 발표된 논문들은 당시 연결주의 연구가 얼마나 넓고 깊게 확장되고 있었는지를 명확히 보여준다.</p>
<p>주요 발표 주제는 매우 다채로웠다. 제약 만족 문제(constraint satisfaction problems)를 해결하기 위한 ‘자동 지역 어닐링(Automatic Local Annealing)’ 기법 23, 컴퓨터 비전에서의 모델 매칭과 지각적 조직화를 위한 신경망 23, 그리고 인간의 학습 과정을 모방하려는 ‘자기 학습 신경망(A Self-Learning Neural Network)’ 24 등 이론적 탐구가 활발히 이루어졌다. 동시에, 아날로그 VLSI 칩을 이용한 신경망 하드웨어 구현 24, 필기체 서명 인식 24, 음소 분류 24 등 구체적인 응용 연구들도 대거 발표되었다. NIPS의 등장은 연결주의가 더 이상 변방의 학문이 아니라, AI의 주류 패러다임 중 하나로 당당히 자리매김했음을 선언하는 것과 같았다.</p>
<h3>3.2  역전파 알고리즘의 이론적 토대: 얀 르쿤의 공헌</h3>
<p>연결주의 부활의 핵심 동력은 단연 <strong>역전파(Backpropagation) 알고리즘</strong>이었다. 그러나 1988년 이전까지 역전파는 주로 경험적으로 유효성이 입증된 ’기술’에 가까웠으며, 그 작동 원리에 대한 깊은 이론적 이해는 부족했다. 이러한 상황에서 프랑스 출신의 젊은 연구자 얀 르쿤(Yann LeCun)이 1988년 Connectionist Models Summer School에서 발표한 논문, “A Theoretical Framework for Back-Propagation“은 역전파에 견고한 수학적 토대를 제공했다는 점에서 기념비적인 성과로 평가받는다.5</p>
<p>르쿤은 이 논문에서 최적 제어 이론(optimal control theory)에서 영감을 받아 **라그랑지안 형식주의(Lagrangian formalism)**를 도입했다.5 그는 다층 신경망의 학습 과정을 ’비선형 제약 조건(non-linear constraints)을 갖는 최적화 문제’로 재정의했다. 이 프레임워크에서, 네트워크의 전체 비용 함수는 두 부분으로 구성된 라그랑지안 함수(<span class="math math-inline">\mathcal{L}</span>)로 표현된다. 첫 번째 부분은 네트워크의 최종 출력과 목표값 사이의 오차를 나타내는 목적 함수(<span class="math math-inline">E</span>)이고, 두 번째 부분은 각 계층의 상태(<span class="math math-inline">X_p(k)</span>)가 이전 계층의 상태(<span class="math math-inline">X_p(k-1)</span>)와 가중치 행렬(<span class="math math-inline">W(k)</span>)에 의해 어떻게 결정되는지를 나타내는 동역학(dynamics) 제약 조건이다.5</p>
<p>라그랑지안 함수는 다음과 같이 표현될 수 있다. 여기서 <span class="math math-inline">p</span>는 패턴 인덱스, <span class="math math-inline">k</span>는 계층 인덱스, <span class="math math-inline">\lambda</span>는 라그랑주 승수, <span class="math math-inline">F</span>는 활성화 함수를 나타낸다.</p>
<p><span class="math math-display">
\mathcal{L}(X, \lambda, W) = E(X) + \sum_{p,k} \lambda_{p,k}^T (X_p(k) - F(W(k)X_p(k-1)))
</span><br />
이러한 재정의를 통해, 역전파 알고리즘은 단순히 연쇄 법칙(chain rule)을 영리하게 적용한 것을 넘어, 제약이 있는 최적화 문제를 푸는 일반적인 수학적 원리의 한 사례임이 증명되었다.5 르쿤의 이 연구는 역전파 알고리즘에 대한 이론적 깊이를 더하고, 이후 가중치 공유(weight sharing)나 네트워크 구조에 제약을 가하는 등의 다양한 변형 알고리즘을 개발하는 데 중요한 이론적 발판을 제공했다. 이는 경험적 성공에 머물렀던 연결주의를 엄밀한 과학의 반열에 올려놓는 중요한 기여였다.</p>
<h3>3.3  실세계 응용의 서막: ALVINN과 필기체 우편번호 인식</h3>
<p>이론적 기반이 다져지는 동시에, 연결주의는 실세계의 복잡한 문제를 해결할 수 있는 잠재력을 입증하기 시작했다. 1988년 NIPS 학회에서 발표된 두 개의 연구, ALVINN과 필기체 우편번호 인식 시스템은 이러한 흐름을 상징적으로 보여준다. 이들은 픽셀과 같은 저수준의 원시 데이터(raw data)로부터 직접 의미 있는 정보를 추출하여 실제적인 과업을 수행할 수 있다는 신경망의 강력한 능력을 세상에 알렸다.</p>
<p>카네기 멜런 대학의 Dean Pomerleau가 발표한 **ALVINN(Autonomous Land Vehicle In a Neural Network)**은 신경망을 이용한 자율주행 연구의 효시로 꼽힌다.4 ALVINN은 CMU의 자율주행 테스트 차량인 NAVLAB을 제어하기 위해 설계된 3계층 역전파 네트워크였다.4</p>
<ul>
<li>
<p><strong>아키텍처:</strong> 네트워크의 입력층은 차량 전방에 설치된 카메라로부터 30x32 픽셀 크기의 비디오 이미지를 받아들이는 ’망막’으로 구성되었다. 이 960개의 입력 유닛은 29개의 은닉 유닛과 완전 연결되고, 은닉층은 다시 45개의 출력 유닛과 연결되었다. 출력 유닛들은 차량이 나아가야 할 방향(회전 곡률)을 선형적으로 표현했다.4</p>
</li>
<li>
<p><strong>학습 방식:</strong> ALVINN의 가장 혁신적인 부분은 학습 방식에 있었다. 실제 도로를 주행하며 방대한 양의 학습 데이터를 수집하는 것은 비효율적이고 위험했다. Pomerleau는 이 문제를 해결하기 위해 다양한 도로 형태, 조명 조건, 노이즈를 가진 **‘시뮬레이션된 도로 생성기’**를 개발하여 1200개의 가상 도로 이미지를 만들고, 이를 이용해 네트워크를 훈련시켰다.4 40 에포크(epoch)의 학습 후, ALVINN은 실제 NAVLAB 차량에 탑재되어 CMU 캠퍼스 내 도로를 성공적으로 자율주행했다.4</p>
</li>
<li>
<p><strong>의의:</strong> ALVINN의 성공은 신경망이 복잡한 시각 정보를 실시간으로 처리하여 물리적 세계의 로봇을 제어하는 고도의 지각-행동(perception-action) 과업을 수행할 수 있음을 최초로 입증한 사례 중 하나였다. 이는 추상적인 기호 처리에서 벗어나, 센서 데이터에 직접 기반하여 행동하는 ’체화된 지능(embodied intelligence)’의 가능성을 보여주었으며, 오늘날 딥러닝 기반 자율주행 연구의 직접적인 원형이 되었다.30</p>
</li>
</ul>
<p>같은 해 NIPS에서 Bell Labs의 연구팀(John Denker, Isabelle Guyon, Yann LeCun 등)이 발표한 **“Neural Network Recognizer for Hand-Written Zip Code Digits”**는 패턴 인식 분야에서 신경망의 실용성을 증명했다.23</p>
<ul>
<li>
<p><strong>데이터와 성능:</strong> 이 연구는 실제 미국 우편물에서 수집한 필기체 우편번호 숫자 이미지를 사용하여 신경망을 훈련하고 테스트했다.23 이는 당시 사용되던 USPS 데이터셋의 전신으로, 통제된 환경이 아닌 실제 세계의 노이즈 섞인 데이터에 대해 신경망이 얼마나 강건하게 동작할 수 있는지를 보여주었다. 시스템은 분류 불가능한 소수의 예제를 제외하고 매우 낮은 오류율을 달성하여 당시 최첨단 인식기들과 비교해도 손색없는 성능을 보였다.23</p>
</li>
<li>
<p><strong>영향:</strong> 이 연구의 성공은 얀 르쿤이 이듬해인 1989년 발표한 기념비적인 논문, “Backpropagation Applied to Handwritten Zip Code Recognition“으로 직접 이어졌다.32 이 후속 연구에서는 가중치 공유(weight sharing), 지역적 수용장(local receptive fields)과 같은 개념이 도입되어 현대 **합성곱 신경망(Convolutional Neural Networks, CNN)**의 시초가 된 <strong>LeNet</strong> 아키텍처가 탄생했다.33 따라서 1988년의 우편번호 인식 연구는 딥러닝 시대의 이미지 인식 기술을 연 결정적인 발판이었다고 평가할 수 있다.</p>
</li>
</ul>
<p>이처럼 실용적인 응용의 성공은 연결주의에 대한 학계와 산업계의 인식을 바꾸는 결정적인 계기가 되었다. ALVINN과 같은 야심 찬 공학적 도전은 신경망의 잠재력을 극적으로 보여주었고, 이는 다시 르쿤의 연구처럼 그 잠재력을 뒷받침할 이론적 탐구를 촉진했다. 이론적 엄밀함은 다시 더 정교하고 강력한 응용을 가능하게 했다. 1988년은 이처럼 <strong>‘응용이 이론을 이끌고, 이론이 다시 응용을 가능하게 하는’</strong> 선순환 구조가 본격적으로 작동하기 시작한 해였으며, 이는 이후 딥러닝 혁명을 이끈 핵심 동력이 되었다.</p>
<h2>4.  현대 AI의 패러다임을 정립한 이론적 혁신</h2>
<p>1988년은 연결주의의 부활뿐만 아니라, 현대 AI의 지적 지형을 근본적으로 바꾼 두 가지 거대한 이론적 혁신이 동시에 일어난 해이기도 하다. 상징주의 AI가 직면했던 가장 큰 난제는 바로 현실 세계에 만연한 불확실성과, 장기적인 목표를 달성하기 위해 경험으로부터 순차적으로 학습하는 능력이었다. 규칙 기반 시스템은 예외와 불확실성 앞에서 쉽게 무너졌고, 새로운 상황에 적응하는 학습 메커</p>
<p>니즘이 부재했다. 1988년, 유디 펄과 리처드 서튼은 각각 이 두 가지 난제를 정면으로 돌파하는 새로운 이론적 패러다임을 제시했다. 이들의 연구는 AI가 어떻게 불확실한 세상 속에서 추론하고, 어떻게 경험을 통해 행동을 개선해 나가는지에 대한 수학적 청사진을 제공했다.</p>
<h3>4.1  불확실성과의 조우: 유디 펄과 베이지안 네트워크 혁명</h3>
<p>1988년, UCLA의 교수 유디 펄(Judea Pearl)은 그의 기념비적인 저서 **『Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference』**를 출간했다.6 이 책은 AI 분야에 확률과 통계학의 원리를 체계적으로 도입하여, 불확실성 하에서의 추론(reasoning under uncertainty) 문제를 다루는 방식을 근본적으로 바꾸어 놓았다.6 펄 이전에도 확률을 AI에 적용하려는 시도는 있었지만, 변수가 많아질수록 계산량이 폭발적으로 증가하는 문제 때문에 실용적인 해법을 찾지 못하고 있었다. 펄은 이 문제를 해결하기 위해 <strong>베이지안 네트워크(Bayesian Networks)</strong>, 또는 **믿음 네트워크(Belief Networks)**라는 강력한 도구를 제시했다.</p>
<ul>
<li>
<p><strong>핵심 개념:</strong></p>
</li>
<li>
<p><strong>베이지안 네트워크:</strong> 베이지안 네트워크는 변수들 간의 <strong>조건부 독립성(conditional independence)</strong> 관계를 **방향성 비순환 그래프(Directed Acyclic Graph, DAG)**로 표현하는 확률적 그래피컬 모델이다.7 그래프의 각 노드(node)는 확률 변수를, 노드를 연결하는 간선(edge)은 변수 간의 직접적인 인과적 또는 확률적 의존성을 나타낸다. 이 구조를 통해, 수천 개의 변수가 얽힌 복잡한 결합 확률 분포(joint probability distribution)를 소수의 지역적 조건부 확률(local conditional probabilities)의 곱으로 분해하여 효율적으로 표현하고 계산할 수 있게 된다.6</p>
</li>
<li>
<p><strong>믿음 전파 (Belief Propagation):</strong> 펄은 베이지안 네트워크 위에서 효율적으로 추론을 수행하는 알고리즘인 ’믿음 전파’를 제안했다.37 이 알고리즘은 특정 변수의 상태가 관측되었을 때(증거, evidence), 그 정보가 네트워크를 따라 전파되면서 다른 모든 변수들의 확률, 즉 ’믿음(belief)’을 업데이트하는 메시지 전달(message-passing) 방식이다.39 부모 노드로부터는 인과적 지지를 나타내는 <strong><span class="math math-inline">\pi</span> 메시지</strong>를 받고, 자식 노드로부터는 진단적 지지를 나타내는 <strong><span class="math math-inline">\lambda</span> 메시지</strong>를 받아, 각 노드는 자신의 최종 믿음(<span class="math math-inline">BEL(x)</span>)을 계산한다.40</p>
</li>
<li>
<p><strong>핵심 수식:</strong> 노드 <span class="math math-inline">X</span>의 최종 믿음 <span class="math math-inline">BEL(x)</span>은 다음과 같이 계산된다. 여기서 <span class="math math-inline">\alpha</span>는 정규화 상수이다.40</p>
<p><span class="math math-display">
BEL(x) = \alpha \lambda(x) \pi(x)
</span><br />
이때, 부모 노드들(<span class="math math-inline">U</span>)로부터 받는 결합된 <span class="math math-inline">\pi</span> 메시지는 다음과 같이 계산된다.40</p>
<p><span class="math math-display">
\pi(x) = \sum_{u} P(X=x \vert U=u) \prod_{k} \pi_{U_k}(u_k)
</span></p>
</li>
<li>
<p><strong>의의:</strong> 펄의 연구는 ’참’과 ’거짓’만으로 세상을 보던 상징주의 AI의 경직된 틀에서 벗어나, 불확실성을 수학적으로 엄밀하고 효율적으로 다룰 수 있는 길을 열었다. 이는 의료 진단, 금융 예측, 고장 분석 등 불완전한 정보로부터 합리적인 결론을 도출해야 하는 거의 모든 실세계 문제에 적용될 수 있는 강력한 프레임워크를 제공했다.6 특히, 베이지안 네트워크는 변수 간의 의존 관계를 명시적으로 보여주기 때문에, 시스템이 왜 그런 결론을 내렸는지 그 추론 과정을 설명할 수 있다는 장점이 있다. 이는 오늘날 **설명 가능한 AI(Explainable AI, XAI)**의 중요한 이론적 토대가 되었다.36 펄의 업적은 AI를 논리학의 울타리에서 확률과 통계학의 광대한 세계로 이끌어낸 혁명이었다.</p>
</li>
</ul>
<h3>4.2  경험을 통한 학습의 공식화: 리처드 서튼과 시간차 학습</h3>
<p>펄이 불확실성 문제를 해결하고 있을 때, 또 다른 한편에서는 AI가 어떻게 환경과의 상호작용을 통해 스스로 행동을 학습할 수 있는지에 대한 근본적인 질문이 탐구되고 있었다. 1988년, 당시 GTE 연구소에 있던 리처드 서튼(Richard Sutton)은 <em>Machine Learning</em> 저널에 **“Learning to Predict by the Methods of Temporal Differences”**라는 제목의 논문을 발표했다.8 이 논문은 현대 **강화학습(Reinforcement Learning)**의 이론적 초석을 놓은 것으로 평가받으며, AI 역사상 가장 영향력 있는 논문 중 하나로 꼽힌다.</p>
<ul>
<li>
<p><strong>핵심 개념:</strong></p>
</li>
<li>
<p><strong>시간차(TD) 학습:</strong> 서튼이 제안한 시간차 학습의 핵심 아이디어는 혁신적이었다. 기존의 지도학습 방식은 예측(<span class="math math-inline">P_t</span>)과 실제 최종 결과(<span class="math math-inline">z</span>) 사이의 오차(<span class="math math-inline">z - P_t</span>)를 이용해 학습했다. 이는 최종 결과를 알 때까지 학습을 미뤄야 한다는 단점이 있었다.43 반면, TD 학습은 최종 결과를 기다리는 대신, **시간적으로 연속된 두 예측(<span class="math math-inline">P_t</span>와 <span class="math math-inline">P_{t+1}</span>) 사이의 차이(<span class="math math-inline">P_{t+1} - P_t</span>)**를 학습 신호로 사용한다.8 즉, 더 나중에 한 예측이 더 많은 정보를 담고 있을 것이라는 가정하에, 현재의 예측을 바로 다음 순간의 예측에 가깝도록 수정해 나가는 것이다. 이는 마치 ‘추측으로부터 또 다른 추측을 배우는(learning a guess from a guess)’ 과정과 같으며, **부트스트래핑(bootstrapping)**의 원리를 학습에 도입한 것이다.45</p>
</li>
<li>
<p><strong>TD(<span class="math math-inline">\lambda</span>) 알고리즘:</strong> 서튼은 이 논문에서 한 단계 앞의 예측만을 사용하는 TD(0)와, 에피소드가 끝날 때까지 기다려 모든 보상을 합산하는 몬테카를로(Monte Carlo) 방법 사이를 매끄럽게 일반화하는 <strong>TD(<span class="math math-inline">\lambda</span>)</strong> 알고리즘을 제시했다.46 <span class="math math-inline">\lambda</span>는 0과 1 사이의 값으로, 얼마나 먼 미래의 예측까지 현재 학습에 반영할지를 조절하는 파라미터다. <span class="math math-inline">\lambda=0</span>이면 순수한 TD(0)가 되고, <span class="math math-inline">\lambda=1</span>이면 몬테카를로 방법과 유사해진다.45</p>
</li>
<li>
<p><strong>핵심 수식:</strong> TD(<span class="math math-inline">\lambda</span>) 알고리즘에서 가중치(<span class="math math-inline">w</span>)를 업데이트하는 규칙은 다음과 같이 표현된다. 여기서 <span class="math math-inline">\alpha</span>는 학습률, <span class="math math-inline">\nabla_w P_k</span>는 예측 <span class="math math-inline">P_k</span>에 대한 가중치의 그래디언트(gradient)를 의미한다.46</p>
<p><span class="math math-display">
\Delta w_t = \alpha (P_{t+1} - P_t) \sum_{k=1}^{t} \lambda^{t-k} \nabla_w P_k
</span></p>
</li>
<li>
<p><strong>의의:</strong> 서튼의 연구는 보상(reward)이라는 신호를 통해, 어떤 행동이 장기적으로 더 좋은 결과를 가져오는지를 시행착오를 통해 학습하는 강화학습의 핵심 메커니즘을 수학적으로 정립했다. 이는 <strong>시간적 신용 할당 문제(temporal credit assignment problem)</strong>, 즉 어떤 행동이 나중에 받은 보상에 얼마나 기여했는지를 알아내는 어려운 문제를 해결하는 효과적인 방법을 제공했다. TD 학습은 이후 Q-러닝과 같은 알고리즘으로 발전했으며, 딥마인드의 AlphaGo를 비롯한 현대 심층 강화학습(Deep Reinforcement Learning) 시스템의 근간을 이루는 가장 중요한 이론이 되었다.48</p>
</li>
</ul>
<table><thead><tr><th>구분</th><th>지도학습 (Supervised Learning)</th><th>시간차 학습 (Temporal Difference Learning)</th></tr></thead><tbody>
<tr><td><strong>학습 신호</strong></td><td>예측과 실제 정답(결과)의 차이</td><td>시간적으로 연속된 예측 간의 차이</td></tr>
<tr><td><strong>업데이트 시점</strong></td><td>최종 결과가 주어진 후 일괄 업데이트</td><td>매 시간 단계마다 점진적 업데이트</td></tr>
<tr><td><strong>정보 효율성</strong></td><td>최종 결과가 나올 때까지의 경험을 보관해야 함</td><td>더 적은 메모리와 계산으로 즉각적인 학습 가능</td></tr>
<tr><td><strong>적용 분야</strong></td><td>정적인 데이터셋 기반의 분류, 회귀</td><td>동적 환경과의 상호작용을 통한 순차적 의사결정</td></tr>
</tbody></table>
<p>결론적으로, 1988년은 현대 AI를 떠받치는 세 개의 기둥이 동시에 세워진 해였다. 펄의 확률적 추론은 AI에게 <strong>불확실한 세상 속에서 합리적으로 사고하는 능력</strong>을, 서튼의 강화학습은 <strong>경험을 통해 목표 지향적 행동을 배우는 능력</strong>을, 그리고 르쿤을 비롯한 연결주의자들은 <strong>방대한 원시 데이터로부터 세상을 인식하는 능력</strong>을 부여했다. 하나의 완전한 지능형 에이전트가 갖추어야 할 이 세 가지 핵심 요소의 이론적 청사진이 같은 해에 마련되었다는 사실은 결코 우연이 아니다. 이는 상징주의 AI의 한계가 명확해진 시점에서, AI 연구의 패러다임이 근본적으로 전환되고 있었음을 보여주는 강력한 증거이다.</p>
<h2>5.  물리 세계와의 상호작용, 로봇 공학의 진화</h2>
<p>AI의 이론적 지평이 확장되던 1988년, 로봇 공학 분야는 이러한 지적 성과를 물리적 세계와 연결하는 중요한 역할을 수행하고 있었다. 로봇은 AI 알고리즘이 가상 세계를 벗어나 실제 환경의 복잡성과 불확실성에 직면하게 만드는 궁극적인 시험대였다. 이 시기 로봇 연구는 한편으로는 로봇 자체의 물리적 한계를 극복하기 위한 정밀한 동역학 모델링과 제어 기술을 발전시켰고, 다른 한편으로는 AI의 새로운 패러다임들을 받아들여 로봇을 더욱 지능적인 존재로 만들려는 시도를 활발히 전개했다.</p>
<h3>5.1  ICRA ’88: 복잡한 현실 세계의 로봇 제어</h3>
<p>1988년에 열린 **IEEE 국제 로봇 및 자동화 학회(International Conference on Robotics and Automation, ICRA)**는 당시 로봇 연구의 최전선을 보여주는 장이었다.9 발표된 논문들은 로봇이 이상적인 강체(rigid body)가 아니라, 실제 물리 법칙의 지배를 받는 복잡한 기계 시스템이라는 인식을 바탕으로 하고 있었다.9</p>
<ul>
<li>
<p><strong>유연/탄성 로봇(Flexible/Elastic Robots):</strong> 고속으로 정밀한 작업을 수행하기 위해서는 로봇 팔의 미세한 휘어짐이나 관절의 탄성을 무시할 수 없었다. ICRA ’88에서는 이러한 **유연성(flexibility)과 탄성(elasticity)**을 고려한 동역학 모델링 및 제어에 관한 다수의 논문이 발표되었다.9 Friedrich Pfeiffer 등의 “A multistage-approach to the dynamics and control of elastic robots“나 Alessandro De Luca의 “Dynamic control of robots with joint elasticity“와 같은 연구들은 유연한 로봇을 안정적으로 제어하기 위한 수학적 모델과 제어 기법을 제시했다.9 이는 로봇의 성능을 물리적 한계까지 끌어올리기 위한 핵심적인 연구 방향이었다.</p>
</li>
<li>
<p><strong>중복 로봇(Redundant Robots):</strong> 인간의 팔처럼 작업에 필요한 최소한의 자유도보다 더 많은 관절을 가진 <strong>중복 로봇</strong>은 장애물을 피하거나 복잡한 자세를 취하는 데 유리하지만, 제어가 훨씬 복잡하다. ICRA ’88에서는 이러한 중복 로봇의 무한한 역기구학 해(inverse kinematics solutions) 중에서 최적의 해를 찾거나, 로봇이 특정 자세에서 움직임이 제한되는 특이점(singularity)을 회피하는 방법에 대한 연구들이 활발히 논의되었다.9 Rajiv V. Dubey 등의 “An efficient gradient projection optimization scheme for a seven-degree-of-freedom redundant robot“과 같은 연구는 중복성을 활용하여 로봇의 작업 능력을 극대화하려는 시도였다.9</p>
</li>
</ul>
<p>이처럼 ICRA ’88의 주요 연구들은 로봇 공학이 추상적인 기구학을 넘어, 실제 세계의 복잡한 물리 현상을 정밀하게 다루는 성숙한 공학 분야로 발전하고 있었음을 보여준다.</p>
<h3>5.2  지능형 로봇을 향한 탐색</h3>
<p>로봇 제어 기술의 발전과 함께, 로봇에 더 높은 수준의 ’지능’을 부여하려는 AI 기술과의 융합도 본격화되고 있었다. 이는 단순히 정해진 경로를 따라 움직이는 것을 넘어, 스스로 환경을 인식하고 판단하여 목표를 달성하는 자율적인 로봇을 향한 탐색이었다.</p>
<ul>
<li>
<p><strong>경로 계획 및 장애물 회피:</strong> 로봇이 복잡하고 동적인 환경에서 스스로 경로를 계획하고 장애물을 피하는 것은 지능형 로봇의 핵심 과제였다. ICRA ’88에서는 장애물이 존재하는 환경에서 최적의 경로를 생성하는 알고리즘 9, 여러 로봇이 충돌 없이 움직이는 경로를 실시간으로 생성하는 기법 등이 발표되었다.9</p>
</li>
<li>
<p><strong>파지 및 조작(Grasping and Manipulation):</strong> 물체를 집고 다루는 능력은 로봇이 실제 작업을 수행하기 위한 필수 기능이다. 인간의 손재주를 모방하려는 <strong>다지(multi-fingered) 로봇 핸드</strong>의 운동학과 제어에 대한 연구, 그리고 주어진 물체를 안정적으로 파지하는 방법을 찾는 연구가 ICRA ’88에서 중요하게 다루어졌다.9 Thea Iberall 등의 “Knowledge-based prehension: capturing human dexterity“는 인간의 파지 전략에서 지식을 추출하여 로봇에 적용하려는 시도였다.9</p>
</li>
<li>
<p><strong>로봇 학습:</strong> 특히 주목할 만한 점은 AI 분야의 새로운 학습 패러다임이 로봇 공학에 빠르게 접목되기 시작했다는 것이다.</p>
</li>
<li>
<p>AAAI-88에서는 Benjamin Kuipers와 Yung-Tai Byun이 발표한 “A Robust, Qualitative Method for Robot Spatial Learning“이 최우수 논문상 후보에 올랐다.3 이 연구는 로봇이 미지의 환경을 탐험하며 스스로 지도를 작성하고 공간을 학습하는 방법을 제시했다.</p>
</li>
<li>
<p>ICRA ’88에서는 <strong>신경망</strong>을 로봇 제어에 적용하려는 선구적인 시도들이 등장했다. Yagyensh C. Pati 등은 신경망을 이용해 로봇의 <strong>촉각 인지(tactile perception)</strong> 능력을 구현하고자 했고, Michael Kuperstein은 신경망을 통해 감각-운동 제어(sensory-motor control)를 적응적으로 학습하는 모델을 제시했다.9 이는 앞서 살펴본 ALVINN 프로젝트와 함께, AI와 로봇 공학의 융합이 단순한 기호적 계획을 넘어, 데이터 기반의 학습을 통해 이루어지고 있었음을 보여주는 중요한 증거이다.</p>
</li>
</ul>
<p>이러한 흐름은 AI의 발전이 더 이상 추상적인 문제 해결에만 머무르지 않고, 물리적 세계와 상호작용하는 ’체화된 지능(embodied intelligence)’을 향해 나아가고 있었음을 시사한다. 로봇 공학은 AI에게 현실 세계라는 가장 혹독하고 정직한 피드백을 제공하는 실험장이었고, 이 둘의 상호작용은 이후 수십 년간 두 분야의 발전을 가속화하는 핵심 동력이 되었다.</p>
<p>한편, 이러한 기술적 진보의 배경에는 종종 실패한 것으로 평가받는 거대 프로젝트의 보이지 않는 유산이 있었다. 1982년 일본 통상산업성(MITI) 주도로 시작된 <strong>제5세대 컴퓨터 시스템(Fifth Generation Computer Systems, FGCS)</strong> 프로젝트는 논리 프로그래밍에 기반한 대규모 병렬 추론 컴퓨터를 개발하여 AI 시대를 선도하겠다는 야심 찬 목표를 내걸었다.53 1988년은 이 10개년 프로젝트의 중간 단계를 마감하고 그 성과를 발표하는 중요한 해였다.55</p>
<p>FGCS는 병렬 추론 머신(PIM) 프로토타입과 병렬 운영체제(PIMOS), 그리고 커널 언어인 KL1 등 상당한 기술적 성과를 거두었다.56 그러나 자연어 이해, 전문가 시스템 등 당초 내걸었던 거창한 AI 응용 목표를 달성하는 데는 실패했고, 결국 상업적으로 성공하지 못한 채 막을 내렸다.53 하지만 FGCS의 진정한 영향은 그 직접적인 결과물이 아니라, 전 세계 AI 연구 지형에 미친 간접적인 파급 효과에 있었다. FGCS의 등장은 미국과 유럽에 큰 충격을 주었고, 이에 대응하기 위한 대규모 AI 연구 개발 프로젝트(예: 미국의 MCC, 유럽의 ESPRIT)를 촉발시켰다.57 1980년대 AI 연구 붐을 이끈 막대한 자금은 상당 부분 이러한 국가적 경쟁 구도 속에서 투입되었다. 즉, 1988년에 꽃피운 여러 혁신적인 연구들은 FGCS가 만들어낸 전 지구적 연구 경쟁과 풍부한 연구 자금이라는 토양 위에서 가능했던 것이다. 역설적으로, FGCS가 논리 프로그래밍이라는 단일한 기술 경로에 집중하다 실패한 것은, 펄, 서튼, 르쿤 등이 제시한 확률, 학습, 데이터 기반의 대안적 접근법이 얼마나 유망한지를 더욱 돋보이게 만드는 거대한 ‘반면교사’ 역할을 하기도 했다. 따라서 FGCS는 비록 실패한 프로젝트로 기록될지라도, 1988년 AI 패러다임 전환의 중요한 촉매제였다고 재평가할 수 있다.</p>
<h2>6. 결론: 1988년의 유산 - 미래를 향한 파종</h2>
<p>1988년은 인공지능의 역사에서 가장 극적인 전환점 중 하나로 기록되어야 마땅하다. 표면적으로는 상업적 기대가 무너지며 ’AI 겨울’이라는 혹독한 침체기가 시작된 해였지만, 그 차가운 지표면 아래에서는 미래 AI 혁명을 가능하게 할 가장 중요한 지적 씨앗들이 동시에 뿌려지고 싹을 틔운, 역사상 가장 비옥한 ’지적 파종기’였다.</p>
<p>본 보고서에서 살펴본 바와 같이, 1988년의 AI 지형은 여러 패러다임의 명암이 극명하게 교차하는 역동적인 모습을 보였다.</p>
<ul>
<li>
<p><strong>상징주의 AI</strong>는 수십 년간의 발전을 통해 정성적 추론, 설명 기반 학습 등 고도로 정교한 이론을 구축하며 지적 성숙도의 정점을 찍었다. 그러나 동시에 지식 획득의 본질적 어려움과 동적 세계에 대한 취약성을 드러내며 그 한계에 봉착했다. 고전적 계획에서 반응형 시스템으로의 전환은 이러한 한계를 극복하려는 내부의 몸부림이었으며, 상징주의 시대의 황혼을 알리는 신호탄이었다.</p>
</li>
<li>
<p><strong>연결주의</strong>는 긴 암흑기를 깨고 화려하게 부활했다. 역전파 알고리즘에 대한 얀 르쿤의 이론적 정립은 신경망에 수학적 견고함을 부여했으며, ALVINN과 필기체 숫자 인식 시스템의 성공은 신경망이 더 이상 이론 속의 모델이 아니라 실세계의 복잡한 문제를 해결할 수 있는 강력한 공학적 도구임을 입증했다.</p>
</li>
<li>
<p>무엇보다 중요한 것은, 현대 AI를 정의하는 두 개의 새로운 거대한 기둥, 즉 <strong>확률적 추론</strong>과 <strong>강화 학습</strong>의 이론적 토대가 바로 이 해에 확립되었다는 점이다. 유디 펄의 베이지안 네트워크는 AI가 불확실성을 다루는 방식을 혁신했고, 리처드 서튼의 시간차 학습은 AI가 경험으로부터 스스로 학습하는 원리를 공식화했다.</p>
</li>
</ul>
<p>1988년에 제시된 이 아이디어들은 단순한 학문적 성과에 그치지 않고, 이후 수십 년에 걸쳐 21세기의 기술 지형을 바꾸어 놓은 혁신의 직접적인 원천이 되었다.</p>
<ul>
<li>
<p>얀 르쿤의 초기 연구는 **합성곱 신경망(CNN)**으로 발전하여 현대 컴퓨터 비전과 <strong>딥러닝 혁명</strong>을 이끌었다.33</p>
</li>
<li>
<p>리처드 서튼의 시간차 학습은 <strong>심층 강화학습</strong>의 근간이 되어, 인간 챔피언을 이긴 <strong>AlphaGo</strong>와 같은 초인적인 AI 시스템을 탄생시켰다.48</p>
</li>
<li>
<p>유디 펄의 베이지안 네트워크와 인과 추론 연구는 데이터 속에서 숨겨진 인과 관계를 발견하고, AI의 결정 과정을 설명하려는 <strong>설명 가능한 AI(XAI)</strong> 분야의 핵심 이론으로 자리 잡았다.35</p>
</li>
<li>
<p>Dean Pomerleau의 ALVINN 프로젝트는 신경망을 이용한 <strong>자율주행 자동차</strong> 연구의 선구자적 사례로서, 오늘날 딥러닝 기반 자율주행 기술의 직접적인 뿌리가 되었다.30</p>
</li>
</ul>
<p>결론적으로, 1988년은 쇠퇴와 탄생, 절망과 희망이 공존했던 역설의 해였다. 상업적 실패가 야기한 ’겨울’은 오히려 기존 패러다임의 한계를 명확히 드러내고, 새로운 아이디어가 자라날 수 있는 지적 공간을 열어주었다. 그 공간 속에서 뿌려진 연결주의, 확률적 추론, 강화학습이라는 씨앗들은 훗날 딥러닝이라는 거대한 나무로 자라나 인류의 삶을 바꾸어 놓았다. 따라서 1988년은 AI의 역사를 단순한 ’붐과 버스트’의 순환으로 이해해서는 안 되며, 하나의 시대가 저물고 새로운 시대가 잉태된, 가장 결정적인 변곡점으로 재평가되어야 한다. 그 해의 지적 유산은 오늘날 우리가 경험하고 있는 AI 혁명의 가장 깊은 곳에 여전히 살아 숨 쉬고 있다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>AI winter - Wikipedia, https://en.wikipedia.org/wiki/AI_winter</li>
<li>What Happened With Expert Systems? | Towards Data Science, https://towardsdatascience.com/what-happened-with-expert-systems-aad399eab180/</li>
<li>AAAI-88: Seventh National Conference on Artificial Intelligence, https://aaai.org/conference/aaai/aaai88/</li>
<li>ALVINN: An Autonomous Land Vehicle in a Neural Network, https://proceedings.neurips.cc/paper/1988/file/812b4ba287f5ee0bc9d43bbf5bbe87fb-Paper.pdf</li>
<li>Y. Le Cun. A theoretical framework for back-propagation. In D …, https://new.math.uiuc.edu/MathMLseminar/seminarPapers/LeCunBackprop1988.pdf</li>
<li>Probabilistic Reasoning in Intelligent Systems - 1st Edition - Elsevier Shop, https://shop.elsevier.com/books/probabilistic-reasoning-in-intelligent-systems/pearl/978-0-08-051489-5</li>
<li>Probabilistic Reasoning In Intelligent Systems Networks Of Plausible Inference Representation And Reasoning - Orcatec, https://www.app.orcatec.com/scoincidej/nformulateo/pcriticizee/58C24931E5/probabilistic+reasoning+in+intelligent+systems+networks+of+plausible+inference+representation+and+reasoning.pdf</li>
<li>Learning to Predict by the Methods of Temporal Differences - Jose M. Vidal, https://jmvidal.cse.sc.edu/lib/sutton88a.html</li>
<li>Proceedings of the 1988 IEEE International Conference on Robotics …, https://researchr.org/publication/icra-1988</li>
<li>What Is a Knowledge Representation?, https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/1029/947</li>
<li>The 1998 AI Planning Systems Competition, https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/1506/1405</li>
<li>AI Qual Summary: Planning - Duke Computer Science, https://cs.duke.edu/brd/Teaching/Previous/AI/Lectures/Summaries/planning.html</li>
<li>What is the Role of Planning in Artificial Intelligence? - GeeksforGeeks, https://www.geeksforgeeks.org/artificial-intelligence/what-is-the-role-of-planning-in-artificial-intelligence/</li>
<li>1988-Goals as Parallel Program Specifications - The Association for the Advancement of Artificial Intelligence, https://cdn.aaai.org/AAAI/1988/AAAI88-011.pdf</li>
<li>Reactive Planning using a “Situation Space”, http://www.ccs.neu.edu/~marsella/publications/pdf/Reactive90.pdf</li>
<li>Situated approach (artificial intelligence) - Wikipedia, https://en.wikipedia.org/wiki/Situated_approach_(artificial_intelligence)</li>
<li>Seventh National Conference on Artificial Intelligence - AAAI - The, https://auld.aaai.org/Library/AAAI/aaai88contents.php</li>
<li>Most Influential AAAI Papers (2024-09 Version), https://www.paperdigest.org/2024/09/most-influential-aaai-papers-2024-09/</li>
<li>EXPERT SYSTEMS DEVELOPMENT: SOME PROBLEMS, MOTIVES AND ISSUES IN AN EXPLORATORY STUDY - INIS-IAEA, https://inis.iaea.org/collection/NCLCollectionStore/_Public/25/032/25032127.pdf</li>
<li>expert systems and knowledge-based engineering (1984-1991) - IU ScholarWorks, https://scholarworks.iu.edu/journals/index.php/ijdl/article/view/12891/19564</li>
<li>Explained: Neural networks | MIT News | Massachusetts Institute of Technology, https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414</li>
<li>Neural Information Processing Systems (NIPS) - SIGMOD, http://www.sigmod.org/publications/dblp/db/conf/nips/index.html</li>
<li>NIPS 1988 | OpenReview, https://openreview.net/group?id=dblp.org/conf/NIPS/1988</li>
<li>NeurIPS 1988 Accepted Paper List - Paper Copilot, https://papercopilot.com/paper-list/neurips-paper-list/neurips-1988-paper-list/</li>
<li>A Self-Learning Neural Network - NIPS, https://proceedings.neurips.cc/paper/1988/hash/a2557a7b2e94197ff767970b67041697-Abstract.html</li>
<li>(PDF) A Theoretical Framework for Back-Propagation - ResearchGate, https://www.researchgate.net/publication/2360531_A_Theoretical_Framework_for_Back-Propagation</li>
<li>ALVINN: An Autonomous Land Vehicle in a Neural Network - NIPS, https://proceedings.neurips.cc/paper/1988/hash/812b4ba287f5ee0bc9d43bbf5bbe87fb-Abstract.html</li>
<li>E cient Training of Arti cial Neural Networks for Autonomous Navigation 1 Introduction - Washington, https://courses.cs.washington.edu/courses/cse481c/11au/papers/Pomerleau.pdf</li>
<li>ALVINN: An Autonomous Land Vehicle in a Neural Network, https://papers.neurips.cc/paper_files/paper/1988/file/812b4ba287f5ee0bc9d43bbf5bbe87fb-Paper.pdf</li>
<li>History Channel 1998 : Driverless Car Technology Overview at Carnegie Mellon University, https://www.youtube.com/watch?v=2KMAAmkz9go</li>
<li>(PDF) A survey of deep learning techniques for autonomous driving - ResearchGate, https://www.researchgate.net/publication/337264008_A_survey_of_deep_learning_techniques_for_autonomous_driving</li>
<li>Handwritten Digit Recognition with a Back-Propagation Network, https://proceedings.neurips.cc/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf</li>
<li>LeNet - Wikipedia, https://en.wikipedia.org/wiki/LeNet</li>
<li>Yann LeCun - A.M. Turing Award Laureate, https://amturing.acm.org/award_winners/lecun_6017366.cfm</li>
<li>REVIEWS JUDEA PEARL. Probabilistic reasoning in intelligent systems: networks of plausible inference. Series in representation a - Cambridge University Press, https://www.cambridge.org/core/services/aop-cambridge-core/content/view/12004ABE6A62B67B79D92DB3CE16D0D8/S0022481200021514a.pdf/judea-pearl-probabilistic-reasoning-in-intelligent-systems-networks-of-plausible-inference-series-in-representation-and-reasoning-morgan-kaufmann-san-mateo1988-xix-552-pp.pdf</li>
<li>Judea Pearl, 14th Frontiers of Knowledge Award in Information and Communication Technologies, https://www.frontiersofknowledgeawards-fbbva.es/galardonados/judea-pearl-2/</li>
<li>Belief propagation - Wikipedia, https://en.wikipedia.org/wiki/Belief_propagation</li>
<li>Belief propagation - YouTube, https://www.youtube.com/watch?v=lEOUO0cQHks</li>
<li>On the Power of Belief Propagation: A Constraint Propagation Perspective - Microsoft, https://www.microsoft.com/en-us/research/wp-content/uploads/2010/01/2010_pearl_DecBidMatRol.pdf</li>
<li>Loopy Belief Propagation for Approximate Inference: An … - arXiv, https://arxiv.org/pdf/1301.6725</li>
<li>INFERENCE IN BAYESIAN NETWORKS - BELIEF PROPAGATION - Stony Brook Computer Science, https://www3.cs.stonybrook.edu/~sael/teaching/cse537/Slides/chapter14d_BP.pdf</li>
<li>Learning to Predict by the Method of Temporal Differences - ResearchGate, https://www.researchgate.net/publication/225264698_Learning_to_Predict_by_the_Method_of_Temporal_Differences</li>
<li>Learning to predict by the methods of temporal differences - Rich Sutton, http://incompleteideas.net/papers/sutton-88-with-erratum.pdf</li>
<li>Truncating Temporal Di erences: On the Efficient Implementation of TD( ) for Reinforcement Learning - Journal of Artificial Intelligence Research, https://www.jair.org/index.php/jair/article/download/10128/23987/18424</li>
<li>Temporal difference learning - Wikipedia, https://en.wikipedia.org/wiki/Temporal_difference_learning</li>
<li>Temporal Difference Learning - Chessprogramming wiki, https://www.chessprogramming.org/Temporal_Difference_Learning</li>
<li>TD(λ) Networks: Temporal-Difference Networks with Eligibility Traces, https://icml.cc/Conferences/2005/proceedings/papers/112_TDLambdaNetworks_TannerSutton.pdf</li>
<li>Reinforcement Learning (RL) - Alberta Machine Intelligence Institute (Amii), https://www.amii.ca/research-talent/research-areas/reinforcement-learning-rl</li>
<li>Richard S. Sutton - Artificial Intelligence, https://schneppat.com/richard-s-sutton.html</li>
<li>Pioneering AI Professors Awarded Turing Award for Groundbreaking Reinforcement Learning - PyLessons.com, https://pylessons.com/news/ai-reinforcement-learning-turing-award</li>
<li>How Canadians Helped Shape the Future of AI - Checkpoint Research, https://checkpointresearch.ca/how-canadians-helped-shape-the-future-of-ai/</li>
<li>IEEE International Conference on Robotics and Automation : ICRA - McMaster Experts, https://experts.mcmaster.ca/display/journal-ieee-international-conference-on-robotics-and-automation–icra–proceedings-ieee-international-conference-on-robotics-and-automation</li>
<li>Fifth Generation Computer Systems - Wikipedia, https://en.wikipedia.org/wiki/Fifth_Generation_Computer_Systems</li>
<li>InfoPile 5th GENERATION COMPUTERS | PDF | Artificial Intelligence - Scribd, https://www.scribd.com/document/685708166/InfoPile-5th-GENERATION-COMPUTERS</li>
<li>Preface, https://www.airc.aist.go.jp/aitec-icot/ICOT/Museum/FGCS/FGCS88en-rpt/88ePREFACE.pdf</li>
<li>A Retrospective and Prospects of the Fifth Generation Computer Project - University of Texas at Austin, https://repositories.lib.utexas.edu/bitstreams/59d2cad0-608d-4585-83f6-53d4d96a70e0/download</li>
<li>Fifth Generation Computer Systems 1988: Volume 1 Proceedings of the International … - Barnes &amp; Noble, https://www.barnesandnoble.com/w/fifth-generation-computer-systems-1988-institute-for-new-generation-computer-technology-icot/1117008840</li>
<li>The Japanese National Fifth Generation Project: Introduction, survey, and evaluation - Stacks, https://stacks.stanford.edu/file/druid:kv359wz9060/kv359wz9060.pdf</li>
<li>What happened with “The Fifth Generation Computer Systems project (FGCS)”?, https://www.researchgate.net/post/What-happened-with-The-Fifth-Generation-Computer-Systems-project-FGCS</li>
<li>Artificial Intelligence and Japan’s Fifth Generation - Dr. Shunryu Colin Garvey, https://www.shunryugarvey.com/wp-content/uploads/2021/03/Garvey_2019_Artificial-Intelligence-and-Japans-Fifth-Generation-1.pdf</li>
<li>Yann LeCun - Wikipedia, https://en.wikipedia.org/wiki/Yann_LeCun</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>