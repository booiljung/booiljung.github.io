<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2003년 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2003년 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2006년 이전의 AI 및 로봇 연구 동향</a> / <span>2003년 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2003년 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 딥러닝 이전 시대의 정점, 2003년 AI 연구의 의의</h2>
<p>2003년은 딥러닝 혁명이 도래하기 약 10년 전으로, 통계적 기계 학습과 확률 모델링이 이론적 정점에 달했던 시기이다. 본 보고서는 2003년을 기점으로 인공지능(AI) 및 로봇 공학 분야에서 발표된 핵심 연구들을 심층적으로 분석한다. 이 시기의 연구들은 데이터의 불확실성을 다루는 정교한 확률 모델의 심화, 레이블링된 데이터의 한계를 극복하려는 비지도 학습의 부상, 그리고 물리적 세계와의 상호작용을 목표로 하는 자율 시스템 기술의 성숙이라는 세 가지 핵심 축을 중심으로 전개되었다.</p>
<p>본 보고서는 먼저 기계 학습 분야의 이론적 토대를 다룬 후, 컴퓨터 비전의 패러다임 변화를 조명하고, 마지막으로 로봇 공학이 현실 세계의 복잡성에 도전하는 과정을 추적한다. 이를 통해 2003년의 연구들이 어떻게 상호작용하며 후속 연구, 특히 현재의 AI 시대를 위한 지적 토대를 마련했는지 분석한다. 보고서의 서두에서는 2003년 한 해 동안 학계에서 가장 주목받은 성과들을 표로 요약하여 제시함으로써, 각 분야의 핵심 연구 주제를 신속하게 파악하고 이어지는 상세 분석에 대한 지적 로드맵을 제공한다.</p>
<h3>1.1 Table 1: 2003년 주요 AI/로봇 공학 학회 최우수 논문상 요약</h3>
<table><thead><tr><th>학회 (Conference)</th><th>상 (Award)</th><th>논문 제목 (Title)</th><th>저자 (Authors)</th></tr></thead><tbody>
<tr><td>NIPS 2003</td><td>Best Paper Award</td><td>Competitive Distribution Estimation: Why is Good-Turing Good?</td><td>Alon Orlitsky, Ananda Theertha Suresh</td></tr>
<tr><td>ICML 2003</td><td>Test of Time Award</td><td>Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions</td><td>Xiaojin Zhu, Zoubin Ghahramani, John Lafferty</td></tr>
<tr><td>ICML 2003</td><td>Test of Time Award</td><td>Online Convex Programming and Generalized Infinitesimal Gradient Ascent</td><td>Martin Zinkevich</td></tr>
<tr><td>CVPR 2003</td><td>Best Paper Award</td><td>Object Class Recognition by Unsupervised Scale-Invariant Learning</td><td>Rob Fergus, Pietro Perona, Andrew Zisserman</td></tr>
<tr><td>ICCV 2003</td><td>Marr Prize</td><td>Image-based Rendering using Image-based Priors</td><td>Andrew Fitzgibbon, Yonatan Wexler, Andrew Zisserman</td></tr>
<tr><td>ICCV 2003</td><td>Marr Prize</td><td>Image Parsing: Unifying Segmentation, Detection and Recognition</td><td>Zhuowen Tu, Xiangrong Chen, Alan L. Yuille, Song-Chun Zhu</td></tr>
<tr><td>ICCV 2003</td><td>Marr Prize</td><td>Detecting Pedestrians using Patterns of Motion and Appearance</td><td>Paul Viola, Michael J. Jones, Daniel Snow</td></tr>
<tr><td>ICRA 2003</td><td>Best Conference Paper Award</td><td>3D Nanomanipulation Using Atomic Force Microscopy</td><td>Guangyong Li, Ning Xi, Mengmeng Yu, Wai Keung Fung</td></tr>
</tbody></table>
<h2>2.  기계 학습의 이론적 도약과 새로운 패러다임</h2>
<h3>2.1  주요 학회의 핵심 연구 동향: NIPS &amp; ICML 2003</h3>
<p>2003년의 기계 학습 분야는 데이터의 근본적인 통계적 속성을 이해하고, 제한된 데이터 환경에서 학습 효율을 극대화하는 이론적 연구들이 정점을 이루었다.</p>
<h4>2.1.1 NIPS 2003 최우수 논문상: Good-Turing 추정의 재해석</h4>
<p>Alon Orlitsky와 Ananda Theertha Suresh의 논문 “Competitive Distribution Estimation: Why is Good-Turing Good?“은 2차 세계대전 당시 앨런 튜링과 I.J. Good이 독일군 암호 해독을 위해 개발했던 통계 기법인 Good-Turing 추정법의 이론적 우수성을 현대적 관점에서 규명했다.1 이 연구는 기존의 접근법, 즉 최악의 시나리오(worst-case)에 대비해 오차를 최소화하는 MinMax 알고리즘의 한계를 지적했다. MinMax 방식은 실제 발생 확률이 낮은 극단적인 경우에 과도하게 최적화되어, 일반적인 상황에서는 오히려 성능이 저하되는 문제를 낳는다. 반면, Good-Turing 추정법은 관찰된 데이터뿐만 아니라 아직 관찰되지 않은 사건의 발생 확률까지 합리적으로 추정함으로써, 특정 최악의 분포가 아닌 모든 가능한 분포에 대해 경쟁력 있는 성능을 보장함을 증명했다. 이 논문은 이산 분포 추정(discrete distribution estimation) 문제에 대한 깊은 통찰을 제공하며, 자연어 처리에서 희소 단어의 확률을 추정하거나 생태학에서 희귀종의 출현 가능성을 예측하는 등 다양한 분야에 견고한 이론적 기반을 제공했다.1</p>
<h4>2.1.2 ICML 2003 ‘Test of Time’ 수상 연구: 새로운 학습 패러다임의 제시</h4>
<p>2013년 ICML 학회는 10년 전인 2003년에 발표된 두 편의 논문에 ‘Test of Time’ 상을 수여하며 그 지속적인 영향력을 인정했다.2 이 두 연구는 각각 데이터 부족 문제와 대규모 데이터 처리 문제에 대한 혁신적인 해법을 제시했다.</p>
<p>첫째, Xiaojin Zhu, Zoubin Ghahramani, John Lafferty의 “Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions“는 준지도 학습(Semi-Supervised Learning)이라는 새로운 패러다임의 이론적 토대를 구축했다.2 이 연구는 소량의 레이블링된 데이터와 대량의 레이블링되지 않은 데이터를 함께 활용하는 방법을 제안했다. 데이터 포인트들이 고차원 공간에서 하나의 매끄러운 매니폴드(manifold)를 형성한다는 가정하에, 레이블 정보를 주변의 레이블 없는 데이터로 ’전파’시키는 방식을 통해 학습 성능을 극적으로 향상시킬 수 있음을 보였다. 이는 의료 영상 분석이나 웹 문서 분류처럼 레이블링 작업에 막대한 비용이 소요되는 현실적인 문제에 대한 강력한 해결책을 제시했다.</p>
<p>둘째, Martin Zinkevich의 “Online Convex Programming and Generalized Infinitesimal Gradient Ascent“는 데이터가 순차적으로 스트리밍되는 온라인 환경에서의 최적화 문제를 다루었다.2 이 논문은 매 순간 들어오는 데이터에 대해 손실 함수를 최소화하는 결정을 내려야 하는 상황에서, 전체 데이터셋을 다시 학습하지 않고도 효율적으로 모델을 업데이트하는 알고리즘을 제안했다. 이는 대규모 데이터 스트림을 실시간으로 처리해야 하는 현대의 광고 입찰, 금융 거래 예측과 같은 응용 분야의 핵심적인 이론적 기초가 되었다.</p>
<h4>2.1.3 NIPS 2003 특징 선택 챌린지</h4>
<p>2003년 NIPS 워크숍의 일환으로 개최된 특징 선택 챌린지(Feature Selection Challenge)는 당시 기계 학습 커뮤니티의 주요 관심사를 명확히 보여주는 상징적인 사건이었다.4 78개의 연구 그룹이 참여한 이 대회는 생물정보학, 텍스트 처리 등 다양한 분야의 5개 데이터셋에 대해, 가능한 한 적은 수의 특징(feature)을 사용하여 최고의 분류 성능을 달성하는 것을 목표로 했다.5 우승팀은 베이즈 신경망(Bayesian neural networks)에 ARD(Automatic Relevance Determination) 사전분포를 적용하는 정교한 기법을 사용했다. ARD는 모델이 학습 과정에서 불필요한 특징에 해당하는 가중치를 0에 가깝게 만들어 자동으로 특징을 선택하는 효과를 낸다. 이 외에도 랜덤 포레스트(Random Forests), 서포트 벡터 머신(SVM)과 같은 커널 방법 등 다양한 기법들이 상위권에 올랐다.4 이 챌린지는 딥러닝이 특징을 자동으로 학습하기 이전 시대에, 고차원 데이터에서 유의미한 ’신호’를 찾아내고 ’소음’을 제거하는 특징 공학 및 선택 과정이 알고리즘의 성패를 좌우하는 핵심 요소였음을 명백히 보여주었다.</p>
<p>이러한 2003년의 주요 기계 학습 연구들은 ’데이터의 본질적 속성 이해’와 ’데이터 부족 및 과잉 문제 해결’이라는 두 가지 큰 흐름으로 요약될 수 있다. Good-Turing 연구는 관찰된 데이터 너머의 보이지 않는 분포를 추정하는 근본적인 통계 문제에 천착했으며, 준지도 학습은 값비싼 레이블 데이터의 한계를 극복하려는 실용적 요구에 부응했다. 특징 선택 챌린지는 고차원 데이터 시대의 서막에서 정보의 정수가 무엇인지 가려내는 능력이 얼마나 중요한지를 입증했다. 이 연구들은 당시 AI 커뮤니티가 더 많은 데이터나 컴퓨팅 파워에 의존하기보다, 확률론과 최적화 이론 같은 수학적 원리와 모델의 정교함을 통해 문제의 본질을 해결하려 했음을 시사한다. 이러한 이론 중심적 접근 방식은 이후 베이즈 딥러닝이나 데이터 효율적 학습과 같은 현대 AI 연구 분야의 지적 토대를 마련했으며, 더 복잡한 모델이 등장했을 때 그것을 분석하고 이해하는 데 필요한 이론적 도구를 제공하는 중요한 역할을 했다.</p>
<h3>2.2  잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)의 등장</h3>
<p>2003년은 자연어 처리(NLP) 분야에 기념비적인 해로 기록되는데, 이는 David Blei, Andrew Ng, Michael I. Jordan이 JMLR(Journal of Machine Learning Research)에 발표한 “Latent Dirichlet Allocation” 논문 덕분이다.7 LDA는 문서 집합(corpus) 내에 숨겨진 주제(topic) 구조를 발견하기 위한 강력한 생성 확률 모델(generative probabilistic model)이다.</p>
<h4>2.2.1 개념 및 배경</h4>
<p>LDA의 핵심 아이디어는 각 문서가 여러 ’주제’의 확률적 혼합으로 구성되고, 각 ’주제’는 다시 여러 ’단어’의 확률 분포로 표현된다는 것이다. 예를 들어, ’정치’라는 주제는 ‘대통령’, ‘국회’, ’선거’와 같은 단어들이 높은 확률로 나타나는 분포이며, ’경제’라는 주제는 ‘시장’, ‘금리’, ’투자’와 같은 단어들이 높은 확률을 갖는 분포이다. 어떤 뉴스 기사는 80%의 ‘정치’ 주제와 20%의 ‘경제’ 주제로 구성될 수 있다.</p>
<p>이 모델은 기존의 pLSA(probabilistic Latent Semantic Analysis)를 완전한 베이즈 통계 프레임워크로 확장한 것이다.10 pLSA는 학습 데이터에 과적합(overfitting)되기 쉽고 새로운 문서에 대한 확률을 부여하는 명확한 방법이 없다는 한계가 있었다.7 LDA는 주제 분포와 단어 분포에 각각 디리클레 사전분포(Dirichlet prior)라는 제약을 가함으로써 이 문제를 해결했다. 이는 모델이 더 일반화되고 안정적인 주제를 학습하도록 유도하여, 보지 못했던 새로운 문서에 대해서도 일관된 주제 추론을 가능하게 했다.</p>
<h4>2.2.2 생성 프로세스 및 수학적 공식</h4>
<p>LDA는 문서가 다음과 같은 가상의 확률적 과정에 의해 생성된다고 가정한다.7</p>
<ol>
<li>
<p>전체 <span class="math math-inline">K</span>개의 주제 각각에 대해, 단어 분포 \phik를 디리클레 분포 <span class="math math-inline">\text{Dir}(\beta)</span>에서 샘플링한다.</p>
</li>
<li>
<p>각 문서 <span class="math math-inline">d</span>에 대해:</p>
</li>
</ol>
<p>a. 해당 문서의 주제 비율 \thetad​를 디리클레 분포 <span class="math math-inline">\text{Dir}(\alpha)</span>에서 샘플링한다.</p>
<p>b. 문서 <span class="math math-inline">d</span>에 포함될 각 단어 <span class="math math-inline">n</span>에 대해:</p>
<p>i. 하나의 주제 <span class="math math-inline">z_{d,n}</span>을 다항 분포 <span class="math math-inline">\text{Multinomial}(\theta_d)</span>에서 선택한다.</p>
<p>ii. 선택된 주제 <span class="math math-inline">z_{d,n}</span>에 해당하는 단어 분포 <span class="math math-inline">\phi_{z_{d,n}}</span>로부터 최종 단어 <span class="math math-inline">w_{d,n}</span>을 샘플링한다.</p>
<p>이러한 생성 과정을 통해, 모델의 파라미터 <span class="math math-inline">\alpha</span>와 <span class="math math-inline">\beta</span>가 주어졌을 때 모든 관찰 가능한 변수(단어 <span class="math math-inline">w</span>)와 잠재 변수(주제 할당 <span class="math math-inline">z</span>, 주제 비율 <span class="math math-inline">\theta</span>, 단어 분포 <span class="math math-inline">\phi</span>)의 결합 확률 분포(joint distribution)는 다음과 같이 수학적으로 표현된다.</p>
<p><span class="math math-display">
p(\mathbf{w}, \mathbf{z}, \theta, \phi | \alpha, \beta) = \prod_{k=1}^{K} p(\phi_k | \beta) \prod_{d=1}^{M} p(\theta_d | \alpha) \prod_{n=1}^{N_d} p(z_{d,n} | \theta_d) p(w_{d,n} | \phi_{z_{d,n}})
</span><br />
실제 응용에서는 관찰된 단어들(<span class="math math-inline">w</span>)을 바탕으로 이 복잡한 사후 확률 분포(posterior distribution)를 추론하여 잠재 변수들, 즉 각 문서의 주제 구성과 각 주제를 대표하는 단어들을 알아낸다.</p>
<h4>2.2.3 영향 및 의의</h4>
<p>LDA의 등장은 텍스트 데이터를 분석하는 방식에 근본적인 변화를 가져왔다. 단순히 단어의 출현 빈도를 세는 ‘bag-of-words’ 모델을 넘어, 문서들 이면에 숨겨진 의미론적 구조를 자동으로 발견하는 강력한 도구를 제공했다. 이로 인해 텍스트 분류, 정보 검색, 문서 요약, 추천 시스템 등 수많은 NLP 응용 분야에서 혁신이 일어났다.11 LDA의 영향력은 NLP에만 국한되지 않았다. 이 모델의 유연성은 유전학에서 유전자 집단의 구조를 분석하거나, 사회 과학에서 여론의 주제를 파악하고, 임상 심리학에서 환자 기록의 핵심 패턴을 찾는 등 텍스트가 아닌 다양한 종류의 이산 데이터 분석에도 널리 적용되는 계기가 되었다.10</p>
<p>LDA의 성공은 2003년 AI 연구의 핵심 조류였던 ’계층적 베이즈 모델링(Hierarchical Bayesian Modeling)’의 가장 빛나는 성과로 평가받는다. 이는 관찰 가능한 데이터(단어)로부터 관찰 불가능한 잠재 구조(주제)를 추론하는 접근법의 힘을 명확히 보여주었다. LDA 이전의 텍스트 분석은 주로 tf-idf나 LSI(Latent Semantic Indexing)와 같은 기법에 의존했는데, 이는 벡터 공간 모델에 기반하며 데이터 생성 과정에 대한 명확한 통계적 가정이 부족했다.7 반면, LDA는 “분석 데이터가 어떻게 생성되었을까?“라는 질문에 답하는 완전한 확률적 ’스토리’를 제공했다. 이러한 생성 모델링(generative modeling) 접근법은 단순히 분류 정확도를 높이는 것을 넘어, 데이터의 내부 구조를 ’해석’하고 ’이해’하려는 시도였다. 결국 LDA는 NLP 분야를 단순 ’패턴 인식’에서 ’잠재 의미 발견’으로 한 단계 격상시켰으며, 이 ’잠재 변수(latent variable)’를 통해 세상을 모델링하려는 철학은 오늘날 Variational Autoencoder(VAE)나 Generative Adversarial Network(GAN)와 같은 딥러닝 기반 생성 모델의 핵심 사상과 직접적으로 연결된다.</p>
<h2>3.  컴퓨터 비전, 세상을 이해하기 시작하다</h2>
<p>2003년 컴퓨터 비전 분야는 레이블링된 데이터의 의존성에서 벗어나려는 시도와 개별 객체 인식을 넘어 장면 전체를 이해하려는 야심 찬 목표를 향해 중요한 발걸음을 내디뎠다.</p>
<h3>3.1  비지도 객체 인식의 서막: CVPR 2003</h3>
<h4>3.1.1 최우수 논문: “Object Class Recognition by Unsupervised Scale-Invariant Learning”</h4>
<p>Rob Fergus, Pietro Perona, Andrew Zisserman이 발표한 이 논문은 당시 컴퓨터 비전 학계에 큰 충격을 주었다.13 주된 이유는 레이블이 전혀 없는 이미지들만으로 특정 객체 클래스(예: 오토바이, 얼굴)의 모델을 학습하는 데 성공했기 때문이다. 이는 막대한 양의 수작업 레이블링 데이터에 의존하던 기존 객체 인식 연구의 패러다임에 근본적인 질문을 던졌다.</p>
<p>연구팀은 베이즈 확률 모델의 한 형태인 ‘부분들의 집합(constellation of parts)’ 모델을 제안했다. 이 모델에서 객체는 여러 개의 지역 특징점(interest points)들의 공간적 배치로 표현된다. 예를 들어, 얼굴은 ‘눈’, ‘코’, ’입’이라는 부분들의 특정 상대적 위치 관계로 모델링된다. 이 연구의 기술적 핵심은 세 가지로 요약할 수 있다. 첫째, 이미지의 크기 변화에 강인한 특징점을 추출하여 객체의 다양한 크기에 대응했다. 둘째, 생성 모델(generative model)을 통해 객체의 각 부분이 어떻게 생겼는지(appearance)와 그 부분들이 어떻게 배치되어 있는지(shape)를 하나의 통합된 확률 모델 안에서 동시에 학습했다. 셋째, 이 모델의 복잡한 파라미터들을 레이블 없이 추정하기 위해 EM(Expectation-Maximization) 알고리즘을 사용했다. EM 알고리즘은 이미지 내에서 어떤 특징점이 어떤 객체 부분에 해당하는지를 반복적으로 추정하고, 그 추정을 바탕으로 모델을 업데이트하는 과정을 통해 최적의 객체 모델을 찾아냈다.</p>
<p>이 연구는 딥러닝 시대가 도래하기 전에 ’표현 학습(representation learning)’의 중요성을 명확히 보여준 사례이다. 모델은 주어진 데이터로부터 객체를 구성하는 ’부분’과 그 ’구조’라는 유의미한 표현을 인간의 개입 없이 스스로 학습했다. 이는 단순히 픽셀 단위의 패턴을 암기하는 것을 넘어, 객체의 본질적인 구성 요소를 학습하려는 시도였다는 점에서 큰 의미를 가진다.</p>
<p>더 나아가, 이 연구는 컴퓨터 비전이 나아가야 할 방향에 대한 철학적 전환을 예고했다. 2003년 당시 대부분의 객체 인식 연구는 수작업으로 제작된 대규모 레이블 데이터셋에 의존했으며, 이는 데이터 수집에 막대한 비용과 시간을 요구하는 ’데이터 병목 현상’을 야기했다. Fergus 등의 연구는 이 문제에 대한 근본적인 해결책으로 ’비지도 학습’을 제시했다. 이는 웹에 존재하는 무한한 양의 레이블 없는 이미지를 학습 자원으로 활용할 수 있다는 가능성을 열어준 것이다.16 이 철학은 현대 AI의 핵심 패러다임인 ’자기지도 학습(Self-Supervised Learning)’과 정확히 일치한다. 자기지도 학습은 이미지의 일부를 가리고 나머지 부분으로 예측하게 하거나, 이미지를 변형시킨 후 원본과의 관계를 맞추게 하는 등 데이터 자체로부터 감독 신호(supervisory signal)를 만들어내어 레이블 없이 유용한 시각적 표현을 학습한다.18 결국 CVPR 2003 최우수 논문은 “레이블이 없어도 세상에 대한 유용한 지식을 학습할 수 있다“는 믿음을 심어주었고, 10여 년 후 대규모 데이터와 컴퓨팅 파워를 만나 자기지도 학습이라는 이름으로 만개하게 되는 아이디어의 씨앗을 뿌린 셈이다.</p>
<h3>3.2  3차원 공간과 장면 이해를 향한 진보: ICCV 2003</h3>
<p>컴퓨터 비전 분야의 또 다른 최고 권위 학회인 ICCV 2003에서는 데이비드 마(David Marr)를 기리는 Marr Prize를 통해 해당 분야의 가장 중요한 진전을 조명했다. 수상작들은 개별 객체 인식을 넘어 3차원 공간을 재구성하고, 장면 전체의 구조를 종합적으로 이해하려는 시도들을 보여주었다.13</p>
<h4>3.2.1 Marr Prize 수상 연구 분석</h4>
<ul>
<li>
<p><strong>“Image-based Rendering using Image-based Priors” (Fitzgibbon et al.):</strong> 이 연구는 3차원 모델을 명시적으로 만들지 않고도, 소수의 2D 이미지만으로 새로운 시점에서 바라본 이미지를 사실적으로 생성하는 이미지 기반 렌더링(Image-based Rendering) 기술을 다루었다. 이미지들 사이에 존재하는 기하학적 제약과 사전 지식(priors)을 활용하여, 가상 시점에서의 모습을 정교하게 합성해내는 방법을 제시함으로써 가상현실 및 컴퓨터 그래픽스 분야에 큰 영향을 미쳤다.</p>
</li>
<li>
<p><strong>“Image Parsing: Unifying Segmentation, Detection and Recognition” (Tu et al.):</strong> 이 논문은 컴퓨터 비전의 세 가지 핵심 과제인 분할(segmentation, 이미지를 의미 있는 영역으로 나누는 것), 탐지(detection, 객체의 위치를 찾는 것), 인식(recognition, 객체가 무엇인지 알아내는 것)을 개별적인 문제로 취급하던 기존의 접근법을 비판하며, 이를 하나의 통합된 프레임워크 안에서 해결하려는 야심 찬 시도를 선보였다. ’이미지 파싱(Image Parsing)’이라는 개념을 통해, 마치 문법이 문장의 구조를 분석하듯 이미지의 계층적 구조(객체, 부분, 배경 등)를 분석하고 최적의 ’해석(parse)’을 찾아내는 확률적 추론 방법을 제안했다.</p>
</li>
<li>
<p><strong>“Detecting Pedestrians using Patterns of Motion and Appearance” (Viola et al.):</strong> 이 연구는 2001년에 발표되어 큰 반향을 일으켰던 Viola-Jones 얼굴 탐지 프레임워크를 한 단계 발전시켰다. 정지 이미지에서의 외형 정보뿐만 아니라, 연속된 비디오 프레임에서 나타나는 움직임 패턴(motion patterns) 정보까지 통합하여 보행자를 효과적으로 탐지하는 방법을 제시했다. 이는 동영상 기반의 실시간 객체 탐지 기술 발전에 중요한 기여를 했으며, 지능형 감시 시스템이나 초기 자율주행 기술의 기반이 되었다.</p>
</li>
</ul>
<p>ICCV 2003의 주요 연구들은 컴퓨터 비전이 개별 ‘객체’ 인식의 단계를 넘어, ‘장면(scene)’ 전체의 구조와 의미를 종합적으로 이해하려는 방향으로 나아가고 있음을 명확히 보여준다. 특히 ’이미지 파싱’은 이러한 ’총체적 접근(holistic approach)’의 정점이라 할 수 있다.</p>
<p>이러한 연구들은 2000년대 초반까지 특정 객체(예: 얼굴)를 잘 탐지하는 데 집중했던 연구의 범위를 크게 확장시켰다. 3D 렌더링은 2D 이미지를 넘어 3D 공간을 다루려 했고, 이미지 파싱은 객체와 배경, 부분과 전체의 관계를 모두 모델링하려 했다. 보행자 탐지는 정지 이미지를 넘어 시간적 차원(움직임)을 통합하려 했다. 이는 컴퓨터 비전 문제를 더 이상 단순한 ‘패턴 매칭’ 문제가 아니라, 인간의 시각 인지 과정과 유사한 복잡한 ‘추론(inference)’ 문제로 바라보기 시작했음을 의미한다. 즉, 2003년의 최첨단 비전 연구는 ’이미지 안에 무엇이 있는가?’라는 질문에서 ’그것들이 어떻게 구성되어 있으며, 서로 어떻게 상호작용하는가?’라는 더 깊은 질문으로 이동하고 있었다. 이는 오늘날 자율주행차가 복잡한 도로 상황을 이해하거나, 생성 AI가 논리적으로 일관성 있는 이미지를 만들어내는 데 필수적인 ‘상황 인식(context awareness)’ 및 ‘구성적 이해(compositional understanding)’ 능력의 초기 형태라 할 수 있다.</p>
<h2>4.  로봇 공학, 현실 세계로의 진출</h2>
<p>2003년 로봇 공학 분야는 가상 환경이나 통제된 실험실을 벗어나, 예측 불가능하고 복잡한 현실 세계에서 자율적으로 임무를 수행하기 위한 핵심 기술들을 성숙시키는 데 집중했다. 자율 이동 로봇의 항법 기술은 이론적 돌파구를 맞이했고, 휴머노이드 로봇은 인간과의 상호작용을 향한 의미 있는 진전을 이루었다.</p>
<h3>4.1  자율 이동 로봇 기술의 혁신</h3>
<h4>4.1.1 SLAM 기술의 패러다임 전환: GraphSLAM의 부상</h4>
<p>2003년 이전까지 SLAM(Simultaneous Localization and Mapping, 동시적 위치 추정 및 지도 작성) 문제의 주류 해법은 확장 칼만 필터(EKF)에 기반을 두고 있었다. EKF-SLAM은 로봇이 움직이며 새로운 관측을 할 때마다, 로봇의 위치와 모든 지도 특징점들의 불확실성을 거대한 하나의 공분산 행렬로 관리하며 순차적으로 업데이트하는 방식이다.20 하지만 이 방식은 지도의 크기가 커질수록 계산량이 기하급수적으로 증가하고, 로봇의 움직임이나 센서 모델의 비선형성이 강할 경우 추정치가 쉽게 발산하는 근본적인 한계를 가지고 있었다.</p>
<p>2003년을 전후하여 이러한 한계를 극복하기 위한 새로운 패러다임으로 GraphSLAM(또는 그래프 기반 SLAM)이 부상했다. GraphSLAM은 SLAM 문제를 전혀 다른 관점에서 접근한다.22 이 접근법은 로봇이 이동한 전체 경로상의 각 위치(pose)와 지도상의 특징점(landmark)들을 그래프의 노드(node)로 표현한다. 그리고 로봇의 주행 기록계(odometry) 측정치나 센서를 통해 관측한 특징점과의 상대적 위치 관계를 두 노드 사이의 제약 조건(constraint)을 담은 엣지(edge)로 표현한다. 이렇게 구축된 전체 그래프에서, 모든 제약 조건을 가장 잘 만족시키는 노드들의 위치를 찾는 전역 최적화 문제(global optimization problem)로 SLAM을 재정의한다.</p>
<p>이 방식은 EKF와 달리 과거의 모든 데이터를 한 번에 처리하여 전체 경로와 지도를 동시에 최적화한다. 따라서 루프 폐쇄(loop closure, 로봇이 이전에 방문했던 장소를 다시 인식하는 것)가 발생했을 때, 누적된 오차를 전체 경로에 걸쳐 재분배함으로써 훨씬 더 정확하고 일관성 있는 지도를 생성할 수 있다.21 이는 대규모 환경을 장시간 탐사하는 로봇을 위한 길을 열어준 이론적 돌파구였다.</p>
<h4>4.1.2 DARPA 그랜드 챌린지: 자율주행 시대의 서막</h4>
<p>2004년 3월에 열릴 첫 번째 DARPA 그랜드 챌린지를 앞두고, 2003년은 전 세계 참가팀들이 기술 개발에 사활을 걸었던 결정적인 해였다. 미 국방고등연구계획국(DARPA)의 목표는 무인 보급 차량과 같은 군사적 활용을 위해, 인간의 개입 없이 사막과 같은 험난한 오프로드를 장거리(약 240 km) 주행할 수 있는 자율주행 기술 개발을 촉진하는 것이었다.23</p>
<p>당시 참가팀들이 개발에 몰두했던 핵심 기술은 다음과 같다.26</p>
<ul>
<li>
<p><strong>위치 추정:</strong> GPS와 관성측정장치(IMU) 데이터를 융합하여 로봇의 정확한 위치와 자세를 추정하는 기술.</p>
</li>
<li>
<p><strong>환경 인식:</strong> LIDAR(레이저 스캐너), RADAR, 스테레오 비전 카메라 등 다양한 센서를 사용하여 전방의 지형과 장애물(바위, 구덩이 등)을 실시간으로 감지하는 기술.</p>
</li>
<li>
<p><strong>경로 계획 및 제어:</strong> DARPA가 제공한 희소한 경로점(waypoint)들을 연결하는 주행 가능한 경로를 생성하고, 인식된 장애물을 회피하며 차량의 조향과 속도를 정밀하게 제어하는 기술.</p>
</li>
</ul>
<p>특히 카네기 멜런 대학(CMU)의 Red Team이 개발한 ‘Sandstorm’ 차량은 사전에 수집한 고정밀 위성 이미지(DOQQ)와 디지털 고도 모델(DEM) 데이터를 활용하여 최적의 전역 경로를 미리 계획하고, 실시간 센서 정보는 지역적인 장애물 회피에 사용하는 계층적 접근법을 채택했다.26</p>
<p>2004년 3월 13일에 열린 첫 대회에서, 15대의 참가 차량 중 단 한 대도 240 km 코스를 완주하지 못했다. 가장 멀리 간 CMU의 Sandstorm조차 약 11.8 km 지점에서 장애물에 걸려 멈춰 섰다.23 이 결과는 실험실 수준의 알고리즘과 실제 사막 환경의 예측 불가능한 가혹함 사이의 거대한 간극을 여실히 보여주었다. 이는 이후 자율주행 연구가 단순히 똑똑한 알고리즘을 넘어, 하드웨어의 신뢰성, 수많은 예외 상황에 대한 강인성(robustness) 확보에 집중하게 되는 중요한 계기가 되었다.24</p>
<p>2003년의 자율 이동 기술은 이처럼 두 가지 상호 보완적인 방향으로 발전했다. GraphSLAM은 ’어떻게 하면 이론적으로 완벽하고 일관성 있는 지도를 만들 것인가’라는 질문에 대한 정교한 해법을 제시했고, DARPA 챌린지는 ’어떻게 하면 불확실하고 거친 현실 세계에서 살아남을 것인가’라는 극단적인 실용적 문제를 제기했다. DARPA 챌린지는 단순한 기술 경진대회를 넘어, 자율주행이라는 새로운 산업 생태계를 탄생시킨 ’촉매제’였다. 이 대회는 이전까지 개별 알고리즘의 우수성을 증명하는 데 머물렀던 연구들을, 인식, 판단, 제어의 모든 요소가 유기적으로 결합되어야만 하는 ‘통합 시스템’ 구축의 장으로 이끌었다. 이 과정에서 모인 다양한 배경의 엔지니어와 연구자들은 하나의 커뮤니티를 형성했고 24, 이들 중 상당수가 훗날 구글(웨이모), 오로라, 우버 등 자율주행 산업을 이끄는 핵심 인력으로 성장했다.29 결국 2003년의 치열했던 개발 과정은 이후 20년간 이어질 자율주행 기술 혁신의 진정한 출발점이었다.</p>
<h3>4.2  휴머노이드 로봇과 인간-로봇 상호작용(HRI)의 발전</h3>
<p>2003년은 로봇이 기계적 성능을 넘어 인간과 소통하고 협력하는 파트너로서의 가능성을 모색하기 시작한 중요한 해였다. 혼다의 아시모(ASIMO)가 그 선두에 있었으며, 주요 로봇 학회에서는 물리적 상호작용의 범위를 인간의 감각을 초월하는 영역으로까지 확장했다.</p>
<h4>4.2.1 혼다 아시모(ASIMO)의 유럽 데뷔와 지능 기술</h4>
<p>2003년 7월, 혼다는 독일 다름슈타트 공과대학에서 열린 심포지엄에서 휴머노이드 로봇 아시모를 유럽에 처음으로 공개했다.32 이 시연은 단순히 두 발로 걷고 계단을 오르내리는 것을 넘어, 로봇이 인간의 사회적 맥락 속에서 어떻게 행동할 수 있는지를 보여주었다는 점에서 큰 의미를 가졌다. 혼다는 이 자리에서 아시모에 적용된 새로운 ’지능 기술’을 상세히 발표했다.33</p>
<p>아시모는 머리에 장착된 두 개의 카메라 ’눈’을 통해 시각 정보를 처리하여, 사람의 얼굴을 약 10명까지 인식하고 저장된 이름으로 부를 수 있었다.32 또한, 사람이 손을 흔들거나 특정 방향을 가리키는 제스처를 이해하고 그에 맞춰 행동할 수 있었다. 예를 들어, 따라오라는 손짓을 인식하고 사람을 따라가거나, 악수를 청하는 손을 내밀면 맞잡는 등의 상호작용이 가능했다. 음성 인식 기능도 탑재되어 자신의 이름을 부르면 반응하고, 간단한 음성 명령을 수행할 수 있었다.35 이는 로봇 연구의 초점이 기계적인 운동 제어의 완성에서 인간과의 자연스러운 ’상호작용’으로 확장되고 있음을 보여주는 상징적인 이정표였다.</p>
<h4>4.2.2 ICRA &amp; IROS 2003: 물리적 상호작용의 확장</h4>
<p>로봇 공학 분야의 양대 최고 학회인 ICRA와 IROS에서도 ’상호작용’은 핵심적인 화두였다.</p>
<p>ICRA 2003에서는 Wen Jung Li 교수 연구팀의 “3D Nanomanipulation Using Atomic Force Microscopy” 논문이 최우수 논문상을 수상했다.36 이 연구는 원자간력 현미경(AFM)의 미세한 탐침을 로봇 팔처럼 제어하여, 나노미터 스케일의 입자를 3차원 공간상에서 정밀하게 밀고, 자르고, 배열하는 기술을 다루었다.38 이는 로봇 기술이 인간의 감각과 능력을 초월하는 미시 세계로 확장되어 새로운 물질을 만들거나 분자 단위의 작업을 수행할 수 있는 가능성을 열어준 획기적인 성과였다.</p>
<p>IROS 2003에서 발표된 연구 목록을 살펴보면, 로봇이 주변 환경 및 인간과 더 풍부하고 정교한 물리적 상호작용을 하기 위한 기반 기술들이 활발히 연구되고 있었음을 알 수 있다. 여기에는 인간의 피부처럼 압력과 질감을 감지하는 촉각 센서(tactile sensor) 기술, 여러 대의 무인 항공기(UAV)가 협력하여 공동의 목표를 달성하는 기술, 곤충이나 동물의 움직임을 모방하여 효율적인 이동을 구현하는 생체모방 보행 로봇, 그리고 인간과 로봇이 같은 공간에서 협력하여 작업을 수행하는 기술 등이 포함되었다.39</p>
<p>2003년 로봇 연구는 이처럼 ’상호작용’이라는 키워드를 중심으로 다양한 차원에서 수렴하고 있었다. 아시모는 인간과의 ’사회적 상호작용’을, ICRA 최우수 논문은 눈에 보이지 않는 세계와의 ’나노스케일 물리적 상호작용’을, IROS의 여러 연구들은 ’환경 및 다개체와의 복잡한 상호작용’을 탐구했다. 이는 로봇을 더 이상 고립된 기계가 아닌, 환경과 인간을 포함한 더 큰 시스템의 일부로 바라보려는 관점의 확산을 의미한다.</p>
<p>특히 2003년 아시모의 지능 기술 시연은 “로봇이 인간과 함께 살아가려면 어떤 능력이 필요한가?“라는 새로운 질문을 학계와 대중에게 던졌다.32 얼굴 인식, 제스처 이해, 음성 소통과 같은 기능들은 로봇이 인간의 사회적 신호를 이해하고 적절히 반응하기 위한 첫걸음이었다. 이러한 시도는 이후 사회적 로봇(social robotics)과 인간-로봇 상호작용(HRI) 분야의 연구 의제를 설정하는 데 결정적인 영향을 미쳤다. 로봇의 인간과 유사한 외형이 사람들의 기대치에 미치는 영향(anthropomorphism), 비언어적 소통의 중요성, 로봇에 대한 신뢰 형성 과정 등이 HRI의 핵심 연구 주제로 자리 잡게 된 배경에는 아시모와 같은 선구적인 시도가 있었다.42 결국 2003년의 아시모는 기술적 성취를 넘어 ’인간과 공존하는 로봇’이라는 비전을 대중과 연구자들에게 각인시켰고, 로봇 공학의 목표를 단순한 ’기능 구현’에서 ’관계 형성’으로 확장시키는 중요한 철학적 전환점이 되었다.</p>
<h2>5. 결론: 2003년이 남긴 유산과 미래 기술에의 영향</h2>
<p>2003년은 인공지능과 로봇 공학이 각자의 영역에서 이론적 깊이를 더하고 현실 세계의 복잡성에 본격적으로 도전하기 시작한 ’성숙의 해’였다. 이 시기는 딥러닝이라는 거대한 파도가 밀려오기 직전, 통계적 기계 학습과 고전적 로봇 공학이 그 정점에서 빛나던 순간이었다.</p>
<p>종합적으로 분석했을 때, 2003년의 연구들은 세 가지 주요 유산을 남겼다. 첫째, <strong>확률 모델을 통한 잠재 구조의 발견</strong>이다. 기계 학습 분야에서 발표된 잠재 디리클레 할당(LDA)은 관찰되는 데이터 이면에 숨겨진 의미론적 구조(주제)를 발견하는 새로운 길을 열었다. 이는 데이터를 단순한 패턴의 집합이 아닌, 의미 있는 잠재 변수들이 생성해낸 결과물로 보는 패러다임의 승리였다. 둘째, <strong>데이터 한계 극복을 위한 비지도 학습의 부상</strong>이다. 컴퓨터 비전 분야의 비지도 객체 인식 연구는 막대한 레이블링 비용이라는 현실적 장벽을 넘어서려는 대안을 제시했다. 이는 데이터 자체의 내재적 구조를 활용하여 유용한 표현을 학습하려는 시도로, 딥러닝 시대의 자기지도 학습(self-supervised learning)의 철학적 원형이 되었다. 셋째, <strong>현실 세계의 복잡성에 대한 도전</strong>이다. 로봇 공학 분야에서 GraphSLAM은 대규모 환경에서의 자율 항법을 위한 견고한 이론적 토대를 마련했으며, DARPA 그랜드 챌린지와 혼다 아시모는 각각 자율주행차와 소셜 로봇이라는 미래 비전을 현실로 끌어당기는 강력한 기폭제 역할을 했다.</p>
<p>이 시기의 연구들은 딥러닝 시대의 직접적인 전조였다. 비지도 학습에 대한 탐구는 대규모 데이터셋을 활용한 사전학습(pre-training)의 중요성을 예고했으며, LDA가 보여준 잠재 변수 모델링은 현대의 표현 학습(representation learning)과 그 맥이 닿아있다. 또한, DARPA 챌린지를 통해 축적된 시스템 통합 경험과 HRI에 대한 초기 탐구는 오늘날 AI 기술이 단순한 알고리즘을 넘어 완전한 제품과 서비스로 발전하는 데 필수적인 공학적, 사회적 토대를 제공했다. 결국 2003년은 미래의 폭발적인 성장을 예비한, 조용하지만 결정적인 변곡점이었으며, 당시의 이론적 성취와 실용적 도전이 없었다면 현재의 AI 혁명은 다른 모습이었을 것이다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>ECE Student, Professor Win Best Paper Award at NIPS Conference - UC San Diego Today, https://today.ucsd.edu/story/ece_student_professor_win_best_paper_award_at_nips_conference</li>
<li>Awards | ICML Atlanta, https://icml.cc/2013/index.html%3Fpage_id=21.html</li>
<li>Award-winning classic papers in ML and NLP - Desh Raj, https://desh2608.github.io/2018-08-30-classic-papers/</li>
<li>Result Analysis of the NIPS 2003 Feature Selection Challenge, https://papers.nips.cc/paper/2728-result-analysis-of-the-nips-2003-feature-selection-challenge</li>
<li>Result Analysis of the NIPS 2003 Feature Selection Challenge - ResearchGate, https://www.researchgate.net/publication/221620519_Result_Analysis_of_the_NIPS_2003_Feature_Selection_Challenge</li>
<li>Result Analysis of the NIPS 2003 Feature Selection Challenge - Semantic Scholar, https://www.semanticscholar.org/paper/Result-Analysis-of-the-NIPS-2003-Feature-Selection-Guyon-Gunn/e1bfd52ce6e38e3e542df2b977ee2c1481f8782a</li>
<li>Latent Dirichlet Allocation - Journal of Machine Learning Research, https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf</li>
<li>latent Dirichlet allocation (LDA), https://jmlr.csail.mit.edu/papers/v3/blei03a.html</li>
<li>(PDF) Latent Dirichlet Allocation - ResearchGate, https://www.researchgate.net/publication/221620547_Latent_Dirichlet_Allocation</li>
<li>Latent Dirichlet allocation - Wikipedia, https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation</li>
<li>What is Latent Dirichlet allocation - IBM, https://www.ibm.com/think/topics/latent-dirichlet-allocation</li>
<li>Topic Modeling Using Latent Dirichlet Allocation (LDA) - Analytics Vidhya, https://www.analyticsvidhya.com/blog/2023/02/topic-modeling-using-latent-dirichlet-allocation-lda/</li>
<li>CVPR and ICCV Best Paper Awards, http://tab.computer.org/pamitc/conference/best-paper-awards.html</li>
<li>CVPR Paper Awards - IEEE Computer Society Technical Committee on Pattern Analysis and Machine Intelligence, https://tc.computer.org/tcpami/awards/cvpr-paper-awards/</li>
<li>CVPR Best Paper Award - IEEE Computer Society Technical Committee on Pattern Analysis and Machine Intelligence, https://tc.computer.org/tcpami/2022/08/22/cvpr-best-paper-award/</li>
<li>Why Does Unsupervised Pre-training Help Deep Learning?, https://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf</li>
<li>Why Does Unsupervised Pre-training Help Deep Learning?, https://jmlr.org/papers/volume11/erhan10a/erhan10a.pdf</li>
<li>(PDF) A Review on Self-Supervised Learning - ResearchGate, https://www.researchgate.net/publication/368631104_A_Review_on_Self-Supervised_Learning</li>
<li>Self-supervised Learning: A Succinct Review - PMC - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC9857922/</li>
<li>Simultaneous Localisation and Mapping (SLAM): Part I The Essential Algorithms - People @EECS, https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/Durrant-Whyte_Bailey_SLAM-tutorial-I.pdf</li>
<li>Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age, https://rpg.ifi.uzh.ch/docs/TRO16_cadena.pdf</li>
<li>The GraphSLAM Algorithm with Applications to … - Sebastian Thrun, http://robots.stanford.edu/papers/thrun.graphslam.pdf</li>
<li>DARPA Grand Challenge - Wikipedia, https://en.wikipedia.org/wiki/DARPA_Grand_Challenge</li>
<li>The DARPA Grand Challenge: Ten Years Later, https://www.darpa.mil/news/2014/grand-challenge-ten-years-later</li>
<li>Grand Challenge 2004 Fin.al Report - Esd.whs.mil, <a href="https://www.esd.whs.mil/Portals/54/Documents/FOID/Reading%20Room/DARPA/15-F-0059_GC_2004_FINAL_RPT_7-30-2004.pdf">https://www.esd.whs.mil/Portals/54/Documents/FOID/Reading%20Room/DARPA/15-F-0059_GC_2004_FINAL_RPT_7-30-2004.pdf</a></li>
<li>High Speed Navigation of Unrehearsed Terrain: Red Team …, https://www.ri.cmu.edu/pub_files/pub4/urmson_christopher_2004_1/urmson_christopher_2004_1.pdf</li>
<li>Explore feature - Grand Challenger - UF Office of Research, http://www.research.ufl.edu/publications/explore/v11n1/story2.html</li>
<li>The Drive for Autonomous Vehicles: The DARPA Grand Challenge - HeroX, https://www.herox.com/blog/159-the-drive-for-autonomous-vehicles-the-darpa-grand</li>
<li>Stanley: The robot that won the DARPA Grand Challenge - Stanford AI Lab, http://robotics.stanford.edu/~dstavens/jfr06/thrun_etal_jfr06.pdf</li>
<li>NOVA | The Great Robot Race | Cars That Drive Themselves - PBS, https://www.pbs.org/wgbh/nova/darpa/cars.html</li>
<li>A Brief History of Autonomous Vehicles – from Renaissance to Reality | Mobileye Blog, https://www.mobileye.com/blog/history-autonomous-vehicles-renaissance-to-reality/</li>
<li>ASIMO Makes Debut In Europe | Honda Global Corporate Website, https://global.honda/en/newsroom/worldnews/2003/c030701.html</li>
<li>The World’s Most Advanced Humanoid Robot Meets Members of the EU - Honda Global, https://global.honda/en/newsroom/worldnews/2005/c050125_c.html</li>
<li>ASIMO Robot Turns 10, Honda Bakes a Cake - autoevolution, https://www.autoevolution.com/news/asimo-robot-turns-10-honda-bakes-a-cake-25823.html</li>
<li>ASIMO - Wikipedia, https://en.wikipedia.org/wiki/ASIMO</li>
<li>Winner, Best Conference Paper Award, 2003 IEEE Int. Conf. on Robotics and Automation (IEEE-ICRA 2003) - CityUHK Scholars, https://scholars.cityu.edu.hk/en/prizes/winner-best-conference-paper-award-2003-ieee-int-conf-on-robotics</li>
<li>WJLBio - Prof. Wen Jung LI - wjl research group, https://www.wenjungli.org/wjlbio</li>
<li>3D nanomanipulation using atomic force microscopy | Request PDF - ResearchGate, https://www.researchgate.net/publication/4041640_3D_nanomanipulation_using_atomic_force_microscopy</li>
<li>2003 IEEE/RSJ International Conference on Intelligent Robots and Systems, Las Vegas, Nevada, USA, October 27 - Researchr, https://researchr.org/publication/iros-2003</li>
<li>IROS 2003 Accepted Paper List, https://papercopilot.com/paper-list/iros-paper-list/iros-2003-paper-list/</li>
<li>What we learned from ASIMO | Honda Robotics, https://global.honda/en/robotics/asimo/</li>
<li>Human-Robot Interaction and Social Robot: The Emerging Field of Healthcare Robotics and Current and Future Perspectives for Spinal Care - PMC - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC11456931/</li>
<li>Human-Robot Interaction, https://rrl.cse.unr.edu/media/documents/2016/585.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>