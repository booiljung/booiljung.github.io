<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:1995년 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>1995년 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2006년 이전의 AI 및 로봇 연구 동향</a> / <span>1995년 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>1995년 AI 및 로봇 연구 동향</h1>
<p>1995년은 인공지능(AI)과 로봇공학 분야에서 심대한 전환이 이루어진 해로 기록된다. 이 시기는 논리와 규칙 기반의 패러다임, 즉 ’초기 AI(Good Old-Fashioned AI, GOFAI)’에서 데이터 중심의 통계적 학습 방법론으로 무게 중심이 결정적으로 이동한 분기점이었다. 동시에 로봇공학은 통제된 실험실 환경에서 벗어나 예측 불가능한 공공 도로라는 현실 세계로 극적인 도약을 감행하며 그 적용 가능성을 입증했다. 본 보고서는 1995년에 일어난 기계 학습의 이론적 돌파구(서포트 벡터 머신), 자율 시스템의 역사적 실증(Navlab 5), 그리고 응용 AI 기술의 성숙(얼굴 검출, 강화학습)이 한데 어우러져 21세기 AI의 초석을 다졌다는 중심 명제를 제시한다.</p>
<p>이 해의 주요 학술 동향은 국제인공지능학회(IJCAI-95), 신경정보처리시스템학회(NIPS 1995), IEEE 국제로봇자동화학회(ICRA 1995) 등 저명한 학회를 통해 확인할 수 있다.1 또한, 미국인공지능학회(AAAI)의 ’국가 정보 인프라에서 지능형 시스템의 역할’과 같은 정책 보고서는 당시 AI 분야가 품고 있던 원대한 포부를 보여준다.4 1995년의 학술적 지형을 조망하기 위해 주요 학회와 발표 내용을 아래 표로 요약했다.</p>
<table><thead><tr><th>학회/저널 (Conference/Journal)</th><th>주요 발표 분야 (Key Research Areas Presented)</th><th>대표 논문/프로젝트 (Representative Paper/Project)</th></tr></thead><tbody>
<tr><td>Machine Learning Journal</td><td>통계적 학습 이론, 분류 알고리즘</td><td>“Support-Vector Networks” (Cortes &amp; Vapnik)</td></tr>
<tr><td>NIPS 1995</td><td>신경망 응용, 컴퓨터 비전, 강화학습</td><td>“Human Face Detection in Visual Scenes” (Rowley, Baluja, Kanade)</td></tr>
<tr><td>NIPS 1995</td><td>강화학습, 동적 최적화</td><td>“Improving Elevator Performance Using Reinforcement Learning” (Crites &amp; Barto)</td></tr>
<tr><td>IEEE Symposium on Intelligent Vehicles</td><td>자율주행, 컴퓨터 비전, 로봇공학</td><td>“No Hands Across America” Project (Pomerleau &amp; Jochem)</td></tr>
<tr><td>Robotics and Autonomous Systems</td><td>다중 에이전트 시스템, 군집 로봇공학</td><td>“Issues and approaches in the design of collective autonomous agents” (Matarić)</td></tr>
<tr><td>IJCAI-95</td><td>컴퓨터 비전, 로봇공학, 자동 추론, 탐색</td><td>다중 에이전트, 내비게이션, 학습, 증명 계획 등 다수</td></tr>
<tr><td>JAIR (Journal of AI Research)</td><td>학습 및 추론, 지식 표현</td><td>“An Integrated Framework for Learning and Reasoning” (Giraud-Carrier &amp; Martinez)</td></tr>
</tbody></table>
<h2>1. 기계 학습의 패러다임 전환: 통계적 학습 이론의 부상</h2>
<p>1995년은 기계 학습 분야에 수학적 엄밀성과 통계적 학습 이론의 원칙이 본격적으로 도입된 해였다. 이는 당시 주류였던 경험적 신경망 접근법에 대한 강력한 이론적 대안을 제시하는 동시에, 바로 그 신경망 기술이 전례 없는 실용적 성공을 거두는 이중적인 양상을 보였다.</p>
<h3>1.1 서포트 벡터 네트워크(Support-Vector Networks)의 탄생: Corinna Cortes와 Vladimir Vapnik의 혁신</h3>
<p>1995년, 코리나 코르테스(Corinna Cortes)와 블라디미르 바프닉(Vladimir Vapnik)은 학술지 ’Machine Learning’에 ’서포트 벡터 네트워크’라는 논문을 발표하며 기계 학습의 역사를 새로 썼다.5 이 논문은 단순히 새로운 알고리즘을 제시한 것을 넘어, 바프닉이 수십 년간 연구해 온 통계적 학습 이론(Statistical Learning Theory, SLT)과 VC 차원(Vapnik-Chervonenkis dimension)의 실용적인 정점을 보여준 결과물이었다.8</p>
<p>이 접근법의 핵심은 단순히 훈련 데이터를 분리하는 것을 넘어, 보이지 않는 데이터에 대해서도 우수한 성능을 내는 모델, 즉 높은 일반화 성능을 갖춘 모델을 구축하는 데 있었다. 이를 위해 SVM은 클래스 간의 마진(margin)을 최대화하는 ’최적 초평면(optimal hyperplane)’을 찾는다는 원칙을 제시했다.9</p>
<p>이 논문의 가장 중요한 실용적 기여는 ‘소프트 마진(soft margin)’ 개념의 도입이었다. 이전의 모델은 데이터가 선형적으로 완벽하게 분리되는 이상적인 경우에만 작동했다. 코르테스와 바프닉은 슬랙 변수(<span class="math math-inline">\xi_i</span>)와 규제 파라미터(<span class="math math-inline">C</span>)를 도입하여, 일부 데이터 포인트가 마진을 위반하거나 잘못 분류되는 것을 허용했다. 이 혁신 덕분에 SVM은 이론적 호기심의 대상에서 벗어나, 노이즈가 많고 비선형적으로 얽힌 현실 세계의 데이터를 다룰 수 있는 강력한 도구로 거듭났다.5</p>
<p>소프트 마진 SVM의 최적화 문제는 다음과 같은 원시 문제(primal problem)로 공식화된다. 여기서 목표는 마진을 최대화(이는 가중치 벡터 <span class="math math-inline">w</span>의 노름(norm)을 최소화하는 것과 같음)하는 것과 분류 오류를 최소화하는 것 사이의 균형을 맞추는 것이다. 규제 파라미터 <span class="math math-inline">C</span>는 이 두 목표 사이의 상충 관계를 조절하는 역할을 한다.11</p>
<p><span class="math math-display">
\min_{w, b, \xi} \frac{1}{2} \|w\|^2 + C \sum_{i=1}^{n} \xi_i
</span><br />
제약 조건은 다음과 같다.</p>
<p><span class="math math-display">
\text{subject to } y_i(w \cdot x_i + b) \ge 1 - \xi_i, \quad \xi_i \ge 0 \quad \text{for } i=1, \dots, n
</span><br />
이 문제는 라그랑주 쌍대성(Lagrangian duality)을 통해 쌍대 문제(dual problem)로 변환될 수 있다. 이 변환의 가장 큰 장점은 데이터가 내적(<span class="math math-inline">K(x_i, x_j)</span>) 형태로만 나타난다는 점이다. 이는 고차원 특징 공간으로의 비선형 매핑을 효율적으로 계산할 수 있게 하는 ’커널 트릭(kernel trick)’의 기반이 된다.5</p>
<table><thead><tr><th>구분 (Category)</th><th>최대 마진 분류기 (Hard-Margin SVM)</th><th>소프트 마진 분류기 (Soft-Margin SVM - Cortes &amp; Vapnik, 1995)</th></tr></thead><tbody>
<tr><td><strong>목적 함수 (Objective Function)</strong></td><td><span class="math math-inline">\min \frac{1}{2} |w|^2</span></td><td><span class="math math-inline">\min \frac{1}{2} |w|^2 + C \sum_{i=1}^{n} \xi_i</span></td></tr>
<tr><td><strong>제약 조건 (Constraints)</strong></td><td><span class="math math-inline">y_i(w \cdot x_i + b) \ge 1</span></td><td><span class="math math-inline">y_i(w \cdot x_i + b) \ge 1 - \xi_i, \quad \xi_i \ge 0</span></td></tr>
</tbody></table>
<h3>1.2 신경망의 응용 확장</h3>
<p>SVM이 이론적 토대를 다지는 동안, 신경망은 이전에 다루기 어려웠던 복잡하고 고차원적인 문제들을 해결하며 실용적 성공을 거두고 있었다. 1995년은 이론과 실제가 서로를 자극하며 발전하는 흥미로운 이중성을 보여준다. SVM이 통계적 학습 이론이라는 탄탄한 기반 위에서 일반화 성능을 약속했다면, 당시에는 이론적 근거가 다소 부족한 ’블랙박스’로 여겨졌던 신경망은 복잡한 현실 세계 데이터에서 획기적인 성과를 내놓았다. 이러한 신경망의 실용적 성공은 데이터 기반 접근법의 유효성을 입증했고, 이는 다시 SVM과 같은 더 강력하고 해석 가능한 학습 알고리즘에 대한 수요를 창출하는 선순환 구조를 만들었다.</p>
<h4>1.2.1 시각 장면에서의 얼굴 검출</h4>
<p>카네기 멜런 대학교(CMU)의 헨리 라울리(Henry Rowley), 슈미트 발루자(Shumeet Baluja), 타케오 카나데(Takeo Kanade)는 NIPS 1995에서 신경망 기반 얼굴 검출 시스템을 발표했다.2 이 연구는 복잡한 배경 속에서 다양한 크기와 조명의 얼굴을 자동으로 찾아내는 문제에 대한 효과적인 해결책을 제시했다.</p>
<p>시스템의 핵심은 망막처럼 연결된(retinally-connected) 신경망 필터였다. 이 필터는 20x20 픽셀 크기의 작은 이미지 창을 입력으로 받아, 해당 영역에 얼굴이 있는지 여부를 판단했다. 은닉층은 10x10, 5x5, 20x5 등 다양한 크기의 중첩된 수용 영역을 갖도록 설계되어, 눈, 입, 코와 같은 얼굴의 구성 요소를 여러 스케일에서 포착할 수 있었다.17</p>
<p>이 연구의 가장 혁신적인 부분은 ‘부트스트랩(bootstrap)’ 학습 알고리즘이었다. 당시 AI가 직면한 핵심 과제 중 하나는 데이터 병목 현상이었다. 얼굴이 아닌 모든 이미지를 수집하여 데이터셋을 만드는 것은 불가능에 가까웠다. 라울리 연구팀은 이 문제를 해결하기 위해, 초기에 소수의 ‘non-face’ 이미지로 학습을 시작하고, 시스템이 스스로 저지른 오류, 즉 얼굴이 아닌데 얼굴로 잘못 판단한 이미지(false positives)를 다시 훈련 데이터에 추가하는 방식을 고안했다. 이는 가장 판별하기 어려운 예제에 학습을 집중시키는 일종의 능동적 학습(active learning)으로, 신경망이 더 정교한 특징을 학습하도록 강제하는 매우 효율적인 전략이었다.15</p>
<p>전체 시스템은 먼저 이미지 피라미드를 통해 다양한 크기의 얼굴을 탐지한 후, 여러 신경망 필터의 결과를 ’중재자(arbitrator)’가 결합하고 중복된 검출 결과를 병합하여 최종적으로 얼굴 위치를 결정하는 파이프라인으로 구성되었다.15</p>
<h4>1.2.2 강화학습의 실용적 도약: 엘리베이터 제어</h4>
<p>같은 해 NIPS에서 로버트 크라이츠(Robert Crites)와 앤드류 바르토(Andrew Barto)는 ’강화학습을 이용한 엘리베이터 성능 향상’이라는 논문을 통해 강화학습이 대규모 실용 문제에 적용될 수 있음을 증명했다.2 이 연구는 10층 건물에서 4대의 엘리베이터를 제어하는 복잡한 문제를 다루었다. 이 문제의 상태 공간은 <span class="math math-inline">10^{22}</span>개를 초과하여 전통적인 동적 계획법으로는 해결이 불가능했다.20</p>
<p>연구팀은 각 엘리베이터를 제어하는 독립적인 강화학습 에이전트로 구성된 팀을 사용했다. 각 에이전트는 자신의 결정(정지, 이동 등)을 내리지만, 보상은 시스템 전체의 성능, 즉 모든 승객의 평균 대기 시간 및 이동 시간 최소화라는 전역적인 신호로 받았다. 이 분산된 접근법은 시뮬레이션 환경에서 생성된 경험을 통해 학습하며, 실제로 시스템이 마주칠 가능성이 높은 상태에 계산을 집중시켰다. 이 ‘스마트 데이터’ 활용 방식은 얼굴 검출의 부트스트랩 기법과 맥을 같이하며, 데이터의 한계를 극복하려는 당시의 지혜를 보여준다. 이 연구는 Q-러닝과 같은 알고리즘을 신경망과 결합한 함수 근사 기법을 활용하여, 기존의 어떤 휴리스틱 기반 제어 알고리즘보다도 뛰어난 성능을 달성했다.21</p>
<h2>2. 자율 시스템의 이정표: 도로 위를 달리는 로봇</h2>
<p>1995년은 자율주행 기술이 실험실의 호기심을 넘어 장거리 실제 주행이 가능한 공학적 도전 과제로 전환되었음을 증명한 해였다. ‘No Hands Across America’ 프로젝트는 당시 기술로 구현할 수 있는 인식, 계획, 제어 능력의 놀라운 통합을 보여준 기념비적 사건이다.</p>
<h3>2.1 “No Hands Across America”: Navlab 5 프로젝트</h3>
<p>1995년 7월, CMU의 연구원 딘 포멀루(Dean Pomerleau)와 토드 조켐(Todd Jochem)은 Navlab 5라 불리는 개조된 1990년식 폰티악 트랜스 스포츠 미니밴을 타고 피츠버그에서 샌디에이고까지의 여정을 시작했다.25 이 프로젝트는 순수한 학술 연구를 넘어, 10년 뒤에 있을 DARPA 그랜드 챌린지보다 앞서 자율주행 기술의 성숙도를 입증하고 연구 자금을 확보하려는 목적도 있었다.25 총 2,849마일(약 4,585km)의 여정 중 2,797마일(98.2%)을 차량이 스스로 조향했으며, 이는 자율 시스템의 견고성과 신뢰성에 대한 전례 없는 실증이었다.25</p>
<h4>2.1.1 RALPH 시스템의 기술적 분석</h4>
<p>Navlab 5의 성공은 근본적으로 컴퓨터 비전의 성공이었으며, 그 중심에는 RALPH(Rapidly Adapting Lateral Position Handler)라는 인식 알고리즘이 있었다.29 RALPH는 복잡한 추론 시스템이 아니라, 고도로 최적화된 ‘인식-행동’ 루프였다. 이는 실제 세계 로봇공학의 근본 원리, 즉 견고한 인식이 모든 상위 수준 자율성의 기반이라는 점을 명확히 보여준다. 여정 중 마주친 어려움은 대부분 상위 수준의 논리적 판단 실패가 아닌, 석양의 눈부심, 악천후, 희미한 차선 등 인식의 실패였다.25 RALPH의 처리 과정은 세 단계로 이루어졌다.</p>
<ol>
<li>
<p><strong>이미지 샘플링</strong>: RALPH는 원본 카메라 이미지를 직접 처리하지 않았다. 대신, 도로 전방의 사다리꼴 영역에 역투영 변환(inverse perspective mapping)을 적용하여 32x30 픽셀의 조감도(bird’s-eye-view) 이미지로 변환했다. 이 결정적인 단계 덕분에 실제 도로의 평행한 차선들이 이미지상에서도 평행하게 보여 후속 처리가 매우 단순해졌다.31</p>
</li>
<li>
<p><strong>도로 곡률 결정</strong>: 이 단계에서는 독창적인 ‘가설 설정 및 검증(hypothesize and test)’ 전략이 사용되었다. RALPH는 급한 좌회전, 완만한 좌회전, 직선 등 여러 가능한 도로 곡률을 가설로 설정했다. 각 가설에 해당하는 전단 변환(shear transformation)을 조감도 이미지에 적용한 후, 어떤 변환이 도로의 특징들을 가장 반듯한 수직선으로 만드는지 평가했다. 가장 높은 점수를 받은 곡률 가설이 실제 도로의 곡률로 채택되었다. 이 방식은 흰색 차선과 같은 특정 특징에 의존하지 않고, 기름 얼룩이나 도로의 홈 등 도로와 평행한 어떤 특징이든 활용할 수 있어 매우 견고했다.31</p>
</li>
<li>
<p><strong>측면 오프셋 결정</strong>: 2단계에서 결정된 최적의 곡률을 이용해 도로 이미지를 ‘반듯하게 편’ 후, 일반적인 차선의 모습을 담은 1차원 템플릿을 이 이미지와 상호 상관(correlation)시켜 차량이 차선 중앙에서 얼마나 벗어났는지 정확한 측면 오프셋을 계산했다. 이 오프셋 값은 최종적으로 조향 명령을 생성하는 데 사용되었다.31</p>
</li>
</ol>
<p>이 프로젝트는 자율 시스템이 마주할 수 있는 수많은 현실 세계의 예외 상황(공사 구간, 악천후, 불량한 차선 표시 등)에 대한 귀중한 데이터를 제공했으며, 이는 오늘날의 자율주행 시스템 개발에도 여전히 중요한 과제로 남아있다.25 또한 이 프로젝트는 CMU를 자율주행 연구의 중심으로 확립시켰고, 세바스찬 스런(Sebastian Thrun), 크리스 엄슨(Chris Urmson)과 같은 차세대 분야 리더들을 양성하는 요람이 되었다.26</p>
<h3>2.2 다중 에이전트 및 군집 로봇 시스템</h3>
<p>Navlab 5가 단일 로봇의 위업이었다면, 1995년에는 로봇 그룹의 협력에 대한 연구 또한 활발히 진행되었다. 마야 마타리치(Maja Matarić)의 1995년 논문은 집단 자율 에이전트 설계의 핵심 쟁점들, 즉 통신 전략, 임무 할당, 간섭과 협력, 제어 아키텍처(중앙집중형 대 분산형) 등을 포괄적으로 정리했다.32</p>
<p>이 시기의 연구 동향은 미묘하지만 중요한 변화를 보여준다. 초기 연구는 종종 단순하고 동일한 에이전트 다수로 구성된 ’군집 지능(swarm intelligence)’에 초점을 맞췄다.32 그러나 1995년에 발표된 연구들은 이기종 로봇(heterogeneous robots)으로 구성된 팀의 협력에 대한 관심이 커지고 있음을 보여준다. 예를 들어, 파커(Parker)의 연구는 독성 폐기물 처리와 같은 복잡한 임무를 위해 서로 다른 능력을 가진 로봇들이 행동 기반으로 임무를 공유하는 방법을 다루었다.32 이는 추상적인 생물학적 영감에서 벗어나, 다양한 능력을 요구하는 구체적이고 복잡한 공학 문제를 해결하려는 분야의 성숙을 반영한다.</p>
<h2>3. AI의 이론적 기반과 미래 전망</h2>
<p>1995년은 AI 분야의 다양한 흐름들이 각자의 방향으로 깊이를 더해가던 시기였다. 전통적인 AI 분야는 꾸준히 발전했으며, AI 커뮤니티는 스스로의 미래를 적극적으로 조망하고 있었다.</p>
<h3>3.1 탐색, 추론, 지식 표현의 진화</h3>
<p>IJCAI-95와 JAIR(Journal of Artificial Intelligence Research)의 발표 내용들은 전통적인 AI 분야의 꾸준한 발전을 보여준다.1 탐색 분야에서는 실시간 의사 결정, 제한된 메모리 활용, 트레일블레이저(Trailblazer) 탐색과 같은 새로운 전략들이 발표되었다.1 자동 추론 분야는 단순한 정리 증명을 넘어 증명 계획(Bundy &amp; Lombart), 유추 기반 증명 구성(Melis), 비단조 이론 변화를 위한 귀추법적 추론(Inoue &amp; Sakama) 등 더 정교한 방향으로 나아가고 있었다.1 지식 표현 분야에서는 추상화의 형식화(Nayak &amp; Levy)나 서로 다른 논리적 표현 간의 변환(Khardon)에 대한 중요한 연구가 이루어졌다.1</p>
<h3>3.2 년의 AI: 성찰과 비전</h3>
<p>1995년의 AI 커뮤니티는 자신들의 연구가 사회에 미칠 영향을 내다보며 미래를 설계하고 있었다. AAAI의 ‘국가 정보 인프라에서 지능형 시스템의 역할’ 보고서는 AI가 당시 막 부상하던 정보화 시대(인터넷 중심 세계의 전신)의 ‘중추적(pivotal)’ 기술이 될 것이라는 비전을 제시했다.4 이는 AI 커뮤니티가 21세기를 위한 기초 연구 의제를 정의하며 장기적인 궤도를 전략적으로 계획하고 있었음을 보여준다.4</p>
<p>이 시기 AI 연구의 단면을 살펴보면, 뚜렷한 방법론적 분리가 관찰된다. 한편에는 SVM, 신경망, 강화학습과 같이 엄청난 추진력을 얻고 있던 통계적, 데이터 기반의 하위기호적(sub-symbolic) 접근법이 있었다. 다른 한편에는 자동 추론, 지식 표현 등 AI의 전통적인 심장이었던 논리 기반의 기호적(symbolic) 접근법이 있었다. NIPS 1995의 발표 목록은 거의 전적으로 신경망과 학습 이론에 집중된 반면 2, IJCAI-95의 자동 추론 세션은 순수하게 기호적 주제들로 채워져 있었다.1</p>
<p>1995년은 이 두 패러다임이 각자의 전문성을 극대화하며 가장 멀리 갈라졌던 시점으로 볼 수 있다. 이러한 분리는 실패가 아니라, 지능의 서로 다른 측면을 깊이 파고들기 위한 필수적인 전문화 과정이었다. 1995년에 암묵적으로 설정된 AI의 미래를 향한 거대한 도전 과제는 바로 이 두 접근법을 통합하는 것, 즉 데이터로부터 학습하면서 동시에 추론하고, 계획하고, 추상적 지식을 활용할 수 있는 시스템을 만드는 것이었다.</p>
<h2>4. 결론</h2>
<p>1995년은 AI 역사에서 단순한 한 해가 아니라, 심오하고 상호 연결된 변화가 일어난 분수령이었다. 서포트 벡터 네트워크의 이론적 우아함은 기계 학습에 새로운 토대를 제공했다. Navlab 5의 대륙 횡단 여정은 실제 세계 로봇공학의 포부를 재정의했다. 얼굴 검출과 강화학습에서의 실용적 성공은 복잡하고 노이즈가 많은 영역에 학습 알고리즘을 적용하는 것의 위력을 증명했다. 1995년의 이러한 발전들은 단순히 당시의 최첨단 기술을 한 단계 끌어올린 것을 넘어, 분야의 궤도를 근본적으로 바꾸어 놓았다. 이는 21세기 AI 혁명으로 직접 이어지는 지적, 공학적 의제를 설정한 결정적인 순간이었다.</p>
<h2>5. 참고 자료</h2>
<ol>
<li>Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (I), https://www.ijcai.org/proceedings/1995-1</li>
<li>Advances in Neural Information Processing Systems 8 (NIPS 1995), https://proceedings.neurips.cc/paper/1995</li>
<li>International Conference on Robotics and Automation (ICRA), https://sigmod.org/publications/dblp////db/conf/icra/index.html</li>
<li>Past AAAI Policy Reports - The Association for the Advancement of Artificial Intelligence, https://aaai.org/about-aaai/ai-science-policy/</li>
<li>Support-vector networks - BibBase, https://bibbase.org/network/publication/cortes-vapnik-supportvectornetworks</li>
<li>Cortes, C.; Vapnik, V. “Support-vector networks”. Machine Learning, vol 20, no. 3. pp 273-297, 1995., https://www.sciepub.com/reference/184327</li>
<li>Cortes, C. and Vapnik, V. (1995) Support-Vector Networks. Machine Learning, 20, 273-297. - References - Scientific Research Publishing, https://www.scirp.org/reference/referencespapers?referenceid=1150668</li>
<li>(PDF) Support Vector Machines: Theory and Applications - ResearchGate, https://www.researchgate.net/publication/221621494_Support_Vector_Machines_Theory_and_Applications</li>
<li>Support-Vector Networks - SciSpace, https://scispace.com/pdf/support-vector-networks-2jd9a1kl0z.pdf</li>
<li>Support Vector Machine Solvers - Leon Bottou, https://leon.bottou.org/publications/pdf/lin-2006.pdf</li>
<li>Support Vector Machine Solvers, https://www.csie.ntu.edu.tw/~cjlin/papers/bottou_lin.pdf</li>
<li>Random Machines: A Bagged-Weighted Support Vector Model with Free Kernel Choice - Journal of Data Science, https://jds-online.org/journal/JDS/article/899/file/pdf</li>
<li>support-vector networks - College of Engineering | Oregon State …, https://web.engr.oregonstate.edu/~huanlian/teaching/ML/2018spring/extra/svn-1995.pdf</li>
<li>A distance-based kernel for classification via Support Vector Machines - Frontiers, https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1287875/full</li>
<li>Human Face Detection in Visual Scenes, http://papers.neurips.cc/paper/1168-human-face-detection-in-visual-scenes.pdf</li>
<li>[PDF] Neural network-based face detection - Semantic Scholar, https://www.semanticscholar.org/paper/Neural-network-based-face-detection-Rowley-Baluja/a3885c13438132b516e5ffc8b640d20b4e41a7a4</li>
<li>Human Face Detection in Visual Scenes - ResearchGate, https://www.researchgate.net/profile/Henry-Rowley/publication/2459475_Human_Face_Detection_in_Visual_Scenes/links/00b4953739bb2a53f3000000/Human-Face-Detection-in-Visual-Scenes.pdf</li>
<li>(PDF) Human Face Detection in Visual Scenes - ResearchGate, https://www.researchgate.net/publication/2459475_Human_Face_Detection_in_Visual_Scenes</li>
<li>Neural Network-Based Face Detection - Carnegie Mellon University Robotics Institute, https://www.ri.cmu.edu/pub_files/pub1/rowley_henry_1996_3/rowley_henry_1996_3.pdf</li>
<li>(PDF) Large-Scale Dynamic Optimization Using Teams of …, https://www.researchgate.net/publication/2260639_Large-Scale_Dynamic_Optimization_Using_Teams_of_Reinforcement_Learning_Agents</li>
<li>Reinforcement-Learning: An Overview from a Data Mining Perspective | Semantic Scholar, https://www.semanticscholar.org/paper/Reinforcement-Learning%3A-An-Overview-from-a-Data-Cohen-Maimon/a49e90a386b4cd500c77e10503952819003bd887</li>
<li>References - CMU School of Computer Science, https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/kaelbling96a-html/node62.html</li>
<li>Elevator Group Control Using Multiple Reinforcement Learning Agents - ResearchGate, https://www.researchgate.net/publication/2433267_Elevator_Group_Control_Using_Multiple_Reinforcement_Learning_Agents</li>
<li>Elevator Group Control Using Multiple Reinforcement Learning Agents - Rice University, https://www.clear.rice.edu/comp540/papers/elev.pdf</li>
<li>25 Years Ago, the First Robot Car Drove Across America’s Highways, https://www.robopgh.org/news/2020-7-31-3rf390xlo9uy6cuijm1enahk18rmkd</li>
<li>Back to the Future: Autonomous Driving in 1995 - The Robot Report, https://www.therobotreport.com/back-to-the-future-autonomous-driving-in-1995/</li>
<li>Then and Now: The 2850-mile, no-hands road trip, https://csd.cmu.edu/news/then-and-now-the-2850mile-nohands-road-trip</li>
<li>No Hands Across America Home Page - Carnegie Mellon University, https://www.cs.cmu.edu/~tjochem/nhaa/nhaa_home_page.html</li>
<li>RALPH: Rapidly Adapting Lateral Position Handler - Carnegie Mellon University, https://www.cs.cmu.edu/~tjochem/nhaa/ralph.html</li>
<li>RALPH: rapidly adapting lateral position handler - Semantic Scholar, https://www.semanticscholar.org/paper/RALPH%3A-rapidly-adapting-lateral-position-handler-Pomerleau/534210704d2d3490383da56cd1ca1ce7f3232714</li>
<li>RALPH: Rapidly Adapting Lateral Position Handler - Intelligent …, https://www.ri.cmu.edu/pub_files/pub2/pomerleau_dean_1995_2/pomerleau_dean_1995_2.pdf</li>
<li>Robotics and Autonomous Systems, <a href="https://www.eng.auburn.edu/~troppel/courses/00sum13/7970%202013A%20ADvMobRob%20sp13/literature/paper%20Z1%20mataric%20elsevier%201995.pdf">https://www.eng.auburn.edu/~troppel/courses/00sum13/7970%202013A%20ADvMobRob%20sp13/literature/paper%20Z1%20mataric%20elsevier%201995.pdf</a></li>
<li>Vol. 3 (1995) | Journal of Artificial Intelligence Research, https://www.jair.org/index.php/jair/issue/view/1087</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>