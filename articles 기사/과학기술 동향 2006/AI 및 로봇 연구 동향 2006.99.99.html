<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2006년 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2006년 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2006년 이전의 AI 및 로봇 연구 동향</a> / <span>2006년 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2006년 AI 및 로봇 연구 동향</h1>
<h2>1. 서론</h2>
<p>2006년은 인공지능 역사에서 단순한 진보의 해가 아닌, 근본적인 패러다임 전환이 시작된 ’특이점(singularity)’으로 기록되어야 한다. 수십 년간 심층 신경망(deep neural network)의 훈련을 가로막았던 이론적, 실질적 장벽이 제프리 힌튼(Geoffrey Hinton)과 그의 동료들에 의해 마침내 허물어졌기 때문이다. 이들의 연구는 ’AI의 두 번째 겨울’이라 불리던 시기의 정체를 타개하고, 현재 AI 기술의 근간을 이루는 심층 학습(Deep Learning) 혁명의 도화선이 되었다.1 2006년 이전까지 심층 신경망은 기울기 소실(vanishing gradient) 문제로 인해 실질적인 학습이 불가능하다고 여겨졌으나, 힌튼이 제시한 새로운 훈련 방법론은 이 오랜 난제를 해결할 실마리를 제공하며 연구계에 새로운 활력을 불어넣었다.</p>
<p>동시에 로봇 공학 분야는 혁명보다는 성숙과 진화의 길을 걸었다. 자율 이동 로봇의 핵심 기술인 동시적 위치 추정 및 지도 작성(Simultaneous Localization and Mapping, SLAM)은 이론적 토대를 공고히 하며 실제 적용 가능한 알고리즘으로 발전했고, 확장 칼만 필터(EKF)와 파티클 필터(Particle Filter) 기반의 접근법들이 경쟁하며 기술적 완성도를 높여갔다.3 한편, 혼다의 아시모(ASIMO)와 같은 휴머노이드 로봇은 연구실을 넘어 실용적인 과업 수행 능력을 선보이며 대중과 산업계의 기대를 한 몸에 받았다.5 이는 로봇 공학이 알고리즘의 정교화와 더불어 복잡한 시스템을 통합하는 공학적 성숙 단계에 접어들었음을 보여주는 사례였다.</p>
<p>본 보고서는 1부에서 2006년 AI 분야의 가장 결정적 사건인 심층 신경망 훈련 방법론의 등장을 심층 분석하고, 2부에서는 당시 머신러닝 학계의 전반적인 연구 동향을 조망하여 심층 학습 이전 시대의 기술적 지형도를 그린다. 마지막으로 3부에서는 로봇 공학 분야의 주요 성과들을 SLAM, 휴머노이드, 산업 동향의 세 축으로 나누어 상세히 기술함으로써, 2006년이 AI와 로봇 공학 두 분야 모두에게 어떠한 의미를 갖는 해였는지 종합적으로 평가하고자 한다.</p>
<h2>2. 부: 심층 신경망의 여명: 힌튼의 혁신적 연구</h2>
<p>2006년 힌튼의 연구가 가져온 가장 큰 변화는 단순히 새로운 알고리즘의 등장을 넘어선 심리적 돌파구의 마련에 있었다. 마빈 민스키(Marvin Minsky)와 시모어 페퍼트(Seymour Papert)가 저서 “퍼셉트론(Perceptrons)“에서 제기한 비판 이후, AI 커뮤니티는 역전파(backpropagation) 과정에서 발생하는 기울기 소실 문제라는 거대한 장벽 앞에서 심층 다층 신경망 연구를 사실상 포기한 상태였다.1 힌튼의 연구는 새로운 알고리즘을 제시했을 뿐만 아니라, 심층 구조가 실제로 ’훈련 가능하며 강력하다’는 개념 증명(proof of concept)을 해냈다는 점에서 그 의의가 크다. 이는 수십 년간 닫혀 있던 연구의 문을 다시 열어젖히는 계기가 되었고, 연구자들에게 심층 모델을 재탐구할 수 있는 ’허락’과 자신감을 부여했다. NIPS 2006에서 벤지오(Bengio) 등이 힌튼의 알고리즘을 즉각적으로 검증하고 확장한 연구를 발표한 것은 8, 학계가 이 돌파구의 잠재력을 얼마나 빠르게 인지하고 반응했는지를 보여주는 명백한 증거이다. 이처럼 2006년의 성과는 기술적 진보와 함께 연구 커뮤니티의 오랜 패러다임을 전환시킨 심리적 혁명이었다.</p>
<h3>2.1  깊은 믿음 신경망(DBN)과 탐욕적 계층별 사전훈련</h3>
<p>심층 신경망 훈련의 근본적인 난제는 데이터가 주어졌을 때 여러 은닉층(hidden layer)의 사후 확률 분포(posterior distribution)를 효율적으로 추론하기 어렵다는 점에 있었다. 특히, 상위 계층의 정보가 하위 계층 뉴런들의 독립성을 깨뜨려 서로 종속적으로 만드는 ‘설명 소거(explaining away)’ 현상은 학습 과정을 매우 복잡하고 비효율적으로 만들었다.10 이는 마치 어떤 결과(예: 집이 흔들림)가 관찰되었을 때, 그 원인이 될 수 있는 여러 독립적인 사건들(예: 지진, 대형 트럭 통과)이 서로 경쟁하며 상호 배타적인 관계가 되는 것과 같다. 이러한 복잡한 의존성 때문에 정확한 추론이 어려워지고, 이는 곧 심층 신경망의 학습 실패로 이어졌다.</p>
<p>이 문제를 해결하기 위해 힌튼, 사이먼 오신데로(Simon Osindero), 이와이 테(Yee-Whye Teh)는 2006년 학술지 <em>Neural Computation</em>에 “깊은 믿음 신경망을 위한 빠른 학습 알고리즘(A Fast Learning Algorithm for Deep Belief Nets)“이라는 기념비적인 논문을 발표했다.13 이 논문의 핵심 아이디어는 전체 네트워크의 모든 가중치를 한 번에 최적화하려는 시도를 버리고, 한 번에 한 층씩(one layer at a time) 탐욕적으로(greedy) 학습하는 것이었다.11 이 계층별 학습 방식은 복잡한 전체 최적화 문제를 다루기 쉬운 여러 개의 작은 문제로 분해함으로써, 심층 구조의 학습을 현실적으로 가능하게 만들었다.</p>
<p>이 계층별 훈련의 기본 구성 단위(building block)는 제한된 볼츠만 머신(Restricted Boltzmann Machine, RBM)이었다. RBM은 관측된 데이터를 받는 가시 유닛(visible units)과 데이터의 특징을 추출하는 은닉 유닛(hidden units)으로 구성된 2층 구조의 무방향성(undirected) 에너지 기반 모델이다.1 RBM의 가장 큰 특징은 같은 층 내의 유닛 간에는 연결이 없고, 오직 가시층과 은닉층 사이에만 대칭적인 가중치로 연결되어 있다는 점이다. 이 ‘제한된’ 구조 덕분에, 한 층의 상태가 주어졌을 때 다른 층에 있는 각 유닛의 활성화 확률을 독립적으로, 그리고 매우 효율적으로 계산할 수 있다.</p>
<p>이러한 RBM을 이용한 비지도 사전훈련(unsupervised pre-training) 과정은 다음과 같이 진행된다.</p>
<ol>
<li>
<p>첫 번째 RBM을 입력 데이터(예: 이미지 픽셀)를 가시층에 입력하여 훈련시킨다. 이 과정은 주로 대조 발산(Contrastive Divergence, CD)이라는 효율적인 근사 알고리즘을 통해 이루어지며, RBM은 데이터의 확률 분포를 모델링하도록 학습하여 데이터의 저차원 특징(feature)을 은닉층에 포착하게 된다.10</p>
</li>
<li>
<p>첫 번째 RBM의 학습이 완료되면, 입력 데이터를 이 RBM에 통과시켜 얻은 은닉 유닛들의 활성화 확률(또는 상태)을 다음 층의 입력 데이터로 사용한다. 즉, 첫 번째 은닉층이 두 번째 RBM의 가시층이 되는 것이다.</p>
</li>
<li>
<p>이 과정을 원하는 깊이의 층이 만들어질 때까지 반복한다. 각 층은 바로 아래 층이 추출한 특징들을 조합하여 더 복잡하고 추상적인 특징을 학습하게 된다. 이 비지도 사전훈련 단계는 전체 신경망의 가중치를 데이터의 통계적 구조를 잘 반영하는 ‘좋은 초기값’ 근처로 유도하는 역할을 한다.1</p>
</li>
</ol>
<p>사전훈련을 통해 전체 네트워크의 가중치가 의미 있는 값으로 초기화된 후, 마지막으로 지도 학습(supervised learning)을 통해 전체 네트워크를 미세조정(fine-tuning)한다. 힌튼의 논문에서는 대조적 버전의 깨움-잠(contrastive wake-sleep) 알고리즘을 사용하여 생성 모델(generative model)의 성능을 최적화했다.11 이 2단계 접근법(비지도 사전훈련 + 지도 미세조정)을 통해 훈련된 3개의 은닉층을 가진 DBN은, 당시 MNIST 손글씨 숫자 분류 문제에서 특별한 사전 지식 없이도 1.25%의 오류율을 기록하며 최고 수준의 판별 모델(discriminative models)들을 능가하는 성능을 보였다.12 이는 심층 구조가 실제로 우수한 성능을 낼 수 있음을 실험적으로 증명한 최초의 사례 중 하나였다.</p>
<h3>2.2  오토인코더를 통한 비선형 차원 축소</h3>
<p>힌튼은 DBN 연구의 성공에 이어, 동료 연구자 루슬란 살라후트디노프(Ruslan Salakhutdinov)와 함께 세계적인 과학 학술지 <em>Science</em>에 “신경망을 이용한 데이터의 차원 축소(Reducing the Dimensionality of Data with Neural Networks)“라는 논문을 발표하며 사전훈련 방법론의 강력함과 범용성을 다시 한번 입증했다.1 이 논문은 AI 커뮤니티를 넘어 과학계 전반에 심층 학습의 잠재력을 각인시키는 결정적인 계기가 되었다.</p>
<p>이 연구의 핵심 모델은 오토인코더(Autoencoder)였다. 오토인코더는 고차원의 입력 데이터를 저차원의 ’코드(code)’로 압축하는 인코더(encoder)와, 이 코드로부터 원본 입력을 최대한 유사하게 복원하는 디코더(decoder)로 구성된 신경망이다.2 네트워크의 학습 목표는 입력과 출력(복원된 결과) 간의 차이, 즉 재구성 오류(reconstruction error)를 최소화하는 것이다. 중앙의 가장 작은 층이 바로 데이터의 압축된 표현, 즉 저차원 코드가 된다.</p>
<p>하지만 DBN과 마찬가지로, 여러 개의 은닉층을 가진 심층 오토인코더 역시 기존의 역전파 방식만으로는 효과적인 훈련이 매우 어려웠다.7 무작위로 초기화된 가중치로는 좋지 않은 지역 최솟값(local minima)에 빠지기 쉬웠기 때문이다. 힌튼과 살라후트디노프는 이 문제를 해결하기 위해 DBN에서 사용했던 계층별 사전훈련 기법을 그대로 적용했다. 먼저, 여러 개의 RBM을 차례로 쌓아 인코더 부분의 가중치를 순차적으로 학습시켰다. 각 RBM은 이전 층의 출력을 입력으로 받아 데이터의 더 추상적인 특징을 학습했다. 이 사전훈련이 완료된 후, 학습된 RBM 스택을 ‘펼쳐서(unfold)’ 인코더와 디코더를 구성했다. 즉, 디코더의 가중치는 인코더 가중치의 전치(transpose) 행렬과 유사한 형태로 초기화되었다. 마지막으로, 전체 오토인코더 네트워크를 역전파 알고리즘으로 미세조정하여 재구성 오류를 최소화했다.1</p>
<p>이러한 방식으로 훈련된 심층 오토인코더는 각 층의 비선형 활성화 함수 덕분에 데이터의 복잡한 비선형적(non-linear) 구조를 학습할 수 있었다. 이는 데이터를 선형적(linear) 초평면에 투영하는 방식인 주성분 분석(Principal Component Analysis, PCA)과 근본적인 차이점이며, 성능의 우위로 직결되었다.1 논문에서는 다양한 데이터셋을 통해 그 효과를 극적으로 보여주었다. MNIST 손글씨 숫자 이미지 데이터에서 심층 오토인코더는 PCA보다 훨씬 낮은 재구성 오류를 보였으며, 데이터를 2차원으로 압축하여 시각화했을 때 PCA보다 훨씬 명확하게 숫자 군집을 분리해냈다.1 또한, 얼굴 이미지나 뉴스 기사 문서 데이터에서도 PCA 기반의 방법(LSA)보다 월등히 우수한 성능을 보이며, 이 방법론이 특정 데이터에 국한되지 않는 범용적인 기술임을 증명했다.7</p>
<h3>2.3  2006년의 반향과 후속 연구</h3>
<p>힌튼의 두 기념비적인 논문과 NIPS 2006에서 발표된 벤지오의 후속 연구가 결합되면서, 2006년은 심층 신경망을 훈련하기 위한 최초의 성공적이고 일반화된 ’레시피(recipe)’가 탄생한 해로 기록되었다. 이 레시피는 바로 <strong>‘탐욕적 계층별 비지도 사전훈련 + 지도 미세조정’</strong> 이라는 2단계 전략이다. 이 방법론의 진정한 힘은 특정 모델에 종속되지 않는 범용성에 있었다. 힌튼은 이 기법을 생성 모델인 DBN과 차원 축소를 위한 오토인코더에 성공적으로 적용했으며 2, 벤지오는 RBM 대신 오토인코더를 사전훈련의 기본 단위로 사용해도 동일하게 효과적임을 보여주었다.9 이처럼 서로 다른 구조와 목적을 가진 모델들에 동일한 원리가 성공적으로 적용될 수 있다는 사실이 입증되면서, 이 ’레시피’는 단순히 하나의 영리한 기법을 넘어 심층 학습 전체를 관통하는 근본적인 방법론으로 자리 잡게 되었다. 이는 이후 등장하는 모든 심층 학습 프레임워크의 기초를 다지는 역할을 했다.</p>
<p>이러한 흐름 속에서, 요슈아 벤지오(Yoshua Bengio) 연구팀은 NIPS 2006에서 “깊은 신경망의 탐욕적 계층별 훈련(Greedy Layer-Wise Training of Deep Networks)“이라는 논문을 발표하며 힌튼의 아이디어를 즉각적으로 검증하고 이론적으로 확장했다.8 이 연구는 탐욕적 계층별 비지도 사전훈련이 두 가지 중요한 역할을 동시에 수행한다는 가설을 실험적으로 뒷받침했다. 첫째, 이 방법은 심층 신경망의 복잡한 오류 표면(error surface)에서 좋은 해법 근처로 가중치를 초기화하는 효과적인 ‘최적화(optimization)’ 전략으로 기능한다. 둘째, 각 층이 레이블 정보 없이 데이터 자체의 분포를 학습하게 함으로써, 입력 데이터의 고차원적이고 추상적인 표현을 생성한다. 이는 과적합(overfitting)을 방지하고 일반화 성능을 향상시키는 일종의 ‘정규화(regularization)’ 효과를 가져온다.8</p>
<p>더 나아가 벤지오의 연구는 RBM 대신 오토인코더를 각 층의 사전훈련에 사용해도 유사한 성능 향상을 얻을 수 있음을 실험적으로 보였다.9 이는 힌튼이 제안한 원리가 특정 모델(RBM)에 국한되지 않는, 보다 일반적인 원리임을 시사하는 중요한 발견이었다. 이처럼 힌튼의 선구적인 제안과 벤지오의 신속하고 심도 있는 후속 연구가 같은 해에 발표되면서, 2006년은 심층 학습 연구의 본격적인 시작을 알리는 원년으로서 그 입지를 확고히 하게 되었다.</p>
<h2>3. 부: 2006년 머신러닝 연구 동향: NIPS를 중심으로</h2>
<p>2006년의 NIPS(신경정보처리시스템학회) 학회 발표 목록은 당시 머신러닝 세계가 ‘얕은 학습(shallow learning)’ 패러다임의 정점에 있었음을 보여주는 중요한 스냅샷이다.17 학회 전반을 지배했던 주제는 서포트 벡터 머신(SVM)과 같은 커널 방법(kernel methods), 정교한 확률적 그래픽 모델, 그리고 컴퓨터 비전 문제를 해결하기 위한 고도의 특징 공학(feature engineering)이었다. 이는 계층적이고 학습된 표현(hierarchical, learned representation)이 부재한 모델들을 가지고 문제를 해결하는 데 학계가 얼마나 정교해졌는지를 보여준다. 바로 이 학회에서 발표된 힌튼과 벤지오의 심층 학습 관련 논문들은 단순한 하나의 연구 트랙이 아니었다. 그것은 특징 계층이 ’설계’되는 것이 아니라 데이터로부터 ’학습’될 수 있다는 점을 시사하며, 당시의 지배적인 패러다임에 대한 정면 도전이었다. NIPS 2006의 발표 목록에서 심층 학습 논문들과 나머지 연구들 사이에 나타나는 극명한 대조는, 전자가 얼마나 혁명적인 성격을 띠고 있었는지를 명확히 보여준다.</p>
<h3>3.1  확률적 그래픽 모델과 베이즈 추론의 지속적 강세</h3>
<p>2006년 머신러닝 학계의 주류는 여전히 데이터의 생성 과정을 확률적으로 모델링하고, 이를 통해 불확실성을 정량화하려는 접근법에 있었다. NIPS 2006의 발표 논문 목록을 살펴보면, 조건부 무작위장(Conditional Random Fields, CRFs), 은닉 마르코프 모델(Hidden Markov Models, HMM), 그리고 비모수적 베이즈 방법론의 대표주자인 계층적 디리클레 과정(Hierarchical Dirichlet Processes, HDP) 등 다양한 그래픽 모델과 베이즈 추론 기법에 대한 연구가 매우 활발히 이루어졌음을 확인할 수 있다.17</p>
<p>이 시기의 주요 연구들은 모델의 표현력과 추론의 정확도를 높이기 위한 정교한 수학적 기법들을 제안하는 데 집중되었다. 예를 들어, “Training Conditional Random Fields for Maximum Labelwise Accuracy“와 같은 논문은 순차적 데이터의 레이블링 정확도를 극대화하기 위한 새로운 학습 기준을 제시했고, “Hierarchical Dirichlet Processes with Random Effects“는 데이터 군집의 수를 미리 정할 필요 없이 데이터로부터 자동으로 구조를 발견하는 비모수적 모델링의 지평을 넓혔다.17 이러한 연구들은 데이터에 내재된 복잡한 통계적 구조를 명시적으로 표현하고 해석하려는 시도가 당시 연구의 핵심적인 흐름이었음을 명확히 보여준다.</p>
<h3>3.2  서포트 벡터 머신(SVM)과 정규화 기법의 발전</h3>
<p>2000년대 중반, 서포트 벡터 머신(SVM)은 분류 및 회귀 문제에서 가장 강력하고 신뢰성 있는 성능을 보이는 ‘얕은(shallow)’ 학습 모델의 대표주자였다. SVM은 커널 트릭(kernel trick)을 통해 입력 데이터를 고차원 특징 공간으로 매핑하여 비선형 문제를 선형적으로 해결하는 강력한 방법론으로, 이론적 견고함과 우수한 일반화 성능 덕분에 학계와 산업계에서 폭넓게 사용되었다. 2006년의 SVM 관련 연구 동향은 주로 두 가지 방향으로 집중되었다. 첫째는 대용량 데이터셋에 대한 SVM의 훈련 속도와 메모리 효율성을 개선하는 것이고, 둘째는 레이블이 지정되지 않은 방대한 양의 데이터를 학습에 활용하는 준지도학습(semi-supervised learning)으로 SVM의 적용 범위를 확장하는 것이었다.17</p>
<p>NIPS 2006에서 발표된 “Branch and Bound for Semi-Supervised Support Vector Machines“는 레이블이 부족한 상황에서도 SVM의 성능을 유지하려는 시도를 보여주는 대표적인 예이며, “Support Vector Machines on a Budget“과 같은 연구는 제한된 계산 자원 내에서 SVM을 효율적으로 훈련하기 위한 알고리즘적 해법을 모색했다.17 이는 SVM이 성숙기에 접어들면서, 그 실용적 한계를 극복하고 적용 범위를 넓히려는 연구 커뮤니티의 노력을 반영한다.</p>
<h3>3.3  컴퓨터 비전의 주요 과제들</h3>
<p>심층 학습이 이미지로부터 특징을 자동으로 학습하는 시대를 열기 전, 2006년의 컴퓨터 비전 연구는 이미지로부터 유용하고 강건한(robust) 특징(feature)을 어떻게 ’설계하고 추출할 것인가’에 대한 깊은 고민에 빠져 있었다. SIFT(Scale-Invariant Feature Transform), HOG(Histogram of Oriented Gradients)와 같은 수작업 특징(hand-crafted feature)들이 주를 이루었으며, 연구자들은 이러한 특징들을 효과적으로 표현하고 모델링하는 방법에 집중했다.</p>
<p>이러한 맥락에서 희소 코딩(Sparse Coding)은 중요한 연구 주제 중 하나였다. 희소 코딩은 이미지를 소수의 ‘기저(basis)’ 벡터들의 선형 조합으로 표현하여, 간결하면서도 핵심적인 정보를 담은 표현을 학습하는 비지도 학습 방법이다. 이는 뇌의 시각 피질이 정보를 처리하는 방식과 유사하다는 점에서 이론적 관심을 끌었으며, 이미지 노이즈 제거, 압축, 특징 추출 등에서 뛰어난 성능을 보였다. NIPS 2006에서 앤드류 응(Andrew Ng) 연구팀이 발표한 “Efficient sparse coding algorithms“는 희소 코딩을 대규모 이미지 데이터에 적용하기 위한 계산 효율성을 높이는 데 기여했다.17 또한, “Detecting Humans via Their Pose“와 같은 연구는 사람의 신체 부위(parts) 간의 관계를 모델링하여 복잡한 배경 속에서도 사람을 탐지하는 정교한 접근법을 제시했다.17 이러한 연구들은 심층 학습 시대 이전의 연구자들이 비전 문제를 해결하기 위해 얼마나 정교하고 창의적인 방식으로 특징과 모델을 설계했는지를 보여주는 중요한 사례이다.</p>
<h2>4. 부: 로봇 공학의 진보: SLAM, 휴머노이드, 그리고 산업 동향</h2>
<p>2006년 로봇 공학 분야의 발전은 두 가지 뚜렷한 경로의 분기를 보여준다. 하나는 SLAM 커뮤니티에서 나타난 ’알고리즘적 정교화’이고, 다른 하나는 혼다의 아시모 프로젝트에서 보여준 ’시스템 통합’을 통한 발전이다. SLAM 연구자들은 EKF와 파티클 필터 접근법의 수학적, 계산적 장단점을 놓고 치열하게 논쟁하며 알고리즘의 핵심을 개선하는 데 집중했다.3 ICRA 2006의 발표 목록은 “FastSLAM 알고리즘의 일관성”, “EKF-SLAM의 불확실성 경계 설정” 등 알고리즘 최적화에 대한 깊은 탐구를 보여준다.22 반면, 아시모의 새로운 능력들은 단일 알고리즘의 혁신이 아닌, 진보된 기계 역학, 다중 센서(시각, 힘, 초음파), 그리고 제어 시스템의 성공적인 통합의 결과물이었다.6 이는 로봇 공학의 발전이 특정 수학 문제에 대한 깊고 좁은 탐구와, 복잡하고 광범위한 시스템 수준의 공학이라는 두 가지 트랙 위에서 동시에 진행됨을 명확히 보여준다.</p>
<h3>4.1  동시적 위치 추정 및 지도 작성(SLAM) 기술의 성숙</h3>
<p>SLAM은 GPS와 같은 외부 위치 결정 시스템의 도움 없이, 로봇이 자신의 센서(예: 레이저 스캐너, 카메라) 데이터만을 이용해 미지의 환경을 탐험하면서 동시에 주변 환경의 지도를 작성하고, 그 지도 내에서 자신의 위치를 실시간으로 추정하는 자율 이동 로봇의 핵심 문제이다.3 2006년은 이 근본적인 문제에 대한 주요 확률적 접근법들이 이론적으로 성숙하고 실제 적용을 위한 구체적인 알고리즘으로 다듬어지던 시기였다.</p>
<p>당시 SLAM 연구 커뮤니티는 확률적 베이즈 필터(Bayesian Filter)에 기반한 두 가지 주요 패러다임을 중심으로 경쟁하고 발전했다.4</p>
<p>첫 번째는 <strong>확장 칼만 필터(Extended Kalman Filter, EKF-SLAM)</strong> 기반 접근법이다. 이 방법은 로봇의 현재 위치(자세)와 환경 내 모든 랜드마크(특징점)의 위치를 하나의 거대한 상태 벡터(state vector)로 정의하고, 이들의 불확실성을 단일 다변량 가우시안 분포로 근사하여 추정한다.21 EKF-SLAM의 가장 큰 장점은 랜드마크 위치 추정치 간의 상관관계를 공분산 행렬에 명시적으로 유지한다는 점이다. 새로운 관측이 들어올 때마다 이 상관관계를 이용해 이전에 관측했던 모든 랜드마크의 위치를 함께 갱신함으로써, 전역적으로 일관된 지도를 생성하는 데 유리했다.3 하지만 치명적인 단점도 존재했다. 랜드마크의 수가 증가함에 따라 공분산 행렬의 크기가 랜드마크 수의 제곱(O(K2))으로 커져 계산 복잡도가 매우 높았고, 로봇의 움직임이나 관측 모델이 강한 비선형성을 띨 경우, 선형화 과정에서 발생하는 오차로 인해 필터가 발산할 위험이 컸다.21</p>
<p>두 번째는 <strong>Rao-Blackwellized 파티클 필터(FastSLAM)</strong> 기반 접근법이다. 이 방법은 복잡한 SLAM 문제를 두 개의 더 간단한 문제로 분해하는 독창적인 아이디어에 기반한다. 즉, 로봇의 전체 경로를 추정하는 문제와, 만약 로봇의 경로가 주어진다면 각 랜드마크의 위치는 서로 독립적으로 추정될 수 있다는 점을 이용하는 것이다.21 FastSLAM은 로봇의 가능한 경로들을 다수의 파티클(particle)로 표현하고, 각 파티클은 자신만의 랜드마크 지도(저차원 칼만 필터들의 집합)를 독립적으로 유지한다. 이 구조 덕분에 로봇의 비선형적인 움직임을 선형화할 필요가 없어 비선형성에 강건하며, 데이터 연관(data association) 과정에서의 불확실성을 여러 파티클을 통해 자연스럽게 표현할 수 있었다.26 그러나 이 방법 역시 한계가 있었다. 시간이 지남에 따라 소수의 유망한 파티클들만 살아남고 나머지는 소멸하여 경로 추정의 다양성이 사라지는 ‘파티클 고갈(particle depletion)’ 문제가 발생할 수 있으며, 이는 장기적인 탐사에서 불확실성을 과소평가하는 결과로 이어질 수 있었다.26</p>
<p>2006년 ICRA와 같은 주요 로봇 학회에서는 이 두 방법론의 이론적 한계를 극복하고 일관성(consistency), 효율성, 강건성(robustness)을 개선하기 위한 다양한 연구들이 발표되었다.20 “Consistency of the FastSLAM Algorithm”, “Speeding-up Rao-blackwellized SLAM”, “Bounding Uncertainty in EKF-SLAM” 등의 논문 제목들은 당시 연구계가 두 패러다임의 장점을 취하고 단점을 보완하려는 치열한 노력을 기울이고 있었음을 명확히 보여준다.22</p>
<table><thead><tr><th>특징 (Feature)</th><th>EKF-SLAM</th><th>FastSLAM (Rao-Blackwellized Particle Filter)</th></tr></thead><tbody>
<tr><td><strong>핵심 원리 (Core Principle)</strong></td><td>로봇과 모든 랜드마크의 상태를 단일 고차원 가우시안으로 모델링 21</td><td>로봇 경로를 파티클 집합으로 표현하고, 각 파티클에 대해 랜드마크를 독립적인 저차원 칼만 필터로 추정 21</td></tr>
<tr><td><strong>상태 표현 (State Representation)</strong></td><td>하나의 거대한 상태 벡터 <span class="math math-inline">x_t = (s_t^T, \theta_0^T,..., \theta_K^T)^T</span> 와 공분산 행렬 <span class="math math-inline">\Sigma</span> 21</td><td>M개의 파티클 집합, 각 파티클은 경로 가설과 K개의 작은 EKF(평균, 공분산)로 구성 21</td></tr>
<tr><td><strong>계산 복잡도 (Complexity)</strong></td><td>랜드마크 수(K)에 대해 <span class="math math-inline">O(K^2)</span> 21</td><td>파티클 수(M)와 랜드마크 수(K)에 대해 <span class="math math-inline">O(M \log K)</span> 21</td></tr>
<tr><td><strong>선형성 가정 (Linearity Assumption)</strong></td><td>로봇 모션 및 관측 모델의 지역적 선형성 가정이 필수적. 강한 비선형성에서 발산 위험 26</td><td>로봇 모션 모델에 대한 선형화 불필요. 랜드마크 관측 모델만 선형화하여 비선형성에 더 강건함 26</td></tr>
<tr><td><strong>장점 (Strengths)</strong></td><td>모든 랜드마크 간의 상관관계를 명시적으로 유지하여 일관성 있는 맵 생성에 유리 3</td><td>데이터 연관(Data Association) 불확실성에 강하고, 비선형적 환경에 더 잘 적응함 26</td></tr>
<tr><td><strong>단점 (Weaknesses)</strong></td><td>높은 계산 비용, 비선형성 및 데이터 연관 실패에 취약함 26</td><td>파티클 고갈(Particle Depletion) 문제로 장기적인 경로에서 불확실성을 과소평가할 수 있음 26</td></tr>
</tbody></table>
<h3>4.2  휴머노이드 로봇의 실용화를 향한 도약: 혼다 아시모(ASIMO)</h3>
<p>2006년을 전후하여 혼다가 발표한 새로운 아시모(ASIMO)는 휴머노이드 로봇 연구의 패러다임이 기초 보행 기술 확보 단계를 넘어, 실제 인간 생활 환경에서 유용한 작업을 수행하는 실용적 기능 구현 단계로 진입했음을 알리는 중요한 이정표였다.6 이전 모델들이 안정적인 이족 보행과 계단 오르기 등 이동 능력 자체에 집중했다면, 이 시기의 아시모는 주변 환경을 인식하고 인간과 상호작용하며 구체적인 임무를 수행하는 능력에 초점을 맞추었다.</p>
<p>2005년 12월에 발표되어 2006년부터 본격적으로 운용된 새로운 아시모의 핵심적인 발전 사항은 다음과 같다.</p>
<ul>
<li>
<p><strong>향상된 이동 능력:</strong> 가장 눈에 띄는 발전은 주행 능력이었다. 이전 모델의 시속 3km/h에서 두 배 향상된 시속 6km/h로 달릴 수 있게 되었는데, 이는 사람이 빠르게 걷는 속도와 유사하다.6 단순히 속도만 빨라진 것이 아니라, 원을 그리며 달릴 때 원심력에 대응하여 몸의 중심을 안쪽으로 자연스럽게 기울이는 등 고도의 동적 균형 제어 기술이 적용되었다. 이를 통해 아시모는 공중에 떠 있는 시간(airborne time)을 갖는 진정한 의미의 ’달리기’를 구현했다.6</p>
</li>
<li>
<p><strong>고도화된 작업 수행 능력:</strong> 아시모는 이제 단순한 물체 조작을 넘어, 힘 제어(force control)가 통합된 섬세한 작업을 수행할 수 있게 되었다. 양 팔의 손목에 장착된 힘 센서(kinesthetic sensor)를 이용해 카트를 미는 힘을 조절하며 부드럽게 운반하거나, 사람이 건네는 쟁반을 안정적으로 받아들고 전달하는 작업이 가능해졌다.6 이는 로봇이 단순히 정해진 위치로 움직이는 것을 넘어, 외부 환경과의 물리적 상호작용을 실시간으로 조절할 수 있게 되었음을 의미한다.</p>
</li>
<li>
<p><strong>자율적인 인간-로봇 상호작용:</strong> 혼다가 독자적으로 개발한 IC 통신 카드(IC Tele-interaction Communication Card)를 통해 특정 인물을 식별하고, 그 사람의 움직임에 맞춰 자율적으로 행동하는 능력이 크게 향상되었다.6 예를 들어, 방문객에게 안내 서비스를 제공하거나, 사람의 손을 잡고 보조를 맞춰 함께 걷는 등, 사람과 ’동기화(in sync)’된 행동이 가능해졌다. 이러한 기능들은 아시모가 통제된 환경을 벗어나 사무실과 같은 실제 공간에서 접수원이나 안내원과 같은 서비스 업무를 자율적으로 수행할 수 있는 가능성을 열어주었다.31</p>
</li>
</ul>
<p>혼다는 이러한 기술적 성과를 대중에게 적극적으로 알리는 데에도 힘썼다. 2006년 12월, 아시모를 주인공으로 한 TV 광고 캠페인을 전개하여 기술적 친숙함을 높였고 33, 미국 디즈니랜드의 투모로우랜드에 “아시모에게 인사하세요(Say Hello To ASIMO)“라는 상설 쇼를 개설하여 수많은 방문객에게 아시모의 놀라운 능력을 직접 선보였다.34 이는 아시모를 단순한 연구 개발의 결과물이 아닌, 미래 생활의 일부가 될 수 있는 친근한 존재로 포지셔닝하려는 전략의 일환이었다.</p>
<h3>4.3  산업용 로봇 시장의 변화</h3>
<p>2006년의 산업용 로봇 시장 데이터는 세계 제조업 지형의 미묘하지만 중대한 변화를 예고하는 선행 지표였다. 북미와 같은 성숙 시장에서는 자동차 산업의 주기적인 투자 감소로 인해 로봇 판매량이 일시적으로 하락했지만, 중국을 필두로 한 신흥 시장에서는 자동차 산업을 중심으로 로봇 도입이 폭발적으로 증가했다. 이러한 상반된 흐름은 로봇이 말 그대로 공장을 따라 이동하고 있음을 보여준다. 2005년 북미 자동차 업계의 대규모 투자로 최고치를 기록했던 산업용 로봇 시장은 2006년에 30%가량 급감하는 뚜렷한 조정기를 맞았다.35 이는 대규모 설비 투자가 일단락된 후 나타나는 자연스러운 주기적 현상이었다.</p>
<p>그러나 이 시기의 가장 중요하고 장기적인 추세는 두 가지 방향에서 나타났다. 첫째는 <strong>비자동차 분야로의 확산</strong>이었다. 2006년 북미 시장에서 자동차 산업의 로봇 주문은 급감했지만, 비자동차 분야의 주문은 사상 최고치를 기록했다. 이로 인해 전체 로봇 주문에서 비자동차 분야가 차지하는 비중은 2005년의 30%에서 2006년에는 44%로 극적으로 증가했다.35 특히 식음료, 목재, 제지, 가구, 생명 과학, 플라스틱 및 고무 등 매우 다양한 산업에서 로봇 도입이 활발해졌다.35 이는 로봇 기술이 과거보다 더 유연해지고, 사용자 친화적이 되며, 비용 효율성이 높아짐에 따라 전통적인 강세 분야였던 자동차 및 전자 산업의 경계를 넘어 제조업 전반으로 확산되고 있음을 보여주는 중요한 신호였다.38</p>
<p>둘째는 <strong>제조업의 글로벌 중심 이동</strong>이다. 북미 시장이 조정을 겪는 동안, 아시아, 특히 중국의 산업용 로봇 시장은 급성장했다. 2006년 중국은 전년 대비 29% 증가한 5,800대의 산업용 로봇을 도입하며 아시아에서 세 번째로 큰 시장으로 부상했다. 중국 시장의 성장을 견인한 것 역시 자동차 산업이었지만, 고무, 플라스틱, 전자 산업의 수요 또한 빠르게 증가하고 있었다.36 산업용 로봇은 공장 신설 및 현대화와 직결된 핵심 자본재이다. 따라서 2006년에 나타난 북미 시장의 감소와 중국 시장의 급증이라는 상반된 동향은, 세계 제조업의 자본과 인프라가 기존의 서구 선진국에서 아시아 신흥국으로 대규모로 이전되고 있던 당시의 거시 경제적 흐름을 물리적으로 보여주는 명백한 증거였다.</p>
<h2>5. 결론: 2006년의 유산과 미래 전망</h2>
<p>2006년은 인공지능과 로봇 공학에서 서로 다른 성격의 중요한 이정표를 세운 해였다. AI 분야에서는 심층 학습이라는, 이후 10년 이상 기술 지형을 완전히 바꿔놓을 파괴적 혁신의 씨앗이 뿌려졌다. 반면 로봇 공학 분야에서는 SLAM, 휴머노이드, 산업용 로봇 기술이 수년에 걸친 꾸준한 발전을 통해 신뢰성과 실용성을 높이며 내실을 다지는 진화적 성숙을 보여주었다. 이 두 분야는 각기 다른 서사를 써 내려갔다.</p>
<p>힌튼과 벤지오의 연구는 ’데이터로부터 특징을 어떻게 학습할 것인가’라는 머신러닝의 근본적인 질문에 새로운 패러다임을 제시했다. 계층별 비지도 사전훈련이라는 아이디어는 수십 년간 해결 불가능해 보였던 심층 신경망의 훈련 문제를 해결했을 뿐만 아니라, 특징 공학에 대한 의존도를 낮추고 데이터 기반의 표현 학습(representation learning) 시대를 여는 계기가 되었다. 이 혁신은 향후 컴퓨터 비전, 자연어 처리, 음성 인식 등 AI의 모든 하위 분야에 지대한 영향을 미쳤으며, 로봇이 더 정교한 인식(perception) 능력을 갖추는 데 필수적인 기반 기술이 되었다.</p>
<p>2006년 당시에는 AI의 혁신과 로봇 공학의 진화가 다소 독립적인 경로로 진행되는 것처럼 보였을 수 있다. 그러나 장기적인 관점에서 볼 때, 2006년에 시작된 AI의 혁명은 로봇이 단순히 정해진 동작을 반복하는 기계를 넘어, 복잡한 실제 환경을 스스로 이해하고, 예측 불가능한 상황에 지능적으로 적응하며, 인간과 자연스럽게 상호작용하는 진정한 의미의 자율적 에이전트로 발전하는 데 결정적인 동력을 제공하게 될 것이었다. 따라서 2006년은 AI와 로봇 공학이라는 두 거대한 기술 흐름이 미래의 어느 한 지점에서 만나 폭발적인 시너지를 일으킬 ’위대한 융합’의 서막을 연 해로 기억될 것이다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>Reducing the Dimensionality of Data with Neural Networks | by Deep Learning - Medium, https://medium.com/@deeplearning1/reducing-the-dimensionality-of-data-with-neural-networks-c9b45871ff84</li>
<li>(PDF) Reducing the Dimensionality of Data with Neural Networks (2006) | Geoffrey E. Hinton | 20400 Citations - SciSpace, https://scispace.com/papers/reducing-the-dimensionality-of-data-with-neural-networks-51w34pmjfl</li>
<li>Simultaneous Localisation and Mapping (SLAM): Part I The Essential Algorithms - People @EECS, https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/Durrant-Whyte_Bailey_SLAM-tutorial-I.pdf</li>
<li>Past, Present, and Future of Simultaneous Localization And Mapping - cs.wisc.edu, https://pages.cs.wisc.edu/~jphanna/teaching/25spring_cs639/resources/SLAM-past-present-future.pdf</li>
<li>Honda humanoid robots development - ResearchGate, https://www.researchgate.net/publication/6651194_Honda_humanoid_robots_development</li>
<li>Honda Debuts New ASIMO | Honda Global Corporate Website, https://global.honda/en/newsroom/news/2005/c051213-asimo-eng.html</li>
<li>Reducing the Dimensionality of Data with Neural Networks, https://www.cs.toronto.edu/~hinton/absps/science.pdf</li>
<li>Greedy Layer-Wise Training of Deep Networks, https://proceedings.neurips.cc/paper/3048-greedy-layer-wise-training-of-deep-networks.pdf</li>
<li>(PDF) Greedy layer-wise training of deep networks - ResearchGate, https://www.researchgate.net/publication/303137904_Greedy_layer-wise_training_of_deep_networks</li>
<li>A Fast Learning Algorithm for Deep Belief Nets — All Things Phi, https://allthingsphi.com/blog/2016/12/08/a-fast-learning-algorithm-for-deep-belief-nets.html</li>
<li>A Fast Learning Algorithm for Deep Belief Nets - ResearchGate, https://www.researchgate.net/publication/7017915_A_Fast_Learning_Algorithm_for_Deep_Belief_Nets</li>
<li>A fast learning algorithm for deep belief nets - Department of …, https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf</li>
<li>A Fast Learning Algorithm for Deep Belief Nets - Economics of AI, https://www.economicsofai.com/s/intro.pdf</li>
<li>[PDF] A Fast Learning Algorithm for Deep Belief Nets - Semantic Scholar, https://www.semanticscholar.org/paper/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero/8978cf7574ceb35f4c3096be768c7547b28a35d0</li>
<li>A Fast Learning Algorithm for Deep Belief Nets - Department of Computer Science, University of Toronto, https://www.cs.toronto.edu/~fritz/absps/ncfast.pdf</li>
<li>(PDF) Greedy layer-wise training of deep networks - ResearchGate, https://www.researchgate.net/publication/200744514_Greedy_layer-wise_training_of_deep_networks</li>
<li>Advances in Neural Information Processing Systems 19 (NIPS 2006), https://proceedings.neurips.cc/paper/2006</li>
<li>List of Proceedings, https://papers.nips.cc/</li>
<li>An Overview on the Advancements of Support Vector Machine Models in Healthcare Applications: A Review - MDPI, https://www.mdpi.com/2078-2489/15/4/235</li>
<li>Evaluation of algorithms for bearing-only SLAM - Rutgers University, https://scholarship.libraries.rutgers.edu/esploro/outputs/conferenceProceeding/Evaluation-of-algorithms-for-bearing-only-SLAM/991031666199804646</li>
<li>EKF SLAM vs. FastSLAM – A Comparison - Infoscience, https://infoscience.epfl.ch/bitstreams/d5871034-a345-4220-9e46-293f9e66e02a/download</li>
<li>Proceedings of the 2006 IEEE International Conference on Robotics …, https://researchr.org/publication/icra%3A2006</li>
<li>Review on simultaneous localization and mapping (SLAM) - ResearchGate, https://www.researchgate.net/publication/305194581_Review_on_simultaneous_localization_and_mapping_SLAM</li>
<li>
<ol start="46">
<li>Simultaneous Localization and Mapping - CS@Columbia, https://www.cs.columbia.edu/~allen/F19/NOTES/slam_paper.pdf</li>
</ol>
</li>
<li>SLAM Tutorial - CS@Columbia, https://www.cs.columbia.edu/~allen/F19/NOTES/slam_pka.pdf</li>
<li>HybridSLAM: Combining FastSLAM and EKF-SLAM for reliable mapping - The University of Sydney, https://www-personal.acfr.usyd.edu.au/tbailey/papers/brooks08.pdf</li>
<li>SLaM Tutorial (Part I), https://cse.sc.edu/~yiannisr/774/2015/SLAM1.pptx</li>
<li>SEIF, EnKF, EKF SLAM, Fast SLAM, Graph SLAM - People @EECS, https://people.eecs.berkeley.edu/~pabbeel/cs287-fa11/slides/SEIF_EnKF_EKFSLAM_FastSLAM_GraphSLAM.pdf</li>
<li>EKF-SLAM hands-on tutorial - Jihong Ju, https://jihongju.github.io/2019/07/06/ekfslam-hands-on-tutorial/</li>
<li>The new ASIMO model (Honda, 2006). - ResearchGate, https://www.researchgate.net/figure/The-new-ASIMO-model-Honda-2006_fig3_221710040</li>
<li>Honda ASIMO Robot Now Does Chores - BetaNews, https://betanews.com/2005/12/13/honda-asimo-robot-now-does-chores/</li>
<li>How ASIMO Works - Science | HowStuffWorks, https://science.howstuffworks.com/asimo.htm</li>
<li>Honda’s Asimo makes TV debut | Advertising - The Guardian, https://www.theguardian.com/media/2006/dec/15/advertising</li>
<li>ASIMO - YouTube, https://www.youtube.com/watch?v=JlRPICfnmhw</li>
<li>Non-Automotive Orders for Robots Rise in 2006, But Overall Sales Fall 30% in North America - A3 Association for Advancing Automation, https://www.automate.org/robotics/news/non-automotive-orders-for-robots-rise-in-2006-but-overall-sales-fall-30-in-north-america</li>
<li>EXECUTIVE SUMMARY 2006 World Robot Market, http://www.diag.uniroma1.it/deluca/rob1_en/2007_WorldRobotics_ExecSummary.pdf</li>
<li>World robotics 2006 executive summary | Industrial Robot | Emerald Publishing, https://www.emerald.com/insight/content/doi/10.1108/ir.2007.04934bab.008/full/html</li>
<li>ITP Sensors and Automation: Robotics in Manufacturing Technology Roadmap, November 2006 - eere.energy.gov, https://www1.eere.energy.gov/manufacturing/industries_technologies/sensors_automation/pdfs/robotics_roadmap.pdf</li>
<li>The new hire: How a new generation of robots is transforming manufacturing, https://www.nist.gov/system/files/documents/mep/data/TheNewHire.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>