<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:1998년 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>1998년 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2006년 이전의 AI 및 로봇 연구 동향</a> / <span>1998년 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>1998년 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 1998년, 현대 인공지능의 여명을 열다</h2>
<p>1998년은 인공지능(AI)과 로봇 공학의 역사에서 단순한 한 해가 아닌, 중대한 패러다임 전환이 시작된 변곡점으로 기록된다. 이 시기는 기존의 지배적인 연구 방법론들이 정점에 달하는 동시에, 향후 수십 년을 지배할 새로운 사상의 씨앗이 뿌려진 ’성숙’과 ’잉태’의 해였다. 한편에서는 서포트 벡터 머신(SVM)과 같은 통계적 학습 이론이 절정을 이루며 수학적 우아함과 강력한 성능을 과시했고, 다른 한편에서는 훗날 딥러닝 혁명을 촉발할 그래디언트 기반 종단간 학습(end-to-end learning)의 원형이 제시되었다. 강화학습 분야에서는 그간 축적된 연구들이 하나의 통일된 이론적 체계로 집대성되었으며, 로봇 공학에서는 불확실성을 다루는 확률적 접근법이 자율 시스템의 새로운 가능성을 열었다.</p>
<p>본 보고서는 1998년에 발표된 주요 연구들을 심층적으로 분석하여, 당시의 기술적 성취를 조명하고 이들이 현대 AI 및 로봇 공학에 미친 심대한 영향을 추적한다. 보고서는 크게 세 가지 핵심 주제를 중심으로 전개된다. 첫째, 학습 기반 특징 추출의 서막을 연 합성곱 신경망(CNN)과 커널 방법론의 철학적 대립을 탐구한다. 둘째, 로봇의 지능화와 자율성 증대를 이끈 확률적 로봇 공학과 고차원 경로 계획 기술의 발전을 분석한다. 셋째, AI 계획(Planning)의 표준화, 컴퓨터 비전의 주류 연구, 그리고 감성 컴퓨팅과 같은 새로운 연구 영역의 확장을 다룬다.</p>
<p>이러한 분석을 통해, 1998년이 단지 과거의 기록이 아니라 현재 우리가 마주한 AI 기술의 근간을 이해하는 데 필수적인 통찰을 제공하는 시기임을 명확히 하고자 한다. 아래 표는 본 보고서에서 다룰 1998년의 핵심 연구들을 요약한 것이다.</p>
<p><strong>표 1: 1998년 AI 및 로봇 분야 주요 연구 요약</strong></p>
<table><thead><tr><th>분야</th><th>주요 연구</th><th>저자/주도자</th><th>핵심 기여</th><th>발표 학회/저널</th></tr></thead><tbody>
<tr><td><strong>컴퓨터 비전 / 딥러닝</strong></td><td>“Gradient-Based Learning Applied to Document Recognition” (LeNet-5)</td><td>Y. LeCun, L. Bottou, Y. Bengio, P. Haffner</td><td>종단간 학습이 가능한 합성곱 신경망(CNN) 아키텍처 제시, 자동 특징 추출 패러다임의 시작</td><td>Proceedings of the IEEE</td></tr>
<tr><td><strong>기계 학습 이론</strong></td><td>“Kernel PCA and De-Noising in Feature Spaces”</td><td>B. Schölkopf, A. Smola, K. Müller</td><td>커널 트릭을 이용한 비선형 주성분 분석 방법론 정립</td><td>NIPS’98</td></tr>
<tr><td><strong>강화 학습</strong></td><td>“Reinforcement Learning: An Introduction”</td><td>R. Sutton, A. Barto</td><td>강화학습 분야의 핵심 개념과 알고리즘을 집대성한 교과서적 저작</td><td>MIT Press</td></tr>
<tr><td><strong>강화 학습</strong></td><td>“The MAXQ Method for Hierarchical Reinforcement Learning”</td><td>T. Dietterich</td><td>계층적 강화학습을 위한 가치 함수 분해 방법론 제시</td><td>ICML’98</td></tr>
<tr><td><strong>로봇 공학</strong></td><td>“Integrating topological and metric maps for mobile robot navigation”</td><td>S. Thrun, W. Burgard, D. Fox</td><td>확률적 접근을 통한 로봇의 지도 작성 및 위치 추정(SLAM) 기술의 기반 마련</td><td>AAAI’98 / ICRA’98</td></tr>
<tr><td><strong>AI 계획</strong></td><td>제1회 AI Planning Systems (AIPS) Competition</td><td>AIPS’98 조직위원회</td><td>계획 문제 표준 표기법 PDDL(Planning Domain Definition Language) 도입 및 벤치마크 확립</td><td>AIPS’98</td></tr>
</tbody></table>
<h2>2.  기계 학습의 패러다임 전환: 학습 기반 특징 추출의 서막</h2>
<p>1998년 기계 학습 분야는 두 개의 강력한 철학이 공존하며 지적 긴장감을 형성하던 시기였다. 한 축은 정교한 수학적 이론에 기반하여 데이터의 특징 공간을 변환하는 커널 방법론이었고, 다른 한 축은 생물학적 영감에서 출발하여 데이터로부터 직접 특징을 학습하려는 신경망 접근법이었다. 당시 주류는 전자에 가까웠으나, 후자는 훗날 필드를 완전히 재편할 잠재력을 품고 있었다. 이 장에서는 이러한 패러다임 전환의 전조를 보인 LeNet-5의 등장, 당시 최첨단 기술이었던 서포트 벡터 머신과 커널 방법론의 확립, 그리고 강화학습 분야의 이론적 기반 정립 과정을 심층적으로 분석한다.</p>
<h3>2.1  합성곱 신경망의 등장: LeNet-5와 그래디언트 기반 학습</h3>
<p>1998년, Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner는 IEEE 회보(Proceedings of the IEEE)에 “Gradient-Based Learning Applied to Document Recognition“이라는 기념비적인 논문을 발표했다.1 이 논문은 단순히 새로운 알고리즘을 제시한 것을 넘어, 패턴 인식 분야의 오랜 지배적 패러다임에 근본적인 질문을 던졌다. 당시 표준적인 접근법은 전문가가 직접 특징 추출기(feature extractor)를 설계하고, 그 결과물을 학습 가능한 분류기(trainable classifier)에 입력하는 방식이었다.3 이 방식의 성능은 전적으로 전문가의 직관과 노력에 의존했다. LeCun과 동료들은 이러한 수작업 기반의 특징 공학을 비판하며, 원시 데이터(raw pixels)로부터 직접 특징 계층을 학습하는 ‘종단간 학습’ 패러다임의 우수성을 LeNet-5라는 구체적인 아키텍처를 통해 입증했다.1</p>
<h4>2.1.1 LeNet-5 아키텍처 심층 분석</h4>
<p>LeNet-5는 현대 딥러닝 아키텍처의 원형으로 평가받으며, 합성곱(Convolution)과 부표본추출(Subsampling, 또는 풀링) 연산을 교대로 쌓아올려 입력 이미지의 공간적 위계 구조를 학습하도록 설계되었다. 32x32 픽셀 크기의 흑백 이미지를 입력받는 LeNet-5의 구조는 다음과 같다.2</p>
<ol>
<li>
<p><strong>C1 (첫 번째 합성곱 계층):</strong> 6개의 특징 맵(feature map)으로 구성된다. 각 특징 맵은 5x5 크기의 커널(필터)을 사용하여 입력 이미지와 합성곱 연산을 수행한다. 이 계층의 핵심은 ‘가중치 공유(weight sharing)’ 개념으로, 하나의 특징 맵 내 모든 유닛은 동일한 커널 가중치를 공유한다. 이는 학습할 파라미터 수를 획기적으로 줄여주며, 이미지의 특정 위치에 무관하게 동일한 특징(예: 수직선, 모서리)을 감지하는 이동 불변성(translation invariance)을 부여한다.</p>
</li>
<li>
<p><strong>S2 (첫 번째 부표본추출 계층):</strong> C1의 6개 특징 맵 각각에 대해 2x2 영역의 평균을 계산하고(average pooling), 가중치를 곱한 후 편향을 더해 다음 계층으로 전달한다. 이 과정은 특징 맵의 해상도를 절반으로 줄여 계산 효율성을 높이고, 입력의 미세한 변형에 대한 강건성(robustness)을 증대시킨다.</p>
</li>
<li>
<p><strong>C3 (두 번째 합성곱 계층):</strong> 16개의 특징 맵으로 구성되며, S2 계층의 특징 맵들을 다양한 조합으로 입력받아 5x5 커널로 합성곱 연산을 수행한다. 이를 통해 이전 계층에서 학습된 저수준 특징들(선, 모서리 등)을 조합하여 더 복잡하고 추상적인 고수준 특징(곡선, 특정 형태 등)을 학습한다.</p>
</li>
<li>
<p><strong>S4 (두 번째 부표본추출 계층):</strong> C3의 16개 특징 맵 각각에 대해 S2와 동일한 방식으로 2x2 평균 풀링을 적용한다.</p>
</li>
<li>
<p><strong>C5 (세 번째 합성곱 계층):</strong> 120개의 1x1 특징 맵으로 구성된다. S4의 모든 특징 맵과 5x5 커널로 합성곱 연산을 수행하는데, 이는 사실상 완전 연결(fully connected) 계층과 동일한 연산이다.</p>
</li>
<li>
<p><strong>F6 (완전 연결 계층):</strong> 84개의 유닛으로 구성되며, C5의 120개 유닛과 모두 연결된다.</p>
</li>
<li>
<p><strong>출력 계층:</strong> 10개의 유닛으로 구성되며, 각 유닛은 0부터 9까지의 숫자를 나타낸다. 활성화 함수로는 주로 하이퍼볼릭 탄젠트(<code>tanh</code>)나 시그모이드 함수가 사용되었다.4</p>
</li>
</ol>
<h4>2.1.2 수학적 기반: 그래디언트 기반 종단간 학습</h4>
<p>LeNet-5의 진정한 혁신성은 아키텍처 자체뿐만 아니라, 전체 시스템이 하나의 거대한 미분 가능한 함수처럼 취급되어 역전파(Backpropagation) 알고리즘을 통해 종단간으로 학습된다는 점에 있다.4 시스템의 최종 출력과 정답 레이블 간의 손실 함수(loss function)를 정의하고, 이 손실을 최소화하기 위해 그래디언트 하강법(gradient descent)을 사용한다. 손실 함수의 그래디언트는 출력 계층에서부터 입력 계층까지, 풀링과 합성곱 연산을 거슬러 전파되며 모든 학습 가능한 가중치(커널 가중치, 편향 등)를 업데이트한다. 이는 특징 추출기와 분류기가 분리되어 있던 기존 방식과 달리, 분류 성능에 가장 도움이 되는 방향으로 특징 추출기(합성곱 계층)가 스스로를 최적화하도록 만든다.</p>
<p>더 나아가, LeCun 등은 이 개념을 개별 문자 인식을 넘어 전체 문서 인식 시스템으로 확장하는 ’그래프 변환기 네트워크(Graph Transformer Networks, GTN)’라는 더 큰 비전을 제시했다.1 GTN은 필드 추출, 문자 분할, 문자 인식, 언어 모델링 등 여러 모듈로 구성된 복잡한 시스템 전체를 그래디언트 기반 학습으로 통합하여 전역적인 성능 지표를 최적화하는 패러다임을 제안한 것으로, 이는 LeNet-5의 철학을 시스템 수준으로 확장한 것이다.2 이 시스템은 단순한 학문적 연구에 그치지 않고, 실제로 NCR사에 의해 상용화되어 미국 전역의 은행에서 매달 수백만 장의 수표를 판독하는 데 사용되었다.1 이는 1998년 당시 AI 연구가 실질적인 산업적 가치를 창출할 수 있음을 보여준 중요한 사례였다.</p>
<h3>2.2  서포트 벡터 머신과 커널 방법론의 확립</h3>
<p>LeNet-5가 미래를 향한 급진적인 제안이었다면, 1998년 기계 학습의 현재를 지배한 것은 서포트 벡터 머신(SVM)과 커널 방법론이었다. 이 접근법은 블라디미르 바프닉(Vladimir Vapnik)의 통계적 학습 이론(Statistical Learning Theory)에 깊이 뿌리내리고 있으며, 복잡한 최적화 문제 없이도 높은 일반화 성능을 달성할 수 있는 수학적 견고함으로 각광받았다. 특히 1998년 신경정보처리시스템학회(NIPS’98)에서는 Bernhard Schölkopf, Alexander Smola 등 구겐(Gunn)의 연구를 포함한 여러 연구자들이 커널 방법론의 지평을 넓히는 중요한 연구들을 발표했다.6</p>
<h4>2.2.1 기술 심층 분석: 커널 주성분 분석 (Kernel PCA)</h4>
<p>NIPS’98에서 발표된 “Kernel PCA and De-Noising in Feature Spaces“는 커널 방법론의 정수를 보여주는 대표적인 연구다.6 이 연구는 선형 데이터 분석의 대표적인 기법인 주성분 분석(PCA)을 비선형 영역으로 확장했다.</p>
<ul>
<li>
<p><strong>핵심 아이디어:</strong> Kernel PCA의 핵심은 데이터를 직접 비선형 변환하는 대신, 비선형 사상(mapping) 함수 <span class="math math-inline">\Phi</span>를 통해 원본 데이터를 고차원 특징 공간(feature space) <code>F</code>로 사상한 후, 그 특징 공간 내에서 선형 PCA를 수행하는 것이다.9 특징 공간 <code>F</code>는 무한 차원일 수도 있지만, ’커널 트릭(kernel trick)’을 통해 <span class="math math-inline">\Phi(x)</span>를 명시적으로 계산할 필요가 없어진다.</p>
</li>
<li>
<p><strong>수학적 공식화:</strong> 모든 계산은 특징 공간에서의 내적(dot product) <span class="math math-inline">\langle \Phi(x_i), \Phi(x_j) \rangle</span> 형태로 표현되는데, 이를 커널 함수 <span class="math math-inline">k(x_i, x_j)</span>로 치환하는 것이 커널 트릭의 핵심이다. 특징 공간에서의 공분산 행렬의 고유벡터(eigenvector)를 찾는 문제는, 결국 <code>l x l</code> 크기(l은 데이터 샘플 수)의 커널 행렬 <span class="math math-inline">K</span> (여기서 <span class="math math-inline">K_{ij} = k(x_i, x_j)</span>)의 고유값 문제(eigenvalue problem)로 귀결된다. 풀어야 할 방정식은 다음과 같다.9<br />
<span class="math math-display">
l\lambda\alpha = K\alpha
</span><br />
여기서 <span class="math math-inline">\lambda</span>는 고유값, <span class="math math-inline">\alpha</span>는 고유벡터를 구성하는 계수 벡터다. 이 방정식을 풀면 데이터의 비선형적인 주성분을 찾을 수 있다.</p>
</li>
<li>
<p><strong>전상 문제(Pre-image Problem):</strong> Kernel PCA의 중요한 이론적, 실용적 난제는 ’전상 문제’다. 특징 공간에서 주성분 분석을 통해 잡음이 제거된 데이터 포인트 <span class="math math-inline">\Phi(z)</span>를 찾았다고 하더라도, 이 포인트에 해당하는 원본 입력 공간의 데이터 <code>z</code>가 존재하지 않거나 찾기 어려울 수 있다. 이 논문은 잡음 제거와 같은 응용을 위해 근사적인 전상을 찾는 방법을 논의하며, 이 문제의 중요성을 부각시켰다.6</p>
</li>
</ul>
<p>1998년 당시, SVM과 커널 방법론은 수많은 분류 및 회귀 문제에서 최첨단 성능을 보였다. 이들은 신경망 학습 시 흔히 발생하는 지역 최솟값(local minima) 문제가 없는 볼록 최적화(convex optimization) 문제로 공식화될 수 있었고, VC 차원과 같은 강력한 이론적 배경을 가지고 있었다.11 Kernel PCA의 등장은 커널 트릭의 힘이 지도 학습인 분류 문제를 넘어, 비지도 학습인 특징 추출 영역까지 확장될 수 있음을 명확히 보여주었다.</p>
<p>이러한 두 연구 흐름, 즉 LeNet-5와 Kernel PCA는 1998년 기계 학습 분야의 중요한 이중성을 드러낸다. 한쪽에서는 복잡한 구조를 통해 특징 자체를 ’학습’하려는 시도가 있었고, 다른 한쪽에서는 정교한 수학을 통해 특징 공간을 ’변환’하려는 시도가 있었다. 당시에는 후자가 이론적 성숙도와 실용성 면에서 우위에 있었지만, 역사는 데이터와 컴퓨팅 자원의 폭발적인 증가와 함께 전자의 패러다임이 결국 승리했음을 보여준다. 1998년은 이 두 위대한 아이디어가 최고 수준에서 경쟁하며 공존했던, 기계 학습 역사상 매우 흥미로운 순간이었다.</p>
<h3>2.3  강화학습의 이론적 기반 정립</h3>
<p>1998년은 강화학습(Reinforcement Learning, RL) 분야가 학문적 성숙기에 접어들었음을 알리는 해였다. 이전까지 여러 갈래로 흩어져 있던 연구들이 하나의 통일된 프레임워크로 집대성되었고, 복잡한 문제를 해결하기 위한 새로운 방법론이 제시되었으며, 핵심 알고리즘의 이론적 토대가 더욱 공고해졌다.</p>
<h4>2.3.1 핵심 연구 1: 이론의 집대성 - “Reinforcement Learning: An Introduction”</h4>
<p>Richard S. Sutton과 Andrew G. Barto가 1998년 MIT Press를 통해 출간한 “Reinforcement Learning: An Introduction“은 단순한 책 한 권을 넘어, 강화학습 분야의 ’헌법’과 같은 역할을 했다.12 이 책은 강화학습 연구자들에게 공통의 언어와 개념적 틀을 제공함으로써 분야의 발전을 가속화하는 결정적인 계기를 마련했다.</p>
<ul>
<li>
<p><strong>핵심 개념의 성문화:</strong> 이 책은 강화학습의 핵심 요소들을 명확하고 체계적으로 정의했다.15</p>
</li>
<li>
<p><strong>강화학습 문제:</strong> 에이전트(agent), 환경(environment), 상태(state), 행동(action), 보상(reward)으로 구성된 상호작용 루프를 통해 누적 보상을 최대화하는 문제로 정립했다.16</p>
</li>
<li>
<p><strong>마르코프 결정 과정(Markov Decision Process, MDP):</strong> 강화학습 문제를 수학적으로 엄밀하게 표현하기 위한 공식적인 프레임워크로 MDP를 제시했다. MDP는 상태 전이 확률과 보상 함수로 환경의 동역학을 모델링한다.15</p>
</li>
<li>
<p><strong>벨만 방정식(Bellman Equations):</strong> 가치 함수(value function)가 만족해야 하는 근본적인 재귀 관계식을 벨만 방정식으로 명명하고, 이를 통해 강화학습 문제의 구조를 밝혔다. 특히, 최적 정책(optimal policy) 하에서의 가치 함수가 만족하는 벨만 최적 방정식은 대부분의 강화학습 알고리즘의 이론적 기반이 된다.21 최적 상태 가치 함수 <span class="math math-inline">V^*(s)</span>에 대한 벨만 최적 방정식은 다음과 같다.</p>
<p><span class="math math-display">
V^*(s) = \max_{a} \sum_{s&#39;, r} p(s&#39;, r \vert s, a)[r + \gamma V^*(s&#39;)]
</span></p>
</li>
</ul>
<p>이 식은 상태 <code>s</code>에서의 최적 가치는, 해당 상태에서 가능한 모든 행동 <code>a</code>를 취했을 때 얻게 될 즉각적인 보상 <code>r</code>과 할인된(discounted) 다음 상태 <span class="math math-inline">s&#39;</span>의 최적 가치 <span class="math math-inline">\gamma V^*(s&#39;)</span>의 기댓값 중 최댓값과 같다는 의미를 담고 있다.22</p>
<ul>
<li><strong>해결 방법론:</strong> 문제를 해결하기 위한 세 가지 핵심 방법론인 동적 계획법(Dynamic Programming), 몬테카를로 방법(Monte Carlo methods), 그리고 시간차 학습(Temporal-Difference learning)을 체계적으로 소개했다. 특히 TD 학습은 DP와 MC의 장점을 결합한 모델-프리(model-free) 학습 방식으로, Q-러닝(Q-Learning)과 Sarsa 같은 핵심 알고리즘을 포함한다.15</li>
</ul>
<h4>2.3.2 핵심 연구 2: 계층적 강화학습 - MAXQ 방법론</h4>
<p>복잡하고 거대한 상태 공간을 가진 현실적인 문제를 해결하기 위해, 1998년 국제 기계 학습 학회(ICML’98)에서 Thomas G. Dietterich는 “The MAXQ Method for Hierarchical Reinforcement Learning“을 발표했다.26 이 연구는 복잡한 목표를 여러 개의 단순한 하위 목표(sub-goal)로 분해하여 계층적으로 해결하는 접근법을 제시했다.</p>
<ul>
<li>
<p><strong>핵심 아이디어:</strong> MAXQ의 핵심 혁신은 가치 함수 자체를 계층적으로 분해하는 데 있다. 전체 문제의 가치 함수를 각 하위 과제의 가치 함수와, 그 하위 과제가 완료된 후 상위 과제를 마치는 데 필요한 가치의 합으로 표현한다.28</p>
</li>
<li>
<p><strong>수학적 공식화:</strong> 상위 과제 <code>i</code>의 상태 <code>s</code>에서 하위 과제(행동) <code>a</code>를 수행하는 것의 가치 <span class="math math-inline">Q(i, s, a)</span>는 다음과 같이 두 요소로 분해된다.</p>
<p><span class="math math-display">
Q(i, s, a) = V(a, s) + C(i, s, a)
</span><br />
여기서 <span class="math math-inline">V(a, s)</span>는 하위 과제 <code>a</code>를 상태 <code>s</code>에서 시작하여 완료했을 때 얻는 총 보상의 기댓값이며, <span class="math math-inline">C(i, s, a)</span>는 ’완료 함수(completion function)’로, 하위 과제 <code>a</code>가 종료된 후 상위 과제 <code>i</code>를 마칠 때까지 얻게 될 총 보상의 기댓값을 의미한다. 이 분해는 각 계층에서 독립적으로 학습을 진행할 수 있게 하여, 학습 효율을 크게 향상시키고 상태 추상화(state abstraction)를 가능하게 한다.28</p>
</li>
</ul>
<h4>2.3.3 핵심 연구 3: 이론적 수렴성 분석</h4>
<p>NIPS’98에서는 Q-러닝과 같은 핵심 알고리즘의 이론적 기반을 다지는 연구도 발표되었다. “Finite-Sample Convergence Rates for Q-Learning and Indirect Algorithms“는 유한한 수의 샘플만으로 Q-러닝이 최적 정책에 얼마나 가까워질 수 있는지, 즉 샘플 복잡도(sample complexity)에 대한 이론적 보장을 제공했다.30 이러한 연구는 강화학습 알고리즘의 신뢰성을 높이고, 이론과 실제 응용 사이의 간극을 메우는 데 기여했다.</p>
<p>1998년 강화학습 분야의 이러한 발전들은 중요한 패턴을 보여준다. Sutton과 Barto의 교과서는 분야의 핵심 원리들을 ’성문화’함으로써 학문적 기틀을 마련했다. 이는 마치 한 국가의 헌법이 제정되는 것과 같이, 이후의 모든 연구가 참조할 수 있는 안정적인 기반을 제공했다. 이러한 견고한 이론적 토대 위에서 Dietterich의 MAXQ와 같은 더 복잡하고 실용적인 문제 해결을 위한 연구가 꽃필 수 있었다. 이 ‘성문화 이후의 혁신’ 패턴은 매우 중요하다. 1998년에 정립된 강화학습의 원리들은, 10여 년 후 LeNet-5와 같은 강력한 함수 근사기(function approximator)인 심층 신경망과 결합하여 ’심층 강화학습(Deep Reinforcement Learning)’이라는 진정한 혁명을 일으키게 된다. 즉, 1998년은 강화학습 혁명 그 자체는 아니었지만, 미래의 혁명을 가능하게 한 결정적인 지적 초석을 다진 해였다.</p>
<h2>3.  로보틱스의 지능화와 자율성 증대</h2>
<p>1998년 로봇 공학 분야는 인공지능의 이론적 발전이 물리적 세계와 만나 어떻게 실질적인 자율성으로 구현될 수 있는지를 보여주는 역동적인 현장이었다. 특히, 불확실하고 동적인 환경에서 로봇이 스스로 위치를 파악하고 지도를 작성하며, 복잡한 고차원 공간에서 충돌 없이 움직이는 문제는 이 시기 연구의 핵심 과제였다. 이 장에서는 확률적 로봇 공학의 부상, 고차원 경로 계획 기술의 발전, 그리고 다양한 특수 환경에서의 로봇 응용 사례를 통해 1998년 로봇 기술의 진보를 탐색한다.</p>
<h3>3.1  확률적 로봇 공학의 발전: SLAM의 서막</h3>
<p>1990년대 후반, 로봇 공학계에서는 결정론적이고 기하학적인 모델에 기반한 전통적인 접근법의 한계가 명확해지고 있었다. 센서의 노이즈, 환경의 불확실성, 모델의 불완전성은 실제 환경에서 로봇의 강건한 작동을 방해하는 주된 요인이었다. 이러한 문제에 대응하기 위해 Sebastian Thrun을 비롯한 연구자들은 확률과 통계 이론을 로봇의 인식 및 제어 문제에 본격적으로 도입하기 시작했다. 1998년 AAAI와 ICRA 같은 최고 수준의 학회에서 발표된 그들의 연구는 현대 확률적 로봇 공학, 특히 동시적 위치 추정 및 지도 작성(Simultaneous Localization and Mapping, SLAM) 기술의 기틀을 마련했다.31</p>
<ul>
<li>
<p><strong>핵심 기여:</strong></p>
</li>
<li>
<p><strong>확률적 지도 작성(Probabilistic Mapping):</strong> “Probabilistic mapping of an environment by a mobile robot” 논문은 로봇이 불확실한 센서 측정값들을 통합하여 일관성 있는 환경 지도를 구축하는 확률적 방법을 제시했다.31 이는 들어오는 데이터를 단순히 기하학적으로 쌓는 것이 아니라, 각 측정값의 불확실성을 고려하여 지도 상의 각 지점의 존재 확률을 갱신하는 베이즈적(Bayesian) 접근법을 채택했다.</p>
</li>
<li>
<p><strong>동적 환경에서의 위치 추정(Localization in Dynamic Environments):</strong> “Position estimation for mobile robots in dynamic environments” 연구는 현실 세계의 복잡성을 한 단계 더 깊이 다루었다.31 정적인 환경을 가정한 기존 연구와 달리, 이 연구는 사람들처럼 움직이는 장애물이 존재하는 환경에서 로봇이 자신의 위치를 정확하게 추정하는 문제를 해결하고자 했다. 이는 센서 데이터 중 어떤 것이 정적인 배경에 해당하고 어떤 것이 일시적인 동적 요소인지를 확률적으로 구분하는 기법을 통해 가능해졌다.</p>
</li>
<li>
<p><strong>지도 통합(Map Integration):</strong> 1998년 AAAI에서 발표된 “Integrating topological and metric maps for mobile robot navigation: A statistical approach“는 당시 로봇 내비게이션의 핵심 난제 중 하나를 해결한 중요한 연구다.31 미터 지도(metric map)는 환경의 정확한 기하학적 정보를 담고 있어 정밀한 경로 계획에 유리하지만, 환경이 커질수록 데이터양이 기하급수적으로 늘어나고 노이즈에 취약했다. 반면, 위상 지도(topological map)는 환경을 장소(노드)와 경로(엣지)의 그래프로 표현하여 효율적이고 대규모 환경에 강건하지만, 기하학적 정밀성이 부족했다. 이 연구는 두 지도의 장점을 결합하기 위해 통계적 기법을 제안했다. 로봇이 위상 지도의 노드들 사이를 이동하면서 얻는 미터 정보를 이용하여, 위상 관계와 미터 관계의 일관성을 확률적으로 최대화하는 방식으로 두 지도를 정합했다. 이는 더 강건하고 확장 가능한 내비게이션 시스템의 기반이 되었다.</p>
</li>
<li>
<p>사례 연구: 박물관 안내 로봇(The Interactive Museum Tour-Guide Robot):</p>
</li>
</ul>
<p>이러한 확률적 로봇 공학 원리들의 집약체는 1998년 AAAI 최우수 논문상을 수상한 ‘대화형 박물관 안내 로봇’ 프로젝트였다.31 이 로봇 ’미네르바(Minerva)’는 실제 박물관이라는 복잡하고 예측 불가능한 공공장소에서 장시간 동안 자율적으로 작동하며 방문객들을 안내했다. 미네르바는 앞서 설명한 확률적 위치 추정 및 지도 작성 기술을 사용하여 끊임없이 변화하는 환경 속에서 자신의 위치를 파악하고, 동적 장애물(관람객)을 회피하며 경로를 계획했다. 또한, 간단한 템플릿 기반 제스처 인식을 통해 인간과 상호작용하는 능력까지 갖추었다.31 이 프로젝트는 실험실 수준의 개별 기술들이 어떻게 하나의 완전한 자율 시스템으로 통합되어 실제 세계에서 유의미한 임무를 수행할 수 있는지를 보여준 강력한 실증 사례였다.</p>
<h3>3.2  고차원 공간에서의 경로 계획</h3>
<p>로봇의 자율성을 위한 또 다른 핵심 요소는 충돌 없이 시작점에서 목표점까지 움직일 경로를 찾는 경로 계획(path planning) 기술이다. 특히, 여러 개의 관절을 가진 로봇 팔(manipulator)처럼 자유도(degrees of freedom)가 높은 로봇의 경우, 경로를 탐색해야 하는 설정 공간(configuration space)의 차원이 매우 높아져 기존의 결정론적 탐색 방법으로는 해결이 거의 불가능했다. 이러한 ’차원의 저주(curse of dimensionality)’를 극복하기 위해 1990년대 중반부터 확률적 샘플링에 기반한 방법들이 제안되었으며, 1998년은 이러한 기법들이 활발히 연구되고 적용되던 시기였다.</p>
<ul>
<li>핵심 방법론: 확률적 로드맵 (Probabilistic Roadmaps, PRM):</li>
</ul>
<p>Lydia Kavraki 연구팀이 1996년에 발표한 PRM은 고차원 경로 계획 문제의 대표적인 해법으로 자리 잡았다.33 PRM 알고리즘은 문제를 두 단계로 나누어 효율성을 극대화한다.35</p>
<ol>
<li>
<p><strong>학습 단계 (로드맵 구축):</strong> 이 단계에서는 실제 경로 탐색 요청(쿼리)이 들어오기 전에, 설정 공간의 연결성을 파악하는 ’로드맵’을 미리 구축한다. 알고리즘은 설정 공간 내에서 무작위로 샘플(로봇의 특정 자세)을 생성하고, 이 샘플이 장애물과 충돌하지 않는 유효한 설정인지 확인한다. 유효한 샘플들은 로드맵의 노드가 된다. 그 후, 가까운 노드들을 단순하고 빠른 ‘지역 경로 계획기(local planner)’(예: 직선 경로)로 연결해보고, 그 경로 또한 충돌이 없으면 두 노드 사이에 엣지를 추가한다. 이 과정을 반복하면, 자유 공간(collision-free space)의 연결 정보를 담은 그래프, 즉 로드맵이 생성된다.33</p>
</li>
<li>
<p><strong>쿼리 단계 (경로 탐색):</strong> 사용자가 시작 설정과 목표 설정을 입력하면, 알고리즘은 먼저 이 두 설정을 로드맵 상의 가장 가까운 노드에 연결한다. 그 다음, A*와 같은 표준 그래프 탐색 알고리즘을 사용하여 로드맵 상에서 두 노드를 잇는 경로를 찾는다. 이 방식은 복잡한 공간 탐색을 사전 계산 단계로 옮김으로써, 개별 쿼리에 대한 응답 시간을 수 초에서 1초 미만으로 획기적으로 단축시켰다.33</p>
</li>
</ol>
<ul>
<li><strong>관련 연구:</strong> 1998년의 로봇 관련 학회들에서는 PRM 외에도 다양한 경로 계획 및 충돌 회피 기법들이 논의되었다. 예를 들어, 인공적인 척력(repulsive force)을 장애물 주변에 생성하여 로봇이 이를 피하도록 하는 포텐셜 필드(potential field) 방법이나 37, 비선형 진동자(nonlinear oscillator)를 제어에 활용하여 장애물을 회피하는 동역학적 접근법 등이 연구되었다.38</li>
</ul>
<h3>3.3  다양한 환경에서의 로봇 응용</h3>
<p>1998년의 로봇 연구는 이론적 발전에만 머무르지 않고, 공장 자동화를 넘어선 다양한 도전적인 환경으로 그 응용 범위를 넓혀나갔다.</p>
<ul>
<li>도전적 환경 (Robotics ’98 학회):</li>
</ul>
<p>’도전적 환경을 위한 로봇 공학’을 주제로 한 이 전문 학회는 당시 로봇 기술의 최전선을 보여주었다.38</p>
<ul>
<li>
<p><strong>유연 매니퓰레이터(Flexible Manipulators):</strong> 기존의 단단한 로봇 팔과 달리, 가늘고 긴 유연한 팔의 진동을 제어하는 연구는 경량화 및 고속 작동을 위해 필수적이었다.38</p>
</li>
<li>
<p><strong>행성 탐사 로봇:</strong> 화성과 같은 미지의 행성 표면을 탐사하기 위한 소형 로봇(마이크로 로버)의 설계 및 제어는 극한 환경에서의 자율성 연구를 선도했다.38</p>
</li>
<li>
<p><strong>수중 로봇:</strong> 높은 기동성을 갖춘 자율 수중 로봇(AUV) 개발은 해양 탐사 및 수중 구조물 검사에 새로운 가능성을 열었다.38</p>
</li>
<li>
<p><strong>건설 및 위험 환경:</strong> 30톤급 대형 크레인의 자동화나 송전탑 건설과 같은 인간에게 위험하고 힘든 작업을 로봇으로 대체하려는 시도들이 이루어졌다.38</p>
</li>
<li>
<p>산업 및 재활 로봇 (Industrial Robot 저널):</p>
</li>
</ul>
<p>이 저널에서는 보다 실용적이고 상업적인 응용 사례들이 소개되었다.37</p>
<ul>
<li>
<p><strong>Handy 1 재활 로봇:</strong> 중증 장애인이 식사 등의 일상 활동을 할 수 있도록 돕는 저비용 상용 재활 로봇 시스템으로, 기술이 사회적 약자에게 어떻게 기여할 수 있는지를 보여준 성공 사례였다.37</p>
</li>
<li>
<p><strong>자동화된 검사:</strong> 항공기 동체 표면의 미세한 결함을 검사하는 로봇 시스템은 인간 검사자의 피로와 실수를 줄여 항공 안전을 향상시키는 데 기여했다.37</p>
</li>
<li>
<p><strong>미래 기술 탐색:</strong> 상업용 바닥 청소 로봇이나, 군사 정찰 및 교통 감시를 위한 곤충형 비행 로봇과 같은 혁신적인 아이디어들도 이 시기에 논의되기 시작했다.37</p>
</li>
</ul>
<p>1998년 로봇 공학 연구는 두 가지 중요한 방향성을 보여준다. 첫째, 확률적 로봇 공학은 ‘데이터 기반(data-driven)’ 접근법의 부상을 알렸다. 로봇은 더 이상 완벽하게 주어진 세계 모델에 의존하는 것이 아니라, 불확실한 센서 데이터로부터 스스로 세계를 학습하고 이해하기 시작했다. 박물관 안내 로봇은 이러한 철학의 성공적인 구현체였다. 둘째, PRM과 같은 경로 계획 연구는 ‘모델 기반(model-driven)’ 접근법이 어떻게 계산적 복잡성을 해결하는지를 보여주었다. 이는 완벽한 모델이 주어졌을 때, 고차원 문제에 대한 해답을 효율적으로 찾는 데 중점을 두었다. 이 두 접근법, 즉 불확실한 세계를 학습하는 능력과 복잡한 공간에서 계획하는 능력의 융합은 이후 10년간 로봇 공학의 핵심 과제가 되었다. 더 나아가, 박물관 로봇과 같은 야심찬 프로젝트들은 인식, 지도 작성, 위치 추정, 경로 계획, 상호작용 등 AI의 여러 하위 분야 기술들의 ’통합’을 강제하는 역할을 했다. 이는 개별 알고리즘 개발을 넘어, 완전한 지능 시스템을 구축하려는 현대 AI 및 로봇 공학의 흐름을 예고하는 중요한 경향이었다.</p>
<h2>4.  인공지능 연구의 확장</h2>
<p>1998년은 합성곱 신경망이나 강화학습의 이론 정립과 같은 혁명적인 사건들 외에도, 인공지능 분야 전반의 성숙과 확장을 보여주는 중요한 발전들이 있었던 해였다. AI 계획(Planning) 분야에서는 과학적 엄밀성을 더하기 위한 기반이 마련되었고, 컴퓨터 비전 분야는 꾸준한 성과를 축적했으며, 인간의 감정과 같은 비논리적 지능을 탐구하려는 새로운 시도들이 나타났다. 이 장에서는 이러한 다양한 연구 동향을 통해 1998년 AI 연구의 폭과 깊이를 조명한다.</p>
<h3>4.1  AI 계획 시스템 경쟁과 PDDL의 탄생</h3>
<p>1998년 6월에 열린 제1회 인공지능 계획 시스템(AIPS) 경쟁은 AI 계획 연구의 역사에서 중요한 전환점이었다.39 이 경쟁 이전에는 연구자마다 각기 다른 문제 표현 방식과 자체적인 테스트 도메인을 사용하여 자신의 플래너(planner)를 평가했기 때문에, 시스템 간의 객관적인 성능 비교가 거의 불가능했다. 이러한 상황은 분야의 과학적 발전을 저해하는 요소로 작용했다.</p>
<p>AIPS 경쟁은 이 문제를 해결하기 위해 두 가지 핵심적인 기여를 했다:</p>
<ol>
<li>
<p><strong>표준화된 문제 표현 언어의 도입:</strong> 경쟁을 준비하는 과정에서 ’계획 도메인 정의 언어(Planning Domain Definition Language, PDDL)’가 탄생했다.39 PDDL은 STRIPS와 같은 고전적인 계획 표현을 확장하여, 객체의 타입, 술어(predicate), 행동(action)의 전제조건(precondition)과 효과(effect) 등을 형식적으로 기술할 수 있는 표준화된 구문을 제공했다. 이를 통해 연구자들은 물류, 블록 쌓기, 원자로 제어 등 다양한 계획 문제를 공통의 언어로 정의하고 공유할 수 있게 되었다.</p>
</li>
<li>
<p><strong>공통 벤치마크 문제 저장소 구축:</strong> 경쟁은 다양한 난이도와 특성을 가진 표준 벤치마크 문제 세트를 제공했다. 이는 새로운 플래너의 성능을 평가하고 기존 시스템과 공정하게 비교할 수 있는 실험적 기반을 마련해주었다.39</p>
</li>
</ol>
<p>이 행사는 AI 계획 연구를 개인적인 예술의 영역에서, 엄밀한 실험과 경쟁을 통해 발전하는 과학의 영역으로 이끄는 계기가 되었다. 이는 훗날 ImageNet과 같은 대규모 벤치마크와 경쟁이 컴퓨터 비전 분야의 발전을 폭발적으로 가속화한 것과 유사한 역할을 했다. PDDL의 도입은 재현 가능하고 측정 가능한 진보를 위한 ’지적 인프라’를 구축한 것으로, AI 연구의 성숙을 보여주는 상징적인 사건이었다.</p>
<h3>4.2  컴퓨터 비전의 주요 성과</h3>
<p>1998년 컴퓨터 비전 및 패턴 인식 학회(CVPR’98)는 당시 컴퓨터 비전 분야의 주류 연구 동향을 명확하게 보여주었다.40 LeNet-5가 픽셀로부터 직접 학습하는 급진적인 아이디어를 제시했지만, CVPR’98의 대다수 연구는 통계적, 기하학적 모델링에 기반한 정교한 방법론에 집중하고 있었다.</p>
<ul>
<li>
<p><strong>주요 연구 동향:</strong></p>
</li>
<li>
<p><strong>얼굴 및 인간 행동 분석:</strong> 얼굴 검출 및 인식은 이 시기 매우 활발한 연구 분야였다.41 또한, 비디오 시퀀스에서 사람의 움직임을 추적하고, 손 제스처나 특정 행동을 인식하는 기술에 대한 연구가 다수 발표되었다.43 이러한 기술들은 AAAI’98에서 발표된 박물관 안내 로봇이 제스처를 인식하는 기능에 직접적으로 응용되는 등, 로봇과의 상호작용 분야에서 즉각적인 활용 가능성을 보였다.31</p>
</li>
<li>
<p><strong>3차원 복원 및 장면 이해:</strong> 스테레오 비전(두 대의 카메라 사용)을 통해 3차원 깊이 정보를 추정하고, 이를 바탕으로 물체의 형태를 복원하는 연구가 주를 이루었다.43 또한, 이미지를 의미 있는 영역으로 분할(segmentation)하거나, 여러 장의 파노라마 이미지를 조합하여 3차원 모델을 구축하는 기술도 중요한 연구 주제였다.43</p>
</li>
<li>
<p><strong>이미지 검색:</strong> 대규모 이미지 데이터베이스에서 원하는 이미지를 효율적으로 찾아내는 콘텐츠 기반 이미지 검색(Content-Based Image Retrieval, CBIR) 기술이 발전했다. 베이즈 정리를 활용하여 이미지의 의미론적 콘텐츠를 특성화하거나, 인간의 색상 인지 모델에 기반한 클러스터링을 통해 이미지를 인덱싱하는 방법들이 제안되었다.43</p>
</li>
</ul>
<p>CVPR’98의 연구들은 컴퓨터가 시각적 세계를 기하학적 구조와 통계적 패턴으로 이해하려는 노력이 정점에 달했음을 보여준다. 이는 LeNet-5의 ‘학습 기반’ 접근법과는 다른 철학을 가지고 있었지만, 당시로서는 매우 정교하고 실용적인 결과를 만들어내고 있었다.</p>
<h3>4.3  감성 컴퓨팅 및 에이전트 연구 동향</h3>
<p>1998년 AAAI 가을 심포지엄의 주제 중 하나는 “감성적이고 지능적인: 인지의 얽힌 매듭(Emotional and Intelligent: The Tangled Knot of Cognition)“이었다.44 이는 순수한 논리, 추론, 최적화를 넘어 인간 지능의 또 다른 중요한 측면인 ’감성’을 AI 연구의 영역으로 끌어들이려는 초기 시도들을 보여준다.</p>
<ul>
<li>
<p><strong>새로운 연구 주제:</strong></p>
</li>
<li>
<p><strong>감성 모델링:</strong> 베이즈 네트워크와 같은 확률 모델을 사용하여 인간의 감정 상태나 성격을 모델링하려는 연구가 발표되었다. 또한, 신뢰, 루머, 음악적 감흥과 같은 복잡한 사회적, 감성적 현상을 계산적으로 모델링하려는 시도도 있었다.44</p>
</li>
<li>
<p><strong>감성과 로봇 학습:</strong> 자율 로봇이 학습하는 과정에서 감정이 어떤 역할을 할 수 있는지 탐구하는 연구가 등장했다. 예를 들어, 긍정적/부정적 감정 신호를 강화학습의 보상 신호처럼 사용하여 학습을 가속화하거나, 특정 상황에서 특정 행동을 유발하는 편향(bias)으로 작용하게 하는 아이디어가 제안되었다.44</p>
</li>
<li>
<p><strong>인간-로봇 상호작용(HRI):</strong> 로봇이 인간과 원활하게 상호작용하기 위해서는 감성적 표현이 중요하다는 인식이 싹트기 시작했다. 동기(motivation)나 감정을 제스처와 같은 상징적 형태로 표현하여 인간과의 상호작용을 조절하려는 초기 실험들이 이루어졌다.44</p>
</li>
</ul>
<p>이러한 연구들은 감성 컴퓨팅(Affective Computing)과 소셜 로보틱스(Social Robotics) 분야의 여명기에 해당한다. 이는 AI가 단지 효율적인 문제 해결 도구를 넘어, 인간과 사회적 맥락에서 소통하고 협력하는 파트너가 되기 위해서는 감성을 이해하고 모델링하며, 심지어 표현할 수 있어야 한다는 중요한 인식을 반영한다.</p>
<p>1998년 AI 연구의 확장은 분야의 내적 성숙을 보여주는 증거다. AI 계획 분야는 PDDL이라는 ’과학적 인프라’를 구축하여 발전을 위한 토대를 다졌다. 컴퓨터 비전은 꾸준히 현실 세계의 복잡한 시각 정보를 해석하는 능력을 향상시켰다. 그리고 감성 컴퓨팅 연구는 ’지능이란 무엇인가’라는 근본적인 질문에 새로운 차원을 더했다. 이 시기 AI 연구는 ‘최적의 계획을 세우는 논리적 지능’, ‘세상을 정확히 인식하는 지각적 지능’, ’사회적 단서를 이해하는 감성적 지능’이라는 여러 갈래로 분화하며 그 정의를 확장하고 있었다. 이러한 다양한 지능의 정의 사이의 긴장감과 통합의 필요성은 1998년에 이미 뚜렷하게 나타났으며, 이는 오늘날 범용 인공지능(AGI)을 향한 연구에서도 여전히 핵심적인 화두로 남아 있다.</p>
<h2>5. 결론: 1998년 연구의 유산과 현대 AI에의 영향</h2>
<p>1998년은 인공지능과 로봇 공학의 역사가 과거의 패러다임을 완성하고 미래의 청사진을 동시에 그려낸, 보기 드문 지적 풍요의 해였다. 이 시기에 발표된 연구들은 단지 학문적 성과에 그치지 않고, 오늘날 우리가 경험하고 있는 AI 혁명의 근간을 이루는 핵심적인 아이디어와 방법론의 직접적인 기원이 되었다. 1998년의 유산은 크게 세 가지 측면에서 현대 AI에 지대한 영향을 미치고 있다.</p>
<p>첫째, 1998년의 연구는 현대 AI 기술의 <strong>직접적인 혈통</strong>을 형성했다.</p>
<ul>
<li>
<p><strong>LeNet-5에서 현대 딥러닝으로:</strong> Yann LeCun의 LeNet-5는 합성곱과 풀링을 반복하는 계층적 구조, 가중치 공유, 그리고 역전파를 통한 종단간 학습이라는 핵심 원칙을 모두 구현했다.4 이는 2012년 AlexNet의 등장과 함께 시작된 딥러닝 혁명의 구조적, 철학적 원형이었다. 1998년에는 하드웨어와 데이터의 한계로 그 잠재력이 완전히 발현되지 못했지만, 그 개념적 토대는 이미 완벽하게 제시되어 있었다.</p>
</li>
<li>
<p><strong>Sutton &amp; Barto에서 심층 강화학습으로:</strong> Sutton과 Barto의 교과서는 마르코프 결정 과정, 벨만 방정식, 시간차 학습 등 강화학습의 이론적 프레임워크를 집대성했다.12 이 견고한 이론적 기반은 훗날 DeepMind와 같은 연구 그룹이 테이블 형태의 가치 함수를 LeNet-5와 같은 심층 신경망으로 대체하여 심층 Q-네트워크(DQN)와 알파고(AlphaGo)를 탄생시키는 데 결정적인 역할을 했다. 1998년의 이론 정립이 없었다면, 현대 심층 강화학습의 눈부신 성공은 불가능했을 것이다.</p>
</li>
<li>
<p><strong>확률적 로봇 공학에서 자율주행차로:</strong> Sebastian Thrun 연구팀이 제시한 확률적 지도 작성 및 위치 추정 방법론은 현대 SLAM 기술의 초석이 되었다.31 불확실성 하에서 센서 데이터를 융합하여 환경을 이해하는 이 능력은 오늘날 자율주행차, 드론, 실내 서비스 로봇의 항법 시스템의 핵심 기술로 자리 잡았다. 실제로 Thrun은 이후 구글의 자율주행차 프로젝트를 이끌며 1998년의 연구를 현실 세계의 혁신으로 직접 연결시켰다.</p>
</li>
</ul>
<p>둘째, 1998년은 AI 발전에 있어 <strong>잠재된 가능성의 시기</strong>였다. LeNet-5와 같은 아이디어는 시대를 너무 앞서 나갔다. 당시의 CPU 성능과 제한된 데이터셋(예: MNIST, USPS)은 이러한 복잡한 모델을 대규모로 훈련시키기에 역부족이었다. 이 아이디어들은 이후 10여 년간 일종의 ’지적 휴면기’를 거쳐야 했다. 2010년대에 들어 GPU 컴퓨팅의 보편화와 인터넷을 통한 대규모 데이터셋의 등장이 결합되면서, 1998년에 잉태되었던 잠재력은 비로소 폭발적으로 발현될 수 있었다. 이는 위대한 과학적 돌파구가 종종 아이디어 자체뿐만 아니라, 그 아이디어를 실현할 수 있는 기술적, 환경적 조건이 무르익었을 때 일어난다는 사실을 보여준다.</p>
<p>셋째, 1998년에 제기된 <strong>근본적인 질문들은 오늘날에도 여전히 유효하다</strong>.</p>
<ul>
<li>
<p><strong>지식의 표현과 학습:</strong> 수작업으로 정교하게 설계된 특징(SVM/커널)과 데이터로부터 종단간으로 학습된 특징(CNN) 사이의 대립은, 오늘날 사전 학습된 대규모 언어 모델(LLM)에 특정 지식을 어떻게 주입하고 제어할 것인가에 대한 논쟁으로 이어지고 있다.</p>
</li>
<li>
<p><strong>지능의 정의:</strong> 논리적 추론(AI 계획), 시각적 인식(컴퓨터 비전), 사회적 감성(감성 컴퓨팅) 중 무엇이 진정한 지능을 구성하는가에 대한 1998년의 다원적 탐구는, 현재 인간과 같은 수준의 범용 인공지능(AGI)을 추구하는 과정에서 더욱 핵심적인 질문이 되었다.39</p>
</li>
<li>
<p><strong>과학적 방법론:</strong> AI 계획 경쟁에서 PDDL을 통해 표준화와 공정한 비교의 중요성을 확립한 것은, 오늘날 AI 연구의 재현 가능성(reproducibility)과 투명성을 확보하려는 노력의 선구적인 사례다.39</p>
</li>
</ul>
<p>결론적으로, 1998년은 현대 AI의 DNA가 형성된 결정적인 해였다. 당시의 연구들은 오늘날 AI 기술의 근간을 이루는 알고리즘과 이론을 낳았을 뿐만 아니라, 우리가 여전히 씨름하고 있는 근본적인 철학적, 방법론적 질문들을 제기했다. 따라서 1998년의 유산을 깊이 이해하는 것은 현재의 AI 기술을 올바르게 평가하고 미래의 발전 방향을 예측하는 데 필수적인 지적 나침반을 제공한다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>PROC. OF THE IEEE, NOVEMBER 1998 - Gradient-Based Learning …, https://www.iro.umontreal.ca/~lisa/pointeurs/lecun-01a.pdf</li>
<li>(PDF) Gradient-Based Learning Applied to Document Recognition - ResearchGate, https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition</li>
<li>Gradient-Based Learning Applied to Document Recognition, http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf</li>
<li>A Deep Dive into Yann LeCun’s 1998 CNN Paper — Explained Simply with Examples, https://medium.com/@dbhatt245/a-deep-dive-into-yann-lecuns-1998-cnn-paper-explained-simply-with-examples-ff88c26f1154</li>
<li>LeNet : Gradient-Based Learning Applied to Document Recognition - The VITALab website, https://vitalab.github.io/article/2017/03/29/lenet.html</li>
<li>NIPS 1998 | OpenReview, https://openreview.net/group?id=dblp.org/conf/NIPS/1998</li>
<li>Gunn, S.R. (1998) Support vector machines for classification and regression. Technical Report, School of Electronics and Computer Science, University of Southampton. - References, https://www.scirp.org/reference/referencespapers?referenceid=22798</li>
<li>Support vector machines (1998) | Marti A. Hearst | 5728 Citations - SciSpace, https://scispace.com/papers/support-vector-machines-2ytuqaishs</li>
<li>Kernel PCA and De-Noising in Feature Spaces, https://proceedings.neurips.cc/paper/1491-kernel-pca-and-de-noising-in-feature-spaces.pdf</li>
<li>Kernel Principal Component Analysis - Alex Smola, https://alex.smola.org/papers/1997/SchSmoMul97.pdf</li>
<li>(PDF) An Introduction to Kernel-Based Learning Algorithms - ResearchGate, https://www.researchgate.net/publication/5608575_An_Introduction_to_Kernel-Based_Learning_Algorithms</li>
<li>Reinforcement Learning, second edition: An Introduction - Barnes &amp; Noble, https://www.barnesandnoble.com/w/reinforcement-learning-second-edition-richard-s-sutton/1137255927</li>
<li>REINFORCEMENT LEARNING: AN INTRODUCTION by Richard S. Sutton and Andrew G. Barto, Adaptive Computation and Machine Learning series, MIT Press (Bradford Book), Cambridge, Mass., 1998, xviii + 322 pp, ISBN 0-262-19398-1, (hardback, £31.95). | Robotica, https://www.cambridge.org/core/journals/robotica/article/reinforcement-learning-an-introduction-by-richard-s-sutton-and-andrew-g-barto-adaptive-computation-and-machine-learning-series-mit-press-bradford-book-cambridge-mass-1998-xviii-322-pp-isbn-0262193981-hardback-3195/176DB49A1247A53B75B81EFCF32CA157</li>
<li>Reinforcement Learning: An Introduction - Semantic Scholar, https://www.semanticscholar.org/paper/Reinforcement-Learning%3A-An-Introduction-Sutton-Barto/97efafdb4a3942ab3efba53ded7413199f79c054</li>
<li>Reinforcement Learning: An Introduction - Richard S. Sutton, Andrew G. Barto - Google Books, https://books.google.de/books?id=CAFR6IBF4xYC</li>
<li>Reinforcement Learning: An Introduction - UMBC, https://courses.cs.umbc.edu/graduate/678/spring17/RL-3.pdf</li>
<li>Notes Reinforcement Learning: An Introduction (2nd Edition) - Scott Jeen, https://enjeeneer.io/sutton_and_barto/rl_notes.pdf</li>
<li>Reinforcement Learning: Summary and Review | Bill Mei, https://billmei.net/books/reinforcement-learning/</li>
<li>www.datacamp.com, [https://www.datacamp.com/tutorial/bellman-equation-reinforcement-learning#:<sub>:text=For%20Markov%20Decision%20Processes%20(MDPs,maximize%20the%20total%20expected%20reward.](https://www.datacamp.com/tutorial/bellman-equation-reinforcement-learning#:</sub>:text=For Markov Decision Processes (MDPs,maximize the total expected reward.)</li>
<li>Markov decision process - Wikipedia, https://en.wikipedia.org/wiki/Markov_decision_process</li>
<li>Understanding the Bellman Equation in Reinforcement Learning - DataCamp, https://www.datacamp.com/tutorial/bellman-equation-reinforcement-learning</li>
<li>4.2 Solving Markov Decision Processes | Introduction to Artificial …, https://inst.eecs.berkeley.edu/~cs188/textbook/mdp/solve.html</li>
<li>Sutton &amp; Barto summary chap 03 - Finite Markov Decision Processes - lcalem, https://lcalem.github.io/blog/2018/09/23/sutton-chap03-mdp</li>
<li>Q-Learning: Model Free Reinforcement Learning and Temporal Difference Learning - YouTube, https://www.youtube.com/watch?v=0iqz4tcKN58</li>
<li>Temporal difference reinforcement learning, https://gibberblot.github.io/rl-notes/single-agent/temporal-difference-learning.html</li>
<li>Proceedings of the Fifteenth International Conference on Machine …, https://researchr.org/publication/icml%3A1998</li>
<li>[PDF] The MAXQ Method for Hierarchical Reinforcement Learning - Semantic Scholar, https://www.semanticscholar.org/paper/The-MAXQ-Method-for-Hierarchical-Reinforcement-Dietterich/9aa1d909544fd9ffe061b84a90eb344ac303e6d9</li>
<li>The MAXQ Method for Hierarchical Reinforcement Learning, <a href="http://matt.colorado.edu/teaching/RL/readings/dietterich%201998%20ICML%20maxQ.pdf">http://matt.colorado.edu/teaching/RL/readings/dietterich%201998%20ICML%20maxQ.pdf</a></li>
<li>State Abstraction in MAXQ Hierarchical Reinforcement Learning - NIPS, http://papers.neurips.cc/paper/1770-state-abstraction-in-maxq-hierarchical-reinforcement-learning.pdf</li>
<li>Finite-Sample Convergence Rates for Q-Learning and Indirect Algorithms - NIPS, https://papers.nips.cc/paper/1531-finite-sample-convergence-rates-for-q-learning-and-indirect-algorithms</li>
<li>Papers - Sebastian Thrun - Stanford University, http://robots.stanford.edu/papers.html</li>
<li>AAAI-98 Technical Papers - The Association for the Advancement of Artificial Intelligence, https://aaai.org/proceeding/aaai-98-technical-papers/</li>
<li>(PDF) Probabilistic Roadmaps for Path Planning in High …, https://www.researchgate.net/publication/3298646_Probabilistic_Roadmaps_for_Path_Planning_in_High-Dimensional_Configuration_Spaces</li>
<li>[PDF] Probabilistic roadmaps for path planning in high-dimensional configuration spaces, https://www.semanticscholar.org/paper/Probabilistic-roadmaps-for-path-planning-in-spaces-Kavraki-Svestka/7e81dac6260c4768af3a28ac21c78c5a38a5f7d0</li>
<li>Probabilistic Roadmaps for Path Planning in High-Dimensional …, https://www.cs.cmu.edu/~motionplanning/papers/sbp_papers/PRM/prmbasic_01.pdf</li>
<li>Real-time Path Planning For Senor-based Mobile Robot Based On Probabilistic Roadmap Method, https://alife-robotics.co.jp/members2005/icarob/Papers/GS18/GS18-4.pdf</li>
<li>Top 33 Industrial Robot-an International Journal papers published in 1998 - SciSpace, https://scispace.com/journals/industrial-robot-an-international-journal-1nga15kf/1998</li>
<li>Robotics 98 | Books - ASCE Library, https://ascelibrary.org/doi/book/10.1061/9780784403372</li>
<li>(PDF) 1998 AI Planning Systems Competition - ResearchGate, https://www.researchgate.net/publication/2384744_1998_AI_Planning_Systems_Competition</li>
<li>Direct shape from texture using a parametric surface model and an, https://snu.elsevierpure.com/en/publications/direct-shape-from-texture-using-a-parametric-surface-model-and-an</li>
<li>Computer Vision and Pattern Recognition 1998 - DBLP, https://dblp.org/db/conf/cvpr/cvpr1998.html</li>
<li>Computer Vision and Pattern Recognition - CVPR 2008, http://www.sigmod.org/publications/dblp/db/conf/cvpr/index.html</li>
<li>Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231), https://www.computer.org/csdl/proceedings/cvpr/1998/12OmNzUPpvf</li>
<li>fall-1998-03 Archives - AAAI, https://aaai.org/proceeding/fall-1998-03/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>