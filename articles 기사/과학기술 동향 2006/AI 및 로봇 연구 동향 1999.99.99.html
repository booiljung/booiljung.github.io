<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:1999년 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>1999년 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2006년 이전의 AI 및 로봇 연구 동향</a> / <span>1999년 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>1999년 AI 및 로봇 연구 동향</h1>
<h2>1. 서론</h2>
<p>1990년대 초반의 ’AI 겨울’을 지나, 1999년은 학계와 산업계 전반에 걸쳐 새로운 낙관론이 팽배했던 시기였다. 당시 개최된 제16회 미국 인공지능 학회(AAAI-99)는 이러한 분위기를 ’AI의 봄(AI Spring)’이라 명명하며, 학계 및 산업계의 일자리 증가, 관련 기술에 대한 투자 상승, 그리고 AI 분야에 새로운 도전 과제를 제시하는 기술적 진보가 동시다발적으로 일어나고 있음을 선언했다.1 본 보고서는 이러한 시대적 배경 속에서 1999년이 통계적 학습 이론의 성숙, 컴퓨터 비전과 로봇 공학의 혁신, 그리고 AI 기술의 상업적 성공 가능성을 입증하며 21세기 인공지능 및 로봇 공학의 기술적 지형도를 그린 결정적인 한 해였음을 논증하고자 한다.</p>
<p>보고서는 1999년의 기술적 발전을 세 가지 핵심 축으로 나누어 심층적으로 분석한다. 제1부에서는 지지 벡터 머신(SVM)의 이론적 완성, 확률적 잠재 의미 분석(PLSA)의 탄생 등, 데이터 기반 학습 방법론의 근간을 이룬 핵심 이론들을 수학적 원리와 함께 탐구한다. 제2부에서는 척도 불변 특징 변환(SIFT) 알고리즘의 등장으로 대표되는 컴퓨터 비전의 패러다임 전환과, 불확실성 하에서 로봇의 자율성을 확보하기 위한 확률론적 로봇 공학, 특히 동시적 위치 추정 및 지도 작성(SLAM) 기술의 발전을 추적한다. 마지막으로 제3부에서는 소니 아이보(AIBO)의 출시를 통해, 고도의 AI 기술이 어떻게 상업적 제품으로 구현되어 대중에게 첫선을 보였는지 분석한다.</p>
<p>1999년의 발전은 개별적인 사건의 나열이 아니라, 강력한 인과 관계로 연결된 유기적 흐름으로 이해해야 한다. 1부에서 다루는 통계적 학습 이론의 성숙은 2부의 컴퓨터 비전 및 로봇 공학 분야에 견고한 수학적 도구를 제공했다. 이러한 학문적 성과가 집약되어 3부의 아이보와 같은 상업적 성공으로 가시화될 수 있었다. 즉, 1999년은 이론, 응용, 상업화의 선순환 구조가 본격적으로 작동하기 시작한 원년이라 할 수 있다.</p>
<h2>2.  통계적 기계 학습의 이론적 성숙</h2>
<p>1999년은 기계 학습 분야가 경험적 접근에서 벗어나 엄밀한 통계적, 수학적 기반 위에 재정립되던 시기였다. 주요 학회들은 베이즈주의 방법론, 강화 학습, 커널 방법 등 현대 기계 학습의 핵심 패러다임을 정립하는 연구들로 가득 찼다.</p>
<h3>2.1  1999년 주요 AI 학회 동향 분석: NIPS, ICML, AAAI</h3>
<p>1999년에 개최된 주요 인공지능 학회들은 당시 연구의 흐름과 미래 방향성을 명확히 보여준다. 각 학회는 고유한 초점을 가지면서도, 통계적 학습과 데이터 기반 접근법의 중요성이라는 공통된 주제를 공유했다.</p>
<h4>2.1.1 NIPS 1999 (Neural Information Processing Systems)</h4>
<p>콜로라도 덴버에서 개최된 NIPS’99는 신경망 연구를 넘어 통계적 기계 학습 전반을 아우르는 최고 권위 학회로 그 위상을 공고히 했다.2 학회 발표 목록을 면밀히 분석하면, 현대 기계 학습의 근간을 이루는 다양한 주제들이 이미 활발히 논의되고 있었음을 확인할 수 있다.4 예를 들어, Hagai Attias의 “A Variational Bayesian Framework for Graphical Models“는 근사 베이즈 추론의 중요한 방법론을 제시했으며, Vijay R. Konda와 John N. Tsitsiklis의 “Actor-Critic Algorithms“는 이후 강화 학습 분야의 표준 알고리즘으로 자리 잡았다. 또한 Pavel Laskov의 “An Improved Decomposition Algorithm for Regression Support Vector Machines“는 당시 가장 강력한 분류기였던 SVM의 실용성을 높이는 연구였고, Noam Slonim과 Naftali Tishby의 “Agglomerative Information Bottleneck“은 정보 이론을 기계 학습에 접목한 선구적인 시도였다. 이러한 연구들은 AI 연구의 패러다임이 순수 신경망 모델에서 보다 일반화되고 이론적으로 견고한 확률 및 통계 기반 모델로 확장되고 있었음을 명확히 보여준다.</p>
<h4>2.1.2 ICML 1999 (International Conference on Machine Learning)</h4>
<p>슬로베니아 블레드에서 개최된 제16회 국제 기계 학습 학회(ICML’99) 역시 통계적 학습에 대한 높은 관심을 반영했다.5 특히 이 학회에서는 대규모 데이터베이스에서 유용한 지식을 자동으로 추출하는 ’지식 발견(Knowledge Discovery in Databases, KDD)’이 주요 화두로 부상했다.7 관련 워크숍에서는 기계 학습 알고리즘의 성능이 데이터의 품질에 크게 좌우된다는 인식이 확산되면서, 데이터 전처리(discretization, feature selection) 및 후처리(pruning, rule filtering) 기술의 중요성이 집중적으로 논의되었다. 또한, Dunja Mladenic 등이 주관한 ‘텍스트 데이터 분석에서의 기계 학습’ 워크숍은 웹의 폭발적인 성장과 함께 비영어권 텍스트 및 비정형 데이터를 다루는 새로운 도전 과제를 제시했다.8 이는 기계 학습의 응용 분야가 전통적인 정형 데이터를 넘어 인터넷 규모의 텍스트 데이터로 확장되고 있었음을 보여주는 중요한 사례다.</p>
<p>이러한 학회 동향은 당시 연구자들이 ’데이터’의 중요성을 깊이 인식하고 있었음을 시사한다. 강력한 학습 알고리즘의 등장은 역설적으로 데이터의 질과 양, 그리고 이를 처리하는 전/후처리 파이프라인의 중요성을 부각시키는 결과를 낳았다. 이는 알고리즘 자체의 성능 개선에 집중하던 연구에서, 실제 데이터가 가진 복잡성과 노이즈를 공학적으로 해결하려는 데이터 중심의 문제로 관심사가 이동하는 초기 징후로 해석될 수 있다.</p>
<h4>2.1.3 AAAI-99 (National Conference on Artificial Intelligence)</h4>
<p>플로리다 올랜도에서 열린 AAAI-99는 “AI의 봄“을 선언하며 분야의 부활을 자축하는 상징적인 행사였다.1 학회는 에이전트, 월드 와이드 웹, 인지 시스템, 지식 표현, 학습, 로보틱스 등 인공지능의 광범위한 분야를 포괄하는 연구들을 발표했다.9 특히 AAAI 심포지엄 및 워크숍 프로그램은 이론적 연구가 실제 문제 해결로 어떻게 연결되는지를 잘 보여준다. ‘조정 가능한 자율성을 가진 에이전트(Agents with Adjustable Autonomy)’, ‘불확실성 하에서의 문제 해결을 위한 탐색 기술(Search Techniques for Problem Solving Under Uncertainty and Incomplete Information)’, ’정보 추출을 위한 기계 학습(Machine Learning for Information Extraction)’과 같은 주제들은 당시 AI 연구가 현실 세계의 불확실성과 복잡성을 다루기 위해 진화하고 있었음을 명확히 보여준다.10</p>
<h3>2.2  지지 벡터 머신(Support Vector Machine)의 완성</h3>
<p>1990년대 중반 Corinna Cortes와 Vladimir Vapnik에 의해 제안된 지지 벡터 머신(SVM)은 1999년에 이르러 분류 및 회귀 문제에 가장 강력하고 신뢰성 있는 예측 방법론 중 하나로 그 입지를 굳혔다.12 SVM의 성공은 Vapnik-Chervonenkis (VC) 이론이라는 견고한 통계적 학습 이론에 기반하여, 복잡한 문제에서도 뛰어난 일반화 성능을 보였기 때문이다.</p>
<h4>2.2.1 핵심 원리 1: 최대 마진 초평면 (Maximum-Margin Hyperplane)</h4>
<p>SVM의 근본적인 목표는 주어진 데이터를 두 개의 클래스로 분리하는 최적의 결정 경계, 즉 초평면(hyperplane)을 찾는 것이다. 데이터 공간에는 무수히 많은 분리 초평면이 존재할 수 있지만, SVM은 그중에서 각 클래스에 속한 가장 가까운 데이터 샘플(이를 ’서포트 벡터’라 칭함)과의 거리가 최대가 되는 유일한 초평면을 선택한다. 이 거리를 ’마진(margin)’이라 하며, 마진을 최대화하는 것은 모델이 훈련 데이터에 과적합되는 것을 방지하고 새로운 데이터에 대한 일반화 오류를 최소화하는 강력한 이론적 근거를 제공한다.12</p>
<p>이러한 최대 마진 초평면을 찾는 문제는 다음과 같은 제약 조건이 있는 최적화 문제(Primal Problem)로 공식화될 수 있다. 여기서 <span class="math math-inline">w</span>는 초평면의 법선 벡터, <span class="math math-inline">b</span>는 절편, <span class="math math-inline">x_i</span>는 <span class="math math-inline">i</span>번째 데이터 샘플, <span class="math math-inline">y_i \in \{-1, 1\}</span>는 해당 샘플의 클래스 레이블이다. 목적 함수 <span class="math math-inline">\frac{1}{2} \|w\|^2</span>를 최소화하는 것은 마진 <span class="math math-inline">\frac{2}{\|w\|}</span>를 최대화하는 것과 동일하다.</p>
<p><span class="math math-display">
\min_{w, b} \frac{1}{2} \|w\|^2 \quad \text{subject to} \quad y_i(w^T x_i + b) \ge 1, \quad \forall i=1, \dots, n
</span></p>
<h4>2.2.2 핵심 원리 2: 커널 트릭 (The Kernel Trick)</h4>
<p>실제 데이터는 복잡하게 얽혀 있어 선형 초평면만으로는 완벽하게 분리할 수 없는 경우가 많다. 이러한 비선형 문제를 해결하기 위해 SVM은 ’커널 트릭’이라는 매우 독창적인 기법을 사용한다. 커널 트릭의 핵심 아이디어는 원래의 입력 데이터를 직접 다루기 힘든 더 높은 차원의 특징 공간(feature space)으로 매핑하여, 그 고차원 공간에서 선형 분리가 가능하도록 만드는 것이다.13 놀라운 점은, 이 과정에서 데이터를 고차원 공간으로 실제로 변환하는 복잡한 계산을 수행할 필요가 없다는 것이다. 커널 함수 <span class="math math-inline">k(x_i, x_j)</span>를 사용하면, 원래 공간에서 두 벡터의 내적을 계산하는 것만으로 고차원 특징 공간에서의 내적 결과 <span class="math math-inline">\phi(x_i)^T \phi(x_j)</span>를 얻을 수 있다. 이를 통해 SVM은 계산 복잡도를 크게 높이지 않으면서도 강력한 비선형 분류 능력을 갖추게 된다.12</p>
<h4>2.2.3 수학적 심층 분석: 라그랑주 쌍대 문제 (Lagrangian Duality)</h4>
<p>SVM의 최적화 문제를 효율적으로 풀고 커널 트릭을 적용하기 위해, 라그랑주 승수법을 이용하여 원래의 제약 최적화 문제(Primal Problem)를 쌍대 문제(Dual Problem)로 변환한다. 먼저, 각 제약 조건에 대해 라그랑주 승수 <span class="math math-inline">\alpha_i \ge 0</span>를 도입하여 라그랑지안 함수 <span class="math math-inline">L</span>을 정의한다.15</p>
<p><span class="math math-display">
L(w, b, \alpha) = \frac{1}{2} \|w\|^2 - \sum_{i=1}^{n} \alpha_i
</span><br />
쌍대 문제를 얻기 위해, 라그랑지안 함수 <span class="math math-inline">L</span>을 primal 변수인 <span class="math math-inline">w</span>와 <span class="math math-inline">b</span>에 대해 최소화한다. 이를 위해 <span class="math math-inline">L</span>을 <span class="math math-inline">w</span>와 <span class="math math-inline">b</span>에 대해 각각 편미분하여 0으로 설정하면 다음 두 가지 조건을 얻는다.17</p>
<p><span class="math math-display">
\frac{\partial L}{\partial w} = w - \sum_{i=1}^{n} \alpha_i y_i x_i = 0 \quad \Rightarrow \quad w = \sum_{i=1}^{n} \alpha_i y_i x_i
</span></p>
<p><span class="math math-display">
\frac{\partial L}{\partial b} = - \sum_{i=1}^{n} \alpha_i y_i = 0 \quad \Rightarrow \quad \sum_{i=1}^{n} \alpha_i y_i = 0
</span></p>
<p>이 결과들을 원래의 라그랑지안 함수에 다시 대입하여 정리하면, 문제는 dual 변수인 <span class="math math-inline">\alpha</span>에 대한 최대화 문제로 변환된다. 이 쌍대 문제의 형태는 SVM의 중요한 특성을 드러낸다. 목적 함수가 데이터 샘플 간의 내적(<span class="math math-inline">x_i^T x_j</span>)으로만 표현되기 때문에, 이 부분을 커널 함수 <span class="math math-inline">k(x_i, x_j)</span>로 대체하여 비선형 SVM으로 쉽게 확장할 수 있다. 또한, 최적해에서 <span class="math math-inline">\alpha_i &gt; 0</span>인 데이터 샘플 <span class="math math-inline">x_i</span>만이 서포트 벡터가 되어 결정 경계를 정의하는 데 기여하므로, 모델이 희소(sparse)한 해를 갖게 된다.19</p>
<p><span class="math math-display">
\max_{\alpha} \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (x_i^T x_j) \quad \text{s.t.} \quad \alpha_i \ge 0, \quad \sum_{i=1}^{n} \alpha_i y_i = 0
</span></p>
<h3>2.3  확률적 잠재 의미 분석(Probabilistic Latent Semantic Analysis)의 탄생</h3>
<p>1999년 Thomas Hofmann이 불확실성 인공지능 학회(UAI)에서 발표한 확률적 잠재 의미 분석(PLSA)은 텍스트 데이터 분석에 통계적 모델링을 도입한 획기적인 연구였다.20 기존의 잠재 의미 분석(LSA)이 행렬 분해(SVD)라는 순수 선형 대수 기법에 의존하여 통계적 기반이 부족했던 반면, PLSA는 문서-단어 동시 발생 데이터를 확률적 생성 모델로 설명함으로써 보다 원리적이고 해석 가능한 접근법을 제시했다.20</p>
<h4>2.3.1 핵심 목표</h4>
<p>PLSA의 핵심 목표는 관찰된 문서-단어 행렬의 이면에 존재하는 잠재적인 의미 구조, 즉 ’토픽(topic)’을 발견하는 것이다. 이 모델은 각 문서가 여러 토픽의 확률적 혼합으로 구성되고, 각 토픽은 특정 단어들의 확률 분포로 표현된다는 직관적인 가정을 기반으로 한다. 이를 통해 단어의 다의성(polysemy)과 문서의 동의성(synonymy) 문제를 통계적으로 해결하고자 했다.22</p>
<h4>2.3.2 확률 모델 (Aspect Model)</h4>
<p>PLSA는 ’Aspect Model’이라는 잠재 변수 모델에 기반한다. 이 모델은 관찰된 변수인 문서(<span class="math math-inline">d</span>)와 단어(<span class="math math-inline">w</span>) 사이의 관계를, 관찰되지 않은 잠재 변수인 토픽(<span class="math math-inline">z</span>)을 통해 설명한다. 이 모델이 가정하는 문서 생성 과정은 다음과 같다 22:</p>
<ol>
<li>
<p>특정 문서 <span class="math math-inline">d</span>를 확률 <span class="math math-inline">P(d)</span>로 선택한다.</p>
</li>
<li>
<p>선택된 문서 <span class="math math-inline">d</span>에 대한 토픽 분포 <span class="math math-inline">P(z|d)</span>로부터 하나의 토픽 <span class="math math-inline">z</span>를 샘플링한다.</p>
</li>
<li>
<p>선택된 토픽 <span class="math math-inline">z</span>에 대한 단어 분포 <span class="math math-inline">P(w|z)</span>로부터 하나의 단어 <span class="math math-inline">w</span>를 샘플링한다.</p>
</li>
</ol>
<p>이 생성 과정은 문서와 단어의 동시 발생이 잠재적인 토픽을 매개로 이루어진다는 가정을 수학적으로 표현한 것이다.</p>
<h4>2.3.3 수학적 심층 분석: 확률 분해 및 파라미터 추정</h4>
<p>Aspect Model에 따르면, 문서 <span class="math math-inline">d</span>와 단어 <span class="math math-inline">w</span>가 동시에 관찰될 결합 확률 <span class="math math-inline">P(d, w)</span>는 모든 가능한 잠재 토픽 <span class="math math-inline">z</span>에 대해 주변화(marginalize out)하여 다음과 같이 분해할 수 있다. 이는 PLSA 모델의 가장 핵심적인 수식이다.22</p>
<p><span class="math math-display">
P(d, w) = P(d) P(w|d) = P(d) \sum_{z \in Z} P(w|z) P(z|d)
</span><br />
이 모델의 파라미터는 두 개의 조건부 확률 분포, 즉 각 문서의 토픽 분포를 나타내는 <span class="math math-inline">P(z|d)</span>와 각 토픽의 단어 분포를 나타내는 <span class="math math-inline">P(w|z)</span>이다. 이 파라미터들은 주어진 문서-단어 집합(corpus)에 대한 로그 우도(log-likelihood)를 최대화하는 방식으로 추정된다. 로그 우도 함수는 직접적으로 최적화하기 어렵기 때문에, 일반적으로 기댓값 최대화(Expectation-Maximization, EM) 알고리즘을 사용하여 반복적으로 파라미터를 갱신하며 최적해를 찾는다.22 PLSA의 등장은 이후 잠재 디리클레 할당(LDA)과 같은 더욱 정교한 토픽 모델링 연구의 기폭제가 되었다.</p>
<h2>3.  컴퓨터 비전과 로봇 공학의 혁신</h2>
<p>1999년은 컴퓨터 비전과 로봇 공학 분야에서도 중요한 돌파구가 마련된 해였다. 이론적 성숙을 이룬 기계 학습 방법론은 이들 응용 분야의 오랜 난제들을 해결하는 강력한 도구가 되었고, 이는 새로운 패러다임의 시작을 알렸다.</p>
<h3>3.1  척도 불변 특징 변환(Scale-Invariant Feature Transform)</h3>
<p>1999년 David Lowe가 국제 컴퓨터 비전 학회(ICCV)에서 발표한 “Object Recognition from Local Scale-Invariant Features” 논문은 컴퓨터 비전 분야의 지형을 바꾼 혁명적인 연구로 평가받는다.23 이전의 특징점 검출 방법들은 이미지의 크기(scale), 회전, 시점 변화에 매우 취약하여 실제 환경에서의 객체 인식에 한계가 있었다. SIFT는 이러한 기하학적, 광학적 변화에 강인한(robust) 지역 특징(local feature)을 안정적으로 추출하는 포괄적인 프레임워크를 최초로 제시했다.27</p>
<h4>3.1.1 핵심 목표</h4>
<p>SIFT 알고리즘의 핵심 목표는 이미지의 내용이 변환(translation), 회전(rotation), 크기(scaling) 변화를 겪거나, 조명 조건이나 3D 시점이 다소 바뀌더라도, 동일한 객체나 장면 영역에서는 항상 일관되게 검출되고, 다른 영역의 특징과는 명확히 구별되는 ‘독특한(distinctive)’ 특징점을 대량으로 추출하는 것이다.30 이러한 특징점들은 객체 인식, 이미지 매칭, 3D 재구성 등 다양한 고수준 비전 작업의 기초가 된다.</p>
<h4>3.1.2 알고리즘 4단계 심층 분석</h4>
<p>SIFT는 네 개의 주요 단계로 구성된 정교한 파이프라인을 통해 불변 특징을 추출한다.32</p>
<ol>
<li>
<p><strong>척도-공간 극값 검출 (Scale-space Extrema Detection):</strong> 크기 불변성을 확보하기 위해, SIFT는 먼저 이미지를 다양한 척도에서 분석하는 척도-공간(scale-space)을 구축한다. 이는 원본 이미지를 점진적으로 흐릿하게 만드는 가우시안 블러링을 통해 구현된다. 서로 다른 두 척도의 가우시안 블러 이미지를 빼서 가우시안 차분(Difference of Gaussians, DoG) 이미지를 생성한다. DoG는 계산 비용이 높은 가우시안 라플라시안(LoG)의 효율적인 근사치로, 이미지 내의 얼룩(blob)과 같은 특징 영역을 강조하는 역할을 한다. 이후, 특정 픽셀 값을 인접한 8개의 픽셀 및 상하 척도의 인접한 18개 픽셀(총 26개)과 비교하여 지역적 극값(최대 또는 최소)을 갖는 지점을 키포인트(keypoint) 후보로 선정한다.30</p>
</li>
<li>
<p><strong>키포인트 위치 결정 (Keypoint Localization):</strong> 1단계에서 찾은 후보 키포인트는 위치와 척도가 이산적(discrete)이므로, 보다 정확한 위치를 찾기 위한 정제 과정이 필요하다. 척도-공간 함수에 대한 테일러 급수 전개를 이용하여 서브픽셀(sub-pixel) 수준의 정밀한 위치, 척도, 곡률을 계산한다. 이 과정에서 대비(contrast)가 너무 낮아 노이즈에 민감한 점이나, 경계선(edge)에 위치하여 위치 안정성이 떨어지는 점들은 제거된다. 경계선 응답을 제거하기 위해 2x2 헤시안(Hessian) 행렬의 주곡률(principal curvatures) 비율을 계산하여, 이 비율이 특정 임계값을 초과하는 점들을 걸러낸다.35</p>
</li>
<li>
<p><strong>방향 할당 (Orientation Assignment):</strong> 회전 불변성을 달성하기 위해, 각 키포인트에 표준 방향(canonical orientation)을 할당한다. 정제된 키포인트의 척도에 해당하는 가우시안 블러 이미지에서, 키포인트 주변 영역의 모든 픽셀에 대해 그래디언트 크기와 방향을 계산한다. 이 정보를 바탕으로 360도를 36개의 빈(bin)으로 나눈 방향 히스토그램을 생성하며, 각 픽셀은 그래디언트 크기에 따라 가중치를 부여받아 해당 방향의 빈에 투표한다. 히스토그램에서 가장 높은 값을 가진 빈의 방향이 해당 키포인트의 주 방향으로 결정된다. 만약 다른 빈이 최고점의 80% 이상 값을 가질 경우, 해당 방향도 추가적인 키포인트 방향으로 할당하여 안정성을 높인다.32</p>
</li>
<li>
<p><strong>키포인트 기술자 생성 (Keypoint Descriptor Generation):</strong> 마지막으로, 각 키포인트 주변의 지역적 이미지 정보를 고유하고 강인한 벡터 표현, 즉 기술자(descriptor)로 변환한다. 키포인트의 주 방향에 따라 이미지 영역을 회전시켜 방향 의존성을 제거한다. 이후 키포인트 주변의 16x16 픽셀 영역을 16개의 4x4 부영역으로 나눈다. 각 4x4 부영역 내에서 8방향 그래디언트 방향 히스토그램을 계산한다. 이렇게 생성된 16개의 8차원 히스토그램을 일렬로 연결하여 총 128차원(16개 부영역 x 8방향)의 벡터를 만든다. 이 128차원 벡터가 최종 SIFT 기술자이며, 조명 변화에 대한 강인성을 높이기 위해 벡터를 정규화하는 과정을 거친다.32</p>
</li>
</ol>
<h3>3.2  1999년 주요 로봇 공학 학회 동향: ICRA, IROS</h3>
<p>1999년 로봇 공학 분야의 주요 학회들은 전통적인 기계 공학적 접근과 더불어, 인공지능 기술을 적극적으로 수용하려는 움직임을 뚜렷하게 보여주었다.</p>
<h4>3.2.1 ICRA 1999 (International Conference on Robotics and Automation)</h4>
<p>미국 디트로이트에서 개최된 ICRA’99는 로봇 공학의 광범위한 주제를 포괄하는 대표적인 학회였다.36 발표된 논문 목록을 살펴보면, 로봇 메커니즘 설계, 매니퓰레이터 제어, 이동 로봇의 경로 계획과 같은 전통적인 주제들이 여전히 중요한 비중을 차지하고 있었다. 동시에 비전 기반 내비게이션, 마이크로/나노 스케일 조작, 인간-로봇 상호작용(HRI), 햅틱 인터페이스와 같은 신흥 연구 분야들이 활발히 논의되었음을 알 수 있다.38 이는 로봇 공학의 연구 범위가 산업 현장을 넘어 인간의 일상 환경과 미시 세계로 확장되고 있었음을 시사한다.</p>
<h4>3.2.2 IROS 1999 (International Conference on Intelligent Robots and Systems)</h4>
<p>IROS’99 역시 로봇 운동학 및 동역학, 모션 플래닝, 인간-로봇 인터페이스 등 다양한 주제를 다루었다.39 특히 학회 이름에서 알 수 있듯이 ’지능형 로봇’에 대한 관심이 높았으며, 발표된 논문들에서는 유전 알고리즘, 신경망과 같은 인공지능 기법을 로봇의 학습 및 제어 문제에 접목하려는 시도들이 두드러졌다.39</p>
<h4>3.2.3 CIRA ’99 (Computational Intelligence in Robotics and Automation)</h4>
<p>IEEE가 주관한 이 심포지엄은 로봇 공학에 계산 지능(Computational Intelligence)을 적용하는 데 명확히 초점을 맞추었다는 점에서 주목할 만하다.41 이는 로봇 공학이 순수 기계 공학의 범주를 넘어, 불확실하고 동적인 환경에 적응하고 학습하는 능력을 갖추기 위해 인공지능과의 융합을 필연적인 방향으로 인식하고 있었음을 보여주는 중요한 증거다.</p>
<p>1999년 AI 학회와 로봇 공학 학회의 발표 주제들을 비교 분석하면, 두 분야의 융합이 본격화되는 중요한 변곡점이었음을 알 수 있다. 당시 AI 분야에서 발전된 확률 모델과 통계적 학습 알고리즘은 로봇 공학이 직면한 근본적인 문제, 즉 센서 노이즈와 환경의 ’불확실성’을 다루는 핵심적인 이론적 도구로 채택되기 시작했다. 1999년 가을 AI Magazine에 실린 “AI는 언제 어디서 로봇 공학과 만날 것인가? 표현의 문제들(When and Where Will AI Meet Robotics? Issues in Representation)“이라는 제목의 기사는 이러한 시대적 흐름을 상징적으로 보여준다.42 이는 AI 커뮤니티가 물리적 세계와의 상호작용이라는 로봇 공학의 본질적 과제를 해결하기 위해 의식적인 노력을 기울이기 시작했음을 의미한다. 이 시기에 AI는 더 이상 추상적인 이론에 머무르지 않고, 로봇이라는 구체적인 플랫폼을 통해 그 가능성을 증명하려 했다.</p>
<h3>3.3  확률론적 로봇 공학의 발전과 SLAM</h3>
<p>1999년 당시, 자율 이동 로봇이 미지의 환경에서 자신의 위치를 추정하면서 동시에 주변 환경의 지도를 작성하는 동시적 위치 추정 및 지도 작성(SLAM) 문제는 로봇 자율성의 핵심 난제로 여겨졌다.43 확률론적 로봇 공학은 이러한 불확실성을 수학적으로 모델링하고 통계적 추론을 통해 해결하기 위한 강력한 프레임워크를 제공했다.46</p>
<h4>3.3.1 핵심 개념: 베이즈 필터 기반의 재귀적 상태 추정 (Recursive State Estimation using Bayes Filter)</h4>
<p>확률론적 접근법의 핵심은 로봇의 상태(예: 위치와 방향)와 지도를 확률 분포, 즉 ’믿음(belief)’으로 표현하는 것이다. 로봇이 움직이고 센서를 통해 환경을 관측할 때마다, 이 믿음(확률 분포)을 재귀적으로 갱신하여 불확실성을 점진적으로 줄여나간다. 이 재귀적 갱신 과정은 예측(Prediction)과 업데이트(Update)라는 두 단계로 구성된다.49</p>
<h4>3.3.2 수학적 심층 분석</h4>
<p>로봇의 상태를 나타내는 변수를 <span class="math math-inline">x_t</span>라고 할 때, 시간 <span class="math math-inline">t</span>까지의 모든 제어 입력 <span class="math math-inline">u_{1:t}</span>와 관측 데이터 <span class="math math-inline">z_{1:t}</span>가 주어졌을 때의 믿음, 즉 사후 확률 <span class="math math-inline">bel(x_t) = p(x_t | u_{1:t}, z_{1:t})</span>를 계산하는 것이 목표다.</p>
<ol>
<li>
<p><strong>예측 단계 (Prediction):</strong> 이 단계에서는 시간 <span class="math math-inline">t-1</span>에서의 믿음 <span class="math math-inline">bel(x_{t-1})</span>과 제어 입력 <span class="math math-inline">u_t</span>를 사용하여 시간 <span class="math math-inline">t</span>의 상태를 예측한다. 이는 로봇의 움직임 모델 <span class="math math-inline">p(x_t | u_t, x_{t-1})</span>을 통해 이루어지며, 전확률 법칙(law of total probability)에 따라 이전 상태 <span class="math math-inline">x_{t-1}</span>에 대해 적분하여 시간 <span class="math math-inline">t</span>에서의 사전(prior) 믿음 <span class="math math-inline">\overline{bel}(x_t)</span>을 계산한다.<br />
<span class="math math-display">
\overline{bel}(x_t) = p(x_t | u_{1:t}, z_{1:t-1}) = \int p(x_t | u_t, x_{t-1}) bel(x_{t-1}) dx_{t-1}
</span></p>
</li>
<li>
<p><strong>업데이트 단계 (Update / Correction):</strong> 이 단계에서는 예측된 사전 믿음 <span class="math math-inline">\overline{bel}(x_t)</span>에 시간 <span class="math math-inline">t</span>에서 새로 얻은 센서 측정값 <span class="math math-inline">z_t</span>를 통합한다. 이는 베이즈 정리를 통해 이루어지며, 측정 모델 <span class="math math-inline">p(z_t | x_t)</span>를 우도(likelihood)로 사용하여 사후(posterior) 믿음 <span class="math math-inline">bel(x_t)</span>을 계산한다. 여기서 <span class="math math-inline">\eta</span>는 확률 분포의 합이 1이 되도록 하는 정규화 상수다.</p>
<p><span class="math math-display">
bel(x_t) = \eta p(z_t | x_t) \overline{bel}(x_t)
</span></p>
</li>
</ol>
<p>이러한 재귀적 베이즈 필터링 프레임워크는 SLAM 문제에 사용되는 다양한 구체적인 알고리즘들의 이론적 기반이 된다.51 1999년 당시에는 상태와 불확실성을 가우시안 분포로 가정하고, 비선형적인 로봇 모델을 선형화하여 근사하는 확장 칼만 필터(Extended Kalman Filter, EKF) 기반의 SLAM(EKF-SLAM)이 가장 널리 연구되는 접근법 중 하나였다.55</p>
<h2>4.  인공지능의 상업적 이정표</h2>
<p>1999년은 학술적 성과가 연구실의 경계를 넘어 일반 대중이 체감할 수 있는 상업적 제품으로 구현되기 시작한 중요한 해였다. 특히 소니의 아이보 출시는 이러한 흐름을 상징하는 대표적인 사건이었다.</p>
<h3>4.1  소니 아이보(AIBO) ERS-110 출시</h3>
<p>1999년 5월 11일, 소니는 세계 최초의 가정용 엔터테인먼트 로봇 ‘아이보(AIBO)’ ERS-110 모델을 발표했다.56 이는 고도로 복잡한 인공지능과 로봇 공학 기술이 결합하여 일반 소비자 시장에 진입한 최초의 사례 중 하나로, 기술사적으로 매우 중요한 이정표다. 아이보는 단순히 프로그램된 대로 움직이는 기계가 아니라, 자율적으로 판단하고, 주인과 교감하며, 시간이 지남에 따라 ’성장’하는 능력을 갖춘 인공 생명체로서 새로운 시장을 개척했다.</p>
<h4>4.1.1 탑재된 AI 기술</h4>
<p>아이보의 핵심 가치는 내장된 정교한 인공지능 기술에 있었다.</p>
<ul>
<li>
<p><strong>자율적 판단 및 반응:</strong> 아이보는 기쁨, 분노와 같은 기본적인 감정과 동료애와 같은 사회적 본능을 소프트웨어적으로 내장했다. 이를 바탕으로 외부 자극(소리, 접촉 등)과 자신의 내부 상태(기분, 에너지 등)에 따라 자율적으로 행동하며 다양한 방식으로 감정을 표현했다.56</p>
</li>
<li>
<p><strong>학습 및 성장 능력:</strong> 아이보의 가장 혁신적인 특징 중 하나는 적응형 학습 및 성장 기능이었다. 사용자의 칭찬(머리를 쓰다듬는 행위 등)과 꾸짖음(가볍게 때리는 행위 등)에 따라 행동 패턴이 점진적으로 변화하도록 설계되었다. 이로 인해 모든 아이보는 주인과의 상호작용 경험에 따라 고유한 개성을 가진 존재로 발전할 수 있었다.56</p>
</li>
<li>
<p><strong>고급 상호작용:</strong> 아이보는 18만 화소 컬러 CCD 카메라, 스테레오 마이크, 머리의 터치 센서, 적외선 거리 측정 센서 등 다양한 센서를 통해 외부 환경을 다각적으로 인식했다. 이를 통해 색깔 공을 인식하고 쫓아가거나, 주인의 목소리에 반응할 수 있었다. 또한, 입, 머리, 다리, 꼬리에 걸쳐 총 18개의 자유도를 가진 관절을 정교하게 제어하여 걷고, 앉고, 꼬리를 흔드는 등 풍부한 표현력을 보여주었다.56</p>
</li>
</ul>
<h4>4.1.2 기술적 사양</h4>
<p>아이보 ERS-110의 기술 사양은 1999년 당시 상용화된 임베디드 AI 시스템의 기술 수준과 공학적 한계를 명확히 보여주는 중요한 지표다. 64비트 RISC 프로세서와 16MB의 주 메모리는 오늘날의 기준으로 보면 매우 제한적이지만, 당시로서는 로봇의 자율 행동, 센서 데이터 처리, 학습 알고리즘을 실시간으로 구동하기 위한 최선의 선택이었다.</p>
<p>특히 주목할 점은 프로그램 저장을 위해 소니의 독자 규격인 ’메모리 스틱’을 사용했다는 것이다.56 이는 단순한 데이터 저장을 넘어, 소프트웨어 업데이트를 통해 아이보의 성격이나 능력을 바꿀 수 있는 확장성을 염두에 둔 설계 사상을 보여준다. 이는 현대 스마트 기기의 애플리케이션 생태계와 유사한 개념의 초기 형태로, 하드웨어 플랫폼 위에 다양한 소프트웨어 콘텐츠를 유통하려는 비즈니스 모델의 가능성을 시사한다. 이처럼 아이보의 기술 사양은 당시 하드웨어 제약 속에서 복잡한 AI를 구현하려는 치열한 공학적 고민의 산물이었다.</p>
<p>아래 표는 아이보 ERS-110의 주요 기술 사양을 요약한 것이다. 이 표는 본 보고서에서 논의된 추상적인 AI 및 로봇 공학 이론이 1999년에 어떤 물리적 실체로 구현되었는지를 구체적인 수치로 보여준다.</p>
<h5>4.1.2.1 Table 1: Sony AIBO ERS-110 Technical Specifications</h5>
<table><thead><tr><th>구성 요소 (Component)</th><th>사양 (Specification)</th></tr></thead><tbody>
<tr><td><strong>중앙 처리 장치 (CPU)</strong></td><td>64-bit RISC Processor</td></tr>
<tr><td><strong>주 메모리 (Main Memory)</strong></td><td>16MB</td></tr>
<tr><td><strong>프로그램 메모리 (Program Memory)</strong></td><td>8MB Memory Stick™</td></tr>
<tr><td><strong>자유도 (Degrees of Freedom)</strong></td><td>총 18 DoF (입: 1, 머리: 3, 다리: 3 x 4, 꼬리: 2)</td></tr>
<tr><td><strong>내장 센서 (Internal Sensors)</strong></td><td></td></tr>
<tr><td>영상 입력 (Video Input)</td><td>180,000 pixel color CCD camera (x 1)</td></tr>
<tr><td>음성 입력 (Audio Input)</td><td>Stereo microphone (one on each side)</td></tr>
<tr><td>음성 출력 (Audio Output)</td><td>Speaker (x 1)</td></tr>
<tr><td>열 감지 (Heat Detector)</td><td>Heat Sensor (x 2)</td></tr>
<tr><td>거리 측정 (Range Finder)</td><td>Infra-red range finding sensor (x 1)</td></tr>
<tr><td>가속도 (Acceleration Detector)</td><td>Spatial acceleration sensor (x 1)</td></tr>
<tr><td>각속도 (Rotation Detector)</td><td>Angular velocity sensor (x 1)</td></tr>
<tr><td>접촉 (Contact Detectors)</td><td>Touch sensor (x 1), Switch (x 4)</td></tr>
<tr><td><strong>전원 (Power Source)</strong></td><td>DC7.2V (Lithium Ion Battery)</td></tr>
<tr><td><strong>소비 전력 (Energy Consumption)</strong></td><td>12.6W (autonomous mode)</td></tr>
<tr><td><strong>작동 시간 (Operating Time)</strong></td><td>약 1.5 시간 (완전 충전 시)</td></tr>
<tr><td><strong>크기 (Dimensions, l x w x h)</strong></td><td>약 274 x 156 x 266mm (꼬리 제외)</td></tr>
<tr><td><strong>무게 (Weight)</strong></td><td>약 1.6kg (메모리 스틱 및 배터리 포함)</td></tr>
<tr><td>Data Source: 56</td><td></td></tr>
</tbody></table>
<h2>5. 결론</h2>
<p>1999년은 인공지능과 로봇 공학이 이론적 깊이를 더하고, 응용 분야의 혁신을 이루며, 상업적 가능성을 증명한 역사적인 분수령이었다. 이 해에 이루어진 발전들은 개별적인 성과를 넘어 서로 유기적으로 연결되며 21세기 기술 지형의 토대를 마련했다.</p>
<p>SVM과 PLSA와 같은 정교한 통계적 학습 모델의 등장은 인공지능 연구에 견고한 수학적 기반을 제공했으며, 이는 경험적이고 직관적인 접근에서 벗어나 원리적인 문제 해결을 가능하게 했다. 컴퓨터 비전 분야에서는 SIFT 알고리즘이 이미지의 기하학적, 광학적 변화라는 오랜 난제를 해결하는 결정적인 돌파구를 열었고, 로봇 공학 분야에서는 확률론적 SLAM이 불확실한 실제 환경에서 로봇의 자율성을 확보하는 핵심 기술로 부상했다. 그리고 소니 아이보는 이 모든 추상적인 기술적 성취가 어떻게 인간의 삶과 직접적으로 상호작용하는 구체적인 형태로 결실을 맺을 수 있는지에 대한 명확한 비전을 제시했다.</p>
<p>1999년에 제시된 개념들은 이후 20년간 AI 기술 발전의 씨앗이 되었다. PLSA는 잠재 디리클레 할당(LDA)과 같은 더욱 정교한 토픽 모델링 연구로 직접 이어졌고, SIFT는 딥러닝이 부상하기 전까지 객체 인식과 이미지 매칭 분야를 지배하는 표준 기술로 자리 잡았다. 확률론적 SLAM은 오늘날 자율주행차, 실내 서비스 로봇, 드론 기술의 핵심 기반이 되었다. 아이보가 보여준 인간-로봇 상호작용의 비전은 소셜 로봇과 인공지능 비서 기술로 계승 발전하고 있다.</p>
<p>결론적으로, 1999년은 단순히 과거의 한 해가 아니라, 현재 우리가 경험하고 있는 인공지능 혁명의 청사진이 그려진 ’설계의 시대’였다고 평가할 수 있다. 이 시기에 정립된 이론적 토대와 기술적 돌파구 없이는 오늘날의 AI 기술을 상상하기 어려울 것이다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>AAAI-99: Sixteenth National Conference on Artificial Intelligence, https://aaai.org/conference/aaai/aaai99/</li>
<li>Neural Information Processing Systems (NIPS) - SIGMOD, http://www.sigmod.org/publications/dblp/db/conf/nips/index.html</li>
<li>NIPS: Neural Information Processing Systems 1999 (NIPS*99), http://www.cs.cmu.edu/Groups/NIPS/1999/nips99.html</li>
<li>NeurIPS 1999 Accepted Paper List, https://papercopilot.com/paper-list/neurips-paper-list/neurips-1999-paper-list/</li>
<li>International Conference on Machine Learning (ICML) - ACM SigMod, http://www.sigmod.org/publications/dblp/db/conf/icml/index.html</li>
<li>Machine Learning: Proceedings of the Sixteenth International Conference - Google Books, https://books.google.co.zw/books?id=5HNFAAAAYAAJ&amp;source=gbs_book_other_versions_r&amp;cad=4</li>
<li>UAI maillist archive: ICML-99 workshop: CFP - College of Engineering | Oregon State University, https://web.engr.oregonstate.edu/~dambrobr/uai-archive-pre00/0365.html</li>
<li>UAI maillist archive: CFP: ICML-99 Workshop on Machine Learning in Text Data Analysis, https://web.engr.oregonstate.edu/~dambrobr/uai-archive-pre00/0351.html</li>
<li>Proceedings of the AAAI Conference on Artificial Intelligence, 16 Archives, https://aaai.org/proceeding/aaai-16-1999/</li>
<li>AAAI 1999 Symposia - The Association for the Advancement of Artificial Intelligence, https://aaai.org/conference/spring-symposia/sss99/</li>
<li>AAAI Workshop Papers 1999 Archives - The Association for the Advancement of Artificial Intelligence, https://aaai.org/proceeding/aaaiw-99/</li>
<li>Support Vector Machine - Encyclopedia.pub, https://encyclopedia.pub/entry/29353</li>
<li>Support vector machine - Wikipedia, https://en.wikipedia.org/wiki/Support_vector_machine</li>
<li>History: 1 Support Vector Machines: History | PDF - Scribd, https://www.scribd.com/document/513164667/svm-history2</li>
<li>Lecture 13: Dual Formulation of Support Vector Machines — Applied ML - Kuleshov Group, https://kuleshov-group.github.io/aml-book/contents/lecture13-svm-dual.html</li>
<li>SVM - Understanding the math: duality and Lagrange multipliers - SVM Tutorial, https://www.svm-tutorial.com/2016/09/duality-lagrange-multipliers/</li>
<li>Duality for the SVM - Math ∩ Programming, https://www.jeremykun.com/2017/06/12/duality-for-the-svm/</li>
<li>Lagrangian dual of SVM: derivation - Cross Validated - Stack Exchange, https://stats.stackexchange.com/questions/331931/lagrangian-dual-of-svm-derivation</li>
<li>SVM DUAL FORMULATION. Support Vector Machine (SVM) is a… | by sathvik chiramana | Medium, https://medium.com/@sathvikchiramana/svm-dual-formulation-7535caa84f17</li>
<li>PLSA – Knowledge and References - Taylor &amp; Francis, https://taylorandfrancis.com/knowledge/Engineering_and_technology/Engineering_support_and_special_topics/PLSA/</li>
<li>Probabilistic Latent Semantic Analysis ( cf. [7]). How - arXiv, https://arxiv.org/abs/1301.6705</li>
<li>Probabilistic Latent Semantic Analysis, https://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/AV1011/oneata.pdf</li>
<li>Scale-invariant feature transform - Wikipedia, https://en.wikipedia.org/wiki/Scale-invariant_feature_transform</li>
<li>Object Recognition from Local Scale-Invariant Features | Request PDF, https://www.researchgate.net/publication/2373439_Object_Recognition_from_Local_Scale-Invariant_Features</li>
<li>(PDF) Object recognition from local scale-invariant features (1999) | David G. Lowe, https://scispace.com/papers/object-recognition-from-local-scale-invariant-features-5887b1cgwf</li>
<li>[PDF] Object recognition from local scale-invariant features - Semantic Scholar, https://www.semanticscholar.org/paper/Object-recognition-from-local-scale-invariant-Lowe/f9f836d28f52ad260213d32224a6d227f8e8849a</li>
<li>Object Recognition from Local Scale-Invariant Features 1. Introduction - UBC Computer Science, https://www.cs.ubc.ca/~lowe/papers/iccv99.pdf</li>
<li>Object Recognition from Local Scale-Invariant Features 1. Introduction - People @EECS, <a href="https://people.eecs.berkeley.edu/~yang/courses/cs294-6/papers/LoweD_Object%20recognition%20from%20local%20scale-invariant%20features.pdf">https://people.eecs.berkeley.edu/~yang/courses/cs294-6/papers/LoweD_Object%20recognition%20from%20local%20scale-invariant%20features.pdf</a></li>
<li>SIFT feature detector and descriptor extractor — skimage 0.25.2 documentation, https://scikit-image.org/docs/0.25.x/auto_examples/features_detection/plot_sift.html</li>
<li>What is Scale-Invariant Feature Transform (SIFT)? - Roboflow Blog, https://blog.roboflow.com/sift/</li>
<li>SIFT - UCI Mathematics, https://www.math.uci.edu/~yqi/lect/TutorialSift.pdf</li>
<li>Describe the concept of scale-invariant feature transform (SIFT) - GeeksforGeeks, https://www.geeksforgeeks.org/computer-vision/describe-the-concept-of-scale-invariant-feature-transform-sift/</li>
<li>Introduction to SIFT( Scale Invariant Feature Transform) | by Deep - Medium, https://medium.com/@deepanshut041/introduction-to-sift-scale-invariant-feature-transform-65d7f3a72d40</li>
<li>What is SIFT(Scale Invariant Feature Transform) Algorithm? - Analytics Vidhya, https://www.analyticsvidhya.com/blog/2019/10/detailed-guide-powerful-sift-technique-image-matching-python/</li>
<li>Introduction to SIFT (Scale-Invariant Feature Transform) - OpenCV Documentation, https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html</li>
<li>International Conference on Robotics and Automation (ICRA), https://sigmod.org/publications/dblp////db/conf/icra/index.html</li>
<li>1999 IEEE International Conference on Robotics and Automation - Nanyang Technological University, <a href="https://ntu-sp.primo.exlibrisgroup.com/discovery/fulldisplay?vid=65NTU_INST:65NTU_INST&amp;docid=alma991016308608905146&amp;context=L">https://ntu-sp.primo.exlibrisgroup.com/discovery/fulldisplay?vid=65NTU_INST%3A65NTU_INST&amp;docid=alma991016308608905146&amp;context=L</a></li>
<li>ICRA 1999 - dblp, https://dblp.org/db/conf/icra/icra1999-4.html</li>
<li>IROS: Proceedings of the … IEEE/RSJ International Conference on - Google Books, https://books.google.com/books/about/IROS.html?id=pgZWAAAAMAAJ</li>
<li>Search Results - “Tamiya, Y.” :: Library Catalog, <a href="https://find.lib.uoc.gr/EDS/Search?lookfor=%22Tamiya,+Y.%22&amp;type=AU">https://find.lib.uoc.gr/EDS/Search?lookfor=%22Tamiya%2C+Y%2E%22&amp;type=AU</a></li>
<li>CIRA ’99 : 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation : proceedings : November 8-9, 1999, Monterey, California, USA, <a href="https://librarysearch.mbzuai.ac.ae/discovery/fulldisplay?docid=alma9933109909106&amp;context=L&amp;vid=971MBZUAI_INST:971MBZUAI_INST&amp;lang=en&amp;search_scope=MyInst_and_CI&amp;adaptor=Local+Search+Engine&amp;tab=LibraryCatalog&amp;query=creator,exact,IEEE+Robotics+and+Automation+Society.,AND&amp;facet=creator,exact,IEEE+Robotics+and+Automation+Society.&amp;mode=advanced&amp;offset=30">https://librarysearch.mbzuai.ac.ae/discovery/fulldisplay?docid=alma9933109909106&amp;context=L&amp;vid=971MBZUAI_INST:971MBZUAI_INST&amp;lang=en&amp;search_scope=MyInst_and_CI&amp;adaptor=Local%20Search%20Engine&amp;tab=LibraryCatalog&amp;query=creator%2Cexact%2CIEEE%20Robotics%20and%20Automation%20Society.%2CAND&amp;facet=creator%2Cexact%2CIEEE%20Robotics%20and%20Automation%20Society.&amp;mode=advanced&amp;offset=30</a></li>
<li>Vol. 20 No. 3: Fall 1999 | AI Magazine, https://ojs.aaai.org/aimagazine/index.php/aimagazine/issue/view/135</li>
<li>Probabilistic robotics | Request PDF - ResearchGate, https://www.researchgate.net/publication/220423943_Probabilistic_robotics</li>
<li>Probabilistic Robotics by Sebastian Thrun, Wolfram Burgard and Dieter Fox, MIT Press, 647 pp, ISBN 0-262-20162-3. | Request PDF - ResearchGate, https://www.researchgate.net/publication/220254260_Probabilistic_Robotics_by_Sebastian_Thrun_Wolfram_Burgard_and_Dieter_Fox_MIT_Press_647_pp_ISBN_0-262-20162-3</li>
<li>Handbook of Robotics, 2nd Edition Simultaneous Localization and Mapping, https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/springerbook-slamchapter.pdf</li>
<li>Probabilistic Robotics - Sebastian Thrun, Wolfram Burgard, Dieter Fox - Google Books, https://books.google.com/books/about/Probabilistic_Robotics.html?id=k_yOQgAACAAJ</li>
<li>Probabilistic robotics | Semantic Scholar, https://www.semanticscholar.org/paper/Probabilistic-robotics-Thrun/3f8d7bdfc3ed0ff793f1236730486b3d5cf946aa</li>
<li>Probabilistic Robotics - Homepages of UvA/FNWI staff, https://staff.fnwi.uva.nl/a.visser/education/ProbabilisticRobotics/ProbabilisticRoboticsOverview2018.pdf</li>
<li>EKF-SLAM hands-on tutorial - Jihong Ju, https://jihongju.github.io/2019/07/06/ekfslam-hands-on-tutorial/</li>
<li>Probabilistic Robotics, http://ais.informatik.uni-freiburg.de/teaching/ss15/robotics/slides/22-summary.pdf</li>
<li>From Bayes to Extended Kalman Filter - Cvut, https://people.ciirc.cvut.cz/~hlavac/TeachPresEn/55AutonomRobotics/2015-05-04ReinsteinBayes-ekf.pdf</li>
<li>Visual-Inertial SLAM using Extended Kalman Filter - Yunhai Han, https://y8han.github.io/doc/ECE276APR3.pdf</li>
<li>Probabilistic Robotics, http://ais.informatik.uni-freiburg.de/teaching/ws15/mapping/pdf/slam04-ekf.pdf</li>
<li>Probabilistic Robotics 0262201623, 9780262201629 - DOKUMEN.PUB, https://dokumen.pub/probabilistic-robotics-0262201623-9780262201629.html</li>
<li>thrun.seif.pdf, http://robots.stanford.edu/papers/thrun.seif.pdf</li>
<li>Sony Launches Four-Legged Entertainment Robot, https://www.sony.com/en/SonyInfo/News/Press/199905/99-046/</li>
<li>AIBO - Wikipedia, https://en.wikipedia.org/wiki/AIBO</li>
<li>It’ll soon be Aibo’s birthday! - Sony Support Community, https://ap.community.sony.com/s/question/0D5Dp00002PurZcKAJ/itll-soon-be-aibos-birthday?language=en_US</li>
<li>ERS-110 AIBO (Entertainment Robot) | Gallery | Sony Design, https://www.sony.com/en/SonyInfo/design/gallery/ERS-110/</li>
<li>Sony Launches Special Edition “AIBO” Entertainment Robot, https://www.sony.com/en/SonyInfo/News/Press/199910/99-076/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>