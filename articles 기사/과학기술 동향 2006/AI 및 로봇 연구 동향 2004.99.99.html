<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2004년 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2004년 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2006년 이전의 AI 및 로봇 연구 동향</a> / <span>2004년 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2004년 AI 및 로봇 연구 동향</h1>
<h2>1.  2004년 AI 및 로봇공학의 기술적 지형</h2>
<h3>1.1  시대적 배경: 통계적 패러다임의 확립</h3>
<p>2004년은 닷컴 버블 붕괴 이후 기술 분야가 재정비되던 시기로, 인공지능(AI) 연구는 화려한 수사보다는 내실 있는 기술적 성숙에 집중했다. 이 시기 AI의 주류는 명백히 통계적 기계학습(Statistical Machine Learning)이었으며, 이는 1990년대의 상징적(Symbolic) 접근법과 비교할 때 패러다임 전환이 완성되었음을 보여준다.1 2004년은 단 하나의 혁명적 돌파구가 있었던 해가 아니라, 1990년대 후반과 2000년대 초반의 주요 패러다임—통계적 학습, 커널 방법론, 그래픽 모델—이 제안되는 단계를 넘어 정제되고, 응용되며, 그 한계를 시험받던 심오한 ’공고화’의 시기였다. 이 과정에서 구축된 안정적이고 강력한 기술적 도구들은 AAAI 학회에서 볼 수 있는 응용 중심 연구와 급성장하는 대규모 컴퓨터 비전 분야의 발전을 가능하게 했다.</p>
<p>존 매카시(John McCarthy)와 같은 AI 선구자들은 여전히 인간 수준의 지능이라는 궁극적 목표를 상기시켰으나 2, 학계의 실질적인 연구는 측정 가능하고 재현 가능한 성능을 내는 수학적 모델에 집중되었다. 이러한 흐름은 AI가 점차 과학적 엄밀함을 갖춘 공학 분야로 자리 잡고 있었음을 방증한다.</p>
<h3>1.2  학문적 동향: 통합과 전문화의 공존</h3>
<p>학문적으로 2004년은 AI의 여러 측면을 아우르려는 시도와 특정 분야를 깊이 파고드는 전문화가 공존했다. 강화학습(Reinforcement Learning)과 같은 분야는 학습, 계획, 행동 등 지능의 여러 요소를 통합하려는 시도로서 주목받으며, 지능에 대한 통합적 이론을 찾으려는 학문적 열망을 반영했다.3</p>
<p>동시에, NeurIPS(당시 NIPS), ICML, ICRA 등 최상위 학회에서 발표되는 연구들은 고도로 전문화되어 있었다.5 이러한 빠른 기술 발전은 연구 중심 대학과 다른 교육 기관 간의 AI 교육 내용에 격차를 만들기도 했다. 한 조사에 따르면, 연구 중심이 아닌 기관에서는 상대적으로 오래된 주제에 더 많은 시간을 할애하는 경향이 나타났는데, 이는 최신 연구 동향이 학부 교육 과정에 반영되기까지 시간이 걸림을 시사한다.9</p>
<p>본 보고서는 이러한 시대적, 학문적 배경 속에서 2004년의 주요 학회들을 중심으로 AI와 로봇공학 분야의 핵심 연구 성과를 심층적으로 분석하고, 그 해의 연구가 현재 기술에 미친 영향을 조명하고자 한다.</p>
<h2>2.  기계학습 분야의 지평 확장: NIPS &amp; ICML 2004</h2>
<p>2004년의 기계학습 분야는 흥미로운 이중성을 보였다. 한편으로는 서포트 벡터 머신(SVM)으로 대표되는 기존 패러다임을 완성하려는 ‘활용(exploitation)’ 단계에 있었고, 다른 한편에서는 향후 10년을 정의할 새로운 영역을 조용히 ’탐색(exploration)’하고 있었다. 2004년은 한 시대의 정점이자 다음 시대의 조용한 새벽이었다.</p>
<h3>2.1  핵심 연구 동향: 커널 방법론의 정점과 구조적 예측의 부상</h3>
<h4>2.1.1  커널 헤게모니 (The Kernel Hegemony)</h4>
<p>2004년 기계학습 학회들은 서포트 벡터 머신(SVM)과 커널 방법론이 정점에 달했음을 명확히 보여준다. ICML 2004에서는 SVM 관련 주제가 다수 발표되었으며, 이는 다중 클래스 분류, 특징 선택, 다른 학습 방법과의 결합 등 다양한 측면에서 SVM을 확장하려는 노력이 활발했음을 의미한다.10 한 발표 자료는 2004년 ICML의 핵심 키워드로 ‘SVMs’, ’Kernel’을 꼽으며 당시의 지배적 패러다임을 압축적으로 보여준다.1 커널 방법론은 데이터를 고차원 특징 공간으로 매핑하여 비선형 문제를 선형적으로 해결하는 강력한 프레임워크를 제공했고, 이 시기 연구의 대부분은 이 패러다임을 더욱 정교하게 다듬는 데 집중되었다.</p>
<h4>2.1.2  구조적 출력 공간을 향하여 (Towards Structured Output Spaces)</h4>
<p>단순 분류 문제를 넘어, 시퀀스 데이터나 상호 의존적인 출력을 다루는 구조적 예측(structured prediction) 연구가 주목받았다. 특히 조건부 무작위장(Conditional Random Fields, CRFs)은 이러한 문제에 대한 강력한 확률 모델로 부상했다. ICML에서는 동적 CRF(Dynamic CRFs)나 커널 CRF(Kernel CRFs)와 같은 확장 모델이 발표되어, 시계열 데이터의 레이블링 및 분할 문제에 대한 정교한 접근법을 제시했다.10 이는 기계학습이 단순한 예측을 넘어, 자연어 처리나 컴퓨터 비전의 복잡한 출력 구조를 직접 모델링하는 방향으로 나아가고 있음을 보여주는 중요한 흐름이었다.</p>
<h3>2.2  주요 논문 심층 분석: 미래를 예견한 선구적 연구</h3>
<h4>2.2.1  Nathan Srebro 외, “Maximum-Margin Matrix Factorization”</h4>
<p>이 논문은 추천 시스템과 같은 협업 필터링(collaborative prediction) 문제에 대한 새로운 접근법을 제시한 선구적인 연구다.13</p>
<ul>
<li>
<p><strong>핵심 아이디어</strong>: 기존의 저계수(low-rank) 행렬 분해 대신, SVM의 최대 마진(maximum-margin) 원리를 차용하여 ’낮은 놈(low-norm)’을 갖는 행렬 분해를 제안했다. 이는 관측되지 않은 값을 예측하는 문제를 고차원 공간에서의 선형 분리 문제로 재해석한 것이다.14</p>
</li>
<li>
<p><strong>수학적 공식화</strong>: 이 접근법은 행렬 <span class="math math-inline">X</span>의 트레이스 놈(trace norm) <span class="math math-inline">kXk_*</span> (특이값들의 합)을 최소화하는 것을 목표로 하며, 이는 볼록 최적화 문제, 특히 준정부호 계획법(Semi-Definite Program, SDP)으로 공식화될 수 있다. 관측된 이진 레이블 <span class="math math-inline">Y \in \{\pm1\}</span>에 대한 소프트 마진 공식은 다음과 같이 표현된다 16:</p>
<p><span class="math math-display">
\min_{A, B, X, \xi} \frac{1}{2}(\text{tr}(A) + \text{tr}(B)) + C\sum_{(i,a)\in S} \xi_{ia} \\
\text{s.t.} \quad \begin{pmatrix} A &amp; X \\ X^T &amp; B \end{pmatrix} \succeq 0, \quad y_{ia}X_{ia} \ge 1-\xi_{ia}, \quad \xi_{ia} \ge 0
</span></p>
</li>
<li>
<p><strong>의의</strong>: 이 연구는 두 가지 중요한 흐름을 보여준다. 첫째, 기계학습의 성공적인 패러다임(최대 마진)을 새로운 문제 영역(행렬 완성)으로 확장했다. 둘째, 잠재 요인(latent factor) 모델링의 중요성을 부각시키며, 이후 넷플릭스 챌린지와 같은 대규모 추천 시스템 연구의 이론적 토대를 마련했다.17</p>
</li>
</ul>
<h4>2.2.2  Max Welling, Geoffrey Hinton 외, “Exponential Family Harmoniums with an Application to Information Retrieval”</h4>
<p>이 논문은 딥러닝 혁명의 전조로 평가받는 중요한 연구다.19</p>
<ul>
<li>
<p><strong>핵심 아이디어</strong>: 제한된 볼츠만 머신(Restricted Boltzmann Machine, RBM)의 한 형태인 ’Harmonium’이라는 에너지 기반 모델(Energy-Based Model)을 제시했다. 이는 관측 변수와 잠재 변수 간의 양방향 상호작용을 모델링하는 비지도 학습 방법으로, 데이터의 복잡한 분포를 학습할 수 있다.</p>
</li>
<li>
<p><strong>의의</strong>: 2006년 Hinton 교수가 제안하여 딥러닝의 부흥을 이끈 심층 신뢰 신경망(Deep Belief Networks, DBNs)의 핵심 구성 요소가 바로 RBM이다. 이 논문은 DBNs의 이론적, 구조적 토대를 마련한 연구로 평가된다. 당시 주류였던 판별 모델(discriminative model)과 커널 방법론의 그늘 아래서, 차세대 기계학습 패러다임이 될 생성 모델(generative model)과 비지도 특징 학습의 씨앗을 뿌리고 있었다는 점에서 그 역사적 중요성이 매우 크다.</p>
</li>
</ul>
<h2>3.  컴퓨터 비전의 도약: CVPR 2004</h2>
<p>2004년 컴퓨터 비전 분야의 주요 논문들은 과학적 진보에 내재된 근본적인 공생 관계를 드러낸다. 한편에서는 복잡한 시각 세계를 더 단순하고 구조화된 형태로 표현하려는 새로운 <em>모델링</em>의 전환이 있었고, 다른 한편에서는 강력하지만 다루기 어려웠던 기존 모델을 계산적으로 실용적이게 만드는 <em>알고리즘 최적화</em>의 걸작이 탄생했다. 이 두 축의 발전은 서로를 보완하며 분야 전체를 한 단계 도약시켰다.</p>
<h3>3.1  핵심 연구 동향: 실용성을 위한 효율적 추론과 확장성을 위한 특징 표현</h3>
<p>당시 컴퓨터 비전 분야는 마르코프 무작위장(Markov Random Field, MRF)과 같은 강력한 확률 모델을 스테레오 비전, 영상 복원 등 초기 비전(Early Vision) 문제에 적용하고 있었으나, 엄청난 계산 비용이 실용화의 발목을 잡고 있었다. 또한, 다양한 시점과 조명 변화에도 강인한 객체 인식을 위해 확장 가능한 특징 표현법이 절실히 요구되었다. 이러한 배경 속에서 CVPR 2004에서는 이 두 가지 핵심 난제를 해결하려는 획기적인 연구들이 발표되었다.</p>
<h3>3.2  주요 논문 심층 분석: 비전 연구의 패러다임을 바꾼 두 기둥</h3>
<h4>3.2.1  Pedro Felzenszwalb, Daniel Huttenlocher, “Efficient Belief Propagation for Early Vision”</h4>
<p>이 논문은 이론적으로 강력하지만 비현실적으로 느렸던 모델을 실용적으로 만든 대표적인 ‘가능 기술(enabling technology)’ 연구다.20</p>
<ul>
<li>
<p><strong>문제점</strong>: MRF 기반의 에너지 최소화 문제는 NP-hard이며, 이를 근사적으로 푸는 신뢰 전파(Belief Propagation, BP) 알고리즘은 각 픽셀이 가질 수 있는 레이블(예: 깊이값)의 수 <span class="math math-inline">k</span>에 대해 제곱(<span class="math math-inline">O(k^2)</span>)의 계산 복잡도를 가졌다. 이는 레이블 수가 많은 영상 복원이나 광학 흐름 문제에 BP를 적용하는 것을 거의 불가능하게 만들었다.21</p>
</li>
<li>
<p><strong>핵심 기여</strong>: 저자들은 거리 변환(distance transform)을 활용하여 메시지 전달 계산을 <span class="math math-inline">O(k)</span>로 줄이는 획기적인 알고리즘을 제안했다. 또한, 그리드 그래프에서의 메모리 사용량을 절반으로 줄이는 기법과, coarse-to-fine 방식으로 BP를 수행하여 적은 반복만으로도 좋은 결과를 얻게 하는 멀티그리드 기법을 도입했다. 이 기법들을 결합하여 알고리즘의 속도를 수백 배 향상시켰다.21</p>
</li>
<li>
<p><strong>의의</strong>: 이 연구 덕분에 MRF 기반의 정교한 모델들이 실시간에 가까운 성능을 낼 수 있게 되면서, 이후 컴퓨터 비전 분야에서 그래프 기반 최적화 기법이 널리 사용되는 계기를 마련했다. 강력한 모델이 효율적인 추론 알고리즘 없이는 이론적 호기심에 머물 수 있음을 보여주는 동시에, 알고리즘의 혁신이 어떻게 전체 연구 분야의 가능성을 확장하는지를 증명한 사례다.</p>
</li>
</ul>
<h4>3.2.2  Josef Sivic, Andrew Zisserman, “Video Data Mining Using Configurations of Viewpoint Invariant Regions”</h4>
<p>이 논문은 객체 인식 및 검색 분야에 텍스트 검색의 아이디어를 도입한 패러다임 전환적 연구다.20</p>
<ul>
<li>
<p><strong>핵심 아이디어</strong>: 객체 인식을 정보 검색(Information Retrieval) 문제로 재정의했다. 영상의 지역 특징(local feature)들을 ’시각적 단어(visual words)’로, 영상을 ’문서(document)’로 간주하는 ‘Bag of Visual Words (BoVW)’ 모델을 비디오 데이터에 적용했다.24 이는 객체의 완벽한 3D 모델링 대신, 통계적인 특징 분포로 객체를 표현하는 발상의 전환이었다.</p>
</li>
<li>
<p><strong>처리 과정</strong>:</p>
</li>
</ul>
<ol>
<li>
<p>영상에서 SIFT와 같은 시점 불변 특징점들을 추출한다.</p>
</li>
<li>
<p>추출된 특징 벡터들을 k-means와 같은 알고리즘으로 클러스터링하여 ’시각 단어 사전(visual vocabulary)’을 구축한다.</p>
</li>
<li>
<p>각 영상 프레임을 이 사전에 포함된 시각 단어들의 히스토그램(가방)으로 표현한다.</p>
</li>
<li>
<p>텍스트 검색에 사용되는 역파일(inverted file) 구조를 이용해 특정 객체(시각 단어들의 집합)가 포함된 영상을 빠르게 검색한다.25</p>
</li>
</ol>
<ul>
<li><strong>의의</strong>: 이 연구는 2003년 발표된 “Video Google“의 아이디어를 확장하여, 대규모 영상 데이터베이스에서 특정 객체를 효율적으로 검색하고 마이닝하는 길을 열었다.26 BoVW 접근법은 이후 약 8년간 객체 인식 및 영상 검색 분야의 표준 방법론으로 자리 잡으며, 딥러닝 이전 시대의 기술적 정점을 이루었다. 이는 복잡한 시각적 문제를 더 다루기 쉬운 형태로 추상화하는 모델링의 힘을 보여준 사례다.</li>
</ul>
<h2>4.  지능의 응용과 통합: AAAI 2004</h2>
<p>AAAI 2004의 핵심 주제는 ’의미론적 간극(semantic gap)’을 메우는 도전이었다. 즉, 원시적인 숫자 형태의 센서 데이터와 인간 수준의 의미 있는 개념 사이의 거대한 간극을 어떻게 연결할 것인가의 문제였다. 이 학회에서 발표된 연구들은 AI가 단순한 패턴 인식을 넘어, 인간의 행동과 의도라는 맥락 속에서 데이터를 <em>이해</em>하는 방향으로 나아가고 있음을 보여주었다.</p>
<h3>4.1  핵심 연구 동향: 실세계 문제 해결을 위한 AI 시스템</h3>
<p>AAAI 2004는 AI 기술이 실험실을 넘어 실제 세계의 복잡한 문제들을 해결하는 데 어떻게 사용될 수 있는지 보여주는 장이었다. 구글의 웹 검색 27, MIT 미디어랩의 웨어러블 컴퓨팅을 통한 대면 상호작용 분석 27, NASA의 우주 탐사 로봇 비전 27 등 산업계와 연구계의 거물들이 AI의 응용 사례를 발표했다. 특히 대테러 활동 식별, 지정학적 분쟁 시뮬레이션, 페타바이트급 과학 데이터 그리드 분석 등 국가적, 사회적 난제에 AI를 적용하려는 시도가 두드러졌다.27</p>
<p>이는 AI 연구의 초점이 개별 알고리즘의 성능 향상에서 벗어나, 여러 기술을 통합하여 복잡한 환경과 상호작용하는 지능형 ’시스템’을 구축하는 방향으로 이동하고 있음을 시사한다. AI가 ’무엇이 있는가?’를 넘어 ’이것이 무엇을 의미하는가?’라는 질문에 답하기 시작한 것이다.</p>
<h3>4.2  최우수 논문 심층 분석: Lin Liao, Dieter Fox, Henry Kautz, “Learning and Inferring Transportation Routines”</h3>
<p>이 논문은 AAAI 2004의 응용 지향적, 통합적 연구 경향을 가장 잘 보여주는 상징적인 성과다.28 이 연구는 GPS 점을 추적하는 것을 넘어, 그 점들이 의미하는 <em>목표</em>, <em>교통수단</em>, <em>일상</em>을 추론했다.</p>
<ul>
<li>
<p><strong>문제 정의</strong>: 인지 장애가 있는 사람을 돕는 것과 같은 실제 응용을 목표로, 사용자의 일상적인 이동 패턴을 잡음이 섞인 원본 GPS 데이터로부터 비지도 방식으로 학습하고 추론하는 시스템을 개발했다.29</p>
</li>
<li>
<p><strong>핵심 모델</strong>: 계층적 마르코프 모델, 구체적으로는 동적 베이지안 네트워크(Dynamic Bayesian Network)를 사용하여 문제를 모델링했다. 이 모델은 ’의미론적 간극’을 메우기 위해 명시적으로 설계된 다중 추상화 수준을 가진다 29:</p>
</li>
<li>
<p><strong>하위 레벨</strong>: 원본 GPS 센서 측정값을 처리하여 지도상의 위치와 속도를 추정한다.</p>
</li>
<li>
<p><strong>중간 레벨</strong>: 이동 구간(trip segment)과 교통수단(도보, 버스, 자동차)을 추론한다.</p>
</li>
<li>
<p><strong>상위 레벨</strong>: 사용자의 최종 목적지(집, 직장 등)와 같은 고수준의 ’의도’를 추론한다.</p>
</li>
<li>
<p><strong>추론 및 학습</strong>: 라오-블랙웰화 입자 필터(Rao-Blackwellised Particle Filter)라는 효율적인 추론 기법을 계층 구조의 여러 레벨에 적용했다. 중요한 점은 목적지나 환승 지점과 같은 의미 있는 장소들을 수동 레이블링 없이 데이터로부터 자동으로 학습한다는 것이다.29</p>
</li>
<li>
<p><strong>의의</strong>: 이 연구는 저수준의 센서 데이터와 고수준의 인간 행동 및 의도 사이의 거대한 간극을 확률 모델을 통해 어떻게 체계적으로 연결할 수 있는지를 보여준 기념비적인 작업이다. 이는 오늘날의 위치 기반 서비스, 개인화된 추천, 이상 행동 탐지 등 ‘상황 인지 컴퓨팅(Context-Aware Computing)’ 분야의 핵심 아이디어를 선도적으로 제시했다. 이 논문은 2004년 AI 연구의 지향점이 구문(syntax)에서 의미(semantics)로 이동하고 있었음을 명확히 보여준다.</p>
</li>
</ul>
<h2>5.  로봇공학의 현실과 미래: ICRA &amp; IROS 2004</h2>
<p>2004년 로봇공학 분야는 두 개의 다른 세계가 공존하며 발전하고 있었다. 하나는 성숙한 산업 자동화 시장이고, 다른 하나는 미지의 비정형 환경을 탐사하는 학문적 연구의 장이었다. 특히 학술 연구에서 제기된 도전 과제들은 컴퓨터 비전, 기계학습, 경로 계획, 인간-로봇 상호작용 등 AI의 여러 하위 분야들의 통합을 강력하게 요구하는 ‘강제 함수(forcing function)’ 역할을 했다. 로봇은 이론이 물리적 현실의 제약과 불확실성을 마주해야 하는 궁극적인 시험대였기 때문이다.</p>
<h3>5.1  시장 및 기술 동향: IFR/UNECE World Robotics 2004 서베이 분석</h3>
<ul>
<li>
<p><strong>산업 로봇의 폭발적 성장</strong>: 국제로봇연맹(IFR)과 유엔유럽경제위원회(UNECE)의 ‘World Robotics 2004’ 보고서에 따르면, 2003년 전 세계 산업용 로봇 투자는 19% 증가했으며, 2004년 상반기 수주는 아시아 시장의 57% 급증에 힘입어 사상 최고치를 기록했다.32 특히 자동차 산업에서는 일본, 독일, 이탈리아에서 생산직 근로자 10명당 1대 이상의 로봇이 사용될 정도로 자동화가 고도화되었다.</p>
</li>
<li>
<p><strong>서비스 로봇 시장의 태동</strong>: 가정용 청소 로봇과 잔디깎이 로봇이 약 61만 대 보급되었고, 향후 400만 대 이상 추가될 것으로 예측되었다. 의료, 수중 탐사, 감시 등 전문 서비스 로봇 시장도 형성되기 시작하며, 군사 분야 투자가 민간 시장으로의 기술 파급 효과를 낳을 것으로 전망되었다.32</p>
</li>
</ul>
<p>아래 표는 2003년 기준 주요 국가들의 산업 성숙도를 보여주는 로봇 밀도 지표를 요약한 것이다.</p>
<p><strong>2003년 주요 국가별 제조업 종사자 1만 명당 로봇 밀도</strong></p>
<table><thead><tr><th>국가 (Country)</th><th>로봇 밀도 (Robot Density)</th></tr></thead><tbody>
<tr><td>일본 (Japan)*</td><td>~320</td></tr>
<tr><td>독일 (Germany)</td><td>148</td></tr>
<tr><td>이탈리아 (Italy)</td><td>116</td></tr>
<tr><td>스웨덴 (Sweden)</td><td>99</td></tr>
<tr><td>핀란드, 스페인, 프랑스, 미국 등</td><td>50-80</td></tr>
<tr><td>영국 (United Kingdom)</td><td>~40</td></tr>
</tbody></table>
<p>*주: 일본 수치는 다목적 산업용 로봇 외 모든 유형을 포함하여 타 국가와 직접 비교 어려움. 32</p>
<h3>5.2  주요 연구 분야: 비정형 환경과 인간-로봇 상호작용을 향하여</h3>
<p>ICRA와 IROS 2004 학회에서는 공장과 같은 정형 환경을 벗어나, 예측 불가능하고 동적인 실제 환경에서 작동하는 로봇 기술이 집중적으로 연구되었다.33 이러한 연구들은 본질적으로 AI 기술의 통합을 요구했다.</p>
<ul>
<li>
<p><strong>자율 항법 및 탐사</strong>: 수중(AUV), 상공(헬리콥터, UAV), 험지 등 다양한 비정형 환경에서의 비전 기반 자율 항법 기술이 주요 연구 주제였다.33 ’시각적으로 증강된 항법(Visually Augmented Navigation)’과 같은 연구는 로봇공학과 컴퓨터 비전의 결합이 필수적임을 보여준다.33</p>
</li>
<li>
<p><strong>휴머노이드 로봇</strong>: 인간과 유사한 형태를 가진 로봇 연구가 활발했다. 7자유도 팔과 2자유도 허리를 가진 이족보행 로봇 개발, 감정 표현이 가능한 9자유도 팔, 플루트를 연주하는 로봇 등 인간의 움직임과 표현력을 모사하려는 연구들이 발표되었다.33</p>
</li>
<li>
<p><strong>다중 로봇 시스템과 센서 네트워크</strong>: 분산된 센서 네트워크를 활용하여 여러 로봇에게 작업을 할당하거나 33, 센서 노드의 효율적인 배치를 계획하는 등 33, 개별 로봇의 능력을 넘어서는 협력적 지능에 대한 연구가 이루어졌다.</p>
</li>
<li>
<p><strong>인간-로봇 상호작용(HRI)의 부상</strong>: ‘인간 참여형(human-in-the-loop)’ 제어 33, 인간 활동 모니터링 33을 넘어, 인간과 로봇 간의 ’관계 맺기(engagement)’라는 사회적 상호작용을 탐구하는 연구가 발표되었다.37 이는 로봇이 단순한 도구를 넘어 사회적 행위자가 될 가능성을 탐색하는 초기 단계의 중요한 연구였다.38 ’관찰을 통한 학습(Learning by Observation)’과 같은 연구는 로봇공학과 기계학습의 융합을 명확히 보여준다.33</p>
</li>
</ul>
<h2>6.  종합 및 결론: 2004년이 남긴 유산</h2>
<p>2004년은 AI와 로봇공학 역사에서 ’조용한 거인’과 같은 해였다. 폭발적인 혁명은 없었지만, 이후 10년을 지배할 패러다임이 공고화되고 다음 시대를 열 씨앗이 뿌려진 결정적인 시기였다.</p>
<ul>
<li>
<p><strong>통계적 학습의 완성</strong>: SVM과 커널 방법론은 그 정점에 도달하며 강력하고 성숙한 기술로서의 입지를 굳혔다. 이는 AI가 다양한 산업 분야에 실질적으로 기여할 수 있는 이론적, 실용적 토대를 제공했다.</p>
</li>
<li>
<p><strong>차세대 패러다임의 맹아</strong>: NIPS에서 발표된 Hinton의 에너지 기반 모델과 Srebro의 최대 마진 행렬 분해는 각각 딥러닝과 대규모 추천 시스템이라는 거대한 흐름의 시작을 알렸다. CVPR에서 제시된 Sivic과 Zisserman의 Bag of Visual Words 모델은 딥러닝 이전 시대의 컴퓨터 비전을 정의했다.</p>
</li>
<li>
<p><strong>지능의 시스템화</strong>: AAAI 최우수 논문으로 선정된 Liao, Fox, Kautz의 연구는 AI가 단순한 패턴 인식을 넘어, 저수준 센서 데이터로부터 복잡한 인간의 상황과 의도를 이해하는 통합 시스템으로 발전할 수 있음을 증명했다.</p>
</li>
<li>
<p><strong>로봇, 현실 세계로의 첫걸음</strong>: 산업계에서는 로봇이 경제의 핵심 동력으로 자리 잡았고, 학계에서는 비정형 환경에서의 자율성과 인간과의 사회적 상호작용이라는, 오늘날까지 이어지는 로봇공학의 핵심 과제에 대한 탐구가 본격화되었다.</p>
</li>
</ul>
<p>결론적으로 2004년은 AI와 로봇공학이 이전 시대의 이론적 성과를 집대성하여 강력한 기술적 ’현재’를 구축하는 동시에, 미래의 혁신을 이끌 ’미래’를 조용히 잉태하고 있었던 변곡점의 해로 기록될 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>AAAI - ICML’04, https://cdn.aaai.org/AAAI/2005/SC05-007.pdf</li>
<li>What is Artificial Intelligence - Formal Reasoning Group, https://www-formal.stanford.edu/jmc/whatisai.pdf</li>
<li>Reinforcement Learning as a Context for Integrating AI Research - AAAI, https://aaai.org/papers/0008-fs04-01-008-reinforcement-learning-as-a-context-for-integrating-ai-research/</li>
<li>Reinforcement Learning: A Survey | Journal of Artificial Intelligence Research, https://www.jair.org/index.php/jair/article/view/10166</li>
<li>https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2025.1586473/xml</li>
<li>AI Research Scientist, Robotics @ Facebook | Accel Job Board, https://jobs.accel.com/companies/facebook-2-07d2eb1b-d3ad-4084-93df-74a124ac9233/jobs/49807675-ai-research-scientist-robotics</li>
<li>Research Scientist Intern, Embodied AI (PhD) at Meta in Menlo Park, https://www.disabledperson.com/jobs/68008807-research-scientist-intern-embodied-ai-phd</li>
<li>International Conference on Robotics and Automation - Wikipedia, https://en.wikipedia.org/wiki/International_Conference_on_Robotics_and_Automation</li>
<li>The Pedagogy of Artificial Intelligence: A Survey of Faculty Who Teach Introductory AI - AAAI, https://aaai.org/papers/flairs-2004-017/</li>
<li>machinelearning.org - Proceedings ICML 2004, https://icml.cc/Conferences/2004/proceedings.html</li>
<li>
<ol start="21">
<li>ICML 2004: Banff, Alberta, Canada - ACM SigMod, http://www.sigmod.org/publications/dblp/db/conf/icml/icml2004.html</li>
</ol>
</li>
<li>Summary of ICML’04, https://icml.cc/Conferences/2004/summary.pdf</li>
<li>Advances in Neural Information Processing Systems 17: Proceedings of the - Google Livros, https://books.google.com.br/books?id=etp-l5VrbHsC&amp;hl=pt-BR&amp;source=gbs_navlinks_s</li>
<li>Maximum-Margin Matrix Factorization - NIPS, https://papers.nips.cc/paper/2655-maximum-margin-matrix-factorization</li>
<li>Maximum-margin Matrix Factorization - BibBase, https://bibbase.org/network/publication/srebro-rennie-jaakkola-maximummarginmatrixfactorization-2004</li>
<li>(PDF) Maximum-Margin Matrix Factorization. - ResearchGate, https://www.researchgate.net/publication/221619685_Maximum-Margin_Matrix_Factorization</li>
<li>Maximum Margin Matrix Factorization - TTIC, https://home.ttic.edu/~nati/mmmf/</li>
<li>[PDF] Maximum-Margin Matrix Factorization - Semantic Scholar, https://www.semanticscholar.org/paper/Maximum-Margin-Matrix-Factorization-Srebro-Rennie/cedf154c28178370d95510112413dc8cb48120a8</li>
<li>Advances in Neural Information Processing Systems 17 (NIPS 2004), https://proceedings.neurips.cc/paper/2004</li>
<li>Computer Vision and Pattern Recognition 2004, http://www.sigmod.org/publications/dblp/db/conf/cvpr/cvpr2004-1.html</li>
<li>Efficient Belief Propagation for Early Vision - CS@Cornell, https://www.cs.cornell.edu/~dph/papers/bp-ijcv.pdf</li>
<li>Efficient Belief Propagation for Early Vision - CS@Cornell, https://www.cs.cornell.edu/~dph/papers/bp-cvpr.pdf</li>
<li>[PDF] Efficient Belief Propagation for Early Vision - Semantic Scholar, https://www.semanticscholar.org/paper/Efficient-Belief-Propagation-for-Early-Vision-Felzenszwalb-Huttenlocher/b3197ff5aa8f9cd36f98bcc8762b96250bdb4168</li>
<li>Video data mining using configurations of viewpoint invariant regions - SciSpace, https://scispace.com/papers/video-data-mining-using-configurations-of-viewpoint-50yvhpnbxh</li>
<li>Video Data Mining Using Configurations of Viewpoint Invariant Regions - GMU CS Department, https://cs.gmu.edu/~zduric/cs774/Papers/Sivic2.pdf</li>
<li>Video Google: a text retrieval approach to object matching in videos - Semantic Scholar, https://www.semanticscholar.org/paper/Video-Google%3A-a-text-retrieval-approach-to-object-Sivic-Zisserman/642e328cae81c5adb30069b680cf60ba6b475153</li>
<li>The 2004 National Conference on AI - AAAI Publications, https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/1787/1685</li>
<li>AAAI-04:Nineteenth National Conference on Artificial Intelligence …, https://aaai.org/conference/aaai/aaai04/</li>
<li>Learning and Inferring Transportation Routines - The Association for the Advancement of Artificial Intelligence, https://cdn.aaai.org/AAAI/2004/AAAI04-056.pdf</li>
<li>Learning and Inferring Transportation Routines - UW Robotics and State Estimation Lab, https://rse-lab.cs.washington.edu/papers/transportation-routines-aij-07.pdf</li>
<li>Learning and Inferring Transportation Routines - AAAI, https://auld.aaai.org/Library/AAAI/2004/aaai04-056.php</li>
<li>IFR/UNECE 2004 World Robotics survey | Industrial Robot | Emerald …, https://www.emerald.com/ir/article/186740/IFR-UNECE-2004-World-Robotics-survey</li>
<li>Proceedings of the 2004 IEEE International Conference on Robotics and Automation, ICRA 2004, April 26 - May 1, 2004, New Orleans, LA, USA - Researchr, https://researchr.org/publication/icra%3A2004</li>
<li>ICRA 2004 Accepted Paper List - Paper Copilot, https://papercopilot.com/paper-list/icra-paper-list/icra-2004-paper-list/</li>
<li>ICRA 2004 - dblp, https://dblp.org/db/conf/icra/icra2004-4</li>
<li>IROS 2004 Accepted Paper List, https://papercopilot.com/paper-list/iros-paper-list/iros-2004-paper-list/</li>
<li>September 30, 2004 12:48 WSPC/INSTRUCTION FILE journal EXPLORATIONS IN ENGAGEMENT FOR HUMANS AND ROBOTS - LIRA-Lab, http://www.liralab.it/teaching/SINA_08-09/SINA_PREV/library/HUMANOIDS2004/paper/11_paper.pdf</li>
<li>Building Trust in Social Robotics: A Pilot Survey | Request PDF - ResearchGate, https://www.researchgate.net/publication/337775803_Building_Trust_in_Social_Robotics_A_Pilot_Survey</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>