<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2022년 1월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2022년 1월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2022년 AI 및 로봇 연구 동향</a> / <span>2022년 1월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2022년 1월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론</h2>
<p>2022년 1월은 인공지능과 로봇 공학 분야에서 단순한 점진적 발전을 넘어, 이후의 기술 지형을 근본적으로 바꿀 패러다임 전환의 신호탄을 쏘아 올린 결정적 시기였다. 이 시기의 연구들은 거대 언어 모델(LLM)이 단순한 언어 생성기를 넘어 복잡한 ’추론’의 영역으로 진입할 수 있음을 증명했고 1, 대화형 AI의 개발 목표가 성능을 넘어 ’안전’과 ’사실 기반’으로 성숙해야 함을 역설했다.3 컴퓨터 비전 분야에서는 트랜스포머 아키텍처의 절대적 우위에 의문을 제기하며 컨볼루션 신경망(CNN)의 잠재력을 재조명하는 연구가 등장했으며 5, 생성 모델의 패러다임이 확산 모델(Diffusion Models)로 넘어가고 있음을 명확히 보여주었다.7 또한, 딥러닝의 ’일반화’라는 근본적인 미스터리에 대한 새로운 단서를 제공하는 현상이 보고되었다.9 로봇 공학에서는 소프트 로보틱스가 개념적 탐구를 넘어 실제적 응용과 정밀 제어의 단계로 진입하고 있음을 보여주는 종합적인 연구들이 발표되었다.11 본 보고서는 이처럼 각 분야에서 나타난 변곡점들을 심층적으로 분석하여, 2022년 1월이 어떻게 미래 AI와 로봇 공학의 청사진을 제시했는지 명확히 밝힌다.</p>
<h2>2.  인공지능(AI) 분야 주요 연구 동향</h2>
<h3>2.1  대규모 언어 모델의 추론 능력 잠금 해제: 사고의 연쇄(Chain-of-Thought)</h3>
<p><code>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</code>는 Jason Wei 등이 발표한 논문으로, LLM 연구의 흐름을 바꾼 기념비적인 성과로 평가받는다.2 이 연구는 단순히 질문에 대한 답을 제시하는 기존의 프롬프팅 방식(Standard Prompting)을 넘어, 문제 해결 과정을 단계별로 서술하는 ‘사고의 연쇄(Chain of Thought, CoT)’ 예시를 몇 개 제공하는 것만으로도 LLM의 복잡한 추론 능력이 극적으로 향상될 수 있음을 입증했다.1 이는 모델의 가중치를 변경하는 파인튜닝 없이, 프롬프팅 기법만으로 모델의 잠재된 능력을 이끌어낼 수 있다는 새로운 가능성을 제시한 것이다.2</p>
<p>방법론의 핵심 아이디어는 인간이 복잡한 문제를 풀 때 중간 단계를 거치는 것과 같이, 모델에게도 중간 추론 과정을 생성하도록 유도하는 데 있다.1 프롬프트는 <code>&lt;입력, 사고의 연쇄, 출력&gt;</code> 형태의 예시(exemplar)로 구성된다.2 이 접근법은 여러 장점을 가진다. 첫째, 다단계 문제를 중간 단계로 분해하여 더 많은 연산을 할당할 수 있게 한다(분해). 둘째, 모델이 어떻게 답에 도달했는지 추론 과정을 보여주어 디버깅 기회를 제공한다(해석 가능성). 셋째, 수학, 상식, 기호 추론 등 인간이 언어로 풀 수 있는 모든 문제에 원칙적으로 적용 가능하다(범용성). 마지막으로, 충분히 큰 규모의 기성 언어 모델에서 CoT 예시를 프롬프트에 포함하는 것만으로 쉽게 유도할 수 있다(즉시성).2</p>
<p>실험 결과는 매우 인상적이었다. 특히 GSM8K 수학 문제 벤치마크에서 540B 파라미터 PaLM 모델에 CoT를 적용했을 때, 기존의 최고 성능(State-of-the-Art, SOTA)을 뛰어넘는 결과를 달성하며 그 효과를 극명하게 보여주었다.2 흥미로운 점은 CoT가 모델의 크기가 특정 임계점(예: 100B 파라미터)을 넘어서야 효과가 나타나는 ’창발적 능력(Emergent Abilities)’의 일종이라는 점이다.14 이는 모델 스케일링이 단순히 성능을 양적으로 높이는 것을 넘어, 질적으로 새로운 능력을 발현시킨다는 중요한 증거가 되었다.</p>
<p>CoT의 발견은 LLM을 단순한 ’지식 압축기’나 ’패턴 매칭기’로 보던 관점에서, ’동적 추론기(Dynamic Reasoner)’로의 패러다임 전환을 촉발했다. 이는 AI의 능력을 평가하는 기준을 ’무엇을 아는가’에서 ’어떻게 생각하는가’로 바꾸는 계기가 되었다. 기존에는 LLM을 입력-출력 쌍을 매핑하는 블랙박스로 간주하고, 성능 향상을 위해 모델 크기, 데이터 양, 파인튜닝에 의존했다. 하지만 CoT 연구는 프롬프트에 추론 과정을 보여주는 것만으로 모델이 스스로 복잡한 문제를 단계별로 풀기 시작하는, 학습되지 않은 새로운 행동 양식을 관찰했다.1 CoT 프롬프트는 모델에게 단순히 ’정답’을 맞추는 것이 아니라 ’과정’을 모방하도록 하는 메타-학습(meta-learning) 신호로 작용한 것이다. 모델은 주어진 예시의 ’형식(format)’을 학습하여, 새로운 문제에 대해서도 유사한 형식의 단계적 추론을 생성하려 시도한다. 이로 인해 LLM 연구는 ’어떻게 더 나은 프롬프트를 설계할 것인가’라는 프롬프트 엔지니어링 분야를 탄생시켰고, 이후 Self-Consistency 13, Chain of Draft 15, Auto-CoT 13 등 수많은 후속 연구를 촉발하며 LLM 추론 기술의 핵심 기반이 되었다.</p>
<h3>2.2  대화형 AI의 새로운 지평: LaMDA</h3>
<p>구글이 발표한 <code>LaMDA: Language Models for Dialog Applications</code>는 대화에 특화된 137B 파라미터의 거대 언어 모델이다.3 LaMDA는 단순히 유창한 대화를 넘어, 대화형 AI가 갖춰야 할 핵심 가치로 **품질(Quality), 안전성(Safety), 사실 기반 응답(Groundedness)**이라는 세 가지 축을 명확히 제시했다는 점에서 중요한 의의를 가진다.4</p>
<p>LaMDA의 방법론은 1.56T 단어에 달하는 방대한 공개 대화 데이터와 웹 텍스트로 사전 훈련하는 것에서 시작된다.3 이는 이전 모델인 Meena보다 약 40배 큰 규모이다.3 품질 평가를 위해 기존의 ’합리성(Sensibleness)’과 ’구체성(Specificity)’에 더해 ’흥미로움(Interestingness, SSI)’이라는 지표를 도입하여 다차원적인 평가를 시도했다.4 안전성 확보를 위해서는 유해한 제안이나 불공정한 편견을 방지하고자 인간의 가치에 기반한 안전 목표를 설정하고, 크라우드소싱으로 수집된 데이터로 파인튜닝된 분류기를 통해 유해한 응답을 필터링했다.3 또한, 모델이 그럴듯한 거짓말을 하는 경향(hallucination)을 줄이기 위해, 정보 검색 시스템, 계산기, 번역기와 같은 외부 지식 소스를 참조하도록 훈련하여 생성된 응답이 검증 가능한 출처에 기반하도록 유도했다.4</p>
<p>주요 결과는 모델 스케일링만으로는 품질은 향상되지만, 안전성과 사실 기반 응답 능력은 인간 수준에 크게 미치지 못한다는 점을 보여주었다.4 반면, 파인튜닝과 외부 도구 활용을 결합했을 때, 모든 지표에서 성능이 크게 향상되었다. 이는 AI 개발에서 무조건적인 스케일링보다 목적 지향적인 파인튜닝과 외부 시스템과의 연동이 중요함을 시사한다.4</p>
<p>LaMDA의 연구 방향은 LLM 개발 커뮤니티에 ’성능의 추구’에서 ’책임 있는 개발’로의 전환을 촉구하는 중요한 철학적 이정표를 제시했다. 2022년 이전까지 LLM 경쟁은 주로 파라미터 수와 벤치마크 점수로 대표되는 ‘성능(capability)’ 중심이었다. 편향, 유해성, 허위 정보와 같은 부작용은 해결해야 할 문제였지만, 개발의 핵심 목표는 아니었다. LaMDA는 ’안전성’과 ’사실 기반’을 모델의 핵심 평가 지표(key metrics)로 전면에 내세우며, 이를 기술적 성능 지표와 동등한 위상으로 격상시켰다.4 이러한 변화는 구글과 같은 대규모 조직이 LLM을 실제 제품(예: 대화형 검색, 어시스턴트)에 적용하기 시작하면서, 학술적 성능을 넘어 실제 사용자가 겪게 될 위험(risk)을 관리해야 할 필요성이 커졌기 때문에 발생했다. 즉, 상용화의 압박이 연구개발의 우선순위를 ’성능’에서 ’신뢰성’과 ’안전성’으로 이동시킨 것이다. LaMDA의 이러한 접근 방식은 이후 등장한 InstructGPT/ChatGPT의 RLHF(인간 피드백 기반 강화학습)와 같은 ‘AI 정렬(AI Alignment)’ 연구의 중요성을 부각시키는 계기가 되었다.14</p>
<h3>2.3  컨볼루션 신경망의 재발견: ConvNeXt</h3>
<p><code>A ConvNet for the 2020s</code>는 Vision Transformer(ViT)가 컴퓨터 비전 분야를 지배하기 시작한 시점에, 전통적인 컨볼루션 신경망(CNN)의 잠재력을 다시 한번 증명한 중요한 연구다.16 저자들은 표준 ResNet 아키텍처에 ViT, 특히 Swin Transformer의 설계 원칙과 훈련 기법들을 점진적으로 적용하여, 어텐션 메커니즘 없이 순수 CNN만으로 Swin Transformer를 능가하는 성능을 달성한 ’ConvNeXt’를 제안했다.5</p>
<p>“현대화” 과정은 체계적인 실험을 통해 진행되었다. 첫째, 300 에포크 훈련, AdamW 옵티마이저, Mixup, Cutmix, RandAugment 등 최신 데이터 증강 및 정규화 기법을 적용하는 것만으로 ResNet-50의 성능이 76.1%에서 78.8%로 크게 향상됨을 보여주었다.21 이후 Swin-T와 유사하게 스테이지별 연산 비율 조정, 스템(stem) 구조 변경, 그룹 컨볼루션(ResNeXt-ify) 도입, 역병목(Inverted Bottleneck) 구조 적용, 깊이별 컨볼루션(depthwise convolution)의 커널 크기를 7x7로 확장, 그리고 활성화 함수(GELU) 및 정규화 층(LayerNorm) 변경 등 세부적인 마이크로 디자인 조정을 순차적으로 가했다.21</p>
<p>그 결과, ConvNeXt는 ImageNet-1K 분류에서 87.8%의 top-1 정확도를 달성했으며, COCO 객체 탐지 및 ADE20K 시맨틱 분할에서도 Swin Transformer를 능가하는 성능을 보였다.5 이는 ViT의 성공이 어텐션 메커니즘 자체의 우월성 때문만이 아니라, 함께 도입된 아키텍처 설계 원칙과 훈련 기법의 영향이 매우 컸음을 시사한다.21</p>
<table><thead><tr><th>모델</th><th>사전 훈련</th><th>입력 크기</th><th>ImageNet-1K Top-1 Acc. (%)</th><th>COCO Box AP (val)</th><th>ADE20K mIoU (val)</th></tr></thead><tbody>
<tr><td>Swin-T</td><td>ImageNet-1K</td><td>2242</td><td>81.3</td><td>51.8</td><td>46.1</td></tr>
<tr><td>ConvNeXt-T</td><td>ImageNet-1K</td><td>2242</td><td>82.1</td><td>52.5</td><td>46.7</td></tr>
<tr><td>Swin-B</td><td>ImageNet-22K</td><td>2242</td><td>86.4</td><td>56.1</td><td>51.9</td></tr>
<tr><td>ConvNeXt-B</td><td>ImageNet-22K</td><td>2242</td><td>86.8</td><td>56.4</td><td>52.3</td></tr>
<tr><td>Swin-L</td><td>ImageNet-22K</td><td>2242</td><td>87.3</td><td>56.3</td><td>53.5</td></tr>
<tr><td>ConvNeXt-L</td><td>ImageNet-22K</td><td>2242</td><td>87.5</td><td>56.5</td><td>53.7</td></tr>
<tr><td></td><td></td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<p>표 1: ConvNeXt와 Swin Transformer 성능 비교. ConvNeXt는 다양한 모델 크기와 평가 지표에서 Swin Transformer와 대등하거나 더 나은 성능을 보여주었다. 데이터는 5에서 재구성되었다.</p>
<p>ConvNeXt는 ’아키텍처’와 ’훈련법’의 기여도를 분리하여 분석함으로써, 커뮤니티의 시선을 ’어떤 아키텍처가 최고인가’라는 질문에서 ’성공적인 아키텍처의 공통 원리는 무엇인가’라는 더 근본적인 질문으로 이동시켰다. 2021년 ViT의 등장 이후, 컴퓨터 비전 커뮤니티는 CNN의 시대가 끝나고 트랜스포머의 시대가 왔다는 인식이 팽배했다. ConvNeXt 연구진은 ViT의 성공 요인을 ’어텐션’이라는 단일 요소로 보지 않고, 훈련법, 매크로/마이크로 디자인 등 여러 요소로 분해했다.21 그리고 이 요소들을 CNN에 이식하자 CNN의 성능이 ViT를 넘어섰다.5 이는 ViT의 성능 향상이 ’어텐션’이라는 새로운 연산 자체의 마법이 아니라, 대규모 데이터셋에 더 효과적인 ’훈련 레시피’와 ‘계층적 설계’, ’더 큰 수용장(receptive field)’과 같은 보편적인 설계 원칙 덕분이었음을 의미한다. 이 연구는 아키텍처 간의 경계를 허물고 하이브리드 설계의 가능성을 열었으며, 특정 아키텍처에 대한 맹신을 경계하고 성공의 근본 원리를 탐구하는 과학적 접근법의 중요성을 상기시킨 사례다.</p>
<h3>2.4  확산 모델의 응용: RePaint를 통한 이미지 인페인팅</h3>
<p><code>RePaint: Inpainting using Denoising Diffusion Probabilistic Models</code>는 이미지 생성 분야에서 GAN의 대안으로 급부상하던 확산 모델(DDPM)을 이미지 인페인팅 문제에 독창적으로 적용한 연구다.7 핵심은 인페인팅 작업을 위해 모델을 별도로 훈련시키지 않고, 사전 훈련된</p>
<p><strong>비조건부(unconditional)</strong> DDPM을 그대로 활용한다는 점이다.8</p>
<p>핵심 방법론은 조건화된 샘플링에 있다. 일반적인 DDPM이 노이즈로부터 이미지를 생성하는 반면, RePaint는 역확산 과정(denoising process)의 각 단계에서 알려진 영역(마스크 밖)의 픽셀을 원본 이미지의 픽셀로 강제 대체한다.7 단순히 알려진 픽셀을 고정하는 것만으로는 생성된 부분과 기존 부분의 조화가 깨질 수 있는데, 이를 해결하기 위해 RePaint는 확산 과정의 시간을 앞뒤로 오가는(forward and backward) 독특한 리샘플링 전략을 제안한다. 즉, 몇 단계 노이즈를 제거한 후 다시 약간의 노이즈를 추가하는 과정을 반복함으로써, 생성되는 부분과 주변부의 조화를 점진적으로 맞춰나간다.7 이 접근법 덕분에 모델 자체가 특정 마스크 분포에 대해 훈련되지 않았음에도, 사각형, 자유형태, 심지어 이미지의 대부분이 가려진 극단적인 마스크 등 어떤 형태의 마스크에도 뛰어난 일반화 성능을 보인다.8</p>
<p>실험 결과, RePaint는 얼굴 및 일반 이미지 인페인팅 태스크에서 기존의 GAN 및 자기회귀(Autoregressive) 모델 기반 SOTA 방법론들을 6개 중 5개의 마스크 분포에서 능가했다.7 이는 확산 모델이 강력한 생성적 사전 지식(generative prior)을 학습하며, 이를 통해 별도의 훈련 없이도 다양한 조건부 생성 태스크에 유연하게 적용될 수 있음을 보여주었다.</p>
<table><thead><tr><th>마스크 유형</th><th>방법론</th><th>LPIPS (↓)</th><th>FID (↓)</th></tr></thead><tbody>
<tr><td><strong>Wide</strong></td><td>LaMa</td><td>0.28</td><td>6.81</td></tr>
<tr><td></td><td><strong>RePaint</strong></td><td><strong>0.25</strong></td><td><strong>6.45</strong></td></tr>
<tr><td><strong>Narrow</strong></td><td>LaMa</td><td>0.16</td><td>3.52</td></tr>
<tr><td></td><td><strong>RePaint</strong></td><td><strong>0.12</strong></td><td><strong>2.61</strong></td></tr>
<tr><td><strong>Half</strong></td><td>LaMa</td><td>0.51</td><td>16.52</td></tr>
<tr><td></td><td><strong>RePaint</strong></td><td><strong>0.46</strong></td><td><strong>15.20</strong></td></tr>
<tr><td></td><td></td><td></td><td></td></tr>
</tbody></table>
<p>표 2: RePaint와 LaMa(GAN 기반 SOTA)의 성능 비교 (CelebA-HQ 데이터셋). RePaint는 다양한 마스크 유형에서 더 낮은 LPIPS와 FID 점수를 기록하며 우수성을 입증했다. 데이터는 7에서 재구성되었다.</p>
<p>RePaint의 접근법은 생성 모델의 활용 패러다임을 ’하나의 태스크를 위한 하나의 모델 훈련’에서 ’강력한 범용 생성 모델을 다양한 태스크에 적응시키는 기술’로 전환하는 중요한 사례다. 기존의 조건부 이미지 생성은 주로 조건(마스크된 이미지)을 입력으로 받아 결과를 출력하도록 모델(주로 GAN)을 처음부터 훈련시키는 방식이었다. RePaint는 이미 이미지 분포에 대한 완벽한 지식을 가진 비조건부 DDPM을 ’엔진’으로 사용하고, 샘플링 과정에 ’제약 조건’을 가하는 방식으로 문제를 풀었다.7 DDPM의 점진적 노이즈 제거 과정은 각 단계에서 중간 결과물을 수정할 수 있는 기회를 제공하는데, RePaint는 이 기회를 활용하여 매 단계마다 ’알려진 사실(원본 픽셀)’을 주입함으로써 생성 과정 전체를 원하는 방향으로 유도할 수 있었다. 이 ‘사전 훈련된 생성 모델 + 샘플링 시점 제어’ 패러다임은 이후 텍스트-이미지 생성(예: classifier-free guidance), 이미지 편집(InstructPix2Pix) 등 확산 모델 기반의 수많은 응용 기술들의 핵심 원리가 되었다.</p>
<h3>2.5  일반화에 대한 새로운 통찰: 그로킹(Grokking) 현상</h3>
<p>OpenAI 연구진이 발표한 <code>Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets</code>는 딥러닝의 일반화에 대한 기존 상식을 뒤흔드는 ‘그로킹’ 현상을 발견하고 명명한 논문이다.9 그로킹은 모델이 훈련 데이터에 거의 완벽하게 오버피팅된 후에도 훈련을 계속하면, 어느 순간 검증 정확도가 갑자기 급상승하여 완벽한 일반화에 도달하는 현상을 말한다.10</p>
<p>실험은 모듈러 연산(x∘y=x/y(mod97))과 같은 알고리즘적으로 생성된 작은 데이터셋을 사용하여 설계되었다. 이 데이터셋은 모델이 단순히 데이터를 암기하는 것이 아니라, 기저의 규칙을 학습해야만 일반화할 수 있도록 만들어졌다.25 실험 결과, 훈련 정확도는 수천 스텝 내에 100%에 도달했지만, 검증 정확도는 수십만 스텝 동안 변화가 없다가 갑자기 치솟는 현상이 뚜렷하게 관찰되었다.26 또한 훈련 데이터의 크기가 작을수록, 그로킹이 일어나기까지 필요한 훈련 스텝 수가 기하급수적으로 증가했으며, 가중치 감쇠(Weight Decay)와 같은 정규화 기법이 그로킹을 촉진하는 데 매우 효과적임을 발견했다.25</p>
<p>그로킹 현상은 딥러닝에서 ’암기(memorization)’와 ’일반화(generalization)’가 완전히 분리된 단계로, 시간차를 두고 일어날 수 있음을 보여주었다. 이는 모델이 훈련 데이터에 대한 ’단순한 해법(암기)’을 먼저 찾은 후, 계속되는 최적화 과정을 통해 더 ’효율적이고 일반적인 해법(규칙 학습)’으로 전환하는 일종의 상전이(phase transition) 현상일 수 있음을 시사한다.9</p>
<p>이 발견은 딥러닝 최적화 과정을 단순히 손실 함수의 최솟값을 찾아가는 과정으로 보는 것을 넘어, 솔루션의 ‘구조(structure)’ 또는 ’복잡도(complexity)’가 변화하는 동적인 과정으로 이해해야 함을 시사한다. 전통적인 머신러닝 관점에서 오버피팅은 훈련을 중단해야 할 신호로 여겨졌지만, 그로킹 현상은 검증 손실이 최악인 상태에서 훈련을 멈추지 않고 계속했을 때, 오히려 더 나은 일반화 성능을 얻을 수 있음을 보여주었다.25 이는 신경망의 손실 함수 공간에 동일한 훈련 손실을 갖지만 일반화 성능이 다른 여러 최솟값(minima)들이 존재함을 암시한다. 초기 단계에서 옵티마이저는 훈련 데이터를 암기하는 ‘뾰족하고 복잡한’ 최솟값에 빠르게 도달한다. 하지만 가중치 감쇠와 같은 정규화 압력 하에 장시간 최적화를 계속하면, 모델은 점차 더 ‘평탄하고 단순한(규칙에 기반한)’ 최솟값으로 이동하게 되고, 이 전환이 ’그로킹’으로 나타나는 것이다. 그로킹은 ‘이중 하강(Double Descent)’ 현상과 함께, 과대 매개변수화된 모델의 일반화 미스터리를 푸는 중요한 열쇠를 제공한다.</p>
<h2>3.  로봇 공학(Robotics) 분야 주요 연구 동향</h2>
<h3>3.1  소프트 로보틱스 기술 동향 종합 분석</h3>
<p><code>Soft, Wearable Robotics and Haptics: Technologies, Trends, and Emerging Applications</code>는 2022년 1월 IEEE에 발표된 리뷰 논문으로, 당시 급성장하던 소프트 로보틱스 분야의 기술 현황과 미래를 종합적으로 조망했다.11 이 논문은 소프트 로보틱스가 인간과 밀접하게 상호작용하는 웨어러블 기기, 보조 로봇, 생체 의료 분야에서 특히 큰 잠재력을 가지고 있음을 강조했다.11</p>
<p>논문은 소프트 로보틱스의 핵심 기술 요소를 체계적으로 분석했다. 재료 측면에서는 실리콘, 폴리우레탄, 하이드로겔과 같은 고분자 재료가 높은 유연성과 내구성으로 인해 주로 사용된다고 언급했다.30 구동 방식으로는 공압/유압 액추에이터, 힘줄 구동 시스템(Tendon-driven), 유전 탄성체(Dielectric elastomers), 형상기억합금(SMA) 등 다양한 기술의 장단점과 적용 사례를 분석했다.30 또한, 인간의 피부처럼 부드럽고 촉각에 민감한 센서 개발과 비선형적이고 변형이 심한 소프트 로봇의 동역학을 모델링하고 제어하는 것이 핵심적인 기술적 과제임을 지적했다.11 주요 응용 분야로는 뇌졸중 환자를 위한 로봇 장갑과 같은 재활 및 보조 장치 28, 사용자에게 상황에 맞는 촉각 피드백을 제공하는 웨어러블 햅틱 인터페이스 등을 제시하며 11, 미래에는 의류처럼 일상 생활에 완벽하게 통합될 것으로 예측했다.28</p>
<p>이 리뷰 논문은 소프트 로보틱스가 ’기이한 로봇’을 만드는 단계를 지나, 인간의 삶의 질을 직접적으로 향상시키는 ’인간 중심 기술’로 성숙하고 있음을 보여준다. 초기 소프트 로보틱스는 문어, 애벌레 등 생명체를 모방한 독특한 형태와 움직임에 초점이 맞춰져 있었다. 하지만 이 리뷰 논문은 ‘웨어러블’, ‘햅틱’, ‘생체 의료’ 등 구체적이고 실용적인 응용 분야를 중심으로 기술을 분류하고 있다.11 이는 연구의 초점이 ’어떻게 만드는가’에서 ’어디에 쓸 것인가’로 이동했음을 보여준다. 소프트 로봇의 본질적인 특성인 유연성, 순응성, 안전성은 기존의 단단한(rigid) 로봇이 접근하기 어려웠던 ’인간 신체와의 직접적인 접촉’을 요구하는 응용 분야에 완벽하게 부합한다. 이는 로봇 공학의 패러다임이 ’인간과 분리된 작업 수행’에서 ’인간과의 공존 및 협력’으로 변화하고 있음을 보여주는 거시적인 증거다.</p>
<h3>3.2  생체모방 로봇 공학의 발전: 기린 목 로봇</h3>
<p><code>Giraffe Neck Robot: First Step Toward a Powerful and Flexible Robot Prototyping Based on Giraffe Anatomy</code>는 기린 목의 해부학적 구조를 모방하여 ’힘’과 ’유연성’이라는 상충되는 특성을 동시에 구현하려는 생체모방 로봇 연구다.29 이 연구는 재난 현장이나 임업과 같이 강력한 힘과 함께 환경 적응성이 요구되는 분야를 위한 새로운 로봇 메커니즘을 제안한다.31</p>
<p>설계는 로봇 공학자와 동물 해부학자의 협력을 통해 실제 기린 목의 근골격 구조를 분석하고 이를 로봇에 반영하는 방식으로 이루어졌다.31 구동 방식으로는 가늘고 유연한 ’멕키번 공압 인공 근육(thin McKibben pneumatic artificial muscles)’을 사용했으며, 인장 고무를 이용한 중력 보상 메커니즘으로 기린의 목덜미 인대(nuchal ligaments)를 모사하여 구조적 안정성을 확보했다.31 제작된 프로토타입은 실험을 통해 근육과 인대 간의 협응을 성공적으로 재현했으며, 외부 힘이 가해졌을 때 충격을 흡수하며 유연하게 형태를 바꾸는 ’형상 적응성’을 보여주었다.31</p>
<h3>3.3  소프트 매니퓰레이터의 정밀 제어</h3>
<p><code>Robust Control of a Multi-Axis Shape Memory Alloy-Driven Soft Manipulator</code>는 소프트 로봇의 실용화를 위해 반드시 해결해야 할 ‘정밀 제어’ 문제를 다룬 연구다.12 특히 형상기억합금(SMA)으로 구동되는 소프트 매니퓰레이터의 다축 3차원 움직임을 정확하게 추적하는 강건한(robust) 제어 기법을 제안했다.33</p>
<p>소프트 로봇은 몸체가 연속적으로 변형되고 재료의 비선형성이 강해 정확한 수학적 모델링이 어렵다는 근본적인 한계가 있다. 이를 극복하기 위해 연구진은 정적 빔 굽힘 모델을 이용해 소프트 로봇을 선형 시불변(LTI) 시스템으로 근사하고, 특이값 분해(SVD)를 이용해 다축 움직임을 분리하는 제어기를 설계했다. 또한, 모델링되지 않은 동역학(unmodeled dynamics)에 대응하기 위한 강건성을 확보했다.12 실제 하드웨어 실험을 통해 제안된 제어기가 낮은 오차로 궤적을 성공적으로 추적함을 입증했다.33</p>
<p>’기린 목 로봇’과 ‘SMA 매니퓰레이터 제어’ 연구는 2022년 1월 당시 소프트 로보틱스 분야의 두 가지 핵심적인 연구 흐름, 즉 ’새로운 가능성을 탐색하는 생체모방 설계’와 ’실용화를 위한 엔지니어링 문제 해결’이 병렬적으로 진행되고 있었음을 보여준다. 초기 소프트 로보틱스는 주로 새로운 디자인과 구동 메커니즘을 제안하는 데 집중되어 있었다. 하지만 같은 시기에 발표된 두 논문은 이 스펙트럼의 양 극단을 대표한다. ’기린 목 로봇’은 자연에서 영감을 받아 힘과 유연성이라는 새로운 기능적 목표를 제시하며 설계의 지평을 넓혔다.31 반면, ‘SMA 매니퓰레이터 제어’ 연구는 이미 존재하는 소프트 로봇을 어떻게 하면 더 신뢰성 있고 정밀하게 만들 수 있는지에 대한 근본적인 제어 공학 문제에 집중했다.12 이는 소프트 로보틱스 분야가 성숙기에 접어들고 있음을 보여주는 신호다. 한편에서는 여전히 창의적이고 혁신적인 아이디어를 탐구하며 분야의 외연을 확장하고, 다른 한편에서는 기존 기술의 한계를 극복하고 실용성을 높이기 위한 깊이 있는 엔지니어링 연구를 수행하고 있다. 이 두 연구 흐름의 공존은 소프트 로보틱스가 실제 산업 및 의료 현장에 적용될 수 있는 신뢰성 있는 기술로 발전하기 위한 필연적인 과정이다.</p>
<h2>4. 결론</h2>
<p>2022년 1월은 AI와 로봇 공학이 중요한 변곡점을 맞이한 시기였다. AI 분야에서는 CoT를 통해 LLM의 ‘추론’ 시대가 열렸고, LaMDA는 ’책임 있는 AI’의 중요성을 부각시켰다. ConvNeXt와 RePaint는 각각 컴퓨터 비전 아키텍처와 생성 모델 분야에서 기존의 통념을 깨고 새로운 방향을 제시했으며, 그로킹 현상은 딥러닝의 근본 원리에 대한 우리의 이해가 아직 부족함을 상기시켰다. 로봇 공학 분야에서는 소프트 로보틱스가 생체모방을 통한 혁신과 정밀 제어를 통한 실용화라는 두 축을 중심으로 성숙해가는 모습을 보여주었다.</p>
<p>이 시기에 발표된 기초 연구들은 씨앗이 되어 이후 폭발적인 기술 발전의 토양을 마련했다. CoT는 ChatGPT와 같은 명령어 기반 모델들의 추론 능력의 근간이 되었고, LaMDA가 제시한 안전성과 사실 기반의 중요성은 AI 정렬 연구의 핵심 과제가 되었다. 확산 모델의 유연한 활용법을 보여준 RePaint의 아이디어는 DALL-E 2, Stable Diffusion과 같은 텍스트-이미지 생성 모델의 혁명으로 이어졌다. 소프트 로보틱스의 발전은 인간과 로봇의 물리적 상호작용을 더욱 안전하고 자연스럽게 만드는 미래를 향한 중요한 발걸음이 되었다. 결국 2022년 1월의 연구들은 단순한 개별 성과를 넘어, AI와 로봇이 나아갈 새로운 방향을 제시한 나침반 역할을 했다고 평가할 수 있다.</p>
<h2>5. 참고 자료</h2>
<ol>
<li>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models - OpenReview, https://openreview.net/pdf?id=_VjQlMeSB_J</li>
<li>Chain-of-Thought Prompting Elicits Reasoning in Large … - arXiv, https://arxiv.org/pdf/2201.11903</li>
<li>[2201.08239] LaMDA: Language Models for Dialog Applications - ar5iv - arXiv, https://ar5iv.labs.arxiv.org/html/2201.08239</li>
<li>LaMDA: Language Models for Dialog Applications, https://arxiv.org/pdf/2201.08239</li>
<li>A ConvNet for the 2020s - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.pdf</li>
<li>[2201.03545] A ConvNet for the 2020s - ar5iv - arXiv, https://ar5iv.labs.arxiv.org/html/2201.03545</li>
<li>RePaint: Inpainting Using Denoising Diffusion … - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2022/papers/Lugmayr_RePaint_Inpainting_Using_Denoising_Diffusion_Probabilistic_Models_CVPR_2022_paper.pdf</li>
<li>RePaint: Inpainting using Denoising Diffusion Probabilistic Models - ResearchGate, https://www.researchgate.net/publication/358143708_RePaint_Inpainting_using_Denoising_Diffusion_Probabilistic_Models</li>
<li>Grokking (machine learning) - Wikipedia, https://en.wikipedia.org/wiki/Grokking_(machine_learning)</li>
<li>Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets - ar5iv, https://ar5iv.labs.arxiv.org/html/2201.02177</li>
<li>Soft, Wearable Robotics and Haptics: Technologies, Trends, and Emerging Applications | Request PDF - ResearchGate, https://www.researchgate.net/publication/357938209_Soft_Wearable_Robotics_and_Haptics_Technologies_Trends_and_Emerging_Applications</li>
<li>Robust Control of a Multi-Axis Shape Memory Alloy-Driven Soft …, https://www.researchgate.net/publication/357856104_Robust_Control_of_a_Multi-Axis_Shape_Memory_Alloy-Driven_Soft_Manipulator</li>
<li>[PDF] Chain of Thought Prompting Elicits Reasoning in Large Language Models, https://www.semanticscholar.org/paper/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Wei-Wang/1b6e810ce0afd0dd093f789d2b2742d047e316d5</li>
<li>2022 in Review: Top language AI research papers + interesting papers to read - Yi Tay, https://www.yitay.net/blog/2022-best-nlp-papers</li>
<li>arXiv:2502.18600v2 [cs.CL] 3 Mar 2025, https://arxiv.org/pdf/2502.18600</li>
<li>Hot papers on arXiv from the past month: January 2022 - ΑΙhub - AI Hub, https://aihub.org/2022/02/01/hot-papers-on-arxiv-from-the-past-month-january-2022/</li>
<li>[PDF] LaMDA: Language Models for Dialog Applications - Semantic Scholar, https://www.semanticscholar.org/paper/LaMDA%3A-Language-Models-for-Dialog-Applications-Thoppilan-Freitas/b3848d32f7294ec708627897833c4097eb4d8778</li>
<li>LaMDA: Language Models for Dialog Applications (2022) | Romal Thoppilan - SciSpace, https://scispace.com/papers/lamda-language-models-for-dialog-applications-2kvv9lfg</li>
<li>LaMDA: Language Models for Dialog Applications - Google Research, https://research.google/pubs/lamda-language-models-for-dialog-applications/</li>
<li>A ConvNet for the 2020s - Mansi Kataria - Medium, https://zoomout.medium.com/a-convnet-for-the-2020s-aa74632b4c2</li>
<li>(PDF) A ConvNet for the 2020s - ResearchGate, https://www.researchgate.net/publication/357733640_A_ConvNet_for_the_2020s</li>
<li>[PDF] RePaint: Inpainting using Denoising Diffusion Probabilistic Models - Semantic Scholar, https://www.semanticscholar.org/paper/RePaint%3A-Inpainting-using-Denoising-Diffusion-Lugmayr-Danelljan/1e91fa21b890a8f5d615578f4ddf46c3cb394691</li>
<li>[2201.09865] RePaint: Inpainting using Denoising Diffusion Probabilistic Models - ar5iv, https://ar5iv.labs.arxiv.org/html/2201.09865</li>
<li>RePaint: Inpainting using Denoising Diffusion Probabilistic Models Supplementary Material - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lugmayr_RePaint_Inpainting_Using_CVPR_2022_supplemental.pdf</li>
<li>Grokking: Generalization beyond overfitting on small algorithmic datasets | by Young Ben, https://youngandbin.medium.com/grokking-generalization-beyond-overfitting-on-small-algorithmic-datasets-b8c7e52b8cb4</li>
<li>arXiv:2201.02177v1 [cs.LG] 6 Jan 2022, https://arxiv.org/pdf/2201.02177</li>
<li>Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets - ResearchGate, https://www.researchgate.net/publication/357646241_Grokking_Generalization_Beyond_Overfitting_on_Small_Algorithmic_Datasets</li>
<li>Soft, Wearable Robotics and Haptics: Technologies, Trends, and …, https://par.nsf.gov/servlets/purl/10358440</li>
<li>Jan-Mar 2022 - Softrobotics.org, http://softrobotics.org/newsletters/jan-mar-2022/</li>
<li>Wearable and Implantable Soft Robots - PMC - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC12140402/</li>
<li>(PDF) Giraffe Neck Robot: First Step Toward a Powerful and Flexible …, https://www.researchgate.net/publication/358181872_Giraffe_Neck_Robot_First_Step_Toward_a_Powerful_and_Flexible_Robot_Prototyping_Based_on_Giraffe_Anatomy</li>
<li>3D-Printed Giraffe Neck Aims to Bring Flexibility, Impact-Resistance to Future Robotic Platforms - Hackster.io, https://www.hackster.io/news/3d-printed-giraffe-neck-aims-to-bring-flexibility-impact-resistance-to-future-robotic-platforms-8da573bc6be5</li>
<li>Robust Control of a Multi-Axis Shape Memory Alloy-Driven Soft Manipulator - ResearchGate, https://www.researchgate.net/publication/355423867_Robust_Control_of_a_Multi-Axis_Shape_Memory_Alloy-Driven_Soft_Manipulator</li>
<li>Robust Control of a Multi-Axis Shape Memory Alloy-Driven Soft Manipulator - arXiv, https://arxiv.org/abs/2110.10022</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>