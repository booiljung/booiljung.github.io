<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2022년 9월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2022년 9월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2022년 AI 및 로봇 연구 동향</a> / <span>2022년 9월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2022년 9월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2022년 9월, AI 연구의 변곡점 – 대규모 모델의 확산과 사회적 책임의 대두</h2>
<p>2022년 9월은 인공지능 연구 분야에서 중요한 변곡점으로 기록된다. 이 시기는 대규모 언어 모델(LLM)과 확산 모델(Diffusion Model)의 영향력이 학계와 산업계 전반으로 빠르게 확산되던 때였다.1 연구의 패러다임은 단순히 모델의 성능 지표를 개선하는 것을 넘어, 저자원(low-resource) 환경에서의 적용 가능성, 주어진 문맥 정보의 정교한 통합, 그리고 AI 기술이 사회에 미치는 영향과 그에 따른 책임이라는 새로운 화두를 향해 나아가고 있었다. 이러한 변화의 흐름 속에서, 2022년 9월에 발표된 연구들은 기술적 성취와 사회적 요구 사이의 상호작용을 명확하게 보여주었다.</p>
<p>본 보고서는 이 시기의 주요 기술적 성과를 심층적으로 분석한다. 먼저, 음성 처리 분야의 세계 최대 학술대회인 <strong>INTERSPEECH 2022</strong>와 AI 생태계의 근간을 이루는 하드웨어 및 시스템 발전을 조망하는 <strong>NVIDIA GTC 2022</strong>를 중심으로 당시의 핵심 의제를 살펴본다.3 이 두 행사는 각각 알고리즘의 정점과 이를 가능하게 하는 물리적 기반을 대표하며, 이들의 상호작용은 AI 기술 발전의 역학을 이해하는 데 필수적이다.</p>
<p>더 나아가, 본 보고서는 학술 논문 사전 공개 플랫폼인 arXiv를 통해 발표된 두 가지 새로운 연구 패러다임을 심층적으로 탐구한다. 첫 번째는 ’잊힐 권리’라는 사회적 요구에 기술적으로 응답하는 **머신 언러닝(Machine Unlearning)**이며, 두 번째는 로봇 공학의 근본적인 설계 방법론에 대한 질문을 던지는 **로봇 공동 최적화(Co-optimization)**이다.5 이 두 주제는 AI 기술이 직면한 프라이버시 문제와 물리적 세계와의 상호작용이라는 현실적인 과제에 학계가 어떻게 대응하고 있는지를 보여주는 중요한 사례다. 이 시기의 연구 동향을 종합적으로 분석함으로써, 우리는 AI 기술이 실험실을 넘어 현실 세계의 복잡한 문제들을 해결하는 단계로 나아가고 있음을 확인할 수 있다.</p>
<h2>2.  2022년 9월 주요 학술 행사 동향 및 핵심 의제</h2>
<p>2022년 9월은 AI 분야의 다양한 주제를 다루는 여러 주요 학술 및 산업 행사가 집중적으로 개최된 시기였다. 이 행사들은 당시 연구 커뮤니티의 관심사와 기술 발전의 방향성을 명확하게 보여주었다. 특히 음성 기술 분야의 INTERSPEECH와 AI 컴퓨팅 분야의 NVIDIA GTC는 각각 소프트웨어와 하드웨어 측면에서 AI 생태계의 핵심 동향을 파악할 수 있는 중요한 바로미터 역할을 했다.</p>
<h3>2.1  인간 중심의 음성 기술: INTERSPEECH 2022</h3>
<p>2022년 9월 18일부터 22일까지 대한민국 인천에서 개최된 INTERSPEECH 2022는 음성 언어 처리 과학 및 기술 분야에서 세계 최대 규모와 권위를 자랑하는 학술대회다.4 이 행사의 주제는 “인간과 인간화 음성 기술(Human and Humanizing Speech Technology)“로 설정되었는데, 이는 음성 기술의 발전 방향이 단순한 기계적 인식률 향상을 넘어 인간의 감정과 뉘앙스를 이해하고, 보다 자연스러운 상호작용을 지향하고 있음을 명확히 보여준다.4</p>
<p>이러한 주제 의식은 학계의 폭발적인 관심으로 이어졌다. INTERSPEECH 2022에는 2,100편이 넘는 방대한 양의 논문이 제출되었으며, 이는 음성 AI 연구의 양적 팽창을 단적으로 보여주는 지표다.9 음성 데이터의 접근성이 향상되고 대규모 모델 훈련이 용이해지면서 연구의 저변이 크게 확대된 것이다. 그러나 이러한 급격한 성장은 학술 커뮤니티에 새로운 도전을 안겨주기도 했다. 급증한 논문 수는 리뷰어와 메타 리뷰어 자원의 부족 및 과부하 현상을 초래했으며, 이는 학문 분야의 성장이 학술적 품질 관리 시스템에 가하는 압박을 보여주는 사례가 되었다.9</p>
<p>한편, Apple, NCSoft와 같은 글로벌 기술 기업들이 대거 참여하여 음성 비서, 대화형 AI, 게임 AI 등 다양한 산업 분야에서의 음성 기술 활용 사례와 연구 결과를 발표했다.10 이는 INTERSPEECH가 순수 학술 연구를 넘어 산업계의 실질적인 수요와 기술 트렌드를 반영하는 중요한 교류의 장임을 입증한다.</p>
<h3>2.2  AI, 하드웨어, 그리고 메타버스의 융합: NVIDIA GTC 2022</h3>
<p>같은 시기인 9월 19일부터 22일까지 가상으로 개최된 NVIDIA GTC(GPU Technology Conference) 2022는 AI, 3D 시뮬레이션, 데이터 과학 및 메타버스 분야의 최신 기술 동향을 선보이는 대표적인 산업 이벤트였다.3 GTC는 특정 학문 분야에 국한되지 않고, AI 모델을 구동하는 근간이 되는 시스템 및 하드웨어의 발전을 조망할 수 있다는 점에서 차별화된다.3</p>
<p>이 행사는 AI 연구가 알고리즘의 혁신만으로는 완성될 수 없으며, 이를 뒷받침하는 강력한 컴퓨팅 인프라와의 긴밀한 상호작용 속에서 발전한다는 사실을 상기시킨다. 예를 들어, INTERSPEECH에서 발표되는 수십억 파라미터 규모의 초거대 음성 모델을 훈련하고 서비스하는 것은 GTC에서 발표되는 것과 같은 고성능 GPU와 최적화된 소프트웨어 스택이 없다면 불가능하다.</p>
<p>INTERSPEECH의 ’인간화 기술’이라는 주제와 GTC의 ’메타버스’라는 주제는 표면적으로 달라 보이지만, 그 기저에는 ’인간과 유사한 지능을 가진 디지털 에이전트’를 구현하려는 공통된 목표가 존재한다. INTERSPEECH가 에이전트의 ’목소리’와 ’언어 이해 능력’을 연구한다면, GTC는 그 에이전트가 활동할 ’가상 세계’와 그 지능을 구동할 ’두뇌(하드웨어)’를 제공하는 역할을 한다. 이처럼 두 행사는 AI 기술 발전의 서로 다른 축을 대표하면서도, 궁극적으로는 인간-컴퓨터 상호작용의 미래라는 하나의 비전을 향해 수렴하고 있음을 보여준다.</p>
<h2>3.  음성 처리 기술의 최신 지평: INTERSPEECH 2022 심층 분석</h2>
<p>INTERSPEECH 2022는 “인간화 음성 기술“이라는 주제 아래, 음성 AI가 직면한 현실적인 문제들을 해결하기 위한 혁신적인 연구들로 가득했다. 특히 최우수 학생 논문상(Best Student Paper Award) 수상작들은 저자원 환경에서의 음성 합성(TTS), 문맥 정보를 활용한 음성 인식(ASR) 등 핵심적인 난제에 대한 창의적인 해결책을 제시하며 학계의 주목을 받았다.</p>
<h3>3.1  저자원 환경의 한계 극복: 비지도 학습 기반 TTS</h3>
<p>고품질 TTS 모델을 훈련시키기 위해서는 방대한 양의 텍스트-음성 쌍 데이터가 필수적이다. 그러나 이러한 데이터셋을 구축하는 것은 막대한 비용과 시간을 필요로 하며, 특히 한국어와 같이 데이터가 상대적으로 부족한 저자원 언어의 경우 이는 기술 발전의 큰 걸림돌이 된다.12</p>
<p>이러한 문제에 대한 획기적인 해결책을 제시한 연구가 바로 최우수 학생 논문상을 수상한 “Transfer Learning Framework for Low-Resource Text-to-Speech using a Large-Scale Unlabeled Speech Corpus“이다.12 이 연구는 텍스트 라벨이 없는 대규모 음성 데이터를 활용하여 TTS 모델의 성능을 극적으로 향상시키는 전이 학습 프레임워크를 제안했다.</p>
<p><strong>제안 방법론의 핵심 단계는 다음과 같다:</strong></p>
<ol>
<li><strong>유사 음소(Pseudo Phoneme) 생성:</strong> 텍스트 정보가 없는 상황에서 음운적 특징을 학습하기 위해, 사전 훈련된 대규모 음성 모델인 wav2vec2.0을 활용한다. wav2vec2.0 모델의 중간 은닉 표현(hidden representation)을 추출하고, 여기에 k-평균 군집화(k-means clustering) 알고리즘을 적용하여 음성 신호를 이산적인 ‘유사 음소’ 단위로 변환한다. 이는 텍스트 없이 음성 데이터만으로 음소와 유사한 특징을 학습하는 독창적인 접근법이다.12</li>
<li><strong>사전 훈련(Pre-training):</strong> VITS라는 최신 TTS 아키텍처를 기반으로, 텍스트 대신 생성된 유사 음소를 입력으로 사용하여 대규모 비라벨링 음성 데이터셋으로 모델을 사전 훈련한다. 이 과정에서 모델은 방대한 음성 데이터로부터 풍부한 음향적, 운율적 특징을 학습하게 된다.12</li>
<li><strong>미세 조정(Fine-tuning):</strong> 사전 훈련을 통해 일반적인 음성 생성 능력을 갖춘 모델을, 목표 화자의 매우 적은 양(예: 10분)의 텍스트-음성 쌍 데이터로 미세 조정한다. 이를 통해 모델은 소량의 데이터만으로도 특정 화자의 목소리와 발음 특성을 빠르고 효과적으로 학습할 수 있다.12</li>
</ol>
<p>이 프레임워크의 핵심은 사전 훈련 단계에서 사용되는 손실 함수에 있다. 기존 VITS 모델의 손실 함수(Lkl)와 더불어, 유사 음소를 조건으로 하는 새로운 손실 함수(<span class="math math-inline">L&#39;_{kl}</span>)를 함께 최적화한다.<br />
<span class="math math-display">
L_{kl} = \log q_{\phi}(z \vert x_{lin}) - \log p_{\theta}(z \vert c_{text}, A_{text})
</span></p>
<p><span class="math math-display">
L_{kl}&#39; = \log q_{\phi}(z \vert x_{lin}) - \log p_{\psi}(z \vert c_{i}&#39;, A_{i}&#39;)
</span></p>
<p>여기서 <span class="math math-inline">c_{text}</span>는 실제 텍스트, <span class="math math-inline">c_{i}&#39;</span>는 유사 음소 시퀀스를 의미하며, 모델은 이 두 가지 조건을 모두 만족시키는 방향으로 학습된다.12</p>
<p>실험 결과, 이 방법을 통해 단 10분의 라벨링 데이터로 미세 조정한 모델이 수십 시간의 데이터로 학습한 기존 베이스라인 모델의 성능을 능가하는 것으로 나타났다.12 이는 저자원 언어의 TTS 기술 개발에 있어 실질적인 돌파구를 마련한 것으로, 향후 다양한 언어에 대한 음성 합성 기술의 보편화에 크게 기여할 것으로 평가된다.</p>
<h3>3.2  문맥을 이해하는 음성 인식: GNN 기반 ASR</h3>
<p>ASR 시스템의 주요 과제 중 하나는 대화의 문맥이나 특정 도메인에서만 등장하는 고유 명사, 기술 용어 등 희귀 단어(long-tail words)를 정확하게 인식하는 것이다. 이러한 ‘바이어싱 단어(biasing words)’ 목록을 ASR 모델에 동적으로 주입하여 인식률을 높이는 연구가 활발히 진행되고 있다.16</p>
<p>INTERSPEECH 2022 최우수 학생 논문상 수상작인 “Tree-constrained Pointer Generator with Graph Neural Network Encodings for Contextual Speech Recognition“은 이 문제에 대한 정교하고 효율적인 해결책을 제시했다.14</p>
<p><strong>제안 방법론의 핵심 아이디어는 다음과 같다:</strong></p>
<ol>
<li><strong>TCPGen (Tree-constrained Pointer Generator):</strong> 이 방법론은 바이어싱 단어 목록을 접두사 트리(prefix-tree) 형태로 효율적으로 구조화한다. 그리고 포인터 생성기(pointer generator)라는 신경망 모듈을 통해 ASR 디코더가 일반적인 어휘를 생성하는 대신, 필요할 때 접두사 트리에 있는 특정 단어를 직접 ‘가리키도록(point)’ 유도한다.16</li>
<li><strong>GNN 인코딩을 통한 ‘미리보기(Lookahead)’ 기능:</strong> 이 연구의 핵심적인 기여는 기존 TCPGen을 그래프 신경망(GNN)으로 한 단계 발전시킨 점이다. 접두사 트리의 각 노드를 Tree-RNN(Tree Recursive Neural Network)이라는 GNN의 일종으로 인코딩한다. 이 과정을 통해 각 노드는 단순히 현재 단어 조각의 정보만이 아니라, 그 노드에서 파생되는 모든 하위 경로, 즉 ’미래에 등장할 수 있는 단어 조각들’의 정보를 압축적으로 포함하게 된다. 이는 ASR 디코더가 다음 단어를 예측할 때, 바이어싱 목록에 있는 단어들의 전체적인 구조를 미리 보고 더 정확한 판단을 내리게 하는 ‘미리보기’ 효과를 가져온다.16</li>
</ol>
<p>Tree-RNN을 통해 트리의 각 노드 <span class="math math-inline">n_j</span>의 표현 <span class="math math-inline">h_{n_j}^{\text{tree}}</span>는 다음과 같은 재귀적인 방식으로 계산된다.<br />
<span class="math math-display">
h_{n_j}^{\text{tree}} = f(W_1 y_j + \sum_{k=1:K} W_2 h_{n_k}^{\text{tree}})
</span><br />
이 수식에서 <span class="math math-inline">y_j</span>는 현재 노드 <span class="math math-inline">n_j</span>의 임베딩 벡터이며, <span class="math math-inline">\sum h_{n_k}^{\text{tree}}</span>는 모든 자식 노드들의 표현을 종합한 것이다. 즉, 노드의 표현은 자신과 모든 자손의 정보를 종합하여 결정된다.16</p>
<p>실험 결과, GNN 인코딩을 추가함으로써 기존 TCPGen 대비 바이어싱 단어의 단어 오류율(WER)을 약 15% 추가로 절감하는 효과를 보였다. 특히, 연구팀은 AMI 회의 데이터셋에 대해 발표 슬라이드의 텍스트를 OCR 기술로 추출하여 실시간 바이어싱 목록으로 활용하는 다중 모드(audio-visual) ASR 파이프라인을 제안함으로써, 이 기술이 실제 회의 환경과 같은 복잡한 시나리오에서도 효과적으로 작동할 수 있음을 입증했다.16</p>
<h3>3.3  표현력을 더하다: 노래 음성 합성 및 음높이 제어 기술</h3>
<p>음성 기술의 발전은 정보 전달의 효율성을 넘어 인간의 표현력을 모방하는 단계로 나아가고 있다. NCSoft의 Speech AI Lab은 INTERSPEECH 2022에서 노래 음성 합성(Singing Voice Synthesis) 및 음성 표현력 제어에 관한 3편의 논문을 발표하며 이 분야의 기술적 진보를 선도했다.10</p>
<p>주요 연구 내용은 다음과 같다:</p>
<ul>
<li><strong>음색과 음높이의 분리:</strong> 적대적 다중 작업 학습(Adversarial Multi-Task Learning)을 이용하여 노래 음성의 핵심 요소인 음색(timbre)과 음높이(pitch)를 효과적으로 분리하고 제어하는 기술을 개발했다. 이를 통해 단일 모델로 여러 사람의 목소리를 생성하면서도 더 자연스러운 노래 음성을 합성할 수 있게 되었다.10</li>
<li><strong>음높이 데이터 증강:</strong> VocGAN-PS라는 새로운 알고리즘을 제안하여, 기존 음성 데이터의 고유한 음색은 그대로 유지하면서 음높이만 자유롭게 변환하는 데이터 증강(augmentation) 기술을 선보였다. 이렇게 생성된 데이터를 TTS 모델 훈련에 활용함으로써, 합성음의 음높이 조절 능력과 전반적인 음질을 크게 개선했다.10</li>
<li><strong>계층적 VAE 구조:</strong> 계층적 다중 스케일 변이형 오토인코더(Hierarchical and Multi-scale VAE)를 통해 음성의 운율(prosody)을 더 정교하게 모델링하여, 단조롭지 않고 다양하며 자연스러운 표현력을 가진 음성을 합성하는 데 성공했다.10</li>
</ul>
<p>이러한 연구들은 음성 AI가 단순한 정보 전달 도구를 넘어, 게임, 엔터테인먼트, 예술 창작 등 인간의 감성과 창의성이 중요한 영역으로 그 활용 범위를 확장하고 있음을 보여주는 중요한 사례다.</p>
<table><thead><tr><th>논문 ID</th><th>제목</th><th>저자</th><th>핵심 기여</th></tr></thead><tbody>
<tr><td><strong>225 (수상)</strong></td><td>Transfer Learning Framework for Low-Resource Text-to-Speech using a Large-Scale Unlabeled Speech Corpus</td><td>Minchan Kim et al.</td><td>대규모 비라벨링 음성 데이터와 wav2vec2.0 기반 ’유사 음소’를 활용한 사전 훈련으로, 10분의 데이터만으로 고품질 저자원 TTS 달성 14</td></tr>
<tr><td><strong>461 (수상)</strong></td><td>Tree-constrained Pointer Generator with Graph Neural Network Encodings for Contextual Speech Recognition</td><td>Guangzhi Sun et al.</td><td>접두사 트리를 GNN으로 인코딩하여 ASR 디코딩 시 ‘미리보기’ 기능을 구현, 문맥적 희귀 단어 인식 정확도 향상 14</td></tr>
<tr><td><strong>10808 (수상)</strong></td><td>Investigating perception of spoken dialogue acceptability through surprisal</td><td>Sarenne Carrol Wallbridge et al.</td><td>언어 모델의 ‘놀람(surprisal)’ 값이 인간이 인지하는 대화의 수용 가능성과 어떤 관련이 있는지 탐구 14</td></tr>
<tr><td>10604</td><td>Trajectories predicted by optimal speech motor control using LSTM networks</td><td>Tsiky Rakotomalala et al.</td><td>최적의 음성 운동 제어를 통해 예측된 궤적을 LSTM 네트워크를 사용하여 모델링 14</td></tr>
<tr><td>10831</td><td>Pharyngealization in Amazigh: Acoustic and articulatory marking over time</td><td>Philipp Buech et al.</td><td>베르베르어의 인두음화 현상을 음향적, 조음적 측면에서 분석 14</td></tr>
<tr><td>10973</td><td>Where’s the uh, hesitation? The interplay between filled pause location, speech rate and fundamental frequency in perception of confidence</td><td>Ambika Kirkland et al.</td><td>간투어(uh)의 위치, 발화 속도, 기본 주파수가 화자의 자신감 인식에 미치는 상호작용 연구 14</td></tr>
<tr><td>478</td><td>Attentive Feature Fusion for Robust Speaker Verification</td><td>Bei Liu et al.</td><td>강인한 화자 인증을 위한 어텐션 기반 특징 융합 방법 제안 14</td></tr>
<tr><td>11100</td><td>Distance-Based Sound Separation</td><td>Katharine Patterson et al.</td><td>음원 간의 거리를 기반으로 한 새로운 음원 분리 방법론 제시 14</td></tr>
<tr><td>11277</td><td>Complex-Valued Time-Frequency Self-Attention for Speech Dereverberation</td><td>Vinay Kothapally et al.</td><td>음성 잔향 제거를 위해 복소수 값 시간-주파수 셀프 어텐션 메커니즘 활용 14</td></tr>
<tr><td>107</td><td>Deep Residual Spiking Neural Network for Keyword Spotting in Low-Resource Settings</td><td>Qu Yang et al.</td><td>저자원 환경에서의 키워드 검출을 위한 심층 잔차 스파이킹 신경망 제안 14</td></tr>
<tr><td>99</td><td>Robust Self-Supervised Audio-Visual Speech Recognition</td><td>Bowen Shi et al.</td><td>강인한 자기 지도 학습 기반의 오디오-비주얼 음성 인식 모델 개발 14</td></tr>
<tr><td>580</td><td>Learning Audio-Text Agreement for Open-vocabulary Keyword Spotting</td><td>Hyeon-Kyeong Shin et al.</td><td>개방형 어휘 키워드 검출을 위해 오디오와 텍스트 간의 일치도를 학습하는 방법론 제안 14</td></tr>
</tbody></table>
<h2>4.  arXiv를 통해 본 AI 연구의 새로운 패러다임</h2>
<p>2022년 9월은 주요 학술대회뿐만 아니라, arXiv를 통해 AI 연구의 근본적인 방향성에 대한 중요한 담론이 형성된 시기이기도 했다. 특히 ’머신 언러닝(Machine Unlearning)’과 ’로봇 공동 최적화(Co-optimization)’라는 두 주제는 각각 AI의 사회적 책임과 물리적 구현이라는 측면에서 새로운 패러다임을 제시했다.</p>
<h3>4.1  기계 학습 모델의 ‘잊힐 권리’: 머신 언러닝(Machine Unlearning) 서베이 분석</h3>
<p>AI 모델이 사회 전반에 깊숙이 통합되면서, 모델이 학습한 데이터에 대한 통제권 문제가 중요한 사회적, 법적 쟁점으로 부상했다. 특히 유럽연합의 일반 데이터 보호 규정(GDPR) 등으로 대표되는 ’잊힐 권리’는 사용자가 자신의 데이터 삭제를 요청할 경우, 기업이 이를 데이터베이스뿐만 아니라 이미 훈련된 AI 모델에서도 제거해야 할 의무를 부과한다.18 이 문제에 대한 기술적 해법을 모색하는 분야가 바로 ’머신 언러닝’이다.</p>
<p>2022년 9월 6일 arXiv에 공개된 “A Survey of Machine Unlearning” (arXiv:2209.02299)은 이 신흥 분야의 개념적 토대를 마련하고 연구 방향을 제시한 중요한 서베이 논문이다.5</p>
<ul>
<li><strong>개념 및 필요성:</strong> 머신 언러닝은 단순히 데이터베이스에서 데이터를 삭제하는 것을 넘어, 훈련된 모델 파라미터에 남아있는 특정 데이터의 ‘기억’ 또는 ’영향’을 제거하는 것을 목표로 한다.5 모델을 처음부터 재훈련하는 것은 데이터 규모가 커질수록 막대한 컴퓨팅 비용을 유발하기 때문에, 특정 데이터의 영향만을 효율적으로 제거하는 기술이 필수적이다.18 이러한 요구는 프라이버시 보호뿐만 아니라, 적대적 공격으로 오염된 데이터를 제거하거나 모델의 편향을 유발하는 데이터를 삭제하여 모델의 보안성과 공정성을 높이는 데에도 중요하다.18</li>
<li><strong>방법론 및 과제:</strong> 이 서베이 논문은 특정 방법론을 제안하기보다는, 기존의 머신 언러닝 연구들을 체계적으로 분류하고 분석한다. 연구들은 크게 ’정확한 언러닝(Exact Unlearning)’과 ’근사적 언러닝(Approximate Unlearning)’으로 나뉜다.20 정확한 언러닝은 해당 데이터를 제외하고 재훈련한 것과 동일한 모델을 만드는 것을 보장하지만 계산적으로 비효율적인 경우가 많다. 반면, 근사적 언러닝은 더 효율적이지만, 데이터의 영향이 얼마나 완벽하게 제거되었는지 검증하는 것이 중요한 과제가 된다. 논문은 중앙 집중식 환경, 연합 학습(Federated Learning) 환경 등 다양한 시나리오에서의 언러닝 기법과 그 검증 방법들을 포괄적으로 다룬다.20</li>
</ul>
<p>이 서베이 논문의 등장은 머신 언러닝이 단편적인 연구 주제를 넘어, 체계적인 프레임워크와 평가 기준을 갖춘 독립된 연구 분야로 자리 잡고 있음을 시사한다. 대규모 모델의 영향력이 커질수록, 그 모델을 통제하고 수정하는 기술의 중요성 또한 비례하여 증가할 것이다. 따라서 머신 언러닝은 향후 ’책임감 있는 AI(Responsible AI)’를 구현하는 핵심 기술로 발전할 가능성이 높다.</p>
<h3>4.2  설계와 제어의 통합: 신경망 기반 로봇 공동 최적화</h3>
<p>전통적인 로봇 공학에서 로봇의 물리적 설계(하드웨어)와 제어 알고리즘(소프트웨어)은 순차적이고 분리된 과정으로 다루어져 왔다. 즉, 먼저 범용적인 하드웨어 플랫폼을 설계한 후, 그 위에서 특정 작업을 수행하기 위한 제어 소프트웨어를 개발하는 방식이다. 그러나 이러한 접근법은 종종 차선책에 머무르며, 로봇의 잠재적 성능을 최대한 이끌어내지 못하는 한계를 가진다.22</p>
<p>2022년 9월 1일 arXiv에 공개된 Charles Schaff의 박사 학위 논문 “Neural Approaches to Co-Optimization in Robotics” (arXiv:2209.00579)는 이러한 전통적인 패러다임에 도전하며, 로봇의 ’몸(morphology)’과 ’뇌(control)’를 동시에 최적화하는 ’공동 최적화(Co-optimization)’라는 새로운 접근법을 심층적으로 탐구했다.6</p>
<ul>
<li>
<p><strong>개념 및 필요성:</strong> 공동 최적화는 특정 과업의 성능을 극대화하는 것을 단일 목표로 하여, 로봇의 물리적 구성요소(예: 다리 길이, 관절 배치)와 제어 알고리즘을 하나의 최적화 문제로 통합하여 해결하는 방식이다.23 이는 특정 환경과 임무에 고도로 특화된 신체 구조를 갖도록 진화한 자연계의 생물들로부터 영감을 받은 접근법으로, 범용 로봇보다 훨씬 높은 효율과 성능을 달성할 수 있는 잠재력을 가진다.22</p>
</li>
<li>
<p><strong>제안 방법론:</strong> 이 연구는 심층 학습, 특히 강화 학습을 공동 최적화 문제에 적용하는 신경망 기반의 접근법을 제시한다.</p>
</li>
<li>
<p><strong>종단간 최적화:</strong> 미분 가능한 물리 시뮬레이터 등을 활용하여, 최종 과업의 성공 여부(보상)로부터 제어 정책 파라미터뿐만 아니라 로봇의 물리적 설계 파라미터까지 그래디언트가 역전파될 수 있는 종단간(end-to-end) 학습 프레임워크를 구축한다.22</p>
</li>
<li>
<p><strong>설계 조건부 제어기:</strong> 다양한 물리적 설계에 대해 일반화하여 적용할 수 있는 ’설계 조건부 제어기(design-conditioned controller)’를 제안한다. 이 제어기는 로봇의 설계 파라미터를 입력의 일부로 받아들이기 때문에, 다중 작업 강화 학습(multi-task reinforcement learning) 프레임워크 내에서 수많은 설계 후보군을 효율적으로 탐색하며 최적의 설계-제어 쌍을 찾아낼 수 있다.6</p>
</li>
</ul>
<p>’머신 언러닝’과 ’로봇 공동 최적화’는 표면적으로는 무관해 보이지만, ’정적으로 주어진 시스템을 동적으로 수정하고 적응시킨다’는 공통된 철학을 공유한다. 머신 언러닝이 학습이 완료된 <em>모델</em>에서 특정 지식을 제거하여 사후적으로 수정한다면, 공동 최적화는 설계 단계에서부터 특정 과업에 맞게 <em>로봇</em>을 최적화하여 사전적으로 적응시킨다. 두 연구 모두 AI와 로봇이 고정된 시스템이 아니라, 변화하는 요구와 환경에 유연하게 대응할 수 있어야 한다는 미래 지향적인 비전을 제시한다. 특히 로봇 공동 최적화는 소프트웨어가 하드웨어의 제약을 극복하는 기존 방식을 넘어, 소프트웨어와 하드웨어가 함께 진화하며 시너지를 창출하는 새로운 공학적 접근법으로, 향후 자율주행차, 드론 등 AI가 탑재된 모든 물리 시스템의 설계 철학에 근본적인 영향을 미칠 수 있다.</p>
<h2>5.  주요 학술지 및 기타 학회 동향</h2>
<p>2022년 9월을 전후하여 발표된 주요 학술지의 논문들과 컴퓨터 비전, 로보틱스 분야 최상위 학회의 수상 연구들은 당시 AI 기술 스펙트럼의 폭과 깊이를 보여준다. 이 연구들은 AI 윤리와 같은 사회적 담론에서부터, 특정 응용 분야의 기술적 난제를 해결하는 구체적인 방법론에 이르기까지 다양한 주제를 아우른다.</p>
<h3>5.1  학술지 AI를 통해 본 응용 연구 동향</h3>
<p>2022년 9월 발행된 학술지 <em>AI</em> 3권 3호에서는 AI 기술을 다양한 현실 세계 문제에 적용하는 연구들이 다수 발표되었다.24 이는 AI가 이론적 탐구를 넘어 실용적인 가치를 창출하는 단계로 나아가고 있음을 보여준다.</p>
<ul>
<li><strong>AI 윤리의 국제적 접근:</strong> “Bridging East-West Differences in Ethics Guidance for AI and Robotics” 연구는 AI 및 로봇 윤리 가이드라인에 대한 동서양의 문화적 차이를 분석했다. 일본을 동양의 대표로, 유럽과 북미를 서양의 대표로 설정하고, 현재의 국제 윤리 지침이 서구의 ’예방적 가치(precautionary values)’에 치우쳐 있음을 지적했다. 이 연구는 일본의 ’낙관적 가치(optimistic values)’를 통합한 하이브리드 접근법을 제안하며, 진정으로 국제적인 윤리 기준 수립의 필요성을 역설했다.24</li>
<li><strong>규칙 기반 학습의 재조명:</strong> “Learning Functions and Classes Using Rules“는 문법적 진화(grammatical evolution)라는 기법을 활용하여 데이터 분류 및 회귀 문제를 위한 해석 가능한 규칙(rule)을 생성하는 새로운 방법론을 제시했다. 이는 심층 신경망의 ‘블랙박스’ 문제에 대한 대안으로서, 설명 가능하고 강건한 AI 시스템 구축에 기여할 수 있다.24</li>
<li><strong>정밀 농업을 위한 로봇 비전:</strong> “Spatial Deep Learning for Autonomous Navigation and Collision Avoidance of a Robotic Platform in Wheat Crop Rows” 연구는 농업용 로봇이 밀밭에서 작물을 밟지 않고 자율적으로 주행하고 장애물을 회피하는 기술을 다루었다. MobileNet SSD와 같은 경량 심층 학습 모델과 스테레오 카메라를 결합하여, 실시간으로 밀 경작열을 인식하고 충돌을 방지하는 공간 AI(Spatial AI) 시스템을 구현했다.24 이는 AI 기술이 식량 생산성 향상과 같은 인류의 근본적인 문제 해결에 기여할 수 있음을 보여주는 사례다.</li>
</ul>
<h3>5.2  컴퓨터 비전 및 로보틱스 최상위 학회 수상 연구 조망</h3>
<p>2022년 하반기는 컴퓨터 비전과 로보틱스 분야의 최상위 학술대회인 ECCV와 IROS가 개최된 시기이기도 하다. 이 학회들에서 최우수 논문상을 수상한 연구들은 각 분야의 기술적 정점을 보여주는 중요한 성과들이다.</p>
<ul>
<li>
<p><strong>ECCV 2022 (European Conference on Computer Vision):</strong> 컴퓨터 비전 분야의 3대 학회 중 하나인 ECCV 2022의 최우수 논문상은 “On the Versatile Uses of Partial Distance Correlation in Deep Learning“에게 수여되었다.25</p>
</li>
<li>
<p><strong>핵심 기여:</strong> 이 연구는 통계학에서 비교적 덜 알려진 척도인 ’부분 거리 상관관계(Partial Distance Correlation, PDC)’를 딥러닝 분야에 본격적으로 도입했다.27 PDC는 서로 다른 차원과 구조를 가진 두 신경망의 특징 표현(feature representation) 공간 사이의 비선형적 상관관계를 효과적으로 측정할 수 있는 강력한 도구다.29 연구팀은 이를 활용하여 ▲두 모델의 학습 내용이 얼마나 유사한지 비교하고, ▲한 모델이 다른 모델이 학습하지 않은 새로운 정보를 학습하도록 유도(조건부 학습)하며, ▲얽힘 없는 표현(disentangled representation)을 학습하는 등 다양한 딥러닝 문제에 대한 새로운 정규화(regularization) 기법을 제시했다.27 이는 모델의 성능을 넘어 모델의 내부 동작을 이해하고 제어하는 새로운 길을 열었다는 점에서 높은 평가를 받았다.</p>
</li>
<li>
<p><strong>IROS 2022 (International Conference on Intelligent Robots and Systems):</strong> 지능형 로봇 분야의 최고 권위 학회인 IROS 2022에서는 “SpeedFolding: Learning Efficient Bimanual Folding of Garments“가 최우수 논문상과 최우수 RoboCup 논문상을 동시에 수상하는 영예를 안았다.30</p>
</li>
<li>
<p><strong>핵심 기여:</strong> 이 연구는 로봇 공학의 오랜 난제 중 하나인 ‘옷감 조작(cloth manipulation)’ 문제, 특히 구겨진 옷을 펴고 접는 작업을 해결하기 위한 효율적인 양팔 로봇 시스템 ’SpeedFolding’을 개발했다.33 핵심은 BiMaMa-Net(BiManual Manipulation Network)이라는 새로운 신경망 아키텍처로, RGB-D 이미지만으로 옷감을 펴기 위한 최적의 양팔 잡기 지점(grasp points)과 동작(fling, drag 등)을 예측한다.33 이 시스템은 시간당 30-40개의 옷을 접는(Folds Per Hour, FPH) 놀라운 성능을 달성했는데, 이는 이전 연구들보다 5배에서 10배 이상 빠른 속도다.33 이는 심층 학습 기반의 인식 및 계획 기술이 비정형적이고 동역학이 복잡한 실제 환경의 조작 문제를 해결하는 데 있어 얼마나 강력한지를 입증한 획기적인 성과다.</p>
</li>
</ul>
<table><thead><tr><th>학회명</th><th>수상 부문</th><th>논문 제목</th><th>저자</th><th>핵심 기여</th></tr></thead><tbody>
<tr><td><strong>ECCV 2022</strong></td><td>Best Paper Award</td><td>On the Versatile Uses of Partial Distance Correlation in Deep Learning</td><td>Xingjian Zhen et al.</td><td>통계학의 ’부분 거리 상관관계’를 딥러닝에 도입하여, 모델 간 유사성 비교, 조건부 학습, 표현 학습 등을 위한 새로운 정규화 도구를 제시 25</td></tr>
<tr><td><strong>IROS 2022</strong></td><td>Best Paper Award &amp; Best RoboCup Paper Award</td><td>SpeedFolding: Learning Efficient Bimanual Folding of Garments</td><td>Yahav Avigal et al.</td><td>BiMaMa-Net 아키텍처를 통해 구겨진 옷감을 효율적으로 펴고 접는 양팔 로봇 시스템을 개발, 기존 대비 5-10배의 속도 향상(30-40 FPH) 달성 30</td></tr>
</tbody></table>
<h2>6. 결론: 종합 및 미래 전망 - 통합, 책임, 그리고 현실 세계로의 확장</h2>
<p>2022년 9월을 기점으로 발표된 AI 및 로봇 분야의 주요 연구들은 세 가지 핵심적인 흐름으로 요약될 수 있다: <strong>통합(Integration)</strong>, <strong>책임(Responsibility)</strong>, 그리고 <strong>현실 세계로의 확장(Real-world Expansion)</strong>. 이 흐름들은 당시 기술 발전의 단면을 보여줄 뿐만 아니라, 미래 연구의 방향성을 명확하게 제시한다.</p>
<p>첫째, <strong>통합</strong>의 경향은 여러 연구에서 두드러지게 나타났다. INTERSPEECH에서는 음성 정보와 시각 정보(슬라이드 텍스트)를 융합하여 음성 인식의 정확도를 높였고 16, IROS에서는 로봇의 물리적 설계와 제어 알고리즘을 하나의 최적화 문제로 통합하여 성능을 극대화했다.6 또한 ECCV에서는 통계학의 개념(부분 거리 상관관계)을 딥러닝에 접목하여 모델을 이해하고 제어하는 새로운 도구를 만들어냈다.27 이는 개별 기술의 고도화를 넘어, 서로 다른 분야와 기술을 창의적으로 융합하여 더 큰 시너지를 창출하려는 노력이 AI 연구의 핵심 동력으로 자리 잡았음을 의미한다.</p>
<p>둘째, <strong>책임</strong>에 대한 고찰이 중요한 연구 주제로 부상했다. 학술지 <em>AI</em>에서 다룬 AI 윤리에 대한 동서양의 철학적 비교는 기술 개발이 나아가야 할 방향에 대한 근본적인 질문을 던졌으며 24, ’잊힐 권리’를 기술적으로 구현하려는 머신 언러닝 연구는 AI 기술이 사회적, 법적 요구에 부응해야 한다는 시대적 과제를 정면으로 다루었다.5 이는 AI 기술의 영향력이 커짐에 따라, 학계와 산업계가 성능 향상뿐만 아니라 기술의 공정성, 투명성, 그리고 사회적 합의를 심도 있게 고민하기 시작했음을 보여준다.</p>
<p>셋째, AI와 로봇 기술이 이상적인 실험실 환경을 넘어 복잡하고 제약이 많은 <strong>현실 세계의 문제</strong>를 해결하려는 노력이 가속화되었다. 저자원 언어에 대한 TTS 기술 개발은 디지털 정보 격차 해소에 기여할 수 있으며 12, 농업 및 가사 노동(옷 개기) 로봇 연구는 인구 고령화와 노동력 부족 문제에 대한 기술적 대안을 모색하는 시도다.24 이는 AI 기술이 더 이상 특정 분야에 국한되지 않고, 인류가 직면한 보편적인 문제 해결에 기여하는 범용 기술로 발전하고 있음을 시사한다.</p>
<p>이러한 흐름들을 종합해 볼 때, 미래의 AI 연구는 다음과 같은 방향으로 전개될 것으로 전망된다. 연구는 더욱 다학제적(interdisciplinary) 성격을 띠며, 컴퓨터 과학, 통계학, 로봇 공학을 넘어 윤리학, 사회학, 인지 과학과의 융합이 가속화될 것이다. 모델의 평가 기준 또한 단순한 정확도를 넘어 공정성, 투명성, 설명가능성, 그리고 ’삭제 가능성(unlearnability)’과 같은 새로운 척도들이 중요해질 것이다. 궁극적으로 AI와 로봇은 가상 세계(메타버스)와 물리적 세계(일상 공간) 양쪽에서 인간과 더욱 긴밀하게 상호작용하며 공생하는 ’체화된 AI(Embodied AI)’로 발전해 나갈 것이다. 이는 IROS 2022의 주제인 ’공생 사회를 위한 체화된 AI(Embodied AI for a Symbiotic Society)’가 정확히 예견한 미래이기도 하다.35</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Influential Machine Learning Papers Of 2022 - Sebastian Raschka, https://sebastianraschka.com/blog/2023/top10-papers-2022.html</li>
<li>[D] The ML Papers That Rocked Our World (2020-2023) : r/MachineLearning - Reddit, https://www.reddit.com/r/MachineLearning/comments/16ij18f/d_the_ml_papers_that_rocked_our_world_20202023/</li>
<li>Top AI and Machine Learning Conferences [2022] - Marketing AI Institute, https://www.marketingaiinstitute.com/blog/marketing-artificial-intelligence-events</li>
<li>Top 9 Machine Learning and AI Conferences in 2022 | PHONEXIA, https://www.phonexia.com/blog/top-8-machine-learning-ai-conferences-in-2022/</li>
<li>[2209.02299] A Survey of Machine Unlearning - arXiv, https://arxiv.org/abs/2209.02299</li>
<li>[2209.00579] Neural Approaches to Co-Optimization in Robotics - arXiv, https://arxiv.org/abs/2209.00579</li>
<li>International Speech Communication Association (ISCA) Products - proceedings.com, https://www.proceedings.com/international-speech-communication-association-isca/</li>
<li>Conference Program - INTERSPEECH 2022, https://www.interspeech2022.org/program/</li>
<li>interspeech 2022 - ISCA Archive, https://www.isca-archive.org/interspeech_2022/interspeech_2022.pdf</li>
<li>Introduction to Three Papers Accepted at INTERSPEECH 2022 - NCsoft, https://about.ncsoft.com/en/news/article/rnd-2022-interspeech-220916</li>
<li>Interspeech 2022 - Apple Machine Learning Research, https://machinelearning.apple.com/updates/apple-at-interspeech-2022</li>
<li>Transfer Learning Framework for Low-Resource Text … - ISCA Archive, https://www.isca-archive.org/interspeech_2022/kim22c_interspeech.pdf</li>
<li>Transfer Learning Framework for Low-Resource Text-to-Speech using a Large-Scale Unlabeled Speech Corpus | Request PDF - ResearchGate, https://www.researchgate.net/publication/363646656_Transfer_Learning_Framework_for_Low-Resource_Text-to-Speech_using_a_Large-Scale_Unlabeled_Speech_Corpus</li>
<li>Best Student Paper Awards - INTERSPEECH 2022, https://www.interspeech2022.org/students/</li>
<li>[2203.15447] Transfer Learning Framework for Low-Resource Text-to-Speech using a Large-Scale Unlabeled Speech Corpus - arXiv, https://arxiv.org/abs/2203.15447</li>
<li>Tree-constrained Pointer Generator with Graph … - ISCA Archive, https://www.isca-archive.org/interspeech_2022/sun22_interspeech.pdf</li>
<li>Brian (Guangzhi) Sun’s Homepage, https://briansidp.github.io/brian-sun.github.io/</li>
<li>Machine Unlearning: The Right to be Forgotten - Kaggle, https://www.kaggle.com/code/tamlhp/machine-unlearning-the-right-to-be-forgotten</li>
<li>A Survey of Machine Unlearning - arXiv, https://arxiv.org/pdf/2209.02299</li>
<li>Machine Unlearning: A Comprehensive Survey - arXiv, https://arxiv.org/html/2405.07406v2</li>
<li>A Survey of Machine Unlearning - arXiv, https://arxiv.org/html/2209.02299v6</li>
<li>Making use of design-aware policy optimization in legged-robotics co-design - OpenReview, https://openreview.net/pdf?id=utaVaqRVO4</li>
<li>Neural Approaches to Co-Optimization in Robotics - ResearchGate, https://www.researchgate.net/publication/363208681_Neural_Approaches_to_Co-Optimization_in_Robotics</li>
<li>AI | September 2022 - Browse Articles - MDPI, https://www.mdpi.com/2673-2688/3/3</li>
<li>Singh research team wins prestigious best paper award at 2022 European Conference on Computer Vision - Biostatistics and Medical Informatics, https://biostat.wiscweb.wisc.edu/2022/10/26/singh-research-team-wins-prestigious-best-paper-award-at-2022-european-conference-on-computer-vision/</li>
<li>[ECCV 2022] [Best Paper] On the Versatile Uses of Partial Distance Correlation in Deep Learning - YouTube, https://www.youtube.com/watch?v=xIeDcih_OdI</li>
<li>On the Versatile Uses of Partial Distance Correlation in Deep Learning, https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136860318.pdf</li>
<li>On the Versatile Uses of Partial Distance Correlation in Deep Learning - ResearchGate, https://www.researchgate.net/publication/364983179_On_the_Versatile_Uses_of_Partial_Distance_Correlation_in_Deep_Learning</li>
<li>On the Versatile Uses of Partial Distance Correlation in Deep Learning - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC10228573/</li>
<li>#IROS2022 best paper awards - Robohub, https://robohub.org/iros2022-best-paper-awards/</li>
<li>Award Winners - IROS 2022, https://iros2022.org/2022/10/30/award-winners/</li>
<li>Research Papers - UC Berkeley’s AUTOLab, https://autolab.berkeley.edu/publications.shtml</li>
<li>SpeedFolding: Learning Efficient Bimanual Folding of Garments - KIT, https://h2t.iar.kit.edu/pdf/Avigal2022.pdf</li>
<li>SpeedFolding: Learning Efficient Bimanual Folding of Garments - Semantic Scholar, https://www.semanticscholar.org/paper/SpeedFolding%3A-Learning-Efficient-Bimanual-Folding-Avigal-Berscheid/2e7cd689fa9df2d0986066d9235c2e8734236851</li>
<li>IROS 2022 – 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems, https://iros2022.org/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>