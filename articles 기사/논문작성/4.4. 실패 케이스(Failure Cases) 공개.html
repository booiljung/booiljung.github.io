<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:4.4. 실패 케이스(Failure Cases) 공개</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>4.4. 실패 케이스(Failure Cases) 공개</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">실전 논문 작성 가이드</a> / <span>4.4. 실패 케이스(Failure Cases) 공개</span></nav>
                </div>
            </header>
            <article>
                <h1>4.4. 실패 케이스(Failure Cases) 공개</h1>
<h2>1.  서론: 학술적 투명성과 실패 공개의 패러다임 전환</h2>
<h3>1.1  완벽주의의 함정과 재현성 위기</h3>
<p>학술 연구, 특히 컴퓨터 과학과 인공지능 분야는 오랫동안 ‘State-of-the-Art (SOTA)’ 성능 달성을 지상 과제로 삼아왔다. 이러한 성과 중심의 문화는 연구자들로 하여금 자신의 방법론이 가진 약점이나 실패 사례를 은폐하고, 특정 벤치마크 데이터셋에서 얻은 최상의 결과만을 선택적으로 보고하게 만드는 압력을 가해왔다. 소위 ’파일 서랍 문제(File Drawer Problem)’라 불리는 이 현상은 실패했거나 통계적으로 유의미하지 않은 결과들이 출판되지 않고 연구자의 서랍 속에 영구히 묻히는 것을 의미한다.1 이는 학계 전체에 심각한 ’생존 편향(Survivorship Bias)’을 야기하여, 후속 연구자들이 동일한 실패를 반복하게 만들고 막대한 시간과 연구 자원을 낭비하게 만드는 주된 원인이 되어왔다.2</p>
<p>그러나 딥러닝 모델의 복잡성이 기하급수적으로 증가하고, 실험 결과의 재현성(Reproducibility) 문제가 심각한 화두로 떠오르면서 학계의 기조는 급격히 변화하고 있다. 연구의 진실성(Integrity)은 이제 단순히 데이터를 조작하지 않는 소극적 윤리를 넘어, 모델이 동작하지 않는 조건과 그 한계를 명확히 밝히는 적극적 투명성을 요구한다.3 완벽해 보이는 논문보다, 솔직하게 한계를 드러낸 논문이 더 신뢰받는 시대가 도래한 것이다. 실패 케이스(Failure Cases)의 공개는 더 이상 논문의 약점이 아니며, 오히려 연구자가 해당 문제를 얼마나 깊이 있게 이해하고 있는지를 증명하는 ’자격 증명서’이자, 독자와 리뷰어에게 신뢰를 구축하는 강력한 전략적 도구로 재정의되고 있다.4</p>
<h3>1.2  주요 학술대회의 정책 변화와 강제성</h3>
<p>이러한 변화를 가장 극명하게 보여주는 것은 NeurIPS, CVPR, ICRA 등 주요 Top-tier 학회들의 투고 규정 변화다. 과거에는 권장 사항에 불과했던 ’한계점 기술’이 이제는 필수적인 심사 요건으로 자리 잡았다.</p>
<p>NeurIPS는 2021년부터 ’논문 체크리스트(Paper Checklist)’를 도입하여, 저자들이 연구의 한계점과 가정(Assumptions)을 명시했는지 공식적으로 묻는다.3 특히 주목해야 할 점은 리뷰어 가이드라인에 “한계점에 대한 정직한 기술을 이유로 논문을 거절해서는 안 된다“고 명시함으로써, 저자들이 불이익에 대한 두려움 없이 실패를 공개할 수 있도록 제도적 장치를 마련했다는 것이다.5 체크리스트에서 한계점에 대해 ’Yes’라고 답하지 않거나, 적절한 설명을 제공하지 않을 경우 데스크 리젝(Desk Reject)의 사유가 될 수 있음을 경고한다.6</p>
<p>컴퓨터 비전 분야의 최고 권위 학회인 CVPR 역시 윤리 가이드라인을 통해 연구의 한계점과 실패 모드(Failure Mode)를 논의할 것을 요구한다. 이는 단순히 모델의 성능 저하를 밝히는 것을 넘어, 데이터셋의 편향성이나 모델의 오작동이 가져올 수 있는 사회적 부정적 영향(Negative Societal Impacts)까지 고려하도록 유도한다.7 예를 들어, 자율주행 모델이 특정 기상 조건에서 실패한다면 이는 단순한 기술적 결함이 아니라 도로 위의 안전을 위협하는 사회적 문제로 직결되기 때문이다.</p>
<p>로보틱스 분야(ICRA, IROS 등)에서는 물리적 환경의 불확실성으로 인해 실패가 빈번하게 발생하므로, ‘실패 감지 및 회복(Failure Detection and Recovery)’ 자체가 하나의 중요한 연구 분야로 다루어진다. 시뮬레이션 환경에서는 성공했지만 실제 환경(Real World)에서는 실패한 사례를 분석하는 ‘Sim-to-Real Gap’ 보고는 로봇 시스템의 견고성(Robustness)을 증명하는 필수적인 과정으로 인식된다.9 따라서 ’실전 논문 작성 가이드’의 독자들에게 섹션 4.4는 선택이 아닌 필수이며, 이를 어떻게 전략적으로 작성하느냐가 논문 채택(Acceptance)의 당락을 가르는 중요한 요소임을 주지시켜야 한다.</p>
<h2>2.  실패 케이스 분석의 이론적 토대와 유형학 (Taxonomy)</h2>
<p>실패 케이스를 효과적으로 작성하기 위해서는 먼저 “우리 모델이 실패했다“라는 단순한 서술을 넘어, 어떤 종류의 실패가 발생했는지 체계적으로 분류하고 명명할 수 있어야 한다. 실패의 유형을 정교하게 분류하는 것(Taxonomy)은 그 자체로 학술적 기여가 되며, 문제 해결의 실마리를 제공한다. 본 보고서에서는 컴퓨터 비전, 로보틱스, 그리고 최근 부상하는 에이전트 AI 시스템의 실패 유형을 심층적으로 분석한다.</p>
<h3>2.1  컴퓨터 비전(Computer Vision) 분야의 실패 유형학</h3>
<p>컴퓨터 비전, 특히 객체 탐지(Object Detection)나 이미지 분류(Classification) 모델의 실패는 단순한 정확도(Accuracy) 수치로 설명되지 않는 다양한 양상을 보인다. 연구자들은 다음과 같은 세부 유형을 통해 실패를 해부해야 한다.11</p>
<h4>2.1.1  분류 및 위치 추정의 불일치 (Classification vs. Localization Error)</h4>
<p>가장 흔한 실패 유형은 모델이 객체의 존재는 인지했지만, 그 속성을 틀리거나 위치를 정밀하게 잡지 못하는 경우다.</p>
<ul>
<li><strong>분류 오류 (Classification Error):</strong> 객체의 위치는 정확히 찾았으나(Intersection over Union, IoU가 임계값 이상), 클래스 라벨을 잘못 예측한 경우다. 예를 들어, ’늑대’를 ’개’로 예측하거나, ’자전거’를 ’오토바이’로 예측하는 사례가 이에 해당한다. 이는 모델이 클래스 간의 미세한 시각적 차이(Inter-class variance)를 학습하지 못했거나, 클래스 간 유사도(Similarity)가 너무 높을 때 발생한다.13</li>
<li><strong>위치 추정 오류 (Localization Error):</strong> 클래스는 정확히 맞췄으나, 바운딩 박스(Bounding Box)의 정확도가 떨어지는 경우다. 객체의 일부분만을 잡거나(Under-segmentation), 배경까지 너무 넓게 잡는(Over-segmentation) 경우가 포함된다. 이는 주로 객체가 서로 겹쳐 있거나(Occlusion), 형태가 비정형적일 때 발생한다.11</li>
<li><strong>중복 탐지 (Duplicate Detection):</strong> 하나의 객체에 대해 여러 개의 바운딩 박스를 예측하는 경우다. 이는 NMS(Non-Maximum Suppression) 알고리즘이 적절히 작동하지 않았거나, 모델이 객체의 부분(Part)을 전체(Whole)로 오인하여 여러 번 탐지했을 때 발생한다.12</li>
</ul>
<h4>2.1.2  허위 경보와 유령 예측 (False Positives &amp; Ghost Predictions)</h4>
<p>모델이 없는 것을 있다고 하거나, 배경을 물체로 착각하는 유형은 시스템의 신뢰도를 치명적으로 떨어뜨린다.</p>
<ul>
<li><strong>배경 혼동 (Background Error):</strong> 아무런 객체가 없는 배경 영역을 특정 클래스로 오인하는 경우다. 예를 들어, 복잡한 무늬의 벽지를 텍스트로 인식하거나, 구름의 그림자를 차량으로 인식하는 사례다. 이는 학습 데이터에 ’배경만 있는 이미지(Negative Samples)’가 부족하여 모델이 배경의 다양성을 충분히 학습하지 못했을 때 주로 발생한다.12</li>
<li><strong>유령 예측 (Ghost Prediction):</strong> 실제로는 존재하지 않는 객체를 높은 확신도(Confidence Score)로 예측하는 현상이다. 이는 데이터셋의 라벨링 오류(Label Noise)나 모델의 과적합(Overfitting)으로 인한 환각(Hallucination) 현상과 관련이 깊다. 특히 최근 연구에 따르면 오픈 데이터셋의 라벨링 오류가 이러한 유령 예측의 주된 원인 중 하나로 지목되고 있다.14</li>
</ul>
<h4>2.1.3  체계적 오류와 편향 (Systematic Errors &amp; Bias)</h4>
<p>무작위적인 노이즈가 아니라, 특정 조건이나 속성 조합에서 일관되게 발생하는 오류는 논문에서 반드시 심도 있게 다뤄야 할 주제다.</p>
<ul>
<li><strong>희소 하위 그룹(Rare Subgroups) 오류:</strong> 데이터셋 내 빈도가 낮은 특정 속성 조합에서 성능이 급격히 떨어지는 현상이다. 예를 들어, 일반적인 ’새’는 잘 인식하지만, 물에 젖은 새나 밤에 찍힌 새는 인식하지 못하는 경우가 이에 해당한다. 이는 데이터 분포의 불균형(Long-tail distribution) 문제를 드러낸다.15</li>
<li><strong>공변량 변화(Covariate Shift) 취약성:</strong> 학습 데이터와 다른 조명, 날씨, 카메라 각도에서 실패하는 경우다. 주간 데이터로 학습한 자율주행 모델이 야간이나 우천 시에 차선을 인식하지 못하는 케이스가 대표적이다.17</li>
</ul>
<h3>2.2  로보틱스(Robotics) 분야의 실패 유형학</h3>
<p>로보틱스 연구는 물리 세계와의 상호작용을 다루므로, 소프트웨어 오류뿐만 아니라 하드웨어, 환경, 그리고 사람과의 상호작용에서 오는 실패를 포괄적으로 다뤄야 한다. ICRA와 IROS 등 로보틱스 학회에서는 다음과 같은 분류 체계를 통해 실패를 보고하는 것을 권장한다.18</p>
<h4>2.2.1  인식 및 센서 실패 (Perception &amp; Sensor Failures)</h4>
<ul>
<li><strong>오인식 (Misidentification):</strong> 물체를 잘못 분류하거나 상태(열림/닫힘, 젖음/마름)를 잘못 파악하여 후속 작업에 영향을 주는 경우다.</li>
<li><strong>센서 노이즈 및 오류 (Sensor Noise/Error):</strong> 라이다(LiDAR)가 유리나 거울 같은 반사 재질(Reflective Surfaces)에서 데이터를 얻지 못하거나, 카메라가 역광(Backlight)으로 인해 화이트아웃(Whiteout)되는 현상이다. 로봇은 잘못된 센서 데이터에 기반해 엉뚱한 판단을 내리게 된다.19</li>
</ul>
<h4>2.2.2  계획 및 실행 실패 (Planning &amp; Execution Failures)</h4>
<ul>
<li><strong>논리적 오류 (Logical Errors):</strong> 작업 순서가 뒤바뀌거나(예: 뚜껑을 열지 않고 물을 따름), 물리적으로 불가능한 경로(Kinematic Singularity)를 생성하여 로봇이 멈추는 경우다.</li>
<li><strong>교착 상태 (Deadlock/Freeze):</strong> 좁은 통로에서 마주 오는 사람이나 로봇을 피하려다 무한히 대기하거나 제자리에서 진동하는 현상이다. 이는 자율 주행 로봇에서 빈번히 발생하는 실패 모드다.21</li>
<li><strong>조작 실패 (Manipulation Failures):</strong> 그리퍼(Gripper)가 물체를 잡았으나 마찰력 부족으로 미끄러지거나(Slippage), 힘 조절 실패로 물체를 부서뜨리는 경우다.</li>
<li><strong>충돌 (Collision):</strong> 계획된 경로를 이동하던 중 예상치 못한 동적 장애물(사람, 동물)과 충돌하거나, 로봇 자신의 팔끼리 충돌(Self-collision)하는 심각한 실패다.</li>
</ul>
<h4>2.2.3  HRI (Human-Robot Interaction) 실패</h4>
<ul>
<li><strong>사회적 규범 위반 (Social Norm Violation):</strong> 로봇이 사람에게 너무 가까이 다가가 불쾌감을 주거나, 사람의 진행 경로를 가로막는 등 ‘사회적으로 어색한’ 행동을 하는 경우다.18</li>
<li><strong>의도 파악 실패 (Misinterpretation):</strong> 사용자의 제스처나 음성 명령의 모호성을 해결하지 못해 엉뚱한 행동을 하는 경우다. 예를 들어 “오른쪽“이라는 말이 로봇 기준인지 사용자 기준인지 헷갈려 실패하는 사례가 있다.22</li>
</ul>
<h3>2.3  에이전트 AI 및 생성형 모델의 실패 유형학</h3>
<p>최근 급부상한 LLM 기반 에이전트 시스템과 생성형 AI는 기존과는 다른 차원의 실패 모드를 보여준다.23</p>
<table><thead><tr><th><strong>실패 유형</strong></th><th><strong>설명</strong></th><th><strong>구체적 사례</strong></th></tr></thead><tbody>
<tr><td><strong>환각 (Hallucination)</strong></td><td>사실이 아닌 정보를 생성하거나 존재하지 않는 객체를 묘사함.</td><td>의료 에이전트가 가짜 치료법을 제안하거나, 비전 모델이 손가락이 6개인 사람을 생성함.</td></tr>
<tr><td><strong>정렬 실패 (Misalignment)</strong></td><td>모델이 사용자의 의도나 안전 가이드라인을 위반함.</td><td>안전 장치를 우회(Jailbreaking)하여 유해한 콘텐츠를 생성하거나, 사용자의 명령을 문자 그대로만 해석하여 의도치 않은 결과를 초래함.</td></tr>
<tr><td><strong>기억 오염 (Memory Poisoning)</strong></td><td>에이전트의 장기 기억에 잘못된 정보가 주입되어 지속적인 오판을 유도함.</td><td>악의적인 사용자가 주입한 거짓 정보가 데이터베이스에 저장되어, 이후 모든 질의응답을 오염시킴.</td></tr>
<tr><td><strong>무한 루프 (Infinite Loops)</strong></td><td>에이전트가 목표를 달성하지 못하고 동일한 행동을 반복함.</td><td>웹 탐색 에이전트가 로그인 페이지와 메인 페이지를 계속 오가며 멈추지 않음.</td></tr>
<tr><td><strong>도구 오용 (Tool Misuse)</strong></td><td>에이전트가 외부 도구(API 등)를 잘못된 파라미터로 호출함.</td><td>검색 API에 쿼리를 잘못 날려 빈 결과를 받거나, 결제 API를 중복 호출함.</td></tr>
</tbody></table>
<h2>3.  실패 케이스 발굴 및 분석 방법론 (Methodology)</h2>
<p>실패 케이스 섹션을 작성하기 위해서는 단순히 “실패했다“는 사실을 기록하는 것을 넘어, “왜 실패했는가“를 과학적으로 규명하는 분석 과정이 선행되어야 한다. 이를 위해 활용할 수 있는 정량적, 정성적 분석 방법론과 최신 도구들을 상세히 조사하였다.</p>
<h3>3.1  정량적 분석 도구: 데이터로 증명하는 실패</h3>
<h4>3.1.1  다중 클래스 혼동 행렬 (Multiclass Confusion Matrix)</h4>
<p>단순한 정확도(Accuracy)나 mAP(mean Average Precision)는 모델의 전반적인 성능만을 보여줄 뿐, 구체적인 약점은 가려버린다. 이를 보완하기 위해 다중 클래스 혼동 행렬을 활용해야 한다.</p>
<ul>
<li><strong>분석 메커니즘:</strong> 행렬의 대각선(Diagonal)은 정답을 맞힌 경우이고, 비대각선(Off-diagonal) 요소들은 오분류 사례다. 여기서 가장 높은 값을 가지는 셀(Cell)을 찾아낸다. 이것이 모델이 가장 헷갈려하는 ’취약 지점’이다.</li>
<li><strong>인사이트 도출:</strong> 예를 들어 “Pedestrian” 클래스가 “Cyclist” 클래스로 오분류되는 빈도가 높다면, 이는 자전거 옆에 서 있는 사람을 자전거 탑승자로 인식하는 ’맥락적 편향(Contextual Bias)’이 모델 내에 존재함을 정량적으로 보여주는 증거가 된다.13</li>
</ul>
<h4>3.1.2  위험 점수 및 불확실성 추정 (Risk Scoring &amp; Uncertainty Estimation)</h4>
<p>성공과 실패의 이분법적 분류를 넘어, 모델이 얼마나 불안정했는지를 연속적인 수치로 분석한다.</p>
<ul>
<li><strong>엔트로피 분석 (Entropy Analysis):</strong> 모델의 출력 확률 분포(Softmax output)의 엔트로피를 계산한다. 엔트로피가 높다는 것은 모델이 정답을 확신하지 못하고 여러 클래스 사이에서 고민했다는 뜻이다. 실패한 샘플들의 엔트로피 분포를 분석하면, 모델이 ’아는 것과 모르는 것’을 구분하고 있는지(Calibration)를 평가할 수 있다.25</li>
<li><strong>위험도 예측 (Risk Prediction):</strong> 로보틱스에서는 현재의 상태(State)와 센서 데이터를 기반으로 미래의 실패 확률을 예측하는 별도의 모델을 학습시키기도 한다. 이 위험 점수가 임계값을 넘는 순간을 포착하여 실패의 전조 증상을 분석한다.26</li>
</ul>
<h4>3.1.3  속성별 성능 분석 (Attribute-based Analysis)</h4>
<p>데이터셋의 메타데이터를 활용하여 다양한 조건에 따른 성능 변화를 분석한다.</p>
<ul>
<li><strong>크기별 분석:</strong> 객체의 픽셀 크기(Small, Medium, Large)에 따른 정확도 변화를 그래프로 그린다. 작은 객체에서 성능이 급감한다면 해상도 문제나 특징 소실 문제를 지적할 수 있다.11</li>
<li><strong>환경 변수별 분석:</strong> 조도(Lux), 날씨, 가려짐(Occlusion) 정도 등 환경 변수에 따른 성능 저하를 분석하여, 모델이 특정 환경(Domain)에 취약함을 드러낸다.</li>
</ul>
<h3>3.2  정성적 분석 및 시각화 기법: 실패를 보여주는 기술</h3>
<p>독자와 리뷰어에게 실패의 원인을 직관적으로 전달하기 위해서는 강력한 시각화가 필수적이다. ‘Distill.pub’ 스타일의 시각화 기법은 훌륭한 벤치마킹 대상이다.27</p>
<h4>3.2.1  특징 시각화 및 Saliency Map</h4>
<p>모델이 오답을 낼 때 ’어디를 보고 있었는지’를 시각화하는 것은 가장 설득력 있는 분석 도구다.</p>
<ul>
<li><strong>Saliency Maps (Grad-CAM 등):</strong> 모델이 ’늑대’를 ’개’로 오인했을 때, 이미지의 배경(눈밭)에 높은 활성화(Activation)가 나타난다면, 이는 모델이 객체 자체가 아니라 배경의 상관관계(Spurious Correlation)를 학습했음을 보여주는 결정적 증거다.28</li>
<li><strong>특징 역연산 (Feature Inversion):</strong> HOG(Histogram of Oriented Gradients)와 같은 특징 벡터를 역으로 이미지로 복원해본다. 모델이 ’자동차’라고 오탐지한 영역을 복원했을 때, 인간의 눈에는 자동차가 아니지만 모델의 특징 공간에서는 자동차와 매우 유사한 패턴을 가짐을 보여줌으로써, 모델의 시각적 착시를 설명할 수 있다.29</li>
</ul>
<h4>3.2.2  실패 시나리오 재구성 (Reconstructing Failure Scenarios)</h4>
<p>로보틱스나 에이전트 시스템처럼 시간의 흐름이 있는 경우, 정지 영상 하나로는 부족하다.</p>
<ul>
<li><strong>타임라인 시각화:</strong> 실패 시점(t)뿐만 아니라 그 전조가 나타난 시점(t-k)부터의 과정을 타임라인으로 시각화한다. 센서 데이터의 급격한 변동, 가치 함수(Value Function)의 하락, 에이전트의 잘못된 행동 선택 순간을 스냅샷으로 나열하여 인과관계를 스토리텔링한다.26</li>
<li><strong>가상 환경 시뮬레이션 (Simulation Replay):</strong> 실제 환경에서의 모호한 실패를 시뮬레이터에서 재현한다. 조명, 마찰력 등의 변수를 하나씩 통제하며(Ablation Study), 실패를 유발하는 결정적 원인(Root Cause)을 찾아내는 과정을 보여준다.9</li>
</ul>
<h3>3.3  자동화된 실패 감지 및 분석 프레임워크</h3>
<p>최근 연구들은 사람의 개입 없이도 실패 케이스를 자동으로 찾아주는 도구들을 제안하고 있다. 논문 작성 시 이러한 도구를 사용했음을 명시하면 분석의 객관성과 체계성을 인정받을 수 있다.</p>
<ul>
<li><strong>RoboFail:</strong> 강화학습을 통해 로봇 정책(Policy)이 실패하는 적대적(Adversarial) 시나리오를 능동적으로 생성하고 탐색하는 프레임워크다. 이를 통해 연구자가 미처 생각하지 못한 기상천외한 ’코너 케이스(Corner Cases)’를 발굴할 수 있다.19</li>
<li><strong>Training De-Confusion:</strong> 분류기의 반응을 기반으로 라벨 오류나 혼동하기 쉬운 샘플을 자동으로 감지하고 시각화하여 사용자가 수정할 수 있게 돕는 인터랙티브 시스템이다.31</li>
<li><strong>SCROD Pipeline:</strong> 생성형 AI(Stable Diffusion 등)를 활용하여 객체의 포즈, 배경, 조명 등을 체계적으로 변화시키며 모델의 약점이 드러나는 조건을 자동으로 탐색하는 파이프라인이다.16</li>
</ul>
<h2>4.  실전 작성 가이드: 실패 케이스를 논문의 강점으로 승화시키는 전략</h2>
<p>수집된 실패 데이터와 분석 결과를 논문에 어떻게 녹여내야 하는가? 이는 단순한 사실의 나열이 아니라, ’방어적 글쓰기(Defensive Writing)’와 ‘과학적 정직성(Scientific Honesty)’ 사이의 균형을 맞추는 고도의 수사학적 작업이다.</p>
<h3>4.1  섹션 배치 전략 (Where to put it?)</h3>
<p>실패 케이스 내용은 논문의 흐름에 따라 적절한 위치에 배치되어야 하며, 각 위치마다 노리는 효과가 다르다.</p>
<ol>
<li><strong>실험(Experiments) 섹션의 하위 섹션 (예: 4.4 Failure Analysis):</strong> 가장 일반적이고 추천되는 위치다. 정량적 결과(표) 뒤에 정성적 분석(Qualitative Analysis)의 일환으로 배치한다. 높은 성능 수치 뒤에 “그럼에도 불구하고 여전히 남은 과제“를 보여줌으로써, 수치 뒤에 숨겨진 모델의 실제 동작 특성을 깊이 있게 설명한다. 이는 리뷰어에게 “이 저자는 결과만 좋게 포장하지 않고 깊이 파고들었구나“라는 인상을 준다.</li>
<li><strong>토의(Discussion) 및 한계(Limitations) 섹션:</strong> 논문의 결론 직전에 배치하여, 연구 결과를 종합적으로 회고하고 향후 연구 방향(Future Work)과 연결하는 다리 역할을 한다. 연구의 범위(Scope)를 명확히 하고, 독자들의 과도한 기대치를 조절하는 데 효과적이다.32</li>
<li><strong>부록(Appendix):</strong> 지면의 제약(Page Limit)이 있는 경우, 본문에는 대표적인 체계적 실패 사례 1~2개와 요약된 통찰만을 싣고, 상세한 실패 갤러리(Failure Gallery)와 추가 분석 차트는 부록으로 넘긴다. NeurIPS 등에서는 부록 활용을 적극 권장하며, 이는 논문의 밀도를 높이면서도 투명성을 잃지 않는 좋은 전략이다.3</li>
</ol>
<h3>4.2  작성 구조: “발표 - 성찰 - 전망” (The Three-Move Structure)</h3>
<p>성공적인 실패 케이스 기술은 무작위적인 나열이 아니라, 논리적인 3단계 구조를 따른다.34 이 구조를 활용하면 실패 고백이 건설적인 제안으로 바뀐다.</p>
<ol>
<li><strong>발표 (Announcing):</strong> 실패의 존재를 명확하고 객관적으로 인정한다. 여기서 비겁한 변명이나 모호한 표현은 금물이다.</li>
</ol>
<ul>
<li><em>나쁜 예:</em> “데이터가 좀 이상해서 가끔 안 될 때가 있다.” (모호함)</li>
<li><em>좋은 예:</em> “전반적인 성능 향상에도 불구하고, 본 모델은 저조도 환경의 30픽셀 이하 작은 객체에 대해 탐지율이 현저히 저하되는 현상이 관찰되었다(Fig. 5).” (구체적 조건 명시)</li>
</ul>
<ol start="2">
<li><strong>성찰 (Reflecting):</strong> 왜 실패했는지 그 원인을 심층적으로 분석한다. 여기서 연구자의 통찰력이 드러난다. 단순히 “어렵다“가 아니라, 기술적/구조적 원인을 지목해야 한다.</li>
</ol>
<ul>
<li><em>분석 예:</em> “이러한 체계적 오류는 인코더의 다운샘플링 연산 과정에서 고주파수 공간 정보가 소실되었기 때문으로 분석된다. 또한, 학습 데이터의 80%가 주간 이미지로 구성된 데이터 불균형 문제도 기여했을 것으로 판단된다.”</li>
</ul>
<ol start="3">
<li><strong>전망 (Forward Looking):</strong> 이 실패가 미래 연구에 어떤 기회를 제공하는지, 또는 현재 상태에서 어떻게 완화(Mitigate)될 수 있는지 제안한다. 이는 실패를 ’미해결 과제’로 프레이밍하여 논문의 가치를 미래로 확장시킨다.</li>
</ol>
<ul>
<li><em>제안 예:</em> “향후 연구에서는 해상도 손실 없이 수용 영역을 유지하기 위해 Dilated Convolution을 도입하거나, 야간 데이터 증강 기법을 적용하여 이 한계를 해결할 수 있을 것이다.”</li>
</ul>
<h3>4.3  학술적 표현 가이드 (Academic Phrasebank)</h3>
<p>영어 논문 작성 시 유용하게 사용할 수 있는, ’해라체’로 번역된 표준 표현들을 정리한다.35</p>
<p><strong>한계 인정 (Acknowledging Limitations):</strong></p>
<ul>
<li>“본 연구의 결과는 몇 가지 한계점을 고려하여 해석되어야 한다.” (The findings of this study have to be seen in light of some limitations.)</li>
<li>“이 접근법의 잠재적 약점은 ~이다.” (A potential weakness of this approach is…)</li>
<li>“가장 빈번하게 관찰된 실패 유형은 ~였다.” (The most frequently observed failure mode was…)</li>
<li>“비록 SOTA 성능을 달성했지만, 여전히 ~와 같은 코너 케이스에서는 취약점을 보인다.” (Although achieving SOTA performance, the model still exhibits vulnerabilities in corner cases such as…)</li>
</ul>
<p><strong>원인 분석 (Analyzing Causes):</strong></p>
<ul>
<li>“이러한 오류는 ~에 기인했을 가능성이 높다.” (This error is likely attributed to…)</li>
<li>“정성적 분석 결과, 모델이 ~에 과도하게 의존하는 경향이 있음이 드러났다.” (Qualitative analysis reveals that the model tends to rely heavily on…)</li>
<li>“혼동 행렬을 자세히 살펴보면(Close inspection of the confusion matrix shows), A와 B 클래스 간의 상당한 오분류가 존재함을 알 수 있다.”</li>
<li>“이는 데이터셋 자체의 라벨링 노이즈에 기인한 것으로 보인다.” (This appears to be due to label noise inherent in the dataset.)</li>
</ul>
<p><strong>미래 연결 (Future Directions):</strong></p>
<ul>
<li>“이러한 코너 케이스를 해결하는 것은 향후 연구의 흥미로운 주제가 될 것이다.” (Addressing these corner cases would be an interesting avenue for future research.)</li>
<li>“~를 통해 이 문제를 완화할 수 있을 것으로 기대된다.” (It is expected that ~ could mitigate this issue.)</li>
<li>“이 한계를 극복하기 위해 추가적인 센서 융합이 필요할 수 있다.” (Overcoming this limitation may require additional sensor fusion.)</li>
</ul>
<h3>4.4  리뷰어 심리를 고려한 ‘방어적’ 기술 전략</h3>
<p>리뷰어들은 본능적으로 논문의 약점을 찾아내어 거절(Reject) 사유로 삼으려는 경향이 있다. 따라서 실패 케이스를 공개할 때는 이것이 ’치명적인 결함(Fatal Flaw)’이 아니라 ’연구의 범위(Scope) 밖’이거나 ’해결 가능한 과제’임을 명확히 프레이밍(Framing)해야 한다.38</p>
<ul>
<li><strong>솔직하되, 비굴하지 않게:</strong> “우리 모델은 형편없다“가 아니라 “특정 극한 조건(Extreme Condition)에서 성능 저하가 관찰된다“고 기술한다. 실패의 조건을 한정 짓는 것(Scoping)이 중요하다.</li>
<li><strong>비교 우위 강조 (Comparative Defense):</strong> 경쟁 모델(Baseline)들도 동일한 조건에서 실패함을 보여주면, 이것이 내 모델만의 문제가 아니라 해당 Task 자체의 본질적 난이도(Intrinsic Difficulty) 때문임을 어필할 수 있다.</li>
<li><em>전략:</em> “흥미롭게도, SOTA 모델인 X 또한 동일한 샘플에 대해 실패하였으며, 이는 해당 데이터 샘플 자체가 시각적으로 구분이 불가능한 모호성을 가지고 있음을 시사한다.” 14</li>
<li><strong>사소한 실패와 체계적 실패의 구분:</strong> 모든 실패를 나열할 필요는 없다. 논문의 결론을 뒤집지 않는 선에서, 독자에게 통찰력을 줄 수 있는 ‘체계적 실패(Systematic Failure)’ 위주로 선별하여 기술한다.32</li>
</ul>
<h2>5.  주요 분야별 실패 케이스 작성 사례 연구 (Case Studies)</h2>
<p>이론적 내용을 실제 논문에 적용했을 때 어떤 모습이어야 하는지, 각 분야별 가상의 논문 섹션을 통해 구체적으로 예시한다.</p>
<h3>5.1  사례 1: 자율주행 객체 탐지 논문 (Computer Vision)</h3>
<p><strong>상황:</strong> 제안한 모델이 야간 자율주행 데이터셋에서 전반적으로 우수한 성능을 보였으나, 특정 조건의 보행자 탐지에 실패함.</p>
<blockquote>
<p><strong>4.4. 실패 분석 및 한계 (Failure Analysis &amp; Limitations)</strong></p>
<p>전반적인 성능 우위(Table 1)에도 불구하고, 본 연구의 모델은 저조도 환경(Low-light conditions)에서 보행자에 대한 미탐지(False Negative) 사례가 간헐적으로 관찰되었다(Fig. 5 참조). 특히 가로등이 없는 비포장도로에서 검은 옷을 입은 보행자를 탐지하는 데 실패하는 경향이 있었다.</p>
<p><strong>원인 분석:</strong> Grad-CAM 시각화 결과, 모델은 보행자의 형상보다는 가로등이나 차량 전조등과 같은 광원(Light Source) 위치에 높은 활성화를 보였다. 이는 학습 데이터의 80%가 도심의 밝은 환경에서 수집된 이미지로 구성된 데이터 불균형(Data Imbalance)과, 야간 이미지 특유의 낮은 대비(Contrast)가 객체의 경계선 검출을 저해했기 때문으로 분석된다. 또한, Fig. 6의 속성별 오차 분석(Attribute-based Error Analysis)에 따르면, 30픽셀 이하의 작은 객체에서 오류율이 급증하는데, 이는 특징 피라미드(Feature Pyramid)의 최상위 레벨에서 소형 객체의 공간 정보가 소실되는 현상과 일치한다.</p>
<p><strong>향후 전망:</strong> 이러한 한계는 야간 데이터 증강(Augmentation) 기법을 적용하거나, 소형 객체 탐지에 특화된 고해상도 특징 맵을 유지하는 아키텍처 개선을 통해 완화될 수 있을 것이다. 또한, 열화상 카메라(Thermal Camera)와 같은 이종 센서와의 융합은 조명 조건에 강건한 탐지를 가능케 할 유망한 후속 연구 방향이다.</p>
</blockquote>
<h3>5.2  사례 2: 로봇 매니퓰레이션 논문 (Robotics)</h3>
<p><strong>상황:</strong> 로봇 팔이 물체를 잡고 이동하는 작업에서 간헐적으로 물체를 놓치는 실패 발생.</p>
<blockquote>
<p><strong>4.4. 실패 모드 및 시스템 견고성 (Failure Modes &amp; System Robustness)</strong></p>
<p>총 100회의 물리적 파지(Grasping) 및 이동 실험 중 12회의 실패가 발생했다. 실패 유형을 체계적으로 분류한 결과(Table 2), ’미끄러짐(Slippage)’이 8건으로 가장 많았으며, ’경로 계획 오류’가 4건이었다.</p>
<p><strong>심층 분석:</strong> 타임라인 분석(Fig. 8)에 따르면, 미끄러짐은 주로 표면 마찰계수가 낮은 금속 물체나 젖은 물체를 파지할 때 발생했다. 이는 현재의 시각 기반(Vision-based) 정책이 물체의 물리적 재질(Material Property)이나 마찰력을 사전에 완벽히 추정하지 못함을 시사한다. 특히 투명한 유리잔의 경우, 깊이 카메라(Depth Camera)의 반사 노이즈로 인해 위치 추정 오차가 발생하여 그리퍼가 물체에 닿기도 전에 닫히거나 충돌(Collision)하는 사례가 관찰되었다.</p>
<p><strong>개선 방향:</strong> 본 실험 결과는 시각 정보만으로는 복잡한 물리적 상호작용을 완벽히 제어하기 어렵다는 점을 보여준다. 그리퍼 끝단에 장착된 촉각 센서(Tactile Sensor)를 통해 미끄러짐을 실시간으로 감지하고 파지력을 조절하는 폐루프(Closed-loop) 제어 방식을 도입한다면, 이러한 실패를 획기적으로 줄일 수 있을 것으로 기대된다.</p>
</blockquote>
<h3>5.3  사례 3: 의료 진단 보조 AI 에이전트 논문 (Agentic AI)</h3>
<p><strong>상황:</strong> 의료 문헌을 검색하여 진단을 보조하는 LLM 에이전트가 가끔 존재하지 않는 논문을 인용하거나 잘못된 의학 정보를 생성함.</p>
<blockquote>
<p><strong>4.4. 환각 및 안전성 분석 (Hallucination &amp; Safety Analysis)</strong></p>
<p>제안된 에이전트는 진단 정확도 면에서 전문의 수준에 근접했으나, 사실성 검증(Factuality) 측면에서 두 가지 주요 실패 유형을 보였다. 첫째, 존재하지 않는 참고문헌을 생성하는 ’인용 환각(Citation Hallucination)’이 전체 응답의 2%에서 발생했다. 둘째, 드물지만 상충되는 두 가지 의학적 소견을 논리적 모순 없이 결합하려다 부정확한 결론을 도출하는 ’논리적 오류’가 관찰되었다.</p>
<p><strong>위험 평가:</strong> 이러한 환각 현상은 학습 데이터에 포함된 인터넷 상의 비전문적 의료 정보나, 모델의 다음 토큰 예측(Next-token prediction) 방식의 본질적 한계에서 기인한다. 특히 희귀 질환(Rare Disease)에 대한 질의에서 이러한 경향이 두드러졌다. 이는 실제 임상 현장에서 심각한 안전 문제를 야기할 수 있다.</p>
<p><strong>완화 전략:</strong> 이를 해결하기 위해 본 연구에서는 검색 증강 생성(RAG) 기법을 도입하여 신뢰할 수 있는 의학 데이터베이스 내에서만 답변을 생성하도록 제한하였다. 그럼에도 불구하고 남은 오류에 대해서는, “의사결정 보조 도구일 뿐 최종 판단은 인간 의사가 해야 한다“는 명확한 안전 가이드라인(Safety Guideline)과 함께 사용되어야 함을 강조한다.</p>
</blockquote>
<h2>6.  결론: 실패는 연구의 ’영혼’이다</h2>
<p>본 심층 조사를 통해 우리는 실패 케이스 공개가 단순한 ’양심 고백’을 넘어, 학술적 성과를 완성하는 핵심 요소임을 확인했다. 4.4 섹션은 연구자가 자신의 연구를 얼마나 객관적으로 바라볼 수 있는지, 그리고 그 한계를 넘어설 비전을 가지고 있는지를 증명하는 공간이다.</p>
<p>가이드북 작성 시 독자들에게 강조해야 할 핵심 메시지는 다음과 같다:</p>
<ol>
<li><strong>두려워하지 마라:</strong> 실패를 숨기려다 들키면 ’게재 거절(Reject)’되지만, 먼저 드러내고 분석하면 ’솔직하고 통찰력 있는 연구’로 ’게재 승인(Accept)’될 확률이 높아진다.</li>
<li><strong>분석하라:</strong> “안 됐다“고 끝내지 말고, “왜 안 됐는지“를 데이터와 시각화로 증명하라. 분류(Taxonomy)하고, 측정(Measure)하고, 보여주어라(Visualize).</li>
<li><strong>제안하라:</strong> 실패를 미래의 연구 주제로 연결하여, 후속 연구자들에게 길을 제시하라.</li>
</ol>
<p>이 보고서의 가이드라인을 따른다면, ’실전 논문 작성 가이드’의 독자들은 자신의 실패를 가장 빛나는 학술적 기여로 바꿀 수 있는 강력한 무기를 손에 쥐게 될 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Why Should Negative Results Be Published? - Enago Academy, https://www.enago.com/academy/why-should-negative-results-be-published/</li>
<li>Experts’ Take: Why Is It Important to Publish Negative Results - Enago, https://www.enago.com/academy/why-it-is-important-to-publish-negative-results/</li>
<li>NeurIPS Paper Checklist Guidelines, https://neurips.cc/public/guides/PaperChecklist</li>
<li>12월 16, 2025에 액세스, [https://www.enago.com/academy/why-should-negative-results-be-published/#:<sub>:text=Preventing%20Wasted%20Effort,compound%20reported%20in%20the%20literature.](https://www.enago.com/academy/why-should-negative-results-be-published/#:</sub>:text=Preventing Wasted Effort, <a href="https://www.enago.com/academy/why-should-negative-results-be-published/#:~:text=Preventing%20Wasted%20Effort,compound%20reported%20in%20the%20literature.">https://www.enago.com/academy/why-should-negative-results-be-published/#:~:text=Preventing%20Wasted%20Effort,compound%20reported%20in%20the%20literature.</a></li>
<li>NeurIPS Paper Checklist - arXiv, https://arxiv.org/html/2505.04037v1</li>
<li>NeurIPS 2025 FAQ for Authors, https://neurips.cc/Conferences/2025/PaperInformation/NeurIPS-FAQ</li>
<li>CVPR 2026 Author Guidelines - The Computer Vision Foundation, https://cvpr.thecvf.com/Conferences/2026/AuthorGuidelines</li>
<li>2025 Ethics Guidelines - CVPR, https://cvpr.thecvf.com/Conferences/2025/EthicsGuidelines</li>
<li>Robotic malfunction checklist: a guide to operating room safety …, https://pubmed.ncbi.nlm.nih.gov/40696214/</li>
<li>Call for papers - GitHub Pages, https://robot-failures.github.io/icra2023/call-for-papers/</li>
<li>Error Analysis of Object Detection Models, https://ir.library.oregonstate.edu/downloads/w0892k13w</li>
<li>Error analysis for object detection models | by Bernat Puig Camps, https://medium.com/data-science-at-microsoft/error-analysis-for-object-detection-models-338cb6534051</li>
<li>Multiclass Confusion Matrix for Object Detection - Tenyks, https://www.tenyks.ai/blog/multiclass-confusion-matrix-for-object-detection</li>
<li>I performed Error Analysis on Open Images and now I have trust …, https://towardsdatascience.com/i-performed-error-analysis-on-open-images-and-now-i-have-trust-issues-89080e03ba09/</li>
<li>Identification of Systematic Errors of Image Classifiers on Rare …, https://openaccess.thecvf.com/content/ICCV2023/papers/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.pdf</li>
<li>Identifying Systematic Errors in Object Detectors with the SCROD …, https://openaccess.thecvf.com/content/ICCV2023W/BRAVO/papers/Boreiko_Identifying_Systematic_Errors_in_Object_Detectors_with_the_SCROD_Pipeline_ICCVW_2023_paper.pdf</li>
<li>Visualisation of Typical Failure Cases a Small-object detection at …, https://www.researchgate.net/figure/Visualisation-of-Typical-Failure-Cases-a-Small-object-detection-at-long-range-b_fig10_398424573</li>
<li>Taxonomy for Early Safety Analysis of Human-Robot Interaction, https://ceur-ws.org/Vol-4099/forum_paper9.pdf</li>
<li>Language-Driven Semantic Clustering of Failures for Robot Safety, https://arxiv.org/pdf/2506.06570</li>
<li>Extending the function failure modes taxonomy for intelligent …, https://www.cambridge.org/core/journals/proceedings-of-the-design-society/article/extending-the-function-failure-modes-taxonomy-for-intelligent-systems-with-embedded-ai-components/94335963BF0A6F0128774CC477584B80</li>
<li>A Taxonomy of System-Level Attacks on Deep Learning Models in …, https://arxiv.org/html/2412.04510v2</li>
<li>Working with roubles and failures in conversation between humans …, https://pmc.ncbi.nlm.nih.gov/articles/PMC10722147/</li>
<li>Taxonomy of Failure Mode in Agentic AI Systems - Microsoft, https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/final/en-us/microsoft-brand/documents/Taxonomy-of-Failure-Mode-in-Agentic-AI-Systems-Whitepaper.pdf</li>
<li>New whitepaper outlines the taxonomy of failure modes in AI agents, https://www.microsoft.com/en-us/security/blog/2025/04/24/new-whitepaper-outlines-the-taxonomy-of-failure-modes-in-ai-agents/</li>
<li>Texture-Based Error Analysis for Image Super-Resolution, https://openaccess.thecvf.com/content/CVPR2022/papers/Magid_Texture-Based_Error_Analysis_for_Image_Super-Resolution_CVPR_2022_paper.pdf</li>
<li>Identifying Precursors to Failures in Robotic Lift-and-Place Tasks, https://openreview.net/pdf/d39eeefd8e1a2e5604b994c545bb6b6eaf185762.pdf</li>
<li>Distilling Model Failures as Directions in Latent Space, https://gradientscience.org/failure-directions/</li>
<li>Understanding RL Vision - Distill.pub, https://distill.pub/2020/understanding-rl-vision/</li>
<li>Visualizing Object Detection Features, https://www.cs.columbia.edu/~vondrick/ihog/ijcv.pdf</li>
<li>RoboFail: Analyzing Failures in Robot Learning Policies - arXiv, https://arxiv.org/html/2412.02818v1</li>
<li>(PDF) Training De-Confusion: An Interactive, Network-Supported …, https://www.researchgate.net/publication/326928180_Training_De-Confusion_An_Interactive_Network-Supported_Visual_Analysis_System_for_Resolving_Errors_in_Image_Classification_Training_Data</li>
<li>How to Write Study Limitations - Yomu AI, https://www.yomu.ai/blog/how-to-write-study-limitations</li>
<li>Limitations of a Research Study | How to Write &amp; Types - Enago, https://www.enago.com/academy/limitations-of-research-study/</li>
<li>How to structure the Research Limitations section of your dissertation, https://dissertation.laerd.com/how-to-structure-the-research-limitations-section-of-your-dissertation.php</li>
<li>Academic Phrasebank - UFS, https://www.ufs.ac.za/docs/librariesprovider68/resources/academic-writing/academic-phrases.pdf?sfvrsn=b5b86820_2</li>
<li>Mastering Academic Writing Begins with the Right Phrase Bank, https://www.educatly.com/blog/708/mastering-academic-writing-begins-with-the-right-phrase-bank</li>
<li>Writing Conclusions - Academic Phrasebank, https://www.phrasebank.manchester.ac.uk/writing-conclusions/</li>
<li>2025 Reviewer Guidelines - NeurIPS 2025, https://neurips.cc/Conferences/2025/ReviewerGuidelines</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>