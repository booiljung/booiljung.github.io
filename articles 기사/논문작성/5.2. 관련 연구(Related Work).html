<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.2. 관련 연구 (Related Work)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.2. 관련 연구 (Related Work)</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">실전 논문 작성 가이드</a> / <span>5.2. 관련 연구 (Related Work)</span></nav>
                </div>
            </header>
            <article>
                <h1>5.2. 관련 연구 (Related Work)</h1>
<p>논문의 본문에서 ‘관련 연구(Related Work)’ 섹션은 수많은 초보 연구자들이 가장 작성하기 어려워하면서도, 동시에 가장 소홀히 다루는 역설적인 부분이다. 흔히 이 섹션을 단순히 내가 읽은 논문들을 요약하여 나열하는 ‘숙제 검사’ 혹은 ‘참고문헌 리스트의 확장판’ 정도로 여기는 경향이 짙다. 그러나 탑 티어 컨퍼런스(CVPR, NeurIPS, ICRA, IROS 등)의 리뷰어들에게 관련 연구 섹션은 <strong>저자의 학문적 깊이(Depth), 연구의 위치(Positioning), 그리고 해당 분야에 대한 통찰(Insight)을 평가하는 리트머스 시험지</strong>와 같다.</p>
<p>이 장에서는 관련 연구 섹션을 단순한 선행 연구의 나열이 아닌, 내 연구의 독창성을 빛내기 위한 전략적 요충지로 활용하는 방법을 극도로 상세하게 기술한다. 인공지능(AI)과 로보틱스 분야의 특성을 고려하여, 방대한 문헌의 홍수 속에서 내 연구의 좌표를 설정하고, 경쟁자들과의 차별점을 논리적으로 전개하는 ’학술적 스토리텔링’의 정수를 다룬다.</p>
<h2>1.  관련 연구의 본질: 학술적 법정에서의 증거 제출</h2>
<p>관련 연구 섹션의 근본적인 목적은 “나는 이 분야의 논문을 이만큼 많이 읽었다“를 과시하는 것이 아니다. 이 섹션의 진정한 목적은 독자(특히 까다로운 리뷰어)에게 **“이 문제는 아직 완전히 해결되지 않았으며, 기존의 방법들은 A, B, C와 같은 명확한 한계가 존재하기에, 내 연구가 반드시 필요하다”**는 사실을 설득하는 데 있다.1 즉, 관련 연구는 내 연구의 기여점(Contribution)을 정당화하기 위해 학술적 법정에 제출하는 논리적 증거물이다.</p>
<ol>
<li>지식의 지도(Map of Knowledge)와 영토 확장</li>
</ol>
<p>성공적인 관련 연구는 해당 분야의 ’지식 지도’를 독자에게 제공하는 것과 같다. 독자가 저자가 그려준 이 지도를 따라가다 보면, 자연스럽게 기존 연구들이 도달하지 못한 ’빈 영토(Gap)’를 발견하게 되고, 그 빈 곳을 채우는 것이 바로 저자의 제안 방법임을 깨닫게 해야 한다. 이를 위해서는 개별 논문을 파편적으로 요약하는 것이 아니라, 연구의 흐름(Flow)과 맥락(Context)을 중심으로 문단을 구성해야 한다. 마치 대동여지도를 그리듯, 기존 연구들의 위치를 정확히 표기하고 내 연구가 점령할 새로운 좌표를 명시하는 작업이다.</p>
<ol start="2">
<li>리뷰어의 심리: “내가 아는 것을 너도 아는가?”</li>
</ol>
<p>리뷰어는 논문을 잡자마자 초록(Abstract)을 읽고, 곧바로 관련 연구 섹션으로 넘어가는 경우가 많다. 이는 일종의 ’제정신 체크(Sanity Check)’이다. 리뷰어는 자신이 해당 분야의 전문가라고 생각하며, 자신이 중요하다고 여기는 핵심 논문(Key Papers)들이 인용되었는지 확인한다. 만약 이 분야의 바이블과도 같은 논문이 빠져 있다면, 리뷰어는 저자의 전문성을 의심하기 시작하며 이후의 방법론이나 실험 결과조차 신뢰하지 않게 된다. 또한, 리뷰어들은 본능적으로 자신의 논문이 인용되었는지를 확인하는 경향이 있다. 이는 단순한 자존심의 문제가 아니라, 자신의 연구 흐름을 저자가 파악하고 있는지를 보는 것이다. 따라서 적절하고 폭넓은 인용은 리뷰어와의 심리적 유대감을 형성하는 첫 단추다.</p>
<h2>2.  ’세탁물 목록(Laundry List)’의 함정과 서사적 변환</h2>
<p>초보 연구자가 범하는 가장 치명적이고 흔한 실수는 이른바 ‘세탁물 목록(Laundry List)’ 방식의 서술이다.5 이는 마치 세탁 바구니에서 옷을 하나씩 꺼내어 보여주듯, “A는 X를 했다. B는 Y를 했다. C는 Z를 했다“와 같이 주어만 바꾸어가며 문장을 기계적으로 나열하는 방식이다.</p>
<ol>
<li>세탁물 목록 스타일의 문제점</li>
</ol>
<p>이러한 서술은 각 연구 간의 유기적인 관계나 발전 과정을 전혀 보여주지 못한다. 독자는 “그래서 어쩌라는 것인가?“라는 질문을 던지게 된다. 왜 이 논문들이 인용되었는지, 그리고 이들이 저자의 연구와 무슨 상관인지 알 수 없기 때문이다. 이는 논문의 가독성을 떨어뜨릴 뿐만 아니라, 저자가 해당 분야의 흐름을 꿰뚫고 있지 못하고 단순히 검색된 논문을 요약만 했다는 인상을 준다.7</p>
<table><thead><tr><th><strong>특성</strong></th><th><strong>세탁물 목록 (Laundry List)</strong></th><th><strong>서사적 흐름 (Narrative Flow)</strong></th></tr></thead><tbody>
<tr><td><strong>주어</strong></td><td>연구자 이름 (Kim et al., Lee et al.)</td><td>연구 주제, 개념, 접근 방식 (Approaches, Recent methods)</td></tr>
<tr><td><strong>연결</strong></td><td>단순 나열 (Also, In addition)</td><td>논리적 연결 (However, In contrast, Despite)</td></tr>
<tr><td><strong>초점</strong></td><td>개별 논문의 요약</td><td>연구 흐름의 진화와 한계점 도출</td></tr>
<tr><td><strong>독자 반응</strong></td><td>“지루하다, 관련성을 모르겠다”</td><td>“이 분야의 역사가 이렇게 흘러왔구나”</td></tr>
<tr><td><strong>목적</strong></td><td>참고문헌 채우기</td><td>연구의 필요성(Gap) 증명</td></tr>
</tbody></table>
<p><strong>2) 나쁜 예시 (The Laundry List)</strong></p>
<blockquote>
<p>“Kim et al. 은 CNN을 사용해 객체를 검출하는 방법을 제안했다. 그들은 VGG 백본을 사용했다. Lee et al. 는 Transformer를 객체 검출에 도입했다. 이 방법은 정확도가 높았다. Park et al. 은 데이터 증강 기법을 사용하여 성능을 올렸다. Chen et al. 는 경량화 모델을 만들었다.”</p>
</blockquote>
<p><strong>3) 좋은 예시 (Narrative Transformation)</strong></p>
<blockquote>
<p>“객체 검출(Object Detection) 분야는 초기 <strong>CNN 기반의 접근법</strong> 에서 시작하여, 최근에는 전역적인 문맥(Global Context)을 포착하기 위한 <strong>Transformer 기반의 구조</strong> 로 패러다임이 전환되고 있다. Transformer 기반 모델들은 높은 정확도를 달성했으나, 방대한 연산량으로 인해 실시간 처리가 어렵다는 단점이 존재했다. 이를 보완하기 위해 <strong>데이터 증강</strong> 이나 <strong>모델 경량화</strong> 와 같은 시도들이 있었으나, 여전히 복잡한 도심 환경에서의 소형 객체 검출 성능은 획기적으로 개선되지 못했다. 본 연구에서는…”</p>
</blockquote>
<p>위의 ’좋은 예시’에서는 개별 연구자(Kim, Lee 등)가 주어가 되는 대신, 기술의 흐름(CNN -&gt; Transformer -&gt; 한계 극복 시도)이 주가 되었다. 인용은 문장의 끝에 자연스럽게 붙어 증거 역할을 수행한다. 이렇게 작성해야 독자는 기존 연구의 한계(소형 객체 검출 부진)를 자연스럽게 받아들이고, 저자의 제안 방법론을 기대하게 된다.6</p>
<h2>3.  분류학(Taxonomy) 구축: 내 연구를 돋보이게 하는 카테고리화</h2>
<p>수백, 수천 편의 논문이 쏟아지는 AI/로보틱스 분야에서 모든 관련 논문을 다룰 수는 없다. 따라서 내 연구의 관점에서 기존 연구들을 분류(Grouping)하고 구조화하는 작업이 선행되어야 한다. 이를 ’분류학(Taxonomy) 구축’이라 하며, 이를 통해 연구자는 해당 분야를 장악하고 있다는 인상을 줄 수 있다.2</p>
<ol>
<li>전략적 분류 기준 설정</li>
</ol>
<p>기존 연구를 분류하는 기준은 절대적이지 않다. 내 연구의 강점을 가장 잘 부각할 수 있는 기준을 선택해야 한다.</p>
<ul>
<li><strong>문제 해결 방식(Approach)에 따른 분류:</strong></li>
<li><em>예:</em> 기하학적 기반(Geometric-based) vs. 학습 기반(Learning-based)</li>
<li><em>전략:</em> 내가 학습 기반의 새로운 방법을 제안한다면, 기하학적 방법의 한계(특징점 추출 실패 등)를 지적하고, 기존 학습 기반 방법의 데이터 의존성을 비판하는 구조를 취한다.</li>
<li><strong>입력 데이터(Modality)에 따른 분류:</strong></li>
<li><em>예:</em> LiDAR 중심 vs. 카메라 중심 vs. 센서 퓨전</li>
<li><em>전략:</em> 내가 카메라 만을 이용한(Vision-only) 방법을 제안한다면, LiDAR의 높은 비용과 퓨전의 복잡성을 지적하며 ‘저비용 고효율’ 프레임워크의 필요성을 강조한다.</li>
<li><strong>알고리즘 구조(Architecture)에 따른 분류:</strong></li>
<li><em>예:</em> One-stage Detector vs. Two-stage Detector</li>
<li><em>전략:</em> 속도가 중요한 로보틱스 어플리케이션을 타겟팅한다면, Two-stage의 느린 속도를 비판하고 One-stage의 정확도 저하 문제를 언급한 뒤, 내 연구가 ’속도와 정확도의 균형’을 맞췄음을 주장한다.</li>
<li>계층적 구조화 (Hierarchical Structuring)</li>
</ul>
<p>관련 연구 섹션은 통상 2~3개의 소제목(Subsection)으로 나뉜다. 이 소제목들은 내 연구를 구성하는 핵심 컴포넌트들과 일치해야 한다. 예를 들어, ’강화학습을 이용한 로봇 팔 제어’에 관한 논문이라면 다음과 같이 구성할 수 있다.</p>
<ul>
<li><strong>5.2.1. Robot Manipulation with Reinforcement Learning:</strong> 강화학습이 로봇 제어에 적용된 역사와, 샘플 효율성(Sample Efficiency) 문제.</li>
<li><strong>5.2.2. Sim-to-Real Transfer Techniques:</strong> 시뮬레이션에서 학습된 정책을 현실로 옮길 때 발생하는 ’Reality Gap’을 줄이기 위한 기존 연구들 (Domain Randomization 등)과 그 한계.</li>
<li><strong>5.2.3. Tactile Sensing in Robotics:</strong> 시각 정보 외에 촉각 정보를 활용하려던 시도들과, 기존 센서 처리의 어려움.</li>
</ul>
<p>이렇게 구성하면, 독자는 저자가 이 세 가지 요소를 결합하여 새로운 해결책을 제시할 것임을 목차만 보고도 예측할 수 있다.2</p>
<h2>4.  비판적 분석(Critical Analysis)과 갭(Gap) 도출</h2>
<p>관련 연구의 핵심은 기존 연구를 존중하되, 그들의 한계를 명확히 지적하여 내 연구의 필요성을 역설하는 것이다. 이를 ’갭 분석(Gap Analysis)’이라 한다.11</p>
<ol>
<li>존중과 비판의 균형 (Respectful Critique)</li>
</ol>
<p>남의 연구를 비판할 때는 학술적이고 정중한 표현을 사용해야 한다. “A의 방법은 틀렸다(wrong)“거나 “형편없다(poor)“는 식의 공격적인 표현은 절대 금물이다. 해당 논문의 저자가 내 논문의 리뷰어가 될 확률이 매우 높기 때문이다. 대신 ‘Yes, But’ 화법을 사용한다.13</p>
<ul>
<li><strong>인정(Acknowledgment):</strong> “While  demonstrated impressive performance in static environments…” (은 정적 환경에서 인상적인 성능을 보여주었으나…)</li>
<li><strong>한계 지적(Limitation):</strong> “…it struggles to maintain robustness under dynamic occlusion.” (…동적인 가림 현상이 발생할 때 강건함을 유지하는 데 어려움이 있다.)</li>
<li><strong>대안 제시(Need):</strong> “This necessitates a method that can explicitly model object dynamics.” (따라서 객체의 동역학을 명시적으로 모델링할 수 있는 방법이 필요하다.)</li>
<li>갭(Gap)의 유형과 서술 전략</li>
</ul>
<p>내 연구가 채우고자 하는 갭은 구체적이어야 한다. 막연히 “기존 연구는 부족하다“는 설득력이 없다.</p>
<ul>
<li><strong>성능의 갭 (Performance Gap):</strong> “기존 방법들은 실시간 처리가 불가능하다( &lt; 10 FPS).” -&gt; CVPR, NeurIPS 등에서 주로 어필.</li>
<li><strong>적용의 갭 (Application Gap):</strong> “기존 방법은 잘 정제된 실내 데이터셋에서는 잘 작동하지만, 조명 변화가 심한 야외 환경이나 비정형 도로에서는 실패한다.” -&gt; ICRA, IROS 등 로보틱스 학회에서 중요.15</li>
<li><strong>방법론의 갭 (Methodological Gap):</strong> “대부분의 기존 연구는 지도 학습(Supervised Learning)에 의존하여 막대한 라벨링 비용이 들지만, 비지도 학습(Unsupervised) 접근은 미비하다.”</li>
</ul>
<p>각 소섹션(Subsection)의 마지막 문장은 반드시 이러한 갭을 요약하고, “따라서 본 연구는 ~에 초점을 맞춘다“는 문장으로 마무리하여 다음 장(방법론)으로의 연결 고리를 만들어야 한다.16</p>
<h2>5.  비교 우위의 시각화: 비교 테이블(Comparison Table) 작성법</h2>
<p>텍스트만으로는 수십 편의 논문과 내 연구의 차이점을 한눈에 보여주기 어렵다. 이때 가장 강력한 무기가 바로 ’비교 테이블’이다. 텍스트로 구구절절 설명하는 것보다, 잘 정리된 표 하나가 리뷰어의 뇌리에 내 연구의 우수성을 각인시킨다.1</p>
<ol>
<li>테이블 구성의 전략</li>
</ol>
<p>비교 테이블은 단순히 기능을 나열하는 것이 아니라, 내 연구가 ’유일한 완전체’임을 보여주도록 설계해야 한다.</p>
<ul>
<li><strong>열(Columns):</strong> 내 연구가 차별화되는 핵심 속성들. (예: End-to-End, Real-time, 3D Support, No-External-Dataset)</li>
<li><strong>행(Rows):</strong> 대표적인 경쟁 논문들 (SOTA).</li>
<li><strong>마지막 행:</strong> “Ours” (내 연구).</li>
<li>체크마크(✓)의 심리학</li>
</ul>
<p>핵심은 기존 연구들은 일부 열에만 체크(✓)가 되어 있거나 X 표시가 되어 있는 반면, “Ours” 행은 모든 긍정적인 요소에 체크(✓)가 되도록 속성을 선정하는 것이다.</p>
<ul>
<li><em>주의사항:</em> 물론 이 비교는 사실에 입각해야 하며 공정해야 한다. 억지로 내 연구에 유리한 이상한 기준을 만들면 오히려 반감을 산다.</li>
<li><em>예시:</em></li>
</ul>
<table><thead><tr><th><strong>Method</strong></th><th><strong>Accuracy</strong></th><th><strong>Real-time</strong></th><th><strong>3D Space</strong></th><th><strong>Low Memory</strong></th></tr></thead><tbody>
<tr><td>Kim et al.</td><td>High</td><td>✗</td><td>✗</td><td>✗</td></tr>
<tr><td>Lee et al.</td><td>Low</td><td>✓</td><td>✗</td><td>✓</td></tr>
<tr><td>Park et al.</td><td>Mid</td><td>✗</td><td>✓</td><td>✗</td></tr>
<tr><td><strong>Ours</strong></td><td><strong>High</strong></td><td><strong>✓</strong></td><td><strong>✓</strong></td><td><strong>✓</strong></td></tr>
</tbody></table>
<p>이 표를 통해 독자는 “아, 기존 연구들은 속도나 정확도 중 하나를 포기해야 했지만, 이 연구는 두 마리 토끼를 다 잡았구나“라고 직관적으로 이해하게 된다.</p>
<h2>6.  커뮤니티별 특성: CVPR/NeurIPS vs. ICRA/IROS</h2>
<p>AI 커뮤니티(CVPR, NeurIPS)와 로보틱스 커뮤니티(ICRA, IROS)는 관련 연구를 다루는 방식과 기대치에서 미묘하지만 중요한 차이를 보인다. 이 ’톤 앤 매너(Tone and Manner)’를 맞추지 못하면 “이 논문은 우리 컨퍼런스 핏(Fit)이 아니다“라는 리뷰를 받기 십상이다.18</p>
<p><strong>1) CVPR / NeurIPS (Computer Vision &amp; AI)</strong></p>
<ul>
<li><strong>SOTA와의 전쟁:</strong> 이곳은 성능 경쟁이 치열하다. 관련 연구 섹션에서도 최신(심지어 2-3달 전 arXiv 논문까지) 방법론들의 성능을 언급하며, 내 모델이 수치적으로(mAP, Accuracy 등) 우월하거나, 혹은 구조적으로 획기적인 효율성을 가짐을 강조해야 한다.20</li>
<li><strong>ArXiv와 속도전:</strong> 공식적으로는 출판되지 않은 arXiv 논문을 반드시 비교할 의무는 없다고(CVPR 가이드라인 18) 되어 있으나, 실제 리뷰 현장에서는 arXiv에 올라온 지 몇 달 된 SOTA를 언급하지 않으면 “Outdated“하다고 공격받는다. 따라서 제출 직전까지 최신 문헌을 모니터링해야 한다.21</li>
<li><strong>밀도:</strong> 8페이지 제한 내에서 관련 연구를 0.5~1페이지 이내로 압축해야 하므로, 매우 간결하고 밀도 높은 문장을 구사해야 한다.</li>
</ul>
<p><strong>2) ICRA / IROS (Robotics)</strong></p>
<ul>
<li><strong>시스템적 통합과 실용성:</strong> 단순한 알고리즘 성능뿐만 아니라, 실제 로봇 하드웨어 적용 가능성, 실시간성, 센서 노이즈에 대한 강건함 등이 중요하다. “이 알고리즘이 실제 로봇에서 돌아가는가?“가 핵심 질문이다.4</li>
<li><strong>도메인 특화:</strong> 로보틱스는 응용 분야(수중, 공중, 의료, 자율주행, 휴머노이드 등)가 다양하다. 일반적인 AI 모델(예: Vision Foundation Model)을 가져왔더라도, 로봇 도메인의 특수성(데이터 부족, 물리적 충돌 위험 등)에 맞게 어떤 수정(Adaptation)이 있었는지를 관련 연구 섹션에서부터 빌드업해야 한다.</li>
<li><strong>실험 환경의 리얼리티:</strong> 시뮬레이션뿐만 아니라 ‘Real-world’ 실험을 수행한 연구들을 우대하며, 관련 연구에서도 이러한 ‘Real-world deployment’ 여부를 중요한 비교 잣대로 삼는다.</li>
</ul>
<h2>7.  집필 워크플로우: 효율적인 작성을 위한 단계별 가이드</h2>
<p>관련 연구 섹션은 논문을 다 쓰고 마지막에 채워 넣는 부록이 아니다. 오히려 연구의 방향성을 잡는 나침반으로서, 연구 초기에 초안이 작성되어야 한다.</p>
<p>Step 1. 키워드 선정 및 문헌 수집 (The Gather)</p>
<p>연구의 핵심 키워드 3~4개를 선정하고, Google Scholar, Connected Papers 등을 통해 최근 3~5년 간의 탑 티어 학회 논문을 수집한다. 이때 ‘Survey’ 논문을 먼저 찾아 읽으면 전체 지도를 파악하는 데 큰 도움이 된다.</p>
<p>Step 2. 분류 및 매트릭스 작성 (The Matrix)</p>
<p>수집한 논문들을 엑셀이나 노션(Notion) 등을 이용해 정리한다. 열에는 논문 제목, 저자, 연도, 핵심 아이디어, 장점, **단점(Limitation)**을 적는다. 특히 ‘단점’ 칸이 비어있으면 안 된다. 이 단점이 내 연구의 출발점이 되기 때문이다.</p>
<p>Step 3. 스토리라인 구성 (The Outline)</p>
<p>논문들을 그룹화하여 소제목을 정한다. 각 문단의 흐름을 잡는다.</p>
<ul>
<li><em>문단 1 (과거):</em> A 분야의 초기 연구들 → 성능은 좋지만 B라는 한계가 있음.</li>
<li><em>문단 2 (현재):</em> 이를 극복하려 했던 최근 연구들 → B는 해결했지만 C라는 새로운 문제가 발생함 (또는 연산량이 너무 많음).</li>
<li><em>문단 3 (제안):</em> 따라서 본 연구는 C 문제를 해결하기 위해 D라는 접근을 취함. (Transition to Methodology)</li>
</ul>
<p>Step 4. 초안 작성 및 문장 다듬기 (The Draft &amp; Polish)</p>
<p>주어(Author) 중심이 아닌 아이디어(Idea) 중심으로 문장을 작성한다.</p>
<ul>
<li><em>수정 전:</em> “Smith  used LSTM for sequence modeling. Jones  used GRU.”</li>
<li><em>수정 후:</em> “Recurrent architectures, such as LSTM  and GRU , have been widely adopted for temporal modeling, yet they suffer from…”.6</li>
</ul>
<p>Step 5. AI 도구의 윤리적 활용 (AI Assistance)</p>
<p>최근 ChatGPT나 Claude와 같은 LLM을 활용해 관련 연구를 작성하는 경우가 늘고 있다. 요약이나 문장 교정에는 유용하지만, 절대 AI가 생성한 텍스트를 그대로 복사해 붙여넣지 말라. AI는 존재하지 않는 논문을 만들어내거나(Hallucination), 논문의 내용을 잘못 해석할 수 있다. 또한, AI가 작성한 글은 특유의 “기계적인 톤“이 있어 리뷰어들이 쉽게 눈치챈다.23 AI는 ’브레인스토밍 파트너’나 ’교정자’로만 활용하고, 최종 검증과 집필은 연구자가 직접 해야 한다. 특히 arXiv 논문 인용 시 2024-2025년 최신 논문은 AI 학습 데이터에 없을 수 있으므로 주의해야 한다.</p>
<h2>8.  리뷰어의 눈: 무엇을 보고 합불을 결정하는가?</h2>
<p>리뷰어는 관련 연구 섹션을 통해 다음 세 가지를 확인하며, 이는 논문의 합불(Accept/Reject)에 지대한 영향을 미친다.</p>
<ol>
<li><strong>“기본은 되어 있는가?” (Sanity Check)</strong></li>
</ol>
<ul>
<li>해당 분야의 핵심 논문(Seminal Works)과 최신 SOTA 논문이 인용되었는가? 이것이 빠지면 ’게으른 연구자’로 낙인찍힌다.</li>
</ul>
<ol start="2">
<li><strong>“내 연구를 무시하지 않았는가?” (The Ego Factor)</strong></li>
</ol>
<ul>
<li>리뷰어는 자신의 연구 분야와 관련된 논문을 심사하게 된다. 따라서 해당 분야의 주요 연구자(잠재적 리뷰어)들의 논문을 적절히 인용하고 존중하는 태도를 보이는 것은 전략적으로 매우 중요하다. 단, 맥락 없는 인용(Citation stuffing)은 오히려 역효과를 낸다.</li>
</ul>
<ol start="3">
<li><strong>“진짜 새로운 게 맞는가?” (Novelty Verification)</strong></li>
</ol>
<ul>
<li>기존 연구와의 차별점이 명확하지 않으면 “Incremental work(기존 연구의 사소한 변형)“로 치부되어 거절당한다. 관련 연구 섹션의 마지막 문단은 반드시 내 연구의 독창성(Novelty)을 한 문장으로 요약하며, 이것이 서론(Introduction)의 기여점(Contribution) 주장과 일치해야 한다.25</li>
</ul>
<h2>9. 요약: 이기는 관련 연구 작성을 위한 5계명</h2>
<ol>
<li><strong>나열하지 말고 구조화하라 (Structure, don’t list):</strong> 저자 이름 나열이 아닌, 아이디어의 흐름을 만들어라.</li>
<li><strong>비판하되 존중하라 (Critique respectfully):</strong> ‘Yes, But’ 화법으로 기존 연구의 가치를 인정하며 한계를 지적하라.</li>
<li><strong>최신 트렌드를 놓치지 말라 (Cover the SOTA):</strong> 2-3년 전 논문만 있다면 이미 늦었다. 최신 arXiv 논문까지 검토하라.</li>
<li><strong>내 연구의 갭(Gap)을 위한 빌드업으로 활용하라 (Build up to contribution):</strong> 모든 문단은 내 연구의 필요성을 가리키는 화살표여야 한다.</li>
<li><strong>비교 테이블로 시각화하라 (Visualize the advantage):</strong> 백 마디 말보다 하나의 잘 짜인 표가 리뷰어를 설득한다.</li>
</ol>
<p>관련 연구는 단순히 과거를 회상하는 회고록이 아니다. 그것은 미래(내 연구)를 제안하기 위한 발판이다. 거인들의 어깨를 밟고 올라서는 것을 두려워하지 말고, 그들의 어깨 위에서 당신이 본 새로운 풍경을 자신 있게 서술하라.</p>
<h2>10. 참고 자료</h2>
<ol>
<li>How to write a “Related Work” section in Computer Science? - Academia Stack Exchange, https://academia.stackexchange.com/questions/68164/how-to-write-a-related-work-section-in-computer-science</li>
<li>Related Work: A Critical Taxonomy of Prior Art - Yegor Bugayenko, https://www.yegor256.com/2023/09/29/how-to-write-related-work-section.html</li>
<li>Practical Tips for Writing Robotics Conference Papers that get Accepted - YouTube, https://www.youtube.com/watch?v=qLu3kT8liNA</li>
<li>Data Laundry-Listing: When Student Writers Lack a Foundational Argument, https://nagoya.repo.nii.ac.jp/record/18954/files/KABARA_NUIdeas_2-2.pdf</li>
<li>avoiding the laundry list literature review - Pat Thomson, https://patthomson.net/2017/09/11/avoiding-the-laundry-list-literature-review/</li>
<li>avoiding the laundry list literature review - Toilet Paper Manifesto, https://chickenbuschautauqua.wordpress.com/2017/10/31/avoiding-the-laundry-list-literature-review/</li>
<li>Improving Personal Narratives with a Focus on Seed Stories - Differentiated Teaching, https://www.differentiatedteaching.com/personal-narratives-with-seed-stories/</li>
<li>Taxonomy-as-a-Service: How To Structure Your Related Work - arXiv, https://arxiv.org/pdf/1906.11217</li>
<li>Organizational Structure and Your Taxonomy: Where Does it Go?, https://www.earley.com/insights/organizational-structure-and-your-taxonomy-where-does-it-go</li>
<li>Academic Phrasebank - The Largest Collection of Academic Phrases - Ref-n-Write, https://www.ref-n-write.com/academic-phrasebank/</li>
<li>Gaps in the Literature - UNE Library Services - University of New England, https://library.une.edu/research-help/help-with/gaps-in-the-literature/</li>
<li>45+ Constructive Feedback on Performance Review Examples - Peoplebox.ai, https://www.peoplebox.ai/blog/negative-feedback-examples/</li>
<li>Being critical - Academic Phrasebank - The University of Manchester, https://www.phrasebank.manchester.ac.uk/being-critical/</li>
<li>Structuring Robotics Conference Papers | MichaelMilford.com, https://michaelmilford.com/structuring-robotics-conference-papers/</li>
<li>Transition Words and Phrases | Writing and Communication Centre - University of Waterloo, https://uwaterloo.ca/writing-and-communication-centre/transition-words-and-phrases</li>
<li>How to Write the Results/Findings Section in Research - Wordvice, https://blog.wordvice.com/writing-the-results-section-for-a-research-paper/</li>
<li>2025 Author Guidelines - CVPR 2026 - The Computer Vision Foundation, https://cvpr.thecvf.com/Conferences/2025/AuthorGuidelines</li>
<li>Thoughts on Writing a Good (Robotics) Paper - Pratap Tokekar, http://tokekar.com/docs/Tokekar-WritingPapers-Talk.pdf</li>
<li>Most Influential CVPR Papers (2025-03 Version) - Paper Digest, https://www.paperdigest.org/2025/03/most-influential-cvpr-papers-2025-03-version/</li>
<li>When can I ignore related work in my paper? - Academia Stack Exchange, https://academia.stackexchange.com/questions/89204/when-can-i-ignore-related-work-in-my-paper</li>
<li>Agentic LLM-based robotic systems for real-world applications: a review on their agenticness and ethics - Frontiers, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2025.1605405/full</li>
<li>Common AI Writing Mistakes and How to Avoid Them - Yomu AI, https://www.yomu.ai/resources/common-ai-writing-mistakes-and-how-to-avoid-them</li>
<li>Avoid 7 Common Mistakes When Using AI to Write - Rescrito, https://rescrito.com/en/common-mistakes-when-using-ai-to-write/</li>
<li>Writing the “Related Work” Section of a Paper/thesis - GitHub Gist, https://gist.github.com/ikbelkirasan/848f97c4a1aee1fa6277ced7b5be80af</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>