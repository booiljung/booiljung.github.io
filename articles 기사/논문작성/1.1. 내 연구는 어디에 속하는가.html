<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:1.1. 내 연구는 어디에 속하는가?</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>1.1. 내 연구는 어디에 속하는가?</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">실전 논문 작성 가이드</a> / <span>1.1. 내 연구는 어디에 속하는가?</span></nav>
                </div>
            </header>
            <article>
                <h1>1.1. 내 연구는 어디에 속하는가?</h1>
<p>연구자가 논문을 작성하기 시작할 때 가장 먼저 마주하는, 그리고 가장 마지막까지 괴롭히는 근원적인 질문은 “내 연구는 무엇인가?“가 아니라 “내 연구는 어디에 놓여야 하는가?“이다. 이는 단순한 서지학적 분류의 문제가 아니다. 이것은 연구의 가치를 가장 잘 알아봐 줄 청중(Audience)을 찾아가는 전략적 포지셔닝(Positioning)의 문제이며, 동시에 자신의 연구가 학술적 대화의 거대한 흐름 속에서 어떤 맥락을 점유하고 있는지를 증명하는 정체성 투쟁의 과정이다.</p>
<p>특히 인공지능(AI)과 로봇공학(Robotics)의 경계가 전례 없이 흐려지고 있는 작금의 연구 지형에서, 자신의 연구 좌표를 설정하는 일은 과거보다 훨씬 복잡하고 교묘해졌다. 컴퓨터 비전 연구자가 로봇 팔을 제어하고, 기계공학 기반의 로봇 연구자가 대형 언어 모델(LLM)을 파인튜닝하는 시대다. 이러한 융합의 소용돌이 속에서 자신이 서 있는 위치를 명확히 인지하지 못한 채 작성된 논문은, 아무리 훌륭한 실험 결과를 담고 있을지라도 “범위가 맞지 않음(Out of Scope)“이라는 차가운 거절 메일을 받기 십상이다. 따라서 펜을 들기 전, 아니 키보드에 손을 올리기 전에 우리는 냉철하게 자문해야 한다. 나는 방법론을 파는가, 문제를 파는가? 나의 연구는 가상 세계에 머무는가, 물리 세계와 충돌하는가? 나는 수학적 증명으로 설득하는가, 아니면 작동하는 시스템으로 증명하는가?</p>
<p>이 장에서는 방대한 연구의 바다에서 자신의 좌표를 설정하고, 자신의 연구를 소비해 줄 적절한 ’부족(Tribe)’을 찾아가는 방법을 심도 있게 논의한다.</p>
<h2>1.  정체성의 스펙트럼: 순수 지능에서 체화된 지능까지</h2>
<p>전통적으로 인공지능과 로봇공학은 서로 다른 뿌리에서 자라난 이질적인 나무였다. 1956년 다트머스 회의에서 태동한 인공지능은 인간의 고등 지적 능력—추론, 학습, 언어 이해—을 기호와 데이터로 시뮬레이션하려는 시도에서 출발했다.1 초기 AI는 컴퓨터라는 상자 안에 갇힌 ’뇌’를 만드는 작업이었으며, 물리적 세계와의 상호작용은 추상화되거나 배제되었다. 반면 로봇공학은 기계공학, 제어 이론, 전자공학의 단단한 토양 위에서 성장했다. 로봇공학의 본질은 ’움직임’과 ’물리적 작업’에 있었으며, 중력과 마찰, 관성이라는 물리 법칙의 제약 속에서 기계를 제어하는 것이 지상 과제였다.2</p>
<p>그러나 딥러닝의 폭발적인 성장과 하드웨어의 발전은 이 두 분야의 경계를 무너뜨렸다. 인공지능은 로봇에게 복잡한 환경을 이해할 수 있는 ’눈’과 ’뇌’를 제공했고, 로봇공학은 인공지능에게 데이터 공간을 넘어 물리적 실체인 ’몸’을 제공했다. 이제 연구자는 자신의 연구가 이 거대한 스펙트럼의 어디쯤 위치하는지를 픽셀 단위로 미세하게 조정해야 한다.</p>
<h3>1.1  순수 AI (Disembodied AI): 데이터 공간의 연금술</h3>
<p>스펙트럼의 한쪽 끝에는 물리적 실체(Body)가 없는 순수 AI, 즉 ’비체화된 AI(Disembodied AI)’가 존재한다. 이 영역의 연구는 주로 데이터의 패턴을 발견하고, 예측 모델을 최적화하며, 정보의 처리를 효율화하는 데 집중한다. 자연어 처리(NLP), 추천 시스템, 그리고 로봇과 무관한 순수 컴퓨터 비전(Computer Vision)이 여기에 속한다.3</p>
<p>이 영역에 속하는 연구의 가장 큰 특징은 ’데이터셋(Dataset)’이 곧 연구의 세계(World)라는 점이다. 연구자는 정제된 벤치마크 데이터셋 위에서 알고리즘의 성능을 검증한다. 이곳에서의 ’성공’은 정확도(Accuracy), F1 점수, 혹은 연산 속도(FPS)와 같은 정량적 지표로 명확하게 정의된다. 물리적 세계의 불확실성—갑자기 변하는 조명, 미끄러운 바닥, 센서 노이즈—은 고려 대상이 아니다.</p>
<p>만약 당신의 연구가 새로운 이미지 생성 모델을 제안하거나, 텍스트 데이터를 분석하여 감정을 분류하는 것이라면, 당신은 순수 AI 진영에 속한다. 이때 당신의 논문은 알고리즘의 수학적 독창성과 대규모 데이터에서의 일반화 성능을 강조해야 한다. 로봇 학회에 투고할 경우 “그래서 이것을 어디에 쓰는가?“라는 질문에 막힐 수 있으며, 반대로 순수 AI 학회에서는 물리적 제약을 고려하지 않은 모델의 비현실성에 대해 공격받을 일이 적다.</p>
<h3>1.2  체화된 AI (Embodied AI): 지능이 몸을 입을 때</h3>
<p>스펙트럼의 반대편, 혹은 그 융합점에는 최근 연구 지형을 뒤흔들고 있는 ’체화된 AI(Embodied AI)’가 있다. 이는 지능이 물리적 에이전트(로봇)를 통해 환경과 상호작용할 때 비로소 발현된다는 철학에 기반한다.4 이곳에서의 지능은 단순히 이미지를 분류하는 것을 넘어, “냉장고 문을 열어라“라는 명령을 수행하기 위해 시각 정보를 해석하고, 로봇 팔의 궤적을 계획하며, 손끝에 느껴지는 반력을 제어하는 일련의 과정으로 정의된다.</p>
<p>체화된 AI 연구는 “본다는 것(Seeing)“과 “움직인다는 것(Moving)“을 분리하지 않는다. 예를 들어, 당신의 연구가 “보이지 않는 물체를 찾기 위해 로봇이 고개를 돌리거나 장애물을 치우는 행위(Active Perception)“를 포함한다면, 이는 단순한 컴퓨터 비전 연구가 아니라 체화된 AI, 즉 로봇공학의 영역으로 깊숙이 들어온 것이다.7 최근 CVPR이나 NeurIPS와 같은 톱티어 AI 학회들이 로봇 관련 워크숍을 대거 개설하며 이 분야를 적극적으로 흡수하고 있는 현상은 시사하는 바가 크다.6</p>
<p>당신의 연구가 체화된 AI에 속한다면, 논문의 평가는 알고리즘의 정확도만으로 이루어지지 않는다. “성공률(Success Rate)“이라는 지표가 등장하며, 시뮬레이션에서 학습된 지능이 실제 물리 세계(Real World)로 전이(Transfer)될 때 발생하는 ’Sim-to-Real Gap’을 어떻게 극복했는지가 핵심적인 평가 요소가 된다.9</p>
<h3>1.3  로봇공학(Robotics): 물리 세계의 지배자</h3>
<p>스펙트럼의 가장 오른쪽에는 순수 로봇공학이 자리 잡고 있다. 이곳은 AI의 도움을 받을지언정, 본질적으로는 기계 시스템의 설계, 제어, 그리고 통합을 다룬다. 인공지능이 ’뇌’라면, 로봇공학은 ’근육’과 ‘골격’, 그리고 ’신경망’을 다룬다.2</p>
<p>이 영역의 연구자들은 소프트웨어 알고리즘뿐만 아니라 하드웨어의 한계, 에너지 효율, 재질의 특성, 그리고 안전(Safety)을 심각하게 고민한다. 예를 들어, 새로운 그리퍼(Gripper) 메커니즘을 설계하거나, 험지를 주행하는 4족 보행 로봇의 동역학 제어기를 개발하는 연구가 여기에 해당한다.10 여기서 ’학습(Learning)’은 제어를 보조하는 수단일 뿐, 연구의 목적 자체가 아닌 경우가 많다. 이 분야의 논문은 시스템이 얼마나 강건하게(Robust) 작동하는지, 그리고 얼마나 복잡한 물리적 작업을 수행할 수 있는지를 증명해야 한다.</p>
<table><thead><tr><th><strong>구분</strong></th><th><strong>순수 AI (Pure AI)</strong></th><th><strong>체화된 AI (Embodied AI)</strong></th><th><strong>로봇공학 (Robotics)</strong></th></tr></thead><tbody>
<tr><td><strong>핵심 대상</strong></td><td>데이터 (이미지, 텍스트)</td><td>에이전트와 환경의 상호작용</td><td>물리적 시스템과 제어</td></tr>
<tr><td><strong>주요 활동</strong></td><td>패턴 인식, 생성, 추론</td><td>인식-행동 루프 (Perception-Action Loop)</td><td>설계, 동역학 제어, 통합</td></tr>
<tr><td><strong>검증 공간</strong></td><td>정적 데이터셋 (Static Dataset)</td><td>시뮬레이터 &amp; 제한된 실환경</td><td>실제 물리 환경 (Real World)</td></tr>
<tr><td><strong>평가 지표</strong></td><td>정확도, F1 Score</td><td>작업 성공률, Sim-to-Real 효율</td><td>강건성, 속도, 에너지 효율</td></tr>
<tr><td><strong>대표 학회</strong></td><td>NeurIPS, ICML, CVPR (일부)</td><td>CoRL, RSS, CVPR, ICRA</td><td>ICRA, IROS, RSS</td></tr>
</tbody></table>
<h2>2.  연구의 나침반: 방법론 중심 대 문제 해결 중심</h2>
<p>자신의 연구가 AI와 로봇공학의 스펙트럼 어디에 위치하는지 파악했다면, 다음으로는 연구의 ’지향점’을 결정해야 한다. 같은 기술을 사용하더라도 연구가 ’방법론(Method)’을 지향하느냐, ’문제 해결(Problem Solving)’을 지향하느냐에 따라 논문의 서술 방식과 투고 전략은 완전히 달라진다.</p>
<h3>2.1  방법론 중심 연구 (Method-driven Research): 새로운 망치를 만들다</h3>
<p>방법론 중심 연구는 “더 나은 도구“를 만드는 것에 집중한다. 기존의 알고리즘이 가진 한계—느린 학습 속도, 낮은 데이터 효율성, 불안정한 수렴성—를 극복하기 위해 새로운 수학적 이론, 신경망 아키텍처, 혹은 최적화 기법을 제안하는 것이 이 연구의 핵심이다.11</p>
<p>이 접근법을 취하는 연구자는 마치 대장장이와 같다. 그들은 자신이 만든 ’새로운 망치’가 얼마나 단단하고 가벼운지를 자랑한다. 이때 중요한 것은 “어떤 못을 박았느냐“가 아니라 “망치 자체의 우수성“이다. 따라서 연구자는 자신의 방법론을 검증하기 위해 표준화된 벤치마크 문제(Canonical Problems)를 사용한다. 예를 들어, 여행하는 외판원 문제(TSP)를 풀기 위해 새로운 그래프 신경망(GNN)을 제안한다면, 이 연구는 TSP라는 문제 자체를 해결하는 것보다 GNN의 구조적 혁신을 보여주는 데 더 큰 비중을 둔다.11</p>
<ul>
<li><strong>강점:</strong> 이론적 기여가 명확하며, 범용성을 인정받을 경우 파급력이 크다.</li>
<li><strong>약점:</strong> 실제 로봇 시스템에 적용했을 때 발생하는 복잡한 현실적 문제(통신 지연, 센서 노이즈 등)를 간과하기 쉽다. 이를 “장난감 문제(Toy Problem)“에만 적용된다고 비판받을 수 있다.9</li>
<li><strong>전략:</strong> 논문에서는 수학적 증명(Proof)이나 광범위한 비교 실험(Ablation Study)을 통해 방법론의 우월성을 입증해야 한다. NeurIPS, ICML과 같은 기계학습 이론 중심 학회가 주 타겟이 된다.</li>
</ul>
<h3>2.2  문제 해결 중심 연구 (Problem-driven Research): 박히지 않는 못을 박다</h3>
<p>반면, 문제 해결 중심 연구는 “해결되지 않은 과제“에서 출발한다. 자율주행 차가 폭설 속에서 차선을 잃어버리는 문제, 수술 로봇이 미세한 혈관을 봉합할 때 손떨림을 보정해야 하는 문제, 재난 현장에서 로봇이 통신 두절 상황을 극복해야 하는 문제 등이 그 예이다.12</p>
<p>이 접근법을 취하는 연구자는 현장의 엔지니어와 같다. 그들은 기존의 망치(알고리즘)들을 조합하거나 개량하여, 도저히 박히지 않던 못을 박아내는 데 집중한다. 여기서 중요한 것은 “어떤 망치를 썼느냐“가 아니라 “못이 제대로 박혔느냐“이다. 때로는 최신 딥러닝 기술보다 고전적인 칼만 필터(Kalman Filter)가 더 효과적일 수 있으며, 이러한 실용적인 선택과 시스템 통합(System Integration)의 노하우가 연구의 핵심 기여(Contribution)로 인정받는다.12</p>
<ul>
<li><strong>강점:</strong> 현실 세계에 즉각적인 임팩트를 줄 수 있으며, 산업계의 수요와 직결된다.</li>
<li><strong>약점:</strong> 이론적 깊이가 얕아 보이거나, 해당 솔루션이 그 특정 상황에서만 작동하는 ’임시방편(Ad-hoc)’적인 해결책으로 치부될 위험이 있다. 소위 “엔지니어링 리포트“라는 비판을 피하기 위해서는 연구 결과의 일반화 가능성을 논증해야 한다.</li>
<li><strong>전략:</strong> 실제 환경(Real World)에서의 실험 결과가 필수적이다. 시뮬레이션 결과만으로는 설득력이 떨어진다. ICRA, IROS, 그리고 필드 로보틱스 관련 저널이 주 타겟이 된다.</li>
</ul>
<h3>2.3  제3의 길: 지식 기반 AI (Knowledge-driven AI)와 하이브리드 접근</h3>
<p>최근에는 이 두 접근법의 장점을 결합한 ’지식 기반 AI(Knowledge-driven AI)’가 주목받고 있다. 순수한 데이터 기반 학습(Data-driven)의 불확실성을 보완하기 위해, 물리학의 법칙이나 도메인 지식(Domain Knowledge)을 AI 모델에 주입하는 방식이다.11</p>
<p>예를 들어, 로봇 팔을 제어하는 신경망을 학습시킬 때, 단순히 입출력 데이터만 주는 것이 아니라 로봇의 기구학(Kinematics) 방정식을 손실 함수(Loss Function)에 포함시키는 것이다. 이는 ’방법론적 혁신’이면서 동시에 ’문제 해결 능력’을 극대화하는 전략이다. 이러한 하이브리드 연구는 이론적 엄밀함과 실용적 성능을 동시에 달성할 수 있어, CoRL이나 RSS와 같은 하이엔드 로봇 학회에서 매우 선호하는 포지셔닝이다.</p>
<p>또한, ‘가설 주도형(Hypothesis-driven)’ 접근도 눈여겨볼 만하다. 단순히 “성능이 좋다“는 것을 넘어, “왜 성능이 좋은가?“에 대한 인과적 이해를 시도하는 연구이다. 예컨대 생성형 AI가 클릭베이트 기사를 만드는 원인을 분석하고, 이를 방지하기 위한 가설을 세워 검증하는 식이다.15 이는 단순한 엔지니어링을 넘어 과학(Science)의 영역으로 연구를 격상시키는 방법이다.</p>
<h2>3.  학술 대화의 장(Venue) 선택: 나의 부족(Tribe)을 찾아서</h2>
<p>연구의 성격을 파악했다면, 이제 그 연구를 가장 잘 이해하고 평가해 줄 ’부족’을 찾아야 한다. 학술대회(Conference)는 단순한 발표 장소가 아니라, 특정한 가치관, 평가 기준, 그리고 은어를 공유하는 연구자들의 커뮤니티이다. 각 학회는 선호하는 연구 주제뿐만 아니라, ’무엇을 좋은 연구로 정의하는가’에 대한 암묵적인 합의가 다르다.</p>
<h3>3.1  컴퓨터 비전의 성지: CVPR, ICCV, ECCV</h3>
<ul>
<li>성향 및 트렌드:</li>
</ul>
<p>컴퓨터 비전 학회는 전통적으로 이미지와 비디오 처리 알고리즘에 집중해 왔으나, 최근에는 로봇공학과의 융합인 ’Embodied AI’의 거점이 되고 있다.6 특히 3D 장면 재구성(3D Reconstruction), NeRF, Gaussian Splatting과 같은 기술이 로봇의 환경 인식 기술로 직결되면서 로봇 연구자들의 투고가 급증하고 있다. CVPR 2025의 주요 토픽으로 ‘3D from Multi-View’, ‘Multimodal Learning’, 그리고 ’Computer Vision for Robotics’가 선정된 것은 이러한 흐름을 방증한다.16</p>
<ul>
<li>평가 기준:</li>
</ul>
<p>이 부족은 ’벤치마크(Benchmark)’를 숭배한다. 새로운 아이디어를 제안했다면, 반드시 표준화된 데이터셋(COCO, ImageNet, nuScenes 등) 위에서 기존 SOTA(State-of-the-Art) 모델들과 정량적인 비교를 수행해야 한다. 실험의 규모와 시각적 결과물의 퀄리티(Visual Quality)가 매우 중요하다. 로봇 논문이라 할지라도 하드웨어 자체보다는 ’시각 정보를 처리하는 지능’에 초점을 맞춰야 한다.</p>
<ul>
<li>전략:</li>
</ul>
<p>로봇 실험이 없어도 시뮬레이션 실험이 정교하고, 시각적 처리에 대한 기여가 명확하다면 충분히 채택될 수 있다. 그러나 최근 추세는 실제 로봇 데모를 포함하는 논문에 가산점을 주는 경향이 있다.6</p>
<h3>3.2  로봇 공학의 본산: ICRA, IROS</h3>
<ul>
<li>성향 및 트렌드:</li>
</ul>
<p>ICRA(International Conference on Robotics and Automation)와 IROS(International Conference on Intelligent Robots and Systems)는 로봇 공학계의 양대 산맥이다. 이곳은 “Real World works“가 지상 과제인 곳이다.18 아무리 이론적으로 우아한 알고리즘이라도 실제 로봇에서 돌아가지 않거나, 현실적인 가정(Assumption)을 무시했다면 가차 없이 거절당한다. 하드웨어 설계, 제어, 센서 퓨전, 휴머노이드, 군집 로봇 등 로봇의 모든 측면을 다룬다.</p>
<ul>
<li>평가 기준:</li>
</ul>
<p>“실제 로봇에서 실험했는가?“는 가장 강력한 필터링 질문이다. 시뮬레이션 결과만 있는 논문은 불리한 위치에서 시작한다. 또한, 시스템 통합 과정에서의 엔지니어링적 통찰, 실험 설계의 타당성, 그리고 결과의 재현성이 중요하다. 최근에는 논문 제출 시 실제 작동 영상을 포함하는 것이 거의 필수가 되었다.20</p>
<ul>
<li>차별점:</li>
</ul>
<p>CVPR 논문들이 ’새로운 방법론’에 집중한다면, ICRA/IROS 논문들은 ’시스템의 완성도’와 ’응용’에 더 관대하다. 임팩트 팩터(Impact Score)는 CVPR에 비해 낮게 보일 수 있지만, 이는 분야의 특성(인용 속도가 느리고, 하드웨어 연구의 진입 장벽이 높음) 때문이지 연구의 질이 낮아서가 아니다.21</p>
<h3>3.3  기계학습의 전당: NeurIPS, ICML, ICLR</h3>
<ul>
<li>성향 및 트렌드:</li>
</ul>
<p>이곳은 AI의 이론적 토대를 다지는 곳이다. 딥러닝, 강화학습, 최적화 이론, 생성 모델의 근원적인 원리를 탐구한다. 로봇은 여기서 종종 ’알고리즘을 검증하기 위한 하나의 애플리케이션’으로 취급된다.5 하지만 최근에는 로봇 학습(Robot Learning)이 강화학습의 주요 응용 분야로 부상하면서, 로봇 관련 워크숍과 논문 비중이 늘어나고 있다.4</p>
<ul>
<li>평가 기준:</li>
</ul>
<p>수학적 엄밀함(Rigour)과 이론적 증명이 핵심이다. “왜 이 알고리즘이 수렴하는가?”, “왜 더 효율적인가?“에 대한 답을 내놓아야 한다. 로봇 실험이 포함되면 좋지만, 그것이 단순한 데모 수준이어서는 안 되며, 알고리즘의 특성을 잘 보여주는 실험이어야 한다.</p>
<h3>3.4  교집합의 엘리트: CoRL, RSS</h3>
<ul>
<li><strong>CoRL (Conference on Robot Learning):</strong> 로봇 공학(ICRA)과 기계학습(NeurIPS)의 교집합에 정확히 위치한다. 딥러닝이나 강화학습을 사용하여 로봇 문제를 해결하는 연구에 특화되어 있다. 이론적 깊이와 실제 로봇 실험을 동시에 요구하는, 진입 장벽이 높은 학회다.9</li>
<li><strong>RSS (Robotics: Science and Systems):</strong> 로봇 학계의 NeurIPS라고 불릴 만큼 이론적, 수학적 완성도를 중시한다. 채택률이 매우 낮으며, 로봇 공학의 근본적인 문제에 대한 깊이 있는 통찰을 요구한다.</li>
</ul>
<table><thead><tr><th><strong>학회</strong></th><th><strong>주요 관심사 (Focus)</strong></th><th><strong>필수 요소 (Must-have)</strong></th><th><strong>금기 사항 (Taboo)</strong></th><th><strong>비유</strong></th></tr></thead><tbody>
<tr><td><strong>CVPR</strong></td><td>시각 지능, 3D, 생성</td><td>SOTA 갱신, 대규모 벤치마크</td><td>빈약한 시각화, 소규모 데이터</td><td>“가장 눈이 좋은 자들의 올림픽”</td></tr>
<tr><td><strong>ICRA</strong></td><td>시스템, 제어, 하드웨어</td><td>리얼 월드 데모, 시스템 강건성</td><td>시뮬레이션 Only (상황따라), 비현실적 가정</td><td>“거친 현장의 생존자 클럽”</td></tr>
<tr><td><strong>NeurIPS</strong></td><td>학습 이론, 최적화</td><td>수학적 증명, 이론적 참신성</td><td>휴리스틱한 해결책, 이론 부재</td><td>“상아탑의 수학자들”</td></tr>
<tr><td><strong>CoRL</strong></td><td>로봇을 위한 학습</td><td>Sim-to-Real, 학습 효율성</td><td>단순 응용, 학습 요소 부재</td><td>“뇌를 가진 로봇의 실험실”</td></tr>
</tbody></table>
<h2>4.  연구 주제별 상세 포지셔닝 가이드</h2>
<p>더 구체적으로 들어가 보자. “나는 자율주행을 연구한다“는 말은 너무 포괄적이다. 자율주행 안에서도 인식을 하느냐, 판단을 하느냐, 제어를 하느냐에 따라 당신의 연구가 속할 하위 카테고리는 달라진다.</p>
<h3>4.1  로봇 매니퓰레이션 (Robotic Manipulation): 손의 지능</h3>
<p>로봇 팔로 물체를 잡고 조작하는 연구는 현재 가장 뜨거운 감자다.</p>
<ul>
<li><strong>고전적 제어 및 기구학:</strong> 로봇 팔의 관절 각도를 계산하고, 힘(Force)을 제어하여 정밀하게 조립하는 연구라면 <strong>ICRA/IROS</strong>가 본진이다.24 여기서는 접촉 모델링(Contact Modeling)과 안정성 해석이 중요하다.</li>
<li><strong>비전 기반 파지 (Grasping):</strong> 카메라로 물체를 인식하고 잡는 점을 찾는 연구라면 <strong>CVPR/ICRA</strong> 모두 가능하다. 단, 인식 알고리즘의 성능이 주라면 CVPR, 잡은 후의 성공률이 주라면 ICRA가 적합하다.</li>
<li><strong>강화학습 기반 제어:</strong> 로봇이 시행착오를 통해 조작 기술을 배우는 연구라면 <strong>CoRL/NeurIPS</strong>가 적합하다. 최근에는 언어 모델과 결합하여 “파란색 컵을 줘“와 같은 명령을 수행하는 VLA(Vision-Language-Action) 모델이 유행하며 학회 간 경계를 허물고 있다.25</li>
</ul>
<h3>4.2  내비게이션 및 자율주행 (Navigation &amp; Autonomous Driving)</h3>
<ul>
<li><strong>SLAM (지도 작성):</strong> 기하학적 수식을 이용한 전통적 SLAM은 <strong>ICRA/IROS</strong>의 영역이다. 그러나 딥러닝을 이용해 이미지에서 직접 지도를 생성하거나, NeRF를 이용한 3D 매핑은 <strong>CVPR/ECCV</strong>의 주력 분야가 되었다.14</li>
<li><strong>경로 계획 (Path Planning):</strong> 복잡한 환경에서 충돌 없는 경로를 찾는 알고리즘은 로봇 공학의 고전적 주제다. 하지만 최근 보행자나 다른 차량의 행동을 예측(Prediction)하고 사회적 상호작용을 고려하는 연구는 <strong>HRI</strong>나 <strong>AI 학회</strong>로 확장되고 있다.</li>
<li><strong>자율주행 시스템:</strong> 차량 전체의 시스템 통합, 안전성 검증, 법적/윤리적 이슈를 다루는 연구는 **IV (Intelligent Vehicles Symposium)**나 <strong>ITSC</strong> 같은 전문 학회, 그리고 <strong>ICRA</strong>에서 주로 다룬다.</li>
</ul>
<h3>4.3  인간-로봇 상호작용 (HRI): 기술과 심리학의 만남</h3>
<ul>
<li><strong>소셜 로봇 (Social Robotics):</strong> 로봇의 표정, 눈맞춤, 대화 턴테이킹 등을 연구한다면 이는 공학보다는 인지과학이나 심리학에 가깝다. <strong>HRI Conference</strong>나 <strong>RO-MAN</strong>이 주 무대이며, 사용자 스터디(User Study)와 통계적 분석이 필수적이다.26</li>
<li><strong>물리적 HRI (pHRI):</strong> 협동 로봇(Cobot)이 인간과 부딪혔을 때 안전하게 멈추거나, 인간의 힘을 보조해주는 제어 기술은 철저한 **로봇 공학(ICRA/IROS)**의 영역이다.14 여기서는 ’친근함’보다는 ’임피던스 제어’나 ’충돌 감지 알고리즘’이 주인공이다.</li>
</ul>
<h2>5.  계보학적 포지셔닝: 나의 ‘연구실(Lab)’ 유형 파악하기</h2>
<p>자신의 연구가 어디에 속하는지 파악하는 가장 실용적인 방법 중 하나는, 세계적인 선도 연구 그룹들의 스타일을 벤치마킹하는 것이다. 당신의 연구 스타일은 어느 연구소의 논문들과 닮아 있는가? 이를 파악하면 참고문헌을 구성하고 논문의 논조를 잡는 데 큰 도움이 된다.</p>
<h3>5.1  CMU Robotics Institute (RI) 스타일: 현장의 개척자들</h3>
<p>카네기 멜론 대학(CMU)의 로봇 연구소는 “현장에서 작동하는 시스템“을 중시하는 전통이 강하다.28 재난 현장, 농장, 수중, 우주와 같은 거친 환경(Field Robotics)에서 실제로 구동되는 로봇을 만든다.</p>
<ul>
<li><strong>당신의 연구가:</strong> 하드웨어 제작부터 소프트웨어 통합, 그리고 야외 필드 테스트까지 포함한다면 당신은 CMU 스타일의 ’시스템 논문’을 쓰고 있는 것이다. 이론적 완벽함보다는 시스템의 완성도와 실증적 가치를 강조하라.</li>
</ul>
<h3>5.2  MIT CSAIL / Berkeley BAIR 스타일: 지능형 로봇의 산실</h3>
<p>MIT의 CSAIL과 UC 버클리의 BAIR(Berkeley Artificial Intelligence Research)는 AI 기술을 로봇에 접목하는 연구를 주도한다.30 딥러닝, 강화학습을 이용해 로봇의 인지 및 제어 능력을 획기적으로 높이는 연구들이 주를 이룬다.</p>
<ul>
<li><strong>당신의 연구가:</strong> 시뮬레이터와 실제 로봇을 오가며 학습 알고리즘을 검증하거나, 새로운 딥러닝 아키텍처를 로봇 퍼셉션에 적용하는 것이라면 이들 그룹의 논문을 참고하라. ’Embodied AI’의 최전선이 여기에 있다.</li>
</ul>
<h3>5.3  Stanford RAIL 스타일: 인간 중심의 학습</h3>
<p>스탠포드의 RAIL(Robotics and AI Lab) 등은 로봇이 인간 환경에서 공존하기 위한 학습 방법론에 강점이 있다.33 인간의 피드백을 이용한 강화학습(RLHF)이나 안전한 상호작용을 위한 제어 기술 등이 주요 주제다.</p>
<ul>
<li><strong>당신의 연구가:</strong> 로봇의 지능뿐만 아니라 윤리, 안전, 인간과의 공존을 고민한다면 스탠포드 스타일의 접근이 유효하다.</li>
</ul>
<p><strong>팁:</strong> 당신이 작성 중인 논문의 참고문헌(References) 목록을 펼쳐보라. 인용된 논문의 70%가 CVPR 출신이라면, 당신은 비전 커뮤니티에 속해 있을 확률이 높다. 반대로 ICRA 논문이 대부분이라면 로봇 커뮤니티가 당신의 홈그라운드다.34 이 비율이 50:50이라면? 당신은 두 커뮤니티의 경계에 있는 융합 연구를 하고 있으며, 양쪽 모두를 설득해야 하는 어려운(하지만 성공하면 가치 있는) 과제를 안고 있는 셈이다. 이때는 투고할 학회의 성격에 맞춰 서론(Introduction)의 강조점을 미세하게 조정하는 ‘프레이밍(Framing)’ 전략이 필요하다.</p>
<h2>6.  결론: 유동적인 경계에서의 전략적 생존법</h2>
<p>“내 연구는 어디에 속하는가?“라는 질문에 대한 답은 고정불변의 좌표가 아니다. 연구의 진행 단계에 따라, 그리고 학계의 트렌드 변화에 따라 유동적으로 변할 수 있다. 중요한 것은 연구자가 자신의 연구 성과를 가장 매력적으로 포장할 수 있는 관점을 능동적으로 선택하는 것이다.</p>
<ol>
<li><strong>연구의 핵심 기여(Contribution)를 한 문장으로 정의하라.</strong> 그것이 알고리즘인가, 시스템인가, 아니면 데이터셋인가?</li>
<li><strong>당신이 가진 가장 강력한 증거(Evidence)를 확인하라.</strong> 수학적 증명인가, 시뮬레이션의 압도적인 성능인가, 아니면 실제 로봇의 데모 영상인가? 증거의 형태가 투고할 곳을 결정한다.</li>
<li><strong>학회의 문법을 익혀라.</strong> CVPR에 낼 때는 시각적 분석을, ICRA에 낼 때는 시스템 구성을, NeurIPS에 낼 때는 이론적 함의를 강조하라.</li>
</ol>
<p>자신의 연구가 속할 곳을 아는 것은 단순히 투고처를 고르는 것을 넘어, 누구와 대화할 것인지를 정하는 일이다. 이제 당신의 연구 노트와 실험 데이터를 다시 한번 살펴보라. 당신은 수학자인가, 엔지니어인가, 아니면 그 둘을 잇는 설계자인가? 그 정체성을 확립하는 순간, 당신의 논문은 비로소 독자에게 말을 걸기 시작할 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Differences between robotics and Artificial Intelligence - Telefónica, https://www.telefonica.com/en/communication-room/blog/difference-robotics-ai/</li>
<li>AI vs Robotics know Key Differences and Future Trends - JU-FET, https://set.jainuniversity.ac.in/blogs/artificial-intelligence-vs-robotics</li>
<li>AI vs. Robotics: What’s the Difference? - Coursera, https://www.coursera.org/articles/ai-vs-robotics</li>
<li>Embodied World Models for Decision Making - NeurIPS 2025, https://neurips.cc/virtual/2025/workshop/109532</li>
<li>NeurIPS Expo Talk Panel Recent developments in embodied AI, https://neurips.cc/virtual/2025/128653</li>
<li>Four Ways Computer Vision Is Driving AI-Enhanced Robotics - CVPR, https://cvpr.thecvf.com/Conferences/2025/News/AI_Enhanced_Robotics</li>
<li>Recent advancements in multimodal human–robot interaction - Frontiers, https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2023.1084000/full</li>
<li>Attending - Embodied AI Workshop, https://embodied-ai.org/cvpr2024/</li>
<li>Publications - Perceptual Reasoning and Interaction Research - Ai2, https://prior.allenai.org/publications</li>
<li>Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review - arXiv, https://arxiv.org/html/2510.21758v3</li>
<li>TOWARDS KNOWLEDGE-DRIVEN AI FOR LARGE-SCALE OPTIMIZATION AND ROBOT LEARNING - Purdue University Graduate School, https://hammer.purdue.edu/articles/thesis/TOWARDS_KNOWLEDGE-DRIVEN_AI_FOR_LARGE-SCALE_OPTIMIZATION_AND_ROBOT_LEARNING/28892984</li>
<li>AI-Driven Robotics: Innovations in Design, Perception, and Decision-Making - MDPI, https://www.mdpi.com/2075-1702/13/7/615</li>
<li>Human-Centered AI and Autonomy in Robotics: Insights from a Bibliometric Study This work has been funded by the PNRR - arXiv, https://arxiv.org/html/2504.19848v1</li>
<li>Fusion of Computer Vision and AI in Collaborative Robotics: A Review and Future Prospects, https://www.mdpi.com/2076-3417/15/14/7905</li>
<li>When AI Learns the Why, It Becomes Smarter—and More Responsible | Yale Insights, https://insights.som.yale.edu/insights/when-ai-learns-the-why-it-becomes-smarter-and-more-responsible</li>
<li>Three of the Hottest Topics in Computer Vision Today - CVPR 2026, https://cvpr.thecvf.com/Conferences/2025/News/Paper_Trends</li>
<li>CVPR 2025 Call for Papers - The Computer Vision Foundation, https://cvpr.thecvf.com/Conferences/2025/CallForPapers</li>
<li>IEEE ICRA 2025 | Call for ICRA Expo, https://2025.ieee-icra.org/contribute/call-for-icra-expo/</li>
<li>2025 IEEE International Conference on Robotics and Automation (ICRA), https://2025.ieee-icra.org/</li>
<li>IEEE ICRA 2025 | Calls for Papers and Posters, https://2025.ieee-icra.org/contribute/</li>
<li>Conference impact factor : r/PhD - Reddit, https://www.reddit.com/r/PhD/comments/1aq0bbo/conference_impact_factor/</li>
<li>NeurIPS 2025 Call for Papers, https://neurips.cc/Conferences/2025/CallForPapers</li>
<li>NeurIPS 2025 Workshop on Embodied and Safe-Assured Robotic Systems, https://neurips.cc/virtual/2025/workshop/127833</li>
<li>Learning and Classification Archives - CMU Robotics Institute - Carnegie Mellon University, https://www.ri.cmu.edu/research-topic/learning-and-classification/</li>
<li>CVPR 2025 Workshop List, https://cvpr.thecvf.com/Conferences/2025/workshop-list</li>
<li>Socially intelligent robots: dimensions of human–robot interaction - PMC - NIH, https://pmc.ncbi.nlm.nih.gov/articles/PMC2346526/</li>
<li>Research - HRILab Tufts, https://hrilab.tufts.edu/research/</li>
<li>Research - CMU Robotics Institute - Carnegie Mellon University, https://www.ri.cmu.edu/research-/</li>
<li>Research Overview - Carnegie Mellon University Robotics Institute, https://www.ri.cmu.edu/research-overview/</li>
<li>Distributed Robotics Laboratory - MIT CSAIL, https://www.csail.mit.edu/research/distributed-robotics-laboratory</li>
<li>Research Centers and Labs | EECS at UC Berkeley, https://www2.eecs.berkeley.edu/Research/Areas/Centers/</li>
<li>About - Berkeley Artificial Intelligence Research (BAIR) Lab, https://bair.berkeley.edu/about</li>
<li>Research Focus | Center for Position, Navigation and Time - scpnt, https://scpnt.stanford.edu/research-focus</li>
<li>How to write an annotated bibliography | SFU Library, https://www.lib.sfu.ca/help/cite-write/citation-style-guides/annotated-bibliography</li>
<li>REVIEW AND CITATION STYLE IN RESEARCH ARTICLE INTRODUCTIONS: A COMPARATIVE STUDY BETWEEN NATIONAL AND INTERNATIONAL ENGLISH-MED - ERIC, https://files.eric.ed.gov/fulltext/ED586118.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>