<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2017년 3월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2017년 3월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2017년 AI 및 로봇 연구 동향</a> / <span>2017년 3월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2017년 3월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2017년, AI와 로봇공학 연구의 변곡점</h2>
<p>2017년 3월은 인공지능(AI)과 로봇공학 분야가 중대한 변곡점을 맞이한 시기로 기록된다. 딥러닝 기술이 학문적 성공을 넘어 산업 전반으로 급속히 확산되던 이 시기는, 알파고(AlphaGo)의 역사적인 승리 이후 AI에 대한 사회적 기대와 관심이 최고조에 달했던 때였다. 연구 커뮤니티는 초기 성공에 만족하지 않고, 기술의 근본적인 한계와 잠재적 위험을 해결하려는 성숙한 움직임을 보이기 시작했다. 이 시기의 연구들은 단순한 성능 향상을 넘어 강건성(robustness), 데이터 효율성(data efficiency), 빠른 적응성(fast adaptation), 그리고 윤리적 고찰이라는 새로운 화두를 전면에 내세우며 현재 AI 기술 지형의 견고한 토대를 마련했다.1</p>
<p>본 보고서는 2017년 3월에 발표된 주요 연구 성과들을 세 가지 핵심 축을 중심으로 심층적으로 분석하고자 한다. 첫째, <strong>거시적 관점에서의 사회경제적 영향</strong>을 탐구한다. 자동화 기술이 노동 시장에 미치는 영향을 실증적으로 분석하고, AI가 야기할 윤리적, 규제적 문제를 선제적으로 고찰한 연구들을 살펴본다.3 둘째,</p>
<p><strong>AI 핵심 방법론의 심화</strong>를 다룬다. 딥러닝의 일반화 미스터리를 파헤치는 이론적 탐구부터 데이터 효율성, 강건성, 적응성을 획기적으로 개선한 새로운 알고리즘들의 등장을 조명한다. 셋째, <strong>로봇공학의 물리적 구현</strong>을 분석한다. 인간과 로봇의 상호작용(HRI)에 대한 깊이 있는 탐구와 소프트 로보틱스와 같은 하드웨어 혁신이 어떻게 AI의 물리적 구현을 앞당겼는지 고찰한다.</p>
<p>이 시기의 연구들은 AI 기술이 단순한 패턴 인식 도구를 넘어, 현실 세계와 상호작용하고 사회 구조에 영향을 미치는 행위자(agent)로 진화하고 있음을 명확히 보여주었다. 따라서 2017년 3월의 연구 동향을 분석하는 것은 현재 우리가 마주한 생성 AI 시대의 기술적, 사회적 논의의 뿌리를 이해하는 데 필수적인 과정이라 할 수 있다.</p>
<h2>2.  거시적 관점: AI와 로봇이 사회 및 경제에 미치는 영향</h2>
<p>2017년은 AI 기술의 잠재력에 대한 장밋빛 전망과 함께, 그것이 초래할 사회경제적 변화에 대한 심도 깊은 우려가 본격적으로 제기된 시점이었다. 연구는 크게 두 방향으로 나뉘었다. 하나는 과거 데이터를 기반으로 자동화가 노동 시장에 미친 영향을 실증적으로 분석하는 것이고, 다른 하나는 미래 기술이 야기할 윤리적, 규제적 문제를 선제적으로 고찰하는 것이었다. 이 두 흐름은 기술 발전을 사회적 맥락 안에서 이해하려는 중요한 노력이었다.</p>
<h3>2.1  자동화와 고용 시장의 재편: Acemoglu &amp; Restrepo의 실증 분석</h3>
<p>기술 발전이 일자리에 미치는 영향에 대한 논의는 오랜 역사를 가지고 있지만, 2017년 3월 발표된 MIT의 Daron Acemoglu와 Pascual Restrepo의 NBER 워킹 페이퍼 “Robots and Jobs: Evidence from US Labor Markets“는 이 논쟁에 강력한 실증적 근거를 제시하며 큰 파장을 일으켰다.6 이 연구는 1990년부터 2007년까지 산업용 로봇 도입이 미국 지역 노동 시장(commuting zones)에 미친 영향을 분석했다.</p>
<p>연구의 핵심적인 기여는 ’로봇 노출도(exposure to robots)’라는 혁신적인 계량 변수를 도입한 데 있다. 이 변수는 특정 지역의 산업 구성과 전국적인 산업별 로봇 도입률을 결합하여, 각 지역이 로봇 도입의 충격에 얼마나 노출되었는지를 정량화했다. 이 변수를 활용한 회귀 분석 결과, 산업용 로봇이 고용과 임금에 미치는 부정적인 영향이 통계적으로 유의미하게 나타났다. 구체적으로, 근로자 1,000명당 로봇이 한 대 증가할 때마다 해당 지역의 고용-인구 비율은 약 0.18에서 0.34 퍼센티지 포인트 감소했으며, 임금은 0.25에서 0.5 퍼센트 감소했다.6 이 연구는 존 메이너드 케인스(John Maynard Keynes)가 예견했던 ’기술적 실업’에 대한 오랜 경고를 구체적인 데이터로 뒷받침하며, 자동화의 경제적 효과에 대한 논의를 한 단계 끌어올렸다.6</p>
<p>같은 시기, 컨설팅 기업 PwC에서 발간한 보고서들 역시 거시 경제적 차원에서 자동화의 파급 효과를 조명했다.4 “UK Economic Outlook” 보고서는 미래 전망에 초점을 맞춰, 2030년대 초까지 영국 일자리의 최대 30%가 자동화될 가능성이 높은 고위험군에 속할 수 있다고 예측했다. 이 비율은 미국(38%)이나 독일(35%)보다는 낮지만, 일본(21%)보다는 높은 수치였다.4 또한 “Artificial Intelligence and Robotics – 2017” 보고서는 인도 시장을 중심으로 AI와 로봇 기술이 가져올 지속 가능한 성장의 기회와 함께, ‘Make in India’, ’Skill India’와 같은 국가적 이니셔티브에 미칠 긍정적 영향을 강조하면서도, 사회적, 경제적, 윤리적 고려사항을 담은 정책 프레임워크의 필요성을 역설했다.5</p>
<p>이러한 연구들은 서로 다른 관점과 방법론을 통해 자동화라는 거대한 흐름을 입체적으로 조명했다. Acemoglu와 Restrepo의 연구가 과거의 명확하게 정의된 기술(산업용 로봇)이 남긴 상흔을 정밀하게 분석했다면, PwC의 보고서들은 아직 완전히 실현되지 않은 미래의 범용 기술(AI 및 스마트 머신)이 가져올 잠재적 변화를 예측하고 대비하려 했다. 이러한 시간적, 기술적 분석의 불일치는 2017년 당시 AI 담론의 핵심적인 딜레마를 드러낸다. 즉, 우리는 이미 일어난 공장 자동화에 대해서는 정밀한 데이터를 가지고 있지만, 정작 사회가 더 크게 우려하는 미래의 지능 자동화에 대해서는 추정과 전망에 의존할 수밖에 없다는 점이다. 이 간극은 AI의 사회적 영향에 대한 논의가 종종 추상적이거나 과거 사례에 과도하게 의존하게 되는 원인이 되며, 증거 기반 정책을 수립하려는 정책 입안자들에게 근본적인 도전 과제를 안겨준다.</p>
<table><thead><tr><th>구분</th><th>NBER (Acemoglu &amp; Restrepo)</th><th>PwC (UK Economic Outlook)</th></tr></thead><tbody>
<tr><td><strong>분석 대상 기술</strong></td><td>산업용 로봇 (Industrial Robots)</td><td>자동화 (Automation), 스마트 머신</td></tr>
<tr><td><strong>분석 기간/시점</strong></td><td>1990년 - 2007년 (과거 데이터 분석)</td><td>2030년대 초 (미래 전망)</td></tr>
<tr><td><strong>핵심 방법론</strong></td><td>계량경제학 모델 (로봇 노출도 회귀분석)</td><td>잠재적 자동화 가능성 추정</td></tr>
<tr><td><strong>주요 결론 (고용)</strong></td><td>로봇 1대/1000명 증가 시 고용률 0.18-0.34%p 감소</td><td>영국 일자리의 ~30%가 자동화 고위험</td></tr>
<tr><td><strong>주요 결론 (임금)</strong></td><td>로봇 1대/1000명 증가 시 임금 0.25-0.5% 감소</td><td>명시적 분석 없음</td></tr>
<tr><td></td><td></td><td></td></tr>
</tbody></table>
<h3>2.2  윤리적, 규제적 프레임워크의 모색</h3>
<p>기술 발전의 속도가 사회적 합의와 법적 제도를 앞지르면서, AI와 로봇의 도입에 따른 윤리적, 법적 공백을 메우려는 노력이 본격화되었다. 2017년경 발표된 여러 보고서와 논문들은 이러한 문제의식을 공유하며 체계적인 논의의 틀을 제시하고자 했다.</p>
<p>유럽 의회(European Parliament)를 위해 작성된 보고서는 AI 배포와 관련된 핵심적인 윤리적 딜레마를 포괄적으로 분석했다.3 이 보고서는 AI 기술이 가져올 잠재적 이익을 인정하면서도, 그 이면의 복잡하고 불확실한 문제들을 수면 위로 끌어올렸다. 주요 쟁점으로는 ▲기술 발전의 혜택을 사회 내에서 어떻게 공정하게 분배할 것인가(fair benefit-sharing) ▲자율 시스템이 야기한 문제의 책임은 누구에게 있는가(assigning of responsibility) ▲자동화가 노동자의 권익을 침해하지는 않는가(exploitation of workers) ▲AI 시스템의 막대한 에너지 수요가 환경 및 기후 변화에 미치는 영향 등이 포함되었다.3 더 나아가, 보고서는 AI가 인간의 심리에 미치는 영향까지 고찰했다. 예를 들어, 노인 돌봄과 같은 인간의 사회적 역할을 지능형 로봇이 맡게 될 경우, 인간-로봇 관계가 기존의 인간-인간 관계를 예측하지 못한 방식으로 변화시킬 수 있음을 경고했다. 이는 인권, 정서적 피해, 책임성, 보안, 사생활, 안전, 사회 정의 등 광범위한 윤리적 질문으로 이어졌다.3</p>
<p>학계에서도 규제적 대응을 모색하는 연구가 활발히 이루어졌다. Ronald Leenes 등이 발표한 “Regulatory challenges of robotics: some guidelines for addressing“은 유럽연합 집행위원회의 지원을 받은 RoboLaw 프로젝트의 성과를 바탕으로 로봇 기술에 대한 새로운 규제 패러다임을 제안했다.10 이 연구는 로봇공학 분야의 네 가지 주요 규제 딜레마를 제시했다. 첫째, 빠르게 발전하는 기술을 법규가 어떻게 따라잡을 것인가. 둘째, 기술 혁신 촉진과 시민의 기본권 보호 사이에서 어떻게 균형을 맞출 것인가. 셋째, 기존의 사회 규범을 강화할 것인가, 아니면 새로운 방향으로 변화를 유도할 것인가. 넷째, 기존 법률 체계 내에서 규제할 것인가, 아니면 로봇에 특화된 새로운 법(sui generis laws)을 만들 것인가. 이러한 근본적인 질문들은 유럽의 ‘로보법(robolaw)’ 논의의 기초를 형성하며, 기술과 사회의 조화로운 발전을 위한 법적, 제도적 틀 마련의 중요성을 강조했다.10 이 시기의 논의들은 AI와 로봇 기술을 단순한 효율성 증대의 도구가 아닌, 사회적 가치와 규범 체계에 깊숙이 관여하는 행위자로 인식하기 시작했음을 보여주는 중요한 증거다.</p>
<h2>3.  AI 핵심 방법론의 심화: 딥러닝의 이론과 응용</h2>
<p>2017년 3월은 딥러닝의 폭발적인 경험적 성공을 이론적으로 설명하려는 노력과 함께, 데이터 효율성, 강건성, 적응성과 같은 실용적 한계를 극복하려는 연구가 정점에 달했던 시기였다. 이 시기에 발표된 논문들은 딥러닝을 단순한 ’블랙박스’에서 벗어나 이해하고 제어하려는 연구 커뮤니티의 지적 열망을 보여주는 결정체였다. 이러한 노력은 AI 연구의 패러다임이 ’최적의 성능(Optimal Performance)’에서 ’신뢰 가능한 자율성(Trustworthy Autonomy)’으로 전환되는 중요한 변곡점을 형성했다.</p>
<h3>3.1  경험적 손실 지형에 대한 이론적 탐구: 과대-매개변수화의 미스터리</h3>
<p>딥러닝의 가장 큰 미스터리 중 하나는 ‘수백만 개의 파라미터를 가진 거대한 모델이 훈련 데이터에 과적합되지 않고 어떻게 새로운 데이터에 대해 우수한 일반화(generalization) 성능을 보이는가’ 하는 점이었다. 2017년 3월, Tomaso Poggio 연구실에서 발표한 arXiv 프리프린트 “Theory II: Landscape of the Empirical Risk in Deep Learning“은 이 문제에 대한 중요한 이론적 단초를 제공했다.11</p>
<p>이 연구는 과대-매개변수화(over-parametrization), 즉 훈련 데이터의 수보다 모델 파라미터의 수가 훨씬 많은 심층 컨볼루션 신경망(DCNN)의 경험적 손실(empirical risk) 함수의 지형(landscape)을 분석했다. 연구의 핵심적인 이론적 도구는 대수기하학의 베주 정리(Bézout’s theorem)였다. 연구진은 DCNN의 활성화 함수인 ReLU를 다항식 비선형 함수로 근사할 경우, 훈련 데이터에 대한 오차를 0으로 만드는 가중치(weights)를 찾는 문제는 다변수 다항 방정식 시스템의 해를 찾는 문제와 같아진다고 보았다. 베주 정리에 따르면, 과대-매개변수화된 시스템에서는 이러한 방정식의 해가 무수히 많이 존재한다. 이는 경험적 손실 함수의 지형에 훈련 오차를 0으로 만드는 전역 최솟값(global minimizers)이 단 하나가 아니라 매우 많이 존재하며, 이 해들이 특정 차원에서 ‘평평한(flat)’ 특성을 갖는 퇴화된(degenerate) 형태임을 시사했다.11</p>
<p>이러한 이론적 분석은 손실 함수의 지형이 흔히 생각하는 것처럼 나쁜 지역 최솟값(local minima)이나 안장점(saddle point)과 같은 함정으로 가득 찬 복잡한 형태가 아닐 수 있다는 중요한 관점을 제시했다. 대신, 경사 하강법(gradient descent)과 같은 최적화 알고리즘이 쉽게 도달할 수 있는 넓고 평평한 ‘계곡’ 형태의 전역 최솟값들이 많이 존재할 가능성을 열어주었다.13</p>
<p>이 이론은 ICLR 2017 학회에서 발표된 Chiyuan Zhang 등의 논문 “Understanding deep learning requires rethinking generalization“의 실험 결과와 맞물리며 그 중요성이 더욱 부각되었다.14 이 논문은 최신 DCNN 모델이 실제 이미지 데이터뿐만 아니라, 픽셀을 무작위로 섞은 노이즈 이미지나 레이블을 무작위로 부여한 데이터에도 훈련 오차 0으로 완벽하게 학습할 수 있음을 실험적으로 보였다. 이는 모델의 복잡도를 제어하여 일반화 성능을 높인다는 기존의 통계적 학습 이론이나 정규화(regularization) 기법으로는 딥러닝의 놀라운 일반화 성능을 설명할 수 없음을 의미했다.14 손실 지형에 대한 이론적 탐구는 바로 이 설명의 공백을 메우고, 딥러닝의 작동 원리를 더 깊이 이해할 새로운 길을 제시한 것이다.</p>
<h3>3.2  데이터 효율성 증대를 위한 베이즈 딥러닝과 액티브 러닝</h3>
<p>딥러닝의 실용화를 가로막는 가장 큰 장벽 중 하나는 대규모의 정답(레이블)이 달린 데이터에 대한 의존성이었다. 2017년 3월, Yarin Gal, Zoubin Ghahramani 등이 발표한 “Deep Bayesian Active Learning with Image Data“는 이 문제를 해결하기 위한 매우 실용적이면서도 이론적으로 탄탄한 접근법을 제시했다.15</p>
<p>이 연구의 핵심은 **베이즈 딥러닝(Bayesian Deep Learning)**과 **액티브 러닝(Active Learning)**이라는 두 가지 강력한 기계학습 패러다임을 결합한 것이다. 액티브 러닝은 모델이 스스로 어떤 데이터가 학습에 가장 도움이 될지 판단하여 전문가(oracle)에게 레이블링을 요청함으로써 최소한의 비용으로 최대의 학습 효과를 얻는 것을 목표로 한다.16 이를 위해서는 모델이 자신의 예측에 대해 얼마나 확신하는지, 즉 ’불확실성(uncertainty)’을 정량적으로 측정할 수 있어야 한다. 그러나 일반적인 딥러닝 모델은 불확실성을 표현하는 능력이 부족했다.</p>
<p>이 연구는 이 문제를 해결하기 위해 베이즈 컨볼루션 신경망(Bayesian Convolutional Neural Network, BCNN)을 도입했다. 특히, 기존의 드롭아웃(dropout) 기법을 훈련 시뿐만 아니라 추론(test) 시에도 여러 번 적용하고 그 결과의 변동성을 측정하는 <strong>MC 드롭아웃(Monte Carlo Dropout)</strong> 방식을 사용하여, 복잡한 BCNN의 사후 확률 분포(posterior distribution)를 근사적으로 추정하고 모델의 불확실성을 계산하는 실용적인 방법을 제안했다.16</p>
<p>이렇게 추정된 불확실성은 ’획득 함수(acquisition function)’를 통해 어떤 데이터를 레이블링할지 결정하는 데 사용된다. 연구에서는 최대 엔트로피(Max Entropy)나 BALD(Bayesian Active Learning by Disagreement)와 같은 다양한 획득 함수를 실험했다.18 실험 결과, 이 방법론은 이미지 데이터와 같은 고차원 데이터에 대한 액티브 러닝을 성공적으로 수행할 수 있음을 입증했다. MNIST 손글씨 숫자 데이터셋을 이용한 실험에서, 무작위로 데이터를 선택하는 방식으로는 835개의 레이블링된 이미지가 필요했던 5%의 테스트 에러율을, 제안된 액티브 러닝 기법을 통해서는 단 295개의 이미지, 즉 절반 이하의 데이터만으로 달성할 수 있었다.15 이 연구는 의료 영상 분석과 같이 데이터 확보 및 레이블링 비용이 매우 높은 분야에서 딥러닝의 적용 가능성을 크게 확장시킨 중요한 성과로 평가받는다.19</p>
<h3>3.3  강화학습의 새로운 지평: 강건성과 빠른 적응</h3>
<p>2017년은 강화학습(Reinforcement Learning, RL)이 게임과 같은 가상 환경을 넘어 로봇 제어와 같은 현실 세계의 문제에 본격적으로 도전하기 시작한 해였다. 이 과정에서 두 가지 핵심적인 난제, 즉 시뮬레이션과 현실의 차이에서 오는 ‘강건성’ 문제와 새로운 환경에 빠르게 대처하는 ‘적응성’ 문제가 대두되었다. 2017년 3월에 발표된 두 편의 논문은 이 문제들에 대한 혁신적인 해법을 제시하며 강화학습 연구의 새로운 방향을 열었다.</p>
<h4>3.3.1 강건성 (Robustness): Robust Adversarial Reinforcement Learning (RARL)</h4>
<p>시뮬레이션 환경에서 성공적으로 학습된 강화학습 정책이 실제 로봇에 적용되었을 때 제대로 작동하지 않는 ‘현실 격차(reality gap)’ 문제는 로보틱스 분야의 오랜 난제였다. Lerrel Pinto 등이 발표한 “Robust Adversarial Reinforcement Learning (RARL)“은 이 문제를 정면으로 다루었다.20</p>
<p>이 연구는 문제의 원인을 시뮬레이션 모델의 불완전성이나 훈련 환경과 테스트 환경의 미세한 차이로 보고, 이러한 불확실성을 ’적대적인 외력(adversarial disturbance)’으로 모델링하는 독창적인 아이디어를 제안했다. RARL은 문제를 두 에이전트 간의 제로섬(zero-sum) 미니맥스(minimax) 게임으로 재구성한다. 한쪽에는 원래의 과업을 수행하려는 **주인공 에이전트(protagonist)**가 있고, 다른 한쪽에는 주인공의 임무 수행을 최대한 방해하는 외력을 가하는 **적대자 에이전트(adversary)**가 있다.21 두 에이전트는 함께 훈련된다. 적대자는 주인공을 실패하게 만드는 가장 효과적인 교란(destabilizing forces)을 학습하고, 주인공은 이러한 최악의 교란 속에서도 임무를 완수할 수 있는 강건한 정책(robust policy)을 학습하게 된다.21</p>
<p>이러한 적대적 훈련 방식은 주인공 에이전트가 예상치 못한 변화에 대응하는 능력을 길러, 시뮬레이션과 현실의 차이나 다양한 테스트 환경에 훨씬 더 잘 일반화될 수 있도록 만든다. 다수의 OpenAI Gym 환경에서의 실험 결과, RARL로 훈련된 에이전트는 훈련 안정성이 향상되고, 다양한 테스트 조건에 대한 강건성이 뛰어났으며, 심지어 적대자가 없는 일반적인 환경에서도 기존 방식보다 더 나은 성능을 보였다.20 이는 강화학습의 실용성을 한 단계 끌어올린 중요한 패러다임 전환이었다.</p>
<h4>3.3.2 빠른 적응 (Fast Adaptation): Model-Agnostic Meta-Learning (MAML)</h4>
<p>인간은 몇 번의 시도만으로 새로운 기술을 빠르게 배우지만, 기존의 딥러닝 모델은 새로운 과제를 학습하기 위해 수많은 데이터와 반복 훈련을 필요로 했다. Chelsea Finn, Pieter Abbeel, Sergey Levine이 발표한 “Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks (MAML)“은 소수의 데이터만으로 새로운 과제에 빠르게 적응하는 ‘메타-러닝(meta-learning)’ 또는 ’학습하는 법을 학습(learning to learn)’하는 문제에 대한 매우 일반적이면서도 강력한 해법을 제시했다.23</p>
<p>MAML의 핵심 아이디어는 특정 과제에 최적화된 모델 파라미터를 찾는 것이 아니라, 다양한 과제 분포(<span class="math math-inline">p(\mathcal{T})</span>)에서 어떤 새로운 과제가 주어지더라도 단 몇 번의 경사 하강(gradient steps)만으로 쉽게 미세 조정(fine-tuning)될 수 있는 ’최적의 초기 파라미터(<span class="math math-inline">\theta</span>)’를 학습하는 것이다.25 즉, 모델을 ‘미세 조정하기 쉬운’ 상태로 만드는 것이 목표다.</p>
<p>MAML의 학습 과정은 두 개의 루프(loop)로 구성된다. **내부 루프(inner loop)**에서는 샘플링된 각각의 태스크에 대해 현재의 초기 파라미터 <span class="math math-inline">\theta</span>로부터 몇 단계의 경사 하강을 수행하여 태스크에 특화된 파라미터 <span class="math math-inline">\theta&#39;*{i}</span>를 얻는다. **외부 루프(outer loop)**에서는 이렇게 업데이트된 파라미터 <span class="math math-inline">\theta&#39;*{i}</span>들을 사용하여 각 태스크의 테스트 데이터에 대한 손실을 계산하고, 이 손실의 합을 최소화하는 방향으로 초기 파라미터 <span class="math math-inline">\theta</span>를 업데이트한다.24 이 과정은 그래디언트를 통해 그래디언트를 계산하는(gradient through a gradient) 2차 미분을 필요로 한다.</p>
<p>MAML의 가장 큰 장점은 모델 불가지론적(model-agnostic)이라는 점이다. 경사 하강법으로 학습 가능한 모든 모델(예: CNN, RNN)과 모든 종류의 과제(분류, 회귀, 강화학습)에 별도의 수정 없이 적용할 수 있다.27 이 연구는 소수샷 이미지 분류(few-shot image classification) 벤치마크에서 당시 최고 성능을 달성했을 뿐만 아니라, 강화학습 에이전트가 새로운 목표에 빠르게 적응하도록 하는 데에도 성공적인 결과를 보여주며 메타-러닝 분야에 큰 획을 그었다.23</p>
<p>이 시기에 등장한 RARL과 MAML, 그리고 베이즈 액티브 러닝과 같은 연구들은 AI 연구의 초점이 단순한 성능 경쟁에서 벗어나, 현실 세계의 복잡성과 불확실성에 대응할 수 있는 ’신뢰성’을 확보하는 방향으로 이동하고 있음을 명확히 보여준다. RARL은 ‘어떤 상황에서도 잘 작동하는가?’(강건성)를, MAML은 ‘새로운 상황에 얼마나 빨리 적응하는가?’(적응성)를, 베이즈 액티브 러닝은 ‘최소한의 비용으로 신뢰할 만한 모델을 만들 수 있는가?’(효율성)를 묻는다. 이러한 질문들은 현재 활발히 연구되고 있는 설명가능 AI(XAI), AI 안전성(AI Safety), 강건한 AI(Robust AI) 분야의 직접적인 뿌리가 되었다.</p>
<table><thead><tr><th>연구 분야</th><th>해결하고자 하는 문제</th><th>핵심 아이디어</th><th>기술적 기여</th></tr></thead><tbody>
<tr><td><strong>딥러닝 이론</strong></td><td>과대-매개변수화 모델의 일반화 성능</td><td>경험적 손실 함수의 지형은 ‘평평한’ 전역 최솟값들로 구성</td><td>베주 정리를 통한 전역 최솟값 존재 증명</td></tr>
<tr><td><strong>데이터 효율성</strong></td><td>대규모 레이블링 데이터 의존성</td><td>베이즈 CNN으로 불확실성을 추정, 정보 가치가 높은 데이터 선택</td><td>딥러닝과 액티브 러닝의 실용적 결합</td></tr>
<tr><td><strong>강화학습 (강건성)</strong></td><td>Sim-to-Real 격차, 환경 변화 취약성</td><td>주인공-적대자 에이전트 간의 미니맥스 게임</td><td>강건한 정책 학습을 위한 적대적 훈련 프레임워크 (RARL)</td></tr>
<tr><td><strong>강화학습 (적응성)</strong></td><td>소수 샘플 기반의 빠른 신규 과제 학습</td><td>‘미세 조정하기 쉬운’ 초기 파라미터 학습</td><td>모델-불가지론적 메타-러닝 알고리즘 (MAML)</td></tr>
</tbody></table>
<h3>3.4  자연어 생성(NLG) 기술 동향 종합</h3>
<p>2017년 3월은 이후 자연어 처리(NLP) 분야에 혁명을 가져온 트랜스포머(Transformer) 아키텍처(“Attention Is All You Need”)가 발표되기 불과 몇 달 전이었다.30 이 시점에 Albert Gatt와 Emiel Krahmer가 발표한 서베이 논문 “Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation“은 당시 자연어 생성(Natural Language Generation, NLG) 분야의 기술 현황을 집대성한 중요한 학술적 기록이다.31</p>
<p>이 논문은 NLG를 ’비언어적 입력으로부터 텍스트나 음성을 생성하는 과업’으로 정의하고, 지난 10여 년간 데이터 기반 방법론이 부상하면서 NLG 분야가 겪은 변화를 체계적으로 정리했다.32 특히, 복잡한 NLG 시스템을 구성하는 핵심 과업들을 다음과 같이 세분화하여 설명했다 33:</p>
<ol>
<li>
<p><strong>내용 결정 (Content Determination):</strong> 생성할 텍스트에 어떤 정보를 포함할지 입력 데이터로부터 선택하는 단계.</p>
</li>
<li>
<p><strong>텍스트 구조화 (Text Structuring):</strong> 선택된 정보들을 어떤 순서로 배열하고 문단이나 섹션으로 구성할지 결정하는 단계.</p>
</li>
<li>
<p><strong>문장 집합 (Sentence Aggregation):</strong> 관련된 정보들을 하나의 문장으로 결합할지, 여러 문장으로 나눌지 결정하는 단계.</p>
</li>
<li>
<p><strong>어휘화 (Lexicalisation):</strong> 추상적인 개념이나 의미를 구체적인 단어나 구로 변환하는 단계.</p>
</li>
<li>
<p><strong>지시 표현 생성 (Referring Expression Generation, REG):</strong> 문맥 속에서 특정 대상을 지칭하기 위해 ‘그 로봇’, ’파란색 상자’와 같은 적절한 표현을 선택하는 단계.</p>
</li>
<li>
<p><strong>언어적 구현 (Linguistic Realisation):</strong> 앞선 단계에서 결정된 내용과 구조를 문법적으로 올바른 문장으로 최종 완성하는 단계. 이 단계에서는 템플릿 기반 방식, 문법 규칙 기반 방식, 통계적 방식 등이 사용되었다.32</p>
</li>
</ol>
<p>또한, 이 논문은 NLG 시스템의 성능을 평가하는 것이 왜 어려운 문제인지를 심도 있게 다루었다. NLG는 정답이 하나로 정해져 있지 않고 다양한 표현이 가능하기 때문에, 평가가 매우 복잡하다. 논문은 평가 방법론을 크게 두 가지로 나누어 설명했다 32:</p>
<ul>
<li>
<p><strong>내재적 평가 (Intrinsic Evaluation):</strong> 생성된 텍스트 자체의 품질을 평가하는 방법. 여기에는 사람이 직접 유창성(fluency), 문법성(grammaticality), 적절성(appropriateness) 등을 주관적으로 평가하는 방식과, BLEU나 ROUGE와 같이 생성된 텍스트를 사람이 작성한 참조 텍스트와 비교하여 유사도를 측정하는 자동 평가 지표가 포함된다.</p>
</li>
<li>
<p><strong>외재적 평가 (Extrinsic Evaluation):</strong> 생성된 텍스트가 특정 과업(예: 사용자가 길을 찾는 데 도움을 주는 것)을 얼마나 잘 수행하는지를 평가하는 방법. 이는 시스템의 실용적인 가치를 측정하는 데 중점을 둔다.</p>
</li>
</ul>
<p>이 서베이 논문은 딥러닝 기반의 종단간(end-to-end) 모델이 NLG를 지배하기 직전, 파이프라인 기반의 전통적인 접근법과 초기 데이터 기반 방법론이 공존하던 시기의 기술 지형을 상세히 보여준다.35 이는 이후 트랜스포머 기반 모델들이 어떤 문제들을 해결했으며, 여전히 어떤 과제들이 남아있는지를 이해하는 데 중요한 비교 기준점을 제공한다.</p>
<h2>4.  로봇공학의 발전: 인간과의 상호작용 및 물리적 구현</h2>
<p>AI 방법론의 발전은 로봇이 더 복잡한 환경에서 인간과 더 정교하게 상호작용하고 협력할 수 있는 가능성을 열었다. 2017년 3월의 로봇공학 연구는 AI의 지능을 어떻게 물리적 세계에 구현하고(하드웨어 및 제어), 인간 사회에 자연스럽게 통합할 것인가(인간-로봇 상호작용)라는 두 가지 핵심 질문에 집중되었다. 이러한 연구들은 AI와 로봇공학이 더 이상 분리된 분야가 아니라, ’체화된 지능(Embodied Intelligence)’이라는 하나의 목표를 향해 수렴하고 있음을 명확히 보여주었다.</p>
<h3>4.1  HRI 2017 학회를 통해 본 인간-로봇 상호작용의 최전선</h3>
<p>2017년 3월 6일부터 9일까지 오스트리아 비엔나에서 개최된 제12회 ACM/IEEE 국제 인간-로봇 상호작용 컨퍼런스(HRI 2017)는 “스마트 상호작용(Smart Interaction)“을 주제로, 인간과 로봇이 어떻게 효과적으로 소통하고 협력할 수 있는지에 대한 최신 연구들을 선보였다.37 학회에서 발표된 논문들은 로봇의 표현력, 대화 능력, 그리고 인간의 신뢰와 같은 HRI의 핵심적인 주제들을 깊이 있게 다루었다.37</p>
<p>주요 연구 동향은 다음과 같이 요약할 수 있다:</p>
<ul>
<li>
<p><strong>표현성 증대 (Creating Expressive Robots):</strong> 로봇이 자신의 내부 상태나 의도를 인간에게 효과적으로 전달하는 것은 원활한 상호작용의 핵심이다. HRI 2017에서는 로봇의 표현력을 높이기 위한 다양한 연구가 발표되었다. 예를 들어, 외형이 단순한 로봇이 색상, 소리, 진동의 조합을 통해 감정을 표현하는 연구, 서보 모터의 소리를 의도적인 상호작용 신호로 활용하는 연구, 그리고 로봇 팔의 움직임 타이밍을 조절하여 자신감이나 운반하는 물체의 무게와 같은 정보를 전달하는 연구 등이 주목받았다.39 특히 시선 처리는 중요한 연구 주제였는데, 광학적 착시를 이용해 여러 사람에게 동시에 시선을 보내는 듯한 효과를 주는 ’Transgazer’나, 그룹 대화 상황에서 로봇의 몸 방향과 시선이 상호작용에 미치는 영향을 분석한 연구는 로봇의 사회적 상호작용 능력을 한 단계 끌어올리려는 시도였다.40</p>
</li>
<li>
<p><strong>대화 및 교육 (Human-Robot Dialog &amp; Robots in Education):</strong> 로봇이 인간의 언어를 이해하고 사용하는 능력은 HRI의 중요한 축이다. 한 연구에서는 인간이 로봇과 대화할 때 로봇의 어휘를 따라 하는 ‘어휘적 동화(lexical entrainment)’ 현상이 발생하며, 이는 상호작용이 끝난 후에도 지속됨을 발견했다.37 이는 로봇이 인간의 언어 사용에 영향을 미칠 수 있음을 시사한다. 또한, 컨시어지 로봇이 사용자와의 상호작용을 통해 스스로 대화 능력을 향상시키는 온라인 학습 방법론도 제시되었다.37</p>
</li>
<li>
<p><strong>신뢰와 프라이버시 (Trust and Privacy):</strong> 인간이 자율 시스템을 어떻게 인식하고 신뢰하는지에 대한 근본적인 질문들이 제기되었다. 한 연구는 사용자가 자율주행차에 대해 자신의 운전 스타일을 모방하기보다는, 더 방어적인 운전 스타일을 선호한다는 흥미로운 사실을 발견했다.37 이는 ‘인간과 같은’ AI가 항상 최선은 아닐 수 있음을 시사한다. 또한, 시스템의 투명성이 사용자의 신뢰에 미치는 영향을 동적으로 분석한 연구는, 신뢰가 고정된 변수가 아니라 상호작용을 통해 진화하는 과정임을 보여주며, 투명성이 신뢰 하락을 완화하는 데 기여할 수 있음을 밝혔다.39</p>
</li>
</ul>
<p>이러한 연구 동향 속에서, **최우수 논문 후보작(Best Paper Award Nominee)**으로 선정된 Maryam Moosaei 등의 **“Using Facially Expressive Robots to Calibrate Clinical Pain Perception”**은 HRI 연구가 실제 사회 문제 해결에 어떻게 기여할 수 있는지를 보여주는 대표적인 사례였다.40 이 연구는 표정이 풍부한 로봇 환자 시뮬레이터(Robotic Patient Simulator, RPS)를 개발하고, 이를 의료진의 통증 진단 능력 향상에 활용하고자 했다. 연구진은 자율적인 얼굴 표정 합성 기술을 이용해 고통, 분노, 혐오 등의 표정을 물리적 로봇과 가상 아바타에 구현했다. 그리고 51명의 임상의와 51명의 비전문가를 대상으로 이 표정을 얼마나 정확하게 인식하는지 실험했다.42</p>
<p>실험 결과는 두 가지 흥미로운 사실을 드러냈다. 첫째, 임상의들이 비전문가 집단보다 합성된 고통 표정을 인식하는 정확도가 오히려 낮았다. 이는 임상의들이 실제 환자를 대하는 경험이 오히려 시뮬레이션된 표정 인식에 편향으로 작용할 수 있음을 시사한다. 둘째, 모든 참가자가 가상 아바타보다 물리적 로봇의 표정을 인식하는 데 더 어려움을 겪었다.40 이는 로봇이라는 물리적 실체(embodiment)가 인간의 인식에 복잡한 영향을 미친다는 것을 보여주는 결과로, ‘불쾌한 골짜기(uncanny valley)’ 현상과도 관련지어 해석될 수 있다. 이 연구는 로봇을 의료진의 진단 능력을 객관적으로 측정하고 보정하는 훈련 도구로 활용할 수 있다는 새로운 가능성을 제시함과 동시에, HRI 분야의 핵심적인 이론적 질문인 ’물리적 구현’의 효과를 탐구했다는 점에서 높은 평가를 받았다.43</p>
<table><thead><tr><th>세션 주제</th><th>대표 연구 내용</th><th>핵심 기여 및 시사점</th></tr></thead><tbody>
<tr><td><strong>표현성 증대</strong></td><td>로봇의 움직임 타이밍, 시선, 비언어적 신호를 통한 내부 상태 표현</td><td>인간이 로봇의 의도를 더 잘 이해하고 예측할 수 있게 하여 상호작용의 투명성 증대</td></tr>
<tr><td><strong>인간-로봇 대화</strong></td><td>로봇과의 대화에서 나타나는 언어적 동화 현상 분석</td><td>로봇이 인간의 언어 사용에 영향을 미칠 수 있음을 보여주며, 더 자연스러운 대화 모델 연구의 필요성 제시</td></tr>
<tr><td><strong>신뢰 및 프라이버시</strong></td><td>자율주행차의 운전 스타일에 대한 사용자 선호도 분석</td><td>사용자는 자신의 운전 스타일보다 더 방어적인 스타일을 선호. ‘인간과 같은’ AI가 항상 최선은 아님을 시사</td></tr>
<tr><td><strong>의료 및 임상</strong></td><td>표정 로봇을 이용한 임상의의 통증 인식 정확도 측정 (최우수 논문 후보)</td><td>로봇을 의료진 훈련 및 능력 보정 도구로 활용할 새로운 가능성 제시. 물리적 구현이 인식에 미치는 영향 탐구</td></tr>
</tbody></table>
<h3>4.2  로봇 하드웨어 및 제어 기술의 혁신</h3>
<p>AI 알고리즘의 발전은 로봇의 ’두뇌’를 고도화하는 과정이라면, 하드웨어와 제어 기술의 혁신은 로봇의 ’몸’을 만들고 움직이게 하는 과정이다. 2017년 3월을 전후하여 발표된 연구들은 로봇의 물리적 형태와 능력을 근본적으로 바꾸려는 시도들을 보여주었다.</p>
<h4>4.2.1 소프트 로보틱스와 3D 프린팅의 결합</h4>
<p>전통적인 로봇이 금속과 모터로 이루어진 강체(rigid body)였던 반면, 생명체처럼 부드럽고 유연한 소재로 만들어진 소프트 로봇(soft robot)은 새로운 가능성을 제시했다. ICRA 2017 학회에 발표된 “3D-Printed Ionic Polymer Metal Composite (IPMC) Soft Crawling Robot“은 소프트 로보틱스와 적층 제조(additive manufacturing) 기술의 융합을 보여주는 대표적인 사례다.45</p>
<p>이 연구의 핵심은 **이온성 고분자-금속 복합체(IPMC)**라는 스마트 소재를 활용한 것이다. IPMC는 낮은 전압을 가하면 구부러지는 특성을 가진 ‘인공 근육’ 소재로, 부드러운 작동기(actuator)를 만드는 데 이상적이다.48 연구진은 이 IPMC 소재를 3D 프린팅 기술을 이용해 원하는 형태로 직접 제작하는 데 성공했다. 이를 통해 다리와 몸통이 일체화된 벌레 형태의 소프트 크롤링 로봇을 저렴하고 빠르게 제작할 수 있었다.46 이 로봇은 전압 신호에 따라 다리를 움직여 기어가는 움직임을 구현했다. 이 연구는 복잡한 조립 과정 없이 기능적인 소프트 로봇을 ’출력’할 수 있는 길을 열었으며, 이는 맞춤형 로봇이나 일회용 의료 로봇 등 새로운 응용 분야의 가능성을 제시했다.50</p>
<h4>4.2.2 자율 로봇을 위한 제어 및 인식 기술</h4>
<p>로봇이 복잡하고 예측 불가능한 실제 환경에서 안정적으로 임무를 수행하기 위해서는 정교한 제어 및 인식 기술이 필수적이다. 이 시기에도 관련 기반 기술 연구가 꾸준히 발전했다.</p>
<p>학술지 <em>Robotics</em> 2017년 3월호에 실린 연구들은 이러한 기술적 진보를 잘 보여준다.52 한 연구에서는 마이크로 공중 비행체(Micro Aerial Vehicle, MAV)의 안정적인 비행을 위해, 여러 개의 카메라 뷰를 파티클 필터(particle filter) 프레임워크 내에서 동시에 고려하는 새로운 비전 기술(Combined Vision Technique, CVT)을 제안하여 자세 추정의 정확도를 높였다. 또 다른 연구는 동적인 환경에서 자율 이동 로봇이 장애물을 회피하며 목표 지점까지 최단 거리와 최소 에너지로 도달할 수 있는 다중 센서 기반의 최적 경로 계획 알고리즘을 개발했다. 이 외에도 재난 상황에서 군중을 대피시키는 로봇이나, 시각 정보를 이용해 자신의 위치를 인식하는 기술(Visual Place Recognition)에 대한 연구도 발표되었다.52</p>
<p>이러한 하드웨어 및 제어 기술의 발전은 제2부에서 논의된 AI 방법론의 발전과 깊은 연관을 맺는다. 예를 들어, 로봇이 실제 환경에서 작동하려면 예측 불가능한 물리적 변화에 강건해야 하는데, 이는 RARL이 목표하는 바와 정확히 일치한다.20 또한 로봇이 다양한 가정이나 공장 환경에서 유용하려면 새로운 물건을 다루거나 새로운 작업을 배우는 데 빠르게 적응해야 하며, 이는 MAML이 해결하고자 하는 문제다.23 반대로, 3D 프린팅 소프트 로봇과 같은 새로운 하드웨어의 등장은 기존의 강체 로봇과는 다른 새로운 제어 알고리즘과 학습 패러다임을 요구하며 AI 연구에 새로운 도전 과제를 제시한다.53 이처럼 AI의 발전은 로봇의 지능을 고도화하고, 로봇이라는 물리적 플랫폼은 AI 연구에 새로운 영감과 현실적인 제약조건을 제공하며 상호 발전을 촉진하는 선순환 구조가 이 시기에 본격적으로 형성되기 시작했다.</p>
<h2>5. 결론: 2017년 3월이 남긴 유산과 미래 전망</h2>
<p>2017년 3월에 발표된 주요 연구들은 AI와 로봇공학 분야가 폭발적인 양적 성장을 넘어 질적 성숙의 단계로 진입했음을 보여주는 중요한 이정표였다. 이 시기는 딥러닝의 경험적 성공에 대한 환호 속에서, 그 기술의 근본적인 원리를 탐구하고(손실 지형), 실용적 한계를 극복하며(데이터 효율성, 강건성, 적응성), 사회적 책임을 고민하는(고용, 윤리, 규제) 다각적인 노력이 동시에 분출된 지적 전환점이었다.</p>
<p>첫째, 사회경제적 차원에서 AI는 더 이상 기술자들만의 논의가 아닌, 사회 전체의 의제가 되었다. Acemoglu와 Restrepo의 연구는 자동화가 노동 시장에 미치는 영향을 구체적인 숫자로 제시하며 논의의 무게를 더했고, 유럽 의회와 여러 학자들은 AI의 윤리적, 규제적 프레임워크를 선제적으로 모색하며 기술의 책임 있는 발전을 위한 초석을 다졌다.</p>
<p>둘째, AI 방법론은 ’성능’을 넘어 ’신뢰’라는 새로운 가치를 향해 나아갔다. 과대-매개변수화 모델의 일반화 가능성을 탐구한 이론 연구, 최소한의 데이터로 최대의 효과를 내려는 베이즈 액티브 러닝, 현실의 불확실성에 맞서는 강건한 강화학습(RARL), 그리고 새로운 환경에 빠르게 적응하는 메타-러닝(MAML)은 모두 예측 가능하고 신뢰할 수 있는 AI를 만들려는 노력의 일환이었다. 이러한 흐름은 현재 AI 연구의 핵심 화두인 설명가능성(XAI), 안전성(AI Safety), 그리고 정렬(Alignment) 문제의 직접적인 선구자 역할을 했다.</p>
<p>셋째, 로봇공학은 AI라는 강력한 두뇌와 결합하여 ’체화된 지능’으로의 진화를 가속화했다. HRI 2017 학회에서 논의된 로봇의 표현력, 대화 능력, 신뢰 문제는 AI가 해결해야 할 새로운 사회적, 인지적 과제를 제시했다. 동시에 3D 프린팅 소프트 로봇과 같은 하드웨어 혁신은 AI 알고리즘이 도전할 새로운 물리적 플랫폼을 제공하며 AI와 로봇공학의 상호 촉진적인 발전을 이끌었다.</p>
<p>결론적으로 2017년 3월은 AI 기술이 단순한 도구를 넘어 사회의 구조를 바꾸고 인간과 새로운 관계를 맺는 ’행위자(agent)’로서의 가능성과 책임을 동시에 인식하기 시작한 중요한 시점이었다. 이때 제시된 개념들과 시작된 고민들은 이후 수많은 후속 연구를 통해 각 분야의 표준적인 방법론으로 자리 잡았으며, 오늘날 우리가 마주한 거대 언어 모델(LLM)과 생성 AI 시대의 복잡한 도전 과제들을 이해하고 해결하는 데 여전히 깊고 유효한 통찰을 제공하고 있다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>AI and Robotics: Transforming Industries and Society, https://ijfans.org/uploads/paper/ca5d9c92c719a4b3e6ab9ae9fd949d15.pdf</li>
<li>(PDF) The future of Robotics Technology - ResearchGate, https://www.researchgate.net/publication/315986147_The_future_of_Robotics_Technology</li>
<li>The ethics of artificial intelligence: Issues and initiatives - European Parliament, https://www.europarl.europa.eu/RegData/etudes/STUD/2020/634452/EPRS_STU(2020)634452_EN.pdf</li>
<li>Will robots steal our jobs? The potential impact of automation - PwC UK, https://www.pwc.co.uk/economic-services/ukeo/pwcukeo-section-4-automation-march-2017-v2.pdf</li>
<li>Artificial Intelligence and Robotics - 2017 - PwC India, https://www.pwc.in/assets/pdfs/publications/2017/artificial-intelligence-and-robotics-2017.pdf</li>
<li>Robots and Jobs: Evidence from US Labor Markets - National …, https://www.nber.org/system/files/working_papers/w23285/w23285.pdf</li>
<li>Robots and Jobs: Evidence from US Labor Markets | NBER, https://www.nber.org/papers/w23285</li>
<li>Robots and Jobs: Evidence from US Labor Markets - Industrial Relations Section, https://irs.princeton.edu/sites/irs/files/event/uploads/robots_and_jobs_march_3.17.2017_final.pdf</li>
<li>Harnessing the power of artificial intelligence and robotics impact on attaining competitive advantage for sustainable development in hospitals with conclusions for future research approaches - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC11035984/</li>
<li>Regulatory challenges of robotics: some guidelines for addressing legal and ethical issues, https://www.tandfonline.com/doi/full/10.1080/17579961.2017.1304921</li>
<li>[1703.09833] Theory II: Landscape of the Empirical Risk in Deep Learning - arXiv, https://arxiv.org/abs/1703.09833</li>
<li>Theory II: Landscape of the Empirical Risk in Deep Learning | Request PDF - ResearchGate, https://www.researchgate.net/publication/315695851_Theory_II_Landscape_of_the_Empirical_Risk_in_Deep_Learning</li>
<li>Theory of Deep Learning IIb: Optimization Properties of SGD, https://cbmm.mit.edu/sites/default/files/publications/CBMM-Memo-072.pdf</li>
<li>[1611.03530] Understanding deep learning requires rethinking generalization - arXiv, https://arxiv.org/abs/1611.03530</li>
<li>[1703.02910] Deep Bayesian Active Learning with Image Data - arXiv, https://arxiv.org/abs/1703.02910</li>
<li>Deep Bayesian Active Learning with Image Data, https://proceedings.mlr.press/v70/gal17a/gal17a.pdf</li>
<li>Deep Bayesian Active Learning with Image Data - arXiv, https://arxiv.org/pdf/1703.02910</li>
<li>Deep Bayesian Active Learning with Image Data, https://www.cs.ox.ac.uk/people/yarin.gal/website/PDFs/NIPS_2016_workshop_paper.pdf</li>
<li>Deep Active Learning for Robust Biomedical Segmentation - bioRxiv, https://www.biorxiv.org/content/10.1101/2023.03.28.534521v2.full.pdf</li>
<li>[1703.02702] Robust Adversarial Reinforcement Learning - arXiv, https://arxiv.org/abs/1703.02702</li>
<li>Robust Adversarial Reinforcement Learning, http://proceedings.mlr.press/v70/pinto17a/pinto17a.pdf</li>
<li>Robust Adversarial Reinforcement Learning with Dissipation Inequation Constraint - The Association for the Advancement of Artificial Intelligence, https://cdn.aaai.org/ojs/20481/20481-13-24494-1-2-20220628.pdf</li>
<li>Model-Agnostic Meta-Learning for Fast Adaptation of Deep … - arXiv, https://arxiv.org/abs/1703.03400</li>
<li>Model-Agnostic Meta-Learning for Fast Adaptation of Deep … - arXiv, https://arxiv.org/pdf/1703.03400</li>
<li>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks, https://proceedings.mlr.press/v70/finn17a/finn17a.pdf</li>
<li>1월 1, 1970에 액세스, https://arxiv.org/pdf/1703.03400.pdf</li>
<li>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks - ResearchGate, https://www.researchgate.net/publication/314433751_Model-Agnostic_Meta-Learning_for_Fast_Adaptation_of_Deep_Networks</li>
<li>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks, https://dvl.in.tum.de/slides/automl-ss21/MAML.pdf</li>
<li>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks - HyoJung Han, https://h-j-han.github.io/papers/model_agnostic_meta_learning_for_fast_adaptation_of_deep_networks/</li>
<li>[1706.03762] Attention Is All You Need - arXiv, https://arxiv.org/abs/1706.03762</li>
<li>[1703.09902] Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation - arXiv, https://arxiv.org/abs/1703.09902</li>
<li>arXiv:1703.09902v1 [cs.CL] 29 Mar 2017 - ResearchGate, https://www.researchgate.net/profile/Emiel-Krahmer/publication/315696017_Survey_of_the_State_of_the_Art_in_Natural_Language_Generation_Core_tasks_applications_and_evaluation/links/58dea98aaca272059aaac79a/Survey-of-the-State-of-the-Art-in-Natural-Language-Generation-Core-tasks-applications-and-evaluation.pdf</li>
<li>Natural Language Generation - OSF, https://osf.io/jn9y3/download</li>
<li>Survey of the State of the Art in Natural language Generation: Core tasks, applications and evaluation - Tilburg University Research Portal, https://research.tilburguniversity.edu/en/publications/survey-of-the-state-of-the-art-in-natural-language-generation-cor</li>
<li>Survey of Hallucination in Natural Language Generation - arXiv, https://arxiv.org/pdf/2202.03629</li>
<li>
<ol start="8">
<li>Natural Language Generation, https://ufal.mff.cuni.cz/~odusek/courses/npfl099/slides/NPFL099-2024_08-nlg.pdf</li>
</ol>
</li>
<li>Full Papers – HRI 2017 / Vienna / March 6-9, 2017, https://humanrobotinteraction.org/2017/authors/call-for-papers/index.html</li>
<li>HRI ’17 : companion of the 2017 ACM/IEEE International Conference on Human Robot Interaction : March 6-9, 2017, Vienna, Austria - University of New South Wales, <a href="https://primoa.library.unsw.edu.au/discovery/fulldisplay?docid=alma9951043665201731&amp;context=L&amp;vid=61UNSW_INST:UNSWS&amp;lang=en&amp;search_scope=MyInst_and_CI&amp;adaptor=Local+Search+Engine&amp;tab=Everything&amp;query=sub,exact,Human-machine+systems,AND&amp;mode=advanced&amp;offset=0">https://primoa.library.unsw.edu.au/discovery/fulldisplay?docid=alma9951043665201731&amp;context=L&amp;vid=61UNSW_INST:UNSWS&amp;lang=en&amp;search_scope=MyInst_and_CI&amp;adaptor=Local%20Search%20Engine&amp;tab=Everything&amp;query=sub%2Cexact%2CHuman-machine%20systems%2CAND&amp;mode=advanced&amp;offset=0</a></li>
<li>Top 281 papers presented at Human-Robot Interaction in 2017 - SciSpace, https://scispace.com/conferences/human-robot-interaction-19a8wssp/2017</li>
<li>Accepted Full Papers - Human-Robot Interaction, https://humanrobotinteraction.org/2017/programme/accepted-full-papers/index.html</li>
<li>Towards Robot Autonomy in Group Conversations: Understanding the Effects of Body Orientation and Gaze, https://www.ri.cmu.edu/pub_files/2017/3/BrainstormingExperiment_HRI17.pdf</li>
<li>(PDF) Using Facially Expressive Robots to Calibrate Clinical Pain …, https://www.researchgate.net/publication/314160014_Using_Facially_Expressive_Robots_to_Calibrate_Clinical_Pain_Perception</li>
<li>Facing the FACS—Using AI to Evaluate and Control Facial Action Units in Humanoid Robot Face Development - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC9237251/</li>
<li>(PDF) In Your Face, Robot! The Influence of a Character’s Embodiment on How Users Perceive Its Emotional Expressions - ResearchGate, https://www.researchgate.net/publication/2932479_In_Your_Face_Robot_The_Influence_of_a_Character’s_Embodiment_on_How_Users_Perceive_Its_Emotional_Expressions</li>
<li>Accepted 2017 ICRA papers by Utah Robotics Faculty and Students, https://robotics.coe.utah.edu/icra_2017/</li>
<li>3D-printed ionic polymer-metal composite soft crawling robot - Semantic Scholar, https://www.semanticscholar.org/paper/3D-printed-ionic-polymer-metal-composite-soft-robot-Carrico-Kim/655596d3fe08fc0e42119aee99a1506b61ca3772/figure/2</li>
<li>papers in conference proceedings - Professor Kwang J. Kim, Ph.D. | University of Nevada, Las Vegas, http://www.kwangjinkim.org/c_papers.html</li>
<li>3D-printed ionic polymer-metal composite soft crawling robot | Request PDF - ResearchGate, https://www.researchgate.net/publication/318692267_3D-printed_ionic_polymer-metal_composite_soft_crawling_robot</li>
<li>‪James D.Carrico, Ph.D.‬ - ‪Google Scholar‬, https://scholar.google.com/citations?user=KtFN6O8AAAAJ&amp;hl=en</li>
<li>A Proprioceptive Soft Robot Module Based on Supercoiled Polymer Artificial Muscle Strings - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC9182732/</li>
<li>3D-Printing and Machine Learning Control of Soft Ionic Polymer, https://ouci.dntb.gov.ua/en/works/4MoAYPz9/</li>
<li>Robotics, Volume 6, Issue 2 (June 2017) – 8 articles, <a href="https://www.mdpi.com/2218-6581/6/2?view=abstract&amp;listby=pubdate_published+DESC,firstpage+DESC,number+DESC&amp;page_no=1">https://www.mdpi.com/2218-6581/6/2?view=abstract&amp;listby=pubdate_published+DESC%2Cfirstpage+DESC%2Cnumber+DESC&amp;page_no=1</a></li>
<li>Practical hardware for evolvable robots - Frontiers, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2023.1206055/full</li>
<li>Open Robot Hardware: Progress, Benefits, Challenges, and Best Practices - ResearchGate, https://www.researchgate.net/publication/366430814_Open_Robot_Hardware_Progress_Benefits_Challenges_and_Best_Practices</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>