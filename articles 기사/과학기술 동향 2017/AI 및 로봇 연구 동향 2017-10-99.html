<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2017년 10월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2017년 10월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2017년 AI 및 로봇 연구 동향</a> / <span>2017년 10월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2017년 10월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2017년 10월, AI 역사의 변곡점</h2>
<p>2017년 10월은 인공지능(AI) 기술의 역사에서 하나의 패러다임이 저물고 새로운 패러다임이 부상하는 결정적 변곡점으로 기록된다. 이 시기는 단순히 몇 가지 주목할 만한 기술적 진보가 이루어진 것을 넘어, AI가 인간의 지식 체계를 뛰어넘어 스스로 지식을 창출할 수 있다는 가능성을 명백히 증명했으며, 동시에 그 강력한 기술력에 대한 사회적, 윤리적 성찰이 본격적으로 분출되기 시작한 시점이었다.1 AI 연구의 ’내재적 동력’이 정점에 달하는 순간, 그 힘을 어떻게 제어하고 사회와 조화시킬 것인가에 대한 ’외재적 성찰’이 동시에 시작된 것이다.</p>
<p>구글 딥마인드의 알파고 제로(AlphaGo Zero)는 인간의 데이터를 전혀 사용하지 않고 오직 자가 대국(self-play)만으로 기존의 모든 인공지능과 인간 최고수를 압도하는 경지에 도달하며, AI가 데이터의 제약으로부터 해방될 수 있음을 선언했다.4 이는 AI 발전의 동력이 ’인간 데이터의 학습’에서 ’규칙 내에서의 무한한 탐색’으로 전환될 수 있음을 시사하는 기념비적인 사건이었다. 거의 동시에, AI의 사회적 영향을 분석하는 AI Now Institute의 2017년 보고서가 발표되고 딥마인드 내부에 AI 윤리 및 사회팀이 신설된 것은 우연이 아니다.3 이처럼 폭발적인 기술적 도약은 그 기술이 가져올 사회적 파장에 대한 깊은 고찰을 필연적으로 요구했고, 2017년 10월은 바로 그 두 흐름이 교차하고 융합하기 시작한 역사적 분기점이었다.</p>
<p>본 보고서는 이처럼 중대한 의미를 지니는 2017년 10월 한 달 동안 AI 및 로봇 분야에서 발표된 주요 연구 및 산업 동향을 심층적으로 분석하고자 한다. 1장에서는 강화학습의 새로운 지평을 연 알파고 제로의 기술적 성취와 그 의의를 상세히 해부한다. 2장에서는 세계 최고 권위의 학술대회인 ICCV와 IROS에서 발표된 컴퓨터 비전 및 로보틱스 분야의 핵심 연구들을 조명하며 당시 기술의 최전선을 살펴본다. 3장에서는 항공우주 기업 보잉(Boeing)의 전략적 투자를 중심으로 AI 기술의 산업적 파급력과 상용화 동향을 분석한다. 마지막으로 4장에서는 AI가 경제에 미치는 영향에 대한 거시적 담론과 연구 동향을 체계적으로 추적하려는 초기 노력들을 고찰한다. 이 모든 사건들이 어떻게 유기적으로 연결되어 현재 우리가 마주한 AI 시대의 초석을 다졌는지 종합적으로 분석함으로써, 2017년 10월이 AI 역사에서 차지하는 독보적인 위상을 명확히 규명하는 것을 목표로 한다.</p>
<h2>2.  강화학습의 신기원: 알파고 제로(AlphaGo Zero)</h2>
<p>2017년 10월 19일, 세계적인 과학 학술지 <em>Nature</em>에 게재된 한 편의 논문은 전 세계 AI 연구 커뮤니티에 거대한 충격을 안겨주었다. 구글 딥마인드(DeepMind)가 발표한 알파고 제로는 인간의 기보 데이터나 사전 지식 없이, 오직 바둑의 규칙만을 가지고 무(無)의 상태(<em>tabula rasa</em>)에서 학습하여 이전의 모든 AI와 인간을 압도하는 전례 없는 성과를 달성했다. 이는 강화학습의 새로운 패러다임을 제시했을 뿐만 아니라, AI가 인간 지식의 경계를 넘어설 수 있다는 가능성을 현실로 증명한 사건이었다.</p>
<h3>2.1  논문 발표와 그 의의: “인간의 지식 없이 바둑을 마스터하다”</h3>
<p>딥마인드 연구팀이 발표한 논문 “Mastering the game of Go without human knowledge“는 그 제목에서부터 AI 연구의 오랜 목표를 달성했음을 명확히 했다.6 기존의 성공적인 AI 시스템, 특히 이전 버전의 알파고는 인간 전문가의 결정을 모방하는 지도학습(supervised learning)에 크게 의존했다.7 그러나 이러한 접근법은 전문가 데이터가 비싸거나, 신뢰할 수 없거나, 혹은 아예 존재하지 않는 수많은 현실 세계의 문제에 적용하기 어렵다는 근본적인 한계를 내포하고 있었다.7</p>
<p>알파고 제로는 이 한계를 정면으로 돌파했다. 논문의 핵심 메시지는 순수한 강화학습(reinforcement learning)만으로, 어떠한 인간 데이터나 도메인 지식의 도움 없이도 인간의 능력을 뛰어넘는 초인적인 수준에 도달할 수 있음을 증명한 것이었다.8 알파고 제로는 스스로가 스스로의 스승이 되는 혁신적인 자기 주도 학습 방식을 채택했다. 초기에는 무작위로 수를 두는 신경망이 자가 대국을 통해 생성된 데이터를 바탕으로 점차 정교해지고, 이 개선된 신경망은 다시 더 수준 높은 탐색을 가능하게 하여 더 양질의 자가 대국 데이터를 생성한다. 이러한 선순환 구조를 통해 시스템은 기하급수적으로 빠르게 성장했다.4</p>
<p>이러한 ‘자체 생성 데이터’ 기반의 학습 방식은 AI가 더 이상 인간 지식의 한계에 갇히지 않음을 의미했다. 이전 버전의 알파고가 인간 기보를 통해 바둑의 ’정석’을 배웠다면, 알파고 제로는 수천 년 바둑 역사에서 인간이 발견하지 못했던 새롭고 창의적인 전략을 스스로 창조해냈다.4 이는 AI가 단순히 인간의 지식을 모방하고 최적화하는 도구를 넘어, 새로운 지식을 발견하고 창출하는 파트너가 될 수 있음을 시사하는 중요한 전환점이었다.</p>
<h3>2.2  핵심 방법론 심층 분석: <em>Tabula Rasa</em> 학습의 구현</h3>
<p>알파고 제로의 경이로운 성공은 역설적으로 이전 버전보다 훨씬 단순화된 아키텍처와 혁신적인 강화학습 알고리즘의 결합을 통해 이루어졌다. 더 적은 요소로 더 강력한 성능을 이끌어낸 핵심 기술들을 수식을 통해 상세히 분석한다.</p>
<h4>2.2.1  통합 신경망(Single Neural Network) 구조</h4>
<p>알파고 제로의 가장 큰 구조적 특징은 이전 버전에서 분리되어 있던 정책망(policy network)과 가치망(value network)을 하나의 심층 신경망 <span class="math math-inline">f_{\theta}</span>로 통합한 것이다.6 이 단일 신경망은 바둑판의 현재 상태 <span class="math math-inline">s</span>를 입력으로 받아, 다음 수에 대한 확률 분포 벡터 <span class="math math-inline">\mathbf{p}</span>와 현재 국면에서 승리할 확률을 나타내는 스칼라 값 <span class="math math-inline">v</span>를 동시에 출력한다.7</p>
<p><span class="math math-display">
(\mathbf{p}, v) = f_{\theta}(s)
</span><br />
이러한 통합 구조는 두 네트워크가 바둑판 상태에 대한 강력한 특징 표현(representation)을 공유하게 함으로써 학습 효율성과 성능을 극대화하는 시너지를 창출했다.4 또한, 입력 특징(input feature)을 대폭 단순화하여 인간이 설계한 어떠한 도메인 특화 피처도 사용하지 않고, 오직 바둑판 위 흑돌과 백돌의 위치 정보만을 원시(raw) 형태로 입력받았다.4 이는 알파고 제로의 방법론이 바둑뿐만 아니라 다른 영역에도 적용될 수 있는 일반성을 확보했음을 의미한다.</p>
<h4>2.2.2  강화된 몬테카를로 트리 탐색(MCTS)</h4>
<p>알파고 제로의 몬테카를로 트리 탐색(MCTS)은 이전 버전과 비교하여 중요한 혁신을 이루었다. 가장 큰 차이점은 탐색의 마지막 단계에서 무작위로 게임을 끝까지 시뮬레이션하여 승패를 예측하던 ‘롤아웃(rollout)’ 단계를 완전히 제거한 것이다.4 대신, 탐색 트리가 확장되어 도달한 새로운 상태(leaf node)의 가치를 전적으로 통합 신경망이 출력하는 가치 값</p>
<p><span class="math math-inline">v</span>에 의존했다. 이는 무작위성에 기반한 롤아웃보다 훨씬 정확하고 효율적인 평가를 가능하게 하여 탐색의 질을 비약적으로 향상시켰다.10</p>
<p>MCTS의 각 시뮬레이션은 현재 상태인 루트 노드(root node)에서 시작하여, 각 엣지 <span class="math math-inline">(s, a)</span>에 저장된 통계량을 기반으로 다음 노드를 선택하는 과정을 반복한다. 엣지에는 사전 확률 <span class="math math-inline">P(s, a)</span>, 방문 횟수 <span class="math math-inline">N(s, a)</span>, 그리고 액션 가치 <span class="math math-inline">Q(s, a)</span>가 저장된다. 다음 행동 <span class="math math-inline">a</span>를 선택하는 기준은 액션 가치 <span class="math math-inline">Q(s, a)</span>에 탐사 보너스 항 <span class="math math-inline">U(s, a)</span>를 더한 값이 최대가 되는 것이다.9</p>
<p><span class="math math-display">
a_t = \underset{a}{\mathrm{argmax}} \left( Q(s_t, a) + U(s_t, a) \right)
</span><br />
여기서 <span class="math math-inline">U(s, a)</span>는 <span class="math math-inline">U(s, a) \propto \frac{P(s, a)}{1 + N(s, a)}</span>의 형태를 가지며, 신경망이 제안하는 유망한 수(높은 <span class="math math-inline">P(s, a)</span>)를 탐색하면서도 아직 방문 횟수가 적은(낮은 <span class="math math-inline">N(s, a)</span>) 수를 탐험하도록 유도한다. 이 메커니즘은 탐사와 활용(exploration-exploitation) 사이의 정교한 균형을 맞추는 핵심적인 역할을 수행한다.</p>
<h4>2.2.3  손실 함수와 자가 대국(Self-Play) 학습 과정</h4>
<p>알파고 제로의 학습 과정은 MCTS를 통한 정책 개선(policy improvement)과 자가 대국을 통한 정책 평가(policy evaluation)가 상호작용하며 반복되는 정책 반복(policy iteration) 프레임워크를 기반으로 한다.10</p>
<p>학습은 무작위 가중치를 가진 신경망에서 시작된다. 이 신경망을 이용해 자가 대국 게임을 진행한다. 게임의 각 수순 <span class="math math-inline">t</span>에서, 현재 상태 <span class="math math-inline">s_t</span>를 루트로 하여 MCTS를 수천 번 실행한다. 이 탐색을 통해 얻어진 방문 횟수 분포로부터 향상된 정책, 즉 탐색 확률 <span class="math math-inline">\boldsymbol{\pi}_t</span>를 계산한다. 게임이 종료되면 최종 승자 <span class="math math-inline">z</span>가 결정되며, 이는 현재 플레이어 관점에서 승리 시 <span class="math math-inline">+1</span>, 패배 시 <span class="math math-inline">-1</span>의 값을 갖는다. 이렇게 게임의 모든 수순에서 수집된 데이터 튜플 <span class="math math-inline">(s_t, \boldsymbol{\pi}_t, z_t)</span>은 신경망을 훈련시키기 위한 학습 데이터로 사용된다.16</p>
<p>신경망의 파라미터 <span class="math math-inline">\theta</span>는 다음과 같은 손실 함수 <span class="math math-inline">l</span>을 최소화하도록 경사 하강법(gradient descent)을 통해 업데이트된다.7<br />
<span class="math math-display">
l = (v - z)^2 - \boldsymbol{\pi}^T \log(\mathbf{p}) + c\|\theta\|^2
</span><br />
이 손실 함수는 세 가지 요소로 구성된다.</p>
<ol>
<li>
<p><strong>가치 손실 (Value Loss):</strong> <span class="math math-inline">(v - z)^2</span>는 신경망이 예측한 승률 <span class="math math-inline">v</span>와 실제 게임 결과 <span class="math math-inline">z</span> 사이의 평균 제곱 오차(mean-squared error)이다. 이는 신경망이 국면의 승패를 더 정확하게 예측하도록 학습시킨다.</p>
</li>
<li>
<p><strong>정책 손실 (Policy Loss):</strong> <span class="math math-inline">-\boldsymbol{\pi}^T \log(\mathbf{p})</span>는 신경망의 정책 출력 <span class="math math-inline">\mathbf{p}</span>와 MCTS가 탐색을 통해 얻은 향상된 정책 <span class="math math-inline">\boldsymbol{\pi}</span> 사이의 교차 엔트로피(cross-entropy) 손실이다. 이는 신경망의 직관적인 판단이 MCTS의 깊이 있는 탐색 결과와 유사해지도록 유도한다.</p>
</li>
<li>
<p><strong>규제 항 (Regularization Term):</strong> <span class="math math-inline">c\|\theta\|^2</span>는 L2 가중치 규제항으로, 모델의 과적합(overfitting)을 방지하고 일반화 성능을 높이는 역할을 한다.</p>
</li>
</ol>
<p>이러한 학습 과정이 반복되면서, 신경망은 점점 더 정확한 가치와 정책을 출력하게 되고, 이는 다시 MCTS 탐색의 질을 높인다. 이처럼 신경망과 MCTS가 서로를 점진적으로 강화하는 부트스트래핑(bootstrapping) 과정을 통해 알파고 제로는 단기간에 초인적인 기력에 도달할 수 있었다.</p>
<h3>2.3  성능 비교 분석: 진화의 정점</h3>
<p>알파고 제로는 이전 버전들과 비교하여 압도적인 성능 향상을 기록했다. 훈련을 시작한 지 불과 3일 만에, 2016년 이세돌 9단을 4대 1로 꺾었던 ‘알파고 리(AlphaGo Lee)’ 버전을 상대로 100전 100승이라는 완벽한 승리를 거두었다.4 21일간의 학습 후에는 당시 최강 버전으로 알려졌으며, 커제 9단을 포함한 세계 최상위 프로 기사들을 상대로 60전 전승을 기록했던 ’알파고 마스터(AlphaGo Master)’의 수준에 도달했고, 40일이 경과했을 때는 알파고 마스터마저 능가하는 성능을 보였다.4</p>
<p>이러한 성능 향상은 단순히 알고리즘의 우수성뿐만 아니라, 대폭 향상된 계산 효율성 덕분에 가능했다. 알파고 리가 48개의 TPU(Tensor Processing Unit)를 분산 환경에서 사용했던 반면, 알파고 제로는 단 4개의 TPU를 탑재한 단일 머신에서 추론을 수행했다.13 이는 아키텍처의 단순화와 알고리즘의 효율화가 얼마나 큰 차이를 만들어내는지를 명확히 보여주는 결과이다. 아래 표는 알파고 버전별 핵심 특징과 성능을 비교하여 그 진화 과정을 요약한 것이다.</p>
<table><thead><tr><th>항목</th><th>AlphaGo Lee</th><th>AlphaGo Master</th><th>AlphaGo Zero (40일)</th></tr></thead><tbody>
<tr><td><strong>Elo 레이팅</strong></td><td>3,739</td><td>4,858</td><td>5,185 (추정)</td></tr>
<tr><td><strong>학습 방식</strong></td><td>지도학습 + 강화학습</td><td>지도학습 + 강화학습</td><td>순수 강화학습 (자가 대국)</td></tr>
<tr><td><strong>신경망 구조</strong></td><td>정책망/가치망 분리</td><td>정책망/가치망 분리</td><td>정책/가치망 통합</td></tr>
<tr><td><strong>입력 특징</strong></td><td>인간 설계 특징 포함</td><td>인간 설계 특징 포함</td><td>원시 바둑판 정보만 사용</td></tr>
<tr><td><strong>하드웨어 (추론)</strong></td><td>48 TPUs (분산)</td><td>4 TPUs (단일 머신)</td><td>4 TPUs (단일 머신)</td></tr>
<tr><td><strong>주요 성과</strong></td><td>이세돌 9단 4:1 승리</td><td>온라인 고수 60:0 승리</td><td>AlphaGo Lee 100:0 승리</td></tr>
</tbody></table>
<p>자료: 4 기반 재구성</p>
<h3>2.4  AI 연구에 미친 영향과 미래 전망</h3>
<p>알파고 제로의 등장은 특정 게임을 정복했다는 사실을 넘어, AI가 복잡한 문제에 접근하는 방식 자체에 대한 근본적인 패러다임 전환을 예고했다. 가장 중요한 영향은 AI 연구의 오랜 난제였던 ’지식의 병목 현상(Knowledge Bottleneck)’을 해결할 실마리를 제공했다는 점이다. 이전까지 AI 시스템의 성능은 학습에 사용되는 인간 전문가 데이터의 양과 질에 의해 크게 좌우되었다. 이는 양질의 데이터 확보가 어려운 분야에서는 AI의 발전이 더딜 수밖에 없다는 한계를 의미했다.</p>
<p>그러나 알파고 제로는 AI가 규칙이 명확한 환경 내에서 자가 대국을 통해 인간 전문가보다 훨씬 우수한 품질의 데이터를 거의 무한하게 생성할 수 있음을 보여주었다. 이는 AI 개발의 핵심 제약 조건이 ’데이터 수집(data collection)’에서 ’계산 능력(computing power)’으로 전환되었음을 의미한다. 즉, 충분한 컴퓨팅 자원만 있다면, 인간의 지식이 부족하거나 존재하지 않는 미지의 영역에서도 AI가 스스로 해법을 탐색하고 최적의 전략을 발견할 수 있는 길이 열린 것이다.10</p>
<p>이러한 가능성은 딥마인드가 2017년 12월에 발표한 후속 연구 ’알파제로(AlphaZero)’를 통해 더욱 명확해졌다.13 알파제로는 알파고 제로의 알고리즘을 일반화하여, 바둑뿐만 아니라 체스, 쇼기(일본 장기)에도 동일하게 적용했다. 그 결과, 각 게임의 규칙 외에는 어떠한 사전 지식도 없이 단 몇 시간의 학습만으로 기존의 세계 최고수준 체스 프로그램(스톡피시)과 쇼기 프로그램(엘모)을 압도하는 성능을 달성했다.21</p>
<p>알파고 제로와 알파제로의 성공은 AI의 응용 범위를 게임의 영역 너머로 확장시키는 기폭제가 되었다. 명확한 규칙과 시뮬레이션 환경을 구축할 수 있는 다양한 과학 및 공학 분야, 예를 들어 신약 개발을 위한 단백질 구조 예측(알파폴드), 신소재 개발, 에너지 소비 최적화 등 인류의 난제 해결에 이 방법론이 적용될 수 있다는 기대감을 불러일으켰다.4 2017년 10월, 알파고 제로의 등장은 AI를 통한 과학적 발견의 새로운 시대, 즉 ’AI for Science’의 서막을 알리는 신호탄이었다.</p>
<h2>3.  주요 학술대회 동향 및 핵심 연구 발표</h2>
<p>2017년 10월은 AI 분야의 양대 산맥이라 할 수 있는 컴퓨터 비전과 로보틱스 분야에서도 중요한 학술적 성과가 집중적으로 발표된 시기였다. 이탈리아 베네치아에서 개최된 세계 최고 권위의 컴퓨터 비전 학회 ICCV 2017과 캐나다 밴쿠버에서 열린 대표적인 로보틱스 학회 IROS 2017은 당시 기술의 최전선을 보여주는 핵심 연구들의 경연장이었다. 이들 학회에서 발표된 연구들은 AI의 ’인식(Perception)’과 ‘행동(Action)’ 능력을 한 단계 끌어올리는 중요한 발판이 되었다.</p>
<h3>3.1  ICCV 2017: 컴퓨터 비전 기술의 정점</h3>
<p>ICCV(International Conference on Computer Vision) 2017에서는 특히 객체 인식(object recognition) 분야의 오랜 난제들을 해결하는 기념비적인 연구들이 주목받았다. 그중에서도 Facebook AI Research(FAIR)가 발표한 두 편의 논문은 각각 최우수 논문상과 최우수 학생 논문상을 석권하며, 이후 컴퓨터 비전 연구의 방향성에 지대한 영향을 미쳤다.</p>
<h4>3.1.1  최우수 논문(Marr Prize): Mask R-CNN과 인스턴스 분할(Instance Segmentation)의 완성</h4>
<p>Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick이 발표한 논문 “Mask R-CNN“은 ICCV 2017의 최고 영예인 Marr Prize를 수상했다.24 이 연구는 이미지 내의 각 객체 인스턴스를 개별적으로 식별하고 그 영역을 픽셀 단위로 정확하게 분할하는 ’인스턴스 분할’이라는 고난도 작업을 위한 매우 간결하면서도 강력하고, 유연한 프레임워크를 제시했다는 점에서 높은 평가를 받았다.27</p>
<ul>
<li>
<p><strong>핵심 방법론:</strong> Mask R-CNN의 가장 큰 특징은 당시 가장 성공적인 2단계(two-stage) 객체 탐지기였던 Faster R-CNN의 구조를 최소한으로 확장하여 인스턴스 분할 기능을 구현했다는 점이다. 기존 Faster R-CNN이 각 후보 영역(Region of Interest, RoI)에 대해 클래스 분류와 바운딩 박스(bounding box) 회귀를 수행하는 두 개의 브랜치(branch)를 가졌던 것에 더해, 객체의 마스크를 예측하는 세 번째 브랜치를 병렬로 추가하는 직관적인 구조를 채택했다. 이 마스크 브랜치는 각 RoI에 적용되는 작은 FCN(Fully Convolutional Network)으로, 픽셀 단위의 분할 마스크를 생성한다.27</p>
</li>
<li>
<p><strong>기술적 기여 (RoIAlign):</strong> 논문은 Faster R-CNN에서 사용되던 RoIPool 연산이 특징 추출 과정에서 소수점 좌표를 버리는 거친 공간 양자화(coarse spatial quantization)를 수행하기 때문에, 입력과 출력 간의 픽셀 수준 정렬(pixel-to-pixel alignment)이 깨지는 문제를 지적했다. 이는 바운딩 박스 예측에는 큰 문제가 되지 않았지만, 픽셀 단위의 정확성이 요구되는 마스크 예측에는 치명적이었다. 이 문제를 해결하기 위해, 양자화 과정을 제거하고 쌍선형 보간법(bilinear interpolation)을 사용하여 특징 맵의 정확한 위치 값을 계산하는 ’RoIAlign’이라는 새로운 레이어를 제안했다. 이 간단하면서도 핵심적인 개선은 마스크 예측의 정확도를 비약적으로 향상시키는 결정적인 기여를 했다.28</p>
</li>
<li>
<p><strong>다중 작업 손실 함수 (Multi-task Loss):</strong> Mask R-CNN은 학습 과정에서 각 RoI에 대해 다중 작업 손실(multi-task loss) 함수 <span class="math math-inline">L</span>을 사용한다. 이 손실 함수는 클래스 분류 손실 <span class="math math-inline">L_{cls}</span>, 바운딩 박스 회귀 손실 <span class="math math-inline">L_{box}</span>, 그리고 마스크 분할 손실 <span class="math math-inline">L_{mask}</span>의 합으로 정의된다.</p>
<p><span class="math math-display">
L = L_{cls} + L_{box} + L_{mask}
</span><br />
여기서 마스크 손실 <span class="math math-inline">L_{mask}</span>는 평균 이진 교차 엔트로피(average binary cross-entropy) 손실로 계산된다. 중요한 점은 마스크 브랜치가 <span class="math math-inline">K</span>개의 클래스에 대해 <span class="math math-inline">K</span>개의 독립적인 이진 마스크를 예측한다는 것이다. 이는 클래스 간 경쟁을 유발하는 소프트맥스(softmax) 함수를 사용하지 않음으로써, 객체 분류 작업과 마스크 생성 작업을 분리(decouple)하여 더 높은 성능을 달성할 수 있게 했다.</p>
</li>
</ul>
<h4>3.1.2  최우수 학생 논문: Focal Loss와 밀집 객체 탐지(Dense Object Detection)의 난제 해결</h4>
<p>Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, Piotr Dollár가 발표한 “Focal Loss for Dense Object Detection“은 최우수 학생 논문상을 수상했다.24 이 논문은 YOLO나 SSD와 같은 1단계(one-stage) 탐지기들이 2단계 탐지기에 비해 속도는 빠르지만 정확도가 떨어졌던 근본적인 원인을 ‘극심한 전경-배경 클래스 불균형(extreme foreground-background class imbalance)’ 문제로 규명하고, 이를 해결하기 위한 혁신적인 손실 함수를 제안했다.31</p>
<ul>
<li>
<p><strong>핵심 방법론 (Focal Loss):</strong> 1단계 탐지기는 이미지 전체에 걸쳐 수많은 후보 위치(anchor box)를 조밀하게(dense) 예측하는데, 이 과정에서 대부분의 후보 위치는 객체가 없는 ’쉬운 배경(easy negatives)’에 해당한다. 표준 교차 엔트로피 손실 함수는 이러한 수많은 쉬운 배경 샘플들이 생성하는 작은 손실 값들이 합쳐져, 소수의 중요한 전경 객체(foreground object) 샘플의 학습 기여도를 압도하는 문제를 야기한다. Focal Loss는 이 문제를 해결하기 위해 표준 교차 엔트로피 손실에 동적인 스케일링 인자를 추가했다. 이 인자는 정확하게 분류된 샘플에 대해서는 가중치를 낮추고, 분류하기 어려운 샘플에 대해서는 가중치를 높여 모델이 학습 과정에서 어려운 예제에 집중하도록 유도한다.32</p>
</li>
<li>
<p><strong>Focal Loss 수식:</strong> Focal Loss는 다음과 같이 정의된다.</p>
<p><span class="math math-display">
\text{FL}(p_t) = -(1-p_t)^\gamma \log(p_t)
</span><br />
여기서 <span class="math math-inline">p_t</span>는 정답 클래스에 대한 모델의 예측 확률이며, <span class="math math-inline">\gamma \ge 0</span>는 조절 파라미터(focusing parameter)이다. 잘 분류된 예제일수록 <span class="math math-inline">p_t</span>는 1에 가까워지고, 이 경우 조절 인자 <span class="math math-inline">(1-p_t)^\gamma</span>는 0에 가까워져 해당 샘플의 손실 기여도를 크게 줄인다. 반면, 잘못 분류된 어려운 예제일수록 <span class="math math-inline">p_t</span>는 0에 가까워지고, 조절 인자는 1에 가까워져 손실이 거의 그대로 유지된다. 논문에서는 <span class="math math-inline">\alpha</span>-balanced variant도 함께 제안하여 클래스별 가중치를 추가로 조절했다.</p>
</li>
<li>
<p><strong>RetinaNet 아키텍처:</strong> 연구팀은 Focal Loss의 효과를 입증하기 위해 ’RetinaNet’이라는 새로운 1단계 탐지기 아키텍처를 설계했다. RetinaNet은 ResNet과 FPN(Feature Pyramid Network)을 백본(backbone)으로 사용하여 다양한 크기의 객체를 효과적으로 탐지할 수 있도록 하고, 분류 및 박스 회귀를 위한 두 개의 서브 네트워크를 사용한다. 이 RetinaNet을 Focal Loss로 훈련시켰을 때, 당시 모든 1단계 및 2단계 탐지기들을 능가하는 최고 수준의 정확도를 달성하며 Focal Loss의 우수성을 입증했다.31</p>
</li>
</ul>
<p>아래 표는 ICCV 2017의 주요 수상 논문과 그 핵심 기여를 요약한 것이다. 이 표를 통해 당시 컴퓨터 비전 분야의 연구를 주도했던 FAIR의 압도적인 영향력과, 객체 인식의 두 가지 핵심 난제(인스턴스 분할, 클래스 불균형)에 대한 해결책이 제시되었음을 한눈에 파악할 수 있다.</p>
<table><thead><tr><th>수상 부문</th><th>논문 제목</th><th>저자 (소속)</th><th>핵심 기여</th></tr></thead><tbody>
<tr><td><strong>최우수 논문 (Marr Prize)</strong></td><td>Mask R-CNN</td><td>Kaiming He, G. Gkioxari, P. Dollár, R. Girshick (Facebook AI Research)</td><td>Faster R-CNN을 확장하여 인스턴스 분할을 위한 간결하고 강력한 프레임워크 제시. RoIAlign을 통해 픽셀 정렬 문제 해결.</td></tr>
<tr><td><strong>최우수 학생 논문</strong></td><td>Focal Loss for Dense Object Detection</td><td>T.-Y. Lin, P. Goyal, R. Girshick, K. He, P. Dollár (Facebook AI Research)</td><td>1단계 객체 탐지기의 클래스 불균형 문제를 해결하는 Focal Loss 제안. RetinaNet을 통해 SOTA 성능 달성.</td></tr>
</tbody></table>
<p>자료: 24 기반 재구성</p>
<h3>3.2  IROS 2017: 지능형 로봇과 시스템의 현재</h3>
<p>IROS(IEEE/RSJ International Conference on Intelligent Robots and Systems) 2017에서는 로봇이 복잡하고 동적인 실제 환경과 상호작용하기 위한 지능의 핵심 요소들, 즉 인식, 제어, 협업, 학습에 대한 심도 있는 연구들이 발표되었다.</p>
<h4>3.2.1  기조 연설 분석: 모델 기반과 학습 기반의 통합</h4>
<p>IROS 2017의 기조 연설은 당시 로보틱스 분야의 가장 중요한 화두를 제시했다. 주요 연사로는 워싱턴 대학교의 Dieter Fox 교수, 스탠포드 대학교/구글의 Fei-Fei Li 교수, 서던캘리포니아 대학교의 Maja Matarić 교수 등이 참여하여 로봇 지능의 미래에 대한 통찰을 공유했다.35</p>
<p>특히 Dieter Fox 교수의 “모델 기반과 학습 기반 로봇 공학의 통합(Unifying Model-based and Learning-based Robotics)“이라는 주제의 연설은 큰 주목을 받았다.35 그는 로봇 공학의 전통적인 접근법인 물리 모델 기반(model-based) 방식과, 당시 급부상하던 딥러닝 기반(learning-based) 방식의 장단점을 명확히 분석했다. 물리 모델 기반 방식은 일반화 능력이 뛰어나고 다양한 상황에 적용 가능하지만, 모델이 부정확하거나 관찰되지 않은 변수가 있을 때 취약하다는 단점이 있다. 반면, 딥러닝 기반 방식은 특정 작업에서 인간을 뛰어넘는 성능을 보이지만, 학습된 데이터 분포를 벗어나는 새로운 상황에 대한 일반화 능력이 부족하다. Fox 교수는 이 두 패러다임을 대립적인 것으로 볼 것이 아니라, 이 둘의 장점을 결합하여 상호 보완하는 통합적인 접근법이 진정으로 강건하고 자율적인 로봇 시스템을 개발하는 데 필수적이라고 역설했다. 이는 이후 로보틱스 연구에서 중요한 방향성으로 자리 잡게 되었다.</p>
<h4>3.2.2  주요 수상 논문 분석: 딥러닝 기반 로봇 인식</h4>
<p>IROS 2017 RoboCup 최우수 논문상은 독일 본 대학교의 Hafez Farazi와 Sven Behnke가 발표한 “딥 LSTM 네트워크를 이용한 온라인 시각적 로봇 추적 및 식별(Online Visual Robot Tracking and Identification using Deep LSTM Networks)“에 수여되었다.37</p>
<ul>
<li><strong>핵심 방법론:</strong> 이 연구는 외형이 완전히 동일한 여러 대의 로봇을 단일 카메라 비전 정보만을 이용해 실시간으로 추적하고, 각각의 고유 ID를 식별하는 어려운 문제에 대한 새로운 해결책을 제시했다. 기존의 필터 기반 접근법과 달리, 이 연구는 순차적 데이터(sequential data) 처리에 강점을 가진 순환 신경망(RNN)의 일종인 LSTM(Long Short-Term Memory) 네트워크를 활용했다. 로봇의 시각적 탐지 정보와 각 로봇이 Wi-Fi를 통해 보고하는 자신의 방향(heading) 정보를 시계열 데이터로 입력받아, LSTM 네트워크가 복잡한 데이터 연관(data association) 문제를 학습을 통해 해결하도록 했다.39 특히, 방대한 양의 시뮬레이션 데이터를 생성하여 네트워크를 사전 훈련시킨 후, 소량의 실제 데이터로 미세 조정(fine-tuning)하는 전략을 사용하여, 장기간의 가려짐(occlusion)과 같이 실제 환경에서 발생하는 까다로운 문제에 대해서도 강건한 성능을 보였다. 이는 데이터 기반의 딥러닝 접근법이 로봇의 동적 상태 추정 문제에 효과적으로 적용될 수 있음을 보여준 중요한 사례였다.</li>
</ul>
<p>ICCV 2017과 IROS 2017에서 발표된 주요 연구들은 서로 다른 분야의 성과처럼 보이지만, 실제로는 AI-로보틱스 파이프라인의 완성을 향한 상호 보완적인 관계를 형성한다. ICCV에서 발표된 Mask R-CNN과 Focal Loss는 로봇에게 ‘무엇이(what), 어디에(where)’ 있는지를 정교하게 인식할 수 있는 시각적 지능을 부여했다. 이는 로봇이 주변 환경을 정적인 단일 프레임에서 깊이 있게 이해하는 능력에 해당한다. 반면, IROS의 LSTM 기반 추적 연구는 이러한 정적인 인식 결과를 ‘시간의 흐름 속에서(over time)’ 일관되게 추적하고 해석하여, 각 객체의 동적인 상태와 정체성을 파악하는 능력을 제공했다. 즉, ICCV의 연구가 로봇의 ’눈’을 혁신했다면, IROS의 연구는 그 눈으로 본 정보를 해석하여 ’뇌’에서 일관된 이해를 형성하는 과정을 다룬 셈이다. 이 두 분야의 발전이 결합될 때, 비로소 로봇은 복잡하고 동적인 실제 세계에서 의미 있는 ’행동(action)’을 수행할 수 있는 기반을 갖추게 된다. 2017년 10월은 바로 이 ’인식’과 ’행동’을 잇는 기술적 연결고리가 한층 더 견고해진 시점이었다.</p>
<h2>4.  산업계 동향 및 기술 상용화</h2>
<p>2017년 10월은 학계의 혁신적인 연구 성과가 산업계의 구체적인 투자와 미래 전략으로 빠르게 연결되는 모습을 명확히 보여준 시기이기도 했다. 특히 항공우주 산업의 거인인 보잉(Boeing)이 자율 비행 기술 스타트업에 단행한 투자는 AI와 로보틱스 기술이 미래 핵심 시장의 판도를 어떻게 바꿀 것인지를 보여주는 상징적인 사건이었다. 동시에, 기술 발전을 선도하는 빅테크 기업들 내부에서는 기술의 사회적 책임에 대한 논의가 본격화되며 새로운 움직임이 나타났다.</p>
<h3>4.1  보잉의 투자와 자율 비행 기술의 미래</h3>
<p>2017년 10월 19일, 보잉의 벤처 캐피털 자회사인 ’보잉 호라이즌X(Boeing HorizonX)’는 자율 비행 기술 분야의 선도 기업인 ’니어 어스 오토노미(Near Earth Autonomy)’에 대한 투자를 공식 발표했다.40 이는 2017년 4월에 설립된 호라이즌X가 자율 기술 분야에 집행한 첫 번째 투자로, 보잉이 미래 항공우주 시장의 핵심 동력으로 자율 비행 기술을 주목하고 있음을 명확히 드러낸 전략적 행보였다.41</p>
<h4>4.1.1  니어 어스 오토노미의 핵심 기술력</h4>
<p>니어 어스 오토노미는 로봇 공학 분야의 세계적인 명문인 카네기 멜런 대학교(CMU) 로봇공학 연구소에서 분사(spin-off)한 기업으로, 수십 년간 축적된 자율 비행 분야의 깊이 있는 전문성을 보유하고 있었다.40 이 회사의 핵심 기술은 소형 드론부터 실물 크기의 대형 헬리콥터에 이르기까지 다양한 항공 플랫폼에 적용 가능한 소프트웨어 및 센서 기술 포트폴리오였다. 이 기술은 항공기가 스스로 주변 지형과 인프라를 정밀하게 검사, 매핑, 측량하고, 지정된 화물을 목적지까지 자율적으로 운송하는 것을 가능하게 했다.41 특히 GPS 신호가 닿지 않는 터널이나 숲속과 같은 까다로운 환경에서도 안전하게 자율 항법을 수행할 수 있는 기술을 개발하고 있었다는 점이 주목할 만하다.44</p>
<p>니어 어스 오토노미는 이미 2010년에 미 육군과의 파트너십을 통해 세계 최초로 실물 크기 헬리콥터의 완전 자율 비행에 성공하는 등 괄목할 만한 성과를 거둔 바 있으며, 미 해군 연구국(Office of Naval Research)과 함께 미 해병대를 위한 자율 공중 화물 운송 플랫폼을 개발하는 프로젝트를 지속적으로 수행하며 기술력을 입증해왔다.40</p>
<h4>4.1.2  도시 항공 모빌리티(UAM) 시장의 부상</h4>
<p>보잉의 이번 투자는 단순한 자금 지원을 넘어, 양사 간의 전략적 파트너십 구축을 목표로 했다. 파트너십의 핵심 목표는 ’플라잉 카(flying car)’로 대표되는 도시 항공 모빌리티(Urban Air Mobility, UAM)라는 거대한 신흥 시장을 위한 미래 제품과 애플리케이션을 공동으로 탐색하고 개발하는 것이었다.40</p>
<p>이 사건은 AI와 로보틱스 기술이 기존 산업의 효율성을 높이는 보조적인 역할을 넘어, UAM과 같은 완전히 새로운 교통 및 물류 패러다임을 창출하는 핵심 기술로 부상했음을 의미한다. 전통적인 항공기 제조사인 보잉이 외부의 혁신적인 스타트업에 손을 내밀어 미래 시장을 선점하려는 움직임은, AI 기술의 파괴적 잠재력을 산업계의 거인들이 얼마나 심각하게 받아들이고 있는지를 보여주는 단적인 예였다.</p>
<h3>4.2  빅테크 기업의 AI 연구 동향과 사회적 책임</h3>
<p>기술 발전의 속도가 빨라질수록, 그 기술이 사회에 미칠 영향에 대한 우려와 책임 의식 또한 높아졌다. 2017년 10월은 AI 기술의 ’기회’와 ’책임’이라는 양면성이 극명하게 드러난 시기였다. 한편에서는 보잉과 같은 거대 기업이 UAM이라는 유토피아적 미래를 그리며 AI 기술에 막대한 투자를 집행했고, 다른 한편에서는 바로 그 기술을 만드는 선두 주자들과 이를 비판적으로 감시하는 그룹이 AI의 잠재적 위험을 경고하며 윤리적 고삐를 죄려는 움직임을 보였다.</p>
<h4>4.2.1  딥마인드 AI 윤리 및 사회팀 신설</h4>
<p>알파고 제로라는 경이로운 기술을 선보인 딥마인드는 바로 그달, AI가 제기하는 복잡한 윤리적, 사회적 질문들을 탐구하기 위한 새로운 연구팀인 ’딥마인드 윤리 및 사회(DeepMind Ethics and Society)’의 출범을 공식화했다.3 이는 기술 개발의 최전선에 있는 주체가 스스로 기술의 잠재적 위험성을 인지하고, 그에 대한 사회적 합의와 윤리적 가이드라인을 모색하기 시작했다는 점에서 매우 중요한 진전이었다. 기술의 가속 페달을 밟는 동시에 브레이크의 필요성을 인정한 것이다.</p>
<h4>4.2.2  AI Now Institute 2017년 보고서</h4>
<p>2017년 10월 18일, AI의 사회적 영향에 대한 연구를 전문으로 하는 AI Now Institute는 2017년 연례 보고서를 발표하며 AI 기술에 대한 사회적 논의를 한 단계 끌어올렸다.5 이 보고서는 AI 기술이 사회에 미치는 영향을 다음과 같은 네 가지 핵심 영역으로 나누어 심도 있게 분석하고, 잠재적 위험을 완화하기 위한 구체적인 권고안을 제시했다.</p>
<ul>
<li>
<p><strong>노동과 자동화 (Labor and Automation):</strong> AI가 일자리에 미치는 영향과 노동 시장의 변화</p>
</li>
<li>
<p><strong>편향과 포용 (Bias and Inclusion):</strong> 알고리즘에 내재된 편향이 사회적 불평등을 심화시킬 위험</p>
</li>
<li>
<p><strong>권리와 자유 (Rights and Liberties):</strong> AI를 이용한 감시와 통제가 개인의 권리와 자유에 미치는 위협</p>
</li>
<li>
<p><strong>윤리와 거버넌스 (Ethics and Governance):</strong> AI 기술을 책임감 있게 개발하고 배포하기 위한 윤리적 원칙과 거버넌스 체계의 필요성</p>
</li>
</ul>
<p>이 보고서는 AI 기술에 대한 막연한 기대나 공포를 넘어, 구체적인 문제 영역을 설정하고 학술적, 체계적으로 분석하려는 시도였다는 점에서 큰 의의를 가진다. 2017년 10월은 이처럼 AI 기술의 무한한 상업적 가능성과 그에 따르는 막중한 사회적 책임에 대한 논의가 동시에, 그리고 같은 무게감으로 대두되기 시작한, AI 시대의 본격적인 서막을 알리는 시점이었다.</p>
<h2>5.  거시적 관점에서의 AI: 경제와 윤리</h2>
<p>2017년 10월은 개별 기술의 발전을 넘어, AI가 경제와 사회 전반에 미치는 영향을 거시적인 관점에서 분석하고, AI 분야의 연구 동향 자체를 체계적으로 추적하려는 중요한 시도들이 나타난 시기이기도 했다. 이는 AI를 둘러싼 강력한 ’서사(Narrative)’와 실제 데이터로 측정되는 ‘실체(Reality)’ 사이의 간극을 처음으로 진지하게 탐색하기 시작했음을 의미한다.</p>
<h3>5.1  생산성 역설과 AI의 경제적 효과</h3>
<p>알파고 제로와 같은 눈부신 기술적 성과는 AI가 곧 인간의 모든 지적 노동을 대체하고 생산성을 폭발적으로 증가시킬 것이라는 강력한 서사를 만들어냈다. 그러나 현실의 경제 지표는 다른 이야기를 하고 있었다. 2017년 10월, 전미경제연구소(NBER)는 “Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics“라는 제목의 워킹 페이퍼를 통해 이 문제를 정면으로 다루었다.2</p>
<p>이 보고서는 ’현대의 생산성 역설’이라는 현상을 제기했다. 즉, AI 기술은 이미지 인식, 음성 인식, 게임 등 다양한 영역에서 인간의 수준을 넘어서는 등 비약적으로 발전하고 있지만, 거시 경제 지표상으로 측정된 생산성 증가율은 지난 10년간 오히려 절반으로 감소했으며, 다수 미국인의 실질 소득은 1990년대 후반부터 정체되어 있다는 것이다.2</p>
<p>보고서는 이러한 기대와 통계 사이의 충돌, 즉 역설에 대해 네 가지 잠재적인 설명을 제시했다.</p>
<ol>
<li>
<p><strong>잘못된 희망 (False Hopes):</strong> AI 기술에 대한 기대가 과장되었을 가능성.</p>
</li>
<li>
<p><strong>측정의 오류 (Mismeasurement):</strong> AI가 창출하는 가치(예: 무료 디지털 서비스)가 기존의 생산성 지표에 제대로 포착되지 않을 가능성.</p>
</li>
<li>
<p><strong>부의 재분배 (Redistribution):</strong> AI로 인한 이익이 소수의 기업이나 개인에게 집중되어 총생산성 증가로는 나타나지 않을 가능성.</p>
</li>
<li>
<p><strong>도입 지연 (Implementation Lags):</strong> 범용 기술(General Purpose Technology)인 AI가 사회 전반에 확산되고 실질적인 생산성 향상으로 이어지기까지는 상당한 시간이 걸릴 것이라는 가능성.</p>
</li>
</ol>
<p>이 분석은 AI의 경제적 효과가 사회 전체에 긍정적으로 나타나기까지는 기술 개발 외에도 많은 시간과 노력이 필요함을 시사했다. 이는 AI에 대한 막연한 낙관론에 데이터 기반의 냉정한 현실 인식을 제공하며, AI의 실질적인 영향을 측정하고 이해하는 것이 얼마나 중요한 과제인지를 일깨워주었다.</p>
<h3>5.2  AI 연구의 이정표: AI 인덱스(AI Index)의 출범</h3>
<p>AI 기술에 대한 서사와 실체 사이의 간극을 메우기 위한 또 다른 중요한 움직임은 바로 AI 연구 동향을 객관적인 데이터로 측정하려는 시도였다. 2017년, 스탠포드 대학교 인간 중심 AI 연구소(Stanford HAI)의 주도로 ‘AI 인덱스(AI Index)’ 프로젝트가 시작되었고, 그 첫 번째 연례 보고서가 발표되었다.45</p>
<p>AI 인덱스의 목표는 AI 분야에서 일어나는 활동과 진척 상황을 추적, 수집, 분석하고 이를 시각화하여 제공함으로써, 정책 입안자, 연구자, 기업 임원, 언론인 등 다양한 이해관계자들이 데이터에 기반하여 AI 분야에 대한 정보에 입각한 대화를 나눌 수 있도록 돕는 것이었다.45 이는 AI 연구 동향을 단편적인 성공 사례나 일화가 아닌, 체계적이고 포괄적인 데이터로 측정하고 논의하려는 최초의 대규모 시도였다는 점에서 큰 의의를 가진다.</p>
<p>NBER의 생산성 역설 분석과 AI 인덱스의 출범은 2017년 10월이 AI 분야가 성숙의 단계로 접어들고 있음을 보여주는 중요한 증거이다. 초기 기술 개발의 열광적인 단계를 지나, 이제는 그 기술의 실제 효과를 냉정하게 측정하고, 사회에 미치는 영향을 비판적으로 분석하며, 미래를 위한 책임 있는 방향을 설정하려는 노력이 본격적으로 시작된 것이다.</p>
<h2>6. 결론: 새로운 시대의 서막</h2>
<p>2017년 10월 한 달 동안 AI 및 로봇 분야에서 일어난 일련의 사건들은 개별적인 성과를 넘어, AI 발전의 새로운 시대를 여는 거대한 서막이었음을 종합적으로 보여준다. 이 시기는 기술의 폭발적인 잠재력과 그에 따르는 사회적 책임이 역사상 처음으로 동시에, 그리고 같은 무게감으로 대두된, AI 역사의 진정한 ’성년식’과 같은 순간이었다.</p>
<p>첫째, 딥마인드의 알파고 제로는 ’탈(脫)인간 데이터’라는 혁명적인 학습 패러다임을 제시하며 AI의 지식 창출 능력을 새로운 차원으로 끌어올렸다. 이는 AI가 더 이상 인간이 축적한 데이터의 한계에 갇히지 않고, 스스로 데이터를 생성하고 학습하여 미지의 영역을 탐험할 수 있는 가능성을 열었다. 이로써 AI 개발의 제약 조건은 데이터에서 컴퓨팅 파워로 전환되었고, 이는 과학적 발견을 가속하는 새로운 도구로서 AI의 역할을 예고했다.</p>
<p>둘째, ICCV와 IROS와 같은 최고 학술대회에서 발표된 연구들은 AI의 인식과 행동 능력이 실제 세계의 복잡한 문제들을 해결할 수 있는 수준으로 성숙했음을 증명했다. Mask R-CNN과 Focal Loss는 컴퓨터 비전 기술이 이미지 속 객체를 인간보다 더 정교하고 정확하게 이해할 수 있게 했으며, LSTM 기반 로봇 추적 기술은 이러한 인식 능력을 동적인 실제 환경에서의 행동으로 연결하는 중요한 다리를 놓았다. 이는 ‘인식에서 행동으로’ 이어지는 AI-로보틱스 파이프라인이 견고하게 구축되기 시작했음을 의미한다.</p>
<p>셋째, 산업계의 움직임은 이러한 기술적 진보가 더 이상 실험실에 머무르지 않고, 미래 산업 지형을 근본적으로 바꿀 핵심 동력임을 입증했다. 보잉의 자율 비행 기술 투자는 도시 항공 모빌리티(UAM)라는 새로운 시장의 개화를 알렸으며, 이는 AI 기술이 가져올 거대한 경제적 기회를 상징적으로 보여주었다.</p>
<p>마지막으로, 이 모든 눈부신 발전과 동시에 기술의 그림자에 대한 깊은 성찰이 시작되었다. AI Now Institute의 보고서와 딥마인드 윤리팀의 출범, 그리고 NBER의 생산성 역설에 대한 논의는 이 강력한 기술을 인류에게 이롭게 사용하기 위한 사회적, 경제적, 윤리적 거버넌스 구축이 더 이상 미룰 수 없는 시급한 과제가 되었음을 명확히 했다.</p>
<p>결론적으로 2017년 10월은 AI 기술의 순수한 잠재력이 만개함과 동시에, 그 기술을 책임감 있게 이끌어야 할 인류의 과제가 본격적으로 시작된 역사적 분기점이었다. 기술적 경이와 사회적 성찰이라는 두 개의 축이 함께 작동하기 시작한 이 순간이야말로, 진정한 의미의 AI 시대가 개막되었음을 알리는 신호탄이었다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>12 Amazing Deep Learning Breakthroughs of 2017 - TOPBOTS, https://www.topbots.com/12-amazing-artificial-intelligence-deep-learning-breakthroughs-2017/</li>
<li>Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics - National Bureau of Economic Research, https://www.nber.org/system/files/working_papers/w24001/w24001.pdf</li>
<li>Google DeepMind - Wikipedia, https://en.wikipedia.org/wiki/Google_DeepMind</li>
<li>AlphaGo Zero: Starting from scratch - Google DeepMind, https://deepmind.google/discover/blog/alphago-zero-starting-from-scratch/</li>
<li>AI Now 2017 Report, https://ainowinstitute.org/publications/ai-now-2017-report-2</li>
<li>Mastering the game of Go without human knowledge (Silver et al., Nature 2017), https://jkk.name/reading-notes/old-blog/2017-10-23_alphagozero/</li>
<li>crackbitswilp.in - AWS, <a href="https://cbwilp-artefacts.s3.ap-south-1.amazonaws.com/AIML/SEM2/SUB-DRL/RESEARCH-PAPERS/Mastering%20the%20game%20of%20Go%20without%20human%20knowledge.pdf">https://cbwilp-artefacts.s3.ap-south-1.amazonaws.com/AIML/SEM2/SUB-DRL/RESEARCH-PAPERS/Mastering%20the%20game%20of%20Go%20without%20human%20knowledge.pdf</a></li>
<li>Mastering the game of Go without human knowledge - PubMed, https://pubmed.ncbi.nlm.nih.gov/29052630/</li>
<li>Mastering the Game of Go without Human … - UCL Discovery, https://discovery.ucl.ac.uk/10045895/1/agz_unformatted_nature.pdf</li>
<li>Mastering the game of Go without human knowledge - Rashmeet Kaur Nayyar, https://www.rashmeetnayyar.com/post/silver_2017/</li>
<li>Mastering the game of Go without human knowledge - UCL Discovery, https://discovery.ucl.ac.uk/10045895/</li>
<li>Artificial Intelligence Learns to Learn Entirely on Its Own | Quanta Magazine, https://www.quantamagazine.org/artificial-intelligence-learns-to-learn-entirely-on-its-own-20171018/</li>
<li>AlphaGo Zero - Wikipedia, https://en.wikipedia.org/wiki/AlphaGo_Zero</li>
<li>AlphaGo Zero - Deepgram, https://deepgram.com/ai-glossary/alphago-zero</li>
<li>Monte Carlo Tree Search (MCTS) in AlphaGo Zero | by Jonathan Hui - Medium, https://jonathan-hui.medium.com/monte-carlo-tree-search-mcts-in-alphago-zero-8a403588276a</li>
<li>Simple Alpha Zero - Surag Nair, https://suragnair.github.io/posts/alphazero.html</li>
<li>Mastering the game of Go without human knowledge - Augmenting Long-term Memory, https://augmentingcognition.com/assets/Silver2017a.pdf</li>
<li>AlphaGo Zero loss function - Data Science Stack Exchange, https://datascience.stackexchange.com/questions/63305/alphago-zero-loss-function</li>
<li>What does DeepMind’s latest publication mean for A.I.? | by Axel Sooriah, https://becominghuman.ai/what-does-deepminds-latest-publication-mean-for-a-i-d496ab06d61f</li>
<li>AlphaGo Zero Explained In One Diagram | by David Foster | Applied Data Science - Medium, https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0</li>
<li>Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm, https://arxiv.org/abs/1712.01815</li>
<li>Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm arXiv:1712.01815v1 [cs.AI] 5 Dec 2017, https://arxiv.org/pdf/1712.01815</li>
<li>How AI Revolutionized Protein Science, but Didn’t End It | Quanta Magazine, https://www.quantamagazine.org/how-ai-revolutionized-protein-science-but-didnt-end-it-20240626/</li>
<li>Report on International Conference on Computer Vision (ICCV) 2017 | by Anil Bas | Medium, https://medium.com/@anilbas/report-on-international-conference-on-computer-vision-iccv-2017-f9b6d5cc70e1</li>
<li>ICCV 2017 Best Paper Award: Mask R-CNN | IEEE Signal Processing Society, https://signalprocessingsociety.org/newsletter/2018/01/iccv-2017-best-paper-award-mask-r-cnn</li>
<li>ICCV Paper Awards - IEEE Computer Society Technical Committee on Pattern Analysis and Machine Intelligence, https://tc.computer.org/tcpami/awards/iccv-paper-awards/</li>
<li>[1703.06870] Mask R-CNN - arXiv, https://arxiv.org/abs/1703.06870</li>
<li>Mask R-CNN - CVF Open Access, https://openaccess.thecvf.com/content_ICCV_2017/papers/He_Mask_R-CNN_ICCV_2017_paper.pdf</li>
<li>(PDF) Mask R-CNN (2017) | Kaiming He | 22940 Citations - SciSpace, https://scispace.com/papers/mask-r-cnn-4jykye6d41</li>
<li>[PDF] Mask R-CNN - Semantic Scholar, https://www.semanticscholar.org/paper/Mask-R-CNN-He-Gkioxari/84d440eac8a3fb52ea5708e4943d02fc3fcfe009</li>
<li>(PDF) Focal Loss for Dense Object Detection (2017) | Tsung-Yi Lin | 20552 Citations, https://scispace.com/papers/focal-loss-for-dense-object-detection-j0su4gk9as</li>
<li>Focal Loss for Dense Object Detection - CVF Open Access, https://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf</li>
<li>Focal Loss for Dense Object Detection - ICCV 2017 Open Access Repository, https://openaccess.thecvf.com/content_iccv_2017/html/Lin_Focal_Loss_for_ICCV_2017_paper.html</li>
<li>[PDF] Focal Loss for Dense Object Detection - Semantic Scholar, https://www.semanticscholar.org/paper/Focal-Loss-for-Dense-Object-Detection-Lin-Goyal/1a857da1a8ce47b2aa185b91b5cb215ddef24de7</li>
<li>IROS 2017, Vancouver, Canada - Plenaries and Keynotes, https://ewh.ieee.org/conf/iros/2017/iros2017.org/program/plenaries-and-keynotes.html</li>
<li>IROS 2017 Fox Plenary: Unifying Model-based and Learning-based Robotics - YouTube, https://www.youtube.com/watch?v=9ZuCo5tHZ6I</li>
<li>IROS 2017 RoboCup Best Paper Award, https://www.robocup.org/news/39</li>
<li>IROS RoboCup Best Paper Award, https://www.robocup.org/iros_robocup_best_paper_award</li>
<li>Online Visual Robot Tracking and Identification … - ais.uni-bonn.de, http://www.ais.uni-bonn.de/papers/IROS_2017_Farazi.pdf</li>
<li>Boeing Invests in Robotics Institute Autonomous Flight Spinoff - News, https://www.cmu.edu/news/stories/archives/2017/october/boeing-investment.html</li>
<li>Boeing HorizonX Invests in Unmanned Systems Technology Leader …, https://boeing.mediaroom.com/2017-10-19-Boeing-HorizonX-Invests-in-Unmanned-Systems-Technology-Leader-Near-Earth-Autonomy</li>
<li>Boeing HorizonX invests in unmanned systems technology company Near Earth Autonomy, https://verticalmag.com/press-releases/boeing-horizonx-invests-unmanned-systems-technology-company-near-earth-autonomy/</li>
<li>Boeing’s VC arm backs unmanned sensor firm Near Earth Autonomy, https://www.washingtontechnology.com/2017/10/boeings-vc-arm-backs-unmanned-sensor-firm-near-earth-autonomy/344220/</li>
<li>Boeing HorizonX invests in Near Earth Autonomy, boosting self-flying tech - GeekWire, https://www.geekwire.com/2017/boeing-horizonx-invests-near-earth-autonomy-boosting-self-flying-tech/</li>
<li>AI Experts Launch Data Index, Report - MIT Initiative on the Digital Economy, https://ide.mit.edu/insights/ai-experts-launch-data-index-report/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>