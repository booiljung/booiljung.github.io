<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2015년 2분기 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2015년 2분기 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2015년 AI 및 로봇 연구 동향</a> / <span>2015년 2분기 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2015년 2분기 AI 및 로봇 연구 동향</h1>
<h2>1.  서론</h2>
<h3>1.1  2015년 2분기의 기술사적 의의</h3>
<p>2015년 2분기는 인공지능(AI) 기술의 역사에서 중요한 변곡점으로 기록된다. 이 시기는 심층 학습(Deep Learning), 특히 합성곱 신경망(Convolutional Neural Networks, CNN)이 학술적 성공을 넘어 산업계의 표준으로 자리 잡기 시작한 ’성숙의 서막’이었다. 동시에, 최첨단 로봇 기술이 현실 세계의 복잡성과 물리적 제약이라는 거대한 장벽에 부딪히며 그 한계를 명확히 드러낸 ’현실 인식’의 시기이기도 했다. 이는 추상적 지능(소프트웨어)의 폭발적 발전과 물리적 지능(하드웨어)의 점진적 발전 사이의 간극을 극명하게 보여주는 분기점으로서 중요한 의미를 지닌다.</p>
<p>이 시기의 특징은 AI 발전의 이중성(Duality)으로 요약될 수 있다. 한편에서는 구글의 GoogLeNet과 같은 혁신적인 알고리즘이 디지털 데이터, 즉 ’비트(bits)’의 세계에서 초인적인 패턴 인식 능력을 입증하며 추상적 지능의 가능성을 무한히 확장했다.1 다른 한편에서는, 2015년 6월에 열린 DARPA 로보틱스 챌린지(DRC) 결선에 참가한 세계 최고 수준의 휴머노이드 로봇들이 현실 세계의 물리 법칙, 즉 ’아톰(atoms)’의 세계 앞에서 고전하며 지능의 물리적 구현(physical embodiment)이 얼마나 어려운 과제인지를 역설적으로 증명했다.3 이처럼 ’비트와 아톰의 간극’은 2015년 2분기 AI 기술 지형을 이해하는 핵심적인 분석 프레임워크를 제공한다. 컴퓨터 비전 분야는 잘 정의된 문제와 대규모 데이터셋 위에서 눈부신 성과를 거두었지만, 로봇 공학은 예측 불가능한 물리적 상호작용과 실시간 제어라는 훨씬 더 복잡한 문제와 씨름하고 있었다. 이 간극에 대한 명확한 인식은 이후 강화학습(Reinforcement Learning), 모방학습(Imitation Learning), 그리고 시뮬레이션과 현실 세계의 차이를 극복하려는 Sim-to-Real 연구 흐름을 촉발하는 중요한 계기가 되었다.</p>
<h3>1.2  보고서의 목적 및 구성</h3>
<p>본 보고서는 2015년 2분기 동안 발표된 주요 학술대회 논문, 핵심 연구기관의 성과, 그리고 산업계의 전략적 움직임을 심층적으로 분석하는 것을 목적으로 한다. 이를 통해 당시 AI 및 로봇 공학 기술 수준의 현주소를 정밀하게 진단하고, 이러한 성과와 도전 과제들이 이후 연구 개발의 방향성에 어떠한 영향을 미쳤는지를 다각적으로 고찰하고자 한다. 보고서는 다음과 같이 구성된다. 제2장에서는 CVPR, ICRA 등 해당 분기의 주요 학술대회에서 발표된 핵심 연구들을 분석하여 각 분야의 기술적 최전선을 탐색한다. 제3장에서는 DARPA 로보틱스 챌린지를 중심으로, 그리고 구글, 페이스북, MIT, CMU 등 주요 기업 및 대학 연구소의 동향을 추적하여 이론적 성과가 현실 세계에서 어떻게 구현되고 있었는지를 살펴본다. 마지막으로 제4장에서는 앞선 분석들을 종합하여 2015년 2분기가 AI 기술 발전에 남긴 유산을 평가하고 미래 전망을 제시한다.</p>
<h2>2.  주요 학술대회 발표 동향</h2>
<p>2015년 2분기를 전후하여 개최된 최고 수준의 학술대회들은 당시 인공지능 및 로봇 공학의 각 하위 분야가 도달한 기술적 최전선을 명확하게 보여주는 지표 역할을 했다. 본 장에서는 컴퓨터 비전, 로봇 공학, 머신러닝 이론 분야를 대표하는 학회에서 발표된 핵심 연구 성과들을 심층적으로 분석한다. 아래 표는 본 보고서에서 중점적으로 다룰 주요 학술대회들의 개요를 정리한 것이다. 이 표는 각 학회의 전문 분야, 규모, 그리고 당시의 경쟁 수준을 일목요연하게 보여줌으로써, 개별 논문 분석에 앞서 거시적인 학술 지형에 대한 이해를 돕는다.</p>
<p><strong>Table 1: 2015년 2분기 주요 AI/로봇 학술대회 개요</strong></p>
<table><thead><tr><th>학회명 (Full Name)</th><th>약칭</th><th>개최 시기</th><th>개최 장소</th><th>핵심 분야</th><th>주요 특징 및 규모</th><th>관련 자료</th></tr></thead><tbody>
<tr><td>IEEE International Conference on Robotics and Automation</td><td>ICRA 2015</td><td>2015년 5월 26-30일</td><td>미국 시애틀</td><td>로봇 공학 전반 (조작, 이동, HRI, 비전)</td><td>IEEE RAS 주관 플래그십 컨퍼런스. 2,275편 제출, 940편 채택 (채택률 41%). 3,000명 이상 참가.</td><td>4</td></tr>
<tr><td>IEEE Conference on Computer Vision and Pattern Recognition</td><td>CVPR 2015</td><td>2015년 6월 7-12일</td><td>미국 보스턴</td><td>컴퓨터 비전, 패턴 인식, 딥러닝</td><td>컴퓨터 비전 분야 최고 권위 학회. GoogLeNet 논문 발표.</td><td>6</td></tr>
<tr><td>International Conference on Autonomous Agents and Multiagent Systems</td><td>AAMAS 2015</td><td>2015년 5월 4-8일</td><td>터키 이스탄불</td><td>자율 에이전트, 다중 에이전트 시스템, 강화학습</td><td>에이전트 기반 시스템 및 이론 분야의 대표 학회.</td><td>8</td></tr>
<tr><td>International Conference on Machine Learning</td><td>ICML 2015</td><td>2015년 7월 6-11일</td><td>프랑스 릴</td><td>머신러닝 이론 및 알고리즘</td><td>머신러닝 분야 최고 권위 학회 중 하나. 발표 논문집이 6월 1일 출간되어 2분기 연구 동향에 포함.</td><td>10</td></tr>
</tbody></table>
<h3>2.1  컴퓨터 비전 분야의 혁신: CVPR 2015</h3>
<p>2015년의 컴퓨터 비전 분야는 심층 학습의 성공에 힘입어 폭발적인 발전을 거듭하고 있었다. 특히 CVPR 2015에서는 딥러닝 아키텍처의 설계 철학을 한 단계 발전시킨 기념비적인 연구가 발표되었다.</p>
<h4>2.1.1  “Going Deeper with Convolutions” 심층 분석</h4>
<p>2015년 2분기 AI 분야에서 발표된 가장 중요한 단일 연구 성과를 꼽는다면 단연 Christian Szegedy를 필두로 한 Google 연구팀의 “Going Deeper with Convolutions“일 것이다.1 이 논문은 ILSVRC(ImageNet Large-Scale Visual Recognition Challenge) 2014 대회에서 압도적인 성능으로 우승한 ‘GoogLeNet’ 아키텍처를 상세히 소개하며, 심층 신경망 설계의 새로운 패러다임을 제시했다. 당시 연구의 주도권이 학계에서 구글과 같은 대규모 산업계 연구소로 넘어가고 있음을 보여주는 상징적인 사례이기도 했다.</p>
<p>이 연구의 핵심 목표는 단순히 네트워크를 더 깊게 쌓아 성능을 높이는 기존의 방식을 넘어서는 것이었다. 연구팀은 ’제한된 연산 예산(computational budget)’이라는 현실적인 제약 조건 하에서 네트워크의 깊이(depth)와 너비(width)를 어떻게 효율적으로 증가시킬 수 있을지에 대한 근본적인 질문을 던졌다.1 이는 딥러닝 모델을 학술적 호기심의 대상에서 벗어나, 대규모 데이터셋을 다루는 실제 상용 제품에 합리적인 비용으로 적용 가능하게 만들려는 명확한 공학적 목표를 반영한 것이었다.</p>
<p>이러한 목표를 달성하기 위해 제안된 핵심 아이디어가 바로 ’인셉션 모듈(Inception module)’이다. 인셉션 모듈의 구조와 그 기저에 깔린 철학은 다음과 같이 분석할 수 있다.</p>
<ul>
<li>
<p><strong>다중 스케일 처리 (Multi-scale processing):</strong> 기존의 CNN이 각 계층에서 단일 크기의 컨볼루션 필터(예: 3x3)를 사용하는 것과 달리, 인셉션 모듈은 1x1, 3x3, 5x5 컨볼루션 필터와 3x3 맥스 풀링(max pooling) 연산을 동일한 입력에 대해 병렬적으로 적용하고, 그 결과로 나온 특징 맵(feature map)들을 채널 방향으로 모두 합치는 구조를 채택했다.2 이는 이미지 내의 객체가 다양한 크기와 시점에서 나타날 수 있다는 점에 착안하여, 네트워크가 한 계층 내에서 여러 스케일의 특징을 동시에 포착하도록 유도하는 직관적인 설계였다.</p>
</li>
<li>
<p><strong>차원 축소 병목(Dimension Reduction Bottleneck):</strong> 다중 스케일 처리 아이디어의 가장 큰 문제점은 연산량의 폭발적인 증가였다. 특히 5x5 컨볼루션은 3x3 컨볼루션에 비해 훨씬 많은 계산을 요구한다. 연구팀은 이 문제를 해결하기 위해, 연산량이 많은 3x3 및 5x5 컨볼루션 앞에 저렴한 1x1 컨볼루션을 ‘병목(bottleneck)’ 계층으로 배치하는 기법을 도입했다.12 이 1x1 컨볼루션은 입력 특징 맵의 채널 수를 줄이는 차원 축소 역할을 수행함으로써, 후속 컨볼루션 연산의 계산량을 극적으로 감소시켰다. 이는 Lin 등이 제안한 ‘Network-in-Network’ 개념을 독창적으로 활용한 사례로, 네트워크의 깊이와 너비를 확장하면서도 전체 파라미터 수를 효율적으로 제어하는 결정적인 역할을 했다.12</p>
</li>
<li>
<p><strong>헤브의 원리(Hebbian Principle) 기반 설계:</strong> 논문은 이러한 아키텍처 설계가 신경과학의 고전적 원리인 헤브의 원리, 즉 “함께 발화하는 뉴런은 함께 연결된다(neurons that fire together, wire together)“는 개념에서 영감을 얻었다고 밝히고 있다.2 이는 통계적으로 높은 상관관계를 보이는 유닛(특징)들은 다음 계층에서 하나의 클러스터로 묶여 함께 처리되어야 한다는 아이디어로 해석될 수 있다.12 인셉션 모듈 내에서 다양한 필터를 통해 특징을 추출하고 이를 다시 1x1 컨볼루션으로 묶어주는 구조는, 이러한 헤브의 원리를 통해 희소하게 연결된(sparsely connected) 구조를 효율적인 밀집 행렬 연산(dense matrix operations)으로 구현하려는 시도로 볼 수 있다.14</p>
</li>
</ul>
<p>GoogLeNet의 기술적 의의는 단순히 ILSVRC 대회 우승에 그치지 않는다. VGGNet과 같이 필터를 무작정 깊게 쌓는 단순하고 균일한 구조에서 벗어나, 효율적으로 설계된 ’마이크로 아키텍처(인셉션 모듈)’를 반복적으로 쌓아 전체 네트워크를 구성하는 새로운 설계 방향을 제시했다. 이는 제한된 하드웨어 자원 내에서 최대한의 성능을 끌어내야 하는 현실적인 문제에 대한 강력한 해법을 제공했으며, 이후 ResNet의 잔차 블록(residual block), DenseNet의 밀집 블록(dense block) 등 효율적인 네트워크 모듈 설계 연구의 기폭제가 되었다. 결과적으로 GoogLeNet은 딥러닝 모델의 실용성을 한 차원 높여, AI 기술이 다양한 상용 제품과 서비스에 탑재되는 것을 가속화하는 데 결정적인 기여를 했다.</p>
<h3>2.2  로봇 공학의 현주소: ICRA 2015</h3>
<p>ICRA 2015는 컴퓨터 비전 분야의 눈부신 발전과는 대조적으로, 로봇 공학이 현실 세계의 물리적 제약과 불확실성이라는 본질적인 문제와 어떻게 씨름하고 있는지를 여실히 보여주었다. 발표된 주요 연구들은 인간과의 안전한 상호작용, 비전 정보를 이용한 정밀한 조작 등 구체적이고 현실적인 과제에 집중하는 경향을 보였다.</p>
<h4>2.2.1  물리적 인간-로봇 상호작용(pHRI)의 제어</h4>
<p>안전한 인간-로봇 협업은 당시 로봇 공학의 가장 중요한 화두 중 하나였다. ICRA 2015 최우수 컨퍼런스 논문상 최종 후보작에 오른 로마 라 사피엔차 대학(Sapienza University of Rome)의 Alessandro De Luca 등이 발표한 “Control of Generalized Contact Motion and Force in Physical Human-Robot Interaction“은 이 분야의 핵심적인 기술적 과제를 다루었다.15</p>
<p>이 연구의 핵심 기여는 별도의 고가 힘/토크 센서(force/torque sensor)를 부착하지 않고도 인간과 로봇 간의 물리적 상호작용을 정밀하게 제어하는 방법을 제시한 데 있다.17 연구팀은 로봇의 정밀한 동역학 모델과 각 관절의 모터 전류(혹은 토크) 정보만을 이용하여, 로봇의 어느 부위에 접촉이 발생했는지, 그리고 그 접촉 힘이 어느 정도인지를 실시간으로 추정하는 알고리즘을 개발했다. 이를 바탕으로, 사용자가 로봇을 밀거나 당길 때 마치 로봇이 특정 질량이나 마찰을 가진 물체처럼 느껴지도록 만드는 임피던스 제어(impedance control)나, 사용자가 가하는 힘을 일정한 수준으로 유지하거나 조절하는 직접적인 힘 제어(force control)를 구현했다.17 이는 값비싼 추가 센서 없이도 소프트웨어만으로 로봇의 안전성과 상호작용 능력을 크게 향상시킬 수 있음을 보여준 연구로서, 협동로봇의 산업 현장 적용 및 상용화 가능성을 한층 높이는 중요한 기술적 진보였다.18</p>
<h4>2.2.2  비전 기반 로봇 조작</h4>
<p>로봇이 주변 환경을 ‘보고’ 그 정보를 바탕으로 물체를 ’조작’하는 능력은 자율 로봇의 핵심 기능이다. 워싱턴 대학(University of Washington)과 독일 항공우주센터(DLR) 연구진이 공동으로 발표하여 최우수 논문, 최우수 비전 논문, 최우수 학생 논문상 최종 후보에 모두 오른 “Depth-Based Tracking with Physical Constraints for Robot Manipulation“은 이 분야에서 중요한 진전을 이루었다.19</p>
<p>이 연구는 RGB 이미지 대신 깊이(depth) 정보만을 이용하여 로봇 팔과 조작 대상 물체를 실시간으로 추적하는 기술을 제안했다.20 특히 이 연구가 주목받은 이유는 단순히 시각 정보에만 의존하지 않고 ’물리적 제약(physical constraints)’을 추적 알고리즘에 명시적으로 통합했기 때문이다. 구체적으로, 로봇 팔과 물체, 또는 여러 물체들이 서로를 뚫고 지나갈 수 없다는 ‘상호 관통 불가(non-interpenetration)’ 제약과, 로봇 손의 토크 센서나 터치 센서에서 감지된 ’접촉 정보(contact information)’를 최적화 과정에 포함시켰다.20 예를 들어, 센서가 접촉을 감지했는데 추정된 로봇 손과 물체의 위치가 떨어져 있다면, 알고리즘은 이를 오류로 간주하고 자세 추정치를 수정한다. 이러한 접근은 로봇이 단순히 이미지를 ’보는 것’을 넘어, 물리 법칙을 ’이해’하며 주변 환경을 인식하도록 만들어 추적의 정확성과 강인성을 크게 향상시켰다. 이는 로봇 인식 기술이 순수한 기하학적 문제를 넘어 동역학적, 물리적 상호작용을 고려하는 방향으로 발전하고 있음을 보여주는 대표적인 사례였다.</p>
<h4>2.2.3  아마존 피킹 챌린지</h4>
<p>ICRA 2015에서는 학술 발표 외에도 중요한 이벤트가 처음으로 개최되었는데, 바로 ’아마존 피킹 챌린지(Amazon Picking Challenge)’였다.4 이 대회는 아마존의 실제 물류 창고 환경을 모사하여, 선반에 놓인 다양한 크기, 모양, 재질의 물품들을 로봇이 자율적으로 인식하고 집어서 지정된 상자에 옮기는 과제를 제시했다. 이 챌린지는 당시 학계의 연구가 산업 현장에서 직면하는 실제 문제, 즉 비정형 객체의 인식 및 파지(grasping) 문제와 얼마나 괴리되어 있는지를 보여주는 동시에, 이 간극을 메우기 위한 전 세계 연구팀들의 노력을 한자리에 모으는 계기가 되었다. 이는 로봇 커뮤니티가 이론적 탐구를 넘어 산업적 난제 해결에 본격적으로 뛰어들기 시작했음을 알리는 상징적인 사건이었다.</p>
<h3>2.3  머신러닝 이론의 진화: ICML &amp; AAMAS 2015</h3>
<p>컴퓨터 비전과 로봇 공학 분야에서 경험적, 공학적 발전이 이루어지는 동안, ICML과 AAMAS와 같은 학회에서는 이러한 기술들의 근간을 이루는 머신러닝 이론의 심화가 이루어지고 있었다. 이 시기의 이론 연구들은 알고리즘의 성능 보장, 한계 규명, 그리고 새로운 학습 패러다임 제시 등에 초점을 맞추었다.</p>
<h4>2.3.1  온라인 부스팅 알고리즘의 최적화 (ICML Best Paper)</h4>
<p>ICML 2015 최우수 논문상 수상작 중 하나인 “Optimal and Adaptive Algorithms for Online Boosting“은 Yahoo Labs와 프린스턴 대학 연구진에 의해 발표되었다.21 이 연구는 데이터가 한 번에 주어지는 배치(batch) 학습 환경이 아닌, 데이터가 순차적으로 계속 들어오는 온라인(online) 또는 스트리밍 환경에서의 학습 문제를 다루었다.</p>
<p>’부스팅(Boosting)’은 성능이 다소 낮은 여러 개의 간단한 예측 모델(약한 학습기, weak learner)을 순차적으로 결합하여 강력한 예측 모델(강한 학습기, strong learner)을 만드는 앙상블 기법이다. 이 논문은 온라인 환경에 적용 가능한 새로운 부스팅 알고리즘들을 제안하고 그 성능을 이론적으로 분석했다. 특히, 약한 학습기의 성능 등 특정 파라미터가 사전에 알려진 경우 이론적으로 최적의 오류율을 달성하는 ‘OnlineBBM’ 알고리즘과, 이러한 정보가 없을 때에도 데이터에 적응적으로 학습하는 ‘AdaBoost.OL’ 알고리즘을 제시했다.21 실험 결과, 제안된 알고리즘들은 12개 중 10개의 벤치마크 데이터셋에서 기존의 다른 모든 부스팅 알고리즘보다 낮은 오류를 기록했다.21 이는 대규모 스트리밍 데이터를 실시간으로 처리해야 하는 금융 사기 탐지, 실시간 광고 입찰, 추천 시스템 등 다양한 산업 응용 분야에 직접적인 영향을 미칠 수 있는 중요한 이론적 진보였다.23</p>
<h4>2.3.2  모델 기반 강화학습의 이해 (AAMAS Best Paper)</h4>
<p>AAMAS 2015 최우수 논문상을 수상한 미시간 대학(University of Michigan) 연구팀의 “The Dependence of Effective Planning Horizon on Model Accuracy“는 강화학습, 특히 모델 기반 강화학습(model-based reinforcement learning)의 근본적인 딜레마를 탐구했다.25 모델 기반 강화학습에서 에이전트는 데이터로부터 환경의 동작 방식(모델)을 학습한 뒤, 그 모델을 이용해 최적의 행동 계획을 수립한다.</p>
<p>이 논문의 핵심적인 발견은, 데이터로부터 학습된 환경 모델이 필연적으로 부정확할 경우, 에이전트가 무한히 먼 미래까지 내다보며 완벽한 계획을 세우려 하기보다는 오히려 ’더 짧은 미래(shorter planning horizon)’만을 고려하여 계획을 세우는 것이 결과적으로 더 나은 정책으로 이어질 수 있다는 점을 이론적으로 규명한 것이다.25 연구팀은 학습 이론의 원리를 적용하여, 계획 horizon이 학습될 정책 클래스의 복잡도(complexity)를 제어하는 일종의 정규화(regularization) 매개변수 역할을 함을 보였다. 즉, 짧은 horizon은 더 단순한 정책을 유도하여, 불완전하고 노이즈가 낀 모델에 대한 과적합(overfitting)을 방지하는 효과를 낳는다는 것이다.27 이는 마치 학생이 불완전한 요약 노트를 가지고 공부할 때, 너무 깊게 파고들기보다 핵심적인 내용에 집중하는 것이 더 나은 시험 결과로 이어지는 것과 유사하다. 이 연구는 모델의 불확실성 하에서 강화학습 에이전트의 견고성(robustness)을 확보하는 문제에 대한 중요한 이론적 통찰을 제공했다.</p>
<p>이상의 학술대회 동향을 종합해 보면, 2015년 2분기 AI 연구 생태계의 다층적인 구조가 드러난다. CVPR에서는 ImageNet이라는 대규모 표준 데이터셋과 명확한 평가 지표 위에서 ’효율적인 대규모 인식’이라는 잘 정의된 문제를 해결하며 딥러닝 기술이 폭발적으로 성장하고 있었다. 반면, ICRA에서는 ’물리적 상호작용의 불확실성 제어’라는, 정량화하기 어렵고 훨씬 더 복잡한 문제와 씨름하고 있었다. 이는 문제의 차원이 인식(perception)을 넘어 계획(planning)과 제어(control)를 포괄하기 때문이었다. 이러한 경험적 성공(CVPR)과 현실적 어려움(ICRA) 사이의 간극을 메우기 위해, ICML과 AAMAS에서는 ‘온라인 학습’, ’모델 불확실성’과 같은 알고리즘의 근본적인 가정과 한계에 대한 이론적 탐구가 심도 있게 이루어지고 있었다. 결국 이 시기 AI 연구는 ‘잘 닦인 고속도로(컴퓨터 비전)’, ‘험난한 비포장도로(로보틱스)’, 그리고 그 도로들을 건설하기 위한 ’기초 공학(머신러닝 이론)’이 각기 다른 속도와 방향으로 발전하며 공존하는 양상이었다. 이러한 분야별 성숙도의 차이를 이해하는 것이 2015년 AI 생태계를 정확히 파악하는 열쇠라 할 수 있다.</p>
<h2>3.  주요 연구기관 및 기업 연구 동향</h2>
<p>학술대회에서의 이론적, 실험적 성과와 더불어, 2015년 2분기는 주요 연구기관과 기업들이 대규모 프로젝트와 전략적 투자를 통해 AI 및 로봇 기술의 한계를 시험하고 미래 방향을 설정하던 시기였다. 특히 미 국방고등연구계획국(DARPA)이 주최한 로보틱스 챌린지는 당시 로봇 기술의 현주소를 대중에게 가장 극적으로 보여준 사건이었다.</p>
<h3>3.1  재난 로봇 기술의 시험대: DARPA 로보틱스 챌린지 결선</h3>
<p>2011년 일본 후쿠시마 원전 사고는 인간이 접근할 수 없는 극한의 재난 환경에서 로봇의 필요성을 절감하게 만든 계기가 되었다. 이에 DARPA는 2012년부터 인간을 대신하여 재난 현장에서 복구 임무를 수행할 수 있는 반자율(semi-autonomous) 로봇 개발을 목표로 DARPA 로보틱스 챌린지(DRC)를 개최했으며, 그 최종 결선이 2015년 6월 5일과 6일, 미국 캘리포니아 포모나에서 열렸다.28</p>
<p>DRC 결선은 로봇에게 매우 구체적이고 복잡한 일련의 과제를 요구했다. 이는 단순한 기술 시연을 넘어, 실제 재난 상황에서 로봇이 마주할 법한 복합적인 문제 해결 능력을 종합적으로 평가하기 위함이었다. 아래 표는 DRC 결선에서 로봇이 수행해야 했던 8가지 주요 과제를 정리한 것이다. 이 과제들은 ’이미지 분류’와 같은 추상적인 작업과는 근본적으로 다른, 물리 세계와의 정교한 상호작용을 요구했다.</p>
<p><strong>Table 3: DARPA 로보틱스 챌린지 2015 결선 주요 과제</strong></p>
<table><thead><tr><th>과제 (Task)</th><th>요구 능력</th></tr></thead><tbody>
<tr><td>1. 차량 운전 (Drive a utility vehicle)</td><td>원격 조종, 페달 및 핸들 조작, 공간 인식</td></tr>
<tr><td>2. 차량 하차 (Travel dismounted)</td><td>복잡한 자세 제어, 균형 유지</td></tr>
<tr><td>3. 문 열고 통과 (Open a door and enter a building)</td><td>손잡이 인식 및 조작, 동시 이동 및 조작</td></tr>
<tr><td>4. 밸브 잠그기 (Locate and close a valve)</td><td>밸브 인식, 파지 및 회전력 제어</td></tr>
<tr><td>5. 벽 뚫기 (Use a tool to break through a concrete panel)</td><td>공구 파지 및 작동, 힘 제어</td></tr>
<tr><td>6. 장애물 지형 통과 (Remove debris or traverse rubble)</td><td>비정형 지형 보행, 장애물 제거</td></tr>
<tr><td>7. 계단 오르기 (Climb an industrial ladder)</td><td>반복적인 손-발 협응, 강력한 파지력</td></tr>
<tr><td>8. 호스 연결 (Connect a fire hose)</td><td>커넥터 정밀 조작, 유연체 조작</td></tr>
</tbody></table>
<p>이처럼 복합적인 과제들로 구성된 대회에서, 카네기 멜런 대학(CMU)과 MIT의 팀들은 각기 다른 철학으로 설계된 로봇과 알고리즘을 선보이며 주목받았다.</p>
<h4>3.1.1  CMU Tartan Rescue 팀의 CHIMP 로봇</h4>
<p>CMU 국립로봇공학센터(NREC)가 주축이 된 Tartan Rescue 팀의 CHIMP 로봇은 최종 3위를 차지하며 50만 달러의 상금을 획득, 세계 최고 수준의 필드 로보틱스 기술력을 입증했다.3 CHIMP의 가장 큰 특징은 보스턴 다이내믹스의 Atlas와 같은 이족보행 휴머노이드가 아니라는 점이었다. CHIMP는 네 개의 다리 끝에 바퀴(정확히는 무한궤도)가 달려 있어, 평지에서는 바퀴로 구르고 험지에서는 다리로 걷거나 기어가는 하이브리드 형태를 취했다.30 이러한 설계는 이족보행의 동적인 균형 제어 문제에서 벗어나 정적인 안정성(static stability)을 확보하기 위한 전략적 선택이었다.</p>
<p>이러한 설계 철학의 진가는 대회 첫날 극적으로 드러났다. CHIMP는 문을 여는 과제를 수행하던 중 예기치 않게 넘어졌지만, 대회에 참가한 수많은 로봇 중 유일하게 외부의 도움 없이 스스로의 힘으로 다시 일어서는 데 성공했다.3 관중들은 이 장면에 열광했으며, 이는 단순히 과제를 성공하는 능력뿐만 아니라, 예측 불가능한 환경에서 ’실패로부터 회복하는 능력(resilience)’이 재난 로봇에게 얼마나 중요한지를 상징적으로 보여준 사건이었다. CHIMP는 넘어지는 역경을 딛고 그날 주어진 8개의 과제를 모두 완수하며 첫날 경기에서 1위를 차지하는 기염을 토했다.3</p>
<h4>3.1.2  MIT CSAIL 팀의 Atlas 로봇</h4>
<p>MIT 컴퓨터과학 및 인공지능 연구소(CSAIL)가 운영한 Atlas 로봇은 최종 6위를 기록했다.32 순위는 다소 낮았지만, MIT 팀은 대회에서 가장 진보된 수준의 동작 계획(motion planning) 및 제어 알고리즘을 선보였다는 평가를 받았다.</p>
<p>MIT 팀의 접근 방식은 로봇의 모든 움직임을 하나의 거대한 최적화 문제로 푸는 것이었다. 특히, 로봇이 환경과 접촉하는 모든 지점(발바닥, 손, 심지어 들고 있는 공구 등)에서 발생하는 힘을 고려하여, 로봇의 전체 무게 중심(center of gravity)의 변위를 최소화하면서 안정적으로 움직일 수 있는 동작을 실시간으로 계산해냈다.34 이는 로봇이 단순히 미리 프로그래밍된 동작을 재생하는 것을 넘어, 변화하는 상황에 맞춰 물리 법칙에 기반한 최적의 동작을 스스로 생성해내는 고도의 자율성을 추구한 것이었다. 비록 대회 성적은 기대에 미치지 못했지만, MIT 팀이 개발한 알고리즘들은 이후 휴머노이드 로봇의 동적 보행 및 전신 제어(whole-body control) 연구에 큰 영향을 미쳤다. 이는 DRC가 단순한 로봇 경진대회를 넘어, 최첨단 로봇 제어 이론을 검증하고 발전시키는 중요한 실험장이었음을 보여준다.32</p>
<h4>3.1.3  DRC의 유산과 평가</h4>
<p>DRC 결선은 로봇들이 인간에 비해 터무니없이 느린 속도로 움직이고, 우스꽝스럽게 넘어지는 장면들이 연출되면서 ’실패한 대회’라는 비판적인 시각에 직면하기도 했다.35 하지만 대회의 진정한 유산은 그 이면에 있다. DARPA는 이 대회를 통해 전 세계 연구팀들이 열악한 통신 환경 하에서 반자율적으로 복잡한 물리적 과업을 수행하는 기술을 개발하도록 유도했으며, 그 결과 관련 기술 수준을 한 세대 앞당겼다는 평가를 받는다.28 또한, 대회 과정에서 공개된 시뮬레이션 환경(Gazebo), 로봇 플랫폼(Atlas), 그리고 수많은 실패와 성공을 통해 축적된 방대한 데이터와 경험은 이후 로봇 공학 연구 커뮤니티 전체의 귀중한 자산이 되었다.29 DRC는 로봇 기술의 현주소를 냉정하게 보여줌과 동시에, 앞으로 해결해야 할 과제가 무엇인지를 명확히 제시한 이정표였다.</p>
<h3>3.2  글로벌 AI 연구의 지각 변동</h3>
<p>2015년 2분기는 기업들이 AI 연구 개발의 주도권을 잡기 위해 본격적으로 움직이기 시작한 시기이기도 했다. 특히 페이스북의 행보는 이러한 변화를 상징적으로 보여준다.</p>
<h4>3.2.1  Facebook AI Research (FAIR) 파리 연구소 설립</h4>
<p>2015년 6월 2일, 페이스북은 자사의 인공지능 연구 조직인 FAIR(Facebook AI Research)가 미국 외 지역에서는 최초로 프랑스 파리에 새로운 연구소를 설립한다고 공식 발표했다.36 이는 기존의 멘로파크와 뉴욕 연구소에 이은 세 번째 AI 연구 거점이었다.</p>
<p>FAIR 파리 연구소 설립의 목표는 이미지 인식, 자연어 처리, 음성 인식 등 핵심 AI 분야에서 장기적인 관점의 기초 연구(fundamental research)를 수행하는 것이었다.36 페이스북은 프랑스가 세계 최고 수준의 AI 연구자들을 보유하고 있다고 평가하며, 이들과의 협력을 통해 기술 혁신을 가속화하겠다는 의지를 밝혔다.37 이 사건은 몇 가지 중요한 의미를 내포한다. 첫째, 구글, 마이크로소프트가 주도하던 AI 연구 경쟁에 페이스북이 본격적으로 뛰어들었음을 알리는 신호탄이었다. 둘째, AI 기술이 기업의 미래 경쟁력을 좌우할 핵심 요소로 부상하면서, 최고의 인재를 확보하기 위한 글로벌 경쟁이 국경을 넘어 치열하게 전개되기 시작했음을 시사한다.38 셋째, 과거 대학과 국책 연구소의 영역이었던 기초 과학 연구의 중심이 막대한 자본과 데이터를 보유한 거대 기술 기업으로 빠르게 이동하고 있음을 보여주는 명백한 증거였다.</p>
<h3>3.3  선도 대학 연구소의 핵심 성과</h3>
<p>DRC와 같은 대규모 프로젝트 외에도, 세계 유수의 대학 연구소들은 AI와 로봇 기술을 다양한 응용 분야로 확장하는 연구를 꾸준히 발표하며 기술의 지평을 넓히고 있었다.</p>
<h4>3.3.1  MIT CSAIL</h4>
<p>MIT CSAIL은 DRC 준비와 병행하여 AI 기술을 의료, 제조 등 다양한 분야에 접목하는 연구에서 두각을 나타냈다. 2015년 4월, 연구팀은 딥러닝 모델을 이용해 현미경으로 관찰한 조직 샘플 이미지로부터 림프종의 여러 아형(subtype)을 자동으로 구별해내는 시스템을 개발했다고 발표했다.40 이는 병리학자의 진단 정확도를 높이고 시간을 단축시켜 줄 수 있는 기술로, AI의 의료 분야 적용 가능성을 보여준 사례였다.</p>
<p>또한 5월에는 비디오 영상만을 분석하여 대상 물체의 미세한 떨림을 증폭, 그 재료의 고유한 물리적 특성(강성 등)을 추정하는 ‘시각 마이크로폰(Visual Microphone)’ 기술의 확장 연구를 발표했다.40 같은 달, 여러 대의 자율 로봇이 복잡한 조립 작업을 수행할 때, 실시간으로 발생하는 상황 변화에 맞춰 각자 맡을 작업을 동적으로 재분배하는 알고리즘을 개발하기도 했다.40 이러한 연구들은 AI와 로봇 기술이 단일 과제 해결을 넘어, 의학, 신소재 발견, 자동화된 제조 공정 등 사회 전반의 복잡한 문제 해결에 기여할 수 있는 범용 기술로서의 잠재력을 가지고 있음을 시사했다.</p>
<h4>3.3.2  CMU 로보틱스 연구소</h4>
<p>CMU 로보틱스 연구소는 DRC에서 CHIMP 로봇을 통해 보여준 압도적인 기술력으로 필드 로보틱스 분야의 세계적인 선두주자임을 다시 한번 각인시켰다.3 CHIMP의 성공은 단순히 로봇 하드웨어의 우수성뿐만 아니라, 그 이면에 있는 CMU의 깊이 있는 연구 역량에 기반한 것이었다. CHIMP 개발 과정에서 축적된 모듈형 로봇 설계 기술, 극한의 상황에서도 안정적으로 동작하는 강인한 제어 소프트웨어, 그리고 제한된 통신 환경 하에서 직관적인 원격 조작을 가능하게 하는 사용자 인터페이스 기술 등은 이후 다양한 상용 및 연구용 로봇 시스템 개발의 중요한 기술적 자산이 되었다.30</p>
<p>이 시기 주요 연구기관들의 활동을 종합해 보면, ‘챌린지’ 기반 연구 방식의 장점과 단점이 명확히 드러난다. DRC와 같은 대규모 경진대회는 ’재난 대응’이라는 명확하고 도전적인 목표를 제시하고, 경쟁 구도를 통해 단기간에 관련 기술을 집약적으로 발전시키는 데 매우 효과적이었다.28 하지만 동시에, 대회 규칙에 최적화된 기술 개발에 자원이 집중되면서, 보다 근본적이고 장기적인 연구 주제(예: 일반화된 조작 능력, 상식 추론, 인간과 유사한 학습 능력)에 대한 탐구가 상대적으로 저해될 수 있다는 한계도 내포하고 있었다. 예를 들어, CMU의 CHIMP가 이족보행의 근본적인 어려움을 회피하고 정적 안정성을 극대화하는 설계를 택한 것은, ’넘어지지 않고 과제를 완수하는 것’이 높은 점수를 받는다는 대회 규칙에 대한 매우 영리한 공학적 해법이었다. 그러나 이러한 접근 방식이 인간과 같은 환경에서 인간처럼 유연하게 움직이는 ’범용 휴머노이드’라는 더 큰 비전과 항상 일치하는 것은 아닐 수 있다. 이는 특정 목표 달성을 위한 공학적 최적화와, 미지의 미래에 대비하는 기초 과학 연구 사이의 영원한 긴장 관계를 보여주는 사례라 할 수 있다.</p>
<h2>4.  종합 분석 및 결론</h2>
<p>2015년 2분기는 인공지능과 로봇 공학 분야가 양적 팽창과 질적 심화를 동시에 겪으며, 미래 기술의 향방을 결정하는 중요한 분기점이었다. 이 시기의 다양한 연구 성과와 사건들은 서로 다른 방향으로 분화하면서도 각자의 영역에서 깊이를 더해가는 양상을 보였다.</p>
<h3>4.1  2015년 2분기의 핵심 요약: 분화와 심화</h3>
<p>이 시기의 가장 두드러진 특징은 AI 연구가 두 개의 뚜렷한 경로로 ’분화(Divergence)’되었다는 점이다. 첫 번째는 방대한 데이터와 강력한 연산 능력을 기반으로 디지털 세계의 인식(perception) 문제를 해결해 나가는 ’딥러닝 경로’이다. CVPR에서 발표된 GoogLeNet은 이 경로의 정점에 서 있는 성과로, 효율적인 아키텍처 설계를 통해 인식의 정확도를 극한까지 끌어올렸다. 두 번째는 물리 세계와의 상호작용(interaction)이라는 근본적인 난제에 직면한 ’로보틱스 경로’이다. DRC와 ICRA의 주요 연구들은 이 경로의 어려움을 상징적으로 보여주었다. 로봇은 센서 노이즈, 예측 불가능한 접촉 역학, 실시간 제어의 복잡성 등 현실 세계의 수많은 제약 조건 속에서 임무를 수행해야 했다.</p>
<p>동시에 각 경로는 자신만의 방식으로 ’심화(Deepening)’되었다. 딥러닝 커뮤니티는 단순히 성능을 높이는 것을 넘어, GoogLeNet을 통해 ’연산 효율성’이라는 새로운 차원의 최적화 문제로 나아갔다. 이는 AI를 실험실에서 꺼내 실제 제품으로 옮기기 위한 필수적인 과정이었다. 로보틱스 커뮤니티는 DRC의 수많은 실패를 통해 ’강인성(robustness)’과 ’실패 복구(failure recovery)’라는, 시뮬레이션에서는 쉽게 간과될 수 있는 현실적인 문제의 중요성을 절감했다. 한편, ICML과 AAMAS를 중심으로 한 머신러닝 이론 분야는 이러한 실제적, 경험적 발견들을 뒷받침하는 수학적 원리를 탐구하며 연구의 깊이를 더했다. 온라인 학습, 모델 불확실성 하에서의 계획 등은 이러한 이론적 심화의 대표적인 예시이다. 아래 표는 당시 이론 연구의 최전선을 보여주는 주요 학회의 최우수 논문상 수상작들을 요약한 것이다.</p>
<p><strong>Table 2: 2015년 2분기 주요 학술대회 최우수 논문상 요약</strong></p>
<table><thead><tr><th>학회</th><th>논문 제목</th><th>저자 및 소속</th><th>핵심 기여</th><th>관련 자료</th></tr></thead><tbody>
<tr><td><strong>ICML 2015</strong></td><td>Optimal and Adaptive Algorithms for Online Boosting</td><td>Alina Beygelzimer, Satyen Kale, Haipeng Luo (Yahoo Labs, Princeton University)</td><td>실시간 데이터 스트림 환경에서 약한 학습기(weak learner)를 결합하여 예측 성능을 높이는 온라인 부스팅 알고리즘의 이론적 최적성과 적응성을 달성.</td><td>21</td></tr>
<tr><td><strong>AAMAS 2015</strong></td><td>The Dependence of Effective Planning Horizon on Model Accuracy</td><td>Nan Jiang, Alex Kulesza, Satinder Singh Baveja, Richard L. Lewis (University of Michigan)</td><td>데이터로부터 학습된 불완전한 모델을 사용할 경우, 의도적으로 계획 horizon을 줄이는 것이 과적합을 방지하고 더 나은 정책을 유도할 수 있음을 이론적으로 규명.</td><td>25</td></tr>
<tr><td><strong>AAMAS 2015 (학생)</strong></td><td>Welfare Effects of Market Making in Continuous Double Auctions</td><td>Elaine Wah, Michael P. Wellman (University of Michigan)</td><td>연속적인 이중 경매 시장에서 마켓 메이커(market maker)의 존재가 시장 참여자들의 전반적인 후생(welfare)에 미치는 긍정적 효과를 시뮬레이션을 통해 분석.</td><td>25</td></tr>
</tbody></table>
<h3>4.2  기술적 유산과 미래 전망</h3>
<p>2015년 2분기에 발표된 연구 성과들은 이후 AI 기술 발전에 지속적인 영향을 미쳤다. GoogLeNet의 인셉션 아키텍처가 제시한 효율성 중심의 설계 철학은, 제한된 연산 자원을 가진 스마트폰이나 임베디드 시스템에서도 강력한 딥러닝 모델을 구동할 수 있는 길을 열었다. 이는 AI 기술의 대중화와 온-디바이스 AI(On-device AI) 시대를 여는 중요한 기술적 이정표가 되었다.</p>
<p>반면, DRC가 남긴 교훈은 로봇 연구의 방향성을 재설정하는 계기가 되었다. 수많은 로봇들이 넘어지고 실패하는 모습은, 통제된 실험실 환경이나 시뮬레이션 상의 성공을 넘어, 현실 세계의 예측 불가능성과 불확실성을 극복하는 것이 로봇 공학의 핵심 과제임을 모든 연구자에게 각인시켰다. 이 경험은 이후 물리 엔진의 정확도를 높인 고품질 시뮬레이터를 개발하고, 시뮬레이션에서 학습한 정책을 현실 로봇으로 원활하게 이전하는 ‘Sim-to-Real’ 연구가 폭발적으로 증가하는 직접적인 원인이 되었다. 또한, 시행착오를 통해 학습하는 강화학습이 로봇 제어의 새로운 해법으로 주목받는 계기를 마련했다.</p>
<p>FAIR 파리 연구소 설립으로 대표되는 기업들의 공격적인 AI 연구 투자는 기술 발전의 생태계를 근본적으로 바꾸어 놓았다. 막대한 데이터, 컴퓨팅 자원, 그리고 자본을 앞세운 기업 연구소들이 기초 과학 연구의 새로운 중심지로 부상했으며, 이는 학계와 산업계 간의 인재 유치 경쟁과 협력 모델에 대한 새로운 논의를 촉발했다.</p>
<h3>4.3  결론: 새로운 질문의 시대</h3>
<p>결론적으로 2015년 2분기는 ’딥러닝으로 무엇이든 할 수 있다’는 폭발적인 낙관론과, ’로봇으로 현실 세계에서 유용한 무언가를 하는 것은 여전히 지극히 어렵다’는 냉정한 현실론이 극적으로 교차하는 시점이었다. 이 시기를 통해 AI 커뮤니티는 “어떻게 더 깊고 정확한 네트워크를 만들 것인가?“라는 기존의 질문을 넘어, “어떻게 그 추상적 지능을 예측 불가능한 물리 세계에 안전하고, 강인하며, 효율적으로 구현할 것인가?“라는 더 근본적이고 어려운 질문과 본격적으로 마주하게 되었다.</p>
<p>이 새로운 질문의 등장이 바로 2015년 2분기가 AI 기술의 역사에 남긴 가장 중요한 유산이라 할 수 있다. 인식의 성공을 행동의 성공으로 연결하려는 이 도전적인 과제는 이후 AI 연구의 핵심 동력이 되었으며, 오늘날 우리가 목도하고 있는 생성형 AI와 물리적 세계의 결합, 즉 ‘Embodied AI’ 시대를 향한 긴 여정의 실질적인 출발점이 되었다.</p>
<h2>5. 참고 자료</h2>
<ol>
<li>Going Deeper with Convolutions - Google Research, https://research.google.com/pubs/pub43022.html?authuser=0&amp;hl=es</li>
<li>[1409.4842] Going Deeper with Convolutions - arXiv, https://arxiv.org/abs/1409.4842</li>
<li>Robot Finishes Third In DARPA Robotics Challenge - News - Carnegie Mellon University, https://www.cmu.edu/news/stories/archives/2015/june/CHIMP-finishes-third.html</li>
<li>IEEE ICRA 2015—Celebrating the Diversity of Robots and Roboticists - UTK-EECS, https://web.eecs.utk.edu/~leparker/publications/RAM-ICRA-2015-report.pdf</li>
<li>ICRA 2015 Workshop Autonomous Industrial Vehicles: From the Laboratory to the Factory Floor Organizers - National Institute of Standards and Technology, https://www.nist.gov/document/icra-2015-workshop-autindvehiclespdf</li>
<li>CVPR 2015 Open Access Repository, https://openaccess.thecvf.com/CVPR2015.py</li>
<li>CVPR 2015 Open Access Repository - The Computer Vision Foundation, https://openaccess.thecvf.com/content_cvpr_2015/html/Chen_On_Learning_Optimized_2015_CVPR_paper.html</li>
<li>AAMAS 2015 Proceedings - IFAAMAS, https://www.ifaamas.org/Proceedings/aamas2015/</li>
<li>Proceedings of the 14th International Conference on Autonomous Agents and Multiagent Systems (AAMAS) - Maastricht University, https://cris.maastrichtuniversity.nl/en/publications/proceedings-of-the-14th-international-conference-on-autonomous-ag</li>
<li>Volume 37: International Conference on Machine Learning, 7-9 July 2015, Lille, France, https://proceedings.mlr.press/v37/</li>
<li>MACHINE LEARNING. INTERNATIONAL CONFERENCE. 32ND 2015. (ICML 2015) (3 VOLS) - proceedings.com, https://www.proceedings.com/27550.html</li>
<li>Going Deeper With Convolutions - UNC Computer Science, https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf</li>
<li>Going Deeper with Contextual CNN for Hyperspectral Image Classification - arXiv, https://arxiv.org/pdf/1604.03519</li>
<li>
<ol start="4">
<li>Unsupervised Hebbian learning — Neurocomputing - Julien Vitay, https://julien-vitay.net/lecturenotes-neurocomputing/4-neurocomputing/5-Hebbian.html</li>
</ol>
</li>
<li>Finalist, http://www.diag.uniroma1.it/deluca/ICRA15_BestPaperAward_Finalist.pdf</li>
<li>https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2018.00065/xml, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2018.00065/xml</li>
<li>Control of generalized contact motion and force in physical human …, https://www.youtube.com/watch?v=NHn2cwSyCCo</li>
<li>The Need for Combining Implicit and Explicit Communication in Cooperative Robotic Systems - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC7805696/</li>
<li>ICRA Awards Finalist – Dieter Fox - University of Washington, https://homes.cs.washington.edu/~fox/finalist-icra-awards/</li>
<li>Depth-Based Tracking with Physical Constraints for Robot …, https://rse-lab.cs.washington.edu/papers/DepthBasedTracking-icra-2015.pdf</li>
<li>ICML 2015 best paper summary: Optimal and adaptive algorithms …, https://www.microsoft.com/en-us/research/blog/icml-2015-best-paper-summary-optimal-and-adaptive-algorithms-for-online-boosting/</li>
<li>Awards | ICML Lille, https://icml.cc/2015/index.html%3Fp=51.html</li>
<li>What Is Boosting? | IBM, https://www.ibm.com/think/topics/boosting</li>
<li>A Family of Online Boosting Algorithms - Vision - University of California San Diego, <a href="https://vision.ucsd.edu/sites/default/files/publications/pdfs/A%20Family%20of%20Online%20Boosting%20Algorithms.pdf">https://vision.ucsd.edu/sites/default/files/publications/pdfs/A%20Family%20of%20Online%20Boosting%20Algorithms.pdf</a></li>
<li>Michigan Researchers Win Both Best Paper Awards at AAMAS 2015, https://cse.engin.umich.edu/stories/michigan-researchers-win-both-best-paper-awards-at-aamas-2015</li>
<li>Satinder Singh’s Papers, https://web.eecs.umich.edu/~baveja/aamaspapers.html</li>
<li>(PDF) The dependence of effective planning horizon on model …, https://www.researchgate.net/publication/283581089_The_dependence_of_effective_planning_horizon_on_model_accuracy</li>
<li>Robots from South Korea, U.S. Win DARPA Finals - DVIDS, https://www.dvidshub.net/news/503827/robots-south-korea-us-win-darpa-finals</li>
<li>DARPA Robotics Challenge - Wikipedia, https://en.wikipedia.org/wiki/DARPA_Robotics_Challenge</li>
<li>CHIMP Robot Gets Ready for DARPA Finals June 5-6 - News - Carnegie Mellon University, https://www.cmu.edu/news/stories/archives/2015/may/darpa-chimp.html</li>
<li>What Happened at the DARPA Robotics Challenge, and Why? - CMU School of Computer Science, https://www.cs.cmu.edu/~cga/drc/jfr-what.pdf</li>
<li>Data, drones, and 3-D-printed hearts | MIT News | Massachusetts Institute of Technology, https://news.mit.edu/2015/top-csail-news-2015</li>
<li>Computer vision | MIT News | Massachusetts Institute of Technology, <a href="https://news.mit.edu/topic/computer-vision?keyword&amp;no_redirect=true&amp;type=1&amp;page=13">https://news.mit.edu/topic/computer-vision?keyword=&amp;no_redirect=true&amp;type=1&amp;page=13</a></li>
<li>Robotics competition generated groundbreaking research | MIT News, https://news.mit.edu/2015/robotics-competition-algorithms-0611</li>
<li>The DARPA Robotics Challenge Was A Bust - Popular Science, https://www.popsci.com/darpa-robotics-challenge-was-bust-why-darpa-needs-try-again/</li>
<li>Facebook expands AI research team to Paris - Engineering at Meta, https://engineering.fb.com/2015/06/02/ml-applications/facebook-expands-ai-research-team-to-paris/</li>
<li>Facebook opens 3rd AI research centre in Paris - Techtrends Zambia, https://www.techtrends.co.zm/facebook-opens-3rd-ai-research-centre-in-paris/</li>
<li>The state of AI in 2015 – Digital Society Blog, https://www.hiig.de/en/the-state-of-ai-in-2015/</li>
<li>After 3 years of Facebook AI Research Paris, Facebook announces the reinforcement of Facebook’s investments in AI in France. - helloneko, https://helloneko.io/3-years-facebook-ai-research-paris-facebook-announces-reinforcement-facebooks-investments-ai-france/</li>
<li>Computer Science and Artificial Intelligence Laboratory (CSAIL) | MIT News | Massachusetts Institute of Technology, https://news.mit.edu/clp/csail?type=1&amp;page=70</li>
<li>Carnegie Mellon’s Six-legged “Snake Monster” Is First of New Breed of Reconfigurable Modular Robots - News, https://www.cmu.edu/news/stories/archives/2015/january/reconfigurable-modular-robots.html</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>