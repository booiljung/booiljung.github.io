<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2015년 1분기 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2015년 1분기 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2015년 AI 및 로봇 연구 동향</a> / <span>2015년 1분기 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2015년 1분기 AI 및 로봇 연구 동향</h1>
<h2>1. 서론</h2>
<p>2015년 1분기는 2013년부터 본격화된 제3차 인공지능(AI) 붐이 새로운 국면으로 접어드는 중요한 시점이었다. 딥러닝이 이미지 인식과 같은 지각(perception) 문제에서 압도적인 성공을 거둔 이후, 연구계는 이 강력한 도구를 의사결정(decision-making) 문제로 확장하려는 시도를 하고 있었다.1 이 시기는 통계적 학습 방법론과 확률적 표현이 AI, 머신러닝, 통계학, 제어 이론 등 다양한 분야에 깊숙이 통합되면서 학문 간 경계가 허물어지고 상호 발전이 가속화되던 때이기도 하다.3</p>
<p>본 보고서는 2015년 1분기가 단순한 점진적 발전의 시기를 넘어, AI 연구의 패러다임을 전환하는 질적 도약의 순간이었음을 주장한다. 이 시기는 기술적 ’합성(synthesis)’과 학문적 ’성찰(self-reflection)’이라는 두 가지 중요한 흐름이 동시에 나타난 변곡점으로 특징지을 수 있다. 기술적 합성의 정점은 심층 신경망과 강화 학습을 성공적으로 결합하여 ’심층 강화 학습(Deep Reinforcement Learning)’이라는 새로운 분야를 개척한 기념비적인 연구의 등장이었다. 이와 동시에, AI 기술의 능력이 기하급수적으로 성장함에 따라 학계 내부에서는 그 사회적 영향, 윤리적 문제, 그리고 실제 세계로의 적용 가능성에 대한 깊은 성찰이 시작되었다. 이러한 성찰은 주요 학회를 중심으로 AI와 로봇 공학, 인간-컴퓨터 상호작용 등 인접 학문과의 적극적인 융합을 모색하고, 기술의 책임감 있는 발전을 논의하는 형태로 나타났다.</p>
<p>따라서 본 보고서는 2015년 1분기에 발표된 세 가지 핵심 이정표—DeepMind의 심층 Q-네트워크(DQN) 논문, 제29회 AAAI 학회(AAAI-15), 그리고 제10회 HRI 학회(HRI 2015)—를 중심으로 당시의 가장 중요한 연구 성과를 심층적으로 분석한다. 이를 통해 기술적 돌파와 학문적 성찰이 어떻게 상호작용하며 이후 AI 연구의 방향을 설정했는지 조망하는 것을 목적으로 한다.</p>
<h2>2.  심층 강화 학습의 새로운 지평: Deep Q-Network (DQN)</h2>
<h3>2.1  기념비적 연구의 발표: “Human-level control through deep reinforcement learning”</h3>
<p>2015년 1분기 AI 연구에서 가장 중요한 사건은 Volodymyr Mnih를 필두로 한 구글 딥마인드(Google DeepMind) 연구팀의 논문이 2015년 2월 26일, 세계적인 과학 저널 <em>Nature</em>에 게재된 것이다.4 이 논문이 컴퓨터 과학 전문 학회가 아닌, 과학계 전반을 아우르는 최고 권위의 저널에 실렸다는 사실은 해당 연구가 가진 파급력과 중요성을 명백히 보여준다.</p>
<p>논문의 핵심 기여는 고차원의 감각 입력(high-dimensional sensory inputs)으로부터 종단간(end-to-end) 강화 학습을 통해 직접 성공적인 제어 정책(policy)을 학습할 수 있는 최초의 인공 에이전트, ’심층 Q-네트워크(Deep Q-Network, DQN)’를 제안한 것이다.4 이전까지의 강화 학습 연구는 체스나 바둑처럼 상태 공간이 명확히 정의되거나, 수작업으로 설계된 저차원의 특징(handcrafted features)을 입력으로 사용하는 제한된 환경에서만 성공을 거두었다.5 DQN은 이러한 한계를 극복하고, 비디오 게임의 원시 픽셀(raw pixels)과 같은 복잡한 시각 정보만을 이용해 인간 전문가 수준의 제어 능력을 학습할 수 있음을 입증함으로써 AI 연구의 새로운 지평을 열었다.</p>
<h3>2.2  핵심 방법론: DQN 아키텍처와 학습 안정화 기법</h3>
<p>DQN의 성공은 단일 기술이 아닌, 심층 신경망의 표현력과 강화 학습의 불안정성을 제어하는 독창적인 기법들의 유기적인 결합에 기인한다.</p>
<h4>2.2.1 합성곱 신경망 (Convolutional Neural Network, CNN) 기반 상태 표현</h4>
<p>DQN은 에이전트가 처한 상황, 즉 상태(state)를 표현하기 위해 합성곱 신경망을 사용한다. 아타리 2600 게임의 <span class="math math-inline">210x160</span> 픽셀 이미지를 <span class="math math-inline">84 \times 84</span> 크기로 변환하고, 최근 4개의 프레임을 겹쳐서 <span class="math math-inline">84 \times  84 \times  4</span> 텐서 형태로 네트워크에 입력한다.4 CNN은 이 고차원 입력으로부터 자동으로 계층적인 시각적 특징(예: 공의 위치, 적의 움직임)을 추출하여, 각 행동(action)에 대한 Q-값(행동 가치)을 예측한다. 이는 기존 방식처럼 연구자가 직접 특징을 설계할 필요성을 제거한 종단간 학습의 핵심 혁신이었다.</p>
<h4>2.2.2 경험 리플레이 (Experience Replay)</h4>
<p>강화 학습을 심층 신경망과 같은 비선형 함수 근사기와 결합할 때, 학습 과정은 매우 불안정해지는 경향이 있다. 이는 에이전트가 순차적으로 경험하는 데이터들이 서로 높은 시간적 상관관계(temporal correlation)를 갖기 때문이다. 이러한 문제를 해결하기 위해 DQN은 ‘경험 리플레이’ 기법을 도입했다.8</p>
<p>경험 리플레이의 작동 방식은 다음과 같다. 에이전트는 매 타임스텝 <span class="math math-inline">t</span>마다 환경과 상호작용한 경험, 즉 <span class="math math-inline">(현재 상태 s_t, 행동 a_t, 보상 r_t, 다음 상태 s_{t+1})</span>의 튜플 <span class="math math-inline">e_t</span>를 ’리플레이 메모리’라는 고정된 크기의 버퍼 <span class="math math-inline">D</span>에 저장한다.10 실제 신경망을 업데이트할 때는 가장 최근의 경험 하나만을 사용하는 대신, 리플레이 메모리 <span class="math math-inline">D</span>에서 미니배치(mini-batch) 크기만큼의 경험들을 무작위로 균등하게 샘플링 <span class="math math-inline">(s, a, r, s&#39;) ~ U(D)</span>하여 사용한다.10 이 무작위 샘플링 과정은 데이터 간의 상관관계를 깨뜨려 마치 독립적이고 동일하게 분포된(i.i.d.) 데이터로 학습하는 것과 유사한 효과를 내며, 과거의 다양한 경험을 재사용함으로써 데이터 효율성을 높이고 학습을 안정화시킨다.11</p>
<h4>2.2.3 타겟 네트워크 (Target Network)</h4>
<p>Q-러닝의 업데이트 목표, 즉 ‘타겟’ 값은 현재 Q-값 추정치에 의존한다. 만약 Q-값을 예측하는 네트워크와 타겟 값을 계산하는 네트워크가 동일하다면, 매 업데이트마다 타겟 값 자체가 변동하는 ’움직이는 타겟 문제(moving target problem)’가 발생한다. 이는 마치 자신의 꼬리를 쫓는 개처럼 학습 목표가 계속해서 움직여 학습이 불안정해지거나 발산하는 원인이 된다.14</p>
<p>DQN은 이 문제를 해결하기 위해 ’타겟 네트워크’라는 별도의 네트워크를 도입했다.8 타겟 네트워크 <span class="math math-inline">Q(s, a; θ-)</span>는 Q-값을 예측하는 주 네트워크(online network) <span class="math math-inline">Q(s, a; θ)</span>와 동일한 구조를 갖지만, 그 가중치 <span class="math math-inline">θ-</span>는 즉시 업데이트되지 않는다. 대신, 일정 주기(예: 수천 번의 업데이트)마다 주 네트워크의 가중치 <span class="math math-inline">θ</span>를 그대로 복사하여 고정된 상태로 유지된다.10 손실 함수를 계산할 때 타겟 Q-값은 이 고정된 타겟 네트워크를 통해 계산되므로, 주 네트워크가 업데이트되는 동안 학습 목표가 안정적으로 유지되어 전체 학습 과정의 수렴성을 크게 향상시킨다.15</p>
<table><thead><tr><th>구성 요소 (Component)</th><th>목적 (Purpose)</th><th>작동 방식 (Mechanism)</th></tr></thead><tbody>
<tr><td>합성곱 신경망 (CNN)</td><td>고차원 시각 입력(픽셀)으로부터 특징을 자동으로 추출하여 상태(state)를 표현한다.</td><td>여러 개의 합성곱 및 완전 연결 계층을 통해 이미지로부터 Q-값을 예측하는 함수를 근사한다.</td></tr>
<tr><td>경험 리플레이 (Experience Replay)</td><td>학습 데이터의 시간적 상관관계를 제거하고 데이터 효율성을 높여 학습을 안정화한다.</td><td><span class="math math-inline">(상태, 행동, 보상, 다음 상태)</span> 튜플을 버퍼에 저장하고, 학습 시 무작위 미니배치를 샘플링하여 사용한다.</td></tr>
<tr><td>타겟 네트워크 (Target Network)</td><td>Q-러닝 타겟 값의 변동성을 줄여 ’움직이는 타겟 문제’를 해결하고 학습을 안정화한다.</td><td>주 네트워크와 동일한 구조를 가지며, 주기적으로 주 네트워크의 가중치를 복사하여 타겟 Q-값 계산에 사용된다.</td></tr>
</tbody></table>
<h3>2.3  수학적 원리: 손실 함수와 최적화</h3>
<p>DQN의 학습 목표는 최적 행동-가치 함수인 <span class="math math-inline">Q^*(s, a)</span> 를 신경망으로 근사하는 것이다. <span class="math math-inline">Q^*(s, a)</span> 는 상태 <span class="math math-inline">s</span> 에서 행동 <span class="math math-inline">a</span> 를 취한 후, 최적 정책을 따랐을 때 얻게 될 미래 보상의 총합(기댓값)을 의미하며, 이는 벨만 최적 방정식(Bellman optimality equation)을 만족한다.</p>
<p><span class="math math-display">
Q^{*}(s, a) = \mathbb{E}_{s&#39; \sim \mathcal{E}} \left[ r + \gamma \max_{a&#39;} Q^{*}(s&#39;, a&#39;) \vert s, a \right]
</span></p>
<p>DQN은 이 방정식을 기반으로 반복적인 업데이트를 통해 Q 함수를 학습한다. i 번째 반복에서의 손실 함수 <span class="math math-inline">L_i(\theta_i)</span> 는 타겟 네트워크( <span class="math math-inline">\theta_i^−</span>​ )가 계산한 타겟 값과 주 네트워크( <span class="math math-inline">\theta_i</span>​ )가 예측한 Q-값 사이의 평균 제곱 오차(Mean Squared Error, MSE)로 정의된다.20</p>
<p><span class="math math-display">
L_i(\theta_i) = \mathbb{E}_{(s, a, r, s&#39;) \sim U(D)} \left[ \left( y_i - Q(s, a; \theta_i) \right)^2 \right]
</span></p>
<p>여기서 타겟 <span class="math math-inline">y_i</span>​ 는 경험 리플레이 버퍼에서 샘플링된 튜플 (s,a,r,s′) 에 대해 다음과 같이 계산된다.</p>
<p><span class="math math-display">
y_i = r + \gamma \max_{a&#39;} \hat{Q}(s&#39;, a&#39;; \theta_i^-)
</span></p>
<p>이 손실 함수를 최소화하기 위해, 손실 함수의 그래디언트 <span class="math math-inline">\Delta \theta_i L_i(\theta_i)</span> 를 계산하고 확률적 경사 하강법(Stochastic Gradient Descent, SGD)과 같은 최적화 알고리즘을 사용하여 주 네트워크의 가중치 <span class="math math-inline">\theta_i</span> 를 업데이트한다. 일부 구현에서는 Q-값 추정치가 매우 노이즈가 많을 때를 대비하여, 오차가 클 때 MSE보다 이상치(outlier)에 덜 민감한 Huber 손실을 사용하기도 한다.22</p>
<h3>2.4  실험 결과 및 파급 효과</h3>
<p>딥마인드 연구팀은 제안된 DQN 에이전트를 49개의 고전 아타리 2600 게임 도메인에 적용하여 그 성능을 평가했다. 놀랍게도, 단일 아키텍처와 하이퍼파라미터를 사용한 DQN 에이전트는 별도의 게임별 사전 지식 없이 오직 원시 픽셀과 점수만을 입력받아, 49개 게임 중 29개에서 전문 인간 게임 테스터를 능가하는 성능을 보였다.5 이는 기존의 모든 강화 학습 및 AI 알고리즘을 압도하는 결과였다.</p>
<p>이 연구는 복잡하고 고차원적인 환경에서 범용적인 학습이 가능한 AI 에이전트의 잠재력을 최초로 실증적으로 입증했다는 점에서 엄청난 파급 효과를 낳았다. DQN의 성공은 강화 학습 분야에 딥러닝을 접목하는 ‘심층 강화 학습’ 연구의 폭발적인 성장을 촉발했으며, 이후 알파고(AlphaGo)를 비롯한 수많은 후속 연구들의 이론적, 기술적 토대가 되었다. 이는 지각 문제를 넘어 복잡한 순차적 의사결정 문제 해결에 대한 AI 커뮤니티의 자신감을 고취시킨 결정적인 이정표였다.</p>
<h2>3.  제29회 AAAI 인공지능 학회(AAAI-15) 주요 연구 동향</h2>
<h3>3.1  학회 개요: AI 연구의 확장과 통합</h3>
<p>2015년 1월 25일부터 30일까지 미국 텍사스주 오스틴에서 개최된 제29회 AAAI 인공지능 학회(AAAI-15)는 AI 분야의 양적 성장과 질적 확장을 동시에 보여준 중요한 행사였다.24 이 학회에는 총 1,991편이라는 역대 최대 규모의 논문이 제출되었으며, 그중 539편이 엄격한 심사를 거쳐 채택되었다.25 이는 이전 기록을 40%나 상회하는 수치로, AI 연구에 대한 전 세계적인 관심이 폭발적으로 증가하고 있음을 시사한다.</p>
<p>AAAI-15의 특징은 특정 하위 분야에 국한되지 않고, AI의 근본적인 주제들을 포괄하는 광범위한 기술 트랙을 운영했다는 점이다.24 머신러닝, 자연어 처리, 컴퓨터 비전과 같은 데이터 기반 분야뿐만 아니라, 휴리스틱 탐색, 지식 표현, 게임 이론, 다중에이전트 시스템 등 전통적인 AI 분야의 연구도 활발하게 논의되었다.26 이러한 구조는 AAAI가 단순히 최신 연구를 발표하는 장을 넘어, AI의 다양한 하위 분야들이 서로 교류하고 융합하는 ’인큐베이터이자 통합자’로서의 역할을 수행하고 있었음을 보여준다. 학회 조직위원회가 의도적으로 로보틱스 프로그램을 확장하고, 다른 최고 학회의 동향을 요약하는 세션을 마련한 것은 이러한 통합적 기능을 강화하려는 명백한 시도였다. 이는 전문화된 개별 학회들과는 차별화되는 AAAI만의 정체성을 보여주는 부분이다.</p>
<h3>3.2  머신러닝 및 탐색/최적화 (Machine Learning &amp; Search/Optimization)</h3>
<p>AAAI-15에서는 알고리즘의 성능과 효율성을 극한으로 끌어올리려는 연구들이 두드러졌다. ‘휴리스틱 탐색 및 최적화’ 트랙에서는 ’메타 학습을 통한 베이지안 하이퍼파라미터 최적화 초기화(Initializing Bayesian Hyperparameter Optimization via Meta-Learning)’와 같은 연구가 발표되었다.26 이는 머신러닝 모델의 성능을 좌우하는 하이퍼파라미터 튜닝 과정을 자동화하고, 과거의 경험(메타 데이터)을 활용하여 최적화 과정을 가속화하려는 시도였다. 또한, ‘GPU에서의 대규모 병렬 A* 탐색(Massively Parallel A* Search on a GPU)’ 연구는 GPU의 병렬 처리 능력을 고전적인 탐색 알고리즘에 접목하여 대규모 문제 해결 능력을 획기적으로 향상시킬 수 있는 가능성을 보여주었다.26 이러한 연구들은 AI 알고리즘의 실용성을 높이기 위한 자동화 및 하드웨어 가속화가 당시의 중요한 연구 흐름이었음을 나타낸다.</p>
<h3>3.3  자연어 처리 및 웹 인텔리전스 (NLP &amp; Web Intelligence)</h3>
<p>‘AI와 웹’ 트랙에서는 소셜 미디어, 추천 시스템, 온라인 콘텐츠 분석 등 방대한 웹 데이터를 활용하는 연구가 주를 이루었다. 특히 딥러닝 기술을 응용한 연구들이 주목받았다. 예를 들어, ‘점진적으로 훈련되고 도메인 전이된 딥 네트워크를 이용한 강건한 이미지 감성 분석(Robust Image Sentiment Analysis Using Progressively Trained and Domain Transferred Deep Networks)’ 논문은 텍스트를 넘어 이미지 콘텐츠에 담긴 감성을 분석하는 데 딥러닝을 활용했다.26 또한, ’사용자 신뢰와 아이템 평점의 명시적/암묵적 영향을 모두 활용한 협업 필터링(TrustSVD: Collaborative Filtering with Both the Explicit and Implicit Influence of User Trust and of Item Ratings)’과 같은 연구는 추천 시스템의 정확도를 높이기 위해 사용자 간의 신뢰 관계라는 사회적 맥락을 모델에 통합하는 새로운 접근법을 제시했다.26 이러한 연구들은 텍스트, 이미지, 사용자 행동 등 이종 데이터를 융합하고, 사회적 관계망을 분석에 활용하여 더 깊은 통찰을 얻으려는 시도가 활발했음을 보여준다.</p>
<h3>3.4  로보틱스 프로그램의 확장과 AI-로보틱스 융합</h3>
<p>AAAI-15는 AI와 로보틱스라는 상호 보완적인 두 커뮤니티 간의 교류를 촉진하기 위해 로보틱스 프로그램을 대대적으로 강화했다.25 미국 국립과학재단(NSF) 등의 지원을 받아 로봇 공학의 선구적인 프로젝트인 ’Shakey’의 50주년 기념 행사, 로보컵(RoboCup) 축구 시연, 로보틱스 전시회 등 다양한 부대 행사를 마련했다.25</p>
<p>학술적으로도 로보틱스는 주요 기술 트랙 중 하나로 격상되었다. 특히, AAAI-15에서 발표된 일부 논문들은 이후 세계 최고 로봇 학회인 ICRA 2015에서 다시 발표되는 등, 두 분야 간의 활발한 학술적 교류를 증명했다.27 예를 들어, ’불충분한 통계량을 이용한 예측 상태 표현의 스펙트럼 학습(Spectral Learning of Predictive State Representations with Insufficient Statistics)’이나 ’압축과 제어(Compress and Control)’와 같은 논문들은 강화 학습과 표현 학습 등 AI의 핵심 이론이 로봇의 상태 추정 및 제어 문제에 직접적으로 적용될 수 있음을 보여주었다.27 이는 AI의 추상적인 알고리즘이 물리 세계와 상호작용하는 로봇에 구현되는 구체적인 사례로서, 두 분야의 융합이 본격화되고 있음을 시사한다.</p>
<h3>3.5  컴퓨터 비전 및 인지 시스템 (Computer Vision &amp; Cognitive Systems)</h3>
<p>AAAI-15의 기술 트랙 목록에 ’컴퓨터 비전’이 독립적으로 명시되지는 않았지만, 학회 프로그램 내에 ‘컴퓨터 비전 및 패턴 인식의 최신 동향(What’s Hot in Computer Vision and Pattern Recognition)’ 세션이 별도로 편성되었다는 점은 주목할 만하다.28 이는 AAAI가 CVPR과 같은 최고 수준의 컴퓨터 비전 전문 학회의 연구 성과를 적극적으로 수용하고, 이를 더 넓은 AI 커뮤니티와 공유하며 논의하는 플랫폼 역할을 했음을 의미한다. 비전 기술은 독립적인 연구 주제일 뿐만 아니라, 다른 AI 분야의 문제를 해결하는 핵심 도구로 인식되고 있었다. 앞서 언급된 ‘AI와 웹’ 트랙의 이미지 감성 분석 연구 26나, ‘인지 시스템’ 트랙에서 시각 정보와 의미론적 지식을 결합하여 추론하는 연구 26 등은 비전 기술이 자연어 처리, 지식 표현 등 다른 AI 분야와 융합되어 새로운 응용 가능성을 창출하는 양상을 명확히 보여준다.</p>
<table><thead><tr><th>기술 트랙 (Technical Track)</th><th>대표 연구 주제 (Representative Research Topics)</th><th>예시 논문 제목 (Example Paper Title)</th></tr></thead><tbody>
<tr><td>머신러닝 / 탐색</td><td>메타러닝, 하이퍼파라미터 최적화, GPU 기반 병렬 탐색</td><td>Initializing Bayesian Hyperparameter Optimization via Meta-Learning 26</td></tr>
<tr><td>자연어 처리 / AI와 웹</td><td>소셜 미디어 감성 분석, 토픽 모델링, 협업 필터링, 추천 시스템</td><td>TrustSVD: Collaborative Filtering with Both the Explicit and Implicit Influence… 26</td></tr>
<tr><td>로보틱스</td><td>예측 상태 표현 학습(PSRs), 심층 표현 학습, 압축 기반 제어</td><td>Spectral Learning of Predictive State Representations with Insufficient Statistics 27</td></tr>
<tr><td>게임 이론 / 경제학</td><td>조합 경매, 스태켈버그 게임, 안정 매칭 문제</td><td>A Faster Core Constraint Generation Algorithm for Combinatorial Auctions 26</td></tr>
</tbody></table>
<h2>4.  인간과 로봇의 상호작용 심화: HRI 2015</h2>
<h3>4.1  학회 개요 및 주제: HRI의 외연 확장</h3>
<p>2015년 3월에 개최된 제10회 ACM/IEEE 국제 인간-로봇 상호작용 학회(HRI 2015)는 해당 분야가 중요한 성숙 단계에 접어들었음을 알리는 이정표였다.29 학회의 주제가 “HRI의 확장: 기술, 디자인, 방법론, 지식의 활성화(Broadening HRI: Enabling Technologies, Designs, Methods, and Knowledge)“로 설정된 것은 HRI 연구의 초점이 단순히 기술적 ’가능성’을 증명하는 것을 넘어, 실제 세계에서의 ’실용성’을 확보하는 문제로 이동하고 있음을 명확히 보여준다.29 이는 로봇의 기술적 구현을 넘어, 인간과 효과적으로 상호작용하기 위한 디자인 가이드라인, 신뢰할 수 있는 평가 방법론, 그리고 인간 행동에 대한 이론적 지식 등 다학제적 관점의 중요성을 강조하는 것이었다.</p>
<p>이러한 변화는 HRI 커뮤니티가 초기 탐색 단계를 지나, 장기적이고 예측 불가능한 실제 환경에서의 상호작용 문제를 본격적으로 다루기 시작했음을 의미한다. 수상 논문들이 협업의 미묘함, 도덕적 딜레마, 사용자의 예상치 못한 행동과 같은 복잡한 주제를 다루고, 동시에 학계 내에서 연구 방법론의 엄밀성에 대한 자성의 목소리가 높아진 것은 HRI가 통제된 실험실을 넘어 사회 속으로 나아가기 위한 준비를 하고 있었음을 보여주는 증거이다.</p>
<h3>4.2  주요 수상 논문 심층 분석: 협업, 윤리, 그리고 사회적 과제</h3>
<p>HRI 2015의 수상 논문들은 당시 연구계가 주목하던 핵심 과제들을 명확하게 보여준다.</p>
<p>**최우수 기술상(Best Enabling Technology Award)**을 수상한 “인간-로봇 협업 과업을 위한 공동 행동 시연으로부터의 효율적인 모델 학습(Efficient Model Learning from Joint-Action Demonstrations for Human-Robot Collaborative Tasks)“은 인간과 로봇의 유연한 협업을 위한 새로운 학습 패러다임을 제시했다.29 이 연구의 핵심은 인간 전문가 팀이 협업하는 모습을 녹화한 ’시연 데이터’로부터 로봇이 스스로 인간의 협업 스타일을 학습하게 하는 것이다. 구체적으로, 비지도 학습(unsupervised learning)을 통해 시연된 행동 시퀀스를 몇 가지 대표적인 ’인간 유형(human types)’으로 군집화하고, 각 유형에 대해 역강화학습(Inverse Reinforcement Learning)을 적용하여 그들이 암묵적으로 따르는 보상 함수(reward function)를 추론한다. 이 학습된 모델들은 혼합 관찰 가능성 마르코프 결정 과정(Mixed-Observability Markov Decision Process, MOMDP) 프레임워크에 통합되어, 로봇이 새로운 파트너를 만났을 때 그의 유형을 실시간으로 추론하고 그에 맞는 최적의 협업 정책을 수행할 수 있게 한다.32</p>
<p>**최우수 지식상(Best Enabling Knowledge Award)**을 받은 “다수를 위해 하나를 희생할 것인가?: 인간과 로봇 에이전트에 각기 다른 도덕 규범을 적용하는 사람들(Sacrifice One For the Good of Many?: People Apply Different Moral Norms to Human and Robot Agents)“은 ‘기계 윤리(Machine Ethics)’ 분야의 중요한 질문을 던졌다.29 이 연구는 트롤리 딜레마와 같은 상황에서 사람들이 인간의 결정과 로봇의 결정에 대해 서로 다른 도덕적 잣대를 적용한다는 사실을 실험적으로 밝혔다. 이는 자율주행차와 같은 AI 시스템이 피할 수 없는 사고 상황에서 윤리적 결정을 내려야 할 때, 사회가 그 결정을 어떻게 수용할 것인지에 대한 근본적인 논의를 촉발시켰다.</p>
<p>**최우수 현장 연구상(Best Enabling Field Study Award)**을 수상한 “아동의 사회적 로봇 학대로부터 벗어나기(Escaping from Children’s Abuse of Social Robots)“는 HRI 연구가 실제 환경에서 직면하는 예측 불가능한 사회적 과제를 다루었다.29 연구팀은 쇼핑몰에 로봇을 배치하고 아동들이 로봇을 둘러싸고 길을 막거나 물리적으로 괴롭히는 현상을 관찰했다. 이는 로봇이 장기간 공공장소에서 운용될 때 발생할 수 있는 사회적 상호작용의 어두운 단면을 보여주며, 로봇의 내구성과 안전뿐만 아니라 사회적 규범을 이해하고 대응하는 능력의 중요성을 부각시켰다.</p>
<table><thead><tr><th>수상 부문 (Award Category)</th><th>논문 제목 (Paper Title)</th><th>저자 (Authors)</th><th>핵심 기여 (Core Contribution)</th></tr></thead><tbody>
<tr><td>최우수 기술상 (Best Enabling Technology)</td><td>Efficient Model Learning from Joint-Action Demonstrations for Human-Robot Collaborative Tasks</td><td>S. Nikolaidis, R. Ramakrishnan, K. Gu, J. Shah</td><td>비지도 학습과 역강화학습을 결합하여 인간의 협업 유형을 시연으로부터 학습하는 프레임워크 제시.</td></tr>
<tr><td>최우수 지식상 (Best Enabling Knowledge)</td><td>Sacrifice One For the Good of Many?: People Apply Different Moral Norms to Human and Robot Agents</td><td>B. Malle, M. Scheutz, J. Voiklis, et al.</td><td>사람들이 로봇과 인간에게 다른 도덕적 기준을 적용함을 실험적으로 입증하여 기계 윤리 연구에 기여.</td></tr>
<tr><td>최우수 디자인상 (Best Enabling Design)</td><td>Design and Evaluation of a Peripheral Robotic Conversation Companion</td><td>G. Hoffman, O. Zuckerman, et al.</td><td>주변 환경에 녹아들어 대화를 보조하는 로봇 동반자의 디자인 및 평가.</td></tr>
<tr><td>최우수 현장 연구상 (Best Enabling Field Study)</td><td>Escaping from Children’s Abuse of Social Robots</td><td>D. Brscic, H. Kidokoro, et al.</td><td>실제 환경(쇼핑몰)에서 아동들이 로봇을 괴롭히는 현상을 관찰하고 로봇의 회피 행동을 연구.</td></tr>
</tbody></table>
<h3>4.3  핵심 연구 주제와 방법론적 성찰</h3>
<p>HRI 2015에서 발표된 논문들은 협업 로봇, 사회적/반려 로봇, 원격 현존 로봇(telepresence robots), 보조 로봇 등 다양한 플랫폼을 포괄했다.29 공통적으로 인간의 의도 인식, 신뢰 구축, 장기 상호작용, 그리고 인간과 로봇 간의 안전성 확보와 같은 주제들이 핵심적으로 다루어졌다.</p>
<p>이와 동시에, HRI 커뮤니티 내부에서는 연구 방법론의 과학적 엄밀성을 높여야 한다는 자성의 목소리가 커지고 있었다. 심리학 등 인접 분야에서 제기된 ’재현성 위기(Replicability Crisis)’에 대한 우려가 HRI 분야에도 영향을 미치기 시작했다.34 이에 따라 연구 결과를 다른 연구자들이 검증하고 재현할 수 있도록 실험 절차, 참가자 정보, 사용된 로봇 플랫폼 등을 상세히 기술하는 표준화된 보고 형식의 필요성이 제기되었다.35 또한, 대다수 연구가 서구의 고학력 산업 사회 출신(Western, Educated, Industrialized, Rich, and Democratic, WEIRD) 참가자에 편중되어 있다는 샘플링 편향 문제가 지적되며, 연구 결과의 일반화 가능성에 대한 비판적 고찰이 이루어졌다.36 이러한 방법론적 성찰은 HRI가 일회성 발견을 넘어 신뢰할 수 있는 과학적 지식을 축적하려는 성숙한 학문 분야로 나아가고 있음을 보여주는 중요한 신호였다.</p>
<h2>5.  기타 주요 학술지 발표 연구</h2>
<p>2015년 1분기에는 주요 학회 외에도 권위 있는 학술지들을 통해 AI 분야의 중요한 연구 성과들이 발표되었다. 이들은 심층 강화 학습과 같은 신흥 분야뿐만 아니라, 탐색 및 추론과 같은 고전적 AI 분야에서도 혁신이 계속되고 있음을 보여준다.</p>
<h3>5.1  다중 에이전트 경로 탐색의 진일보: Conflict-Based Search (CBS)</h3>
<p><em>Artificial Intelligence</em> 저널 2015년 1월호에는 Guni Sharon 등이 발표한 “Conflict-based search for optimal multi-agent pathfinding” 논문이 게재되었다.37 이 연구는 다수의 에이전트가 충돌 없이 각자의 목적지까지 최적의 경로를 찾는 다중 에이전트 경로 탐색(Multi-Agent Pathfinding, MAPF) 문제에 대한 혁신적인 해법인 ‘충돌 기반 탐색(Conflict-Based Search, CBS)’ 알고리즘을 제안했다.</p>
<p>CBS 알고리즘의 핵심은 문제를 두 단계의 계층적 탐색으로 분해하는 데 있다. 하위 레벨(low-level) 탐색에서는 다른 에이전트를 장애물로 간주하고 각 에이전트의 개별적인 최단 경로를 독립적으로 찾는다. 만약 이 경로들 사이에 충돌(conflict)이 발생하면, 상위 레벨(high-level) 탐색이 개입한다. 상위 레벨 탐색은 충돌을 하나의 노드로 표현하는 ’제약 트리(constraint tree)’를 구축하고, 충돌을 회피하기 위한 새로운 제약조건(예: 특정 시간에 특정 위치를 점유하지 말 것)을 추가하여 하위 레벨 탐색을 다시 호출한다. 이 과정은 모든 에이전트의 경로가 충돌 없이 최적임이 보장될 때까지 반복된다. 이 접근법은 모든 에이전트의 움직임을 동시에 고려하는 기존의 결합된 A* 탐색 방식에 비해 탐색해야 할 상태 공간을 극적으로 줄이면서도, 해의 최적성을 보장하는 효율성을 달성했다.37 이 연구는 데이터 기반의 학습 접근법이 주류를 이루는 가운데에서도, 탐색과 추론에 기반한 고전적 AI 분야의 알고리즘적 혁신이 여전히 강력한 영향력을 가지고 있음을 보여주는 중요한 사례이다.</p>
<h3>5.2  1분기 주요 저널 동향 및 주제</h3>
<p>이 시기 AI 관련 주요 저널들은 기술적 진보와 더불어 AI의 사회적, 윤리적 함의에 대한 논의를 심도 있게 다루기 시작했다. <em>AI Magazine</em> 2015년 겨울호에 실린 “강건하고 유익한 인공지능을 위한 연구 우선순위(Research Priorities for Robust and Beneficial Artificial Intelligence)” 아티클이 대표적이다.3 이 글은 AI의 경제적 영향 분석, 자율 시스템에 대한 법적 책임 및 기계 윤리 문제, 그리고 AI 시스템의 안전성과 예측 가능성을 보장하기 위한 컴퓨터 과학 연구 등 단기 및 장기적 연구 의제를 포괄적으로 제시하며, 학계가 기술 개발과 함께 사회적 책임을 고민해야 함을 촉구했다.</p>
<p>응용 분야에서는 AI 기술의 확산이 두드러졌다. <em>International Journal of Artificial Intelligence &amp; Applications</em> 2015년 1월호는 사이버 범죄 탐지 및 예방을 위한 AI 기술 적용에 대한 서베이 논문을 게재하여, AI가 보안이라는 새로운 실용적 문제 해결에 기여하고 있음을 보여주었다.38 학문적으로는 <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, <em>Journal of Machine Learning Research (JMLR)</em>, <em>Artificial Intelligence</em>, 그리고 <em>IEEE Transactions on Robotics</em> 와 같은 저널들이 각 분야에서 가장 영향력 있는 Q1 등급의 저널로 확고히 자리 잡고 있었다.39</p>
<h2>6. 결론</h2>
<p>2015년 1분기는 인공지능 연구 역사에서 중요한 변곡점으로 기록된다. 이 시기는 심층 강화 학습이라는 새로운 패러다임의 탄생, AI의 다양한 하위 분야 간의 활발한 융합, 그리고 기술의 사회적·윤리적 함의에 대한 깊은 성찰이 동시에 폭발적으로 이루어진 결정적인 순간이었다. 본 보고서에서 분석한 주요 성과들은 이후 AI 기술 발전의 방향을 설정하는 데 지대한 영향을 미쳤다.</p>
<p>이 시기의 핵심 트렌드는 다음과 같이 요약할 수 있다.</p>
<ol>
<li>
<p><strong>종단간(End-to-End) 학습 패러다임의 확립:</strong> 딥마인드의 DQN 연구는 고차원의 원시 데이터(raw data)로부터 복잡한 의사결정 정책을 직접 학습하는 종단간 학습의 위력을 입증했다. 이는 특징 공학에 의존하던 기존의 한계를 극복하고, 이후 수많은 강화 학습 문제에 딥러닝을 적용하는 길을 열었다.</p>
</li>
<li>
<p><strong>AI 분야의 통합과 확장:</strong> AAAI-15는 AI와 로보틱스, AI와 웹, 머신러닝과 탐색 등 인접 분야 간의 경계를 허물고 적극적인 융합을 모색하는 플랫폼 역할을 수행했다. 이는 개별 기술의 발전을 넘어, 기술 간의 시너지를 통해 더 복잡하고 실용적인 문제를 해결하려는 연구계의 노력을 반영한다.</p>
</li>
<li>
<p><strong>인간 중심 AI(Human-Centric AI)의 부상:</strong> HRI 2015는 기술적 성능 지표를 넘어 인간과의 유연한 협업, 신뢰 형성, 윤리적 상호작용, 그리고 사회적 수용성과 같은 인간 중심적 가치를 연구의 핵심 의제로 부상시켰다. 이는 AI가 실험실을 나와 인간의 일상과 사회 속으로 들어오기 위해 반드시 해결해야 할 과제들에 대한 논의가 본격화되었음을 의미한다.</p>
</li>
</ol>
<p>결론적으로, 2015년 1분기에 제시된 아이디어와 방법론들은 이후 수년간 AI 기술 발전의 청사진이 되었다. DQN이 촉발한 심층 강화 학습 연구의 물결은 알파고의 승리로 이어지며 AI의 가능성을 전 세계에 각인시켰다. 또한, AAAI와 HRI에서 시작된 융합 연구와 윤리적 성찰은 현재 AI 거버넌스, 설명 가능한 AI(XAI), 그리고 책임감 있는 AI(Responsible AI) 연구의 중요한 초석이 되었다. 따라서 2015년 1분기는 현대 AI 시대를 연 기술적, 철학적 토대가 마련된 시기였다고 평가할 수 있다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Going Deeper with Convolutions - Google Research, https://research.google.com/pubs/pub43022.html?authuser=0&amp;hl=es</li>
<li>[1409.4842] Going Deeper with Convolutions - arXiv, https://arxiv.org/abs/1409.4842</li>
<li>Robot Finishes Third In DARPA Robotics Challenge - News - Carnegie Mellon University, https://www.cmu.edu/news/stories/archives/2015/june/CHIMP-finishes-third.html</li>
<li>IEEE ICRA 2015—Celebrating the Diversity of Robots and Roboticists - UTK-EECS, https://web.eecs.utk.edu/~leparker/publications/RAM-ICRA-2015-report.pdf</li>
<li>ICRA 2015 Workshop Autonomous Industrial Vehicles: From the Laboratory to the Factory Floor Organizers - National Institute of Standards and Technology, https://www.nist.gov/document/icra-2015-workshop-autindvehiclespdf</li>
<li>CVPR 2015 Open Access Repository, https://openaccess.thecvf.com/CVPR2015.py</li>
<li>CVPR 2015 Open Access Repository - The Computer Vision Foundation, https://openaccess.thecvf.com/content_cvpr_2015/html/Chen_On_Learning_Optimized_2015_CVPR_paper.html</li>
<li>AAMAS 2015 Proceedings - IFAAMAS, https://www.ifaamas.org/Proceedings/aamas2015/</li>
<li>Proceedings of the 14th International Conference on Autonomous Agents and Multiagent Systems (AAMAS) - Maastricht University, https://cris.maastrichtuniversity.nl/en/publications/proceedings-of-the-14th-international-conference-on-autonomous-ag</li>
<li>Volume 37: International Conference on Machine Learning, 7-9 July 2015, Lille, France, https://proceedings.mlr.press/v37/</li>
<li>MACHINE LEARNING. INTERNATIONAL CONFERENCE. 32ND 2015. (ICML 2015) (3 VOLS) - proceedings.com, https://www.proceedings.com/27550.html</li>
<li>Going Deeper With Convolutions - UNC Computer Science, https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf</li>
<li>Going Deeper with Contextual CNN for Hyperspectral Image Classification - arXiv, https://arxiv.org/pdf/1604.03519</li>
<li>
<ol start="4">
<li>Unsupervised Hebbian learning — Neurocomputing - Julien Vitay, https://julien-vitay.net/lecturenotes-neurocomputing/4-neurocomputing/5-Hebbian.html</li>
</ol>
</li>
<li>Finalist, http://www.diag.uniroma1.it/deluca/ICRA15_BestPaperAward_Finalist.pdf</li>
<li>https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2018.00065/xml, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2018.00065/xml</li>
<li>Control of generalized contact motion and force in physical human …, https://www.youtube.com/watch?v=NHn2cwSyCCo</li>
<li>The Need for Combining Implicit and Explicit Communication in Cooperative Robotic Systems - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC7805696/</li>
<li>ICRA Awards Finalist – Dieter Fox - University of Washington, https://homes.cs.washington.edu/~fox/finalist-icra-awards/</li>
<li>Depth-Based Tracking with Physical Constraints for Robot …, https://rse-lab.cs.washington.edu/papers/DepthBasedTracking-icra-2015.pdf</li>
<li>ICML 2015 best paper summary: Optimal and adaptive algorithms …, https://www.microsoft.com/en-us/research/blog/icml-2015-best-paper-summary-optimal-and-adaptive-algorithms-for-online-boosting/</li>
<li>Awards | ICML Lille, https://icml.cc/2015/index.html%3Fp=51.html</li>
<li>What Is Boosting? | IBM, https://www.ibm.com/think/topics/boosting</li>
<li>A Family of Online Boosting Algorithms - Vision - University of California San Diego, <a href="https://vision.ucsd.edu/sites/default/files/publications/pdfs/A%20Family%20of%20Online%20Boosting%20Algorithms.pdf">https://vision.ucsd.edu/sites/default/files/publications/pdfs/A%20Family%20of%20Online%20Boosting%20Algorithms.pdf</a></li>
<li>Michigan Researchers Win Both Best Paper Awards at AAMAS 2015, https://cse.engin.umich.edu/stories/michigan-researchers-win-both-best-paper-awards-at-aamas-2015</li>
<li>Satinder Singh’s Papers, https://web.eecs.umich.edu/~baveja/aamaspapers.html</li>
<li>(PDF) The dependence of effective planning horizon on model …, https://www.researchgate.net/publication/283581089_The_dependence_of_effective_planning_horizon_on_model_accuracy</li>
<li>Robots from South Korea, U.S. Win DARPA Finals - DVIDS, https://www.dvidshub.net/news/503827/robots-south-korea-us-win-darpa-finals</li>
<li>DARPA Robotics Challenge - Wikipedia, https://en.wikipedia.org/wiki/DARPA_Robotics_Challenge</li>
<li>CHIMP Robot Gets Ready for DARPA Finals June 5-6 - News - Carnegie Mellon University, https://www.cmu.edu/news/stories/archives/2015/may/darpa-chimp.html</li>
<li>What Happened at the DARPA Robotics Challenge, and Why? - CMU School of Computer Science, https://www.cs.cmu.edu/~cga/drc/jfr-what.pdf</li>
<li>Data, drones, and 3-D-printed hearts | MIT News | Massachusetts Institute of Technology, https://news.mit.edu/2015/top-csail-news-2015</li>
<li>Computer vision | MIT News | Massachusetts Institute of Technology, <a href="https://news.mit.edu/topic/computer-vision?keyword&amp;no_redirect=true&amp;type=1&amp;page=13">https://news.mit.edu/topic/computer-vision?keyword=&amp;no_redirect=true&amp;type=1&amp;page=13</a></li>
<li>Robotics competition generated groundbreaking research | MIT News, https://news.mit.edu/2015/robotics-competition-algorithms-0611</li>
<li>The DARPA Robotics Challenge Was A Bust - Popular Science, https://www.popsci.com/darpa-robotics-challenge-was-bust-why-darpa-needs-try-again/</li>
<li>Facebook expands AI research team to Paris - Engineering at Meta, https://engineering.fb.com/2015/06/02/ml-applications/facebook-expands-ai-research-team-to-paris/</li>
<li>Facebook opens 3rd AI research centre in Paris - Techtrends Zambia, https://www.techtrends.co.zm/facebook-opens-3rd-ai-research-centre-in-paris/</li>
<li>The state of AI in 2015 – Digital Society Blog, https://www.hiig.de/en/the-state-of-ai-in-2015/</li>
<li>After 3 years of Facebook AI Research Paris, Facebook announces the reinforcement of Facebook’s investments in AI in France. - helloneko, https://helloneko.io/3-years-facebook-ai-research-paris-facebook-announces-reinforcement-facebooks-investments-ai-france/</li>
<li>Computer Science and Artificial Intelligence Laboratory (CSAIL) | MIT News | Massachusetts Institute of Technology, https://news.mit.edu/clp/csail?type=1&amp;page=70</li>
<li>Carnegie Mellon’s Six-legged “Snake Monster” Is First of New Breed of Reconfigurable Modular Robots - News, https://www.cmu.edu/news/stories/archives/2015/january/reconfigurable-modular-robots.html</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>