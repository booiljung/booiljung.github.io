<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2023년 9월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2023년 9월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2023년 AI 및 로봇 연구 동향</a> / <span>2023년 9월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2023년 9월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2023년 9월, AI와 로보틱스 연구의 변곡점 - 정제된 확장과 물리적 구현</h2>
<p>2023년 9월 인공지능(AI) 및 로보틱스 분야의 연구 동향은 두 가지 거대한 흐름으로 요약될 수 있다. 첫째는 기존 대규모 모델의 성공을 바탕으로, 무조건적인 확장이 아닌 **‘정제된 확장(Refined Scaling)’**을 추구하는 움직임이다. 이는 계산 효율성, 메모리 관리, 정보 밀도 제어 등 시스템 및 알고리즘 최적화를 통해 AI의 성능과 접근성을 동시에 향상시키는 것을 목표로 한다.1 둘째는 디지털 공간에 머물던 AI의 지능을 현실 세계로 이전시키려는 **‘물리적 구현(Physical Embodiment)’**의 가속화이다. 이는 고전적인 제어 이론과 최신 기계 학습의 융합, 그리고 시뮬레이션과 현실의 간극을 메우는 정교한 학습 방법론을 통해 구체화되고 있다.2</p>
<p>본 보고서는 이러한 두 가지 핵심 흐름을 중심으로, 2023년 9월에 발표된 가장 영향력 있는 연구들을 세 가지 부문으로 나누어 심층 분석하고자 한다.</p>
<ul>
<li>
<p><strong>제1부</strong>에서는 AI 모델의 근본적인 계산 효율성을 혁신하는 연구들을 다룬다. Vision Transformer의 어텐션 메커니즘 재설계, 전문가 혼합(MoE) 모델의 비전 분야 확장, 그리고 대규모 언어 모델(LLM) 서빙의 병목 현상을 해결하는 PagedAttention 기술을 분석한다.</p>
</li>
<li>
<p><strong>제2부</strong>에서는 LLM의 능력을 한 차원 높은 수준으로 끌어올리는 프롬프팅 및 활용 방법론을 탐구한다. 정보 밀도를 정교하게 제어하는 ‘밀도 사슬(Chain of Density)’ 프롬프팅과 LLM 자체를 최적화 도구로 사용하는 ‘OPRO’ 프레임워크를 통해 LLM의 새로운 가능성을 조망한다.</p>
</li>
<li>
<p><strong>제3부</strong>에서는 로보틱스 지능의 도약을 이끄는 학습 및 제어 패러다임의 진화를 다룬다. 복잡한 비선형 시스템을 제어하는 쿠프만 연산자 이론의 적용과, 시뮬레이션에서 학습된 정교한 조작 기술을 현실 로봇으로 이전하는 Sim-to-Real 연구를 심도 있게 분석한다.</p>
</li>
</ul>
<h2>2.  차세대 AI 모델의 효율성 혁명</h2>
<p>이 장에서는 AI 모델의 성능을 유지하거나 향상시키면서도 계산 및 메모리 비용을 획기적으로 절감하는 세 가지 핵심 연구를 분석한다. 이는 AI 기술의 지속 가능한 발전을 위한 필수적인 방향성을 제시한다.</p>
<h3>2.1  Vision Transformer의 재해석: ReLU 어텐션의 부상</h3>
<h4>2.1.1 배경 및 문제 정의</h4>
<p>Vision Transformer(ViT)는 컴퓨터 비전 분야에 혁명을 일으켰으나, 그 핵심 구성 요소인 소프트맥스(Softmax) 기반 어텐션 메커니즘은 본질적인 확장성 한계를 내포하고 있었다.4 어텐션 메커니즘은 입력 시퀀스의 모든 토큰 쌍 간의 상호작용을 계산해야 하므로, 시퀀스 길이(이미지에서는 패치의 수)</p>
<p><span class="math math-inline">N</span>에 대해 시간 및 메모리 복잡도가 <span class="math math-inline">O(N^2)</span>로 증가한다.4 이러한 이차적 복잡도는 고해상도 이미지를 처리하거나, 계산 자원이 제한된 환경에서 ViT를 사용하는 데 있어 심각한 병목으로 작용해왔다. 이는 ViT의 광범위한 적용을 가로막는 근본적인 한계로 지적되었다.</p>
<h4>2.1.2 핵심 방법론: ReLU 기반 선형 어텐션</h4>
<p>이러한 문제를 해결하기 위해 2023년 9월, 소프트맥스를 ReLU(Rectified Linear Unit)와 같은 점별(point-wise) 활성화 함수로 대체하여 어텐션의 계산 복잡도를 선형으로 줄이려는 연구가 발표되었다.1 과거에도 유사한 시도가 있었으나, 단순히 소프트맥스를 ReLU로 대체할 경우 성능 저하가 발생하는 문제가 있었다.7</p>
<p>이번 연구의 핵심적인 발견은, ReLU 활성화 함수를 적용한 후 그 결과를 <strong>시퀀스 길이 <span class="math math-inline">L</span>로 나누는(<span class="math math-inline">scaled\ by\ L^{-1}</span>)</strong> 간단한 정규화 기법을 통해 성능 저하를 완화하고 소프트맥스 어텐션에 근접하는 성능을 달성할 수 있다는 점을 실험적으로 입증한 것이다.7 이는 소프트맥스가 가지는 확률 분포적 특성, 즉 모든 어텐션 가중치의 합이 1이 되어야 한다는 제약 조건 없이도, 어텐션의 핵심 기능인 ’중요한 정보에 대한 가중 합산’을 효과적으로 수행할 수 있음을 시사한다.</p>
<p>이러한 접근법은 어텐션 메커니즘에 대한 근본적인 관점의 전환을 의미한다. 기존의 소프트맥스 기반 어텐션이 각 토큰에 대한 ’확률적 중요도’를 계산하는 방식이었다면, ReLU 기반 어텐션은 쿼리-키 유사도라는 신호에 대한 ‘활성화 및 필터링’ 관점에 더 가깝다고 해석할 수 있다. 소프트맥스의 본질은 입력값들을 0과 1 사이의 값으로 정규화하고 그 합이 1이 되도록 만들어 확률 분포를 형성하는 것이며, 이는 특정 토큰에 ’집중’하는 효과를 낳는다.4 ReLU는 음수 값을 0으로 만들어 신호를 필터링하는데, 만약 쿼리-키 유사도가 높은 곳에서만 양수 값이 나오고 나머지는 0이 된다면 이는 소프트맥스의 ’집중’과 유사한 효과를 낼 수 있다. 과거 연구에서 ReLU로 단순 대체 시 성능이 하락했던 이유는, 소프트맥스가 전체 시퀀스를 고려한 정규화를 수행하여 값의 스케일을 안정시키는 반면 ReLU는 그렇지 않기 때문이었다. ‘시퀀스 길이로 나누는’ 행위는 이러한 스케일 문제를 해결하는 경험적이지만 효과적인 방법으로, 어텐션 값의 총합을 일정 수준으로 유지하려는 시도를 통해 소프트맥스의 글로벌 정규화 효과를 근사하는 역할을 한다.</p>
<h4>2.1.3 기술적 특징 및 결과</h4>
<p>ReLU 어텐션은 기존 소프트맥스 어텐션과 비교하여 ImageNet-21k 데이터셋을 사용한 대규모 실험에서 성능 저하 없이 훈련 속도와 메모리 사용량을 개선했다.1 더 중요한 것은, ReLU 어텐션은 소프트맥스가 요구하는 시퀀스 전체에 대한 집계(gather) 연산이 적어 시퀀스 길이 차원에 대한 병렬화에 더 유리한 구조를 가진다는 점이다.7 이는 향후 하드웨어 아키텍처 설계에 있어 더 높은 처리량을 달성할 수 있는 가능성을 열어주며, 더 큰 모델과 더 높은 해상도의 이미지를 효율적으로 처리할 수 있는 새로운 길을 제시한다. 결과적으로 이 연구는 어텐션의 핵심 기능(가중 선택)과 그것을 구현하는 방식(소프트맥스)을 분리할 수 있음을 보였으며, 이는 향후 더 효율적이고 하드웨어 친화적인 어텐션 변형 모델들의 개발을 촉진할 것이다.</p>
<p>다음 표는 소프트맥스 어텐션과 ReLU 어텐션의 주요 특징을 비교한 것이다.</p>
<p><strong>표 1: Softmax 어텐션과 ReLU 어텐션의 비교 분석</strong></p>
<table><thead><tr><th>지표</th><th>Softmax Attention</th><th>ReLU Attention (w/ SeqLen Scaling)</th></tr></thead><tbody>
<tr><td><strong>계산 복잡도</strong></td><td><span class="math math-inline">O(N^2 \cdot d)</span></td><td><span class="math math-inline">O(N \cdot d^2)</span> (선형 복잡도 달성 가능)</td></tr>
<tr><td><strong>메모리 사용량</strong></td><td><span class="math math-inline">O(N^2)</span>의 어텐션 맵 저장 필요</td><td><span class="math math-inline">O(N \cdot d)</span> (중간 어텐션 맵 불필요)</td></tr>
<tr><td><strong>병렬화 효율성</strong></td><td>시퀀스 차원에 대한 집계 연산 필요</td><td>더 적은 집계 연산으로 높은 병렬성 7</td></tr>
<tr><td><strong>성능 (ImageNet)</strong></td><td>기준 성능 (Baseline)</td><td>기준 성능에 근접하거나 동등 7</td></tr>
</tbody></table>
<h3>2.2  전문가 혼합(MoE) 모델, 비전 분야로의 확장</h3>
<h4>2.2.1 배경 및 개념</h4>
<p>전문가 혼합(Mixture-of-Experts, MoE)은 모델의 전체 파라미터 수를 대폭 늘리면서도, 각 입력에 대해서는 파라미터의 일부(소수의 ‘전문가’)만 활성화하여 계산 비용을 거의 일정하게 유지하는 ‘조건부 계산(conditional computation)’ 기법이다.8 이 아키텍처는 하나의 복잡한 문제를 여러 개의 하위 문제로 나누고, 각 하위 문제를 전문적으로 처리하는 ’전문가 네트워크’와 입력을 어떤 전문가에게 보낼지 결정하는 ’라우터(또는 게이팅 네트워크)’로 구성된다.9 이는 NLP 분야에서 대규모 언어 모델을 수조 개의 파라미터 규모로 확장하는 데 성공적으로 사용되어 왔다.</p>
<h4>2.2.2 핵심 방법론: Vision MoE (V-MoE)</h4>
<p>이러한 MoE 구조를 Vision Transformer(ViT)에 적용하여 V-MoE(Vision MoE)를 제안하는 연구들이 발표되었다.10 V-MoE는 일반적으로 ViT의 다층 퍼셉트론(MLP)으로 구성된 피드포워드 신경망(FFN) 블록을 여러 개의 ’전문가 FFN’과 이들을 선택하는 ’라우터’로 대체하는 방식이다.10 기존 ViT가 이미지의 모든 패치에 동일한 FFN 연산을 적용하는 것과 달리, V-MoE는 라우터를 통해 각 패치를 가장 잘 처리할 수 있는 소수의 전문가에게만 보내 계산 효율성을 높인다.</p>
<h4>2.2.3 기술적 특징 및 혁신</h4>
<p>2023년 9월에 발표된 연구는 MoE를 대규모 모델 확장에 사용하던 기존 패러다임을 넘어, **소형 모델의 효율성을 극대화(scaling-down)**하는 데 초점을 맞췄다는 점에서 주목할 만하다.1 특히, 모바일과 같이 리소스가 제한된 환경에 ViT를 효율적으로 배포하는 것을 목표로, 다음과 같은 혁신적인 설계를 제안했다.</p>
<ol>
<li>
<p><strong>이미지 단위 라우팅(Image-level Routing):</strong> 기존 V-MoE가 개별 이미지 패치(patch)를 각기 다른 전문가에게 라우팅하던 복잡한 방식에서 벗어나, <strong>이미지 전체를 단일 라우터가 판단하여 하나의 전문가에게 할당</strong>하는 대담하고 단순화된 MoE 설계를 도입했다.1 이는 문제의 단위를 ’패치’에서 ’이미지’로 전환한 것으로, “이 이미지는 ‘풍경’ 전문가가 처리하는 게 좋겠다” 또는 “이 이미지는 ‘인물’ 전문가가 처리하는 게 좋겠다“와 같이 더 높은 수준의 분업을 수행한다. 이 방식은 라우팅에 따르는 오버헤드를 크게 줄이고 훈련 안정성을 높이는 효과적인 절충안이다.</p>
</li>
<li>
<p><strong>안정적인 훈련을 위한 가이드:</strong> MoE 훈련 시 발생하는 전문가 불균형 문제(소수의 전문가만 집중적으로 사용되는 현상)를 피하기 위해, <strong>의미론적 슈퍼클래스(semantic super-classes) 정보를 라우터 훈련에 가이드로 사용</strong>하는 기법을 개발했다.1</p>
</li>
</ol>
<h4>2.2.4 결과 및 의의</h4>
<p>실험 결과, 제안된 Mobile V-MoE는 동일한 계산 비용(FLOPs)을 가진 일반(dense) ViT 모델보다 ImageNet-1k 분류 과제에서 3~4% 더 높은 정확도를 달성했다.13 이는 MoE가 대규모 모델의 파라미터 확장을 위한 도구일 뿐만 아니라, 제한된 계산 예산 내에서 모델의 성능을 최대한으로 끌어올리는 데에도 매우 효과적임을 입증한 중요한 결과이다.</p>
<p>MoE의 비전 분야 적용은 단순히 NLP의 성공을 재현하는 것을 넘어, ’계산의 동적 할당’이라는 더 큰 패러다임의 확산을 의미한다. 이미지 내 모든 영역이 동일한 계산 자원을 필요로 하지 않는다는 직관에 기반하여, 라우터가 이미지의 특성에 따라 계산 경로를 동적으로 결정하게 하는 것은 비전 모델의 효율성을 근본적으로 개선할 수 있는 길을 연다. 미래의 비전 모델은 고정된 파이프라인이 아니라, 입력 데이터에 따라 동적으로 구조와 계산량을 조절하는 ‘적응형(adaptive)’ 아키텍처로 발전할 것이며, MoE는 이러한 적응형 계산의 중요한 초기 형태라고 볼 수 있다.</p>
<h3>2.3  LLM 서빙의 병목 현상 해결: PagedAttention</h3>
<h4>2.3.1 배경 및 문제 정의</h4>
<p>대규모 언어 모델(LLM)의 추론 과정은 훈련과 달리 순차적이고 메모리 대역폭에 의해 성능이 좌우되는(memory-bound) 특성을 가진다.14 특히, 자기회귀적(autoregressive)으로 토큰을 생성할 때, 이전에 생성된 모든 토큰들의 키(Key)와 값(Value)을 저장하는 <strong>KV 캐시</strong>는 어텐션 계산에 필수적이다. 그러나 이 KV 캐시의 크기는 생성되는 시퀀스의 길이에 따라 동적으로 변하며 예측이 불가능하다.</p>
<p>기존 LLM 서빙 시스템들은 이 문제를 매우 비효율적으로 처리했다. 즉, 각 요청에 대해 최대 시퀀스 길이를 가정하고, 그에 해당하는 거대한 연속적인 메모리 블록을 미리 할당했다.15 하지만 대부분의 시퀀스는 최대 길이에 도달하지 않기 때문에 할당된 메모리의 상당 부분이 낭비되었다. 이러한 방식으로 인해 GPU 메모리의 60~80%가 낭비되는 심각한 <strong>메모리 단편화(memory fragmentation)</strong> 문제가 발생했으며, 이는 동시에 처리할 수 있는 요청의 수(배치 크기)를 제한하여 시스템 전체의 처리량(throughput)을 저하시키는 주된 원인이었다.14</p>
<h4>2.3.2 핵심 방법론: PagedAttention</h4>
<p>이 문제를 해결하기 위해 vLLM 시스템에서 제안된 PagedAttention은 컴퓨터 과학의 고전적인 운영체제(OS) 원리인 <strong>가상 메모리(virtual memory)와 페이징(paging)</strong> 개념을 LLM의 KV 캐시 관리에 도입했다.1</p>
<p>PagedAttention의 작동 방식은 다음과 같다:</p>
<ol>
<li>
<p><strong>블록 분할:</strong> KV 캐시를 작은 고정 크기의 ’블록(페이지)’으로 분할한다. 각 블록은 정해진 수의 토큰에 대한 키와 값 쌍을 저장할 수 있다.16</p>
</li>
<li>
<p><strong>비연속적 저장:</strong> 이 블록들은 물리적인 GPU 메모리 상에서 비연속적인 위치에 저장될 수 있다.</p>
</li>
<li>
<p><strong>블록 테이블:</strong> 각 요청마다 논리적인 블록 순서와 실제 물리 메모리 주소를 매핑하는 ’블록 테이블’을 유지한다. 이를 통해 어텐션 커널은 논리적으로는 연속적인 데이터에 접근하는 것처럼 작동하지만, 실제로는 흩어져 있는 메모리 블록에서 데이터를 가져온다.16</p>
</li>
<li>
<p><strong>동적 할당:</strong> 새로운 토큰이 생성될 때마다 필요한 만큼의 새 블록을 동적으로 할당한다. 이로써 메모리 사전 할당으로 인한 낭비를 막는다.18</p>
</li>
</ol>
<p>이러한 접근은 OS가 프로세스 메모리 관리를 위해 물리 메모리와 논리 주소 공간을 분리하는 방식과 정확히 일치한다. 여기서 ’프로세스’는 ’LLM 요청’에, ’메모리 페이지’는 ’KV 블록’에 해당한다.1</p>
<h4>2.3.3 기술적 특징 및 효과</h4>
<p>PagedAttention은 메모리 관리 방식의 근본적인 혁신을 통해 다음과 같은 효과를 달성했다.</p>
<ul>
<li>
<p><strong>메모리 효율성 극대화:</strong> 외부 단편화(메모리 공간 사이에 사용 불가능한 작은 조각이 생기는 현상)를 완전히 제거하고, 작은 블록 단위의 동적 할당을 통해 내부 단편화(할당된 블록 내에서 사용되지 않는 공간)를 최소화했다. 그 결과, KV 캐시 메모리 낭비를 4% 미만으로 줄였다.14</p>
</li>
<li>
<p><strong>처리량 대폭 향상:</strong> 메모리 효율성 증가는 동일한 GPU에서 더 많은 요청을 동시에 처리할 수 있게 함을 의미한다(즉, 더 큰 유효 배치 크기). 이로 인해 vLLM은 기존 시스템 대비 처리량을 2배에서 최대 24배까지 향상시켰다.15</p>
</li>
<li>
<p><strong>유연한 메모리 공유:</strong> 빔 서치(beam search)나 병렬 샘플링과 같이 여러 후보 시퀀스가 동일한 초기 부분(prefix)을 공유하는 경우, 해당 부분의 KV 블록을 물리적으로 복사하지 않고 포인터만 공유하는 Copy-on-Write와 유사한 메커니즘을 통해 메모리를 매우 효율적으로 공유할 수 있다.16</p>
</li>
</ul>
<p>PagedAttention의 성공은 LLM 혁명이 단순히 모델 아키텍처의 발전뿐만 아니라, 이를 뒷받침하는 <strong>시스템 수준의 최적화</strong>에 의해 가능하다는 것을 명확히 보여준다. 알고리즘(트랜스포머)이 만들어낸 문제를 고전적인 컴퓨터 과학의 원리(가상 메모리)로 해결한 탁월한 사례이며, LLM 서빙의 경제성을 극적으로 개선하여 기술의 대중화를 가속하는 핵심적인 인프라 기술로 자리 잡았다.18</p>
<h2>3.  대규모 언어 모델의 능력 확장과 응용</h2>
<p>이 장에서는 LLM의 성능을 극대화하고 새로운 방식으로 활용하는 두 가지 혁신적인 방법론을 분석한다. 이는 모델 자체를 변경하지 않고도 상호작용 방식(프롬프팅)을 통해 LLM의 잠재력을 끌어내는 연구의 중요성을 보여준다.</p>
<h3>3.1  정보 밀도 제어를 통한 요약 기술의 정점: 밀도 사슬(CoD) 프롬프팅</h3>
<h4>3.1.1 배경 및 문제 정의</h4>
<p>텍스트 요약은 간결함과 정보량 사이의 섬세한 균형을 요구하는 고난도 과제이다.19 기존의 단일 프롬프트 기반 요약 방식은 생성되는 정보의 ’밀도(density)’를 정교하게 제어하기 어려웠다.20 이로 인해 요약문이 지나치게 장황해지거나, 반대로 핵심적인 세부 정보를 누락하는 경우가 빈번하게 발생했다. 좋은 요약은 상세하고 엔티티 중심적이면서도, 과도하게 빽빽하지 않아 독자가 쉽게 이해할 수 있어야 한다.</p>
<h4>3.1.2 핵심 방법론: 밀도 사슬 (Chain of Density, CoD)</h4>
<p>이러한 문제를 해결하기 위해 제안된 ’밀도 사슬(Chain of Density, CoD)’은 GPT-4와 같은 LLM에게 <strong>고정된 길이 내에서 점진적으로 정보 밀도를 높이도록</strong> 유도하는 혁신적인 반복적 프롬프팅 기법이다.20 CoD의 과정은 인간 전문가가 글을 다듬는 과정을 모방한다.</p>
<ol>
<li>
<p><strong>초기 희소 요약 생성:</strong> 먼저 1~3개의 핵심 엔티티(인물, 장소, 개념 등)만 포함하는, 의도적으로 정보가 희소한(entity-sparse) 긴 요약문(예: 80단어)을 생성하도록 지시한다. 이 단계는 글의 ’초안’을 작성하는 것과 같다.19</p>
</li>
<li>
<p><strong>반복적 정제 및 밀도화:</strong> 이후 정해진 횟수(예: 5회)만큼, 이전 요약에 누락된 주요 엔티티를 1~3개씩 추가하여 요약을 다시 작성하도록 지시한다. 이때 가장 중요한 제약 조건은 <strong>전체 길이를 늘리지 않도록</strong> 강제하는 것이다.20 이는 ’누락 내용 검토’와 ‘수정’ 과정에 해당한다.</p>
</li>
<li>
<p><strong>자연스러운 고차원 언어 능력 유도:</strong> 길이를 유지하면서 새로운 정보를 추가해야 한다는 강력한 제약 조건 하에서, 모델은 자연스럽게 기존 문장을 압축(compression), 여러 정보를 하나의 문장으로 융합(fusion), 그리고 더 상위 개념으로 추상화(abstraction)하는 고차원적인 언어 전략을 사용하게 된다.19</p>
</li>
</ol>
<p>이러한 접근은 LLM에게 단순히 ’결과물’을 요구하는 것을 넘어, ’결과물을 만들어가는 과정’을 구체적으로 지시하는 새로운 프롬프팅 패러다임을 제시한다. 이는 LLM을 단순한 ’답변 생성기’에서 ’반성적 사고를 하는 저술가(reflective writer)’의 역할로 격상시키는 효과를 가진다.</p>
<h4>3.1.3 결과 및 평가</h4>
<p>CNN/DailyMail 데이터셋의 100개 기사에 대한 인간 평가 결과, 사람들은 일반적인 프롬프트로 생성된 GPT-4 요약보다 CoD를 통해 생성된, <strong>인간이 직접 작성한 요약과 비슷한 수준의 밀도</strong>를 가진 요약을 더 선호하는 것으로 나타났다.20 정량적 분석 결과, CoD 요약은 일반 요약에 비해 더 추상적이고, 정보 융합이 많으며, 원문의 앞부분 내용에만 치우치는 ’선행 편향(lead bias)’이 적은 것으로 확인되었다.20 이는 CoD가 LLM의 내재된 언어 능력을 최대한으로 이끌어내기 위해, 인간의 인지 과정을 모방한 ’절차적 프롬프팅(procedural prompting)’의 성공적인 사례임을 보여준다.</p>
<p>다음 표는 CoD 프롬프팅의 각 단계에 따라 요약문이 어떻게 변화하고 엔티티 밀도가 증가하는지를 보여주는 예시이다.</p>
<p><strong>표 2: CoD 프롬프팅의 단계별 요약 변화 및 엔티티 밀도 분석 (CNN/DailyMail 예시 기반)</strong></p>
<table><thead><tr><th>반복 횟수</th><th>요약문 (예시)</th><th>추가된 주요 엔티티</th><th>엔티티 수</th><th>밀도 (E/T)</th></tr></thead><tbody>
<tr><td><strong>1</strong></td><td>“이 기사는 중국 그랑프리에서 두 레이싱 드라이버인 젠슨 버튼과 파스토르 말도나도 사이에 발생한 사건을 다룬다. 두 사람은 13위를 다투던 중 버튼이 말도나도의 차량과 충돌하여 두 차량 모두 손상되었다.”</td><td>Jenson Button, Pastor Maldonado, Chinese Grand Prix</td><td>6.4</td><td>0.089</td></tr>
<tr><td><strong>2</strong></td><td>“McLaren의 젠슨 버튼과 Lotus의 파스토르 말도나도는 중국 그랑프리에서 13위를 다투다 충돌했다. 이 충돌로 인해 두 차량 모두 손상을 입었으며, 레이스 스튜어드들은 이 사건을 조사했다.”</td><td>McLaren, Lotus, race stewards</td><td>8.7</td><td>0.129</td></tr>
<tr><td><strong>3</strong></td><td>“McLaren의 젠슨 버튼은 중국 그랑프리 41번째 랩에서 Lotus의 파스토르 말도나도와 충돌한 후 앞 윙 손상으로 피트인해야 했고, 말도나도는 이 사건으로 5초 페널티를 받았다.”</td><td>41st lap, 5-second penalty, front wing damage</td><td>9.9</td><td>0.148</td></tr>
<tr><td><strong>…</strong></td><td>…</td><td>…</td><td>…</td><td>…</td></tr>
<tr><td><strong>인간 요약</strong></td><td>(인간이 작성한 기준 요약)</td><td>-</td><td>8.8</td><td>0.151</td></tr>
</tbody></table>
<p>주: 표의 데이터는 논문 20에 제시된 통계를 기반으로 재구성됨.</p>
<h3>3.2  언어 모델, 최적화 문제 해결사로의 진화: OPRO 프레임워크</h3>
<h4>3.2.1 배경 및 개념</h4>
<p>LLM의 성능은 프롬프트의 품질에 크게 의존하지만, 특정 과제에 대한 최적의 프롬프트를 찾는 과정은 전문가의 직관과 반복적인 실험에 의존하는 수동적이고 비효율적인 작업이었다. OPRO(Optimization by PROmpting)는 이러한 패러다임을 완전히 뒤집어, <strong>LLM 자체를 최적화기(optimizer)로 사용</strong>하여 프롬프트 최적화 문제를 자동화하는 새로운 프레임워크를 제시한다.1</p>
<h4>3.2.2 핵심 방법론</h4>
<p>OPRO는 자연어로 기술된 최적화 문제를 LLM에게 제시하여 반복적으로 더 나은 해(solution)를 생성하도록 유도하는 프레임워크이다.22 프롬프트 최적화를 예로 들면, 그 과정은 다음과 같다.</p>
<ol>
<li>
<p><strong>메타-프롬프트(Meta-Prompt) 구성:</strong> 최적화할 문제를 자연어로 명확하게 기술한다 (예: “GSM8K 벤치마크에서 더 높은 정확도를 달성하는 새로운 지시문을 생성하라”). 그리고 이 프롬프트에 이전에 생성했던 후보 지시문들과 각각의 성능 점수(정확도)를 함께 제공한다. 이 과거의 ’최적화 궤적’은 LLM이 어떤 종류의 지시문이 더 효과적인지에 대한 패턴을 학습하는 ‘In-context Learning’ 예시로 작용한다.</p>
</li>
<li>
<p><strong>해(Solution) 생성:</strong> LLM은 메타-프롬프트를 입력받아, 기존의 좋은 해들을 참고하고 개선하여 더 나은 성능을 낼 것으로 기대되는 새로운 후보 지시문들을 생성한다.</p>
</li>
<li>
<p><strong>평가 및 반복:</strong> 생성된 후보 지시문들의 성능을 실제로 평가하고, 그 결과(새로운 지시문과 점수)를 다시 메타-프롬프트에 추가하여 다음 최적화 단계의 입력으로 사용한다. 이 과정을 반복하며 점진적으로 더 나은 해를 탐색한다.</p>
</li>
</ol>
<p>이러한 접근은 전통적인 최적화 기법(예: 경사 하강법)이 적용되기 어려운, 목적 함수가 미분 불가능하고 탐색 공간이 거대한 이산 공간(discrete space)인 문제에 특히 효과적이다. LLM은 수학적 연산 대신, 텍스트에 대한 방대한 사전 지식을 바탕으로 ’의미론적 탐색(semantic search)’을 수행한다. 즉, “더 높은 정확도를 내는“이라는 목표를 언어적으로 이해하고, 성공적인 프롬프트들의 의미적 패턴을 분석하여 새로운 후보를 추론해낸다.</p>
<h4>3.2.3 결과 및 의의</h4>
<p>OPRO를 통해 최적화된 프롬프트는 인간 전문가가 설계한 프롬프트보다 수학 문제 해결(GSM8K)에서 최대 8%, 복합 추론 문제(Big-Bench Hard)에서 최대 50%까지 성능을 극적으로 향상시켰다.22 이는 LLM이 단순히 주어진 문제를 푸는 것을 넘어,</p>
<p><strong>문제를 푸는 방법 자체를 개선</strong>할 수 있는 메타-레벨의 추론 능력을 가지고 있음을 실증적으로 보여준다.</p>
<p>OPRO의 등장은 최적화라는 수학적이고 구조적인 문제를 자연어라는 비정형적인 공간으로 성공적으로 옮겨왔다는 점에서 중요한 의미를 가진다. 이는 복잡한 실제 세계의 문제들 중, 명확한 목적 함수를 정의하기 어렵거나 미분 불가능한 문제들을 해결하는 데 LLM이 강력한 도구가 될 수 있음을 시사한다. 앞으로는 복잡한 시스템 설계, 비즈니스 전략 수립, 과학적 가설 생성 등 인간의 직관과 경험이 중요했던 영역에서 LLM이 ’최적화 파트너’로서 역할을 수행할 수 있는 가능성을 열었다.</p>
<h2>4.  로보틱스 지능의 도약: 학습 및 제어 패러다임의 진화</h2>
<p>이 장에서는 AI 기술이 로봇의 물리적 제어 및 학습 능력과 어떻게 융합되어 더 정교하고 강건한 지능을 구현하는지를 보여주는 두 가지 핵심 연구를 분석한다.</p>
<h3>4.1  비선형 동역학 시스템 제어의 새로운 지평: 쿠프만 연산자 기반 제어</h3>
<h4>4.1.1 배경 및 문제 정의</h4>
<p>로봇의 움직임과 같이 실제 물리 세계의 시스템은 대부분 복잡한 비선형 동역학(nonlinear dynamics)을 따른다. 이러한 시스템을 정확하게 모델링하고 안정적으로 제어하는 것은 로보틱스 분야의 오랜 난제였다.23 전통적인 선형 제어 이론은 적용이 간단하고 해석이 용이하지만 비선형성이 강한 시스템에서는 성능이 저하되거나 불안정해질 수 있다.</p>
<h4>4.1.2 핵심 방법론: 쿠프만 연산자 이론과 딥러닝의 융합</h4>
<p>쿠프만 연산자(Koopman Operator) 이론은 이러한 문제에 대한 우아한 수학적 해법을 제공한다. 이 이론의 핵심은, 복잡한 비선형 동역학 시스템을 무한 차원의 함수 공간(관측 공간, space of observables)으로 ‘끌어올리면(lift)’ 그 공간에서는 동역학이 선형적으로 변환된다는 것이다.24 2023년 9월에 발표된 이 연구는 딥러닝을 이용해 원본 상태 공간(예: 로봇의 관절 각도, 속도)을 선형 동역학이 적용되는 고차원의 잠재 공간(latent space)으로 매핑하는 비선형 인코더(embedding function)를 학습하는 방식으로 이 이론을 구현했다.23 일단 잠재 공간에서 시스템이 선형( <span class="math math-inline">z_{k+1} = Az_k + Bu_k</span>)으로 표현되면, LQR(Linear Quadratic Regulator)과 같은 강력하고 효율적인 선형 제어 기법을 적용할 수 있다.</p>
<h4>4.1.3 기술적 특징 및 혁신</h4>
<p>이 연구는 기존 쿠프만 기반 제어 연구에서 한 걸음 더 나아가 다음과 같은 혁신을 이루었다.</p>
<ol>
<li>
<p><strong>대조 인코더(Contrastive Encoder) 도입:</strong> 의미적으로 유사한 상태를 잠재 공간에서 가깝게 배치하는 대조 학습(contrastive learning) 기법을 인코더 학습에 적용했다.23 이는 동역학적으로 예측 가능하고 제어에 용이한 잠재 표현을 학습하는 데 매우 효과적임이 입증되었다.</p>
</li>
<li>
<p><strong>과제 지향적(Task-Oriented) 종단간 학습:</strong> 기존의 2단계 접근법(1단계: 동역학 모델 식별, 2단계: 제어기 설계)은 모델의 예측 오차가 제어 성능 저하로 직결되는 한계가 있었다. 본 연구에서는 이를 극복하기 위해, 모델의 예측 정확도뿐만 아니라 최종적인 <strong>강화학습 과제 보상(task cost)을 직접 최적화</strong>하는 단일 단계의 종단간(end-to-end) 학습 루프를 설계했다.23 결국 로봇에게 중요한 것은 물리 법칙을 완벽히 예측하는 것이 아니라 주어진 과제를 성공적으로 수행하는 것이므로, 최종 목표를 직접 최적화함으로써 시스템은 과제 수행에 가장 ‘유용한’ 동역학 모델을 스스로 학습하게 된다.</p>
</li>
</ol>
<h4>4.1.4 결과 및 의의</h4>
<p>이러한 접근법은 기존에 저차원 시스템에 국한되었던 쿠프만 기반 제어 기법을 <strong>고차원의 복잡한 비선형 시스템(픽셀 기반 시각 입력 포함)으로 확장</strong>하는 데 최초로 성공했다.23 이는 고전 제어 이론의 수학적 안정성과 해석 가능성을 딥러닝의 강력한 표현 학습 능력과 결합하여, 복잡한 로봇 제어 문제에 대한 새로운 해법을 제시했다는 점에서 큰 학문적 의의를 가진다. 이 연구는 ’모델 기반(Model-Based) RL’의 데이터 효율성과 ’모델 프리(Model-Free) RL’의 강건함이라는 두 패러다임의 장점을 통합하는 강력한 대안을 제시한다.</p>
<h3>4.2  시뮬레이션과 현실의 간극 극복: Sim-to-Real 브러시 조작</h3>
<h4>4.2.1 배경 및 문제 정의</h4>
<p>강화학습을 통해 로봇이 복잡한 기술을 배우게 하는 것은 매우 유망하지만, 이 과정을 실제 로봇에서 직접 수행하는 것은 막대한 시간과 비용이 소요되며, 시행착오 과정에서 로봇이나 주변 환경이 손상될 위험이 크다. 이 때문에 시뮬레이션 환경에서 정책을 충분히 학습시킨 후, 학습된 정책을 실제 로봇으로 이전하는 Sim-to-Real 접근법이 널리 사용된다. 하지만 시뮬레이션은 현실 세계의 모든 물리적 현상(특히 마찰, 변형, 복잡한 접촉)을 완벽하게 재현할 수 없기 때문에, 시뮬레이션과 현실 사이의 차이, 이른바 **‘현실 간극(reality gap)’**으로 인해 시뮬레이션에서 잘 작동하던 정책이 실제 환경에서는 실패하는 문제가 발생한다.28</p>
<h4>4.2.2 핵심 방법론: 행동 복제와 강화학습의 전략적 결합</h4>
<p>2023년 9월에 발표된 이 연구는 브러시를 이용한 페인팅이라는, 접촉이 풍부하고 변형이 심한 물체를 다루는 고난도 조작 과제에 도전하며 현실 간극 문제를 해결하기 위한 효과적인 하이브리드 학습 프레임워크를 제안했다.30</p>
<ol>
<li>
<p><strong>행동 복제 (Behavior Cloning, BC)를 통한 초기 정책 학습:</strong> 먼저, 인간 전문가의 시연 데이터를 모방하여 초기 정책을 학습한다. 강화학습만 사용할 경우, 시뮬레이터의 물리적 허점을 파고드는 비현실적인 정책을 학습하거나, 현실적인 동작을 처음부터 탐색하는 데 매우 비효율적일 수 있다. 반면, 인간 시연 데이터는 이미 현실 세계의 물리 법칙을 따르는 ‘현실적인’ 행동의 분포를 제공한다. BC를 통해 정책은 이 현실적인 분포 근처에서 학습을 시작하게 되어, 탐색 공간을 효과적으로 줄이고 학습 초기 단계의 비효율성을 완화한다.</p>
</li>
<li>
<p><strong>강화학습 (Reinforcement Learning, RL)을 통한 미세 조정 및 강건성 확보:</strong> BC만으로는 시연 데이터에 없었던 새로운 상황에 대처하는 능력이 부족하고 외부 방해에 대한 강건성(robustness)이 떨어진다. 따라서 BC로 학습된 초기 정책을 시뮬레이션 환경에서 강화학습으로 미세 조정하여, 더 다양한 상황에 대처하고 예기치 않은 변화에도 강건하게 작동하는 정책으로 발전시킨다.</p>
</li>
</ol>
<p>이러한 접근법은 Sim-to-Real 문제가 단지 ‘물리 파라미터의 정밀한 튜닝’ 문제가 아니라, ‘학습 방법론의 전략적 선택’ 문제임을 보여준다. BC로 ’현실적인 행동의 밑그림’을 그리고, RL로 그 위에서 ’다양한 상황에 대한 대처법과 강건성’을 덧칠하는 이 하이브리드 전략은 ’모방’과 ’탐색’이라는 학습의 두 가지 근본적인 축을 효과적으로 활용하여 현실 간극을 극복한다.</p>
<h4>4.2.3 기술적 특징 및 결과</h4>
<p>연구진은 가상 페인팅 환경인 MyPaint 시뮬레이터와 실제 UR5 로봇 팔로 구성된 물리적 환경을 구축하여 시뮬레이션과 현실 환경 간의 일관성을 높였다.30 이를 통해 브러시의 위치, 압력, 각도 등 고차원의 연속적인 행동 공간을 가진 정책을 효과적으로 학습시켰다. 최종적으로, 제안된 프레임워크는 시뮬레이션에서 학습된 정교한 브러시 조작 기술을 실제 로봇으로 성공적으로 이전할 수 있음을 보여주었다.30 이는 예술, 디지털 디자인, 로봇을 이용한 정밀 외과 수술 등 광범위한 분야에 적용될 수 있는 잠재력을 가진다.</p>
<p>다음 표는 본 보고서에서 다룬 두 가지 핵심 로보틱스 연구의 접근법과 목표를 비교한 것이다.</p>
<p><strong>표 3: 주요 로보틱스 연구(쿠프만 제어, Sim-to-Real)의 접근법 및 성능 비교</strong></p>
<table><thead><tr><th>구분</th><th>Task-Oriented Koopman Control</th><th>Sim-to-Real Brush Manipulation</th></tr></thead><tbody>
<tr><td><strong>핵심 문제</strong></td><td>복잡한 비선형 동역학 시스템의 제어</td><td>시뮬레이션과 현실 간의 ‘Reality Gap’ 극복</td></tr>
<tr><td><strong>주요 기술</strong></td><td>쿠프만 연산자, 대조 학습, 종단간 강화학습</td><td>행동 복제(BC), 강화학습(RL)</td></tr>
<tr><td><strong>접근 방식</strong></td><td>고전 제어 이론 + 딥러닝 표현 학습</td><td>모방 학습 + 탐색 기반 학습</td></tr>
<tr><td><strong>장점</strong></td><td>해석 가능한 선형 모델, 안정성, 고차원 시스템 확장</td><td>데이터 효율성(BC), 강건성 확보(RL), 복잡한 조작</td></tr>
<tr><td><strong>한계점</strong></td><td>모델 학습의 안정성, 매우 복잡한 접촉 동역학</td><td>전문가 시연 데이터 필요, 시뮬레이터 정확도 의존</td></tr>
</tbody></table>
<h2>5. 결론 및 미래 전망</h2>
<h4>5.0.1 년 9월 연구 동향 종합</h4>
<p>본 보고서에서 심층 분석한 2023년 9월의 주요 연구들은 **‘정제된 확장’**과 **‘물리적 구현’**이라는 두 가지 핵심 키워드로 수렴한다. AI 분야에서는 모델의 규모를 무작정 키우는 단계를 넘어, 아키텍처(ReLU-Attention, MoE)와 서빙 시스템(PagedAttention)의 효율성을 극대화하고, 상호작용 방식(CoD, OPRO)을 고도화하여 내재된 능력을 최대한으로 끌어내려는 성숙한 노력이 두드러졌다. 로보틱스 분야에서는 AI의 강력한 학습 및 표현 능력을 고전 제어 이론(쿠프만 연산자)과 창의적으로 결합하거나, 현실 세계의 복잡성을 극복하기 위한 정교한 학습 전략(Sim-to-Real)을 개발함으로써 지능의 물리적 구현을 한 단계 발전시켰다.</p>
<h4>5.0.2 미래 전망</h4>
<p>이러한 연구 동향은 AI와 로보틱스 분야의 미래에 대한 몇 가지 중요한 방향성을 제시한다.</p>
<ul>
<li>
<p><strong>AI 시스템의 통합적 최적화:</strong> 앞으로의 AI 연구는 모델 아키텍처, 학습 알고리즘, 하드웨어, 서빙 시스템을 개별적으로 최적화하는 것을 넘어, 이 모든 것을 통합적으로 고려하는 <strong>‘전주기적(full-stack)’ 최적화</strong> 방향으로 나아갈 것이다. PagedAttention과 같은 시스템 수준의 혁신이 모델의 발전을 이끌고, ReLU 어텐션과 같이 하드웨어 친화적인 아키텍처가 새로운 표준으로 자리 잡는 사례가 더 많아질 것이다.</p>
</li>
<li>
<p><strong>AI와 과학의 융합:</strong> OPRO가 보여준 LLM의 최적화 능력은 신약 개발, 재료 과학, 시스템 설계 등 다양한 과학 및 공학 분야의 난제 해결에 적용될 것이다. 또한 쿠프만 연산자 제어 연구처럼, AI는 기존 과학 이론을 대체하는 것이 아니라, 이를 데이터 기반으로 강화하고 그 적용 범위를 확장하는 강력한 도구로서의 역할을 더욱 공고히 할 것이다.</p>
</li>
<li>
<p><strong>범용 로봇을 향한 길:</strong> 로보틱스 연구는 개별 과제 해결을 넘어, 다양한 기술(비전, 언어, 제어, 학습)을 통합하여 더 일반적이고 적응력 있는 범용 로봇을 구현하는 방향으로 나아갈 것이다. 예를 들어, LLM이 로봇의 상위 수준 계획(예: “책상을 정리해줘”)을 수립하고, 쿠프만/RL 기반의 제어기가 하위 수준의 정교한 실행(예: 물체를 안정적으로 잡고 옮기기)을 담당하는 계층적 구조가 유력한 후보가 될 것이다. 2023년 9월의 연구들은 이러한 미래를 향한 중요한 기술적 초석을 다졌다.</p>
</li>
</ul>
<h2>6. 참고 자료</h2>
<ol>
<li>Top 5 AI papers of September 2023 - LearnOpenCV, https://learnopencv.com/top-5-ai-papers-of-september-2023/</li>
<li>The Evolution and Convergence of Artificial Intelligence and Intelligent Robotics, https://www.researchgate.net/publication/391771428_The_Evolution_and_Convergence_of_Artificial_Intelligence_and_Intelligent_Robotics</li>
<li>A human-centric approach to adopting AI, https://convergence.mit.edu/a-human-centric-approach-to-adopting-ai/</li>
<li>The Linear Attention Resurrection in Vision Transformer - arXiv, https://arxiv.org/html/2501.16182v1</li>
<li>PolaFormer: Polarity-aware Linear Attention for Vision Transformers - arXiv, https://arxiv.org/html/2501.15061v1</li>
<li>[2501.16182] The Linear Attention Resurrection in Vision Transformer - arXiv, https://arxiv.org/abs/2501.16182</li>
<li>Replacing softmax with ReLU in Vision Transformers, https://arxiv.org/pdf/2309.08586</li>
<li>A Survey on Mixture of Experts in Large Language Models - arXiv, https://arxiv.org/pdf/2407.06204</li>
<li>Mixture of Experts in Image Classification: What’s the Sweet Spot? - arXiv, https://arxiv.org/html/2411.18322v1</li>
<li>Scaling Vision with Sparse Mixture of Experts - NIPS, https://papers.neurips.cc/paper_files/paper/2021/file/48237d9f2dea8c74c2a72126cf63d933-Paper.pdf</li>
<li>A Comprehensive Survey of Mixture-of-Experts: Algorithms, Theory, and Applications - arXiv, https://arxiv.org/html/2503.07137v1</li>
<li>[2106.05974] Scaling Vision with Sparse Mixture of Experts - arXiv, https://arxiv.org/abs/2106.05974</li>
<li>Mobile V-MoEs: Scaling Down Vision Transformers via Sparse Mixture-of-Experts - arXiv, https://arxiv.org/abs/2309.04354</li>
<li>Paged Attention from First Principles: A View Inside vLLM | Hamza’s …, https://hamzaelshafie.bearblog.dev/paged-attention-from-first-principles-a-view-inside-vllm/</li>
<li>How PagedAttention resolves memory waste of LLM systems | Red …, https://developers.redhat.com/articles/2025/07/24/how-pagedattention-resolves-memory-waste-llm-systems</li>
<li>How does vLLM serve LLMs at scale? - Substack, https://substack.com/home/post/p-159610212?utm_campaign=post&amp;utm_medium=web</li>
<li>vLLM and PagedAttention: A Comprehensive Overview | by Abonia Sojasingarayar | Medium, https://medium.com/@abonia/vllm-and-pagedattention-a-comprehensive-overview-20046d8d0c61</li>
<li>Introduction to vLLM and PagedAttention | Runpod Blog, https://www.runpod.io/blog/introduction-to-vllm-and-pagedattention</li>
<li>Chain of Density (CoD) - Learn Prompting, https://learnprompting.org/docs/advanced/self_criticism/chain-of-density</li>
<li>From Sparse to Dense: GPT-4 Summarization with Chain of Density …, https://arxiv.org/pdf/2309.04269</li>
<li>From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting - Smith LangChain, https://smith.langchain.com/hub/majid/chain-of-density-prompt</li>
<li>Large Language Models as Optimizers - arXiv, https://arxiv.org/abs/2309.03409</li>
<li>Task-Oriented Koopman-Based Control with Contrastive Encoder, https://proceedings.mlr.press/v229/lyu23a/lyu23a.pdf</li>
<li>Efficient Dynamics Modeling in Interactive Environments with Koopman Theory - arXiv, https://arxiv.org/html/2306.11941v4</li>
<li>Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling | Request PDF - ResearchGate, https://www.researchgate.net/publication/395542521_Robust_Online_Residual_Refinement_via_Koopman-Guided_Dynamics_Modeling</li>
<li>Task-Oriented Koopman-Based Control with Contrastive Encoder - OpenReview, https://openreview.net/forum?id=q0VAoefCI2</li>
<li>arxiv.org, https://arxiv.org/abs/2309.16077</li>
<li>Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey - arXiv, https://arxiv.org/abs/2009.13303</li>
<li>What exactly makes sim to real transfer a challenge in reinforcement learning? - Reddit, https://www.reddit.com/r/robotics/comments/1j99vrt/what_exactly_makes_sim_to_real_transfer_a/</li>
<li>arxiv.org, https://arxiv.org/abs/2309.08457</li>
<li>Sim-to-Real Robotic Sketching using Behavior … - Google Sites, https://sites.google.com/view/sketchingrobot</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>