<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2024년 9월 인공지능 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2024년 9월 인공지능 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2024년 AI 및 로봇 연구 동향</a> / <span>2024년 9월 인공지능 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2024년 9월 인공지능 및 로봇 연구 동향</h1>
<h2>1. 서론</h2>
<p>2024년 9월 인공지능(AI) 및 로봇 공학 분야는 중요한 변곡점을 맞이했음을 시사한다. 새로운 파운데이션 모델의 등장 자체보다는, 기존 모델의 역량을 현실 세계에 적용하고, 그 일반화 가능성을 극대화하며, 안전성과 신뢰성을 확보하는 방향으로 연구의 무게 중심이 뚜렷하게 이동하고 있다. 이는 AI 기술이 ‘존재 증명’ 단계를 지나 ‘견고한 배포’ 단계로 성숙해 가고 있음을 보여준다.</p>
<p>본 보고서는 2024년 9월 한 달간 발표된 주요 연구 성과를 종합적으로 분석하여 현재 기술 지형을 조망하고 미래 방향성을 예측하는 것을 목표로 한다. 이를 위해 다음 네 가지 핵심 영역을 심층적으로 다룬다. 첫째, IROS와 ECCV 같은 최고 수준의 학회를 통해 발표된 최신 학술 동향을 분석하며, 로봇 공학과 컴퓨터 비전 분야의 실질적인 응용 및 새로운 패러다임을 탐구한다. 둘째, 메타(Meta), OpenAI, 구글(Google) 등 산업계를 선도하는 기업들의 주요 발표를 통해 멀티모달리티 확장과 모델 신뢰성이라는 두 가지 핵심 전략을 분석한다. 셋째, arXiv와 같은 사전 공개 플랫폼에 등장한 로봇 공학 논문들을 통해, 특정 작업에 국한되지 않고 새로운 환경에서도 즉시 임무 수행이 가능한 ’일반화된 로봇(Generalist Robots)’을 향한 구체적인 진전을 살펴본다. 마지막으로, MIT와 스탠퍼드(Stanford) 등 세계 유수 대학 연구소들이 제시하는 AI 거버넌스, 위험 분석, 사회적 영향에 대한 연구를 통해 기술 발전의 이면에 있는 책임과 방향성을 고찰한다.</p>
<p>이러한 다각적인 분석을 통해, 2024년 9월이 AI 및 로봇 공학 기술이 단순한 성능 경쟁을 넘어 실제 세계에서의 적용, 일반화, 그리고 안전이라는 복합적인 과제를 해결하기 시작한 중요한 시점임을 명확히 하고자 한다.</p>
<h2>2.  주요 학술 학회 동향 분석</h2>
<p>2024년 9월은 로봇 공학과 컴퓨터 비전 분야에서 가장 권위 있는 두 학회, IROS와 ECCV가 개최되어 학계의 연구 방향성을 명확히 보여준 시기였다. IROS에서는 실제 환경에서의 로봇 적용 기술과 제어 이론의 성숙이 두드러졌고, ECCV에서는 생성형 AI의 폭발적인 진화와 3D 비전, 하드웨어-소프트웨어 공동 설계라는 새로운 패러다임이 핵심 주제로 부상했다.</p>
<h3>2.1  IROS 2024: 지능형 로봇 시스템의 진화</h3>
<p>아부다비에서 개최된 IEEE/RSJ 지능형 로봇 및 시스템 국제 학회(IROS 2024)는 로봇 공학 연구가 추상적인 문제 해결을 넘어, 현실 세계의 복잡하고 구체적인 과제에 직접적으로 기여하는 방향으로 진화하고 있음을 명확히 보여주었다.1</p>
<h4>2.1.1  고급 제어 이론과 복잡한 동역학</h4>
<p>이번 학회에서 가장 주목할 만한 이론적 성과 중 하나는 복잡한 동역학 시스템을 다루기 위한 제어 이론의 발전이었다. 특히, MIT 연구진이 발표한 ‘쿠프만 동역학 모델링(Koopman Dynamic Modeling)’ 연구는 로봇이 환경과 접촉하고 분리되는 과정(making and breaking contact)에서 발생하는 비선형적이고 불연속적인 동역학을 통합적으로 표현하는 새로운 길을 제시했다.1 이 접근법은 복잡한 동역학을 고차원의 선형 공간으로 변환하여, 조작이나 보행과 같이 동역학이 급격히 변하는 작업에 대해 보다 일관되고 전역적으로 안정적인 제어 정책을 설계할 수 있는 이론적 기반을 제공한다.</p>
<p>이와 더불어, 모델 예측 경로 적분 제어(Model Predictive Path Integral, MPPI)를 활용한 내비게이션 아키텍처 연구도 중요한 진전으로 평가된다.3 이 연구는 수천 개의 가능한 제어 시퀀스를 병렬로 샘플링하여 실시간으로 충돌을 회피하는 강인한 제어 프레임워크를 제안했다. 제안된 비용 함수는 목표 지점까지의 거리, 각도, 속도 오차뿐만 아니라 충돌 가능성과 제어 입력의 부드러움까지 고려하여 정교한 경로 계획을 가능하게 한다. 예를 들어, 비용 함수 <span class="math math-inline">c(x,u)</span>는 다음과 같이 정의될 수 있다.<br />
<span class="math math-display">
c(x,u) = 40 c_{dist}(p_x, p_y) + 30 c_{angle}(\theta) + 10 c_{speed}(v) + 50 c_{collision}(p_x, p_y) + c_{cmd}(u)
</span><br />
이러한 연구들은 로봇이 예측 불가능한 실제 환경에서 더 안전하고 효율적으로 작동하기 위한 핵심적인 제어 기술의 성숙을 보여준다.</p>
<h4>2.1.2  인간 중심 환경에서의 로봇 공학</h4>
<p>IROS 2024는 로봇 기술이 농업, 헬스케어 등 인류의 삶에 직접적인 영향을 미치는 분야로 깊숙이 파고들고 있음을 보여주었다. ‘미래 정밀 농업을 위한 AI 및 로봇 공학’ 워크숍에서는 작물 표현형 분석을 위한 모듈형 로봇 시스템, 잡초 및 질병 탐지를 위한 AI, 자율 수확 로봇 등 식량 안보와 지속 가능한 농업 문제 해결을 위한 구체적인 기술들이 논의되었다.4 이는 로봇 공학이 글로벌 난제 해결에 기여하는 중요한 도구로 자리매김하고 있음을 시사한다.</p>
<p>또한, 고령자의 이동성을 향상시키기 위한 ‘두 개의 몸체를 가진 로봇(Two-Body Robot)’ 연구 발표는 보조 로봇 공학 분야의 성장을 잘 보여준다.1 이 로봇은 사용자가 어느 위치에서든 안정적으로 핸들바를 잡을 수 있도록 설계되어, 비정형적인 가정 환경에서 안전한 인간-로봇 상호작용을 목표로 한다. 이러한 연구들은 로봇이 공장을 넘어 우리의 일상 공간으로 들어오기 위해 필요한 안정성과 신뢰성 확보에 연구의 초점이 맞춰지고 있음을 나타낸다.</p>
<h4>2.1.3  시스템 수준의 도구 및 아키텍처</h4>
<p>로봇 시스템의 복잡성이 증가함에 따라, 이를 진단하고 최적화하기 위한 시스템 수준의 도구 개발 또한 중요한 연구 주제로 다루어졌다. ’PEERNet’은 실시간 네트워크 로봇 시스템의 성능 병목 현상을 진단하는 엔드투엔드 프로파일링 도구로, 다중 로봇이나 원격 조작 시나리오에서 시스템의 신뢰성을 보장하는 데 기여할 수 있다.5 또한, 로봇 운영체제(ROS)를 웹어셈블리(WebAssembly)를 통해 웹 환경으로 가져오려는 ‘ROS2WASM’ 프로젝트는 로봇 시뮬레이션 및 제어의 접근성과 플랫폼 독립성을 획기적으로 높일 잠재력을 가진다.6</p>
<p>이러한 학술적 흐름은 로봇 공학 분야의 중요한 변화를 암시한다. 과거에는 추상적인 알고리즘 개발에 집중했다면, 현재는 농업이나 헬스케어와 같은 특정 수직 분야의 현실적인 문제 해결이 새로운 이론적 발전을 견인하고 있다. 예를 들어, 농업 로봇이 다양한 모양의 과일을 잡거나 불규칙한 지면을 이동해야 하는 과제는 바로 쿠프만 연산자 이론이 해결하고자 하는 ‘접촉과 분리’ 문제의 현실적인 예시다. 즉, 실제 응용 분야로의 확장이 더 강인하고 일반화된 제어 이론에 대한 수요를 창출하고, 이러한 이론적 발전이 다시 응용 분야의 성공을 이끄는 선순환 구조가 형성되고 있다. 이는 미래 로봇 공학의 혁신이 순수한 알고리즘 개발이 아닌, 농학자나 노인학 전문가와 같은 도메인 전문가와 제어 이론가 간의 깊은 협력을 통해 이루어질 것임을 시사한다.</p>
<h4>2.1.4 표 1: IROS 2024 주요 발표 논문 요약</h4>
<table><thead><tr><th>논문 제목</th><th>핵심 기여</th><th>응용 분야</th><th>출처</th></tr></thead><tbody>
<tr><td>Koopman Dynamic Modeling for Global and Unified Representations…</td><td>쿠프만 연산자를 이용해 비선형 로봇 동역학, 특히 접촉 과업에 대한 선형 표현 생성</td><td>일반 조작, 보행</td><td>1</td></tr>
<tr><td>Enhancing Elderly Mobility: A Sturdy, Two-Body Robot…</td><td>고령자가 어느 위치에서든 지지받을 수 있는 안정적인 보조 로봇 설계</td><td>헬스케어, 보조 로봇</td><td>1</td></tr>
<tr><td>Workshop: AI and Robotics for Future Precision Agriculture</td><td>표현형 분석, 수확, 농장 관리를 위한 센싱, AI, 로봇 공학 기술 발표 모음</td><td>농업, 식량 안보</td><td>4</td></tr>
<tr><td>PEERNet: An End-to-End Profiling Tool for Real-Time Networked Robotic Systems</td><td>복잡한 네트워크 로봇 시스템의 성능 병목 현상을 진단하는 소프트웨어 도구</td><td>시스템 공학, 다중 로봇 시스템</td><td>5</td></tr>
<tr><td>Navigation Architecture using MPPI</td><td>강인한 충돌 회피를 위한 모델 예측 경로 적분 제어(MPPI) 기반 내비게이션 컨트롤러</td><td>자율 주행</td><td>3</td></tr>
</tbody></table>
<h3>2.2  ECCV 2024: 컴퓨터 비전의 최전선</h3>
<p>9월 29일부터 10월 4일까지 이탈리아 밀라노에서 개최된 유럽 컴퓨터 비전 학회(ECCV 2024)는 2,300편 이상의 논문이 발표된 대규모 학술 행사로, 생성형 AI의 지속적인 혁명, 3D 비전 기술의 약진, 그리고 멀티모달 파운데이션 모델의 고도화가 주된 흐름을 형성했다.7</p>
<h4>2.2.1  생성형 AI 혁명의 지속</h4>
<p>ECCV 2024에서는 확산 모델(Diffusion Model)을 더 빠르고, 더 제어 가능하게 만들려는 연구가 주를 이루었다. 복잡한 다단계 확산 모델을 단일 단계의 GAN(Generative Adversarial Network)으로 증류하여 추론 속도를 획기적으로 가속하는 연구나, LightControlNet처럼 조명 조건을 이미지로 명시하거나 Concept Sliders를 통해 생성 이미지의 특정 속성을 정밀하게 제어하는 기술들이 발표되었다.8</p>
<p>특히, 2D 생성 기술을 3D로 확장하려는 노력이 두드러졌다. ’LGM(Large Multi-View Gaussian Model)’이나 ’GVGEN’과 같은 연구들은 텍스트 프롬프트로부터 직접 고해상도 3D 에셋을 생성하는 새로운 방법을 제시했다.9 이는 증강현실(AR), 가상현실(VR), 시뮬레이션 콘텐츠 제작에 필수적인 기술로, 3D 콘텐츠 생성의 패러다임을 바꿀 잠재력을 보여준다.</p>
<h4>2.2.2  3D 재구성 및 장면 이해</h4>
<p>3D 장면 재구성 기술, 특히 3D 가우시안 스플래팅(Gaussian Splatting)은 여전히 뜨거운 연구 주제였다. ’구조-인지 3D 가우시안 스플래팅(SAGS)’이나 ’빠른 일반화 가우시안 스플래팅 재구성’과 같은 연구들은 이미지로부터 새로운 시점의 뷰를 생성하는 기술의 속도와 품질을 한 단계 끌어올렸다.10</p>
<p>단순한 객체 탐지를 넘어, 장면 전체를 총체적으로 이해하려는 멀티모달 연구 또한 활발했다. ’SceneVerse’는 접지된(grounded) 3D 장면 이해를 위해 3D 비전-언어 학습을 확장하는 것을 목표로 하며, ’Grounding DINO’는 트랜스포머 기반 탐지기를 접지된 사전 학습과 결합하여 이전에 보지 못한 객체도 탐지할 수 있는 개방형 집합(open-set) 객체 탐지 능력을 선보였다.8</p>
<h4>2.2.3  의료 및 특수 분야 응용</h4>
<p>주류 비전 기술을 데이터가 부족한 특수 분야에 적용하려는 노력도 주목받았다. ’AnatoMask’는 3D 의료 영상 분할을 위한 새로운 자기 지도 학습(self-supervised learning) 방법으로, 해부학적으로 중요한 영역을 지능적으로 마스킹하여 제한된 데이터에서도 사전 학습 효율을 높이는 방법을 제안했다.12 이는 고도의 전문성이 요구되는 분야에서 AI의 활용 가능성을 넓히는 중요한 연구다.</p>
<h4>2.2.4  심층 분석: ECCV 2024 최우수 논문 - “자유형 픽셀을 이용한 미니멀리스트 비전”</h4>
<p>이번 ECCV에서 최우수 논문상을 수상한 컬럼비아 대학의 Klotz와 Nayar의 연구는 기존 컴퓨터 비전의 패러다임에 근본적인 질문을 던지는 혁신적인 성과로 평가된다.13 이 연구는 균일한 격자 형태의 사각형 픽셀을 사용하는 전통적인 카메라 대신, 특정 비전 과제 해결에 필요한 최소한의 픽셀만을 사용하되, 각 픽셀이 임의의 모양을 가질 수 있는 ‘자유형 픽셀(freeform pixels)’ 개념을 제안했다.</p>
<p>핵심 방법론은 카메라의 물리적 하드웨어(픽셀 모양을 결정하는 광학 마스크)를 신경망의 첫 번째 레이어로 모델링하는 것이다. 이후의 레이어는 특정 과제(예: 교통량 추정)를 위해 학습되며, 이 과정에서 역전파를 통해 최적의 픽셀 모양이 결정된다. 이 연구는 단 8개의 픽셀만으로 실내 공간 모니터링, 조명 측정, 교통 흐름 추정 등의 작업을 기존 카메라와 비슷한 성능으로 수행할 수 있음을 입증했다.</p>
<p>이 접근법은 세 가지 주요 장점을 가진다. 첫째, <strong>효율성</strong>: 수백만 개의 픽셀 대신 단 몇 개의 픽셀만 사용하므로 데이터 처리량이 극적으로 감소한다.13 둘째, <strong>프라이버시</strong>: 캡처되는 정보 자체가 최소화되어 개인의 시각적 세부 정보를 복원하는 것이 불가능하므로 본질적으로 프라이버시를 보호한다.13 셋째, <strong>자체 전원 구동</strong>: 데이터 측정 및 처리량이 매우 적기 때문에 외부 전원이나 배터리 없이 자체적으로 전력을 수급하여 작동할 수 있다.15</p>
<p>이 최우수 논문 수상은 컴퓨터 비전 연구의 초점이 순수한 소프트웨어 및 알고리즘 개발에서 하드웨어와 소프트웨어를 함께 최적화하는 ‘공동 설계(co-design)’ 접근법으로 이동할 수 있음을 시사하는 중요한 신호다. 이는 단순히 기존 센서가 수집한 데이터를 처리하는 더 좋은 네트워크를 만드는 것을 넘어, 센서 자체를 재고함으로써 효율성과 성능의 근본적인 혁신을 이룰 수 있다는 가능성을 보여준다. 대규모 파운데이션 모델이 방대한 데이터를 처리하는 ‘더 크게, 더 좋게(bigger is better)’ 경향에 맞서, 미니멀리스트 비전은 물리적 수준에서 가장 중요한 정보만을 포착하는, 궁극적인 형태의 ‘어텐션’ 메커니즘을 제안한다. 이는 전력, 비용, 프라이버시가 핵심 제약 조건인 엣지 AI, 사물 인터넷(IoT), 로봇 공학 분야에 막대한 영향을 미칠 수 있는 새로운 연구 흐름의 시작을 예고한다.</p>
<h2>3.  산업계 주요 연구 및 기술 발표</h2>
<p>2024년 9월, 주요 산업계 AI 연구소들은 파운데이션 모델의 역량을 확장하는 동시에, 기술의 신뢰성과 안전성을 확보하려는 이중적인 전략을 명확히 보여주었다. 메타는 비전 기능을 탑재한 새로운 라마(Llama) 모델을 공개하며 역량 경쟁을 주도했고, OpenAI는 모델 환각(hallucination) 현상의 근본 원인을 파헤치는 연구를 통해 신뢰성 문제에 정면으로 대응했다. 구글은 개발자 생태계에 AI를 깊숙이 통합하며 기술의 보편화를 가속화했다.</p>
<h3>3.1  메타 AI: Llama 3.2를 통한 멀티모달 비전 확장</h3>
<p>9월 25일 개최된 ’커넥트 2024(Connect 2024)’에서 메타는 자사의 오픈소스 모델 제품군에 중대한 업데이트인 Llama 3.2를 발표했다.16 가장 핵심적인 변화는 ‘비전(vision)’ 기능의 추가다. Llama 3.2는 메타의 첫 번째 주요 비전-언어 모델(VLM)로서, 텍스트와 이미지를 동시에 이해하고 처리할 수 있는 능력을 갖추었다.17 이를 통해 사용자는 업로드한 사진에 대해 질문하거나(예: 꽃 이름 식별, 음식 사진으로 레시피 생성), 사진 속 요소를 자연어 명령으로 편집하는 등 새로운 차원의 상호작용을 경험할 수 있게 되었다.17</p>
<p>또한, Llama 3.2는 10억 개(1B) 매개변수 수준의 경량 모델을 포함하여, 클라우드 의존도를 줄이고 기기 자체에서 AI를 구동하는 ‘온디바이스 AI(on-device AI)’ 전략을 가속화했다.16 이러한 기술 발전은 새로운 위험을 수반한다는 인식하에, 시각적 콘텐츠를 검토하는 Llama Guard Vision과 같은 안전 도구와 업데이트된 책임감 있는 사용 가이드(Responsible Use Guide)가 함께 배포되었다.16</p>
<p>이러한 AI 역량은 페이스북, 인스타그램, 왓츠앱 등 메타의 핵심 제품군에 깊숙이 통합되고 있다. 사진에 대한 캡션을 자동으로 제안하거나, AI가 채팅방 테마를 생성하고, 레이밴(Ray-Ban) 스마트 안경에서 실시간 번역을 제공하는 등의 기능이 대표적이다.17</p>
<h3>3.2  OpenAI: 언어 모델 신뢰성에 대한 심층 탐구</h3>
<p>OpenAI는 9월에 새로운 모델 출시보다는 AI 기술의 근본적인 신뢰성과 안전성 문제에 집중하는 모습을 보였다. 특히, 모델이 자신감 있게 틀린 정보를 생성하는 ‘환각(hallucination)’ 현상에 대한 심층 연구 논문을 발표하여 큰 주목을 받았다.19</p>
<p>이 연구의 핵심 주장은 환각이 현재의 표준적인 모델 훈련 및 평가 방식의 필연적인 결과라는 것이다. 대부분의 평가 벤치마크는 ’정확도’를 최우선으로 측정하는데, 이는 모델이 불확실한 질문에 대해 ’모르겠다’고 답하는 것(기권)보다 ’추측’을 하도록 유도한다. 기권은 0점을 보장하지만, 추측은 정답일 확률이 있기 때문이다. 이러한 평가 방식이 체계적으로 모델을 과신하도록 훈련시킨다는 것이 연구의 골자다. 이에 대한 해결책으로, OpenAI는 기권보다 자신감 있는 오류에 더 큰 페널티를 부과하여, 모델이 ’겸손함’과 보정된 불확실성을 표현하도록 보상하는 방향으로 평가 지표를 재설계해야 한다고 주장했다.19</p>
<p>이러한 기초 연구와 더불어, OpenAI는 플랫폼의 안전성을 강화하기 위한 실질적인 조치도 단행했다. 청소년 사용자의 안전을 위해 부모가 계정을 연동하여 유해 콘텐츠를 필터링하고, 사용 시간을 제한하며, 심각한 정신적 고통의 징후가 감지될 경우 알림을 받는 ’자녀 보호 기능’을 도입했다.20 또한, 대화 내용을 기억하여 맥락을 유지하는 ‘메모리’ 기능을 무료 사용자를 포함한 모든 사용자에게 확대 적용했다.21</p>
<h3>3.3  구글 AI: 온디바이스 인텔리전스 생태계 육성</h3>
<p>구글의 9월 동향은 단일 모델 출시보다는, 개발자 생태계를 강화하고 AI를 기존 플랫폼 전반에 통합하는 데 초점을 맞춘 전략을 보여준다.22 핵심적인 발표는 가장 효율적인 온디바이스 모델인 ’제미니 나노(Gemini Nano)’를 위한 새로운 실험적 API의 공개였다. 긴 글을 요약하는 API나 100개 이상의 언어를 감지하는 API가 크롬 브라우저에서 직접 실행될 수 있도록 지원함으로써, 오프라인 환경에서도 저지연으로 강력한 AI 기능을 사용할 수 있는 길을 열었다.22</p>
<p>이러한 전략은 Project IDX(브라우저 기반 통합 개발 환경)나 플러터(Flutter), 다트(Dart)와 같은 개발자 도구 및 프레임워크에 AI 기능을 내장하는 방식으로 구체화되고 있다.22 이는 AI를 구글 생태계 내 모든 개발자를 위한 기본적인 구성 요소로 만들려는 의도를 보여준다. 안드로이드 15 출시 역시 이러한 흐름의 연장선상에서, 특히 폴더블폰과 같은 새로운 폼팩터에 최적화된 미디어 경험과 사용자 인터페이스를 제공하는 데 중점을 두었다.22</p>
<p>이처럼 2024년 9월 산업계의 움직임은 AI 전략의 분화를 명확히 보여준다. 한편에서는 메타의 Llama 3.2처럼 비전과 같은 새로운 양식을 추가하려는 ’역량 경쟁’이 치열하게 벌어지고 있다. 다른 한편에서는 OpenAI의 안전성 연구와 구글의 개발자 API처럼 기존 AI를 더 안전하고, 신뢰할 수 있으며, 개발자들이 쉽게 활용할 수 있도록 만드는 ’신뢰성 및 생태계 경쟁’이 심화되고 있다. 이러한 전략적 차이는 각 기업의 시장 위치를 반영한다. 오픈소스 분야에서 경쟁하는 메타는 폐쇄형 모델의 역량에 필적하거나 이를 넘어서야 할 필요가 있다. 시장 선두주자인 OpenAI는 기업 고객 확보의 가장 큰 장벽인 신뢰와 안전 문제를 해결해야 한다. 그리고 지배적인 모바일 OS와 개발자 생태계를 보유한 구글은 AI를 어디에나 존재하고 쉽게 통합할 수 있도록 만드는 것에서 승기를 잡을 수 있다. 이는 미래 AI 시장의 승자가 단 하나의 가장 강력한 모델이 아니라, 가장 안전하고, 가장 효율적이며, 최고의 개발자 도구를 갖춘 모델들의 연합체가 될 수 있음을 시사한다.</p>
<h2>4.  주요 연구 기관의 핵심 연구 성과</h2>
<p>최고 수준의 대학 연구소들은 기술 혁신의 원동력이자, 그 기술이 사회에 미칠 영향을 비판적으로 분석하는 중요한 역할을 수행한다. 2024년 9월, MIT는 AI의 위험을 체계적으로 분류하는 프레임워크를 제시하며 거버넌스의 기틀을 마련했고, 스탠퍼드는 AI 인덱스 보고서를 통해 글로벌 트렌드를 데이터 기반으로 분석하는 동시에 다양한 학문 분야에 AI를 접목하는 성과를 보여주었다.</p>
<h3>4.1  MIT CSAIL: AI 안전 설계 및 생성형 AI의 응용</h3>
<p>MIT 컴퓨터 과학 및 인공지능 연구소(CSAIL)는 최첨단 기술 개발과 함께 AI의 사회적 영향에 대한 깊이 있는 분석을 지속적으로 발표하고 있다.</p>
<h4>4.1.1  포괄적인 AI 위험 프레임워크</h4>
<p>MIT CSAIL과 MIT FutureTech 소속 연구진들은 기존의 AI 위험 관리 프레임워크들을 종합적으로 검토한 결과, 상당한 공백이 존재하며 가장 포괄적인 단일 프레임워크조차 식별된 전체 위험의 약 30%를 누락하고 있음을 발견했다.23 이에 연구진은 기존 연구들을 종합하여 7개의 상위 도메인과 23개의 하위 도메인으로 구성된 통합된 ’AI 위험 분류 체계(Taxonomy)’를 제안했다. 이 분류 체계는 ‘차별 및 유해성’, ‘오보’, ’악의적 행위자’와 같은 상위 범주와 ‘불공정한 차별’, ‘과도한 의존 및 불안전한 사용’, ’인간의 목표와 상충되는 AI 목표 추구’와 같은 구체적인 하위 위험을 포함한다.23 이 연구는 연구자, 정책 입안자, 산업계가 AI 위험을 논의하고 완화하기 위한 표준화된 공통 언어를 제공했다는 점에서 매우 중요한 의미를 가진다.</p>
<h4>4.1.2 표 2: MIT가 제안한 AI 위험 분류 체계</h4>
<table><thead><tr><th>위험 도메인</th><th>하위 도메인 예시</th><th>설명</th><th>출처</th></tr></thead><tbody>
<tr><td>1. 차별 및 유해성</td><td>1.1. 불공정한 차별 및 왜곡된 표현</td><td>AI 시스템이 특정 집단에 대해 편향된 결정을 내리는 경우</td><td>23</td></tr>
<tr><td>2. 프라이버시 및 보안</td><td>2.1. 민감 정보 유출 또는 추론을 통한 프라이버시 침해</td><td>AI 모델이 학습 데이터에 포함된 개인 정보를 의도치 않게 노출하는 경우</td><td>23</td></tr>
<tr><td>3. 오보</td><td>3.1. 허위 또는 오해의 소지가 있는 정보</td><td>AI가 설득력 있지만 사실이 아닌 텍스트, 이미지, 비디오를 생성하는 경우</td><td>23</td></tr>
<tr><td>4. 악의적 행위자 및 오용</td><td>4.2. 사이버 공격, 무기 개발 또는 사용</td><td>AI를 사용하여 새로운 악성코드를 만들거나, 무기를 설계하거나, 공격을 자동화하는 경우</td><td>23</td></tr>
<tr><td>5. 인간-컴퓨터 상호작용</td><td>5.1. 과도한 의존 및 불안전한 사용</td><td>인간이 AI 시스템에 지나치게 의존하여 기술 저하 또는 사고로 이어지는 경우</td><td>23</td></tr>
<tr><td>6. 사회경제 및 환경</td><td>6.2. 불평등 심화 및 고용의 질 저하</td><td>AI가 일자리를 대체하거나 부와 권력을 특정 집단에 집중시키는 경우</td><td>23</td></tr>
<tr><td>7. AI 시스템 안전, 실패 및 한계</td><td>7.1. 인간의 목표나 가치와 상충되는 AI 목표 추구</td><td>발전된 AI 시스템이 주어진 목표를 최적화하는 과정에서 해로운 부작용을 낳는 경우</td><td>23</td></tr>
</tbody></table>
<h4>4.1.3  로봇 공학을 위한 생성형 AI 활용</h4>
<p>MIT 연구진들은 생성형 AI를 사용하여 로봇을 위한 가상 훈련 환경을 다양화하는 연구를 발표했다.24 이는 로봇 학습의 주요 병목 현상 중 하나인, 다양하고 현실적인 시뮬레이션 환경 구축의 어려움을 해결하기 위한 것이다. 생성형 AI를 활용함으로써, 수작업으로 설계하는 것보다 훨씬 더 광범위한 시나리오를 자동으로 생성할 수 있게 되었고, 이를 통해 훈련된 로봇 정책의 강인성(robustness)과 일반화 성능을 향상시킬 수 있다.</p>
<h3>4.2  스탠퍼드 HAI: 글로벌 동향 정량화 및 학제 간 응용 주도</h3>
<p>스탠퍼드 인간 중심 AI 연구소(HAI)는 글로벌 AI 지형을 추적하고, 다양한 학문 분야에 AI 기술을 접목하는 데 선도적인 역할을 하고 있다.</p>
<h4>4.2.1  2025 AI 인덱스 보고서 - 주요 결과</h4>
<p>매년 발표되는 AI 인덱스 보고서는 데이터에 기반하여 AI 분야의 현주소를 보여주는 중요한 자료다.25 2024년에 발표된 보고서의 주요 내용은 다음과 같다.</p>
<ul>
<li><strong>투자</strong>: 미국은 민간 AI 투자에서 1,091억 달러로 압도적인 선두를 유지하며, 중국(93억 달러)과 영국(45억 달러)을 크게 앞질렀다. 특히 생성형 AI 분야의 투자가 급증했다.</li>
<li><strong>성능</strong>: AI는 일부 벤치마크에서 인간의 성능을 능가하기 시작했으며, 주요 벤치마크에서 미국과 중국 모델 간의 성능 격차는 거의 동등한 수준으로 좁혀졌다.</li>
<li><strong>채택</strong>: AI는 일상생활에 빠르게 스며들고 있다. 2024년에는 조직의 78%가 AI를 사용한다고 보고했으며(2023년 55%에서 증가), 2023년 한 해에만 미국 FDA가 223개의 AI 기반 의료 기기를 승인했다.</li>
<li><strong>책임</strong>: AI 관련 사고는 급격히 증가하고 있지만, 개발사들 사이에서 표준화된 책임 있는 AI(RAI) 평가는 여전히 드물다. 반면, 각국 정부는 AI 거버넌스에 대한 국제 협력을 강화하고 있다.</li>
</ul>
<h4>4.2.2  다양한 분야에서의 AI 응용</h4>
<p>스탠퍼드 연구진들은 AI를 광범위한 분야에 적용하며 그 가능성을 확장하고 있다.26</p>
<ul>
<li><strong>광업</strong>: AI를 사용하여 역사적인 손으로 그린 지도를 포함한 지질 데이터를 분석하고, 이를 통해 새로운 광물 자원을 더 지속 가능하고 효율적으로 발견하고 있다.</li>
<li><strong>기후 과학</strong>: 대기 중력파가 기후에 미치는 영향을 더 정확하게 모델링하기 위해 AI를 사용하여 전 지구 기후 모델의 정확도를 높이고 있다.</li>
<li><strong>법률</strong>: 양질의 법률 서비스에 대한 접근성을 높이고 비용을 절감하기 위한 AI 도구를 개발하고 있다.</li>
<li><strong>의료</strong>: 피부과 및 기타 의료 분야를 위한 AI 도구를 개발하고 테스트하는 동시에, 환자 데이터 편향이나 사용자에게 듣고 싶은 말을 해주는 ‘아첨꾼’ 행동과 같은 잠재적 결함에 대해 비판적으로 연구하고 있다.</li>
</ul>
<p>이러한 대학들의 연구 활동은 거시적 분석과 미시적 해결책 사이의 중요한 상호 보완 관계를 보여준다. 스탠퍼드의 AI 인덱스가 ’AI 관련 사고’의 급증이라는 정량적 데이터를 제시하면 25, MIT의 위험 프레임워크는 그 사고들이 구체적으로 무엇인지(예: 오보, 프라이버시 침해, 차별)를 체계적으로 분류하고 이해할 수 있는 정성적 틀을 제공한다.23 스탠퍼드의 보고서가 ’불이 커지고 있다’는 사실을 보여준다면, MIT의 보고서는 ’소화기를 어떻게 설계해야 하는가’에 대한 청사진을 제시하는 셈이다. 이러한 학술적 연구는 효과적인 규제와 정책 수립에 필수적인 정보를 제공하며, 상업적 압력에서 비교적 자유로운 대학이 AI의 사회적 영향에 대한 공정하고 장기적인 연구를 수행하는 독자적인 역할을 하고 있음을 증명한다.</p>
<h2>5.  주요 arXiv 논문 심층 분석</h2>
<p>2024년 9월 arXiv에 공개된 사전 인쇄(pre-print) 논문들에서는 로봇 공학의 오랜 숙원인 ‘일반화(generalization)’ 문제에 대한 중요한 진전이 두드러졌다. 특히, 특정 작업이나 환경에 대한 미세 조정(fine-tuning) 없이, 이전에 경험하지 못한 새로운 환경에서도 즉시 임무를 수행할 수 있는 ‘일반화된 로봇 정책(generalist robot policies)’ 개발이 핵심 주제로 부상했다.</p>
<h3>5.1  로봇 제어의 일반화를 향한 여정</h3>
<p>현재 로봇 공학의 가장 큰 한계 중 하나는 ’일반화 격차(generalization gap)’다. 특정 환경에서 훈련된 정책이 다른 환경에서는 급격한 성능 저하를 보이는 이 문제를 해결하기 위해, 9월에 발표된 ’Neural MP’와 ’Robot Utility Models’는 데이터 중심의 새로운 접근법을 제시했다.</p>
<h4>5.1.1  Neural MP: 일반화된 신경망 모션 플래너</h4>
<ul>
<li><strong>문제 정의</strong>: 전통적인 모션 플래너는 완전한 환경 정보가 필요하고 속도가 느리며, 기존의 신경망 기반 정책은 새로운 장면에 대한 일반화에 어려움을 겪는다.27</li>
<li><strong>핵심 방법론</strong>: ’Neural MP’는 느리지만 정확한 전문가 플래너의 지식을 빠르고 반응적인 일반화 신경망 정책으로 증류하는 3단계 파이프라인을 제안했다.27</li>
</ul>
<ol>
<li><strong>대규모 절차적 데이터 생성</strong>: 시뮬레이션 환경을 수작업으로 만드는 대신, 선반이나 캐비닛과 같은 파라미터화된 객체와 대규모 3D 데이터셋의 모델을 사용하여 수백만 개의 다양한 장면을 절차적으로 생성한다. 이를 통해 정책이 방대한 시각적, 구조적 변화에 노출되도록 보장한다.27</li>
<li><strong>일반화 신경망 정책</strong>: 이 환경들에서 생성된 전문가 경로 데이터를 사용하여 순환 신경망(LSTM)을 훈련시킨다. 모델은 환경의 포인트 클라우드를 입력받아 경로를 출력하는데, 이때 출력층으로 가우시안 혼합 모델(GMM)을 사용하여 여러 개의 가능한 최적 경로(multi-modal solutions)를 효과적으로 모델링한다.29</li>
<li><strong>테스트 시점 최적화</strong>: 안전한 배포를 위해, 훈련된 정책은 단일 예측 경로를 그대로 실행하지 않는다. 대신 여러 경로를 샘플링한 후, 부호 거리 함수(SDF)를 이용한 경량 최적화 단계를 거쳐 가장 안전하고 충돌 없는 경로를 선택한다.29</li>
</ol>
<ul>
<li><strong>결과</strong>: 이 방법은 실제 로봇 테스트에서 95.83%의 높은 성공률을 달성했으며, 기존 방법들보다 수십 배 빠른 속도를 보이면서도 뛰어난 일반화 성능을 입증했다.27</li>
</ul>
<h4>5.1.2  Robot Utility Models (RUMs): 제로샷 배포를 위한 일반 정책</h4>
<ul>
<li><strong>문제 정의</strong>: 일반적인 가정 내 과업(문 열기, 서랍 열기 등)을 수행하는 로봇 정책을 어떻게 하면 어떠한 새로운 가정 환경에서도 추가적인 훈련 없이 ‘즉시(out-of-the-box)’ 작동하도록 만들 수 있는가.30</li>
<li><strong>핵심 방법론</strong>: ’RUMs’는 데이터 수집부터 배포까지 전 과정을 아우르는 ‘시스템 우선(systems-first)’ 프레임워크를 제안했다.30</li>
</ul>
<ol>
<li><strong>확장 가능한 데이터 수집</strong>: 단돈 25달러의 재료비로 제작 가능한 휴대용 데이터 수집 도구 ’Stick-v2’를 개발했다. 이를 통해 한 명의 작업자가 여러 다양한 환경에서 고품질의 시연 데이터를 신속하게 수집할 수 있도록 했다. 연구진은 데이터의 양보다 ’다양성’이 일반화의 핵심임을 강조했다.30</li>
<li><strong>멀티모달 모방 학습</strong>: 이 다양한 데이터를 사용하여 VQ-BeT와 확산 정책(Diffusion Policy) 등 여러 아키텍처를 테스트했으며, 특정 모델 아키텍처보다 데이터의 양과 다양성이 성능에 더 결정적인 영향을 미친다는 사실을 발견했다.30</li>
<li><strong>mLLM 기반 검증 및 재시도</strong>: 로봇이 임무를 수행한 후, 외부의 멀티모달 대규모 언어 모델(mLLM)이 그 결과를 관찰하고 성공 여부를 판단한다. 만약 실패했다고 판단하면, mLLM은 로봇에게 초기 상태로 돌아가 재시도하도록 지시한다. 이 ‘자기 비판’ 메커니즘은 성공률을 74.4%에서 90%로 크게 향상시켰다.31</li>
</ol>
<ul>
<li><strong>결과</strong>: 이 시스템은 25개의 처음 보는 새로운 환경에서 5가지 과업에 대해 평균 90%의 성공률을 달성하며, 진정한 의미의 ‘제로샷(zero-shot)’ 일반화 능력을 증명했다.30</li>
</ul>
<p>이 두 연구의 성공은 로봇 공학 연구의 패러다임이 ’더 나은 알고리즘’에서 ’더 나은 데이터 엔진’으로 전환되고 있음을 강력하게 시사한다. Neural MP의 핵심 혁신이 절차적 장면 생성 파이프라인에 있고, RUMs의 핵심 혁신이 ’Stick-v2’라는 데이터 수집 도구와 방법론에 있다는 점은 이를 명확히 보여준다. 두 프로젝트 모두 일반화의 가장 큰 병목이 모델이 아닌 ’데이터’에 있다고 진단하고, 데이터 문제를 해결하는 데 연구 역량을 집중했다. 이는 컴퓨터 비전과 자연어 처리 분야가 ImageNet과 같은 대규모 데이터셋을 통해 비약적인 발전을 이룬 것과 같은 맥락이다. 로봇 공학 역시 시공간적, 멀티모달 특성을 가진 복잡한 데이터를 대규모로 구축하는 ’ImageNet 모멘트’를 맞이하고 있으며, 이 논문들은 그 기반 인프라를 개척하고 있다. 따라서 미래 로봇 공학 연구의 성패는 순수한 알고리즘 설계 능력뿐만 아니라, 학습 시스템에 다양하고 풍부한 경험을 효율적으로 공급할 수 있는 확장 가능한 ’데이터 엔진’을 구축하는 능력에 의해 좌우될 것이다.</p>
<h3>5.2  고급 제어 및 동적 모델링</h3>
<h4>5.2.1  쿠프만 동역학 모델링</h4>
<p>앞서 IROS 2024 섹션에서 논의된 바와 같이, 쿠프만 연산자 이론은 9월에 발표된 가장 중요한 이론적 성과 중 하나다.1 이 접근법의 핵심은 비선형적인 로봇 동역학 시스템</p>
<p>$ \dot{x} = f(x) $을 관측 가능한 함수들로 구성된 무한 차원의 함수 공간으로 ‘끌어올려(lift)’ 선형 동역학 시스템 $ \dot{g}(x) = \mathcal{K}g(x) $으로 변환하는 것이다. 여기서 <span class="math math-inline">\mathcal{K}</span>는 쿠프만 연산자다. 이를 통해 복잡한 비선형 제어 문제를 잘 알려진 선형 시스템 이론을 사용하여 해결할 수 있는 길을 열어주며, 특히 접촉과 같은 불연속적인 상호작용을 포함하는 시스템에 대한 통합적인 제어 프레임워크를 제공한다는 점에서 그 의의가 크다.</p>
<h2>6. 결론 및 향후 전망</h2>
<p>2024년 9월은 AI 및 로봇 공학 분야가 양적 성장을 넘어 질적 성숙의 단계로 진입하고 있음을 보여준 한 달이었다. 생성형 AI는 ECCV와 메타의 발표에서 보듯이 시각적 영역으로 그 역량을 폭발적으로 확장했으며, 동시에 OpenAI와 MIT의 연구는 기술의 근본적인 한계와 위험을 냉철하게 분석하며 책임감 있는 발전을 모색했다. 로봇 공학 분야에서는 arXiv에 등장한 선구적인 연구들을 통해, 오랫동안 이론에 머물렀던 ’범용 로봇’의 꿈이 제로샷 일반화라는 구체적인 성과를 통해 현실로 한 걸음 다가왔다.</p>
<p>종합적으로, 이 분야는 ’존재 증명’의 단계를 지나 ’견고한 배포’의 시대로 이동하고 있다. 즉, 특정 작업을 수행할 수 있음을 보이는 것을 넘어, 어떠한 환경에서도 안정적이고 안전하게 임무를 수행할 수 있음을 증명하는 것이 새로운 과제로 부상했다. 연구의 초점은 모델 아키텍처 자체에서 데이터, 평가, 그리고 안전성으로 옮겨가고 있다.</p>
<p>이러한 분석을 바탕으로 다음과 같은 미래 연구 방향을 예측할 수 있다.</p>
<ol>
<li><strong>하드웨어-소프트웨어 공동 설계의 부상</strong>: ECCV 최우수 논문인 ’미니멀리스트 비전’에서 영감을 받아, 물리적 센서와 신경망 알고리즘을 함께 최적화하는 연구가 활발해질 것이다. 이는 초고효율 및 프라이버시를 보장하는 엣지 디바이스의 개발로 이어질 것이다.</li>
<li><strong>‘데이터 엔진’ 군비 경쟁</strong>: 일반화된 로봇 정책의 성공은 최고의 데이터 수집 및 시뮬레이션 플랫폼을 구축하기 위한 경쟁을 촉발할 것이다. ’Stick-v2’와 같은 데이터 수집 도구나 절차적 환경 생성 기술의 오픈소스화는 모델 자체를 공개하는 것만큼 중요해질 것이다.</li>
<li><strong>AI 안전성의 공식화</strong>: OpenAI의 평가 방식 비판과 MIT의 위험 프레임워크는 새로운 세대의 ‘책임 있는 AI’ 벤치마크 개발을 이끌 것이다. 이 벤치마크들은 단순한 정확도를 넘어 모델의 보정(calibration), 정직성, 강인성을 측정하며, 모델 평가의 표준 절차로 자리 잡을 것이다.</li>
<li><strong>멀티모달리티의 기본화</strong>: Llama와 같은 주요 오픈소스 모델에 비전 기능이 통합됨에 따라, 멀티모달리티는 더 이상 특수한 기능이 아닌 모든 파운데이션 모델의 기본 사양이 될 것이다. 다음 격전지는 음성, 촉각, 고유수용성감각 등 더 많은 감각 정보를 통합하여 진정으로 체화된(embodied) 에이전트를 구현하는 것이 될 것이다.</li>
</ol>
<h2>7. 참고 자료</h2>
<ol>
<li>Papers to be Presented at IROS 2024 - MIT d’Arbeloff Lab, https://darbelofflab.mit.edu/papers-to-be-presented-at-iros-2024/</li>
<li>AI Conference Deadlines, https://aideadlin.es/</li>
<li>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024) Accepted paper. Accepted June 2024. © 2024 - Mizuho AOKI, https://mizuhoaoki.github.io/media/papers/IROS2024_paper_mizuhoaoki.pdf</li>
<li>IROS-2024, https://iros-2024.netlify.app/</li>
<li>Robotics Sep 2024 - arXiv, https://www.arxiv.org/list/cs.RO/2024-09?show=2000&amp;skip=150</li>
<li>Robotics Sep 2024 - arXiv, https://www.arxiv.org/list/cs.RO/2024-09?skip=300&amp;show=2000</li>
<li>2024 Dates and Deadlines - ECCV, https://eccv.ecva.net/Conferences/2024/Dates</li>
<li>Paper Digest: ECCV 2024 Papers &amp; Highlights, https://www.paperdigest.org/2024/09/eccv-2024-highlights/</li>
<li>Most Influential ECCV Papers (2024-09 Version) - Paper Digest, https://www.paperdigest.org/2024/09/most-influential-eccv-papers-2024-09/</li>
<li>ECCV 2024 Papers, https://eccv.ecva.net/virtual/2024/papers.html</li>
<li>ECCV 2024 Accepted Papers | MMLab@NTU, https://www.mmlab-ntu.com/conference/eccv2024/index.html</li>
<li>ECCV 2024 – Research Impact &amp; Leadership - Georgia Institute of Technology, https://sites.gatech.edu/research/eccv-2024/</li>
<li>ECCV 2024 Awards, https://eccv.ecva.net/virtual/2024/awards_detail</li>
<li>Minimalist Vision with Freeform Pixels - ResearchGate, https://www.researchgate.net/publication/387670934_Minimalist_Vision_with_Freeform_Pixels</li>
<li>Outstanding Research and Best Paper Honors at ECCV 2024 - Columbia CS, https://www.cs.columbia.edu/2024/outstanding-research-and-best-paper-honors-at-eccv-2024/</li>
<li>Connect 2024: The responsible approach we’re taking to generative AI, https://ai.meta.com/blog/responsible-ai-connect-2024/</li>
<li>Meta Connect 2024: Quest 3S, Llama 3.2, &amp; More, https://www.meta.com/blog/connect-2024-keynote-recap-quest-3s-llama-3-2-ai-wearables-mixed-reality/</li>
<li>Meta Quest+ September 2024: New Titles, Additions to the Games Catalog, &amp; More, https://www.meta.com/blog/meta-quest-plus-zero-caliber-we-are-one-arizona-sunshine-synth-riders/</li>
<li>Why language models hallucinate | OpenAI, https://openai.com/index/why-language-models-hallucinate/</li>
<li>One Tech Tip: OpenAI adds parental controls to ChatGPT for teen safety, https://apnews.com/article/openai-chatgpt-chatbot-ai-online-safety-1e7169772a24147b4c04d13c76700aeb</li>
<li>Memory and new controls for ChatGPT - OpenAI, https://openai.com/index/memory-and-new-controls-for-chatgpt/</li>
<li>September 2024 - Newsletter - Google for Developers, https://developers.google.com/newsletter/2024/09</li>
<li>Global AI adoption is outpacing risk understanding, warns MIT CSAIL, https://www.csail.mit.edu/news/global-ai-adoption-outpacing-risk-understanding-warns-mit-csail</li>
<li>News - MIT CSAIL, https://www.csail.mit.edu/news</li>
<li>The 2025 AI Index Report | Stanford HAI, https://hai.stanford.edu/ai-index/2025-ai-index-report</li>
<li>Stanford researchers use AI to push the boundaries of what’s possible, https://news.stanford.edu/stories/2025/09/ai-applications-campus-robotics-mining-nueroscience-law</li>
<li>Neural MP: A Generalist Neural Motion Planner - arXiv, https://arxiv.org/html/2409.05864v1</li>
<li>Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments - arXiv, https://arxiv.org/html/2509.06953v1</li>
<li>[Literature Review] Neural MP: A Generalist Neural Motion Planner - Moonlight, https://www.themoonlight.io/en/review/neural-mp-a-generalist-neural-motion-planner</li>
<li>Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments, https://arxiv.org/html/2409.05865v1</li>
<li>Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments, https://robotutilitymodels.com/</li>
<li>(PDF) Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments - ResearchGate, https://www.researchgate.net/publication/383911788_Robot_Utility_Models_General_Policies_for_Zero-Shot_Deployment_in_New_Environments</li>
<li>Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments, https://www.alphaxiv.org/overview/2409.05865v1</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>