<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2021년 1월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2021년 1월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2021년 AI 및 로봇 연구 동향</a> / <span>2021년 1월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2021년 1월 AI 및 로봇 연구 동향</h1>
<h2>1.  2021년 1월, 기술 변곡점의 서막</h2>
<p>2021년 1월은 인공지능(AI) 역사에서 중요한 변곡점으로 기록된다. GPT-3가 촉발한 거대 언어 모델(Large Language Model, LLM) 패러다임의 영향력이 학계와 산업계 전반으로 확산되는 가운데, OpenAI는 1월 5일 DALL-E를 발표하며 생성형 AI의 가능성을 텍스트의 영역에서 이미지로 폭발적으로 확장시켰다.1 이는 단순한 기술 발표를 넘어, AI가 분석과 분류를 넘어 창작의 영역으로 진입했음을 알리는 신호탄이었다. 동시에, 미국 정부는 1월 1일부로 ’국가 인공지능 이니셔티브(National AI Initiative)’를 공식 출범시키며 AI 기술을 국가 경쟁력의 핵심으로 규정하고 대규모 연구개발(R&amp;D) 투자를 본격화했다.4 이는 AI 기술의 발전이 더 이상 학문적 탐구의 대상을 넘어 경제, 안보, 국제 정치의 핵심 변수가 되었음을 명백히 보여준다.</p>
<p>로봇공학 분야에서도 지능의 본질에 대한 탐구가 심화되었다. OpenAI는 1월 13일 제출된 논문을 통해 강화학습 기반의 ‘비대칭적 자기-대국(Asymmetric Self-play)’ 방법론을 제시하며, 로봇이 인간의 명시적인 지시나 보상 설계 없이도 복잡한 조작(manipulation) 기술을 자율적으로 학습할 수 있는 새로운 지평을 열었다.6 이 세 가지 이정표적 사건들은 개별적인 성과가 아니라, 지난 수년간 축적된 컴퓨팅 파워, 대규모 데이터셋의 가용성, 그리고 Transformer와 같은 범용 아키텍처의 성숙이 임계점을 넘어 여러 분야에서 동시에 혁신을 촉발시킨 결과로 해석해야 한다. 강력한 AI 모델의 등장이 국가적 투자를 유도하고, 이러한 투자는 다시 AI 모델을 물리적 세계로 확장시키는 연구를 가속화하는 선순환, 혹은 경쟁 구도가 2021년 1월을 기점으로 명확히 드러나기 시작했다.</p>
<p>본 보고서는 2021년 1월에 발표된 이정표적 연구들을 심층 분석하고, 이들이 당시의 기술 지형도에 어떤 의미를 가지며, 이후 AI 및 로봇공학의 연구 방향성에 어떠한 영향을 미쳤는지 다각적으로 조망하고자 한다.</p>
<h2>2.  텍스트와 이미지의 경계를 허문 혁신: DALL-E 심층 분석</h2>
<p>2021년 1월 5일, OpenAI는 텍스트 설명으로부터 이미지를 생성하는 신경망 DALL-E를 공개하며 AI 연구 커뮤니티에 큰 파장을 일으켰다.2 DALL-E는 AI가 정보 처리 도구를 넘어 창의적 파트너가 될 수 있다는 가능성을 대중과 연구계에 각인시킨 상징적인 사건이었으며, 이후 ChatGPT로 이어지는 생성형 AI 시대의 본격적인 서막을 열었다.9</p>
<h3>2.1  DALL-E의 기술적 토대와 작동 원리</h3>
<p>DALL-E의 가장 심오한 기여는 ’모든 것은 토큰 시퀀스’라는 아이디어를 시각 데이터에 성공적으로 적용한 데 있다. 이는 Transformer 아키텍처가 특정 데이터 유형(domain)에 구애받지 않는 범용 계산 엔진(universal computation engine)이 될 수 있음을 증명한 것이다. DALL-E는 본질적으로 120억 개의 파라미터를 가진 GPT-3의 변종으로, 텍스트 토큰 시퀀스를 예측하는 대신 이미지 토큰 시퀀스를 생성하도록 훈련되었다.3 이로써 이미지 생성 문제는 ’시각적 문장’을 완성하는 언어 모델링 문제로 성공적으로 치환되었다.</p>
<p>DALL-E는 단일 모델이 아닌, 세 가지 핵심 구성 요소가 유기적으로 결합된 시스템이다.8</p>
<ol>
<li>
<p><strong>이산적 변분 오토인코더 (dVAE):</strong> 첫 번째 핵심 요소는 이미지를 Transformer가 처리할 수 있는 형태로 변환하는 dVAE이다. 256x256 픽셀의 RGB 이미지는 dVAE를 통해 32x32 그리드의 ‘이미지 토큰’ 시퀀스로 압축된다. 각 토큰은 8192개의 코드북(vocabulary) 중 하나에 해당하는 이산적인 값으로, 연속적인 픽셀 공간을 이산적인 토큰 시퀀스로 변환하는 핵심적인 다리 역할을 수행한다.8 이 과정은 시각 데이터를 언어와 같은 이산적 단위로 ’번역’하는 과정에 비유할 수 있다.</p>
</li>
<li>
<p><strong>자기회귀 Transformer (Autoregressive Transformer):</strong> 시스템의 심장부에는 120억 개의 파라미터를 가진 디코더-전용(decoder-only) Transformer가 있다. 이 모델은 바이트 페어 인코딩(BPE)으로 토큰화된 최대 256개의 텍스트 토큰과 dVAE를 통해 생성된 이미지 토큰 시퀀스를 결합하여 입력으로 받는다. 그 후, 자기회귀 방식으로, 즉 이전에 생성된 토큰들을 바탕으로 다음 이미지 토큰을 순차적으로 예측하여 전체 1024개(32x32)의 이미지 토큰 시퀀스를 완성한다.3 이는 마치 언어 모델이 문맥을 바탕으로 다음 단어를 예측하여 문장을 완성하는 것과 동일한 원리다.</p>
</li>
<li>
<p><strong>CLIP (Contrastive Language-Image Pre-training):</strong> DALL-E가 생성한 다수의 이미지 후보군 중에서 주어진 텍스트 프롬프트와 가장 의미적으로 일치하는 이미지를 순위 매기고 선택하는 ‘평론가’ 역할을 CLIP이 수행한다.8 DALL-E와 함께 발표된 CLIP은 4억 개의 이미지-텍스트 쌍으로 사전 훈련되어, 텍스트와 이미지 간의 깊은 의미론적 연결을 이해하는 모델이다. DALL-E가 수많은 이미지를 생성하면, CLIP은 이 이미지들 각각에 대해 주어진 텍스트 캡션이 얼마나 적합한지를 평가하여 최상의 결과물을 선별한다. 이 생성(Generation)과 이해(Understanding) 모델의 결합은 DALL-E 시스템의 최종 결과물 품질을 극적으로 향상시키는 핵심적인 요소다.</p>
</li>
</ol>
<p><strong>표 1: DALL-E 아키텍처 구성 요소 및 역할</strong></p>
<table><thead><tr><th>구성 요소 (Component)</th><th>기술 (Technology)</th><th>핵심 역할 (Primary Role)</th><th>관련 자료</th></tr></thead><tbody>
<tr><td>인코더 (Encoder)</td><td>이산적 변분 오토인코더 (dVAE)</td><td>이미지를 이산적인 토큰 시퀀스로 압축 (이미지 토큰화)</td><td>8</td></tr>
<tr><td>생성기 (Generator)</td><td>자기회귀 Transformer (12B 파라미터)</td><td>텍스트 토큰을 조건으로 이미지 토큰 시퀀스를 예측 및 생성</td><td>3</td></tr>
<tr><td>필터/평가기 (Filter/Ranker)</td><td>CLIP (Contrastive Language-Image Pre-training)</td><td>생성된 이미지 중 텍스트 프롬프트와 가장 일치하는 결과 선별</td><td>8</td></tr>
</tbody></table>
<h3>2.2  DALL-E의 주요 역량과 한계</h3>
<p>DALL-E는 단순히 객체를 사실적으로 묘사하는 것을 넘어, 인간의 상상력에 필적하는 혁신적인 이미지 생성 능력을 선보였다. 서로 관련 없는 개념들을 그럴듯하게 결합하는 능력(“아보카도 모양의 안락의자”), 동물의 의인화(“투투를 입고 개를 산책시키는 아기 무”), 텍스트 렌더링, 기존 이미지에 대한 스타일 변형 적용 등은 모델이 단순한 패턴 매칭을 넘어 시각적 개념에 대한 추상적인 이해를 어느 정도 내재화했음을 시사했다.3</p>
<p>하지만 초기 모델로서 명확한 한계점도 존재했다. DALL-E는 캡션의 작은 변화에도 결과물이 크게 달라지는 취약성(brittleness)을 보였다. 특히, 여러 객체와 그 속성(예: “주황색과 흰색 폭격기 재킷과 주황색과 검은색 터틀넥 스웨터”)을 함께 제시했을 때, 객체와 속성 간의 연관 관계를 혼동하는 경향이 뚜렷하게 나타났다.3 이는 자기회귀 모델이 문장이나 이미지 전체에 걸친 장거리 의존성(long-range dependency)을 완벽하게 포착하는 데 여전히 어려움이 있음을 보여주는 사례다.</p>
<h3>2.3  생성형 AI 패러다임에 미친 영향</h3>
<p>DALL-E의 발표는 텍스트-이미지 생성 분야의 연구를 폭발적으로 촉발시키는 기폭제가 되었다. 1년 후인 2022년 4월에 발표된 DALL-E 2는 아키텍처를 자기회귀 Transformer에서 CLIP 임베딩을 조건으로 하는 확산 모델(diffusion model)로 변경하여, 해상도를 4배 높이고 사실성과 정확성을 극적으로 개선했다.2 DALL-E 2의 성공은 이후 Stability AI의 Stable Diffusion과 같은 강력한 오픈소스 텍스트-이미지 모델의 기술적 토대가 되었으며, 이는 생성형 AI 기술의 대중화를 이끌었다.</p>
<p>결론적으로 DALL-E는 Transformer의 적용 범위를 언어 너머의 세계로 확장할 수 있는 방법론적 청사진을 제시했다. 오디오, 비디오, 유전자 서열, 분자 구조 등 어떤 데이터든 적절한 ’토크나이저(tokenizer)’만 있다면 Transformer를 통해 모델링할 수 있다는 가능성을 연 것이다. 이는 AI 연구의 패러다임을 ’특화된 모델 설계’에서 ’범용 모델의 확장과 응용’으로 전환시키는 중요한 계기가 되었다.</p>
<h2>3.  인공지능 연구 지형의 확장과 심화</h2>
<p>2021년 1월의 AI 연구 동향은 두 가지 방향으로 동시에 심화되고 있었다. 한편으로는 DALL-E와 LLM처럼 ’규모의 경제(Scaling Laws)’를 통해 기존 모델을 극단적으로 확장하여 새로운 능력을 창발시키는 ’수직적 확장’이 진행되었다. 다른 한편으로는 메타러닝, 계층적 강화학습, 프롬프팅 연구처럼 AI가 ‘학습하는 방법’ 자체를 개선하고, 더 효율적이고 유연하게 지식을 활용하는 방법을 탐구하는 ’수평적 정교화’가 이루어졌다. 이 두 흐름은 상호보완적으로 작용하며 AI 연구의 성숙기를 이끌었다.</p>
<h3>3.1  국가 전략과 R&amp;D 투자 동향</h3>
<p>2021년 1월 1일, 미국은 ’국가 인공지능 이니셔티브 법’의 발효와 함께 국가 인공지능 계획을 수립하고 시행할 공식 기구(과학기술정책실 소속)를 출범시켰다.4 이는 AI 기술 개발이 개별 기업이나 연구소 차원을 넘어 국가적 아젠다로 격상되었음을 의미하며, 국제 사회의 AI 규범 정립 및 기술 패권 경쟁이 본격화되었음을 알리는 신호였다.4</p>
<p>이러한 전략적 방향성은 주요 기관들의 R&amp;D 예산 증액을 통해 구체화되었다. 2025 회계연도 예산 요청 보조 자료에 따르면, 국방고등연구계획국(DARPA), 국토안보부(DHS), 국방부(DOD), 국립표준기술연구소(NIST), 국립과학재단(NSF) 등 미국의 핵심 연구 및 국방 기관들이 AI 관련 R&amp;D 예산을 대폭 증액했다.5 특히 DARPA는 전자 기술 분야에 1억 3,120만 달러를, DHS는 AI 보안 및 데이터 보안 등 첨단 R&amp;D 분야에 1,600만 달러를 배정했다. NIST는 인간 중심 지능형 자동화(HCIA)에 2,720만 달러, 인간-컴퓨터 상호작용(HCI)에 2,080만 달러를 투자하며 AI 기술의 실용화와 인간과의 접점에 주목했다. NSF는 국가 AI 연구소 설립 및 운영에 대한 투자를 확대하며 총 2억 8,490만 달러의 예산 증가를 기록했다. 이는 AI 기술의 기초 연구뿐만 아니라, 실용화, 보안, 윤리적 측면까지 고려한 포괄적인 국가 투자 전략이 실행되고 있음을 명확히 보여준다.</p>
<p><strong>표 2: 2021년 미국 주요 기관별 AI R&amp;D 증액 예산 및 중점 분야 (FY2025 요청 기준)</strong></p>
<table><thead><tr><th>기관 (Agency)</th><th>총 증액 예산</th><th>중점 투자 분야 (Key Investment Areas)</th><th>관련 자료</th></tr></thead><tbody>
<tr><td>방위고등연구계획국 (DARPA)</td><td>1억 1,810만 달러</td><td>전자 기술, 차세대 AI 기술</td><td>5</td></tr>
<tr><td>국토안보부 (DHS)</td><td>3,620만 달러</td><td>AI 보안, 데이터 보안, 사이버 복원력</td><td>5</td></tr>
<tr><td>국립표준기술연구소 (NIST)</td><td>7,450만 달러 (LSDM) + 2,720만 달러 (HCIA) 등</td><td>데이터 관리, 인간 중심 지능형 자동화, HCI</td><td>5</td></tr>
<tr><td>국립과학재단 (NSF)</td><td>2억 8,490만 달러</td><td>국가 AI 연구소, 기술·혁신·파트너십</td><td>5</td></tr>
</tbody></table>
<h3>3.2  학계를 통해 본 핵심 연구 흐름</h3>
<p>2021년 1월을 전후하여 학계에서는 AI 모델을 다루는 방법론 자체에 대한 근본적인 혁신이 동시에 추구되었다.</p>
<h4>3.2.1  Transformer의 보편화와 NLP의 새로운 지평</h4>
<p>2017년 등장한 Transformer 아키텍처는 2021년에 이르러 자연어 처리(NLP) 분야를 완전히 장악하고, 컴퓨터 비전(CV) 등 다른 분야로 빠르게 확장되고 있었다.12 이러한 확장성의 배경에는 **프롬프트 기반 학습(Prompt-based Learning)**이라는 새로운 패러다임이 있었다. 거대 언어 모델의 등장으로, 특정 작업(task)을 위해 모델 전체를 미세조정(fine-tuning)하는 대신, 모델이 특정 작업을 수행하도록 유도하는 자연어 ’프롬프트’를 설계하는 방식이 부상했다.13 이 접근법은 소량의 데이터만으로도 새로운 작업에 모델을 적응시키는 few-shot 또는 zero-shot 학습을 가능하게 하여, AI 개발의 효율성을 극적으로 높였다.</p>
<p>한편, 모델이 강력해짐에 따라 그 취약점을 파고드는 연구 또한 활발해졌다. 2021년 1월 3일에 arXiv에 업데이트된 ‘보편적 적대적 트리거(Universal Adversarial Triggers)’ 연구는 입력 데이터와 무관하게 특정 단어나 구문(예: “zoning tapping fiennes”)을 추가하는 것만으로 모델의 출력을 특정 방향으로 조작할 수 있음을 보였다.14 예를 들어, 이 트리거를 긍정적인 영화 리뷰에 추가하면 모델이 99% 이상의 확률로 부정적인 리뷰로 오분류하게 만들 수 있었다. 이는 AI 모델의 안전성(Safety)과 신뢰성(Trust)이 중요한 연구 주제로 부상했음을 시사한다.12</p>
<h4>3.2.2  강화학습(RL)의 진화</h4>
<p>강화학습 분야에서는 학습 알고리즘 자체를 자동화하고, 복잡한 문제를 계층적으로 해결하려는 시도가 두드러졌다.</p>
<p><strong>메타러닝을 통한 RL 알고리즘 자동 설계:</strong> 2021년 1월 8일 arXiv에 제출된 구글의 연구는 강화학습 알고리즘 설계를 메타러닝 문제로 접근했다.15 이들은 기존의 강화학습 알고리즘(예: DQN)을 개선하는 새로운 알고리즘을 인간이 설계하는 대신, 손실 함수를 표현하는 계산 그래프(computational graph) 공간을 진화적 탐색(evolutionary search)을 통해 탐색하여 최적의 손실 함수를 ’발견’하는 방법을 제안했다. 흥미롭게도 이 방법은 스크래치에서 학습을 시작했을 때 시간차(Temporal Difference, TD) 학습과 같은 강화학습의 기본 원리를 스스로 재발견했다. 또한, DQN을 기반으로 탐색을 시작했을 때는 Q-값 과대평가(overestimation) 문제를 완화하는 새로운 정규화 항을 포함하는 손실 함수 <span class="math math-inline">L_{DQNReg} = 0.1 \ast Q(s_t, a_t) + \delta^2</span>를 발견했다. 이는 알고리즘 설계 자체를 자동화할 수 있는 가능성을 열었다.</p>
<p><strong>계층적 강화학습(HRL)과 내재적 동기:</strong> 복잡하고 장기적인 작업을 해결하기 위해, 작업을 여러 계층의 부(sub)작업으로 분해하는 계층적 강화학습(HRL) 연구가 주목받았다. 2021년 1월 16일 arXiv에 제출된 ‘HIDIO(Hierarchical Reinforcement Learning By Discovering Intrinsic Options)’ 연구는 외부 보상이 희소한 환경에서도, 내재적 동기(intrinsic motivation)를 통해 과제와 무관한(task-agnostic) 유용한 ‘옵션(options)’ 또는 ’기술(skills)’들을 스스로 발견하고 이를 조합하여 문제를 해결하는 방법을 제안했다.16 HIDIO의 하위 정책(worker)은 외부 보상 대신, 자신이 생성한 궤적으로부터 자신이 어떤 옵션을 수행 중이었는지 명확히 구분할 수 있도록 하는 내재적 보상을 통해 다양한 기술을 학습한다. 이는 AI가 명시적인 목표 없이도 유용한 행동들을 자발적으로 학습할 수 있는 길을 열어주었다.</p>
<h2>4.  로봇공학: 산업의 성장과 지능의 고도화</h2>
<p>2021년 로봇공학 분야는 산업적 성장이 가속화되는 동시에, 로봇 지능의 근본적인 한계를 돌파하려는 혁신적인 연구들이 등장하며 양적, 질적 성장을 모두 이루었다.</p>
<h3>4.1  2021년 로봇 산업 핵심 동향</h3>
<p>2021년은 로봇 기업에 대한 투자가 매우 활성화된 해였다. IT 뉴스 매체 분석 결과에 따르면, 2021년 1월부터 10월까지 ’로봇 기업에 대한 투자 활성화’가 280건으로 가장 중요한 이슈로 꼽혔다.18 특히 중국의 자율주행 청소 로봇 기업 가우시안 로보틱스(Gaussian Robotics)가 소프트뱅크 비전 펀드 등으로부터 1억 8,800만 달러의 대규모 시리즈 C 투자를 유치한 사례는 이러한 흐름을 상징적으로 보여준다.18</p>
<p>시장 전망 또한 매우 긍정적이었다. 전 세계 산업용 로봇 시장은 2021년 141억 1,600만 달러에서 연평균 15.4%로 성장하여 2026년에는 288억 6,500만 달러에 이를 것으로 전망되었다.19 특히 주목할 점은 인간과 같은 공간에서 협업하는 협동 로봇(Cobot) 시장의 폭발적인 성장세다. 협동 로봇 시장은 2021년 12억 1,400만 달러에서 연평균 42.8%라는 경이로운 성장률을 보이며 2026년에는 72억 1,600만 달러 규모에 이를 것으로 예측되었다.19 이는 로봇이 대규모 공장의 격리된 공간을 넘어 중소기업, 서비스업 등 인간의 일상 공간으로 빠르게 확산되고 있음을 의미한다.</p>
<p>이러한 성장은 다양한 사회적 요구와 맞물려 가속화되었다. 코로나19 팬데믹은 비대면 서비스 수요를 증가시켜 방역, 배달, 물류 창고 관리 등에서 로봇 활용을 촉진하는 기폭제가 되었다.18 또한 국방 분야에서의 군사용 로봇 도입, 고령화 사회에 대응하기 위한 노년층의 정서적 교감용 로봇펫, 그리고 Amazon의 ’Astro’와 같은 가정용 로봇의 등장은 로봇의 적용 범위가 산업 현장을 넘어 사회 전방위적으로 확대되고 있음을 보여주었다.18</p>
<p><strong>표 3: 2021년 1-10월 주요 로봇 이슈 Top 5</strong></p>
<table><thead><tr><th>순위</th><th>이슈 (Issue)</th><th>발생 건수 (Count)</th><th>주요 내용 및 의의</th><th>관련 자료</th></tr></thead><tbody>
<tr><td>1</td><td>로봇 기업에 대한 투자 활성화</td><td>280건</td><td>소프트뱅크 등 대규모 자본이 로봇 스타트업에 유입되며 산업 성장 가속화</td><td>18</td></tr>
<tr><td>2</td><td>코로나 19 예방에 로봇 활용</td><td>158건</td><td>팬데믹으로 인한 비대면 수요 증가가 서비스 로봇 시장 확대의 기폭제 역할</td><td>18</td></tr>
<tr><td>3</td><td>각 국 국방분야에서의 로봇 연구 집중</td><td>95건</td><td>자율 무기 및 정찰 시스템 등 국방 분야에서 로봇 기술의 전략적 중요성 증대</td><td>18</td></tr>
<tr><td>4</td><td>동물 형태의 로봇 시장 출시</td><td>84건</td><td>고령화 사회 진입에 따라 정서적 교감 및 돌봄을 위한 로봇펫 수요 증가</td><td>18</td></tr>
<tr><td>5</td><td>가정용 로봇의 본격적인 도입</td><td>67건</td><td>Amazon ‘Astro’ 등 빅테크 기업의 시장 진출로 가정용 로봇 대중화 기대감 상승</td><td>18</td></tr>
</tbody></table>
<h3>4.2  로봇 지능의 한계를 넘어서: 주요 연구 동향</h3>
<p>산업의 양적 팽창과 더불어, 로봇 지능의 질적 도약을 위한 근본적인 연구들이 발표되었다.</p>
<h4>4.2.1  자동 목표 발견: OpenAI의 ‘비대칭적 자기-대국’</h4>
<p>강화학습을 물리 세계의 로봇 조작(manipulation)에 적용할 때 가장 큰 난관은 희소 보상(sparse rewards)과 효율적인 탐색(exploration) 문제다. 복잡한 작업을 완벽하게 성공해야만 보상을 받는 환경에서 에이전트는 유의미한 학습 신호를 거의 얻지 못해 학습이 불가능에 가깝다.</p>
<p>2021년 1월 13일 arXiv에 제출된 OpenAI의 논문 “Asymmetric self-play for automatic goal discovery in robotic manipulation“은 이 문제를 해결하기 위한 혁신적인 프레임워크를 제시했다.6 이 방법론의 핵심은 ’경쟁’이라는 내재적 동기를 통해 외부의 명시적인 보상 없이 복잡하고 유용한 기술을 자율적으로 습득하는 것이다. 이는 로봇이 특정 작업만을 수행하도록 프로그래밍하는 기존 방식에서 벗어나, 스스로 가능한 작업의 범위를 확장하고 기술을 연마하는 ‘평생 학습(lifelong learning)’ 에이전트로 발전할 수 있는 경로를 제시했다는 점에서 중요한 의미를 가진다.</p>
<p>방법론의 핵심은 두 에이전트, ’앨리스(Alice)’와 ’밥(Bob)’이 서로 경쟁하는 ‘비대칭적 자기-대국(Asymmetric Self-play)’ 게임이다.6</p>
<ul>
<li>
<p><strong>앨리스 (목표 생성자):</strong> 앨리스의 역할은 현재 밥의 능력 수준에서 해결하기 어렵지만, 불가능하지는 않은 ‘도전적인’ 목표 상태를 생성하는 것이다. 앨리스는 밥이 목표 달성에 실패할 때 긍정적인 보상을 받도록 설계되어, 항상 밥의 능력의 한계에 있는 과제를 제시하도록 동기 부여된다.20</p>
</li>
<li>
<p><strong>밥 (목표 해결자):</strong> 밥은 앨리스가 제시한 목표를 달성하는 역할을 하는 목표-조건부(goal-conditioned) 정책이다.</p>
</li>
</ul>
<p>이 두 에이전트의 상호작용은 인간의 개입 없이 자연스러운 커리큘럼 학습(curriculum learning)을 생성한다. 밥의 능력이 향상될수록 앨리스는 더 어려운 목표를 제시해야만 보상을 받을 수 있으므로, 과제의 난이도가 밥의 학습 속도에 맞춰 자동으로 조절된다.20 또한 학습 효율을 높이기 위해, 밥은 앨리스가 목표를 생성하며 보여준 궤적을 모방 학습(Alice Behavioral Cloning, ABC)하여 희소 보상 문제를 완화한다.21</p>
<p>이 방법을 통해 훈련된 단일 정책은 테이블 세팅, 블록 쌓기, 미니 체스, 간단한 퍼즐 맞추기 등 훈련 과정에서 전혀 보지 못했던 다양한 미지의 작업에 대해서도 높은 성공률을 보이는 제로샷(zero-shot) 일반화 성능을 달성했다.7 이는 로봇이 특정 작업을 위해 개별적으로 훈련되는 것이 아니라, 일반적인 물리적 상호작용 능력을 습득한 후 이를 새로운 작업에 유연하게 적용할 수 있음을 보여준 획기적인 결과였다.</p>
<h4>4.2.2  로봇을 위한 시맨틱스 및 오픈소스 하드웨어</h4>
<p>이 외에도 로봇이 단순히 기하학적 정보를 처리하는 것을 넘어, 주변 환경과 객체가 갖는 ’의미(semantics)’를 이해하고 이를 바탕으로 행동하게 하는 시맨틱스 연구가 활발히 진행되었다.23 또한, 수술용 로봇과 같이 복잡하고 고가인 시스템의 연구 장벽을 낮추기 위해, 3D 프린팅과 저가 부품을 활용한 오픈소스 연속체 로봇(continuum robot) ’ENDO’가 제안되는 등 연구의 접근성을 높이려는 노력도 이루어졌다.24</p>
<h2>5.  결론: 종합 및 전망</h2>
<p>2021년 1월은 AI와 로봇공학이 각자의 영역에서 기술적 성숙도를 높이는 동시에, 서로의 경계를 허물며 새로운 패러다임으로의 전환을 예고하는 중요한 변곡점이었다.</p>
<p>DALL-E의 등장은 Transformer 아키텍처의 범용성을 입증하며 텍스트를 넘어 시각 영역까지 생성 모델의 가능성을 확장했고, 이는 이후 멀티모달 생성형 AI 시대의 개막을 알리는 신호탄이 되었다. 국가 차원의 AI 전략 수립과 대규모 R&amp;D 투자는 AI 기술이 학계를 넘어 경제와 안보의 핵심 요소로 자리 잡았음을 보여주며, 글로벌 기술 패권 경쟁의 서막을 열었다. 학계에서는 거대 모델의 잠재력을 극대화하는 프롬프트 기반 학습과 같은 ’수평적 정교화’와, 학습의 원리 자체를 탐구하는 메타러닝 및 계층적 강화학습과 같은 ’근본적 심화’가 동시에 이루어지며 연구의 깊이를 더했다.</p>
<p>로봇공학 분야에서는 산업적 성장이 가속화되는 가운데, ’비대칭적 자기-대국’과 같은 혁신적인 연구가 등장하여 로봇이 명시적인 보상 없이 내재적 동기만으로 물리 세계를 탐험하고 유용한 기술을 스스로 학습하는 새로운 가능성을 제시했다. 이는 AI가 디지털 세계를 넘어 복잡한 물리 세계와 상호작용하는 자율적 에이전트로 발전할 수 있는 중요한 이론적 토대를 마련했다.</p>
<p>2021년 1월에 나타난 이러한 흐름들은 이후 수년간의 기술 발전을 명확하게 예고했다.</p>
<ol>
<li>
<p><strong>생성형 AI의 전성기:</strong> DALL-E를 시작으로 텍스트, 이미지, 코드를 넘나드는 멀티모달(multi-modal) 생성형 AI 모델의 등장이 가속화될 것이며, 이는 창의적 산업과 지식 노동의 패러다임을 근본적으로 변화시킬 것이다.</p>
</li>
<li>
<p><strong>데이터 중심(Data-centric) AI 패러다임의 확산:</strong> AI 커뮤니티의 관심이 모델 중심(model-centric)에서 데이터 중심(data-centric)으로 이동함에 따라, 모델 아키텍처 개선만큼이나 양질의 데이터를 확보하고 관리하는 MLOps의 중요성이 더욱 부각될 것이다.12</p>
</li>
<li>
<p><strong>자율적 에이전트의 부상:</strong> 강화학습과 내재적 동기에 기반한 로봇 및 AI 에이전트는 정해진 작업을 수동적으로 수행하는 것을 넘어, 스스로 목표를 설정하고 복잡한 문제를 해결하는 방향으로 발전하여, 더욱 범용적이고 지능적인 시스템으로 진화할 것이다.</p>
</li>
<li>
<p><strong>AI 안전성과 규제의 중요성 증대:</strong> AI 기술의 사회적 영향력이 커짐에 따라, EU의 AI 규제법안(AIA)과 같은 규제 논의가 본격화되고 12, 모델의 취약점 및 오용 가능성에 대한 연구가 AI 안전성(AI Safety)이라는 핵심 분야로 자리 잡을 것이다.</p>
</li>
</ol>
<p>결론적으로 2021년 1월은 이후 펼쳐질 거대한 기술적, 사회적 변화의 시작을 알리는 중요한 이정표였으며, 이때 제시된 개념과 연구들은 현재까지도 AI와 로봇공학 발전의 핵심 동력으로 작용하고 있다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>생성형 인공지능(Generative AI) 산업 현황 보고서 &gt; 저작권동향(상세) &gt; 저작권동향(판례) &gt; 자료 &gt; 한국저작권위원회, <a href="https://www.copyright.or.kr/information-materials/trend/the-copyright/view.do?brdctsno=51810&amp;pageIndex=7&amp;noticeYn&amp;brdclasscodeList&amp;etc2&amp;etc1&amp;searchText&amp;searchkeyword&amp;brdclasscode=02&amp;nationcodeList&amp;searchTarget=ALL&amp;nationcode">https://www.copyright.or.kr/information-materials/trend/the-copyright/view.do?brdctsno=51810&amp;pageIndex=7¬iceYn=&amp;brdclasscodeList=&amp;etc2=&amp;etc1=&amp;searchText=&amp;searchkeyword=&amp;brdclasscode=02&amp;nationcodeList=&amp;searchTarget=ALL&amp;nationcode=</a></li>
<li>DALL·E 2 | OpenAI, https://openai.com/index/dall-e-2/</li>
<li>DALL·E: Creating images from text | OpenAI, https://openai.com/index/dall-e/</li>
<li>인공지능(AI) 관련 국내외 법제 동향 - 법제처, https://www.moleg.go.kr/boardDownload.es?bid=legnlpst&amp;list_key=3813&amp;seq=1</li>
<li>투자 규모를 중심으로 본 주요국 AI 정책 동향, https://nia.or.kr/common/board/Download.do?bcIdx=28237&amp;cbIdx=82618&amp;fileNo=1</li>
<li>[2101.04882] Asymmetric self-play for automatic goal discovery in robotic manipulation, https://arxiv.org/abs/2101.04882</li>
<li>Asymmetric self-play for automatic goal discovery in robotic manipulation, https://robotics-self-play.github.io/</li>
<li>DALL-E - Wikipedia, https://en.wikipedia.org/wiki/DALL-E</li>
<li>How does DALL-E, the text-to-image generator work? | by Mehul Gupta - Medium, https://medium.com/data-science-in-your-pocket/how-does-dall-e-the-text-to-image-generator-work-c2d9f4a0f26c</li>
<li>DALL-E: Inside the Artificial Intelligence program that creates images from textual descriptions - Paperspace Blog, https://blog.paperspace.com/dall-e-image-generator/</li>
<li>[R] New Paper from OpenAI: DALL·E: Creating Images from Text - Reddit, https://www.reddit.com/r/MachineLearning/comments/kr63ot/r_new_paper_from_openai_dalle_creating_images/</li>
<li>2021년 AI 주요 이슈 및 전망 : State of AI Report 2021를 중심으로 | 국내연구자료 | KDI 경제교육·정보센터, https://eiec.kdi.re.kr/policy/domesticView.do?ac=0000160304</li>
<li>Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing - arXiv, https://arxiv.org/abs/2107.13586</li>
<li>arXiv:1908.07125v3 [cs.CL] 3 Jan 2021, https://arxiv.org/pdf/1908.07125</li>
<li>Evolving Reinforcement Learning Algorithms, https://arxiv.org/abs/2101.03958</li>
<li>[2101.06521] Hierarchical Reinforcement Learning By Discovering Intrinsic Options - arXiv, https://arxiv.org/abs/2101.06521</li>
<li>HIERARCHICAL REINFORCEMENT LEARNING BY … - OpenReview, https://openreview.net/pdf/8ab82acd2672b63eb1d694fcb5fc26a32c2f6d74.pdf</li>
<li>품목별ICT 시장동향, https://www.globalict.kr/upload_file/kms/202112/61312462681790672.pdf</li>
<li>산업용 로봇 시장 - 연구개발특구진흥재단, <a href="https://www.innopolis.or.kr/fileDownload?titleId=178533&amp;fileId=1&amp;fileDownType=C&amp;paramMenuId=MENU00999">https://www.innopolis.or.kr/fileDownload?titleId=178533&amp;fileId=1&amp;fileDownType=C¶mMenuId=MENU00999</a></li>
<li>Asymmetric self-play for automatic goal discovery in robotic manipulation - ResearchGate, https://www.researchgate.net/publication/348486946_Asymmetric_self-play_for_automatic_goal_discovery_in_robotic_manipulation</li>
<li>ROS-I Americas - ROS-Industrial, https://rosindustrial.squarespace.com/s/RICA_2022_William_Harrison2.pdf</li>
<li>Asymmetric self-play for automatic goal discovery in robotic manipulation - Rosanne Liu, https://rosanneliu.com/dlctfs/dlct_210409.pdf</li>
<li>[2101.00443] Semantics for Robotic Mapping, Perception and Interaction: A Survey - arXiv, https://arxiv.org/abs/2101.00443</li>
<li>arXiv:2101.01080v1 [cs.RO] 4 Jan 2021, https://arxiv.org/pdf/2101.01080</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>