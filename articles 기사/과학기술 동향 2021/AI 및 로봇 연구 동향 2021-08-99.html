<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2021년 8월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2021년 8월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2021년 AI 및 로봇 연구 동향</a> / <span>2021년 8월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2021년 8월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2021년 중반 AI 및 로봇 연구의 지형</h2>
<h3>1.1 배경 및 중요성</h3>
<p>2021년은 인공지능(AI) 기술이 학문적 탐구를 넘어 다양한 산업 분야로 확산되며 중대한 변곡점을 맞이한 시기였다. 특히, 자연어 처리(NLP) 분야에서 압도적인 성능을 입증한 트랜스포머(Transformer) 아키텍처가 컴퓨터 비전(Computer Vision) 분야의 패러다임을 재편하기 시작했으며, 로봇 공학은 AI 기반의 지능형 인식 및 조작 기술과 결합하여 자율성의 새로운 지평을 열고 있었다. 당시 세계 AI 시장 규모는 약 400조 원에 달했으며, 2024년에는 585조 원으로의 성장이 예측될 만큼 폭발적인 잠재력을 보였다.1 국내 AI 시장 역시 2025년까지 약 1조 9,047억 원 규모로 성장이 전망되었다.1 이와 더불어, 비대면 수요의 증가는 서비스 로봇 시장의 빠른 회복을 견인하며 2023년 533억 달러에서 2026년 1,033억 달러로 연평균 24.7%의 고속 성장을 예고했다.2</p>
<p>이러한 기술적, 산업적 배경 속에서 2021년 여름에 개최된 자연어 처리 분야의 ACL-IJCNLP, 컴퓨터 비전 분야의 ICCV, 그리고 로봇 공학 분야의 IROS와 같은 최고 권위의 국제 학술대회들은 향후 수년간의 연구 방향을 결정짓는 핵심적인 돌파구를 제시했다. 이들 학회에서 발표된 연구들은 단순히 기존 기술의 성능을 소폭 개선하는 수준을 넘어, 각 분야의 근본적인 문제에 대한 새로운 접근법을 제시하고 기술 융합의 가능성을 탐색했다.</p>
<h3>1.2 보고서의 목적 및 구성</h3>
<p>본 보고서는 해당 시기에 발표된 가장 영향력 있는 연구, 특히 각 학회의 최우수 논문상(Best Paper Award)을 수상한 기념비적인 연구들을 중심으로 심층 분석을 제공하는 것을 목적으로 한다. 이를 통해 2021년 중반 AI 및 로봇 공학 분야의 최첨단 기술 동향을 조망하고, 그 기술적 함의와 미래 발전 가능성을 탐색한다.</p>
<p>보고서는 총 3개의 장으로 구성된다. 제1장에서는 자연어 처리 분야의 혁신을 다루며, ACL-IJCNLP 2021에서 주목받은 어휘 학습 최적화와 연구의 사회적 포용성에 대한 논의를 분석한다. 제2장에서는 컴퓨터 비전의 새로운 패러다임을 제시한 ICCV 2021의 최우수 논문, Swin Transformer를 집중적으로 분석하여 트랜스포머가 어떻게 비전 분야를 혁신했는지 살펴본다. 제3장에서는 IROS 2021을 통해 지능형 로봇 기술의 최신 동향을 파악하고, AI가 로봇의 감각과 행동 능력을 어떻게 고도화하고 있는지 분석한다. 마지막으로, 결론에서는 각 분야의 개별적인 발전을 넘어, 기술 간의 상호 영향과 융합이 어떻게 AI 생태계 전체의 진화를 이끌었는지 종합적으로 조망한다.</p>
<h3>1.3 핵심 요약</h3>
<p>본 보고서에서 심층적으로 다룰 주요 학회별 수상 논문의 핵심 내용은 아래 표와 같다. 이 표는 보고서 전체의 구조를 조망하는 로드맵 역할을 하며, 각 장에서 전개될 상세 분석의 핵심을 미리 파악하는 데 도움을 줄 것이다.</p>
<table><thead><tr><th>학회</th><th>논문 제목 (원제 및 번역)</th><th>핵심 기여</th><th>주요 결과 및 영향</th></tr></thead><tbody>
<tr><td><strong>ACL-IJCNLP 2021</strong></td><td><strong>Best Paper:</strong> Vocabulary Learning via Optimal Transport for Neural Machine Translation (신경망 기계 번역을 위한 최적 수송 기반 어휘 학습)</td><td>정보 이론과 최적 수송 이론을 도입하여, 경험적 방식에 의존하던 어휘 구축 과정을 수학적 최적화 문제로 재정의함.</td><td>기존 방식 대비 어휘 크기를 70% 줄이면서 번역 성능(BLEU)을 0.5점 향상시키고, 탐색 시간을 12배 이상 단축함.3</td></tr>
<tr><td><strong>ACL-IJCNLP 2021</strong></td><td><strong>Best Theme Paper:</strong> Including Signed Languages in Natural Language Processing (자연어 처리에 수어 포함하기)</td><td>텍스트/음성 언어 중심의 NLP 연구에서 소외된 수어의 언어학적 특성을 조명하고, 기술적 포용을 위한 구체적인 연구 방향을 제시함.</td><td>NLP 커뮤니티에 기술의 사회적 책무를 환기시키고, 진정한 멀티모달 AI로 나아가기 위한 핵심 도전 과제를 제시함.5</td></tr>
<tr><td><strong>ICCV 2021</strong></td><td><strong>Marr Prize (Best Paper):</strong> Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Shifted Window를 이용한 계층적 비전 트랜스포머)</td><td>CNN의 계층 구조와 지역성 원리를 트랜스포머에 융합한 ‘Shifted Window’ 메커니즘을 통해, 고해상도 이미지 처리의 효율성과 성능을 극대화함.</td><td>이미지 분류, 객체 탐지, 분할 등 주요 비전 벤치마크에서 SOTA를 달성하며, 이후 컴퓨터 비전 분야의 범용 백본(backbone) 표준으로 자리매김함.6</td></tr>
<tr><td><strong>IROS 2021</strong></td><td><strong>Best Paper:</strong> Extended Tactile Perception: a Neuromorphic-based Approach for Robot-Tool Interaction (확장된 촉각 인지: 뉴로모픽 기반 로봇-도구 상호작용)</td><td>인간이 도구를 통해 느끼는 미세 진동을 모방한 뉴로모픽 센서를 개발하여, 로봇이 도구를 통해 간접적으로 물체를 인지하는 능력을 구현함.</td><td>로봇이 시각 정보 없이 촉각만으로 도구 끝의 접촉을 감지하는 능력을 입증하여, 의료, 서비스 로봇의 조작 능력을 한 단계 발전시킬 가능성을 제시함.8</td></tr>
<tr><td><strong>IROS 2021</strong></td><td><strong>Best Student Paper:</strong> Dynamic Grasping with a “Soft” Drone: From Theory to Practice (이론에서 실제까지, “소프트” 드론을 이용한 동적 파지)</td><td>움직이는 물체를 파지하기 위해 로봇의 도달 가능성(SDF), 물체 움직임에 따른 파지 안정성(신경망)을 통합한 실시간 계획 프레임워크를 제안함.</td><td>동적 환경에서 로봇의 조작 성공률을 높이는 통합적 접근법을 제시하여, 비정형 환경에서의 로봇 자율성 연구에 기여함.9</td></tr>
</tbody></table>
<p>2021년의 연구 지형은 AI 기술의 패러다임이 특정 문제에 특화된 모델을 개발하는 ‘특화(Specialization)’ 단계에서, 다양한 문제에 적용 가능한 범용 아키텍처를 탐구하는 ‘일반화(Generalization)’ 단계로 이동하는 중요한 전환기였음을 시사한다. 이는 서로 다른 분야인 자연어 처리와 컴퓨터 비전에서 공통적으로 트랜스포머 기반의 단일 아키텍처가 범용 백본(general-purpose backbone)으로서의 가능성을 입증한 것에서 명확히 드러난다. 과거 AI 연구가 각 도메인(언어, 비전)에 특화된 아키텍처, 예를 들어 NLP를 위한 순환 신경망(RNN)이나 컴퓨터 비전을 위한 합성곱 신경망(CNN)을 개발하는 데 집중했던 것과 대조적이다. 2021년 8월을 기점으로, ACL에서는 트랜스포머의 근간이 되는 ‘어휘’ 문제를 최적화 이론으로 접근했고 3, ICCV에서는 트랜스포머를 CNN의 계층적 특성과 결합한 ’Swin Transformer’가 범용 비전 백본으로 제시되어 최고상을 수상했다.6 이는 단일한 기본 아키텍처(트랜스포머)가 서로 다른 모달리티의 데이터를 처리하는 표준이 될 수 있음을 암시하는 현상이었다. 이 흐름은 단순히 한 분야의 발전을 넘어, AI 모델 개발의 근본적인 접근 방식이 ’문제별 맞춤 설계’에서 ’강력한 범용 아키텍처의 미세 조정’으로 변화하고 있음을 의미하며, 이는 이후 거대 언어 모델(LLM)과 멀티모달 모델의 폭발적인 성장을 예견하는 중요한 전조 현상으로 평가될 수 있다.</p>
<h2>2.  자연어 처리(NLP) 분야 혁신: ACL-IJCNLP 2021 주요 발표</h2>
<h3>2.1 개요</h3>
<p>2021년 8월 1일부터 6일까지 온라인으로 개최된 ’제59회 전산언어학회 연례회의 및 제11회 자연어 처리 국제 공동 학회(ACL-IJCNLP 2021)’는 자연어 처리 분야의 최고 권위 학회로서, 당시 NLP 연구의 정점을 보여주는 자리였다.12 이 시기 학회에서는 딥러닝 모델의 성능을 극한으로 끌어올리는 기술적 깊이에 대한 탐구와 더불어, AI 기술의 사회적 책무와 포용성을 강조하는 중요한 논문들이 함께 주목받았다. 이는 NLP 커뮤니티가 기술적 성숙과 함께 사회적 역할에 대한 고민을 심화하고 있음을 보여주는 중요한 지표였다.</p>
<h3>2.2  최우수 논문 (Best Paper): 신경망 기계 번역을 위한 최적 수송(Optimal Transport) 기반 어휘 학습</h3>
<h4>2.2.1 문제 제기: 기존 어휘화(Vocabularization) 방식의 한계</h4>
<p>모든 신경망 기반 NLP 모델의 첫 단계는 이산적인 텍스트를 모델이 처리할 수 있는 숫자 벡터의 시퀀스로 변환하는 것이며, 이 과정의 핵심은 텍스트를 의미 있는 단위인 ’토큰(token)’으로 분할하는 어휘화(vocabularization)이다. 모델의 성능은 이 어휘의 구성과 크기에 매우 큰 영향을 받는다. 당시 표준적으로 사용되던 바이트 페어 인코딩(Byte-Pair Encoding, BPE)과 같은 서브워드(sub-word) 분절 알고리즘은 텍스트에 등장하는 문자열의 빈도를 기반으로 탐욕적(greedy) 병합을 수행하는 방식으로 작동했다.4 이러한 방식은 단어와 문자 수준 어휘의 장점을 절충하여 희소성 문제를 완화하는 데 효과적이었으나, 두 가지 근본적인 한계를 내포하고 있었다. 첫째, 탐욕적 접근법은 전역 최적해(global optimum)를 보장하지 못한다. 둘째, 어휘의 크기라는 매우 중요한 하이퍼파라미터를 사용자가 임의로 지정해야 했으며, 최적의 크기를 찾기 위해서는 수많은 모델을 직접 학습하고 평가하는 막대한 계산 비용이 수반되는 ‘시행착오(trial training)’ 과정이 필요했다.3</p>
<h4>2.2.2 핵심 방법론: VOLT (VOcabulary Learning via optimal Transport)</h4>
<p>이 연구는 ’좋은 어휘란 무엇인가?’라는 근본적인 질문에 답하기 위해, 경험적이고 휴리스틱에 의존하던 기존의 어휘 구축 과정을 이론적 기반을 갖춘 최적화 문제로 재정의했다. 이를 위해 정보 이론(Information Theory)과 경제학, 그리고 수학적 최적화 이론을 독창적으로 결합한 VOLT라는 새로운 프레임워크를 제안했다.3</p>
<p>첫 단계는 좋은 어휘를 평가할 수 있는 객관적인 지표를 찾는 것이었다. 연구진은 경제학의 ‘한계 효용(Marginal Utility)’ 개념에서 영감을 받아 ’어휘화의 한계 효용(Marginal Utility of Vocabularization, MUV)’이라는 새로운 지표를 제안했다.4 MUV는 어휘 크기(비용)의 증가가 코퍼스 전체의 정보량, 즉 엔트로피(이익)를 얼마나 효율적으로 감소시키는지를 측정한다. 어휘 크기가 커질수록 문장 길이는 짧아지고 엔트로피는 감소하여 모델 학습에 유리하지만, 동시에 파라미터 수가 증가하고 토큰 희소성 문제가 발생할 수 있다. MUV는 이 둘 사이의 최적의 균형점을 찾기 위한 지표로, 어휘 크기에 대한 엔트로피의 음의 미분 값으로 정의된다. 연구진은 실험을 통해 이 MUV 값이 실제 기계 번역 성능(BLEU 점수)과 높은 양의 상관관계를 가짐을 입증하여, MUV를 최대화하는 것이 좋은 어휘를 찾는 것과 동일한 목표임을 보였다.4</p>
<p>다음 단계는 MUV를 최대화하는 어휘를 효율적으로 찾는 것이었다. 연구진은 이 문제를 ‘최적 수송(Optimal Transport, OT)’ 이론을 통해 공식화했다.3 최적 수송은 한 분포의 질량(mass)을 다른 분포로 옮기는 데 필요한 최소 비용을 찾는 수학적 프레임워크이다. 이 연구에서는 어휘화 과정을 말뭉치에 존재하는 모든 문자(character)들의 분포를 최종 어휘 사전에 포함될 토큰(token)들의 분포로 ’수송’하는 문제로 치환했다. 여기서 수송 비용은 MUV와 관련된 값으로 정의되며, 최적 수송 문제를 해결함으로써 MUV를 최대화하는, 즉 최적의 어휘를 구성하는 토큰들의 집합을 찾아낼 수 있다. 이 문제는 다음과 같은 선형 계획법 문제로 표현될 수 있다.</p>
<p><span class="math math-display">
\min_{T \in \Pi(p, q)} \sum_{i,j} T_{ij} C_{ij}
</span><br />
위 식에서 <span class="math math-inline">T</span>는 문자 <span class="math math-inline">i</span>가 토큰 <span class="math math-inline">j</span>에 할당되는 양을 나타내는 수송 행렬, <span class="math math-inline">p</span>는 소스 분포(문자), <span class="math math-inline">q</span>는 타겟 분포(토큰), 그리고 <span class="math math-inline">C</span>는 수송 비용 행렬을 의미한다. 최적 수송 이론은 이 문제를 다항 시간 내에 효율적으로 풀 수 있는 알고리즘을 제공하므로, 막대한 시행착오 없이 최적의 어휘를 직접 찾아낼 수 있다.</p>
<h4>2.2.3 주요 결과 및 기술적 기여</h4>
<p>VOLT의 성능은 다양한 기계 번역 데이터셋에서 입증되었다. 대표적으로, WMT-14 영어-독일어 번역 태스크에서 기존 BPE 기반 어휘와 비교했을 때, <strong>어휘 크기를 70%나 줄이면서도 번역 성능 지표인 BLEU 점수를 0.5점 향상</strong>시키는 놀라운 결과를 달성했다.3 이는 더 작고 효율적인 모델로 더 나은 성능을 낼 수 있음을 의미한다. 또한, 최적 어휘를 탐색하는 데 필요한 계산 시간을 기존의 BPE-Search 방식이 384 GPU 시간을 소요한 데 비해, VOLT는 <strong>단 30 GPU 시간 만에 완료</strong>하여 효율성을 극적으로 개선했다.4</p>
<p>이 연구의 가장 큰 기여는 NLP의 가장 근본적인 단계 중 하나인 어휘 구축을 직관과 경험의 영역에서 수학적 원리와 최적화의 영역으로 끌어올렸다는 점이다. 이는 향후 언어 모델의 설계와 학습 과정 전반에 걸쳐 보다 원칙적이고 효율적인 접근을 가능하게 하는 이론적 토대를 마련한 것으로 평가된다.</p>
<h3>2.3  최우수 주제 논문 (Best Theme Paper): 자연어 처리에 수어(Signed Language) 포함하기</h3>
<h4>2.3.1 문제 제기: NLP 연구의 사각지대와 사회적 불평등</h4>
<p>자연어 처리 기술은 비약적으로 발전했지만, 그 혜택은 주로 텍스트나 음성으로 표현되는 언어에 집중되어 왔다. 전 세계적으로 약 7천만 명의 청각 장애인이 사용하는 200여 개의 고유한 수어(Signed Language)는 완전한 언어학적 체계를 갖춘 자연어임에도 불구하고, NLP 연구 커뮤니티에서 거의 완벽하게 소외되어 왔다.18 이러한 기술적 배제는 청각 장애인 커뮤니티의 정보 접근성을 심각하게 저해하고, 교육, 고용, 사회 참여 등 여러 방면에서 디지털 격차와 사회적 불평등을 심화시키는 원인이 되었다.</p>
<p>기존의 수어 처리(Sign Language Processing, SLP) 연구는 대부분 컴퓨터 비전(CV) 커뮤니티의 주도로 이루어졌다. 이들 연구는 수어의 시각적 측면, 즉 손의 모양이나 움직임을 인식하는 데 초점을 맞추었으나, 수어가 가진 복잡하고 다층적인 언어학적 구조를 제대로 반영하지 못하는 명백한 한계를 보였다.5 이 논문은 이러한 현실을 직시하고, NLP 커뮤니티가 수어를 연구의 중심 영역으로 포용해야 할 기술적, 사회적 당위성을 역설하는 입장 논문(position paper)이다.</p>
<h4>2.3.2 수어의 고유한 언어학적 특성과 NLP의 도전 과제</h4>
<p>이 논문은 NLP 연구자들이 수어를 모델링할 때 반드시 고려해야 할 고유한 언어학적 특성들을 제시하며, 이것이 기존 NLP 모델에 제기하는 근본적인 도전 과제들을 설명한다.</p>
<ul>
<li>
<p><strong>시각-운동 양식(Visual-gestural modality):</strong> 수어는 음성 기관이 아닌 손, 팔, 얼굴, 상반신 등의 움직임과 3차원 공간을 활용하여 의미를 전달한다. 이는 1차원적인 텍스트 시퀀스와는 근본적으로 다른 데이터 형태를 가진다.5</p>
</li>
<li>
<p><strong>동시성(Simultaneity):</strong> 수어의 가장 큰 특징 중 하나는 여러 정보 채널을 통해 다수의 의미가 동시에 전달될 수 있다는 점이다. 예를 들어, 한 손으로는 특정 대상을 지칭하는 사인을 하면서, 다른 손으로는 그 대상의 움직임을 묘사하고, 동시에 얼굴 표정으로는 그에 대한 감정이나 긍정/부정과 같은 문법적 정보를 표현할 수 있다. 이처럼 정보가 병렬적으로, 동시에 인코딩되는 특성은 정보를 선형적인(sequential) 순서로 처리하도록 설계된 기존의 트랜스포머와 같은 NLP 아키텍처에 근본적인 수정을 요구한다.5</p>
</li>
<li>
<p><strong>공간 문법(Spatial Grammar):</strong> 수어는 대화가 이루어지는 화자 앞의 3차원 공간을 문법적으로 적극 활용한다. 예를 들어, 문장에 등장하는 인물이나 사물을 특정 공간상의 위치에 설정(assign)한 뒤, 그 위치를 가리키거나 그 위치들 사이에서 동사를 움직이는 방향을 통해 ’누가 누구에게’와 같은 문법적 관계를 명확히 표현한다. 이러한 공간적 참조와 문법은 기존 NLP의 통사론이나 의미론 분석 체계로는 포착하기 어려운 새로운 차원의 문제이다.5</p>
</li>
</ul>
<h4>2.3.3 NLP 커뮤니티를 향한 4대 촉구 사항</h4>
<p>이러한 도전 과제들을 극복하고 수어를 NLP의 영역으로 성공적으로 통합하기 위해, 저자들은 NLP 커뮤니티를 향해 다음과 같은 네 가지 구체적인 행동을 강력히 촉구했다.</p>
<ol>
<li>
<p><strong>효율적인 토큰화 방법론 채택:</strong> 현재 수어 연구에서 주로 사용되는 ’글로스(glosses)’라는 텍스트 기반 주석 방식은 수어의 동시성과 공간 정보를 대부분 손실시키는 심각한 한계가 있다. 이를 극복하고 정보 손실을 최소화하는 새로운 형태의 토큰화 표준을 개발하고 채택해야 한다.5</p>
</li>
<li>
<p><strong>언어학 기반 모델 개발:</strong> 수어의 고유한 언어학적 특성, 특히 동시성과 공간 문법을 효과적으로 모델링할 수 있는 새로운 모델 아키텍처에 대한 연구가 시급하다. 이는 기존의 텍스트 기반 모델을 단순히 적용하는 수준을 넘어서는 근본적인 혁신을 요구한다.5</p>
</li>
<li>
<p><strong>실제 데이터 수집:</strong> 편향되지 않고, 다양한 화자와 실제 사용 환경을 포괄하는 대규모 수어 데이터셋을 구축하는 것은 필수적이다. 데이터의 부족은 현재 수어 처리 연구의 가장 큰 병목 중 하나이다.5</p>
</li>
<li>
<p><strong>수어 커뮤니티와의 협력:</strong> 모든 연구 개발 과정에서 실제 수어 사용자인 청각 장애인 커뮤니티가 단순한 데이터 제공자나 피험자가 아닌, 연구 방향을 설정하고 기술을 평가하는 주도적인 파트너로서 참여해야 한다. 이는 기술이 실제 커뮤니티에 도움이 되고 윤리적인 문제를 방지하기 위해 반드시 필요하다.5</p>
</li>
</ol>
<p>ACL 2021에서 발표된 이 두 최우수 논문은 자연어 처리 연구가 나아가야 할 두 가지 중요한 방향성을 명확하게 제시한다. 한편으로는 VOLT 논문에서 볼 수 있듯이, NLP의 가장 기초적인 구성 요소인 ’어휘’를 최적화 이론이라는 엄밀한 수학적 도구로 재해석하여 기술적 깊이를 더하는 ’수학적 엄밀성의 심화’가 있다. 이는 시스템의 내부적인 완성도와 효율성을 극대화하려는 흐름이다. 다른 한편으로는 ‘수어 포함하기’ 논문에서 나타나듯이, NLP 기술이 포괄해야 하는 ’언어’의 정의 자체를 확장하고 기술 개발의 사회적 책임을 강조하며 외부적인 영향력과 포용성을 추구하는 ’사회적 포용성의 확장’이 있다.</p>
<p>이 두 논문이 같은 해에 나란히 최고상으로 선정되었다는 사실은, 2021년 NLP 커뮤니티가 기술적 정교함을 극한으로 추구하는 동시에, 그 기술이 현실 세계의 다양성을 포용하고 실질적인 사회적 가치를 창출해야 한다는 이중의 과제를 깊이 인식하고 있었음을 보여준다. 이는 AI 연구가 순수한 이론 과학을 넘어, 사회와 끊임없이 상호작용하며 발전하는 응용 과학으로서의 정체성을 강화하고 있음을 시사하는 중요한 변화이다. 더 나아가, 수어 연구가 제기한 도전 과제들은 기존 텍스트 기반 거대 언어 모델(LLM)의 근본적인 한계를 드러낸다. 수어의 ’동시성’과 ’공간 문법’은 정보를 선형적 시퀀스로 처리하는 표준 트랜스포머 아키텍처에 직접적으로 도전하며 5, 이를 해결하기 위해서는 텍스트, 이미지, 신체 포즈, 얼굴 표정 등 여러 모달리티의 정보를 시간적으로 정렬하고 이들 간의 복잡한 상호작용을 모델링할 수 있는 새로운 아키텍처가 필수적이다. 따라서 이 논문은 단순히 ’소외된 언어’를 다루는 것을 넘어, 텍스트와 이미지를 단순히 병치하는 수준을 넘어서는 ‘진정한 멀티모달리티’ AI 연구의 필요성을 역설하며, 이후 시각-언어 모델(VLM)의 발전 방향, 특히 시공간적 추론과 신체 기반 상호작용(embodied interaction) 모델링 연구에 중요한 이론적 기반을 제공했다.</p>
<h2>3.  컴퓨터 비전의 새로운 패러다임: ICCV 2021 Swin Transformer</h2>
<h3>3.1 개요</h3>
<p>2021년 10월 11일부터 17일까지 가상으로 개최된 ’IEEE/CVF 국제 컴퓨터 비전 학회(ICCV 2021)’는 컴퓨터 비전 분야의 양대 최고 학회 중 하나로, 이 해에는 자연어 처리 분야에서 시작된 트랜스포머 혁명이 비전 분야를 어떻게 재편하고 있는지를 명확히 보여주는 장이 되었다.20 수많은 혁신적인 연구 중에서도, 최고 영예인 Marr Prize(최우수 논문상)를 수상한 ’Swin Transformer’는 발표 직후부터 엄청난 영향력을 발휘하며 이후 컴퓨터 비전 분야의 표준 아키텍처 중 하나로 확고히 자리매김했다.</p>
<h3>3.2  Vision Transformer(ViT)의 한계와 Swin Transformer의 등장 배경</h3>
<p>Swin Transformer의 등장을 이해하기 위해서는 그 선행 연구인 Vision Transformer(ViT)의 성공과 그에 따른 과제를 먼저 살펴볼 필요가 있다. 2020년 말 구글 브레인 팀이 발표한 ViT는 지난 수년간 컴퓨터 비전 분야를 지배해 온 합성곱 신경망(CNN)을 전혀 사용하지 않고, 오직 트랜스포머 아키텍처만으로 이미지 분류에서 뛰어난 성능을 달성하여 학계에 큰 충격을 주었다. 하지만 ViT는 혁신적인 접근에도 불구하고 실용적인 적용에 있어 두 가지 주요한 한계를 가지고 있었다.7</p>
<p>첫째, <strong>이차 복잡도(Quadratic Complexity)</strong> 문제이다. 트랜스포머의 핵심인 셀프 어텐션(Self-attention) 메커니즘은 입력 시퀀스의 모든 토큰 쌍 간의 관계를 계산하므로, 계산량과 메모리 사용량이 토큰 수의 제곱에 비례하여 증가한다. 텍스트와 달리 이미지는 픽셀 수가 매우 많아 고해상도 이미지를 처리할 경우 토큰(이미지 패치) 수가 기하급수적으로 늘어난다. 이로 인해 ViT를 객체 탐지나 시맨틱 분할과 같이 픽셀 단위의 조밀한 예측(dense prediction)이 필요한 고해상도 작업에 직접 적용하기는 매우 비효율적이었다.7</p>
<p>둘째, **단일 해상도 특징 맵(Single-resolution Feature Map)**의 한계이다. ViT는 입력 이미지를 패치로 나눈 뒤, 전체 네트워크를 통과하는 동안 패치의 해상도를 동일하게 유지한다. 이는 다양한 크기의 객체를 효과적으로 인식하기 위해 저해상도에서는 전역적인 특징을, 고해상도에서는 지역적인 특징을 추출하는 계층적 특징 맵(hierarchical feature maps)을 사용하는 CNN과 대조되는 방식이었다. 이러한 구조적 차이로 인해 ViT는 다양한 스케일의 시각적 정보를 처리하는 데 상대적으로 불리했다.7</p>
<h3>3.3  Swin Transformer 아키텍처 심층 분석: Shifted Window Self-Attention</h3>
<p>Swin Transformer는 ViT의 이러한 한계를 극복하고 트랜스포머를 컴퓨터 비전 분야의 범용 백본(general-purpose backbone)으로 만들기 위해 제안되었다.6 핵심 아이디어는 CNN의 가장 큰 장점인 ’계층적 표현 학습’과 ’지역성(locality)’이라는 귀납적 편향(inductive bias)을 트랜스포머 프레임워크에 효과적으로 다시 도입하는 것이었다.7</p>
<h4>3.3.1 계층적 특징 맵 (Hierarchical Feature Maps)</h4>
<p>Swin Transformer는 CNN과 유사한 계층적 구조를 통해 다양한 스케일의 특징을 추출한다. 이는 ’패치 병합(Patch Merging)’이라는 간단하면서도 효과적인 기법을 통해 구현된다. 네트워크는 4x4 픽셀 크기의 작은 패치들로 시작한다. 네트워크의 각 ’단계(Stage)’가 끝날 때마다, 인접한 2x2 패치 그룹을 하나의 새로운 패치로 병합한다. 이 과정은 특징 맵의 공간적 해상도를 절반으로 줄이는(downsampling) 동시에, 채널 차원을 두 배로 늘리는 효과를 가져온다. 이로써 네트워크의 깊이가 깊어짐에 따라 CNN의 풀링(pooling) 레이어와 유사하게 점차 저해상도의 전역적 특징을 학습하게 되며, 이는 다양한 크기의 객체를 탐지하고 분할하는 데 매우 유리하게 작용한다.7</p>
<h4>3.3.2 Windowed &amp; Shifted Window Multi-head Self-Attention (W-MSA &amp; SW-MSA)</h4>
<p>Swin Transformer의 가장 핵심적인 혁신은 ViT의 이차 복잡도 문제를 해결하기 위해 제안된 ‘Shifted Window’ 기반의 셀프 어텐션 메커니즘이다.</p>
<ul>
<li>
<p><strong>선형 복잡도 달성 (W-MSA):</strong> ViT가 전체 이미지의 모든 패치에 대해 전역적(global) 셀프 어텐션을 계산하는 것과 달리, Swin Transformer는 먼저 특징 맵을 겹치지 않는 여러 개의 작은 윈도우(window)로 분할한다. 그리고 셀프 어텐션 계산을 각 윈도우 내부에서만 독립적으로 수행한다. 이를 **Windowed Multi-head Self-Attention (W-MSA)**라고 한다. 각 윈도우에 포함된 패치의 수는 이미지 크기와 무관하게 고정되어 있으므로, 전체 계산 복잡도는 이미지 크기에 대해 이차적이 아닌 선형(linear)으로 감소한다. 이는 고해상도 이미지를 효율적으로 처리할 수 있게 하는 결정적인 역할을 한다.7</p>
</li>
<li>
<p><strong>윈도우 간 정보 교류 (SW-MSA):</strong> 하지만 W-MSA는 셀프 어텐션의 범위를 윈도우 내부로 제한하기 때문에, 서로 다른 윈도우에 속한 패치들 간의 정보 교류가 차단된다는 명백한 한계를 가진다. 모델의 표현력을 높이기 위해서는 이러한 윈도우 간의 연결이 필수적이다. Swin Transformer는 이 문제를 해결하기 위해 **Shifted Window Multi-head Self-Attention (SW-MSA)**라는 독창적인 방법을 제안했다. 이는 연속된 두 개의 트랜스포머 블록을 한 쌍으로 묶어, 첫 번째 블록에서는 일반적인 W-MSA를 수행하고, 두 번째 블록에서는 윈도우 분할 격자를 윈도우 크기의 절반만큼 대각선 방향으로 이동(shift)시킨 후 W-MSA를 수행하는 방식이다. 이 간단한 ’이동’을 통해, 이전 레이어에서는 서로 다른 윈도우에 속해 있던 패치들이 새로운 레이어에서는 같은 윈도우에 속하게 되어 서로 상호작용할 수 있게 된다. 이 과정을 네트워크 전체에 걸쳐 반복함으로써, 결과적으로는 모든 패치가 이미지의 다른 모든 패치와 간접적으로 정보를 교환할 수 있게 되어, 낮은 계산 비용으로 전역적 셀프 어텐션의 효과를 효율적으로 근사한다.7</p>
</li>
</ul>
<h3>3.4  성능 및 영향력</h3>
<p>Swin Transformer는 이러한 혁신적인 설계를 바탕으로 이미지 분류, 객체 탐지, 시맨틱 분할 등 컴퓨터 비전의 핵심적인 3대 벤치마크에서 당시의 모든 모델을 능가하는 최고 성능(State-Of-The-Art, SOTA)을 달성했다.7</p>
<table><thead><tr><th>Task</th><th>Model</th><th>Metric</th><th>Performance</th></tr></thead><tbody>
<tr><td>Image Classification (ImageNet-1K)</td><td>Swin-B</td><td>Top-1 Accuracy</td><td>87.3%</td></tr>
<tr><td>Object Detection (COCO test-dev)</td><td>Swin-L (Cascade Mask R-CNN)</td><td>Box AP / Mask AP</td><td>58.7 / 51.1</td></tr>
<tr><td>Semantic Segmentation (ADE20K val)</td><td>Swin-L (UperNet)</td><td>mIoU</td><td>53.5</td></tr>
</tbody></table>
<p>이러한 압도적인 성능과 높은 효율성을 바탕으로, Swin Transformer는 발표 직후부터 ResNet이나 EfficientNet과 같은 기존의 CNN 기반 백본을 대체하는 새로운 표준으로 빠르게 자리 잡았다. 특히 계층적 구조 덕분에 다양한 다운스트림 비전 태스크에 손쉽게 적용할 수 있는 범용성(general-purpose)을 갖추어, 이후 수많은 비전 연구에서 기본 백본 아키텍처로 채택되었다.7</p>
<p>Swin Transformer의 성공은 단순히 새로운 고성능 모델의 등장을 의미하는 것을 넘어, AI 아키텍처 발전의 방향성에 대한 중요한 통찰을 제공한다. 이는 ’순수 트랜스포머’로의 완전한 전환이 최선이 아닐 수 있으며, 오히려 트랜스포머와 CNN이라는 두 지배적인 패러다임의 핵심 원리를 성공적으로 ’융합’하는 것이 더 강력한 해법이 될 수 있음을 입증한 사례이다. ViT는 CNN의 핵심적인 귀납적 편향인 지역성(locality)과 이동 불변성(translation invariance)을 과감히 버리고 순수한 트랜스포머의 전역적 어텐션에 의존했다. 이는 혁신적이었지만 고해상도 이미지 처리의 효율성 측면에서 실용적인 한계를 드러냈다.7 반면, Swin Transformer는 CNN의 핵심 철학인 ’계층적 구조’와 ’지역적 연산’을 각각 ’패치 병합’과 ’윈도우 기반 어텐션’이라는 트랜스포머 시대의 언어로 성공적으로 재해석하여 프레임워크 안에 다시 도입했다.7 특히 ‘Shifted Window’ 메커니즘은 지역적 연산의 한계를 극복하고 전역적 정보를 효율적으로 통합하는, 트랜스포머 시대에 맞는 새로운 ’연결 메커니즘’을 발명한 것에 비유할 수 있다. 결론적으로, Swin Transformer는 ’CNN을 버리는 것’이 아니라 ’CNN의 핵심 원리를 트랜스포머의 틀 안에서 창의적으로 재구성’함으로써 성공했다. 이는 AI 연구에서 완전히 새로운 아이디어만이 돌파구를 만드는 것이 아니라, 기존의 검증된 원리들을 새로운 프레임워크와 변증법적으로 결합하는 것이 더 강력하고 실용적인 결과를 낳을 수 있다는 중요한 교훈을 남겼다.</p>
<h2>4.  지능형 로봇 기술 동향: IROS 2021 주요 연구</h2>
<h3>4.1 개요</h3>
<p>2021년 9월 27일부터 10월 1일까지 체코 프라하에서 온/오프라인 하이브리드 형태로 개최된 ’IEEE/RSJ 지능형 로봇 및 시스템 국제 학회(IROS 2021)’는 로봇 공학 및 지능형 시스템 분야의 세계적인 학회이다.30 이 해의 연구들은 AI, 특히 딥러닝과 컴퓨터 비전 기술이 로봇의 인식(perception), 조작(manipulation), 자율 주행(navigation) 능력을 어떻게 근본적으로 혁신하고 있는지를 명확히 보여주었다. 학회 전반에 걸쳐 인간-로봇 협업(Human-Robot Collaboration, HRC), 딥러닝 기반의 정교한 조작 및 인식, 그리고 복잡한 환경에서의 자율 시스템 운용과 관련된 주제들이 주요 트렌드로 부상했다.31</p>
<h3>4.2  최우수 논문 (Best Paper): 확장된 촉각 인지 - 뉴로모픽 기반 로봇-도구 상호작용</h3>
<h4>4.2.1 문제 제기: 로봇 촉각의 한계와 도구 사용의 중요성</h4>
<p>인간은 포크로 음식을 찍거나 칼로 재료를 썰 때, 도구의 끝에서 발생하는 미세한 진동을 손의 피부에 있는 기계수용체(mechanoreceptor)를 통해 감지한다. 이를 통해 우리는 시각 정보 없이도 접촉 여부, 대상의 단단함, 표면의 질감 등을 미세하게 파악할 수 있다. 이처럼 도구를 신체의 일부처럼 사용하여 감각을 확장하는 능력은 인간의 정교한 조작 능력의 핵심이다. 그러나 기존의 로봇들은 대부분 그리퍼나 손가락 끝에 부착된 압력 센서를 통해 직접적인 접촉만을 감지할 수 있었다. 이로 인해 로봇이 도구를 사용할 때, 도구를 통해 전달되는 풍부한 촉각 정보를 활용하지 못하여 인간과 같은 섬세한 조작을 수행하는 데 한계가 있었다.8</p>
<h4>4.2.2 핵심 방법론: 뉴로모픽 센서와 머신러닝 프레임워크</h4>
<p>이 연구는 로봇에게 인간과 같은 ‘확장된 촉각 인지’ 능력을 부여하기 위해 생체모방(bio-inspired) 접근법을 채택했다.</p>
<ul>
<li>
<p><strong>뉴로모픽 촉각 센서 개발:</strong> 연구팀은 인간 피부의 기계수용체가 미세 진동을 감지하여 뇌로 전달하는 원리에서 영감을 얻었다. 이를 모방하여, 도구를 통해 전달되는 미세한 고주파 진동 신호를 매우 빠르고 민감하게 포착할 수 있는 새로운 뉴로모픽(neuromorphic) 촉각 센서를 설계 및 제작했다. 이 센서는 로봇의 그리퍼에 부착되어, 로봇이 쥔 도구로부터 전달되는 진동을 전기 신호로 변환한다.8</p>
</li>
<li>
<p><strong>머신러닝 기반 신호 해석:</strong> 센서로부터 수집된 미세 진동 신호는 매우 복잡하고 노이즈가 많은 시계열 데이터이다. 연구팀은 이 신호로부터 의미 있는 정보를 추출하기 위한 머신러닝 프레임워크를 제안했다. 이 프레임워크는 수집된 진동 데이터를 분석하여, 그것이 어떤 종류의 상호작용(예: 단단한 물체와의 접촉, 부드러운 물체와의 접촉, 미끄러짐 등)으로부터 발생했는지를 분류하고 해석하는 역할을 한다.8</p>
</li>
</ul>
<h4>4.2.3 주요 결과 및 응용 가능성</h4>
<p>연구팀은 실험을 통해 제안된 시스템의 유효성을 성공적으로 입증했다. 로봇이 포크와 같은 도구를 잡고 있는 상태에서, 시각이나 청각 정보 없이 순전히 도구를 통해 전달되는 촉각 진동 신호만으로 도구의 끝이 사과 조각과 같은 다른 물체와 접촉했는지 여부를 매우 높은 정확도로 판단할 수 있음을 보였다.8 또한, 이 기술을 인간과 로봇 간의 물체 핸드오버 상황이나 다양한 종류의 식품을 분류하는 태스크에 적용하여 그 실용성을 확인했다.</p>
<p>이 연구는 로봇 조작 기술의 새로운 가능성을 열었다. 예를 들어, 미래의 의료용 수술 로봇은 이 기술을 통해 수술 도구 끝에서 느껴지는 미세한 진동으로 조직의 상태를 실시간으로 파악하여 더 정밀하고 안전한 수술을 수행할 수 있다. 또한, 가정용 서비스 로봇은 주방 도구를 더 능숙하게 다루어 요리를 하거나, 다양한 물체를 더 섬세하게 조작할 수 있게 될 것이다. 이 연구는 로봇이 단순히 프로그래밍된 동작을 수행하는 것을 넘어, 도구를 통해 주변 환경과 상호작용하며 ’감각’하는 단계로 나아갈 수 있음을 보여주었다.8</p>
<h3>4.3  최우수 학생 논문 (Best Student Paper): “소프트” 드론을 이용한 동적 파지: 이론에서 실제까지</h3>
<p>(주: IROS 2021 최우수 학생 논문상 수상작으로 MIT LIDS 팀의 드론 파지 관련 연구가 언급되었으나 9, 기술적 상세 내용이 더 풍부하게 공개된 Columbia 대학 팀의 동적 파지 프레임워크 연구 34를 중심으로 분석을 진행한다. 두 연구 모두 ’동적 파지’라는 공통된 주제를 다루고 있다.)</p>
<h4>4.3.1 문제 제기: 동적 환경에서의 파지(Grasping) 문제</h4>
<p>컨베이어 벨트 위를 움직이는 물체를 잡거나, 날아오는 물체를 잡는 것과 같은 동적 환경에서의 파지(dynamic grasping)는 로봇 공학의 오랜 난제 중 하나이다. 정지된 물체를 파지하는 것과 달리, 목표물의 미래 위치를 정확히 예측해야 하고, 예측된 위치에 맞춰 로봇 팔의 경로를 실시간으로 재계획해야 한다. 또한, 목표물의 움직임 때문에 안정적이었던 파지 자세가 불안정해지거나, 로봇 팔이 도달할 수 없는 위치로 벗어날 수 있다. 이러한 모든 요소를 수 밀리초(milliseconds) 단위의 짧은 시간 안에 동시에 고려하여 최적의 결정을 내려야 한다.11</p>
<h4>4.3.2 핵심 방법론: Reachability &amp; Motion-Awareness 프레임워크</h4>
<p>이 연구는 동적 파지라는 복잡한 문제를 해결하기 위해, 기하학적 사전 계산, 데이터 기반 학습, 효율적 경로 계획이라는 여러 기술을 유기적으로 결합한 통합 프레임워크를 제시했다.</p>
<ul>
<li>
<p><strong>도달 가능성 인식(Reachability-Awareness):</strong> 로봇이 수많은 잠재적 파지 후보 중에서 물리적으로 불가능한 것들을 실시간으로 빠르게 배제할 수 있도록, 로봇의 작업 공간 전체에 대한 ’도달 가능성 맵’을 미리 계산해 둔다. 이 맵은 부호화 거리 필드(Signed Distance Field, SDF)라는 데이터 구조로 저장되며, 특정 위치와 방향으로 그리퍼가 도달할 수 있는지, 있다면 얼마나 용이한지를 나타내는 값을 담고 있다. 이를 통해 파지 계획 단계에서 비현실적인 후보들을 즉시 제거하여 계산 효율을 극적으로 높인다.11</p>
</li>
<li>
<p><strong>움직임 인식(Motion-Awareness):</strong> 정적인 상태에서는 안정적인 파지라도, 물체가 특정 방향으로 움직일 때는 미끄러지거나 불안정해질 수 있다. 이러한 동적 안정성을 평가하기 위해, 연구팀은 목표물의 현재 움직임(속도, 방향 등)을 입력으로 받아 해당 파지의 성공 확률(품질)을 예측하는 신경망을 사전 학습시켰다. 파지 계획 시, 로봇은 이 신경망을 이용해 현재 상황에서 가장 안정적인 파지 자세를 동적으로 선택한다.11</p>
</li>
<li>
<p><strong>궤적 시딩(Trajectory Seeding):</strong> 목표물이 계속 움직이기 때문에 로봇 팔의 경로는 매 순간 수정되어야 한다. 이때 매번 처음부터 최적 경로를 계산하는 것은 매우 비효율적이다. 이 연구는 ’궤적 시딩’이라는 기법을 제안했는데, 이는 이전 시간 단계(time step)에서 계산했던 경로를 현재 시간 단계의 경로 계획을 위한 ’초기값(seed)’으로 활용하는 방식이다. 이를 통해 최적화 알고리즘이 훨씬 빠르게 수렴할 수 있으며, 로봇의 움직임이 급격하게 변하지 않고 부드럽게 유지되는 효과도 얻을 수 있다.11</p>
</li>
</ul>
<h4>4.3.3 기술적 기여</h4>
<p>이 연구는 동적 파지라는 복잡한 실시간 문제를 해결하기 위해, 기하학적 제약(SDF), 데이터 기반의 동적 안정성 예측(신경망), 그리고 효율적인 실시간 경로 계획(시딩)이라는 세 가지 핵심 요소를 성공적으로 통합한 프레임워크를 제시했다는 점에서 큰 의의가 있다. 이는 로봇이 고도로 통제된 환경을 벗어나 예측 불가능하고 동적인 현실 세계와 상호작용하기 위해 필요한 핵심 기술 요소들을 체계적으로 결합한 좋은 사례이다.</p>
<p>IROS 2021의 주요 수상 논문들은 로봇 공학 연구의 중심 과제가 과거의 ’정밀한 제어’에서 ’불확실한 환경과의 상호작용’으로 이동하고 있음을 명확히 보여준다. ‘확장된 촉각 인지’ 연구는 로봇이 단순히 명령을 수행하는 기계를 넘어, 도구를 통해 미세한 신호를 ’느끼고 해석’하여 예측 불가능한 접촉 상황에 대응하는 능력을 목표로 한다.8 ‘동적 파지’ 연구는 움직이는 물체라는 ’불확실성’에 실시간으로 대응하는 것을 목표로 한다.34 두 연구 모두 공장과 같은 고도로 통제되고 정형화된 환경이 아닌, 일상생활이나 예측 불가능한 현장과 같은 비정형 환경(unstructured environments)에서 로봇이 효과적으로 작동하기 위해 필수적인 능력들을 다루고 있다. 이는 로봇 공학의 패러다임이 ’프로그래밍된 작업의 완벽한 수행’에서 ’끊임없이 변화하는 현실 세계에 대한 적응과 상호작용’으로 전환되고 있음을 보여주는 강력한 증거이며, 로봇이 인간의 생활 공간으로 들어오기 위한 필연적인 발전 방향을 제시한다.</p>
<p>더 나아가, 이 연구들은 현대 로봇 공학의 혁신이 더 이상 기구학이나 제어 이론과 같은 전통적인 로봇 공학 분야에만 국한되지 않음을 보여준다. ’확장된 촉각 인지’는 뉴로모픽 센서(재료 과학/전자 공학) 기술과 머신러닝 기반 신호 처리(AI) 기술의 결합이며 8, ’동적 파지’는 로봇 기구학, 컴퓨터 비전(물체 추적), 머신러닝(품질 예측), 경로 계획 알고리즘이 총동원된 복합 시스템이다.11 이는 현대 로봇 공학의 주요 난제들이 단일 학문의 지식만으로는 해결될 수 없으며, 여러 분야의 최신 기술을 통합하는 시스템 엔지니어링 역량이 그 어느 때보다 중요해졌음을 의미한다. 즉, 미래의 로봇 공학 연구는 ’로봇’이라는 하드웨어 플랫폼 위에서 다양한 AI 및 센서 기술이 어떻게 유기적으로 통합되고 시너지를 낼 수 있는가를 탐구하는 방향으로 더욱 심화될 것이다.</p>
<h2>5. 결론: 2021년 AI 연구의 통합적 조망과 미래 전망</h2>
<h3>5.1 핵심 동향 종합</h3>
<p>2021년 8월을 기점으로 세계 최고 권위의 학회들에서 발표된 주요 연구들을 심층 분석한 결과, 당시 AI 기술은 세 가지 핵심적인 흐름을 중심으로 발전하고 있었음을 명확히 확인할 수 있다.</p>
<ol>
<li>
<p><strong>트랜스포머 아키텍처의 범용화:</strong> 자연어 처리 분야에서 시작된 트랜스포머는 Swin Transformer의 등장을 통해 컴퓨터 비전 분야에서도 그 효율성과 성능을 입증하며 표준 백본 아키텍처로 자리 잡았다. 이는 특정 도메인에 국한되지 않는 강력한 단일 아키텍처가 다양한 AI 문제를 해결하는 기반이 될 수 있음을 시사하며, AI 모델 개발의 패러다임을 통일시키는 거대한 흐름을 형성했다.</p>
</li>
<li>
<p><strong>이론적 깊이와 사회적 책임의 동시 추구:</strong> NLP 분야에서는 VOLT 연구처럼 어휘 구축이라는 근본적인 문제를 수학적 최적화 이론으로 접근하여 기술적 깊이를 더하려는 노력이 인정받는 동시에, ‘수어 포함하기’ 연구처럼 기술 발전의 혜택에서 소외된 커뮤니티를 포용하고 기술의 사회적 책임을 고민하는 흐름이 중요한 의제로 부상했다. 이는 AI 연구 커뮤니티가 기술적 성숙과 함께 학문적, 사회적 지평을 동시에 넓혀가고 있음을 보여준다.</p>
</li>
<li>
<p><strong>AI와 로보틱스의 심층 융합:</strong> 로봇 공학 분야에서는 AI 기술, 특히 딥러닝과 첨단 센서 기술이 로봇의 물리적 상호작용 능력을 근본적으로 혁신하고 있었다. 뉴로모픽 센서를 통한 인간 수준의 촉각 인지 능력 구현이나, 동적 환경에서의 실시간 파지 계획은 AI가 로봇의 ’뇌’뿐만 아니라 ’감각’과 ’행동’을 직접적으로 고도화하고 있음을 보여주었다. 이를 통해 로봇은 과거에는 불가능했던 수준의 자율성과 환경 적응성을 확보하기 시작했다.</p>
</li>
</ol>
<h3>5.2 미래 전망</h3>
<p>본 보고서에서 분석한 2021년의 선도적인 연구들은 이후 AI 기술 발전의 중요한 이정표가 되었으며, 현재 진행 중인 기술 혁신의 씨앗을 품고 있었다.</p>
<ul>
<li>
<p>Swin Transformer가 제시한 ’효율적인 범용 비전 백본’이라는 개념은 이후 텍스트와 이미지를 동시에 이해하는 멀티모달 거대 언어 모델(LLM)의 기반이 되는 시각-언어 모델(Vision-Language Model)의 폭발적인 발전을 촉진하는 핵심적인 기술적 토대가 되었다.</p>
</li>
<li>
<p>수어 연구가 제기한 ’비-텍스트, 비-음성 언어’에 대한 도전은 AI 기술의 포용성을 높이는 연구 방향을 제시했을 뿐만 아니라, 손의 움직임, 얼굴 표정, 공간적 관계 등 복잡한 시공간적 데이터를 종합적으로 이해하고 생성해야 하는 진정한 멀티모달리티 연구의 중요성을 부각시켰다.</p>
</li>
<li>
<p>로보틱스 분야에서 나타난 인간 수준의 감각과 상호작용에 대한 연구는, 로봇이 통제된 공장 환경을 벗어나 예측 불가능한 일상 공간에서 인간과 안전하게 공존하고 협력하는 ‘협력적 지능(Collaborative Intelligence)’ 시대를 여는 핵심 기술로 지속적으로 발전할 것이다.</p>
</li>
</ul>
<h3>5.3 종합적 의의</h3>
<p>결론적으로, 2021년은 AI 기술이 각자의 영역에서 개별적으로 발전하던 단계를 지나, 트랜스포머라는 강력한 공통 아키텍처를 기반으로 서로 융합하고, 이론적 깊이와 사회적 책임을 동시에 추구하며, 물리적 세계와의 상호작용을 통해 그 지능을 현실 세계로 확장해 나가는 새로운 시대로의 진입을 알린 결정적인 시기였다. 본 보고서에서 분석한 연구들은 이러한 거대한 패러다임 전환의 서막을 연 기념비적인 성과들로, 현재 우리가 경험하고 있는 생성형 AI와 지능형 로봇 시대의 기술적 뿌리를 형성하고 있다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>주요국 AI 사용법 : 디지털플랫폼 정부를 위한 AI 활용 | 국내연구자료 | KDI 경제교육·정보센터, https://eiec.kdi.re.kr/policy/domesticView.do?ac=0000170447</li>
<li>국내 서비스 로봇 산업 육성을 위한 정책 제언, https://keti.re.kr/_upload//issue/2023/07/19/application_85fff474d6b6f83106f413351b4f5e5a.pdf</li>
<li>Vocabulary Learning via Optimal Transport for Neural Machine …, https://aclanthology.org/2021.acl-long.571/</li>
<li>Vocabulary Learning via Optimal Transport for Neural Machine Translation - ACL Anthology, https://aclanthology.org/2021.acl-long.571.pdf</li>
<li>Including Signed Languages in Natural Language Processing - ACL …, https://aclanthology.org/2021.acl-long.570/</li>
<li>ICCV Paper Awards - IEEE Computer Society Technical Committee on Pattern Analysis and Machine Intelligence, https://tc.computer.org/tcpami/awards/iccv-paper-awards/</li>
<li>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows, https://www.computer.org/csdl/proceedings-article/iccv/2021/281200j992/1BmGKZoEzug</li>
<li>Assistant Professor Harold Soh and collaborators win Best Paper …, https://www.comp.nus.edu.sg/news/2021-best-paper-iros/</li>
<li>MIT LIDS Alum LIDS Team Won Best Student Paper Award at IROS …, http://lids-alum.org/alma/lids-team-won-best-student-paper-award-iros-2021/</li>
<li>Fishman, Ubellacker, Hughes, and Carlone win Best Student Paper Award at IROS 2021, https://lids.mit.edu/news-and-events/news/fishman-ubellacker-hughes-and-carlone-win-best-student-paper-award-iros-2021</li>
<li>jingxixu/dynamic-grasping: [IROS 2021] Dynamic Grasping … - GitHub, https://github.com/jingxixu/dynamic-grasping</li>
<li>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) - ACL Anthology, https://aclanthology.org/2021.acl-long.0/</li>
<li>ACL/IJCNLP 2021: Virtual Event - DBLP, https://dblp.org/db/conf/acl/acl2021-1.html</li>
<li>The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021) - ACL-IJCNLP 2021, https://2021.aclweb.org/</li>
<li>Vocabulary Learning via Optimal Transport for Neural Machine Translation - UCSB CS, https://sites.cs.ucsb.edu/~lilei/pubs/xu2021vocabulary.pdf</li>
<li>Lei Li https://lileicc.github.io/course/11737mnlp23fa/, https://lileicc.github.io/course/11737mnlp23fa/slides/multiling-22-vocabulary_learning.pdf</li>
<li>Vocabulary Learning via Optimal Transport for Neural Machine Translation - arXiv, https://arxiv.org/abs/2012.15671</li>
<li>Including Signed Languages in Natural Language Processing (Extended Abstract) - IJCAI, https://www.ijcai.org/proceedings/2022/0753.pdf</li>
<li>LTI Master’s Student Urges NLP Focus on Signed Languages - News, https://www.cmu.edu/news/stories/archives/2021/august/signed-language-processing.html</li>
<li>ICCV 2021: Home, https://iccv2021.thecvf.com/home</li>
<li>ICCV 2021 Open Access Repository, https://openaccess.thecvf.com/ICCV2021</li>
<li>CVF Open Access, https://openaccess.thecvf.com/</li>
<li>[PDF] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows | Semantic Scholar, https://www.semanticscholar.org/paper/Swin-Transformer%3A-Hierarchical-Vision-Transformer-Liu-Lin/c8b25fab5608c3e033d34b4483ec47e68ba109b7</li>
<li>arXiv:2103.14030v2 [cs.CV] 17 Aug 2021, https://arxiv.org/pdf/2103.14030</li>
<li>ICCV 2021 Prizes, https://iccv2021.thecvf.com/sites/default/files/2021-10/ICCV-2021-Prizes.pdf</li>
<li>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows | Request PDF - ResearchGate, https://www.researchgate.net/publication/358999201_Swin_Transformer_Hierarchical_Vision_Transformer_using_Shifted_Windows</li>
<li>Building Swin Transformer from Scratch using PyTorch: Hierarchical Vision Transformer using Shifted Windows | by Shubh Mishra | The Deep Hub | Medium, https://medium.com/thedeephub/building-swin-transformer-from-scratch-using-pytorch-hierarchical-vision-transformer-using-shifted-91cbf6abc678</li>
<li>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows | by Christian Lin, https://medium.com/@crlc112358/swin-transformer-hierarchical-vision-transformer-using-shifted-windows-ca1ccc8760b8</li>
<li>This is an official implementation for “Swin Transformer: Hierarchical Vision Transformer using Shifted Windows”. - GitHub, https://github.com/microsoft/Swin-Transformer</li>
<li>IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2021, Prague, Czech Republic, September 27 - Researchr, https://researchr.org/publication/iros-2021</li>
<li>dectrfov/IROS2021PaperList: IROS 2021 paper list - GitHub, https://github.com/dectrfov/IROS2021PaperList</li>
<li>Top 5 Robot Trends 2021 - International Federation of Robotics, https://ifr.org/ifr-press-releases/news/top-5-robot-trends-2021</li>
<li>Trends of Human-Robot Collaboration in Industry Contexts: Handover, Learning, and Metrics - MDPI, https://www.mdpi.com/1424-8220/21/12/4113</li>
<li>Dynamic Grasping with Reachability and Motion Awareness - Columbia Robotics Lab, http://crlab.cs.columbia.edu/dynamic_grasping/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>