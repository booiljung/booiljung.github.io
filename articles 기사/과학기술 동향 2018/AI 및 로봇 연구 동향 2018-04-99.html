<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2018년 4월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2018년 4월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2018년 AI 및 로봇 연구 동향</a> / <span>2018년 4월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2018년 4월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2018년 인공지능 연구의 변곡점</h2>
<p>2018년 초 인공지능(AI) 연구 지형은 딥러닝이 다양한 분야에서 전례 없는 성공을 거둔 후, 그 기반 기술의 신뢰성과 일반화 가능성에 대한 심도 있는 성찰이 시작되던 시점이었다.1 International Conference on Learning Representations (ICLR), International Conference on Machine Learning (ICML), Neural Information Processing Systems (NeurIPS), AAAI Conference on Artificial Intelligence (AAAI)와 같은 최고 수준의 학회들은 이러한 흐름을 주도하며 AI 연구의 방향을 제시했다.3 이 중에서도 ICLR은 표현 학습(Representation Learning)에 중점을 두어 딥러닝의 가장 핵심적인 질문들을 다루는 학회로 그 위상을 공고히 했다.5</p>
<p>2018년 4월 30일부터 5월 3일까지 캐나다 밴쿠버에서 개최된 ICLR 2018은 이러한 시대적 배경 속에서 특히 중요한 의미를 지닌다.6 이 학회에서 발표된 연구들은 단순한 성능 향상을 넘어, 기존 방법론의 근본적인 결함을 파헤치고 수정하며, 새로운 데이터 영역으로의 확장을 모색하고, 더 일반적인 지능을 향한 새로운 학습 패러다임을 제시하는 등 질적인 전환을 이룬 중요한 이정표로 평가된다. 특히 최우수 논문으로 선정된 연구들은 분야의 흐름이 순수한 아키텍처 혁신(더 깊거나 넓은 네트워크 구축)에서 벗어나, AI 분야 전체를 뒷받침하는 근본적인 도구와 가정을 면밀히 검토하고 수정하는 방향으로 전환되고 있음을 명확히 보여주었다. 이는 AI 분야가 초기 ‘골드러시’ 단계를 지나 보다 과학적이고 자기 비판적인 성숙 단계로 접어들고 있음을 시사한다.</p>
<p>본 보고서는 ICLR 2018의 최우수 논문들을 심층적으로 분석하고, 당시 부상하던 주요 연구 동향을 조망하며, 로보틱스 분야와의 접점을 탐구함으로써 2018년 4월이 AI 연구 역사에 남긴 학문적 유산을 다각도로 조명하고자 한다.</p>
<h2>2.  2018년 ICLR 최우수 논문 심층 분석</h2>
<p>ICLR 2018 최우수 논문으로 선정된 세 편의 연구는 각기 다른 주제를 다루고 있지만, AI 기술의 다음 단계를 위한 핵심 과제인 <strong>신뢰성(Reliability)</strong>, <strong>일반성(Generality)</strong>, <strong>적응성(Adaptability)</strong> 을 해결하려는 공통된 목표를 공유한다. 이들은 개별적인 성과를 넘어, AI의 기초를 강화하고, 적용 범위를 확장하며, 현실 세계에서의 강건성을 높이는 상호 연결된 솔루션을 제시했다는 점에서 그 의의가 매우 크다.</p>
<h3>2.1  Adam 옵티마이저의 수렴성 재고찰: “On the Convergence of Adam and Beyond”</h3>
<p>2015년 제안된 Adam 옵티마이저는 딥러닝 모델 학습의 사실상 표준(de facto standard)으로 자리 잡았다.8 그러나 그 효과성에도 불구하고, 대규모 출력 공간을 갖는 문제 등 특정 상황에서 Adam이 최적해로 수렴하지 못하는 경험적 사례들이 보고되면서 그 이론적 견고성에 대한 의문이 제기되었다.9</p>
<p>이론적 결함 분석: 단기 기억의 함정</p>
<p>해당 연구는 Adam의 핵심적인 문제점으로 지수 이동 평균(exponential moving average) 방식을 지목했다. 이 방식은 과거 그래디언트 정보를 빠르게 감쇠시켜, 알고리즘이 사실상 최근의 그래디언트 정보에만 의존하게 만든다. 이러한 “단기 기억” 메커니즘은 특정 조건에서 과거의 큰 그래디언트 정보를 잊어버리게 하고, 이로 인해 2차 모멘텀 추정치(vt)가 작아져 유효 학습률(α/vt)이 부적절하게 급증하는 현상을 유발할 수 있다. 이는 알고리즘의 수렴을 방해하는 근본적인 원인으로 분석되었다.9</p>
<p>비수렴 증명</p>
<p>논문은 간단한 1차원 볼록 최적화(convex optimization) 예시를 통해 Adam의 비수렴 가능성을 수학적으로 증명했다. 특정 그래디언트 시퀀스가 주어졌을 때, Adam의 2차 모멘텀 추정치 vt가 주기적으로 매우 작아지는 현상을 보였다. 이로 인해 유효 학습률이 급격히 커지면서 파라미터가 최적해에서 멀어지는 발산 현상이 발생함을 명확히 입증했다.9 이는 널리 사용되던 도구의 신뢰성에 대한 중대한 경고였다.</p>
<p>해결책: AMSGrad의 제안</p>
<p>이러한 문제를 해결하기 위해 연구진은 AMSGrad라는 새로운 알고리즘을 제안했다. AMSGrad의 핵심은 2차 모멘텀 추정치를 업데이트하는 방식에 있다. 기존 Adam이 현재의 vt를 사용하는 것과 달리, AMSGrad는 과거의 2차 모멘텀 추정치 최댓값과 현재 값을 비교하여 더 큰 값을 유지한다.<br />
<span class="math math-display">
\hat{v}_t = \max(\hat{v}_{t-1}, v_t)
</span><br />
이 간단한 수정을 통해 학습률이 불필요하게 증가하는 것을 원천적으로 방지하고, 알고리즘이 과거 그래디언트의 “장기 기억(long-term memory)“을 효과적으로 유지하게 하여 볼록 설정에서의 수렴성을 보장한다.10</p>
<p>실험적 검증 및 의의</p>
<p>실험 결과, AMSGrad는 기존 Adam의 비수렴 문제를 해결할 뿐만 아니라, 여러 딥러닝 과제에서 경험적으로도 안정적이거나 더 나은 성능을 보였다.9 이 연구는 딥러닝 커뮤니티에서 가장 널리 사용되는 기본 도구 중 하나의 이론적 결함을 명확히 증명하고 실용적인 해결책을 제시함으로써, AI 연구의 신뢰성을 한 단계 끌어올렸다는 점에서 큰 학문적 기여를 인정받았다.13</p>
<table><thead><tr><th>기능</th><th>Adam 알고리즘</th><th>AMSGrad 알고리즘</th></tr></thead><tbody>
<tr><td>1차 모멘텀</td><td><span class="math math-inline">m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t</span></td><td><span class="math math-inline">m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t</span></td></tr>
<tr><td>2차 모멘텀</td><td><span class="math math-inline">v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2</span></td><td><span class="math math-inline">v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2</span></td></tr>
<tr><td><strong>핵심 차이</strong></td><td><span class="math math-inline">\hat{v}_t = v_t / (1 - \beta_2^t)</span> (Bias Correction)</td><td><span class="math math-inline">\hat{v}_t = \max(\hat{v}_{t-1}, v_t)</span> (Long-term Memory)</td></tr>
<tr><td>파라미터 업데이트</td><td><span class="math math-inline">\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t</span></td><td><span class="math math-inline">\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t</span></td></tr>
</tbody></table>
<h3>2.2  구면 데이터 처리를 위한 새로운 패러다임: “Spherical CNNs”</h3>
<p>기존의 합성곱 신경망(CNN)은 2D 평면 이미지의 격자 구조와 평행 이동 대칭성(translational symmetry)에 고도로 특화되어 있다.14 이로 인해 드론이나 자율주행차의 360도 비전, 분자 구조, 지구 기후 모델링 등 구(sphere)와 같은 비유클리드 공간의 데이터를 처리할 때 근본적인 한계에 직면한다. 구면 데이터를 평면으로 투영하는 과정에서 발생하는 심각한 왜곡은 CNN의 핵심 장점인 가중치 공유(weight sharing)를 무력화시키기 때문이다.17</p>
<p>핵심 아이디어: 회전 등변성 (Rotation Equivariance)</p>
<p>“Spherical CNNs” 연구는 이 문제를 해결하기 위해 평면 CNN의 평행 이동 등변성(translation equivariance) 개념을 구면에서의 회전 등변성으로 확장했다. 즉, 입력 구면 신호가 3차원 공간에서 회전하면, 그에 해당하는 출력 특징 맵도 동일하게 회전해야 한다는 원칙을 수학적으로 구현한 것이다.17 이를 위해 그룹 이론(group theory), 특히 3차원 회전 그룹 <span class="math math-inline">SO(3)</span>에 대한 연산을 기반으로 네트워크를 설계했다.15</p>
<p>방법론: 구면 교차 상관관계 (Spherical Cross-Correlation)</p>
<p>연구진은 회전 등변성을 만족하는 새로운 연산자인 ’구면 교차 상관관계’를 제안했다. 이 연산은 필터를 구면 위에서 모든 가능한 방향으로 회전시키며 입력 신호와의 내적(inner product)을 계산하는 과정이다.16 수식적으로는 다음과 같이 정의된다.<br />
<span class="math math-display">
[\psi \star f](R) = \langle L_R\psi, f \rangle = \int_{S^2} \sum_{k=1}^{K} \psi_k(R^{-1}x)f_k(x)dx
</span><br />
여기서 <span class="math math-inline">f</span>는 입력 신호, <span class="math math-inline">\psi</span>는 필터, <span class="math math-inline">R \in SO(3)</span>는 회전, <span class="math math-inline">x \in S^2</span>는 구면 위의 점을 나타낸다. 이 연산의 결과로 생성되는 출력 특징 맵은 구면(S2) 위의 신호가 아니라 회전 그룹(SO(3)) 상의 신호가 된다는 점이 중요한 특징이다.16</p>
<p>효율적 계산: 일반화된 FFT</p>
<p>구면 교차 상관관계의 직접적인 계산은 엄청난 연산량을 요구한다. 이 문제를 해결하기 위해 비가환 조화 해석(non-commutative harmonic analysis) 이론을 활용한 일반화된 고속 푸리에 변환(FFT)을 적용했다.14 신호와 필터를 각각 구면 조화 함수(Spherical Harmonics) 기저로 분해하여 주파수 공간에서 연산을 수행함으로써 계산 효율성을 획기적으로 높였다.21</p>
<p>실험 및 의의</p>
<p>구면 MNIST, 3D 모델 인식, 분자 에너지 회귀 등 다양한 실험에서 Spherical CNN은 기존 방식 대비 월등한 성능과 데이터 효율성을 입증했다.19 이 연구는 기하학적 딥러닝(Geometric Deep Learning) 분야의 중요한 이정표로서, 딥러닝의 적용 범위를 유클리드 공간을 넘어 다양한 기하학적 구조로 확장하는 이론적, 실용적 기반을 마련했다. 이는 AI의 일반성을 데이터의 기하학적 구조 차원으로 확장한 중요한 성과이다.14</p>
<h3>2.3  비정상 환경에서의 지속적 적응: “Continuous Adaptation via Meta-learning”</h3>
<p>대부분의 기계 학습 모델, 특히 강화학습 모델은 환경이 변하지 않는 정적(stationary)이라는 가정 하에 훈련된다.26 그러나 현실 세계는 동적으로 변화하고, 다중 에이전트 환경처럼 예측 불가능하며 적대적일 수 있다. 이러한 비정상(nonstationary) 환경에서 에이전트가 생존하고 성공하기 위해서는 지속적인 적응 능력이 필수적이다.28</p>
<p>핵심 아이디어: 학습하는 방법을 학습하기 (Learning to Learn)</p>
<p>이 연구는 ‘학습하는 방법을 학습하는’ 메타 학습(Meta-Learning)의 관점에서 이 문제에 접근했다.29 단 하나의 최적 정책을 찾는 대신, 환경 변화에 소수의 경험만으로도 빠르게 적응할 수 있는 ‘적응 규칙’ 또는 ’좋은 초기값’을 학습하는 것을 목표로 한다. 이를 위해 MAML(Model-Agnostic Meta-Learning)을 기반으로 한 그래디언트 기반 메타 학습 알고리즘을 제안했다.26</p>
<p>방법론: 연속 과업에 대한 메타-손실</p>
<p>연구진은 비정상 환경을 연속적인 정적 과업($T_i,T_{i+1},\dots <span class="math math-inline">)의 시퀀스로 모델링했다. 메타 학습의 목표는 연속된 과업 쌍(</span>T_i \to T_{i1}$)의 전이(transition)에 대해 최적의 적응을 수행하는 것이다. 구체적으로, 과업 Ti에서 얻은 소량의 데이터로 한 단계 업데이트된 정책이 다음 과업 <span class="math math-inline">T_{i+1}</span>에서 좋은 성능을 내도록 하는 메타-손실(meta-loss)을 정의하고, 이를 시간에 대한 역전파(backpropagation through time)와 유사한 방식으로 최적화했다.26</p>
<p>검증 환경: RoboSumo 및 반복 적응 게임</p>
<p>제안된 방법론의 효과를 검증하기 위해 특별히 설계된 다중 에이전트 경쟁 환경 ’RoboSumo’를 소개했다.6 두 로봇이 상대를 밀어내는 이 3D 물리 시뮬레이션 환경은 상대의 전략 변화로 인해 본질적으로 비정상적이다. 또한, ’반복 적응 게임(iterated adaptation games)’이라는 새로운 평가 프로토콜을 제안하여, 에이전트들이 여러 라운드에 걸쳐 서로의 전략 변화에 지속적으로 적응하는 능력을 정량적으로 평가했다.26</p>
<p>실험 결과 및 의의</p>
<p>실험 결과, 메타 학습을 통해 훈련된 에이전트는 소수의 경험(few-shot)만으로도 다른 적응 기법들(예: fine-tuning)보다 훨씬 빠르고 효과적으로 새로운 상황에 적응함을 보여주었다.26 이는 정적인 환경을 가정한 기존 AI의 한계를 넘어, 보다 동적이고 예측 불가능한 현실 세계 문제에 적용 가능한 AI를 향한 중요한 방향을 제시한다. 이 연구는 AI의 적응성을 강화하여 자율성과 강건성을 높이는 데 크게 기여했다.</p>
<h2>3.  2018년 AI 연구의 주요 동향</h2>
<p>ICLR 2018 최우수 논문들 외에도, 당시 학계 전반에서는 AI 모델의 신뢰성과 성능을 근본적으로 향상시키기 위한 다양한 연구들이 활발하게 진행되었다.</p>
<h3>3.1  적대적 공격과 방어의 창과 방패</h3>
<p>딥러닝 모델이 인간은 인지할 수 없는 미세한 입력 교란(perturbation)에 의해 쉽게 오작동할 수 있다는 적대적 예제(adversarial examples) 문제는 2018년 AI 안전성과 신뢰성 분야의 최대 화두였다.19 초기에는 새로운 공격 기법과 이를 막는 경험적 방어 기법이 번갈아 등장하는 ‘군비 경쟁’ 양상이 나타났으나, 이러한 방어 기법 대부분이 곧 더 정교한 공격에 의해 무력화되었다.32</p>
<p>이러한 배경 속에서, 연구의 흐름은 단순한 경험적 방어에서 벗어나 모델의 강건성을 수학적으로 ’증명(certify)’하려는 원칙적인 접근법으로 이동했다. ICLR 2018에서 발표된 “Certifying Some Distributional Robustness with Principled Adversarial Training“과 같은 연구는 분포적 강건성 최적화(distributionally robust optimization)라는 이론적 틀을 통해 특정 위협 모델 하에서 모델의 성능 하한을 보장하는 훈련 절차를 제안했다.19 비슷한 시기에 열린 ICML 2018에서도 “Obfuscated Gradients Give a False Sense of Security“가 최우수 논문으로 선정되었는데, 이는 많은 방어 기법이 실제 강건성을 높이는 것이 아니라 그래디언트를 왜곡하여 공격을 어렵게 만드는 착시 효과에 불과함을 폭로했다.33 이 두 연구는 당시 머신러닝 커뮤니티가 적대적 강건성 문제를 얼마나 심각하게 다루고 있었는지를 보여주는 명백한 증거이다.</p>
<h3>3.2  강화학습의 진화: 정책 최적화와 분산 학습</h3>
<p>강화학습 분야에서는 에이전트의 학습 효율과 안정성을 높이기 위한 연구가 핵심 과제로 다루어졌다. 특히 강화학습의 핵심 방법론인 정책 그래디언트(policy gradient)는 샘플링으로 인한 높은 분산(high variance) 때문에 학습이 불안정하고 많은 데이터를 요구하는 고질적인 문제를 안고 있었다.32</p>
<p>ICLR 2018에서는 이 문제를 해결하기 위한 다양한 분산 감소(variance reduction) 기법들이 발표되었다. 액션 의존적 베이스라인(action-dependent baselines), 제어 변수(control variates), Stein’s Identity와 같은 통계적 기법을 활용하여 정책 그래디언트 추정치의 분산을 줄이려는 시도들이 주목받았다.32 또한 DeepMind와 같은 주요 연구소들은 새로운 강화학습 알고리즘들을 대거 발표했다. 사후 확률 최대화 정책 최적화(Maximum a posteriori Policy Optimisation, MPO)는 탐색과 안정성 사이의 균형을 맞추는 새로운 최적화 목표를 제시했으며, 분산 분포 결정론적 정책 그래디언트(Distributed Distributional Deterministic Policy Gradients)는 대규모 분산 학습 환경에서 효율성을 높이는 방법을 제안했다.35 이러한 연구들은 강화학습을 이론적 가능성에서 실제 복잡한 문제에 적용 가능한 강력한 도구로 발전시키는 데 기여했다.</p>
<h2>4.  로보틱스 연구의 지평 확장</h2>
<p>2018년은 AI, 특히 심층 강화학습의 발전이 로보틱스 분야의 오랜 난제들을 해결하는 데 실질적인 돌파구를 마련한 해이기도 하다. AI의 이론적 발전이 로봇의 물리적 지능으로 구현되는 사례들이 구체적으로 나타나기 시작했다.</p>
<h3>4.1  강화학습 기반 로봇 제어</h3>
<p>AI, 특히 심층 강화학습은 로봇이 복잡한 조작 기술을 스스로 학습하도록 하는 데 혁신을 가져왔다. 2018년 UC Berkeley 연구팀은 강화학습을 통해 로봇이 젠가 블록을 정교하게 빼내거나, 여러 부품으로 컴퓨터 마더보드를 조립하는 등 매우 복잡하고 섬세한 작업을 단 1~2시간의 학습만으로 100%에 가까운 성공률로 수행하는 놀라운 성과를 발표했다.36</p>
<p>이러한 성공의 핵심에는 시뮬레이션에서의 학습과 실제 로봇의 시행착오(real-world attempts)를 효과적으로 결합하고, 인간의 시연(demonstration)과 피드백을 학습 과정에 통합하는 전략이 있었다. 이는 시뮬레이션 환경과 현실 세계 간의 차이, 즉 ‘현실 격차(reality gap)’ 문제를 해결하는 Sim-to-Real 연구의 중요한 접근법을 보여준다.36 ICLR에서 논의된 강화학습의 분산 감소 기법이나 메타 학습 기반의 빠른 적응 능력과 같은 이론적 발전26이 어떻게 로보틱스 분야의 실질적인 난제 해결36로 직접 이어질 수 있는지를 보여주는 대표적인 사례로, 두 분야 간의 강력한 시너지를 입증했다.</p>
<h3>4.2  소프트 로보틱스의 부상</h3>
<p>전통적인 강체(rigid) 로봇과 달리, 부드럽고 유연한 소재를 사용하여 생물체의 움직임을 모방하는 소프트 로보틱스는 2018년을 기점으로 차세대 로보틱스의 핵심 분야로 부상했다. 소프트 로봇은 본질적인 유연성과 순응성 덕분에 안전한 인간-로봇 상호작용, 비침습적 수술, 예측 불가능한 환경에서의 탐사 등 기존 로봇으로는 불가능했던 새로운 응용 가능성을 열었다.37</p>
<p>2018년 4월에 열린 RoboSoft 학회에서는 소프트 로보틱스의 핵심 기술들이 집중적으로 논의되었다. 식물의 성장 방식을 모방한 탐사 로봇, 공압을 이용한 새로운 소프트 액추에이터 및 센서 개발, 특정 상황에서 몸을 단단하게 만드는 가변 강성(variable stiffness) 메커니즘, 그리고 소프트 로봇의 복잡한 연속적 변형을 제어하기 위한 학습 기반 제어 방법론 등이 주요 연구 주제로 다루어졌다.37 소프트 로봇의 비선형적이고 무한한 자유도를 가진 움직임은 기존의 정형화된 로봇 제어 모델로는 다루기 어렵다. 이는 강화학습을 포함한 AI 기반 제어 알고리즘에 새로운 도전 과제를 제시하며, AI와 로보틱스 융합 연구의 차세대 격전지가 될 것임을 예고했다.37</p>
<h2>5. 결론: 2018년 4월이 남긴 유산과 미래 전망</h2>
<p>2018년 4월, 특히 ICLR 2018을 통해 발표된 주요 연구들은 AI 분야가 양적 팽창을 넘어 질적 성숙으로 나아가는 중요한 변곡점이었음을 명확히 보여준다. 이 시기의 연구들은 AI의 <strong>신뢰성(Reliability)</strong>, <strong>일반성(Generality)</strong>, <strong>적응성(Adaptability)</strong> 이라는 세 가지 핵심 축에서 의미 있는 진전을 이루었다.</p>
<p>“On the Convergence of Adam and Beyond“는 가장 보편적으로 사용되는 최적화 알고리즘의 이론적 결함을 수정하여 딥러닝 연구의 신뢰성을 높이는 견고한 발판을 마련했다. “Spherical CNNs“는 딥러닝의 적용 범위를 평면 데이터를 넘어 구면과 같은 기하학적 구조로 확장함으로써 AI의 일반성을 새로운 차원으로 끌어올렸다. 마지막으로 “Continuous Adaptation via Meta-learning“은 정적인 환경을 가정한 기존 AI의 한계를 극복하고, 동적으로 변화하는 현실 세계에 대응할 수 있는 적응성의 토대를 구축했다.</p>
<p>이러한 기초 연구의 성과는 장기적인 파급 효과를 낳았다. Adam의 수렴성 문제는 이후 다양한 차세대 옵티마이저 연구를 촉발시켰고, Spherical CNN은 기하학적 딥러닝 분야의 발전을 가속화했으며, 메타 학습 기반의 지속적 적응 개념은 자율주행, 로보틱스, 개인화 서비스 등 동적 환경에서의 AI 응용 연구에 깊은 영향을 미쳤다.</p>
<p>2018년에 다져진 이 견고한 이론적 기반 위에서 AI 기술은 이후 더욱 복잡하고 현실적인 문제들을 해결하는 방향으로 나아가고 있다. 이는 기술의 산업적 확산 1 뿐만 아니라, AI의 사회적 책임과 윤리에 대한 논의 39를 심화시키는 계기가 되었다. 결국 2018년 4월은 AI가 스스로의 한계를 성찰하고 더 넓고, 더 신뢰할 수 있으며, 더 역동적인 미래를 향해 도약한 중요한 시점으로 기록될 것이다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>NOTES FROM THE AI FRONTIER MODELING THE IMPACT OF AI ON THE WORLD ECONOMY - McKinsey, <a href="https://www.mckinsey.com/~/media/mckinsey/featured%20insights/artificial%20intelligence/notes%20from%20the%20frontier%20modeling%20the%20impact%20of%20ai%20on%20the%20world%20economy/mgi-notes-from-the-ai-frontier-modeling-the-impact-of-ai-on-the-world-economy-september-2018.ashx">https://www.mckinsey.com/~/media/mckinsey/featured%20insights/artificial%20intelligence/notes%20from%20the%20frontier%20modeling%20the%20impact%20of%20ai%20on%20the%20world%20economy/mgi-notes-from-the-ai-frontier-modeling-the-impact-of-ai-on-the-world-economy-september-2018.ashx</a></li>
<li>Top 5 Artificial Intelligence Conferences to Attend in 2018 | iMerit, https://imerit.net/resources/blog/top-5-artificial-intelligence-conferences-attend-2018/</li>
<li>AAAI Conference on Artificial Intelligence - Wikipedia, https://en.wikipedia.org/wiki/AAAI_Conference_on_Artificial_Intelligence</li>
<li>Best Computer Science Conferences Ranking Machine Learning &amp; Artificial intelligence 2024 | Research.com, https://research.com/conference-rankings/computer-science/machine-learning</li>
<li>ICLR 2018, https://iclr.cc/archive/www/doku.php%3Fid=iclr2018:main.html</li>
<li>ICLR 2018’s Best Papers: Variant Adam, Spherical CNNs, and Meta-Learning - Medium, https://medium.com/syncedreview/iclr-2018s-best-papers-variant-adam-spherical-cnns-and-meta-learning-6b48dca83e8b</li>
<li>ICLR 2018 Awards, https://iclr.cc/virtual/2018/awards_detail</li>
<li>[PDF] Adam: A Method for Stochastic Optimization - Semantic Scholar, https://www.semanticscholar.org/paper/Adam%3A-A-Method-for-Stochastic-Optimization-Kingma-Ba/a6cb366736791bcccc5c8639de5a8f9636bf87e8</li>
<li>On the Convergence of Adam and Beyond - OpenReview, https://openreview.net/forum?id=ryQu7f-RZ</li>
<li>ON THE CONVERGENCE OF ADAM AND BEYOND - OpenReview, https://openreview.net/pdf?id=ryQu7f-RZ</li>
<li>On the Convergence of Adam and Beyond | Request PDF - ResearchGate, https://www.researchgate.net/publication/332553710_On_the_Convergence_of_Adam_and_Beyond</li>
<li>On the convergence of Adam &amp; Beyond | Request PDF - ResearchGate, https://www.researchgate.net/publication/328723323_On_the_convergence_of_Adam_Beyond</li>
<li>Adam Can Converge Without Any Modification On Update Rules, https://papers.neurips.cc/paper_files/paper/2022/file/b6260ae5566442da053e5ab5d691067a-Paper-Conference.pdf</li>
<li>Spherical CNNs | Request PDF - ResearchGate, https://www.researchgate.net/publication/322819132_Spherical_CNNs</li>
<li>spherical cnns - Department of Computer Science, University of Toronto, https://www.cs.toronto.edu/~bonner/courses/2020s/csc2547/papers/equivariance/spherical-cnn,-cohen,-iclr-2018.pdf</li>
<li>SPHERICAL CNNS - OpenReview, https://openreview.net/pdf?id=Hkbd5xZRb</li>
<li>Spherical CNNs - OpenReview, https://openreview.net/forum?id=Hkbd5xZRb</li>
<li>[1801.10130] Spherical CNNs - arXiv, https://arxiv.org/abs/1801.10130</li>
<li>ICLR 2018 Conference Track - OpenReview, https://openreview.net/group?id=ICLR.cc/2018/Conference</li>
<li>Spherical CNNs - GitHub Pages, https://qdata.github.io/deep2Read//talks2019/19sCourse/20190222-Fuwen-SphericalCNNs.pdf</li>
<li>EFFICIENT GENERALIZED SPHERICAL CNNS - Jason McEwen, http://www.jasonmcewen.org/papers/efficient_generalized_s2cnn.pdf</li>
<li>[PDF] Spherical CNNs - Semantic Scholar, https://www.semanticscholar.org/paper/Spherical-CNNs-Cohen-Geiger/ce2845cadc5233ff0a647aa22ae3bbe646258890</li>
<li>[PDF] Scaling Spherical CNNs - Semantic Scholar, https://www.semanticscholar.org/paper/Scaling-Spherical-CNNs-Esteves-Slotine/23bd71fa3324850997230d355adebf9225b4d640</li>
<li>Gauge Equivariant Spherical CNNs - OpenReview, https://openreview.net/forum?id=HJeYSxHFDS</li>
<li>Efficient Generalized Spherical CNNs - OpenReview, https://openreview.net/forum?id=rWZz3sJfCkm</li>
<li>CONTINUOUS ADAPTATION VIA META-LEARNING … - OpenReview, https://openreview.net/pdf/a4d3a6673dbadf98ccf48e6e6a05164f62b31565.pdf</li>
<li>Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments, https://openreview.net/forum?id=Sk2u1g-0-</li>
<li>continuous adaptation via meta-learning in nonstationary and competitive environments - arXiv, https://arxiv.org/pdf/1710.03641</li>
<li>Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments | Request PDF - ResearchGate, https://www.researchgate.net/publication/320321556_Continuous_Adaptation_via_Meta-Learning_in_Nonstationary_and_Competitive_Environments</li>
<li>Continuous Meta-Learning without Tasks, https://proceedings.neurips.cc/paper/2020/file/cc3f5463bc4d26bc38eadc8bcffbc654-Paper.pdf</li>
<li>[PDF] Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments | Semantic Scholar, https://www.semanticscholar.org/paper/6ac5eb309dd937d801d180c830377e4d551699a2</li>
<li>Our key takeaways from ICLR 2018 - Research Blog - RBC Borealis, https://rbcborealis.com/research-blogs/our-key-takeaways-iclr-2018/</li>
<li>[R] ICML 2018 Best Papers: “Obfuscated Gradients Give a False Sense of Security” and “Delayed Impact of Fair Machine Learning” : r/MachineLearning - Reddit, https://www.reddit.com/r/MachineLearning/comments/8uoynk/r_icml_2018_best_papers_obfuscated_gradients_give/</li>
<li>ICML 2018 Awards, https://icml.cc/Conferences/2018/Awards</li>
<li>DeepMind papers at ICLR 2018, https://deepmind.google/discover/blog/deepmind-papers-at-iclr-2018/</li>
<li>Using AI, These Robots Learn Complicated Skills with Startling Accuracy, https://vcresearch.berkeley.edu/news/using-ai-these-robots-learn-complicated-skills-startling-accuracy</li>
<li>Editorial: Current Advances in Soft Robotics: Best Papers From RoboSoft 2018 - Frontiers, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2020.00056/full</li>
<li>Robotics and Autonomous Intelligent Machines - Research - Cardiff University, https://www.cardiff.ac.uk/research/explore/research-units/robotics-and-autonomous-intelligent-machines</li>
<li>The ethics of artificial intelligence: Issues and initiatives - European Parliament, https://www.europarl.europa.eu/RegData/etudes/STUD/2020/634452/EPRS_STU(2020)634452_EN.pdf</li>
<li>Artificial intelligence: revolutionizing robotic surgery: review - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC11374272/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>