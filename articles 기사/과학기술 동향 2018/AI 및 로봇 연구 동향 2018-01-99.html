<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2018년 1월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2018년 1월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2018년 AI 및 로봇 연구 동향</a> / <span>2018년 1월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2018년 1월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2018년, 심화와 확장의 기로에 선 AI 연구</h2>
<p>2018년 초 인공지능(AI) 연구는 딥러닝의 성공이 여러 분야에서 입증된 이후, 새로운 전환점을 맞이하고 있었다. 연구의 초점은 단순히 특정 벤치마크에서 성능을 극대화하는 것을 넘어, 알고리즘의 <strong>견고성(robustness)</strong>, <strong>일반성(generality)</strong>, 그리고 작동 원리에 대한 <strong>근본적인 이해</strong>로 이동하기 시작했다. 2017년 말 발표된 알파고 제로(AlphaGo Zero)와 트랜스포머(Transformer) 아키텍처의 충격적인 등장은 학계 전반에 깊은 영향을 미쳤으며, 이는 2018년 연구 방향성에 지대한 영향을 주었다.1 알파고 제로는 인간의 기보 데이터 없이 순수한 자가 대국(self-play)만으로 최강의 성능에 도달하며 강화학습의 새로운 가능성을 열었고, 트랜스포머는 자연어 처리 분야의 패러다임을 바꾸는 기반이 되었다.</p>
<p>이러한 배경 속에서 2018년 1월을 기점으로 발표된 연구들은 ’성능의 시대’에서 ’이해의 시대’로의 전환을 명확히 보여준다. 기존 방법론의 이론적 한계를 비판적으로 분석하고, 더 엄밀한 수학적 토대를 구축하려는 시도가 두드러졌다. ICLR 2018에서 발표된 주요 논문들은 딥러닝의 표준 최적화 알고리즘이었던 Adam의 수렴성 문제를 증명하거나 3, 적대적 공격에 대한 방어 기법들의 취약성을 폭로하며 4 기존의 경험적 성공에 안주하지 않으려는 학계의 자성을 드러냈다. Google Brain 팀 역시 블로그를 통해 ’기계 학습 시스템 이해(Understanding Machine Learning Systems)’의 중요성을 강조하며, 기존 이론이 딥러닝의 성공을 충분히 설명하지 못함을 인정하고 해석 가능성(interpretability) 연구의 필요성을 역설했다.5 이는 개별 연구를 넘어선 거대한 패러다임의 전환, 즉 딥러닝이 ’연금술’의 단계를 지나 ’과학’의 단계로 진입하려는 집단적 노력의 신호탄이었다.</p>
<p>본 보고서는 2018년 1월을 중심으로 발표된 주요 학술 논문과 산업계 연구소의 발표를 통해 당시 AI 및 로봇 분야의 핵심 연구 동향을 심층적으로 분석하고, 이러한 흐름이 현재 AI 기술 지형에 미친 영향을 조망하는 것을 목표로 한다. 분석은 크게 네 가지 축으로 전개된다. 첫째, 최상위 학회인 AAAI와 ICLR의 동향을 통해 학계의 최전선 연구 주제를 살펴본다. 둘째, 최적화, 신경망 아키텍처, 학습 방법론 등 핵심 기반 기술의 진화를 구체적으로 분석한다. 셋째, Google, Facebook 등 산업계 연구소의 비전과 성과를 통해 이론과 실제의 접점을 탐구한다. 마지막으로, 자동화와 노동 시장 등 AI 기술이 사회경제적으로 미치는 함의를 고찰한다.</p>
<h2>2.  최상위 학회 동향 심층 분석: AAAI 2018 및 ICLR 2018</h2>
<p>2018년 초 AI 연구의 방향성은 인공지능 분야의 양대 산맥인 AAAI(Association for the Advancement of Artificial Intelligence)와 ICLR(International Conference on Learning Representations) 학회에서 발표된 연구들을 통해 가장 명확하게 드러난다. AAAI가 주로 지능형 에이전트와 그 상호작용에 대한 폭넓은 주제를 다루는 반면, ICLR은 딥러닝의 핵심인 표현 학습(Representation Learning)의 근본 원리에 집중하는 경향을 보인다. 두 학회의 주요 수상작 및 발표 동향을 비교 분석함으로써 당시 연구의 다각적인 흐름을 입체적으로 파악할 수 있다.</p>
<p>아래 표는 2018년 초 학계가 주목한 최고 수준의 연구 성과를 요약한 것이다. 이를 통해 AAAI에서는 ’다중 에이전트’가, ICLR에서는 ’기반 기술의 재검토 및 확장’이 핵심 주제로 부상했음을 한눈에 파악할 수 있다. 이는 이어질 심층 분석의 맥락을 설정하고 보고서 전체의 논리적 흐름을 뒷받침하는 역할을 한다.</p>
<table><thead><tr><th>학회</th><th>상</th><th>논문 제목</th><th>저자</th><th>핵심 기여</th></tr></thead><tbody>
<tr><td><strong>AAAI-18</strong></td><td>최우수 논문</td><td>Learning to Teach in Cooperative Multiagent Reinforcement Learning</td><td>Shayegan Omidshafiei, Dong Ki Kim, et al.</td><td>협력적 다중 에이전트 환경에서, 한 에이전트가 다른 에이전트에게 효과적으로 ‘가르치는’ 방법을 학습하여 전체 시스템의 성능을 향상시키는 프레임워크 제시. 6</td></tr>
<tr><td><strong>AAAI-18</strong></td><td>우수 학생 논문</td><td>Counterfactual Multi-Agent Policy Gradients</td><td>Jakob N. Foerster, Gregory Farquhar, et al.</td><td>다중 에이전트 환경에서 각 에이전트의 기여도를 명확히 분리하기 위해 반사실적(counterfactual) 추론을 도입한 새로운 정책 경사법 제시. 6</td></tr>
<tr><td><strong>ICLR-18</strong></td><td>최우수 논문</td><td>On the Convergence of Adam and Beyond</td><td>Sashank J. Reddi, Satyen Kale, Sanjiv Kumar</td><td>널리 사용되는 Adam 옵티마이저의 비수렴 사례를 증명하고, 이를 해결하기 위한 AMSGrad 알고리즘 제안. 3</td></tr>
<tr><td><strong>ICLR-18</strong></td><td>최우수 논문</td><td>Spherical CNNs</td><td>Taco S. Cohen, Mario Geiger, et al.</td><td>구면 데이터에 직접 적용 가능한 회전 등변성(rotation-equivariant)을 갖는 합성곱 신경망 아키텍처 제안. 7</td></tr>
<tr><td><strong>ICLR-18</strong></td><td>최우수 논문</td><td>Continuous Adaptation via Meta-learning in Nonstationary and Competitive Environments</td><td>Maruan Al-Shedivat, Trapit Bansal, et al.</td><td>동적으로 변화하고 경쟁적인 환경에 에이전트가 지속적으로 적응할 수 있도록 하는 메타러닝 알고리즘 제안. 7</td></tr>
</tbody></table>
<h3>2.1  AAAI 2018: 다중 에이전트 강화학습의 도약</h3>
<p>Atari 게임이나 AlphaGo와 같은 단일 에이전트의 성공 이후, AI 연구의 초점은 자연스럽게 복수의 에이전트가 상호작용하는 복잡한 환경으로 확장되었다. 이는 자율주행차 군집, 협력적 로봇, 경제 모델링 등 현실 세계의 문제를 해결하기 위한 필수적인 단계였다.10 이러한 흐름 속에서 AAAI 2018의 최우수 논문상과 우수 학생 논문상 모두 다중 에이전트 강화학습(Multi-Agent Reinforcement Learning, MARL) 분야에 수여된 것은 결코 우연이 아니었다. 이는 개별 에이전트의 지능을 넘어, 에이전트 간의 ‘상호작용’ 자체에서 발생하는 지능(emergent intelligence)을 어떻게 설계하고 최적화할 것인가에 대한 질문으로 연구 패러다임이 이동하고 있음을 명확히 보여준다.</p>
<p>최우수 논문으로 선정된 ’Learning to Teach in Cooperative Multiagent Reinforcement Learning’은 협력적 환경에서 에이전트 간의 효율적인 지식 전달 문제를 다루었다.6 이 연구는 중앙 집중식 제어 없이 분산된 에이전트들이 효과적으로 협력하는 메커니즘을 제시했다는 점에서 큰 의의를 가진다. 구체적으로, 경험이 많은 ‘선생님’ 에이전트가 학습 중인 ‘학생’ 에이전트에게 어떤 정보(예: 조언, 시연)를, 어떤 시점에 전달해야 학생의 학습 효율을 극대화할 수 있는지를 강화학습 프레임워크 내에서 최적화하는 방법을 제안했다. 이는 에이전트 간의 ’소통’이라는 사회적 행위를 수학적으로 모델링하려는 시도로, 단순히 여러 에이전트를 같은 공간에 두는 것을 넘어 그들 간의 관계를 명시적으로 다루었다는 점에서 진일보한 접근이었다.</p>
<p>우수 학생 논문상 수상작인 ’Counterfactual Multi-Agent Policy Gradients’는 MARL의 고질적인 난제인 ‘신용 할당(credit assignment)’ 문제를 정면으로 다루었다.6 팀의 공동 결과(성공 또는 실패)에 대해 각 개별 에이전트가 얼마나 기여했는지를 정확히 측정하는 것은 매우 어렵다. 이 논문은 이 문제를 해결하기 위해 ’만약 내가 다른 행동을 했다면 팀의 결과가 어떻게 달라졌을까?’라는 반사실적(counterfactual) 질문을 수학적으로 모델링했다. 각 에이전트는 자신의 행동이 전역 보상(global reward)에 미치는 한계 기여도(marginal contribution)를 추정함으로써, 다른 에이전트들의 행동으로 인한 노이즈를 제거하고 자신의 정책을 더 효과적으로 업데이트할 수 있게 된다. 이는 ’책임과 기여’라는 사회적 개념을 알고리즘에 통합하려는 시도로 볼 수 있다.</p>
<p>AAAI 2018의 이 두 수상작은 AI 연구가 ‘개체’ 중심에서 ’시스템’과 ‘사회’ 중심으로 확장되고 있음을 시사한다. 이는 미래의 AI 시스템이 단순히 작업을 수행하는 도구를 넘어, 인간 사회나 다른 AI와 복잡한 상호작용을 수행하는 사회적 행위자(social agent)가 될 것임을 예고하며, 이후 인간-AI 협업(Human-AI Collaboration) 11이나 공유 자율성(shared autonomy) 10과 같은 연구 분야의 중요한 이론적 토대를 마련했다.</p>
<h3>2.2  ICLR 2018: 근본을 향한 질문과 새로운 지평</h3>
<p>표현 학습에 중점을 두는 ICLR은 딥러닝 모델의 핵심 구성 요소에 대한 근본적인 탐구가 주를 이루는 학회다. 2018년 ICLR에서는 특히 기존 성공 신화에 대한 비판적 재검토와 함께, 새로운 유형의 데이터 및 환경으로 표현 학습의 지평을 확장하려는 노력이 두드러졌다.7</p>
<p>첫 번째 주요 테마는 <strong>이론적 견고성 확보</strong>였다. 최우수 논문 중 하나인 ’On the Convergence of Adam and Beyond’는 딥러닝 학습의 사실상 표준이었던 Adam 옵티마이저가 특정 조건에서 수렴하지 않음을 증명하며 학계에 경종을 울렸다.7 또한, 동시대에 발표되어 ICLR 2018에서 발표된 다수의 방어 모델들을 무력화시킨 ‘Obfuscated Gradients Give a False Sense of Security’ (ICML 2018 최우수 논문)는 적대적 공격에 대한 많은 방어 기법들이 실제로는 견고성을 제공하는 것이 아니라, 그래디언트를 교묘하게 숨겨 공격을 어렵게 만드는 ’그래디언트 은닉(gradient masking)’에 의존하고 있음을 폭로했다.4 이러한 연구들은 경험적 성공 이면에 숨겨진 이론적 취약점을 파고들며, 커뮤니티에 더 높은 수준의 수학적, 실험적 엄밀함을 요구하는 계기가 되었다.12</p>
<p>두 번째 테마는 <strong>표현 공간의 확장</strong>이었다. 또 다른 최우수 논문인 ’Spherical CNNs’는 기존 CNN이 평면(Euclidean) 데이터에 국한되었던 한계를 극복하고, 구면(non-Euclidean)이라는 새로운 기하학적 공간으로 표현 학습의 범위를 확장했다.7 이는 360도 전방위 비전, 분자 구조 분석, 지구 과학 데이터 처리 등 기존 방식으로는 다루기 어려웠던 새로운 응용 분야의 문을 활짝 열었다.8 이 연구는 데이터가 가진 내재적 기하 구조를 존중하는 모델 설계의 중요성을 부각시키며, 이후 기하 딥러닝(Geometric Deep Learning) 분야의 발전을 촉진하는 중요한 계기가 되었다.</p>
<p>세 번째 테마는 <strong>학습 패러다임의 혁신</strong>이었다. 최우수 논문 ’Continuous Adaptation via Meta-learning in Nonstationary and Competitive Environments’는 ‘학습하는 방법’ 자체를 학습하는 메타러닝(meta-learning)을 통해 AI의 적응 능력을 한 단계 끌어올렸다.7 기존 모델은 한 번 학습이 끝나면 고정되어, 규칙이나 목표가 계속 변하는 비정상적(nonstationary) 환경에서는 성능이 급격히 저하되는 한계가 있었다. 이 연구는 다양한 변화를 겪는 환경들에서 ‘빠르게 적응하는 능력’ 자체를 학습함으로써, 소량의 새로운 경험만으로도 변화된 환경에 신속하게 정책을 미세조정할 수 있는 능력을 부여했다. 이는 평생 학습(lifelong learning)이라는 AI의 궁극적 목표를 향한 중요한 걸음이었다.9</p>
<h2>3.  핵심 기반 기술의 진화</h2>
<p>ICLR 2018 최우수 논문들을 중심으로, 2018년 초 AI 기술의 발전을 견인한 세 가지 핵심 기반 기술—최적화, 신경망 아키텍처, 학습 방법론—의 구체적인 내용과 그 의의를 심층적으로 분석한다. 이 기술들은 딥러닝의 근간을 이루며, 이 시기의 발전은 이후 AI 연구의 방향을 결정짓는 중요한 토대가 되었다.</p>
<h3>3.1  최적화 알고리즘의 재조명: Adam의 수렴성 문제와 AMSGrad의 제안</h3>
<p>2018년 당시, Adam(Adaptive Moment Estimation)은 빠른 수렴 속도와 우수한 성능으로 딥러닝 모델 학습의 사실상 표준(de facto standard) 옵티마이저로 군림하고 있었다. 그러나 Sashank J. Reddi 연구팀은 ‘On the Convergence of Adam and Beyond’ 논문을 통해, 특정 조건 하에서 Adam이 최적해로 수렴하지 못하는 간단한 볼록 최적화(convex optimization) 예시를 제시하여 학계에 큰 충격을 주었다.3 문제의 근원은 과거 그래디언트 정보를 관리하는 방식에 있었다. Adam은 그래디언트의 1차 모멘텀(평균)과 2차 모멘텀(분산의 불편 추정량)을 지수 이동 평균(exponential moving average)으로 추정한다. 이 방식은 최근 그래디언트에 높은 가중치를 부여하여 변화에 빠르게 적응하는 장점이 있지만, 반대로 과거의 중요한 그래디언트 정보가 너무 빨리 소실되는 ‘단기 기억’ 문제를 야기한다. 연구팀이 제시한 반례는, 드물게 발생하지만 크고 유익한 그래디언트가 이동 평균 과정에서 그 영향력을 잃어버려 알고리즘이 잘못된 방향으로 수렴하는 상황을 보여주었다.15</p>
<p>이 문제를 해결하기 위해 연구팀은 ‘장기 기억(long-term memory)’ 메커니즘을 도입한 AMSGrad를 제안했다.16 AMSGrad의 핵심 아이디어는 매우 간단하면서도 효과적이다. 기존 Adam이 현재 시점</p>
<p><span class="math math-inline">t</span>의 2차 모멘텀 추정치 <span class="math math-inline">v_t</span>를 사용하여 학습률을 조절하는 반면, AMSGrad는 과거부터 현재까지 모든 <span class="math math-inline">v_t</span> 값들 중 최댓값인 <span class="math math-inline">\hat{v}_t</span>를 유지하고 이를 학습률 스케일링에 사용한다. 즉, <span class="math math-inline">\hat{v}_t = \max(\hat{v}_{t-1}, v_t)</span> 연산을 통해 2차 모멘텀 추정치가 절대 감소하지 않도록 보장한다. 이 간단한 수정은 드물게 나타나는 큰 그래디언트의 영향력이 소실되는 것을 방지하고, 학습률이 안정적으로 유지되도록 하여 알고리즘의 수렴성을 이론적으로 보장한다.14</p>
<p>아래 표는 Adam과 AMSGrad의 업데이트 규칙을 비교하여 핵심적인 차이를 명확히 보여준다. 이 차이는 <span class="math math-inline">\hat{v}_t</span>의 정의 단 한 줄에 있으며, 이것이 바로 AMSGrad의 ‘장기 기억’ 메커니즘이 구현되는 방식이다.</p>
<table><thead><tr><th>단계</th><th>Adam 알고리즘</th><th>AMSGrad 알고리즘</th><th>설명</th></tr></thead><tbody>
<tr><td>1. 그래디언트 계산</td><td><span class="math math-inline">g_t = \nabla_{\theta} f_t(\theta_{t-1})</span></td><td><span class="math math-inline">g_t = \nabla_{\theta} f_t(\theta_{t-1})</span></td><td>현 파라미터에 대한 그래디언트를 계산한다.</td></tr>
<tr><td>2. 1차 모멘텀 추정</td><td><span class="math math-inline">m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t</span></td><td><span class="math math-inline">m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t</span></td><td>그래디언트의 지수 이동 평균을 계산한다.</td></tr>
<tr><td>3. 2차 모멘텀 추정</td><td><span class="math math-inline">v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2</span></td><td><span class="math math-inline">v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2</span></td><td>그래디언트 제곱의 지수 이동 평균을 계산한다.</td></tr>
<tr><td>4. <strong>핵심 차이</strong></td><td>(별도 단계 없음)</td><td><span class="math math-inline">\hat{v}_t = \max(\hat{v}_{t-1}, v_t)</span></td><td><strong>과거 2차 모멘텀의 최댓값을 유지한다.</strong></td></tr>
<tr><td>5. 파라미터 업데이트</td><td><span class="math math-inline">\theta_t = \theta_{t-1} - \alpha \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}</span></td><td><span class="math math-inline">\theta_t = \theta_{t-1} - \alpha \frac{m_t}{\sqrt{\hat{v}_t} + \epsilon}</span></td><td>Adam은 현재 <span class="math math-inline">v_t</span>를, AMSGrad는 <span class="math math-inline">\hat{v}_t</span>를 사용한다.</td></tr>
</tbody></table>
<p><em>참고: Adam의 편향 보정(bias correction) 단계 <span class="math math-inline">\hat{m}_t</span>, <span class="math math-inline">\hat{v}_t</span>는 설명을 위해 단순화함. AMSGrad는 원 논문에서 편향 보정을 제거함.</em></p>
<h3>3.2  표현 학습의 확장: 구면 CNN (Spherical CNNs)과 등변성</h3>
<p>드론이나 자율주행차의 360도 카메라 이미지, 분자 구조, 지구 기상 데이터 등은 본질적으로 평면이 아닌 구(sphere) 위에 정의되는 신호다. 기존의 합성곱 신경망(CNN)을 이러한 데이터에 적용하기 위해서는 구면 신호를 평면으로 투영하는 과정이 필요했다. 하지만 이 투영 과정은 필연적으로 심각한 왜곡을 발생시키며, 특히 극지방으로 갈수록 왜곡이 심해진다. 이러한 공간적 왜곡은 CNN의 핵심적인 장점인 이동 불변성(translation invariance)과 가중치 공유(weight sharing)의 효과를 무력화시켜 성능 저하를 유발했다.8</p>
<p>Taco S. Cohen 연구팀의 ’Spherical CNNs’는 이러한 문제를 근본적으로 해결하기 위해, 평면 투영 없이 구면 신호에 직접 적용할 수 있는 새로운 유형의 CNN을 제안했다.18 이 모델의 핵심 개념은 평면에서의 ‘합성곱(convolution)’ 연산을 구면에서의 **‘구면 교차 상관(spherical cross-correlation)’**으로 일반화하는 것이다. 구면 교차 상관은 필터 함수를 구면 위에서 모든 가능한 방향으로 ’회전(rotation)’시키면서 입력 신호와의 내적(inner product)을 계산하는 연산이다.19 이 연산은 정의상 **회전 등변성(rotation-equivariance)**을 갖는다. 즉, 입력 신호(예: 구면 이미지)를 특정 각도로 회전시키면, 출력 특징 맵(feature map) 역시 정확히 동일한 각도로 회전된 형태로 나타난다. 이 성질 덕분에 모델은 객체의 방향과 무관하게 본질적인 특징을 학습할 수 있어 데이터 효율성과 일반화 성능이 크게 향상된다.</p>
<p>그러나 이 구면 교차 상관 연산을 공간 영역에서 직접 계산하는 것은 계산적으로 매우 비효율적이다. 논문은 일반화된 푸리에 정리(generalized Fourier theorem)를 활용하여 이 문제를 해결했다. 구면 신호와 필터를 각각 구면 조화 함수(Spherical Harmonics)라는 직교 기저 함수들의 선형 결합으로 분해한 뒤, 주파수 영역(spectral domain)으로 변환한다. 주파수 영역에서는 복잡한 교차 상관 연산이 단순한 성분별 곱셈으로 바뀌므로 매우 효율적인 계산이 가능하다. 계산된 결과는 다시 역변환을 통해 공간 영역의 특징 맵으로 변환된다. 이 모든 과정은 비가환 군(non-commutative group) <span class="math math-inline">SO(3)</span>에 대한 고속 푸리에 변환(FFT) 알고리즘을 통해 효율적으로 구현될 수 있다.13</p>
<p>Spherical CNN은 3D 모델 인식(ModelNet40 데이터셋)과 분자 구조로부터 원자화 에너지(atomization energy)를 예측하는 QM9 데이터셋 실험에서 그 효과를 입증했다. 특히, 훈련 데이터에는 없는 새로운 방향으로 회전된 테스트 데이터에 대해 기존 CNN 기반 모델들보다 월등히 뛰어난 일반화 성능을 보였다. 이는 구면 데이터의 내재적 대칭성을 모델 구조에 직접 통합하는 것의 중요성을 명확히 보여준 사례다.8</p>
<h3>3.3  동적 환경 적응을 위한 메타러닝</h3>
<p>현실 세계의 많은 문제들, 예를 들어 로봇이 마모되면서 물리적 특성이 변하거나, 게임 상대의 전략이 계속 바뀌는 상황은 규칙이나 목표가 시간에 따라 변하는 <strong>비정상적(nonstationary) 환경</strong>에 해당한다. 기존의 강화학습 에이전트는 고정된 환경을 가정하고 최적의 정책을 학습하기 때문에, 이러한 동적인 변화에 효과적으로 대응하지 못하고 성능이 급격히 저하되는 한계를 보였다.7</p>
<p>‘Continuous Adaptation via Meta-learning in Nonstationary and Competitive Environments’ 논문은 이 문제를 ‘학습하는 방법을 배우는(learning-to-learn)’ <strong>메타러닝</strong> 프레임워크를 통해 해결하고자 했다.7 이 접근법의 핵심은 단일 환경에 대한 최적 정책을 찾는 것이 아니라, 다양한 변화를 겪는 여러 환경에 걸쳐 ‘빠르게 적응하는 능력’ 자체를 학습하는 것이다. 에이전트는 메타-훈련(meta-training) 단계에서 환경 변화에 신속하게 정책을 미세조정(fine-tuning)할 수 있는 초기 파라미터와 학습 규칙을 배운다. 덕분에 메타-테스트(meta-test) 단계에서 이전에 겪어보지 못한 새로운 환경 변화에 직면하더라도, 소량의 새로운 경험만으로 자신의 정책을 신속하게 업데이트하여 높은 성능을 유지할 수 있다.22</p>
<p>이러한 지속적인 적응 능력을 효과적으로 평가하기 위해, 연구팀은 **<code>RoboSumo</code>**라는 새로운 다중 에이전트 경쟁 시뮬레이션 환경을 특별히 설계했다.7</p>
<p><code>RoboSumo</code> 환경에서는 두 개 이상의 로봇 에이전트가 원형의 경기장 안에서 서로를 밀어내는 스모 경기를 펼친다. 이 환경의 가장 큰 특징은 경기 도중에 에이전트의 신체 형태(예: 다리 개수, 몸체 크기, 관절의 마찰력)나 물리 법칙이 예고 없이 바뀔 수 있다는 점이다. 예를 들어, 갑자기 한쪽 다리가 마비되거나 경기장 바닥이 미끄럽게 변할 수 있다. 이러한 예측 불가능한 변화는 에이전트에게 고정된 전략이 아닌, 지속적인 탐색과 적응을 요구하는 이상적인 테스트베드 역할을 했다. 실험 결과, 메타러닝으로 훈련된 에이전트는 변화가 발생했을 때 훨씬 적은 시행착오(few-shot)만으로 새로운 환경에 적응하여, 변화를 감지하고 단순히 반응만 하는(reactive) 베이스라인 모델들보다 월등히 높은 승률을 기록했다.23</p>
<h2>4.  산업계 연구소의 비전과 성과</h2>
<p>2018년 초, 학계의 이론적 탐구와 더불어 AI 연구를 선도하는 산업계 연구소들의 움직임 또한 주목할 만했다. 특히 Google(Brain &amp; DeepMind)과 Facebook AI Research(FAIR)는 당시 AI 기술의 현주소와 미래 방향성을 제시하는 중요한 발표들을 내놓았다. 이들의 연구는 학문적 깊이를 추구하면서도 동시에 수십억 명의 사용자를 가진 실제 제품 및 서비스로의 연결고리를 항상 염두에 두고 있다는 점에서 특징적이다.</p>
<h3>4.1  Google (Brain &amp; DeepMind): AI 기술의 민주화와 범용화</h3>
<p>2018년 1월, Google Brain 팀은 블로그 게시물을 통해 2017년의 주요 성과를 회고하고 2018년의 비전을 제시했다.5 이 발표는 기술의 심화와 확산이라는 두 가지 핵심 전략, 즉 **AI 민주화(Democratization)**와</p>
<p><strong>범용 지능(Generality) 추구</strong>로 요약될 수 있다. 이는 AI 기술의 ’사용’을 최대한 쉽게 만들어 광범위한 개발자 생태계를 Google 플랫폼 위에 구축하는 동시에, 아무나 따라올 수 없는 압도적인 기초 연구 성과를 통해 기술적 ’해자(moat)’를 깊게 파는 이중 전략으로 분석된다.</p>
<p>첫째, <strong>AI 민주화</strong>는 AI 기술에 대한 접근 장벽을 낮추어 더 많은 개발자와 기업이 이를 활용할 수 있도록 하는 것을 목표로 한다.</p>
<ul>
<li>
<p><strong>AutoML</strong>은 전문가 수준의 지식이 없어도 강화학습과 진화 알고리즘을 통해 특정 데이터셋에 최적화된 신경망 아키텍처를 자동으로 설계해주는 기술이다. 이는 고성능 모델 개발에 필요한 시간과 노력을 극적으로 줄여주었다.5</p>
</li>
<li>
<p><strong>TensorFlow 생태계 확장</strong> 역시 중요한 축이었다. 모바일 및 임베디드 기기에서 효율적으로 모델을 실행할 수 있는 <code>TensorFlow Lite</code>와, 파이썬처럼 직관적이고 대화형 프로그래밍이 가능한 <code>Eager execution</code> 모드를 도입하여 개발자 저변을 크게 확대했다.5</p>
</li>
<li>
<p>자체 개발한 AI 가속기 칩인 **TPU(Tensor Processing Unit)**를 Google Cloud Platform을 통해 상용 서비스로 제공하고, <code>TensorFlow Research Cloud</code> 프로그램을 통해 전 세계 연구자들에게 1,000개의 Cloud TPU 클러스터에 대한 무료 액세스를 제공함으로써 고성능 컴퓨팅 자원에 대한 접근성을 획기적으로 개선했다.5</p>
</li>
</ul>
<p>둘째, <strong>범용 지능 추구</strong>는 특정 작업에 국한되지 않고 다양한 문제를 해결할 수 있는 일반적인 AI를 개발하려는 장기적 목표를 반영한다.</p>
<ul>
<li>
<p>2017년 12월에 발표된 <strong>AlphaZero</strong>는 이 방향성의 정점을 보여주었다. 이전 버전인 AlphaGo와 달리, AlphaZero는 바둑뿐만 아니라 체스와 쇼기까지 단일 알고리즘으로 정복했다. 특히 인간의 기보 데이터나 특정 게임에 대한 도메인 지식 없이, 오직 게임의 규칙과 순수한 자가 대국(self-play)만으로 수 시간 내에 세계 챔피언 프로그램을 압도하는 초인적인 수준에 도달했다. 이는 강화학습 알고리즘이 특정 문제를 넘어 일반적인 문제 해결 능력으로 확장될 수 있다는 강력한 증거를 제시한 이정표였다.2</p>
</li>
<li>
<p><strong>로보틱스</strong> 분야에서는 로봇이 복잡하고 정돈되지 않은 실제 환경에서 새로운 기술을 빠르게 습득하는 방향에 집중했다. 시뮬레이션 환경에서의 대규모 학습 경험과 소량의 실제 로봇 경험을 효과적으로 결합하는 방법, 그리고 인간의 시연을 관찰하여 행동을 모방하는 <strong>모방 학습(imitation learning)</strong> 연구를 통해, 명시적인 프로그래밍 없이도 로봇이 복잡한 작업을 학습할 수 있는 가능성을 보여주었다.27</p>
</li>
</ul>
<p>Google의 이러한 이중 전략은 상호 보완적이다. AutoML, TensorFlow Lite 등은 더 많은 개발자를 Google의 기술 스택에 유입시켜 강력한 플랫폼 생태계를 구축하는 역할을 한다. 이 생태계는 다시 Google의 기초 연구를 위한 풍부한 데이터, 인재, 그리고 현실 세계의 문제들을 제공하는 토양이 된다. 반면, AlphaZero와 같은 기초 연구의 압도적인 성과는 기술적 리더십을 공고히 하고, 그 결과물은 다시 생태계를 강화하는 새로운 기술과 도구로 환원되는 선순환 구조를 만들어낸다. 2018년 초 Google의 행보는 이러한 선순환 구조를 통해 AI 시대의 패권을 장악하려는 체계적인 전략을 명확히 보여주었다.</p>
<h3>4.2  Facebook AI Research (FAIR): 상호작용과 자기지도학습을 통한 돌파구 모색</h3>
<p>같은 시기, Facebook AI Research(FAIR)는 정적인 데이터셋의 한계를 넘어, 에이전트가 환경과 능동적으로 <strong>상호작용</strong>하며 학습하고, 레이블이 없는 방대한 데이터로부터 스스로 지식을 추출하는 **자기지도학습(self-supervised learning)**을 통해 AI의 근본적인 돌파구를 찾으려는 연구에 집중했다.28 ICLR 2018에서 발표된 FAIR의 주요 연구들은 이러한 방향성을 뚜렷하게 보여주었다.</p>
<p>‘Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent’ 연구는 언어 학습에 대한 새로운 패러다임을 제시했다.29 기존의 자연어 처리 연구가 대부분 정적인 텍스트 데이터셋에 의존했던 것과 달리, 이 연구는 에이전트가 텍스트 어드벤처 게임이라는</p>
<p><strong>상호작용적 환경</strong> 속에서 언어를 학습하도록 했다. ’Mechanical Turker Descent(MTD)’라고 명명된 이 독특한 학습 절차에서는, Amazon Mechanical Turk의 인간 작업자들이 에이전트에게 자연어 명령을 내리고, 에이전트의 현재 능력 수준에 맞춰 점진적으로 더 어렵고 복잡한 과제를 제시한다. 인간 교사는 에이전트가 성공할 수 있도록 돕는 과정에서 자연스럽게 교육 데이터를 ’조정(adapt)’하게 되는데, 이는 정적인 데이터셋을 사용하는 것보다 훨씬 더 풍부하고 효과적인 학습 신호를 제공한다. 이 연구는 언어가 단순히 기호의 나열이 아니라, 특정 환경과 상호작용하며 그 의미가 ’체화(grounded)’되어야 한다는 중요한 철학을 실험적으로 입증했다.</p>
<p>’Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play’는 외부의 명시적인 보상 신호 없이 에이전트가 스스로 학습하도록 유도하는 방법을 탐구했다.29 이 연구는 두 개의 에이전트(Alice와 Bob)가 비대칭적인 게임을 하도록 설계했다. ’Alice’의 목표는 현재 ’Bob’의 능력으로 풀기에 너무 쉽지도, 너무 어렵지도 않은 적절한 난이도의 과제를 스스로 생성하여 제시하는 것이다. 반면 ’Bob’의 목표는 Alice가 제시한 과제를 성공적으로 해결하는 것이다. 이 과정이 반복되면서, 시스템은 외부의 감독 없이도 점진적으로 더 복잡하고 어려운 기술을 학습하는 ’자동 커리큘큘럼(automatic curricula)’을 스스로 만들어낸다. 이는 막대한 양의 레이블링된 데이터에 대한 의존도를 줄이고, AI가 스스로 탐험하고 학습하게 만들려는 자기지도학습의 핵심 목표를 향한 중요한 진전이었다.</p>
<h2>5.  AI 기술의 사회경제적 함의</h2>
<p>2018년 초는 AI 기술의 발전이 단순히 학문적 성과에 머무르지 않고, 사회와 경제 전반에 미칠 구체적인 영향에 대한 논의가 본격화되던 시기였다. 이 시기에 발표된 주요 보고서와 산업계 동향은 AI가 가져올 거시적 변화, 특히 노동 시장의 미래와 특정 산업 분야의 혁신에 대한 깊이 있는 통찰을 제공한다.</p>
<h3>5.1  자동화와 노동 시장의 미래: NBER 연구 분석</h3>
<p>2018년 1월, MIT의 Daron Acemoglu와 보스턴 대학의 Pascual Restrepo는 전미경제연구소(NBER) 워킹 페이퍼 ’Artificial Intelligence, Automation and Work’를 통해 AI와 자동화가 노동 시장에 미치는 영향을 분석하는 정교한 이론적 프레임워크를 제시했다.30 이 연구는 기술 발전에 대한 막연한 낙관론이나 비관론을 넘어, 자동화가 노동 수요에 미치는 복합적인 효과를 체계적으로 분해하여 분석했다는 점에서 큰 의미를 가진다.</p>
<p>프레임워크의 핵심은 자동화가 노동 시장에 미치는 두 가지 상반된 효과를 구분하는 것이다. 첫째는 **‘대체 효과(Displacement Effect)’**다. 이는 기계와 AI가 과거에 인간 노동자가 수행하던 과업(task)을 대체함으로써 해당 직무의 노동 수요와 임금을 직접적으로 감소시키는 부정적인 효과다. 둘째는 **‘생산성 효과(Productivity Effect)’**다. 자동화를 통해 생산 비용이 절감되면 경제 전반의 생산성이 향상되고, 이는 새로운 상품과 서비스에 대한 수요를 창출하여 자동화되지 않은 다른 과업에서 새로운 노동 수요를 유발하는 긍정적인 효과다. 또한, 자동화로 인한 자본 축적은 다시 노동 수요를 증가시키는 추가적인 효과를 낳는다.30</p>
<p>이 연구가 특히 강조하는 것은 이러한 상쇄 효과들만으로는 노동자의 미래를 낙관하기 어렵다는 점이다. 대체 효과를 극복하고 장기적으로 노동 수요와 임금 수준을 유지하는 가장 강력하고 결정적인 힘은 기술 발전 자체가 **‘새로운 과업의 창출(Creation of New Tasks)’**을 이끌어내는 것이다. 즉, AI가 단순히 기존의 업무를 더 효율적으로 수행하는 데 그치지 않고, 데이터 과학자, AI 윤리 전문가, 로봇 유지보수 기술자, AI 모델 튜너 등과 같이 과거에는 존재하지 않았던 완전히 새로운 종류의 인간 노동 과업을 만들어낼 때, 자동화의 긍정적인 효과가 부정적인 효과를 압도할 수 있다는 것이다.30</p>
<p>결론적으로 이 연구는 기술과 노동자 기술 간의 불일치(mismatch), 그리고 사회적 최적 수준을 넘어서는 과도한 자동화(excessive automation) 경향과 같은 시장의 불완전성을 지적한다. 이는 AI 시대에 맞는 교육 시스템의 근본적인 개혁과 더불어, 기술 발전의 방향 자체에 대한 사회적 논의와 정책적 개입의 필요성을 강력하게 시사한다.30</p>
<h3>5.2  응용 분야의 확장: 저널리즘과 콘텐츠 생성</h3>
<p>AI 기술은 노동 시장과 같은 거시 경제뿐만 아니라, 특정 산업 분야의 업무 방식을 근본적으로 바꾸기 시작했다. 2018년 1월 세계경제포럼(WEF)에 게재된 기사는 <strong>저널리즘</strong> 분야에서 AI가 어떻게 활용되고 있는지를 구체적으로 조명했다.31</p>
<p>가장 두드러진 변화는 **‘루틴한 보도의 자동화’**였다. AP 통신은 이미 AI를 활용하여 기업의 분기별 실적 보고서 기사를 자동으로 생성하고 있었으며, 이를 통해 보도 범위를 기존 300개 기업에서 4,000개 기업으로 10배 이상 대폭 확장했다. 스포츠 경기 결과, 주식 시황, 선거 개표 속보 등과 같이 정형화된 데이터를 기반으로 하는 기사 작성은 AI가 인간보다 훨씬 빠르고 정확하게 처리할 수 있는 영역임이 입증된 것이다. Narrative Science의 공동 창업자는 향후 15년 내에 기사의 90%가 AI에 의해 작성될 것이라는 대담한 예측을 내놓기도 했다.31</p>
<p>이러한 변화는 기자들에게 위기이자 기회였다. AI가 반복적인 데이터 기반 기사 작성을 대신해주면서, 기자들은 단순 사실 전달 업무에서 벗어나 인간만이 할 수 있는 심층 인터뷰, 탐사 보도, 현장 취재와 같은 고부가가치 활동에 더 많은 시간을 할애할 수 있게 되었다. 또한, AI는 방대한 데이터를 실시간으로 분석하여 인사이트를 제공하거나, 텍스트 기사를 기반으로 짧은 동영상을 자동으로 제작하는 등 콘텐츠 제작의 진입 장벽을 낮추는 역할도 했다.31</p>
<p>하지만 도전 과제도 명확했다. AI, 특히 딥러닝 모델이 효과적으로 작동하기 위해서는 방대한 양의 학습 데이터가 필요한데, 많은 저널리즘 영역에서는 이러한 데이터가 부족했다. 또한, 정형화된 데이터와 달리 뉘앙스와 맥락이 중요한 비정형 데이터를 이해하고 종합하여 깊이 있는 기사를 작성하는 것은 당시 AI 기술의 명백한 한계였다. AI 저널리즘의 부상은 기술적 가능성과 함께 기자의 역할, 저작권, 그리고 저널리즘의 본질에 대한 근본적인 질문을 던지며 해당 산업에 큰 파장을 일으켰다.31</p>
<h2>6. 결론: 2018년 1월의 유산과 미래 전망</h2>
<p>2018년 초는 AI 연구가 양적인 팽창을 넘어 질적인 심화로 나아가는 중요한 변곡점이었음을 명확히 보여준다. 학계에서는 다중 에이전트 시스템의 사회적 상호작용, 최적화 알고리즘의 이론적 견고성, 그리고 구면과 같은 새로운 데이터 구조로의 표현 학습 확장 등 근본적인 문제에 대한 탐구가 활발히 이루어졌다. 동시에 산업계에서는 AutoML과 TensorFlow 생태계 확장을 통해 AI 기술의 저변을 넓히는 ’민주화’와, AlphaZero를 통해 특정 도메인을 넘어선 범용 알고리즘의 가능성을 증명하는 ’범용화’라는 체계적인 전략이 동시에 추진되었다.</p>
<p>이 시기의 연구들이 이후 AI 기술 발전에 미친 영향은 지대하다. AAAI 2018에서 주목받은 다중 에이전트 강화학습 연구는 오늘날 자율 군집 드론, 협력적 로봇 시스템, 그리고 복잡계 사회경제 시뮬레이션 연구의 중요한 이론적 토대가 되었다. ICLR 2018에서 제기된 Adam의 수렴성 문제와 AMSGrad의 제안은 이후에도 수많은 개선된 최적화 알고리즘 연구에 영감을 주었으며, 모델 학습의 안정성과 신뢰성에 대한 학계의 경각심을 높였다. Spherical CNNs는 기하 딥러닝(Geometric Deep Learning) 분야의 중요한 초기 성과로서, 이후 그래프 신경망(GNN)을 비롯한 다양한 비유클리드 데이터를 다루는 아키텍처 연구를 촉진하는 기폭제가 되었다. 무엇보다 Google의 AutoML과 AlphaZero가 보여준, 특정 문제 해결을 넘어 ’문제 해결 방법 자체를 학습’하거나 ’일반적인 규칙으로부터 전문성’을 이끌어내는 접근법은, 2018년 OpenAI가 GPT-1을 발표한 이래 32 다양한 작업을 수행할 수 있는 거대 언어 모델(LLM)과 같은 ’파운데이션 모델’의 등장을 예고하는 서막이었다.</p>
<p>결론적으로, 2018년 1월에 뚜렷하게 나타난 ’이해를 향한 탐구’와 ’범용성을 향한 도전’이라는 두 가지 거대한 흐름은 오늘날 AI 연구의 핵심 주제로 고스란히 이어지고 있다. AI의 작동 원리를 더 깊이 이해하고(해석 가능성, XAI), 더 넓은 범위의 문제에 안전하고 신뢰성 있게 적용하려는(범용성, 안전성) 노력은, 당시 뿌려진 씨앗이 자라난 결과물이다. 2018년 1월은 AI가 스스로의 한계를 인식하고, 그 한계를 넘어서기 위한 성숙한 첫걸음을 내디딘 시기로 기억될 것이다. 이러한 근본적인 질문에 대한 탐구가 앞으로도 AI 기술 발전의 가장 중요한 동력이 될 것임은 자명하다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>About - Google DeepMind, https://deepmind.google/about/</li>
<li>AlphaZero - Wikipedia, https://en.wikipedia.org/wiki/AlphaZero</li>
<li>On the Convergence of Adam and Beyond - OpenReview, https://openreview.net/forum?id=ryQu7f-RZ</li>
<li>ICML 2018 Announces Best Paper Awards - Synced Review, https://syncedreview.com/2018/06/29/icml-2018-announces-best-paper-awards/</li>
<li>The Google Brain Team — Looking Back on 2017 (Part 1 of 2 …, https://blog.research.google/2018/01/the-google-brain-team-looking-back-on.html</li>
<li>AAAI Conference Paper Awards and Recognition - AAAI, https://aaai.org/about-aaai/aaai-awards/aaai-conference-paper-awards-and-recognition/</li>
<li>ICLR 2018’s Best Papers: Variant Adam, Spherical CNNs, and Meta …, https://medium.com/syncedreview/iclr-2018s-best-papers-variant-adam-spherical-cnns-and-meta-learning-6b48dca83e8b</li>
<li>[1801.10130] Spherical CNNs - arXiv, https://arxiv.org/abs/1801.10130</li>
<li>Meta-Reinforcement Learning by Tracking Task Non-stationarity - IJCAI, https://www.ijcai.org/proceedings/2021/0399.pdf</li>
<li>Human-Centered AI and Autonomy in Robotics: Insights from a Bibliometric Study This work has been funded by the PNRR - arXiv, https://arxiv.org/html/2504.19848v1</li>
<li>Evaluating Human-AI Collaboration: A Review and Methodological Framework - arXiv, https://arxiv.org/html/2407.19098v1</li>
<li>Our key takeaways from ICLR 2018 - Research Blog - RBC Borealis, https://rbcborealis.com/research-blogs/our-key-takeaways-iclr-2018/</li>
<li>ICLR 2018 Conference Track - OpenReview, https://openreview.net/group?id=ICLR.cc/2018/Conference</li>
<li>ON THE CONVERGENCE OF ADAM AND BEYOND - OpenReview, https://openreview.net/pdf?id=ryQu7f-RZ</li>
<li>On the convergence of adam and beyond. - arXiv, https://arxiv.org/pdf/1904.09237</li>
<li>On The Convergence Of ADAM And Beyond - statwiki - Math Wiki Server, https://wiki.math.uwaterloo.ca/statwiki/index.php?title=On_The_Convergence_Of_ADAM_And_Beyond</li>
<li>Gradient Descent Optimization With AMSGrad From Scratch - MachineLearningMastery.com, https://machinelearningmastery.com/gradient-descent-optimization-with-amsgrad-from-scratch/</li>
<li>Spherical CNNs | OpenReview, https://openreview.net/forum?id=Hkbd5xZRb</li>
<li>Spherical correlation as a similarity measure for 3-D radiation patterns of musical instruments | Acta Acustica, https://acta-acustica.edpsciences.org/articles/aacus/full_html/2023/01/aacus220100/aacus220100.html</li>
<li>Shape Registration with Spherical Cross Correlation, http://www-sop.inria.fr/asclepios/events/MFCA08/Proceedings/mfca08_2_3.pdf</li>
<li>How does reinforcement learning deal with non-stationary environments? - Milvus, https://milvus.io/ai-quick-reference/how-does-reinforcement-learning-deal-with-nonstationary-environments</li>
<li>How do intelligent agents cope with non-stationary environments? - Tencent Cloud, https://www.tencentcloud.com/techpedia/126283</li>
<li>Continuous Adaptation via Meta-Learning in Nonstationary and …, https://openreview.net/forum?id=Sk2u1g-0-</li>
<li>Google DeepMind - Wikipedia, https://en.wikipedia.org/wiki/Google_DeepMind</li>
<li>Simple Alpha Zero - Surag Nair, https://suragnair.github.io/posts/alphazero.html</li>
<li>AlphaZero - YouTube, https://www.youtube.com/watch?v=4FdiTTZPkos</li>
<li>The Google Brain Team — Looking Back on 2017 (Part 2 of 2), https://research.google/blog/the-google-brain-team-looking-back-on-2017-part-2-of-2/</li>
<li>FAIR at 5: Facebook Artificial Intelligence Research accomplishments - Engineering at Meta, https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/</li>
<li>Facebook Research at ICLR 2018, https://research.facebook.com/blog/2018/5/facebook-research-at-iclr-2018/</li>
<li>Artificial Intelligence, Automation and Work - National Bureau of Economic Research, https://www.nber.org/system/files/working_papers/w24196/w24196.pdf</li>
<li>Can you tell if this was written by a robot? 7 challenges for AI in journalism, https://www.weforum.org/stories/2018/01/can-you-tell-if-this-article-was-written-by-a-robot-7-challenges-for-ai-in-journalism/</li>
<li>The Future of AI: How Artificial Intelligence Will Change the World - Built In, https://builtin.com/artificial-intelligence/artificial-intelligence-future</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>