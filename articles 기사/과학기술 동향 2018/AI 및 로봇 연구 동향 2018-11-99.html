<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2018년 11월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2018년 11월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2018년 AI 및 로봇 연구 동향</a> / <span>2018년 11월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2018년 11월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2018년, AI 연구의 변곡점</h2>
<p>2018년 하반기는 인공지능 연구, 특히 자연어 처리(NLP)와 로보틱스 분야에서 패러다임의 전환을 예고하는 중요한 시기였다. 이는 대규모 데이터셋의 가용성, Transformer 아키텍처와 같은 혁신적인 모델링 기법의 성숙 1, 그리고 Cloud TPU 등으로 대표되는 연산 능력의 폭발적인 증가가 결합하여 이루어낸 필연적인 결과였다.3 이 시기는 단순히 점진적인 성능 향상을 넘어, 문제에 접근하는 근본적인 방식 자체를 바꾸는 연구들이 등장한 변곡점으로 기록된다.</p>
<p>주요 연구 동향을 살펴보면, 자연어 처리 분야에서는 사전 학습(Pre-training) 후 특정 과업에 맞게 미세 조정(Fine-tuning)하는 패러다임이 주류로 자리 잡았으나, 기존 모델들은 문맥을 이해하는 방식에 본질적인 한계를 가지고 있었다.3 2018년 11월은 이 한계를 극복하려는 시도가 정점에 달한 시기였다. 심층 학습 이론 분야에서는 ResNet의 성공 이후, 심층 신경망의 구조와 깊이에 대한 근본적인 질문이 제기되었고, 이산적인(discrete) 레이어 구조를 연속적인(continuous) 형태로 일반화하려는 탐구가 이루어졌다.5 로보틱스 분야에서는 시뮬레이션 환경을 넘어, 실제 로봇이 물리적 세계와 상호작용하며 대규모 데이터를 스스로 수집하고 학습하는 자기 지도 학습(Self-supervised learning) 및 강화 학습(Reinforcement learning)이 로봇 조작(manipulation) 및 자율 비행(autonomous flight)과 같은 고난도 문제에 성공적으로 적용되기 시작했다.7</p>
<p>본 보고서는 2018년 11월을 전후하여 발표된 AI 및 로봇 분야의 가장 영향력 있는 연구들을 심층적으로 분석한다. 제1장에서는 NLP의 역사를 새로 쓴 BERT를, 제2장에서는 심층 신경망의 이론적 지평을 넓힌 Neural ODE를 다룬다. 제3장과 제4장에서는 각각 로봇 조작과 자율 비행 분야에서 학습 기반 방법론의 새로운 가능성을 제시한 CoRL 2018의 주요 연구들을 분석한다. 마지막으로 결론에서는 이들 연구가 AI 분야의 미래 연구 방향에 미친 총체적인 영향을 고찰한다.</p>
<h2>2.  자연어 처리의 새로운 시대: BERT의 등장과 양방향 언어 표현</h2>
<h3>2.1  기존 언어 모델의 한계와 양방향성의 중요성</h3>
<p>2018년 이전, 사전 학습 기반 언어 모델들은 자연어 처리 분야에서 큰 성공을 거두고 있었지만, 문맥을 이해하는 방식에서 명백한 한계를 드러냈다. OpenAI의 GPT와 같은 모델들은 ‘왼쪽에서 오른쪽으로’ 이어지는 단방향(unidirectional) 구조를 채택했다.10 이러한 구조는 다음 단어를 예측하는 전통적인 언어 모델링(Language Modeling) 작업에는 적합했으나, 문장 전체의 의미를 종합적으로 파악해야 하는 질의응답(Question Answering)이나 자연어 추론(Natural Language Inference)과 같은 과업에서는 정보의 손실을 야기했다. 예를 들어, “나는 은행 계좌에 접근했다“라는 문장에서 ’은행(bank)’의 의미를 정확히 파악하기 위해서는 뒤따라오는 ’계좌(account)’라는 단어가 결정적인 단서가 되지만, 단방향 모델은 이 정보를 활용할 수 없었다.2</p>
<p>이러한 한계를 극복하기 위해 ELMo와 같은 모델들은 독립적으로 학습된 좌-우 방향 LSTM과 우-좌 방향 LSTM의 결과를 단순히 이어 붙이는(concatenate) 방식을 사용했다.4 하지만 이는 ‘얕은(shallow)’ 양방향성에 불과했으며, 심층 신경망의 모든 계층에서 양쪽 문맥을 동시에 통합하여 상호작용하도록 하지는 못했다.2 진정한 의미의 심층 양방향 모델을 구현하는 것은 기술적으로 매우 어려운 과제였다. 예측해야 할 단어가 입력으로 동시에 주어질 경우, 모델이 여러 계층을 거치면서 간접적으로 자기 자신을 ‘엿보는(see itself)’ 순환(cycle) 문제가 발생하여 예측이 무의미해지기 때문이었다.2</p>
<h3>2.2  BERT의 혁신적 사전 학습 방법론</h3>
<p>BERT(Bidirectional Encoder Representations from Transformers)는 이러한 양방향성의 난제를 두 가지 독창적인 사전 학습 과업을 통해 해결했다.</p>
<p>첫째는 **Masked Language Model (MLM)**이다. 이는 고전적인 Cloze task에서 영감을 얻은 방식으로, 입력 문장에서 무작위로 일부 토큰을 특수한 <code>토큰으로 치환한 뒤, 문장의 왼쪽과 오른쪽 문맥을 모두 이용하여 원래의 토큰을 예측하도록 모델을 학습시키는 것이다.[3, 4, 11, 12] 구체적으로, 전체 토큰의 15%를 예측 대상으로 삼되, 이 중 80%는</code> 토큰으로 바꾸고, 10%는 무작위 단어로 대체하며, 나머지 10%는 원래 단어를 그대로 유지했다. 이러한 전략은 모델이 특정 토큰(``)에만 과적합되는 것을 방지하고, 실제 단어에 대한 표현까지 풍부하게 학습하도록 유도했다.11</p>
<p>둘째는 **Next Sentence Prediction (NSP)**이다. 이는 단어 수준의 이해를 넘어 문장 간의 관계를 모델이 학습하도록 설계된 과업이다. 두 개의 문장 A와 B를 입력으로 받아, 문장 B가 코퍼스에서 실제로 문장 A의 바로 다음에 오는 문장인지(<code>IsNext</code>), 아니면 단순히 무작위로 추출된 관련 없는 문장인지(<code>NotNext</code>)를 이진 분류하는 문제이다.2 이 NSP 과업은 질의응답이나 자연어 추론과 같이 두 텍스트 사이의 논리적 관계를 파악하는 것이 중요한 다운스트림 태스크에서 모델의 성능을 크게 향상시키는 역할을 했다.11</p>
<h3>2.3  모델 아키텍처 및 상세 제원</h3>
<p>BERT는 Vaswani 등이 2017년에 제안한 Transformer 아키텍처의 인코더 부분만을 여러 층으로 깊게 쌓은 구조를 기반으로 한다.2 Transformer의 핵심인 Self-Attention 메커니즘은 문장 내 모든 단어 쌍 간의 관계를 직접적으로 계산함으로써, 양방향 문맥 정보를 매우 효과적으로 통합할 수 있게 했다.</p>
<p>모델의 입력을 처리하기 위해 단일 문장과 문장 쌍을 모두 포괄할 수 있는 특별한 입력 표현 방식이 고안되었다. 모든 입력 시퀀스의 시작에는 분류 과업을 위한 정보를 집약하는 <code>토큰이 위치하며, 문장과 문장 사이, 그리고 시퀀스의 끝은</code> 토큰으로 구분된다. 최종적으로 각 토큰의 입력 벡터는 해당 토큰의 고유 의미를 나타내는 ‘Token Embedding’, 문장 A와 B를 구분하는 ‘Segment Embedding’, 그리고 토큰의 순서 정보를 담은 ’Position Embedding’의 합으로 구성된다.4</p>
<p>Google은 두 가지 규모의 사전 학습된 모델을 공개하여 연구 및 활용의 폭을 넓혔다.3</p>
<table><thead><tr><th>모델 (Model)</th><th>Transformer 블록 (L)</th><th>은닉층 크기 (H)</th><th>어텐션 헤드 (A)</th><th>총 파라미터 수 (Total Parameters)</th></tr></thead><tbody>
<tr><td>BERT_BASE</td><td>12</td><td>768</td><td>12</td><td>110M</td></tr>
<tr><td>BERT_LARGE</td><td>24</td><td>1024</td><td>16</td><td>340M</td></tr>
</tbody></table>
<h3>2.4  압도적인 성능과 영향력</h3>
<p>BERT는 공개와 동시에 11개의 주요 NLP 태스크에서 기존 최고 성능(State-of-the-Art, SOTA)을 경신하며 학계와 산업계에 큰 충격을 주었다.2 9개의 다양한 자연어 이해(NLU) 과업으로 구성된 GLUE 벤치마크에서는 80.5%의 점수를 기록하며 기존 SOTA 대비 7.7%p라는 경이적인 절대 성능 향상을 이루었고 4, 스탠포드 질의응답 데이터셋(SQuAD v1.1)에서는 F1 점수 93.2%를 달성하여 인간의 수행 능력(91.2%)마저 뛰어넘었다.2</p>
<table><thead><tr><th>모델 (Model)</th><th>MultiNLI-m/mm Acc (%)</th><th>SQuAD v1.1 F1</th><th>GLUE Score</th></tr></thead><tbody>
<tr><td>OpenAI GPT (Previous SOTA)</td><td>82.1 / 81.4</td><td>88.5</td><td>72.8</td></tr>
<tr><td><strong>BERT_BASE</strong></td><td>84.6 / 83.4</td><td>90.9</td><td>79.6</td></tr>
<tr><td><strong>BERT_LARGE</strong></td><td><strong>86.7</strong> / 85.9</td><td><strong>93.2</strong></td><td><strong>80.5</strong></td></tr>
</tbody></table>
<p>BERT의 등장은 NLP 연구의 패러다임을 근본적으로 바꾸었다. 이전까지 연구자들이 특정 태스크에 맞춰 정교한 모델 아키텍처를 설계하는 데 집중했다면, BERT 이후에는 거대한 비지도 데이터로 사전 학습된 범용 모델을 각자의 태스크에 맞게 미세 조정(fine-tuning)하는 방식이 표준으로 자리 잡았다.2 이는 ’BERTology’라는 신조어를 탄생시키며, 사전 학습된 모델이 무엇을 어떻게 학습하는지를 탐구하는 수많은 후속 연구를 촉발했다.13</p>
<p>BERT의 진정한 혁신은 단순히 성능 향상에만 그치지 않는다. 이는 AI 연구에서 ’규모의 경제’가 작동함을 명확히 증명한 첫 사례 중 하나였다. BERT_LARGE 모델이 BERT_BASE보다 월등한 성능을 보인다는 사실은 3, 더 큰 모델, 더 많은 데이터, 그리고 더 강력한 연산 능력이 곧 더 뛰어난 지능으로 이어진다는 ’스케일링 법칙(Scaling Law)’의 강력한 초기 증거가 되었다. 이 발견은 이후 GPT-3와 같은 초거대 모델의 등장을 이끌었으며, AI 연구의 주도권이 전통적인 학계 연구실에서 구글과 같이 막대한 연산 자원을 보유한 거대 산업 연구소로 이동하는 흐름을 가속화하는 결정적인 계기가 되었다.</p>
<h2>3.  심층 신경망의 재해석: 연속-깊이 모델의 이론적 토대</h2>
<h3>3.1  ResNet과 상미분방정식(ODE)의 연결</h3>
<p>잔차 네트워크(ResNet)의 성공은 심층 신경망의 깊이에 대한 기존의 통념을 깨뜨렸지만, 동시에 그 작동 원리에 대한 근본적인 질문을 던졌다. ResNet의 핵심 아이디어는 다음 레이어의 상태 <span class="math math-inline">h_{t+1}</span>을 이전 레이어 상태 <span class="math math-inline">h_t</span>에 잔차 함수 <span class="math math-inline">f(h_t, \theta_t)</span>를 더하는 이산적인 변환으로 표현된다.5</p>
<p><span class="math math-display">
h_{t+1} = h_t + f(h_t, \theta_t)
</span></p>
<p>“Neural Ordinary Differential Equations” (NODE) 논문은 이 이산적인 업데이트 규칙을 시간 단계 <span class="math math-inline">\Delta t = 1</span>로 고정된 미분방정식의 근사 해법으로 해석했다. 만약 이 시간 단계를 0에 가깝게 무한히 작게 만든다면, 이산적인 레이어의 연속은 하나의 연속적인 변환 과정으로 일반화될 수 있다.6 이 관점에서 ResNet은 상미분방정식(Ordinary Differential Equation, ODE)을 가장 단순한 수치 해법인 오일러 방법(Euler method)으로 이산화(discretization)한 특수한 경우로 볼 수 있다.5 NODE는 여기서 한 걸음 더 나아가, 신경망의 은닉 상태 변화 자체를 신경망 <span class="math math-inline">f</span>에 의해 매개변수화된 연속적인 동역학(continuous dynamics)으로 직접 모델링한다.5</p>
<p><span class="math math-display">
\frac{dh(t)}{dt} = f(h(t), t, \theta)
</span></p>
<p>이 모델에서 네트워크의 최종 출력 <span class="math math-inline">h(T)</span>는 초기값 <span class="math math-inline">h(0)</span>(입력)으로부터 시간 <span class="math math-inline">T</span>까지 이 ODE를 적분하여 얻는 해(solution)로 정의된다. 즉, <span class="math math-inline">h(T) = \text{ODESolve}(h(0), f, t_0, t_1, \theta)</span>이다.</p>
<h3>3.2  Adjoint Sensitivity Method를 이용한 효율적인 학습</h3>
<p>연속-깊이 모델을 학습시키는 데 있어 가장 큰 기술적 난관은 ODE 솔버의 전체 계산 과정을 통해 그래디언트를 역전파(backpropagation)하는 것이다. 이는 순전파 과정에서 계산된 모든 중간값들을 메모리에 저장해야 하므로 엄청난 메모리 비용을 요구하며, 수치적 오차를 누적시키는 문제를 낳는다.17</p>
<p>NODE는 이 문제를 해결하기 위해 제어 이론 분야에서 오랫동안 사용되어 온 Adjoint Sensitivity Method를 도입했다.5 이 방법은 손실 함수 <span class="math math-inline">L</span>의 그래디언트를 직접 계산하는 대신, ’Adjoint’라 불리는 보조 상태 <span class="math math-inline">a(t) = dL/dh(t)</span>를 정의한다. 그리고 이 Adjoint의 동역학을 나타내는 또 다른 ODE를 시간의 역방향으로 풀어 파라미터 <span class="math math-inline">\theta</span>에 대한 그래디언트를 간접적으로, 하지만 매우 효율적으로 계산한다.5</p>
<p><span class="math math-display">
\frac{da(t)}{dt} = -a(t)^T \frac{\partial f(h(t), t, \theta)}{\partial h}
</span></p>
<p>이 방식의 가장 큰 장점은 순전파 과정의 중간값들을 전혀 저장할 필요가 없다는 점이다. 따라서 네트워크의 ‘깊이’(즉, 적분 시간 <span class="math math-inline">T</span>)와 무관하게 **상수 메모리 비용(constant memory cost)**으로 모델을 학습시킬 수 있다.5</p>
<h3>3.3  연속-깊이 모델의 장점과 의의</h3>
<p>NeurIPS 2018 최고 논문상(Best Paper Award)을 수상한 이 연구는 18 심층 학습 분야에 몇 가지 중요한 기여를 했다. 첫째, ODE 솔버는 사용자가 요구하는 정밀도(tolerance)에 따라 계산량을 동적으로 조절하는 **적응형 계산(adaptive computation)**을 가능하게 한다. 이는 입력 데이터의 난이도에 따라 계산량을 조절하거나, 추론 시 속도와 정확도를 유연하게 조절할 수 있음을 의미한다.5</p>
<p>더 중요한 것은 이 연구가 제시한 이론적 관점이다. NODE는 심층 학습 모델을 미분방정식이라는 새로운 수학적 프레임워크 안에서 이해할 수 있는 길을 열었다. 이는 ResNet, Normalizing Flows 등 기존의 여러 모델을 통합된 관점에서 해석하고, 이를 바탕으로 새로운 모델을 설계할 수 있는 강력한 이론적 토대를 제공했다.6</p>
<p>NODE의 등장은 딥러닝 연구의 패러다임이 ’아키텍처 엔지니어링’의 시대를 넘어 ’동역학 시스템 설계’의 시대로 나아갈 수 있는 가능성을 제시했다. 이는 단순히 더 깊은 네트워크를 쌓는 것을 넘어, 네트워크 내부의 정보 흐름 자체를 하나의 연속적인 과정으로 보고, 그 ‘동역학적 속성’(예: 안정성, 수렴성)을 직접 설계하는 새로운 연구 방향을 열었다. 비록 실용적인 측면에서 NODE가 항상 ResNet보다 우월한 성능을 보이지는 않았지만 6, 이 연구는 딥러닝의 수학적 기초를 공고히 하고, 물리 현상을 모델링하는 과학적 기계 학습(Scientific Machine Learning) 분야의 발전에 지대한 영향을 미쳤다.</p>
<h2>4.  로봇 조작의 지능화: 대규모 자기 지도 학습의 약진</h2>
<p>2018년 로봇 학습 컨퍼런스(CoRL)에서는 실제 로봇이 물리적 세계와의 상호작용을 통해 대규모 데이터를 스스로 생성하고, 이를 바탕으로 복잡한 조작 기술을 학습하는 연구들이 큰 주목을 받았다.</p>
<h3>4.1  Dense Object Nets: 조작을 위한 고밀도 시각 표현 학습</h3>
<p>인간은 물체의 특정 부분을 정확히 인지하고 조작할 수 있다. 예를 들어, 신발의 특정 구멍에 끈을 꿰거나, 컵의 손잡이를 잡는 행위가 그렇다. 로봇에게 이러한 능력을 부여하기 위해, CoRL 2018 최고 논문상(Best Paper Award)을 수상한 “Dense Object Nets” 연구는 인간의 레이블링 없이 로봇 스스로 물체의 각 부분에 대한 일관된 시각적 표현(dense visual descriptor)을 학습하는 방법을 제안했다.7 이 표현은 물체의 자세가 바뀌거나 형태가 변형되더라도 특정 지점(e.g., 인형의 오른쪽 귀)을 일관되게 식별하고 파지하는 데 사용될 수 있다.7</p>
<p>이 연구의 핵심은 자기 지도 학습(self-supervised learning) 방법론에 있다.</p>
<ol>
<li>
<p><strong>데이터 생성</strong>: 로봇 팔에 장착된 RGB-D 카메라가 물체를 여러 각도에서 촬영하며 비디오 데이터를 수집한다.25</p>
</li>
<li>
<p><strong>3D 재구성</strong>: 수집된 비디오로부터 물체의 3차원 모델을 재구성한다. 이 3D 모델을 기준으로 삼아, 서로 다른 2D 이미지에 찍힌 픽셀들이 3차원 공간상의 동일한 지점(vertex)에 해당하는지를 자동으로 판단한다. 이를 통해 어떤 픽셀 쌍이 ’일치하는 쌍(match)’이고 어떤 쌍이 ’불일치하는 쌍(non-match)’인지에 대한 방대한 학습 데이터를 자동으로 생성할 수 있다.7</p>
</li>
<li>
<p><strong>Pixelwise Contrastive Loss</strong>: Siamese 네트워크 구조를 사용하여, 일치하는 픽셀 쌍의 디스크립터 벡터 간 L2 거리는 가깝게 만들고(<span class="math math-inline">L_{matches}</span>), 불일치하는 쌍의 거리는 특정 마진 <span class="math math-inline">M</span> 이상으로 멀어지도록 유도하는 손실 함수로 네트워크를 학습시킨다.7</p>
<p><span class="math math-display">
L(I_a, I_b) = \frac{1}{N_{matches}} \sum D^2 + \frac{1}{N_{non-matches}} \sum \max(0, M - D)^2
</span></p>
</li>
</ol>
<p>이 연구는 레이블링 비용 없이 대규모 학습 데이터를 생성하는 확장 가능한 파이프라인을 제시함으로써, 강체뿐만 아니라 변형 가능한(non-rigid) 물체에도 적용 가능한 범용 시각 표현 학습의 새로운 가능성을 열었다.7</p>
<h3>4.2  QT-Opt: 대규모 강화학습을 통한 동적 파지 전략 학습</h3>
<p>기존의 로봇 파지 연구가 대부분 정적인 ’파지 지점’을 찾는 데 집중했다면, “QT-Opt” 연구는 실시간 시각 피드백을 이용해 파지 행동을 동적으로 조절하는 폐쇄 루프(closed-loop) 제어 정책을 심층 강화학습으로 학습하는 접근법을 제시했다.8</p>
<p>이 연구의 핵심은 확장 가능한 오프-정책(off-policy) 강화학습 프레임워크에 있다.</p>
<ol>
<li>
<p><strong>대규모 실제 데이터 수집</strong>: 7대의 실제 로봇 팔을 24시간 가동하여 58만 번 이상의 파지 시도 데이터를 수집했다. 파지에 성공하면 보상 +1, 실패하면 0을 부여하는 단순한 규칙으로 모든 데이터가 자동으로 레이블링되었다.8</p>
</li>
<li>
<p><strong>QT-Opt 알고리즘</strong>: Actor-Critic 구조에서 발생할 수 있는 학습 불안정성을 피하기 위해, Q-함수(Critic)만을 학습하고 행동 선택 시에는 Cross-Entropy Method와 같은 비-그래디언트 기반 최적화 기법으로 Q-값을 최대화하는 행동을 직접 탐색한다. 이는 대규모 데이터셋에서의 안정적인 학습을 가능하게 했다.27</p>
</li>
<li>
<p><strong>분산 학습</strong>: 대규모 오프-정책 데이터를 효율적으로 처리하기 위해 분산된 데이터 수집 및 학습 인프라를 구축하여 학습 속도를 극대화했다.28</p>
</li>
</ol>
<p>이러한 대규모 실제 상호작용 데이터 기반 학습의 결과, 로봇은 명시적으로 프로그래밍되지 않은 복잡하고 지능적인 **창발적 행동(emergent behaviors)**들을 스스로 습득했다.8 예를 들어, 불안정한 파지를 감지하고 물체를 놓았다가 더 안정적으로 다시 잡는</p>
<p><strong>재파지(regrasping)</strong>, 눕혀진 케첩 병을 밀어서 세운 뒤 파지하는 <strong>사전 조작(pre-grasp manipulation)</strong>, 외부 방해에 의해 물체가 움직여도 이를 추적하여 파지에 성공하는 <strong>동적 대응</strong> 능력 등이 관찰되었다.</p>
<p>CoRL 2018 최고 시스템 논문상(Best Systems Paper Award)을 공동 수상한 이 연구는 23, 대규모 실제 데이터와 확장 가능한 강화학습 알고리즘이 결합될 때, 로봇이 인간과 유사한 수준의 동적이고 적응적인 조작 능력을 학습할 수 있음을 입증했다. 이는 로봇 학습 연구의 방향을 시뮬레이션 중심에서 ‘대규모 실제 세계 상호작용(large-scale real-world interaction)’ 중심으로 전환하는 중요한 계기가 되었다.</p>
<p>2018년 CoRL에서 발표된 Dense Object Nets와 QT-Opt는 로봇 학습의 두 가지 핵심 축인 ’표상 학습(Representation Learning)’과 ’정책 학습(Policy Learning)’에서 ’데이터 생성의 자동화와 규모 확장’이라는 공통된 철학을 공유한다. Dense Object Nets는 3D 재구성을 통해 자기 지도 방식으로 표상 학습 데이터를, QT-Opt는 다수의 로봇을 이용한 자동화된 시도를 통해 강화 학습 정책 데이터를 대규모로 생성했다. 이는 로봇 학습의 병목이 더 이상 ’알고리즘 설계’가 아니라 ’양질의 대규모 상호작용 데이터 확보’에 있음을 시사한다. 이 두 연구는 로봇 분야가 NLP의 BERT와 유사한 경로, 즉 대규모 비지도/자기지도 데이터로 범용적인 능력(표상 또는 정책)을 사전 학습하는 방향으로 나아갈 것임을 예고한 선구적인 사례이다.</p>
<h2>5.  고속 자율 비행의 실현: 학습 기반 제어와 Sim-to-Real</h2>
<h3>5.1  Deep Drone Racing: 동적 환경에서의 민첩한 비행</h3>
<p>드론 레이싱과 같이 고속으로 움직이는 게이트를 통과해야 하는 동적 환경은 로봇 자율 비행 기술의 궁극적인 시험대 중 하나이다. 이러한 환경에서는 전통적인 SLAM(Simultaneous Localization and Mapping) 기반의 전역 경로 계획 및 추종 방식이 부적합하다. 고속 비행 중 발생하는 모션 블러와 급격한 조명 변화는 상태 추정의 지연 및 오차를 유발하며, 환경의 동적인 변화에 실시간으로 대응하기 어렵기 때문이다.9</p>
<p>이 문제를 해결하기 위해 CoRL 2018 최고 시스템 논문상(Best Systems Paper Award)을 수상한 “Deep Drone Racing” 연구는 23 학습 기반 인식과 전통적인 제어 기법을 결합한 독창적인 하이브리드 접근법을 제안했다.9</p>
<ol>
<li>
<p><strong>인식 모듈 (Perception Module)</strong>: 컨볼루션 신경망(CNN)이 실시간 카메라 이미지 입력을 받아, 드론의 현재 위치나 지도가 아닌, 다음 목표 지점(waypoint)의 이미지상 방향과 권장 비행 속도를 직접 출력한다. 이는 전역 상태 추정의 필요성을 제거하고, 현재의 시각 정보만으로 즉각적인 결정을 내리게 한다.9</p>
</li>
<li>
<p><strong>계획 및 제어 모듈 (Planning &amp; Control Module)</strong>: CNN이 제시한 로컬 목표 지점과 속도를 입력받아, 계산적으로 매우 효율적인 최소 저크(minimum-jerk) 궤적을 실시간으로 생성하고, 이를 정밀하게 추종하는 모터 명령을 계산한다.9</p>
</li>
</ol>
<h3>5.2  전문가 모방을 통한 정책 학습 및 Sim-to-Real</h3>
<p>이 하이브리드 시스템의 핵심인 CNN 정책은 모방 학습(Imitation Learning)을 통해 학습된다.</p>
<p>먼저, 시뮬레이션 환경에서는 모든 게이트의 위치 정보를 아는 ‘전문가(expert)’ 시스템이 전역적으로 최적인 최소 스냅(minimum-snap) 궤적을 미리 계산할 수 있다.9 그 후, 드론이 이 전문가 궤적을 따라 비행하면서, 각 시점의 카메라 이미지(학습 입력)와 그 상황에서 전문가가 선택했을 목표 지점 및 속도(학습 레이블)를 대규모 데이터셋으로 기록한다. CNN은 이 데이터셋을 이용해 전문가의 ’판단’을 모방하도록 지도 학습(supervised learning) 방식으로 훈련된다.9</p>
<p>놀랍게도, 이렇게 시뮬레이션에서 학습된 정책은 별도의 추가적인 미세 조정 없이 실제 드론에 배포되었을 때 성공적으로 작동했다. 이는 CNN이 학습한 시각적 표현이 시뮬레이션과 실제 세계 간의 차이(reality gap)에 대해 충분히 강건함을 의미한다.</p>
<h3>5.3  성능 및 의의</h3>
<p>제안된 시스템은 게이트가 최대 50%까지 가려지거나(occlusion), 예측 불가능하게 움직이는 동적인 상황에서도 기존의 엔지니어링 기반 시스템보다 훨씬 강건하게 작동함을 입증했다.9 인간 파일럿과의 비교에서는, 전문 파일럿보다는 느렸지만 중간 수준의 파일럿보다는 더 안정적이고 일관된 비행을 보여주었다. 이는 극단적인 속도보다는 안정성과의 균형을 통해 높은 완주율을 달성한 결과이다.9</p>
<p>이 연구의 핵심적인 기여는 ‘End-to-End’ 학습과 ‘모듈화된(Modular)’ 접근법 사이의 현명한 절충안을 제시한 데 있다. 순수한 End-to-End 방식(이미지에서 모터 명령까지)은 학습이 어렵고 안전성을 보장하기 힘든 반면, 순수한 모듈 방식(SLAM → 계획 → 제어)은 동적 환경에서 느리고 쉽게 실패한다. Deep Drone Racing은 시스템을 ’학습 가능한 인식’과 ’검증된 제어’라는 두 모듈로 효과적으로 분리함으로써 각 접근법의 장점을 모두 취했다. 즉, 딥러닝이 가장 잘하는 복잡한 고차원 인식 문제를 맡기고, 고전 제어 이론이 가장 잘하는 정밀하고 빠른 궤적 생성을 맡기는 이 ’하이브리드 패러다임’은 이후 많은 로봇 응용 분야에서 실용적이면서도 강력한 해결책으로 자리 잡았다.</p>
<h2>6. 결론: 2018년 연구 성과가 AI의 미래에 미치는 영향</h2>
<p>2018년 11월을 기점으로 발표된 주요 연구들은 인공지능 분야의 핵심 동력이 ’대규모 데이터’와 ’자기 지도 학습’으로 귀결됨을 명확히 보여주었다. BERT는 웹 스케일의 텍스트 데이터를 활용하여 언어 이해의 새로운 지평을 열었고, CoRL에서 발표된 로봇 연구들은 물리적 상호작용 데이터를 대규모로 생성하고 활용하여 복잡한 조작 및 비행 능력을 구현했다. 한편, Neural ODE는 이러한 경험적 성공을 뒷받침할 수 있는 새로운 이론적 관점을 제시하며 분야의 깊이를 더했다.</p>
<p>특히 BERT_LARGE의 성공은 모델과 데이터의 크기를 키우는 것(scaling)이 직접적인 성능 향상으로 이어진다는 ’스케일링 가설’에 강력한 힘을 실어주었다. 이는 이후 몇 년간 AI 연구, 특히 거대 언어 모델(LLM) 분야의 개발 경쟁을 주도하는 핵심 철학으로 자리 잡았다. 로보틱스 분야에서는 시뮬레이션을 넘어 실제 환경과의 상호작용을 통해 학습하는 것의 중요성과 가능성이 입증되었다. QT-Opt와 Deep Drone Racing은 데이터 기반 학습이 더 이상 제한된 환경의 문제가 아닌, 실제 세계의 복잡하고 동적인 문제를 해결할 수 있는 강력한 도구임을 보여주었다.</p>
<p>결론적으로, 2018년의 성과들은 AI 연구의 다음 단계를 예고했다. NLP에서는 사전 학습된 모델의 능력과 한계를 탐구하는 방향으로, 로보틱스에서는 더 복잡한 작업을 위한 일반화 가능한 표상과 정책을 학습하는 방향으로 연구가 심화될 것임을 시사했다. 이 시기에 제시된 아이디어와 방법론들은 현재 AI 기술의 근간을 이루고 있으며, 앞으로도 오랫동안 해당 분야의 발전에 지속적인 영향을 미칠 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>[PDF] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, https://www.semanticscholar.org/paper/BERT%3A-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang/df2b0e26d0599ce3e70df8a9da02e51594e0e992</li>
<li>Open Sourcing BERT: State-of-the-Art Pre-training for Natural …, https://research.google/blog/open-sourcing-bert-state-of-the-art-pre-training-for-natural-language-processing/</li>
<li>[R] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding : r/MachineLearning - Reddit, https://www.reddit.com/r/MachineLearning/comments/9nfqxz/r_bert_pretraining_of_deep_bidirectional/</li>
<li>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding - ACL Anthology, https://aclanthology.org/N19-1423.pdf</li>
<li>Neural Ordinary Differential Equations, http://papers.neurips.cc/paper/7892-neural-ordinary-differential-equations.pdf</li>
<li>Augmented Neural ODEs, http://papers.neurips.cc/paper/8577-augmented-neural-odes.pdf</li>
<li>Dense Object Nets: Learning Dense Visual Object Descriptors By …, http://proceedings.mlr.press/v87/florence18a/florence18a.pdf</li>
<li>(PDF) QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation - ResearchGate, https://www.researchgate.net/publication/326029397_QT-Opt_Scalable_Deep_Reinforcement_Learning_for_Vision-Based_Robotic_Manipulation</li>
<li>Deep Drone Racing: Learning Agile Flight in Dynamic Environments, http://proceedings.mlr.press/v87/kaufmann18a/kaufmann18a.pdf</li>
<li>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | Request PDF - ResearchGate, https://www.researchgate.net/publication/328230984_BERT_Pre-training_of_Deep_Bidirectional_Transformers_for_Language_Understanding</li>
<li>Review — BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | by Sik-Ho Tsang, https://sh-tsang.medium.com/review-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-59b1684882db</li>
<li>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, https://blog.paperspace.com/bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding/</li>
<li>BERT (language model) - Wikipedia, https://en.wikipedia.org/wiki/BERT_(language_model)</li>
<li>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, https://research.google/pubs/bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding/</li>
<li>Neural Ordinary Differential Equations - NIPS, https://papers.nips.cc/paper/7892-neural-ordinary-differential-equations</li>
<li>[1806.07366] Neural Ordinary Differential Equations - arXiv, https://arxiv.org/abs/1806.07366</li>
<li>Journal Club: Chen et al, 2018: Neural Ordinary Differential Equations - - Thomas Harper -, https://authortomharper.com/2019/06/10/journal-club-chen-et-al-2018-neural-ordinary-differential-equations/</li>
<li>Allen School’s Yin Tat Lee earns Best Paper Award at NeurIPS 2018 for new algorithms for distributed optimization, https://news.cs.washington.edu/2018/12/06/allen-schools-yin-tat-lee-earns-best-paper-award-at-neurips-2018-for-new-algorithms-for-distributed-optimization/</li>
<li>Professor Shai Ben-David and colleagues win best paper award at NeurIPS 2018 | Artificial Intelligence Group | University of Waterloo, https://uwaterloo.ca/artificial-intelligence-group/news/professor-shai-ben-david-and-colleagues-win-best-paper-award</li>
<li>NeurIPS 2018 Best Paper Awards - YouTube, https://www.youtube.com/playlist?list=PLderfcX9H9MpTk97XztxGcZyEs4XB3vn8</li>
<li>Vector Researchers Win Top Honours at NeurIPS 2018, https://vectorinstitute.ai/vector-researchers-win-top-honours-at-neurips-2018/</li>
<li>[PDF] Neural Ordinary Differential Equations - Semantic Scholar, https://www.semanticscholar.org/paper/Neural-Ordinary-Differential-Equations-Chen-Rubanova/449310e3538b08b43227d660227dfd2875c3c3c1</li>
<li>CoRL 2018, https://2018.corl.org/</li>
<li>Learning Dense Visual Object Descriptors By and For Robotic Manipulation - Research, https://groups.csail.mit.edu/robotics-center/public_papers/Florence18a.pdf</li>
<li>Learning dense visual object descriptor by and for robotic manipulation, https://www.cs.utexas.edu/~yukez/cs391r_fall2021/slides/pre_09-21_Gabriel.pdf</li>
<li>Dense Object Nets and Descriptors for Robotic Manipulation - Seita’s Place, https://danieltakeshi.github.io/2019/11/09/paper-set-descriptors/</li>
<li>[1806.10293] QT-Opt: Scalable Deep Reinforcement Learning for …, https://ar5iv.labs.arxiv.org/html/1806.10293</li>
<li>QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation, https://www.pair.toronto.edu/csc2621-w20/assets/slides/lec5_qtopt.pdf</li>
<li>(PDF) Deep Drone Racing: Learning Agile Flight in Dynamic Environments - ResearchGate, https://www.researchgate.net/publication/325965662_Deep_Drone_Racing_Learning_Agile_Flight_in_Dynamic_Environments</li>
<li>Publications | Elia Kaufmann, https://kelia.github.io/publication/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>