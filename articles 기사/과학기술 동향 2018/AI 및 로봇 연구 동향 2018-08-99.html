<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2018년 8월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2018년 8월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2018년 AI 및 로봇 연구 동향</a> / <span>2018년 8월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2018년 8월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2018년, 딥러닝 패러다임의 성숙과 실세계 문제 해결을 위한 기반 구축</h2>
<p>2018년은 인공지능(AI) 분야, 특히 딥러닝 기술이 학문적 탐구를 넘어 산업 전반에 실질적인 영향력을 행사하기 시작한 변곡점으로 기록된다. 이 시기의 기술적 성숙은 Yoshua Bengio, Geoffrey Hinton, Yann LeCun이 딥러닝 분야의 개념적, 공학적 돌파구를 마련한 공로로 2018년 ACM A.M. 튜링상을 수상한 사실에서 상징적으로 드러난다.1 이들의 선구적인 연구는 컴퓨터 비전, 음성 인식, 자연어 처리(NLP), 로보틱스 등 광범위한 분야에서 후속 연구들이 놀라운 발전을 이루는 견고한 토대가 되었다.1</p>
<p>2018년 중반에 발표된 연구들은 특정 벤치마크에서 최고 성능(State-of-the-Art, SOTA)을 경신하는 경쟁을 넘어, AI 시스템의 <strong>강건성(Robustness)</strong>, <strong>샘플 효율성(Sample Efficiency)</strong>, <strong>해석 가능성(Interpretability)</strong>, 그리고 <strong>실세계 적용 가능성</strong>이라는 보다 근본적인 문제에 천착하기 시작했다. 이는 AI 기술이 통제된 실험실 환경을 벗어나 의료, 감시, 자율 시스템과 같은 복잡하고 예측 불가능한 실제 사회 문제에 적용되면서 마주하게 된 필연적인 도전 과제들을 반영하는 흐름이다.2</p>
<p>본 보고서는 2018년 8월을 전후하여 자연어 처리, 컴퓨터 비전, 로보틱스, 강화학습(RL) 분야의 핵심적인 연구 성과들을 심층적으로 분석한다. 각 분야의 개별적인 성취를 조명함과 동시에, 이들 연구가 어떻게 상호작용하며 AI 기술의 거대한 흐름을 형성했는지 그 연관성과 함의를 탐색하는 것을 목표로 한다. 보고서에서 다루는 주요 연구들은 당대 최고의 권위를 자랑하는 학회들에서 발표되었으며, 그 개요는 아래 표와 같다.</p>
<table><thead><tr><th>학회명 (약어)</th><th>전체 이름</th><th>개최 기간</th><th>개최지</th><th>주요 연구 분야</th></tr></thead><tbody>
<tr><td>ACL 2018</td><td>56th Annual Meeting of the Association for Computational Linguistics</td><td>2018년 7월 15-20일</td><td>호주, 멜버른</td><td>자연어 처리, 계산 언어학 4</td></tr>
<tr><td>COLING 2018</td><td>27th International Conference on Computational Linguistics</td><td>2018년 8월 20-26일</td><td>미국, 산타페</td><td>계산 언어학, 자연어 처리 6</td></tr>
<tr><td>ECCV 2018</td><td>15th European Conference on Computer Vision</td><td>2018년 9월 8-14일</td><td>독일, 뮌헨</td><td>컴퓨터 비전, 기계 학습 8</td></tr>
<tr><td>IROS 2018</td><td>IEEE/RSJ International Conference on Intelligent Robots and Systems</td><td>2018년 10월 1-5일</td><td>스페인, 마드리드</td><td>지능형 로봇, 자동화 시스템 10</td></tr>
</tbody></table>
<h2>2.  자연어 처리: 강건성과 제어 가능성을 향한 패러다임 전환</h2>
<p>2018년 자연어 처리 분야는 새로운 모델 아키텍처를 제안하는 단계를 넘어, 기존 연구 방법론의 한계를 성찰하고 모델의 신뢰성과 유용성을 높이는 방향으로 나아가는 질적 성숙을 보여주었다. 이는 AI를 단순한 성능 측정 도구가 아닌, 인간의 의도에 부합하고 실제 문제 해결에 기여할 수 있는 파트너로 만들려는 시도의 시작이었다.</p>
<h3>2.1  모델 평가와 강건성에 대한 자성적 고찰</h3>
<p>ACL 2018에서는 기존 모델의 성능을 맹신하기보다, 그 한계를 명확히 인식하고 평가 방법론 자체를 개선하려는 자성적 움직임이 두드러졌다.12 이는 NLP 연구 커뮤니티가 양적 성장을 넘어 질적 성숙의 단계로 접어들었음을 시사하는 중요한 변화였다.</p>
<p>Dror 등의 연구는 당시 NLP 논문들에서 통계적 유의성 검증이 무시되거나 오용되는 실태를 체계적으로 조사하고, 연구 결과의 신뢰성을 확보하기 위한 올바른 통계적 검증 프로토콜을 제안했다.12 또한, Finegan-Dollak 등은 Text-to-SQL 시스템 평가에 널리 사용되던 데이터셋의 학습-테스트 분할 방식과 변수 익명화 관행에 심각한 결함이 존재함을 지적했다. 이들은 이러한 결함이 모델의 실제 성능을 과대평가하게 만들 수 있음을 경고하며, 문제를 완화한 표준화된 데이터셋을 공개했다.12 이러한 연구들은 단순히 ’더 나은 모델’을 만드는 것을 넘어 ’신뢰할 수 있고, 검증 가능하며, 공정한 모델’을 만들고자 하는 방향으로 연구의 무게중심이 이동하고 있음을 명확히 보여주었다.</p>
<h3>2.2  알려진 지식으로부터의 탈피: ‘Authorless Topic Models’ 심층 분석</h3>
<p>COLING 2018에서 ’최우수 NLP 엔지니어링 실험상’을 수상한 “Authorless Topic Models: Biasing Models Away from Known Structure“는 비지도 학습 모델의 근본적인 한계에 대한 독창적인 해결책을 제시했다.13 기존의 토픽 모델은 데이터에서 가장 강력한 통계적 패턴을 학습하는데, 이 패턴이 저자의 문체나 문서 출처와 같은, 분석가가 이미 알고 있는 메타데이터인 경우가 많았다.15 결과적으로 모델은 여러 저자를 관통하는 미묘하고 새로운 주제적 연결을 발견하는 대신, 자명한 구조를 반복 학습하는 데 통계적 용량을 낭비하게 되는 문제가 발생했다.17</p>
<p>이 문제를 해결하기 위해 연구진은 메타데이터와 강하게 연관된 단어들을 사전에 식별하고, 이 단어들을 선택적으로 **확률적 서브샘플링(probabilistic subsampling)**하여 모델의 편향을 완화하는 방법론을 제안했다.15 이는 모델 훈련 이전에 입력 데이터를 변형하는 간단하면서도 매우 효과적인 접근법이다.16 토픽과 메타데이터 간의 상관관계를 정량적으로 측정하기 위해 **저자 엔트로피(Author Entropy)**를 포함한 세 가지 새로운 지표를 도입했으며, 실험 결과 제안된 방법론이 토픽-메타데이터 상관관계를 극적으로 감소시키고 토픽의 안정성을 향상시키는 동시에, 모델의 의미론적 품질(토픽 일관성)은 유지하거나 오히려 향상시키는 놀라운 결과를 보였다.17 이 연구는 비지도 학습 모델의 출력을 사용자의 분석 목표에 맞게 ’제어’하고, 모델이 자명한 패턴이 아닌 새롭고 유용한 통찰을 발견하도록 유도하는 방법론의 중요성을 부각시킨 선구적인 사례로 평가된다.</p>
<h3>2.3  지식 구축의 가속화: 대화형 주석 플랫폼 ‘INCEpTION’</h3>
<p>NLP 기술 발전의 근본적인 병목 현상 중 하나는 고품질의 대규모 주석 데이터셋을 구축하는 데 드는 막대한 비용과 시간이다. COLING 2018 시스템 데모 세션에서 발표된 ‘INCEpTION’ 플랫폼은 이 문제를 정면으로 다루는 차세대 주석 도구이다.7</p>
<p>INCEpTION은 단순한 주석 도구를 넘어, 인간과 기계가 협력하여 지식을 구축하는 통합 환경을 제공한다. 핵심 기능은 다음과 같다.</p>
<ul>
<li>
<p><strong>주석 지원(Annotation Assistance):</strong> 기계학습 기반의 ’추천기(Recommenders)’가 문맥을 분석하여 가능한 주석 레이블을 능동적으로 제안함으로써 주석가의 작업을 돕고 전체 효율을 극대화한다.7</p>
</li>
<li>
<p><strong>능동 학습(Active Learning):</strong> 불확실성 샘플링(uncertainty sampling)과 같은 전략을 통해, 시스템은 현재 모델이 가장 헷갈려하는 데이터에 대해 주석가의 피드백을 요청한다. 이는 최소한의 노력으로 모델 성능을 가장 빠르게 개선하도록 유도한다.7</p>
</li>
<li>
<p><strong>지식 관리(Knowledge Management):</strong> Wikidata, DBPedia와 같은 대규모 외부 지식베이스(KB)와의 연동은 물론, 특정 도메인에 특화된 지식베이스를 플랫폼 내에서 직접 생성하고 확장, 관리하는 기능을 완벽하게 통합했다.7</p>
</li>
</ul>
<p>INCEpTION은 인간의 전문 지식과 기계의 학습 능력을 결합하는 ‘Human-in-the-loop’ 패러다임의 성공적인 구현 사례이다. 이는 AI를 정답을 출력하는 블랙박스로 취급하는 관점에서 벗어나, 인간과 상호작용하며 함께 성장하는 협력적 파트너로 인식하기 시작했음을 보여주는 중요한 기술적 진보다.</p>
<h2>3.  컴퓨터 비전: 3차원 공간과 다중 양상으로의 감각 확장</h2>
<p>2018년 컴퓨터 비전 분야는 2차원 이미지 인식의 한계를 넘어, 인간이 세상을 인지하는 방식과 유사하게 3차원 공간을 이해하고 다양한 감각 정보를 통합하려는 노력을 본격화했다. 이는 AI가 가상 세계의 패턴 인식을 넘어 물리 세계와 상호작용하는 단계로 나아가기 위한 필연적인 과정이었다.</p>
<h3>3.1  정규 격자를 넘어서: 3D 포인트 클라우드를 위한 ‘SpiderCNN’</h3>
<p>전통적인 컨볼루션 신경망(CNN)은 픽셀이 규칙적인 격자 형태로 배열된 2D 이미지 처리에 최적화되어 있다. 이로 인해 자율주행 라이다(LiDAR) 센서나 3D 스캐너로부터 얻어지는 3D 포인트 클라우드와 같이 불규칙한 구조를 가진 데이터에는 직접 적용하기 어려웠다. ECCV 2018에서 발표된 ’SpiderCNN’은 이 근본적인 한계를 극복하기 위한 혁신적인 컨볼루션 아키텍처를 제안했다.19</p>
<p>SpiderCNN의 핵심은 ’SpiderConv’라 불리는 새로운 컨볼루션 연산이다. 이는 불규칙한 포인트 셋에 적용할 수 있도록 <strong>매개변수화된 컨볼루션 필터(parameterized convolutional filters)</strong> 계열을 학습한다. 이 필터는 점들 사이의 국소적 측지 거리(geodesic distance) 정보를 포착하는 계단 함수와 필터의 표현력을 보장하는 테일러 다항식의 곱으로 정교하게 설계되었다.19 SpiderCNN은 고전적인 CNN의 다중 스케일 계층 구조를 계승하여 점 집합으로부터 깊은 의미론적 특징을 효과적으로 추출할 수 있다. 그 결과, 3D 객체 분류 벤치마크인 ModelNet40에서 당시 최고 수준의 정확도(92.4%)를 달성하며 그 성능을 입증했다.19 이 연구는 3D 데이터 처리가 필수적인 자율주행, 로보틱스, 증강현실(AR) 분야에서 딥러닝의 적용 범위를 크게 확장하는 중요한 기술적 이정표가 되었다.</p>
<h3>3.2  이종 감각의 융합: 다층적 멀티모달 융합 ‘CentralNet’</h3>
<p>인간은 시각, 청각, 촉각 등 여러 감각 정보를 통합하여 주변 환경을 종합적으로 이해한다. 이와 유사하게, AI 시스템의 인지 능력을 향상시키기 위해 여러 종류의 데이터를 함께 사용하는 멀티모달 융합(multimodal fusion)은 매우 중요한 연구 주제이다. 2018년 8월 arXiv에 공개된 “CentralNet: a Multilayer Approach for Multimodal Fusion“은 이 문제에 대한 새로운 해법을 제시했다.20</p>
<p>CentralNet은 각 데이터 양상(modality, 예: 이미지, 오디오)을 처리하는 개별 딥러닝 네트워크들을 유기적으로 연결하는 **중앙 네트워크(Central Network)**를 도입한 독창적인 아키텍처를 제안했다. 중앙 네트워크의 각 계층은 이전 중앙 계층의 출력과 각 양상별 네트워크 계층의 출력에 학습 가능한 가중치를 곱해 합산한 값을 입력으로 받는다. <code>i</code>번째 계층에서의 중앙 은닉 표현 <span class="math math-inline">h_C^{i+1}</span>은 다음과 같이 계산된다.20</p>
<p><span class="math math-display">
h_{C}^{i+1} = \alpha_C^i h_{C}^i + \sum_{k=1}^{n} \alpha_{M_k}^i h_{M_k}^i
</span><br />
여기서 <span class="math math-inline">h_{M_k}^i</span>는 <code>k</code>번째 양상 네트워크의 <code>i</code>번째 은닉 표현이며, <span class="math math-inline">\alpha</span>들은 학습 가능한 가중치이다. 특히, 전체 손실 함수를 중앙 네트워크의 손실과 각 개별 양상 네트워크의 손실의 합으로 구성함으로써, 각 네트워크가 서로의 학습을 보완하고 정규화하는 <strong>멀티태스크 학습(Multi-task learning)</strong> 효과를 유도했다.20 이 접근법은 정보를 어느 계층에서 융합할지를 수동으로 결정해야 했던 기존 방식(초기 융합, 후기 융합)과 달리, 모델이 데이터로부터 최적의 융합 전략을 스스로 학습하게 한다. 실험 결과, CentralNet은 4개의 서로 다른 멀티모달 컴퓨터 비전 데이터셋에서 기존 접근법들보다 일관되게 높은 정확도를 보이며 그 우수성을 증명했다.20</p>
<h3>3.3  주의 집중과 효율성의 진화</h3>
<p>ECCV 2018에서는 제한된 계산 자원 내에서 모델의 성능을 극대화하려는 연구들이 다수 발표되었다. 대표적으로 ’CBAM(Convolutional Block Attention Module)’은 특징 맵(feature map)의 공간적, 채널적 중요도를 학습하여 모델이 ‘어디를’ 그리고 ‘무엇을’ 더 집중해서 봐야 할지를 결정하게 하는 주의 집중(Attention) 메커니즘을 제안했다.21 이는 모델의 효율성과 해석 가능성을 동시에 높이는 중요한 연구 방향으로 자리 잡았다. 이 외에도 인스턴스 분할(Instance Segmentation), 단안 깊이 추정(Monocular Depth Estimation), 비디오 객체 분할(Video Object Segmentation) 등 다양한 고전적 비전 문제에 딥러닝을 성공적으로 적용하여 성능을 한 단계 끌어올린 연구들이 발표되었다.21</p>
<h2>4.  로보틱스: 동적 환경에서의 강건한 자율성 확보</h2>
<p>2018년 로보틱스 분야는 정적인 환경에서의 정밀한 작업을 넘어, 예측 불가능하고 동적인 실제 환경에서 강건하게 임무를 수행할 수 있는 자율성을 확보하는 데 중요한 진전을 이루었다. 특히, 정교한 모델링과 빠른 실시간 최적화를 결합한 제어 전략의 성공은 로봇이 물리적 한계를 뛰어넘을 수 있는 새로운 가능성을 열었다.</p>
<h3>4.1  MIT Cheetah 3의 동적 보행 제어 심층 분석</h3>
<p>IROS 2018에서 발표된 “Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control“은 사족보행 로봇 제어 분야의 기념비적인 연구로 평가받는다.22 이 연구는 MIT Cheetah 3 로봇이 다양한 지형에서 놀라운 속도와 안정성으로 움직일 수 있게 한 핵심 제어 기술을 상세히 소개했다.</p>
<p>이 연구의 성공 비결은 전통적인 로봇 제어의 패러다임을 전환한 데 있다. 기존 접근법이 로봇의 복잡한 동역학을 최대한 정확하게 모델링하는 데 집중했던 반면, 이 연구는 과감하게 모델을 **단일 강체(single rigid body)**로 단순화했다. Cheetah 3의 다리 질량이 전체 로봇 질량의 약 10%에 불과했기에 이러한 근사화는 합리적이었다.25 이 단순화된 모델을 기반으로, 미래의 짧은 시간(최대 0.5초) 동안의 최적 지면 반발력을 계산하는 문제를</p>
<p><strong>볼록 최적화(convex optimization)</strong> 문제로 공식화했다.26 볼록 최적화는 해의 전역 최적성을 보장하며 매우 빠르게 계산할 수 있다는 결정적인 장점을 가진다. 실제로 Cheetah 3의 온보드 컴퓨터는 20-30Hz의 빠른 주기로, 매번</p>
<p><strong>1ms 이내</strong>에 이 최적화 문제를 풀어 새로운 제어 명령을 생성했다.25 이처럼 빠른 주기로 계획을 계속해서 수정(re-plan)함으로써, 단순화된 모델에서 발생하는 오차를 실시간 피드백으로 계속 보정할 수 있었다. 이는 동적이고 불확실한 환경에서는 정교하지만 느린 계획보다, 다소 부정확하더라도 신속한 재계획이 훨씬 효과적일 수 있다는 중요한 제어 철학을 증명한 것이다.</p>
<p>이러한 접근법의 결과는 놀라웠다. Cheetah 3는 동일한 제어기 파라미터를 사용하여 Trot, Gallop, Bound, Pace 등 매우 다양한 보행을 안정적으로 구현했다.23 최대 전진 속도 3 m/s, 최대 각속도 180 deg/sec라는, 당시 전기 모터 기반 사족보행 로봇 중 최고 수준의 동적 성능을 선보였다.23 더 나아가, 별도의 시각 센서 없이 로봇 내부의 관성측정장치(IMU)와 모터 정보만을 이용하여 예상치 못한 지형(예: 장애물이 놓인 계단)을 성공적으로 오르는 ’맹목적 보행(blind locomotion)’을 시연함으로써 제어기의 뛰어난 강건성을 입증했다.28 이 성공은 MPC라는 소프트웨어 알고리즘뿐만 아니라, 낮은 관성의 다리, 높은 토크 밀도의 모터, 그리고 별도의 힘 센서 없이 모터 전류만으로 지면 반발력을 제어하는 ’고유수용성 작동(proprioceptive actuation)’과 같은 맞춤형 기계 설계가 결합된 결과였다.28 이는 최첨단 로봇 시스템의 발전이 소프트웨어 혁신과 이를 뒷받침하는 하드웨어 발전의 시너지를 통해 이루어짐을 명확히 보여준다.</p>
<h3>4.2  인간 사회와의 공존을 위한 로봇 기술</h3>
<p>IROS 2018에서는 Cheetah 3와 같이 극한 환경에서의 성능을 목표로 하는 연구 외에도, 인간의 일상 환경과 상호작용하며 도움을 주는 다양한 로봇 기술들이 발표되었다. 경도인지장애(MCI) 환자의 일상을 돕는 서비스 로봇 ‘RAMCIP’, 온실의 작물 관리를 자동화하는 로봇, 레스토랑에서 음료를 운반하는 웨이터 로봇 등 특정 사회적 요구에 대응하는 응용 시스템들이 소개되었다.22 또한, 인간과 로봇이 안전하게 공존하기 위한 기술, 예를 들어 자원이 제한된 소형 로봇을 위한 경량 충돌 회피 알고리즘이나 협동 로봇을 이용한 의료 진단 보조 시스템 등도 중요한 연구 주제로 다루어졌다.22 이는 로봇 기술이 인간 사회에 통합되기 위해 해결해야 할 다양한 공학적, 사회적 과제에 대한 연구 커뮤니티의 깊은 고민을 보여준다.</p>
<h2>5.  강화학습: 샘플 효율성과 안정성의 돌파구 마련</h2>
<p>강화학습은 시행착오를 통해 최적의 행동 전략을 학습하는 강력한 패러다임이지만, 실제 물리 시스템에 적용하기에는 두 가지 큰 장벽이 존재했다. 첫째는 학습에 막대한 양의 데이터가 필요한 **높은 샘플 복잡도(high sample complexity)**이고, 둘째는 학습 과정이 하이퍼파라미터에 매우 민감하고 불안정한 **취약한 수렴성(brittle convergence)**이다. 2018년 1월 처음 공개되고 8월에 개정판이 발표된 “Soft Actor-Critic(SAC)” 알고리즘은 이 오랜 난제들을 해결할 중요한 돌파구를 제시했다.29</p>
<h3>5.1  최대 엔트로피 강화학습의 이정표: ‘Soft Actor-Critic(SAC)’</h3>
<p>SAC의 성공은 세 가지 핵심 요소를 독창적으로 결합한 데 있다.30</p>
<ol>
<li>
<p><strong>오프-폴리시(Off-Policy) 학습:</strong> 과거에 수집된 데이터를 리플레이 버퍼에 저장하고 반복적으로 재사용함으로써 데이터 효율성을 극적으로 향상시켰다. 이는 실제 로봇과 같이 데이터 수집 비용이 매우 비싼 환경에서 강화학습을 적용하는 데 있어 필수적인 요소이다.</p>
</li>
<li>
<p><strong>액터-크리틱(Actor-Critic) 구조:</strong> 정책을 나타내는 ‘액터’ 네트워크와 해당 정책의 가치를 평가하는 ‘크리틱’ 네트워크를 분리하여 학습함으로써, 학습 과정의 안정성을 높이고 분산을 줄였다.</p>
</li>
<li>
<p><strong>최대 엔트로피(Maximum Entropy) 프레임워크:</strong> SAC의 가장 핵심적인 혁신은 강화학습의 목표 함수 자체를 재정의한 것이다. 전통적인 강화학습이 누적 보상만을 최대화하려 했다면, SAC는 누적 보상과 함께 정책의 엔트로피(무작위성)도 동시에 최대화하는 것을 목표로 한다. 이는 “주어진 과업을 성공적으로 수행하면서, 동시에 가능한 한 무작위적으로 행동하라“는 직관적인 목표를 수학적으로 공식화한 것이다.29 이 최대 엔트로피 원칙은 에이전트가 섣불리 하나의 전략에 수렴하여 지역 최적해(local optimum)에 빠지는 것을 방지하고, 지속적인 탐험(exploration)을 장려하여 궁극적으로 더 강건하고 우수한 정책을 찾도록 돕는다.29</p>
</li>
</ol>
<p>이러한 아이디어는 다음과 같은 핵심 수식으로 구체화된다. 먼저, 목표 함수 <span class="math math-inline">J(\pi)</span>는 표준 보상 항에 엔트로피 항 <span class="math math-inline">\mathcal{H}</span>가 추가된 형태로 정의된다.30</p>
<p><span class="math math-display">
J(\pi) = \sum_{t=0}^{T} \mathbb{E}_{(s_t, a_t) \sim \rho_\pi} [r(s_t, a_t) + \alpha \mathcal{H}(\pi(\cdot\vert s_t))]
</span><br />
여기서 <span class="math math-inline">\alpha</span>는 엔트로피의 상대적 중요도를 조절하는 온도 파라미터이다. 이 새로운 목표 함수에 따라, 가치 함수인 소프트 Q-함수 <span class="math math-inline">Q_\theta(s_t, a_t)</span>는 수정된 벨만 방정식을 만족하도록 학습되며, 정책 <span class="math math-inline">\pi_\phi</span>는 현재의 소프트 Q-값을 최대화하는 방향, 즉 아래의 KL-발산(KL-divergence)을 최소화하는 방향으로 업데이트된다.30</p>
<p><span class="math math-display">
J_\pi(\phi) = \mathbb{E}_{s_t \sim \mathcal{D}} \left[ D_{KL} \left( \pi_\phi(\cdot|s_t) \parallel \frac{\exp(Q_\theta(s_t, \cdot))}{Z_\theta(s_t)} \right) \right]
</span><br />
SAC는 다양한 연속 제어 벤치마크 환경에서 기존의 온-폴리시 및 오프-폴리시 알고리즘들을 성능과 샘플 효율성 측면에서 모두 압도하며 당시 최고 수준의 결과를 달성했다.32 SAC의 등장은 단순히 더 나은 알고리즘의 탄생을 넘어, 강화학습을 시뮬레이션을 넘어 실제 로봇과 같은 물리 시스템에 적용할 수 있는 가능성을 연 중요한 기술적 변곡점으로 평가된다.</p>
<h2>6. 결론: 2018년 연구 성과의 종합적 의의와 미래 전망</h2>
<p>2018년 8월을 기점으로 발표된 AI 및 로봇 분야의 연구들은 각자의 영역에서 중요한 기술적 진전을 이루었을 뿐만 아니라, 분야 간 융합을 통해 미래 AI 기술의 발전 방향을 제시하는 중요한 이정표를 세웠다.</p>
<p>각 분야의 성과를 요약하면, NLP는 모델의 성능을 넘어 신뢰성과 제어 가능성이라는 질적 성숙을 추구하기 시작했다. 컴퓨터 비전은 2D 이미지의 한계를 넘어 3D 공간과 다중 양상으로 인식의 범위를 확장했다. 로보틱스는 과감한 모델 단순화와 빠른 실시간 최적화라는 새로운 제어 패러다임을 통해 동적 환경에서의 강건성을 확보했다. 마지막으로 강화학습은 샘플 효율성과 안정성이라는 오랜 난제를 해결할 결정적인 실마리를 제공했다.</p>
<p>이러한 각 분야의 발전은 독립적이지 않고 서로 밀접하게 연결되어 있다. Cheetah 3와 같은 로봇이 더 복잡한 비정형 환경을 자율적으로 탐색하기 위해서는 SpiderCNN과 같은 3D 비전 기술이 필수적이다. SAC와 같이 샘플 효율적이고 안정적인 강화학습 알고리즘은 로봇이 시뮬레이션이 아닌 실제 환경에서 직접 시행착오를 통해 더욱 정교한 기술을 학습하는 것을 가능하게 할 것이다. 또한, INCEpTION과 같은 도구를 통해 구축된 방대한 지식베이스는 로봇이나 대화형 AI가 세상에 대한 상식적 이해를 갖추고 인간과 더 원활하게 상호작용하는 데 핵심적인 역할을 할 수 있다. 이처럼 2018년의 연구들은 AI의 각 하위 분야들이 성숙하며 서로의 발전을 촉진하는 <strong>기술적 선순환 구조</strong>의 기반을 다진 시기로 평가할 수 있다.</p>
<p>2018년에 제시된 개념들은 이후 AI 기술의 폭발적인 성장을 예고했다. SAC의 안정적인 학습 프레임워크는 훗날 거대 언어 모델(LLM)을 인간의 피드백으로 정교하게 튜닝하는 RLHF(Reinforcement Learning from Human Feedback)의 중요한 사상적 기반 중 하나가 되었다. 강건하고 제어 가능한 NLP 모델에 대한 고민은 AI 윤리와 편향성 문제에 대한 심도 깊은 논의로 이어졌다. 3D 비전과 동적 로봇 제어 기술은 오늘날 자율주행차와 차세대 서비스 로봇의 핵심 기술로 발전하고 있다. 결론적으로 2018년은 AI가 순수한 가능성의 시대를 지나 실용성과 책임의 시대로 나아가는 중요한 전환점이었음을 알 수 있다.</p>
<table><thead><tr><th>알고리즘/시스템</th><th>핵심 분야</th><th>해결 문제</th><th>제안 방법론</th><th>주요 기여 및 의의</th></tr></thead><tbody>
<tr><td><strong>Soft Actor-Critic (SAC)</strong> 29</td><td>강화학습</td><td>높은 샘플 복잡도 및 학습 불안정성</td><td>오프-폴리시 액터-크리틱 + 최대 엔트로피 프레임워크</td><td>샘플 효율성과 안정성을 획기적으로 개선하여 강화학습의 실용화 가능성을 제시함.</td></tr>
<tr><td><strong>Cheetah 3 MPC</strong> 23</td><td>로보틱스</td><td>동적 환경에서의 강건한 고속 보행</td><td>단일 강체 모델 기반 볼록 모델 예측 제어(Convex MPC)</td><td>과감한 모델 단순화와 초고속 실시간 최적화를 통해 동적 로봇 제어의 새로운 패러다임을 정립함.</td></tr>
<tr><td><strong>SpiderCNN</strong> 19</td><td>컴퓨터 비전</td><td>3D 포인트 클라우드 등 불규칙 데이터 처리</td><td>매개변수화된 컨볼루션 필터 ‘SpiderConv’</td><td>딥러닝의 적용 범위를 3D 공간으로 확장하여 자율주행, 로보틱스 분야의 발전을 촉진함.</td></tr>
<tr><td><strong>Authorless Topic Models</strong> 15</td><td>자연어 처리</td><td>비지도 학습 모델이 자명한 메타데이터를 학습하는 문제</td><td>메타데이터 연관 단어의 확률적 서브샘플링</td><td>모델이 유용하고 새로운 통찰을 발견하도록 유도하는 ‘제어 가능한’ 비지도 학습의 가능성을 보임.</td></tr>
<tr><td><strong>CentralNet</strong> 20</td><td>컴퓨터 비전</td><td>다중 양상(Multi-modal) 데이터의 효과적 융합</td><td>중앙 네트워크와 멀티태스크 학습 기반의 다층 융합</td><td>최적의 융합 전략을 데이터로부터 자동 학습하여 멀티모달 인식 성능을 향상시킴.</td></tr>
<tr><td><strong>INCEpTION Platform</strong> 7</td><td>자연어 처리</td><td>고품질 주석 데이터셋 구축의 병목 현상</td><td>기계학습 기반 추천기 및 능동 학습(Active Learning)</td><td>인간-기계 협업(Human-in-the-loop)을 통해 지식 구축을 가속화하는 플랫폼을 제시함.</td></tr>
</tbody></table>
<h2>7. 참고 자료</h2>
<ol>
<li>2018 Turing Award - ACM Awards, https://awards.acm.org/about/2018-turing</li>
<li>Transformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Ethical Landscape and Public Perspectives - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC10815906/</li>
<li>AI Now Report 2018, https://ainowinstitute.org/wp-content/uploads/2023/04/AI_Now_2018_Report.pdf</li>
<li>acl 2018: ACL - researchr conference, https://researchr.org/conference/acl-2018</li>
<li>ACL 2018: About, https://acl2018.org/</li>
<li>COLING 2018 The 27th International Conference on Computational Linguistics Proceedings of the Conference August 20-26, 2018 Santa Fe, New Mexico, USA, https://aclanthology.org/C18-1000.pdf</li>
<li>Proceedings of COLING 2018 - INCEpTION, https://inception-project.github.io/publications/INCEpTION-COLING2018-Demo.pdf</li>
<li>Computer Vision – ECCV 2018 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part VIII - ResearchGate, https://www.researchgate.net/publication/345574969_Computer_Vision_-_ECCV_2018_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_VIII_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_VIII</li>
<li>ECCV 2018 // September 8 - 14 2018 // Munich, Germany, https://eccv2018.org/</li>
<li>INTELLIGENT ROBOTS AND SYSTEMS. IEEE/RSJ INTERNATIONAL CONFERENCE. 2018. (IROS 2018) (13 VOLS) - proceedings.com, https://www.proceedings.com/42518.html</li>
<li>IROS 2018 - International Conference on Intelligent Robots - Madrid, https://www.iros2018.org/</li>
<li>ACL 2018 Highlights: Understanding Representations - ruder.io, https://www.ruder.io/acl-2018-highlights/</li>
<li>COLING 2018 Best papers | COLING 2018, https://coling2018.org/index.html%3Fp=1558.html</li>
<li>Laure Thompson - CDH@Princeton, https://cdh.princeton.edu/people/laure-thompson/</li>
<li>Authorless Topic Models: Biasing Models Away from Known Structure (Conference Paper), https://par.nsf.gov/biblio/10092208-authorless-topic-models-biasing-models-away-from-known-structure</li>
<li>Publications - David Mimno, https://mimno.infosci.cornell.edu/publications.html</li>
<li>Authorless Topic Models: Biasing Models Away from Known …, https://aclanthology.org/C18-1329/</li>
<li>Authorless Topic Models: Biasing Models Away from Known Structure - Semantic Scholar, https://www.semanticscholar.org/paper/Authorless-Topic-Models%3A-Biasing-Models-Away-from-Thompson-Mimno/ed253887c1a5c5883e742e22190d422696d56131</li>
<li>ECCV 2018 Open Access Repository - The Computer Vision Foundation, https://openaccess.thecvf.com/content_ECCV_2018/html/Yifan_Xu_SpiderCNN_Deep_Learning_ECCV_2018_paper.html</li>
<li>CentralNet: a Multilayer Approach for Multimodal Fusion, https://arxiv.org/abs/1808.07275</li>
<li>ECCV 2018 Open Access Repository, https://openaccess.thecvf.com/ECCV2018</li>
<li>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2018, Madrid, Spain, October 1-5, 2018 - researchr publication, https://researchr.org/publication/iros-2018</li>
<li>Dynamic Locomotion in The MIT Cheetah 3 Through Convex Model-Predictive Control | PDF, https://www.scribd.com/document/891748727/Dynamic-Locomotion-in-the-MIT-Cheetah-3-Through-Convex-Model-Predictive-Control</li>
<li>Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control, https://biomimetics.mit.edu/publications/e9ca891c-35de-4be5-896c-780feae67fd4/</li>
<li>Dynamic Locomotion in the MIT Cheetah 3 Through … - DSpace@MIT, https://dspace.mit.edu/bitstream/handle/1721.1/138000/convex_mpc_2fix.pdf</li>
<li>Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control | Request PDF - ResearchGate, https://www.researchgate.net/publication/356295502_Dynamic_Locomotion_in_the_MIT_Cheetah_3_Through_Convex_Model-Predictive_Control</li>
<li>Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control, https://www.researchgate.net/publication/330591547_Dynamic_Locomotion_in_the_MIT_Cheetah_3_Through_Convex_Model-Predictive_Control</li>
<li>MIT Open Access Articles MIT Cheetah 3: Design and Control of a Robust, Dynamic Quadruped Robot, https://dspace.mit.edu/bitstream/handle/1721.1/126619/iros.pdf?sequence=2</li>
<li>Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor - arXiv, https://arxiv.org/abs/1801.01290</li>
<li>Soft Actor-Critic: Off-Policy Maximum Entropy Deep … - Emberpulse, https://emberpulse.com/wp-content/uploads/2023/04/1801.01290-1.pdf</li>
<li>Soft Actor-Critic:, https://ics.uci.edu/~dechter/courses/ics-295/winter-2018/papers/nips/soft-actor-critic-nips-2017.pdf</li>
<li>[1801.01290] Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor - ar5iv, https://ar5iv.labs.arxiv.org/html/1801.01290</li>
<li>Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor | Request PDF - ResearchGate, https://www.researchgate.net/publication/322306636_Soft_Actor-Critic_Off-Policy_Maximum_Entropy_Deep_Reinforcement_Learning_with_a_Stochastic_Actor</li>
<li>[PDF] Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor | Semantic Scholar, https://www.semanticscholar.org/paper/Soft-Actor-Critic%3A-Off-Policy-Maximum-Entropy-Deep-Haarnoja-Zhou/811df72e210e20de99719539505da54762a11c6d</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>