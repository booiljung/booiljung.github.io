<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2018년 10월 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2018년 10월 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2018년 AI 및 로봇 연구 동향</a> / <span>2018년 10월 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2018년 10월 AI 및 로봇 연구 동향</h1>
<h2>1. 서론</h2>
<p>2018년 10월은 인공지능(AI), 특히 자연어 처리(NLP)와 구조적 추론 분야에서 패러다임의 전환이 일어난 결정적인 시기로 기록된다. 이 시기는 단순히 몇 가지 개별 기술의 등장을 넘어, 연구 방법론, 모델 아키텍처, 그리고 응용 분야의 지형을 근본적으로 바꾼 변곡점이었다. Google의 BERT 모델이 제시한 양방향 사전 훈련의 혁신은 자연어 이해의 새로운 지평을 열었고, DeepMind가 제안한 그래프 네트워크 프레임워크는 관계형 데이터에 대한 딥러닝의 접근법을 일반화했다. 동시에, 로봇 공학 분야의 최고 권위 학회인 IROS 2018에서는 로봇이 현실 세계의 복잡한 문제들을 해결하기 위한 실용적 기술들이 심도 있게 논의되었으며, MIT CSAIL에서는 AI 기술을 과학적 발견과 사회적 책임의 영역으로 확장하려는 의미 있는 시도들이 발표되었다.</p>
<p>본 보고서는 2018년 10월에 집중적으로 발표된 이들 핵심 연구의 기술적 세부 사항과 그 의의를 심층적으로 분석한다. 각 기술의 핵심 개념, 방법론, 그리고 주요 성과를 면밀히 검토하고, 이들이 서로에게 미친 영향과 후속 연구에 남긴 지적 유산을 추적하고자 한다. 이를 통해 2018년 10월이라는 특정 시점이 어떻게 현재 AI 기술 지형의 토대를 마련했는지에 대한 종합적인 기술사적 지도를 그리는 것을 목표로 한다.</p>
<h2>2.  자연어 처리의 패러다임 전환: BERT의 등장</h2>
<h3>2.1  연구 배경: 단방향 언어 모델의 본질적 한계</h3>
<p>BERT(Bidirectional Encoder Representations from Transformers)의 등장 이전, 자연어 처리 분야는 OpenAI의 GPT(Generative Pre-trained Transformer)와 같은 모델들이 주도하고 있었다. 이러한 모델들은 문장을 왼쪽에서 오른쪽(left-to-right) 또는 오른쪽에서 왼쪽(right-to-left)으로 순차적으로 처리하는 단방향(unidirectional) 구조를 채택했다. 이 방식은 다음 단어를 예측하며 문장을 생성하는 과제에는 효과적이었으나, 문장 전체의 깊은 양방향 문맥을 종합적으로 이해해야 하는 과제, 예를 들어 질의응답(Question Answering)이나 문장 분류(Sentence Classification) 등에서는 본질적인 한계를 드러냈다. 특정 단어의 의미를 파악하기 위해 그 단어의 앞뒤에 위치한 모든 단어의 정보를 동시에 활용할 수 없었기 때문이다. 이러한 한계를 극복하고자 Google AI 연구팀은 ‘깊은 양방향(deeply bidirectional)’ 표현 자체를 사전 훈련(pre-training) 단계에서부터 학습하는 것을 새로운 목표로 설정했다.1</p>
<h3>2.2  아키텍처: 트랜스포머의 인코더를 채택하다</h3>
<p>BERT는 Vaswani 등이 2017년에 제안한 트랜스포머(Transformer) 아키텍처를 기반으로 한다. 하지만 트랜스포머의 인코더-디코더 구조를 모두 사용하는 대신, 오직 인코더(Encoder) 블록만을 여러 층으로 쌓아 올린 구조를 채택했다.1 이는 트랜스포머의 핵심 메커니즘인 셀프 어텐션(Self-Attention)을 극대화하기 위한 전략적 선택이었다. 셀프 어텐션은 문장 내 모든 단어 쌍 간의 관계를 동시에 계산하여 문맥적 표현을 생성하므로, 양방향 정보 처리에 본질적으로 최적화되어 있다. BERT는 디코더 부분을 의도적으로 배제함으로써, 문장 생성보다는 문장의 의미를 깊이 있게 ’이해(understanding)’하는 데 모든 모델 용량을 집중시켰고, 이는 BERT의 핵심적인 정체성이 되었다.</p>
<h3>2.3  핵심 방법론: 양방향 사전 훈련</h3>
<p>BERT의 진정한 혁신은 아키텍처 자체보다 독창적인 ’사전 훈련 방식’에 있었다. 2018년 10월 11일 arXiv에 처음 논문이 제출된 이후 1, BERT가 제안한 두 가지 자기지도학습(self-supervised learning) 과제는 NLP 연구의 흐름을 완전히 바꾸어 놓았다.</p>
<h4>2.3.1  마스크 언어 모델 (Masked Language Model, MLM)</h4>
<p>진정한 양방향 모델을 훈련시키는 데에는 미묘한 문제가 존재한다. 만약 모델이 예측해야 할 단어 <span class="math math-inline">w_i</span>를 포함한 전체 문장 <span class="math math-inline">w_1,..., w_n</span>을 입력으로 받는다면, 모델은 정답을 이미 알고 있으므로 의미 있는 학습이 불가능하다. BERT는 이 문제를 해결하기 위해 ’마스크 언어 모델(MLM)’이라는 기법을 도입했다. 입력 시퀀스에서 무작위로 15%의 토큰을 선택한 뒤, 이를 <code>라는 특수한 토큰으로 치환한다. 그리고 모델의 목표는 이</code> 된 위치의 원래 토큰이 무엇이었는지를 주변의 모든 문맥(왼쪽과 오른쪽 모두)을 이용하여 예측하는 것이다.1 이는 마치 ‘빈칸 채우기(cloze task)’ 문제와 유사하며, 모델이 단어 수준에서 깊은 양방향 문맥을 학습하도록 강제하는 매우 효과적인 방법이었다.</p>
<h4>2.3.2  다음 문장 예측 (Next Sentence Prediction, NSP)</h4>
<p>MLM이 단어 수준의 문맥 이해를 목표로 했다면, ’다음 문장 예측(NSP)’은 문장 간의 관계를 이해하는 능력을 모델에 부여하기 위해 설계되었다. 사전 훈련 단계에서 모델은 두 개의 문장 A와 B를 입력으로 받는다. 이때 50%의 확률로 문장 B는 실제 문장 A의 바로 다음 문장(<code>IsNext</code>)이고, 나머지 50%의 확률로는 코퍼스에서 무작위로 추출된 관련 없는 문장(<code>NotNext</code>)이다. 모델은 이 두 문장의 관계가 <code>IsNext</code>인지 <code>NotNext</code>인지를 맞추는 이진 분류(binary classification) 문제를 풀게 된다.1 이 훈련을 통해 BERT는 질의응답이나 자연어 추론(Natural Language Inference)과 같이 두 텍스트 간의 논리적 관계 파악이 중요한 다운스트림 태스크에서 뛰어난 성능을 발휘할 수 있는 기반을 마련했다. 이러한 대규모 사전 훈련을 위해, BERT는 Toronto BookCorpus(약 8억 단어)와 영문 위키피디아(약 25억 단어)라는 방대한 텍스트 데이터를 사용했다.1</p>
<h3>2.4  주요 성과 및 기술적 의의</h3>
<p>BERT는 발표와 동시에 11개의 주요 자연어 이해(NLU) 벤치마크에서 기존 최고 성능(State-of-the-Art, SOTA)을 모두 경신하는 압도적인 결과를 보여주었다.1 이는 대규모 데이터로 사전 훈련된 거대 모델을 특정 하위 작업에 맞게 미세 조정(fine-tuning)하는 전이 학습(transfer learning) 패러다임의 위력을 명확히 입증한 사건이었다. 이로 인해 NLP 연구의 표준은 ‘각 태스크를 위한 모델을 처음부터 설계하고 훈련하는’ 방식에서 ‘강력한 사전 훈련 모델을 가져와 특정 문제에 맞게 조정하는’ 방식으로 급격히 전환되었다.</p>
<p>Google은 2018년 11월 2일, BERT 모델의 코드와 사전 훈련된 가중치를 오픈소스로 공개하며 이러한 흐름을 가속화했다.1 이는 막대한 컴퓨팅 자원이 없는 연구자들도 고성능 모델을 쉽게 활용할 수 있게 만들어 NLP 연구의 진입 장벽을 낮추고 생태계 전반의 발전을 촉진하는 데 결정적인 기여를 했다. 이 시점을 기준으로, 현대 NLP 연구는 ’BERT 이전’과 ’BERT 이후’로 나뉜다고 평가해도 과언이 아니다.</p>
<p>BERT의 등장은 단순히 성능이 더 좋은 모델의 출현을 의미하지 않았다. 이는 ‘대규모 데이터셋’, ‘트랜스포머 아키텍처’, 그리고 ’자기지도학습 기반 사전 훈련’이라는 세 가지 요소가 결합된 성공 공식의 완성을 의미했다. 2017년 트랜스포머가 순환 구조 없이 어텐션만으로 시퀀스 데이터를 효과적으로 처리할 수 있음을 보였고, 2018년 상반기 GPT가 생성적 사전 훈련의 가능성을 입증했다면, BERT는 트랜스포머 아키텍처의 핵심인 셀프 어텐션이 양방향 문맥을 동시에 처리하는 데 최적화되어 있다는 본질을 꿰뚫어 보았다. 그리고 MLM이라는 독창적인 훈련 목표를 고안함으로써, 트랜스포머의 잠재력을 ’이해’의 영역에서 완전히 끌어내는 데 성공했다. 따라서 BERT의 등장은 이전 연구들의 성과가 집대성되어 하나의 강력한 패러다임으로 완성된 순간으로 해석할 수 있으며, 이는 이후 등장하는 모든 대규모 언어 모델(LLM)의 사상적 토대가 되었다.</p>
<h2>3.  관계형 추론과 구조적 표현의 도약: 그래프 네트워크</h2>
<h3>3.1  연구 배경: 딥러닝의 근본적 도전, 조합적 일반화</h3>
<p>2018년 당시, 딥러닝은 이미지나 텍스트와 같이 격자(grid)나 시퀀스 형태의 정형화된 데이터 구조에서 경이로운 성공을 거두고 있었다. 그러나 CNN이나 RNN과 같은 표준적인 딥러닝 아키텍처는 세상의 복잡한 시스템, 즉 개별적인 개체(entity)와 그들 사이의 동적인 상호작용(relation)으로 구성된 비정형적 데이터를 모델링하는 데에는 근본적인 한계를 보였다.3 인간 지능의 가장 중요한 특징 중 하나는 ‘조합적 일반화(combinatorial generalization)’ 능력이다. 이는 이미 학습한 지식의 조각들을 새로운 방식으로 조합하여 이전에 한 번도 경험해보지 못한 문제에 적용하는 능력이다. 이러한 능력은 AI에게 여전히 가장 어려운 과제 중 하나로 남아있었다.3</p>
<h3>3.2  핵심 개념: 관계형 귀납 편향</h3>
<p>이러한 배경 속에서, DeepMind, Google Brain, MIT, 그리고 에든버러 대학교의 연구자들로 구성된 대규모 공동 연구팀은 “Relational inductive biases, deep learning, and graph networks“라는 제목의 중요한 논문을 발표했다(초판은 6월, 수정본은 2018년 10월 17일 arXiv에 제출됨).3 이 논문은 AI가 인간과 같은 일반화 능력을 갖추기 위해서는 ’관계형 귀납 편향(relational inductive biases)’을 모델 아키텍처에 명시적으로 통합해야 한다고 주장했다. ’귀납 편향’이란 모델이 특정 유형의 해법을 선호하도록 만드는 가정(assumption)을 의미한다. 따라서 관계형 귀납 편향은 ’세상은 개체와 그들 간의 관계로 구성되어 있다’는 구조적 가정을 모델 설계에 직접 반영하는 것을 뜻한다. 이는 순수하게 데이터로부터 모든 것을 학습하는 ‘end-to-end’ 방식과, 전문가가 직접 규칙을 설계하는 ‘hand-engineering’ 방식의 철학적 장점들을 결합하려는 시도였다.3</p>
<h3>3.3  그래프 네트워크(GN) 프레임워크: 일반화된 모델의 제안</h3>
<p>이 논문은 하나의 특정 모델을 제안하기보다는, 기존에 존재하던 다양한 그래프 기반 신경망들(Graph Neural Networks, Message Passing Neural Networks 등)을 포괄하는 매우 일반화된 프레임워크인 ‘그래프 네트워크(Graph Network, GN)’ 블록을 수학적으로 정의했다는 점에서 큰 의의를 가진다.3</p>
<p>GN 프레임워크에서 그래프 <span class="math math-inline">G = (u, V, E)</span>는 세 가지 요소로 구성된다.</p>
<ul>
<li>
<p><strong>전역 속성(global attribute) <span class="math math-inline">u</span></strong>: 그래프 전체의 상태를 나타내는 벡터.</p>
</li>
<li>
<p><strong>노드 집합(node set) <span class="math math-inline">V = \{v_i\}</span></strong>: 시스템의 개체들을 나타내는 벡터들의 집합.</p>
</li>
<li>
<p><strong>엣지 집합(edge set) <span class="math math-inline">E = \{(e_k, r_k, s_k)\}</span></strong>: 개체 간의 관계를 나타내는 벡터들의 집합. 각 엣지는 속성 <span class="math math-inline">e_k</span>, 수신 노드 인덱스 <span class="math math-inline">r_k</span>, 송신 노드 인덱스 <span class="math math-inline">s_k</span>를 가진다.</p>
</li>
</ul>
<p>GN 블록의 핵심 연산 과정은 다음과 같은 3단계로 이루어진다.</p>
<ol>
<li>
<p><strong>엣지 업데이트</strong>: 각 엣지 <span class="math math-inline">k</span>에 대해, 엣지 자체의 속성 <span class="math math-inline">e_k</span>, 연결된 두 노드의 속성 <span class="math math-inline">v_{r_k}</span>, <span class="math math-inline">v_{s_k}</span>, 그리고 전역 속성 <span class="math math-inline">u</span>를 입력으로 받는 업데이트 함수 <span class="math math-inline">\phi^e</span>를 적용하여 새로운 엣지 속성 <span class="math math-inline">e&#39;_k</span>를 계산한다. 이는 관계의 특성이 주변 개체들의 상태에 따라 어떻게 변하는지를 모델링한다.</p>
<p><span class="math math-display">
e&#39;_k = \phi^e(e_k, v_{r_k}, v_{s_k}, u)
</span></p>
</li>
<li>
<p><strong>노드 정보 취합(Aggregation)</strong>: 각 노드 <span class="math math-inline">i</span>에 대해, 자신을 수신 노드로 하는 모든 엣지들의 갱신된 정보 <span class="math math-inline">\{e&#39;_{k}\}_{r_k=i}</span>를 하나의 벡터 <span class="math math-inline">\bar{e}&#39;_i</span>로 취합한다. 이 과정은 합(summation), 평균(mean) 등과 같은 순서에 무관한(permutation-invariant) 함수 <span class="math math-inline">\rho^{e \to v}</span>를 통해 이루어진다.<br />
<span class="math math-display">
\bar{e}&#39;_i = \rho^{e \to v}(\{e&#39;_{k}\}_{r_k=i})
</span></p>
</li>
<li>
<p><strong>노드 업데이트</strong>: 각 노드 <span class="math math-inline">i</span>에 대해, 취합된 엣지 정보 <span class="math math-inline">\bar{e}&#39;_i</span>, 노드 자신의 기존 속성 <span class="math math-inline">v_i</span>, 그리고 전역 속성 <span class="math math-inline">u</span>를 입력으로 받는 업데이트 함수 <span class="math math-inline">\phi^v</span>를 적용하여 새로운 노드 속성 <span class="math math-inline">v&#39;_i</span>를 계산한다. 이는 주변 관계들의 영향을 받아 개체의 상태가 어떻게 변하는지를 모델링한다.<br />
<span class="math math-display">
v&#39;_i = \phi^v(\bar{e}&#39;_i, v_i, u)
</span></p>
</li>
</ol>
<p>이러한 ‘encode-process-decode’ 구조는 물리 시스템의 입자 상호작용부터 소셜 네트워크의 정보 전파까지, 관계적 구조를 가진 거의 모든 종류의 문제에 유연하게 적용될 수 있는 강력하고 일반적인 추론 도구를 제공한다.6</p>
<h3>3.4  AI 연구에 미친 영향과 전망</h3>
<p>그래프 네트워크 논문은 당시 파편화되어 있던 그래프 기반 딥러닝 연구 분야에 통일된 언어와 견고한 수학적 기틀을 제공했다. 이를 통해 후속 연구들은 자신들의 아이디어를 명확하게 비교하고 체계적으로 확장할 수 있는 공통의 기반을 갖게 되었다. 이 프레임워크는 물리학 시뮬레이션, 신약 개발을 위한 분자 구조 예측, 교통망 분석, 소셜 네트워크 및 추천 시스템 등 복잡한 관계형 데이터가 핵심적인 역할을 하는 다양한 도메인에서 그래프 신경망의 적용을 폭발적으로 가속화하는 중요한 이론적 토대를 마련했다.4</p>
<p>2018년 10월에 발표된 두 기념비적인 연구, BERT와 그래프 네트워크는 표면적으로는 각각 자연어와 일반 그래프라는 다른 문제를 다루지만, ’구조(Structure)’와 ’관계(Relation)’의 중요성을 강조한다는 점에서 깊은 사상적 공통점을 공유한다. BERT의 셀프 어텐션 메커니즘은 문장 내 모든 단어 쌍 간의 ’관계’를 동적으로 계산하여 각 단어의 문맥적 의미를 구성한다. 이는 문장을 선형적인 시퀀스가 아닌, 모든 단어가 서로 연결된 완전 연결 그래프(fully connected graph)로 간주하고 그 관계의 가중치를 학습하는 과정과 유사하다. 그래프 네트워크는 이러한 아이디어를 한 단계 더 일반화하여, 임의의 구조를 가진 데이터에서 명시적으로 정의된 ’관계(엣지)’를 통해 정보를 전파하고 ’개체(노드)’의 표현을 정교화하는 보편적인 프레임워크를 제공한다. 결국 두 연구 모두 데이터 내에 내재된 또는 명시적인 관계 구조를 효과적으로 활용하는 것이 고차원적인 추론과 일반화 능력의 핵심이라는 동일한 철학을 가리킨다. 이런 관점에서 2018년 10월은 AI 연구의 무게 중심이 ’개별 데이터 포인트’의 특성을 학습하는 것에서 ’데이터 간의 관계’를 모델링하는 것으로 전환되는 중요한 시점이었음을 시사한다.</p>
<h2>4.  로봇 및 비전 분야 최신 연구 동향: IROS 2018을 중심으로</h2>
<h3>4.1  IROS 2018 개요: “로봇 사회를 향하여”</h3>
<p>2018년 10월 1일부터 5일까지 스페인 마드리드에서는 로봇 공학 분야의 세계 최고 권위 학회 중 하나인 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2018)가 개최되었다.7 “로봇 사회를 향하여(Towards a Robotic Society)“라는 주제 아래, 이번 학회는 로봇이 통제된 실험실 환경을 넘어 인간의 일상 및 산업 현장에 안전하고 유용하게 통합되기 위해 해결해야 할 실질적인 기술적 과제들에 대한 논의가 집중적으로 이루어졌다. 2,700편 이상의 논문이 제출되고 그중 1,250편 이상이 채택되는 등 역대 최대 규모로 치러진 점은 당시 로봇 공학 연구 커뮤니티의 높은 활기를 방증하는 것이었다.8</p>
<h3>4.2  주요 수상 논문 심층 분석: 실용적 문제 해결에 집중</h3>
<p>IROS 2018에서 주목받은 연구들은 이론적 우수성을 넘어 실제 로봇 시스템이 현장에서 겪는 구체적이고 현실적인 문제들을 해결하는 데 초점을 맞추었다.</p>
<h4>4.2.1  최우수 학생 논문상: Online temporal calibration for monocular visual-inertial systems (Qin, T., et al.)</h4>
<p>저가의 카메라와 관성 측정 장치(IMU)를 결합한 시각-관성 항법 시스템(VINS)은 자율 드론, 증강현실(AR) 기기 등에서 핵심적인 위치 추정 기술이다. 그러나 이 시스템의 성능은 두 센서로부터 들어오는 데이터 간의 미세한 시간 불일치(temporal offset)에 매우 민감하다. 수 밀리초(ms)의 오차만으로도 시스템 전체의 정확도가 심각하게 저하되거나 발산할 수 있어, 이는 VINS의 상용화를 가로막는 고질적인 문제였다.10</p>
<p>홍콩과기대의 Tong Qin 등이 발표한 이 논문은 이러한 문제를 해결하기 위해, 별도의 복잡한 오프라인 캘리브레이션 과정 없이 시스템이 작동하는 동안 실시간으로 시간 오프셋을 추정하고 보정하는 온라인 최적화 기법을 제안했다.12 이 방법은 시간 오프셋을 로봇의 위치, 자세, 속도와 같은 다른 상태 변수들과 함께 통합된 최적화 문제(joint optimization)의 일부로 간주하여 동시에 추정한다. 이 연구는 VINS 기술의 강건성(robustness)과 현장 적용성을 크게 향상시킨 핵심적인 기여로 인정받아 최우수 학생 논문상을 수상했다.12</p>
<h4>4.2.2  IEEE RA-L 2018 최우수 논문상: Vision-Based Reactive Planning for Aggressive Target Tracking While Avoiding Collisions and Occlusions (Penin, B., et al.)</h4>
<p>쿼드콥터와 같은 고속 비행 로봇이 동적으로 움직이는 목표물을 추적하는 임무는 매우 복잡한 제어 문제이다. 로봇은 자신의 물리적 한계(최대 속도, 가속도)를 준수해야 할 뿐만 아니라, 카메라의 제한된 시야각(Field of View), 환경 내 정적/동적 장애물과의 충돌, 그리고 목표물에 대한 시야가 다른 물체에 의해 가려지는 폐색(occlusion) 현상 등 다양한 제약 조건을 동시에 고려해야 한다.14</p>
<p>프랑스 INRIA 연구소의 Bryan Penin 등이 발표한 이 논문은 이러한 복합적인 문제를 해결하기 위해 다중 목표 최적화(multi-objective optimization)에 기반한 실시간 반응형(reactive) 경로 계획 프레임워크를 제시했다.15 이 프레임워크는 목표물 추종의 효율성, 충돌 회피, 폐색 회피라는 서로 상충될 수 있는 목표들 사이에서 실시간으로 최적의 균형점을 찾아 로봇의 제어 입력을 생성한다. 이 연구는 로봇의 동역학, 센서의 제약, 그리고 환경의 제약을 통합적으로 고려하는 고수준 자율 제어 기술의 발전을 보여주는 대표적인 사례로, 그 중요성을 인정받아 IEEE Robotics and Automation Letters (RA-L)의 2018년 최우수 논문으로 선정되었다.14</p>
<h3>4.3  주목할 만한 연구 분야 동향</h3>
<p>IROS 2018에서는 특정 수상 논문들 외에도 로봇 공학의 미래를 조망할 수 있는 여러 중요한 연구 흐름이 관찰되었다. MIT에서 발표한 “Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control” 논문은 볼록 모델 예측 제어(Convex Model-Predictive Control)라는 최적화 기법을 통해 사족 로봇 ’치타 3’의 매우 동적이고 안정적인 보행을 구현하여 큰 주목을 받았다.18 또한, 기존의 딱딱한 강체 로봇의 한계를 극복하기 위해 유연한 소재로 로봇을 제작하는 소프트 로보틱스(Soft Robotics) 분야 역시 다수의 워크숍과 논문 발표를 통해 활발한 연구가 이루어지고 있음을 보여주었다.9 2018년 10월 arXiv의 로보틱스(cs.RO) 및 컴퓨터 비전(cs.CV) 카테고리에서도 자기지도학습 및 강화학습을 이용한 로봇 제어, 자율주행을 위한 3D 객체 인식, 다중 로봇 협력 등 다양한 주제의 연구들이 활발하게 발표되며 기술 발전의 속도를 입증했다.19</p>
<p>이러한 연구 동향들은 로봇 공학 분야가 이상적인 시뮬레이션 환경을 가정한 이론적 연구를 넘어, 실제 로봇 시스템을 구동할 때 필연적으로 발생하는 현실 세계의 문제들을 해결하는 데 집중하고 있음을 명확히 보여준다. 초기 로봇 연구가 이상적인 센서와 완벽한 동기화를 가정하는 경우가 많았다면, IROS 2018의 주요 연구들은 센서 비동기화, 물리적 제약, 지각적 한계와 같은 ’현실의 문제’를 알고리즘적으로 해결하려는 성숙한 단계로 진입했음을 시사한다. 이는 로봇 공학 연구가 이론적 최적성(theoretical optimality)을 넘어 실제 환경에서의 강건성(real-world robustness)을 확보하는 방향으로 나아가고 있음을 의미하는 중요한 지표이다.</p>
<table><thead><tr><th><strong>논문 제목 (Title)</strong></th><th><strong>저자 (Authors)</strong></th><th><strong>핵심 기여 (Key Contribution)</strong></th></tr></thead><tbody>
<tr><td>Online temporal calibration for monocular visual-inertial systems</td><td>Qin, T., et al.</td><td>단안 VIO/SLAM 시스템에서 카메라-IMU 간 시간 오프셋(<span class="math math-inline">t_d</span>)을 온라인 최적화 기법으로 교정. 강건성과 정확도 향상.</td></tr>
<tr><td>Vision-Based Reactive Planning for Aggressive Target Tracking While Avoiding Collisions and Occlusions</td><td>Penin, B., et al.</td><td>다중 목표 최적화를 통해 충돌 및 폐색을 회피하며 동적 표적을 추적하는 실시간 경로 계획.</td></tr>
<tr><td>Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control</td><td>Di Carlo, J., et al.</td><td>볼록 모델 예측 제어(MPC)를 활용하여 사족 로봇의 고속 동적 보행(dynamic locomotion)을 구현.</td></tr>
<tr><td>3D Shape Perception from Monocular Vision, Touch, and Shape Priors</td><td>Wang, S., et al.</td><td>단안 비전, 촉각, 그리고 형태 사전 지식을 융합하여 3D 물체 형태를 인식하는 다중 모달 접근법 제시.</td></tr>
</tbody></table>
<h2>5.  학계의 응용 AI 연구 혁신: MIT CSAIL 사례</h2>
<h3>5.1  프라이버시 보존형 AI: 암호학과 딥러닝의 융합</h3>
<p>2018년 10월 18일, MIT 컴퓨터 과학 및 인공지능 연구소(CSAIL) 연구팀은 세계적인 과학 저널 <em>Science</em>에 “Cryptographic protocol enables greater collaboration in drug discovery“라는 제목의 획기적인 연구를 발표했다.22 이 연구는 신약 개발이라는 매우 중요한 과학적 문제에 AI를 적용하되, 그 과정에서 발생하는 데이터 프라이버시 문제를 암호학 기술로 정면 돌파했다는 점에서 큰 주목을 받았다.</p>
<p>신약 개발 과정에서 개별 제약 회사나 연구 기관들은 방대한 약물-표적 상호작용(Drug-Target Interaction, DTI) 데이터를 보유하고 있지만, 이는 매우 민감한 지적 재산이자 기밀 정보다. 이러한 데이터 사일로(data silo) 현상은 연구자 간의 협력을 가로막고 신약 개발 전체의 효율성을 저해하는 큰 장벽으로 작용해왔다. MIT 연구팀은 이 문제를 해결하기 위해 ’비밀 공유(secret sharing)’라는 다자간 연산(Multi-Party Computation) 암호화 기술을 신경망 모델에 적용했다. 이 기술은 원본 데이터를 직접 공유하는 대신, 데이터를 암호화된 여러 개의 ’조각’으로 분리하여 서로 다른 서버에 분산시킨다. 각 서버는 자신의 조각만으로는 아무런 정보를 얻을 수 없지만, 서버들이 암호화된 상태에서 협력적으로 연산을 수행하면 전체 데이터셋에 대한 신경망 모델의 훈련 및 추론이 가능하다.22</p>
<p>연구팀이 개발한 시스템은 150만 개 이상의 DTI를 포함하는 대규모 공개 데이터셋(STITCH)을 기존의 다른 암호화 프레임워크보다 수십 배 빠른 속도로 처리하는 데 성공했다. 놀랍게도, 데이터를 암호화하지 않은 평문 상태의 모델과 비교했을 때에도 더 높은 예측 정확도를 달성했다. 더 나아가, 이 시스템은 백혈병 치료제인 ’이마티닙’과 특정 효소 ‘ErbB4’ 사이의 알려지지 않았던 새로운 상호작용 가능성을 예측하는 등, 실질적인 과학적 발견으로 이어질 수 있는 잠재력을 보여주었다.22 이 연구는 AI가 단순히 주어진 데이터를 분석하여 예측하는 수동적인 도구를 넘어, 데이터 공유를 가로막는 사회적, 경제적 장벽 자체를 기술적으로 우회하고 협력을 촉진하는 ’조력자(enabler)’로서의 역할을 할 수 있음을 보여준 선구적인 사례이다.</p>
<h3>5.2  AI 연구의 미래를 위한 제도적 기반 마련</h3>
<p>같은 시기인 2018년 10월, MIT는 3억 5천만 달러의 기부금을 바탕으로 ’MIT 스티븐 A. 슈워츠먼 컴퓨팅 대학(MIT Stephen A. Schwarzman College of Computing)’의 설립을 발표했다.23 이 발표는 단순한 단과대학 신설을 넘어, AI 시대에 대응하는 세계 최고 공과대학의 비전과 고민을 담고 있다는 점에서 중요한 의미를 가진다.</p>
<p>새로운 컴퓨팅 대학의 핵심 목표는 컴퓨터 과학, AI, 데이터 과학 연구를 MIT 내의 모든 학문 분야(인문학, 사회과학, 예술 포함)와 유기적으로 융합하는 학제간 연구의 허브 역할을 하는 것이다. 특히 주목할 점은, 이 대학이 순수한 기술 개발뿐만 아니라 AI 기술이 사회에 미치는 ’정책 및 윤리적 문제’를 다루는 것을 핵심 사명 중 하나로 명시했다는 사실이다.23 이는 AI 기술의 발전이 반드시 사회적 책임과 윤리적 성찰을 동반해야 한다는 인식이 학계 최고 수준에서 공식적으로 제도화되기 시작했음을 보여주는 상징적인 사건이다.</p>
<p>이러한 움직임은 2018년 당시의 시대적 배경과 깊이 연결된다. BERT와 같이 사회 전반에 큰 영향을 미칠 수 있는 강력한 AI 기술이 등장하면서 그 잠재력과 함께 오용 가능성에 대한 우려도 커지고 있었다. Google 역시 이 시기에 AI 개발 및 활용에 대한 7가지 원칙을 발표하는 등 24, 기술의 사회적 영향에 대한 논의가 산업계와 학계 전반에서 활발하게 이루어지고 있었다. MIT의 슈워츠먼 컴퓨팅 대학 설립은 이러한 시대적 요구에 부응하여, 미래의 AI 전문가들이 기술적 역량뿐만 아니라 인문사회학적 소양과 윤리적 통찰력을 겸비하도록 교육하는 것이 필수적이라는 판단에서 비롯된 것이다. 이는 기술 발전과 사회적 성찰이 더 이상 분리될 수 없는 과제임을 보여주는 선도적인 사례로 평가할 수 있다.</p>
<h2>6.  결론</h2>
<p>2018년 10월은 AI 기술 발전의 역사에서 ’스케일 업(Scale-up)’과 ’구조화(Structuring)’라는 두 가지 거대한 흐름이 교차하며 새로운 장을 연 시기로 요약할 수 있다. Google의 BERT는 트랜스포머 아키텍처와 방대한 데이터를 결합하여 자연어 이해 능력의 규모를 전례 없는 수준으로 끌어올렸고, 이는 이후 대규모 언어 모델(LLM) 시대의 서막을 열었다. 동시에 DeepMind의 그래프 네트워크 프레임워크는 물리계, 생물학적 네트워크, 사회적 관계망 등 복잡한 시스템을 이해하기 위한 구조적 추론의 일반화된 이론적 기틀을 마련했다.</p>
<p>이 두 흐름은 독립적이지 않고 상호 보완적이었다. BERT가 촉발한 파운데이션 모델의 패러다임은 이후 그래프 신경망(GNN)과 결합하여, 단순한 텍스트를 넘어 분자 구조, 소스 코드, 지식 그래프와 같은 복잡한 구조적 데이터를 이해하는 강력한 모델의 개발로 이어지는 등, 당시의 연구들은 서로 영향을 주고받으며 현재 AI 기술 지형의 근간을 형성했다.</p>
<p>한편, IROS 2018에서 심도 있게 논의된 로봇 공학의 실용적 과제들과 MIT에서 제시된 AI의 사회적 책임에 대한 제도적 고민은 중요한 미래 방향을 제시했다. 로봇이 현실 세계에서 안정적으로 작동하기 위해 센서 동기화나 물리적 제약과 같은 문제를 해결해야 하듯이, AI 기술이 사회에 유익하게 통합되기 위해서는 프라이버시, 공정성, 투명성과 같은 문제를 해결해야 한다. 결국 2018년 10월의 연구들은 AI 기술이 더욱 고도화되고 보편화됨에 따라, 순수한 성능 경쟁을 넘어 ‘강건성(Robustness)’, ‘신뢰성(Reliability)’, ‘해석 가능성(Interpretability)’, 그리고 ’윤리(Ethics)’와 같은 주제가 연구의 핵심으로 부상할 것임을 명확하게 예고한 중요한 변곡점이었다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>BERT (language model) - Wikipedia, https://en.wikipedia.org/wiki/BERT_(language_model)</li>
<li>arXiv:1810.04805v2 [cs.CL] 24 May 2019, https://arxiv.org/abs/1810.04805</li>
<li>[1806.01261] Relational inductive biases, deep learning, and graph networks - arXiv, https://arxiv.org/abs/1806.01261</li>
<li>Relational inductive biases, deep learning, and graph networks - ResearchGate, https://www.researchgate.net/publication/325557043_Relational_inductive_biases_deep_learning_and_graph_networks</li>
<li>Relational inductive biases, deep learning, and graph networks - Google Research, https://research.google/pubs/relational-inductive-biases-deep-learning-and-graph-networks/</li>
<li>Relational inductive biases, deep learning, and graph networks - Semantic Scholar, https://www.semanticscholar.org/paper/Relational-inductive-biases%2C-deep-learning%2C-and-Battaglia-Hamrick/3a58efcc4558727cc5c131c44923635da4524f33</li>
<li>qbrobotics.com, https://qbrobotics.com/events/iros-2018-madrid-spain/</li>
<li>IROS 2018 - International Conference on Intelligent Robots - Madrid, https://www.iros2018.org/</li>
<li>Editorial: Advances in Soft Robotics Based on Outputs From IROS 2018 - ResearchGate, https://www.researchgate.net/publication/343888884_Editorial_Advances_in_Soft_Robotics_Based_on_Outputs_From_IROS_2018</li>
<li>Online Spatial and Temporal Calibration for Monocular Direct Visual-Inertial Odometry - Semantic Scholar, https://pdfs.semanticscholar.org/2228/923e1c941b684f46420fce71907eb835175a.pdf</li>
<li>An Embedded High-Precision GNSS-Visual-Inertial Multi-Sensor Fusion Suite - NAVIGATION, https://navi.ion.org/content/navi/70/4/navi.607.full.pdf</li>
<li>Tong Qin wins IROS 2018 Best Student Paper Award - HKUST Aerial Robotics Group, https://uav.hkust.edu.hk/iros2018-best-student-paper-award/</li>
<li>Optimization-Based Online Initialization and Calibration of Monocular Visual-Inertial Odometry Considering Spatial-Temporal Constraint - Semantic Scholar, https://pdfs.semanticscholar.org/c7f7/d7a73a13542e3c23db1129968fd63d47d240.pdf</li>
<li>IEEE RA-L 2018 Best Paper Award – Rainbow - Inria, https://team.inria.fr/rainbow/ieee-ra-l-best-paper-award/</li>
<li>Vision-Based Reactive Planning for Aggressive Target Tracking While Avoiding Collisions and Occlusions - ResearchGate, https://www.researchgate.net/publication/326367452_Vision-Based_Reactive_Planning_for_Aggressive_Target_Tracking_while_Avoiding_Collisions_and_Occlusions</li>
<li>Quadrotor model II. PRELIMINARIES - ResearchGate, https://www.researchgate.net/figure/Quadrotor-model-II-PRELIMINARIES_fig1_326367452</li>
<li>‪Paolo Robuffo Giordano‬ - ‪Google Scholar‬, https://scholar.google.com/citations?user=dpayTBUAAAAJ&amp;hl=en</li>
<li>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2018, Madrid, Spain, October 1-5, 2018 - researchr publication, https://researchr.org/publication/iros-2018</li>
<li>[1810.08462] Fully Convolutional Siamese Networks for Change Detection - arXiv, https://arxiv.org/abs/1810.08462</li>
<li>Robotics Oct 2018 - arXiv, http://arxiv.org/list/cs.RO/2018-10?skip=0&amp;show=250</li>
<li>Robotics Oct 2018 - arXiv, http://arxiv.org/list/cs.RO/2018-10?skip=75&amp;show=25</li>
<li>Cryptographic protocol enables greater collaboration in drug …, https://news.mit.edu/2018/cryptographic-protocol-collaboration-drug-discovery-1018</li>
<li>AI, the law, and our future | MIT News | Massachusetts Institute of Technology, https://news.mit.edu/2019/first-ai-policy-congress-0118</li>
<li>AI at Google: our principles, https://blog.google/technology/ai/ai-principles/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>