<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:2012년 4분기 AI 및 로봇 연구 동향</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>2012년 4분기 AI 및 로봇 연구 동향</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">기사 (Articles)</a> / <a href="index.html">2012년 AI 및 로봇 연구 동향</a> / <span>2012년 4분기 AI 및 로봇 연구 동향</span></nav>
                </div>
            </header>
            <article>
                <h1>2012년 4분기 AI 및 로봇 연구 동향</h1>
<h2>1. 서론: 2012년 4분기, AI 혁명의 서곡</h2>
<p>2012년 4분기는 인공지능(AI) 및 로봇 공학 분야의 역사에서 단순한 시간의 흐름을 넘어, 현대 AI 혁명의 기술적, 사상적 토대가 마련되고 그 가능성이 명백하게 드러난 결정적 시기로 기록된다. 이 시기는 점진적 개선의 시대를 마감하고, 패러다임의 전환을 알리는 서곡과도 같았다. 학계와 산업계 양쪽에서 동시다발적으로 발생한 일련의 사건들은 향후 10년간 AI 연구 개발의 방향성을 결정지었으며, 그 파급 효과는 오늘날까지 이어지고 있다.</p>
<p>이 보고서는 2012년 10월부터 12월까지 3개월 동안 AI와 로봇 공학 분야에서 발표된 가장 중요한 연구 성과와 기술적 진보를 심층적으로 분석하고 종합하는 것을 목표로 한다. 분석의 초점은 두 개의 주요 전선에 맞추어진다. 첫째는 신경정보처리시스템학회(NeurIPS)와 지능형 로봇 및 시스템 국제학회(IROS)로 대표되는 학술 무대이다. 이들 학회에서는 새로운 이론과 방법론이 동료 연구자들의 엄격한 검증을 통해 그 타당성을 입증받고 학문적 주류로 편입되었다. 특히 NeurIPS 2012는 딥러닝이 머신러닝 분야의 지배적인 패러다임으로 부상하는 공식적인 데뷔 무대 역할을 하였다.1</p>
<p>둘째는 구글과 마이크로소프트 같은 거대 기술 기업의 연구소에서 이루어진 혁신이다. 이들은 학계와는 다른 차원에서 AI 기술의 ’규모(scale)’를 재정의하며, 이론적 가능성을 현실 세계의 문제에 적용할 수 있는 대규모 시스템으로 구현해냈다. 이들의 연구는 AI가 단순한 학문적 탐구를 넘어, 사회 전반에 영향을 미칠 수 있는 강력한 기술적 도구로 변모할 수 있음을 입증했다.</p>
<p>본 보고서는 이 시기에 발표된 핵심 논문과 기술 시연을 면밀히 검토함으로써, 당시의 기술적 성취가 어떻게 상호작용하며 AI 혁명의 기폭제로 작용했는지를 규명하고자 한다. AlexNet이 제시한 컴퓨터 비전의 새로운 가능성, 심층 볼츠만 머신이 탐구한 생성 모델링의 깊이, IROS에서 논의된 로봇의 자율적 학습 능력, 그리고 기업 연구소가 현실화한 대규모 AI 시스템의 구축은 각각 독립적인 성과처럼 보이지만, 실제로는 서로를 보완하고 추동하며 하나의 거대한 흐름을 형성했다. 이 3개월간의 기록은 AI가 어떻게 이론의 영역에서 현실의 영역으로 도약했는지를 보여주는 가장 생생한 증거이다.</p>
<table><thead><tr><th>행사명</th><th>날짜</th><th>장소</th><th>주요 발표 및 주제</th></tr></thead><tbody>
<tr><td>IC3K 2012</td><td>2012년 10월 4-7일</td><td>스페인, 바르셀로나</td><td>지식 발견, 지식 공학 및 지식 관리</td></tr>
<tr><td>IJCCI 2012</td><td>2012년 10월 5-7일</td><td>스페인, 바르셀로나</td><td>계산 지능</td></tr>
<tr><td>IROS 2012</td><td>2012년 10월 7-12일</td><td>포르투갈, 빌라모라</td><td>지능형 로봇 및 시스템, 삶의 질과 지속 가능한 발전을 위한 로보틱스</td></tr>
<tr><td>AIIDE-12</td><td>2012년 10월 8-12일</td><td>미국, 캘리포니아주 팰로앨토</td><td>인공지능 및 인터랙티브 디지털 엔터테인먼트</td></tr>
<tr><td>Microsoft Speech Demo</td><td>2012년 10월 25일</td><td>중국, 톈진</td><td>심층신경망(DNN) 기반 실시간 음성-대-음성 번역 시연</td></tr>
<tr><td>AAAI Fall Symposium</td><td>2012년 11월 2-4일</td><td>미국, 버지니아주 알링턴</td><td>인공지능 관련 다수 심포지엄 진행</td></tr>
<tr><td>NeurIPS 2012</td><td>2012년 12월 3-8일</td><td>미국, 네바다주 레이크 타호</td><td>신경정보처리시스템, 딥러닝의 부상</td></tr>
</tbody></table>
<p><strong>표 1: 2012년 4분기 주요 AI 및 로봇 분야 학술 행사 및 발표</strong> 3</p>
<h2>2.  NeurIPS 2012: 딥러닝, 학계의 주류로 부상하다</h2>
<p>2012년 12월, 네바다주 레이크 타호에서 개최된 제26회 신경정보처리시스템학회(NeurIPS 2012)는 인공지능 역사상 가장 중요한 학술 행사 중 하나로 평가된다.4 이 학회는 딥러닝이 수년간의 동면기를 끝내고 머신러닝 분야의 명실상부한 주류 패러다임으로 자리매김했음을 선언하는 상징적인 사건이었다. 특히 두 편의 যুগ을 가르는(epoch-making) 논문은 딥러닝의 잠재력을 의심하던 학계에 강력한 실증적 증거를 제시하며 이후 연구의 흐름을 완전히 바꾸어 놓았다. 이 장에서는 NeurIPS 2012를 뜨겁게 달구었던 두 가지 핵심 연구, 즉 컴퓨터 비전의 역사를 새로 쓴 AlexNet과 멀티모달 데이터에 대한 생성 모델링의 새로운 지평을 연 심층 볼츠만 머신을 심층적으로 분석한다.</p>
<h3>2.1  AlexNet: 컴퓨터 비전의 패러다임을 재정의한 합성곱 신경망</h3>
<p>Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton이 발표한 논문 “ImageNet Classification with Deep Convolutional Neural Networks“는 NeurIPS 2012에서 가장 큰 주목을 받았으며, 딥러닝 혁명의 기폭제가 된 연구로 평가받는다.12 이 연구의 의의를 이해하기 위해서는 당시 컴퓨터 비전 분야의 기술적 배경을 먼저 살펴볼 필요가 있다. 2012년 이전, 이미지 분류와 같은 과제는 주로 SIFT(Scale-Invariant Feature Transform)와 같은 수작업 특징 공학(hand-crafted feature engineering) 기법과 서포트 벡터 머신(SVM)과 같은 전통적인 분류기를 결합하는 방식에 의존했다.13 이러한 접근 방식은 특징 추출 과정이 전문가의 직관과 많은 노력을 요구했으며, 성능 향상에도 점진적인 한계를 보이고 있었다.</p>
<p>이러한 상황에서 AlexNet은 ImageNet 대규모 시각 인식 챌린지(ILSVRC) 2012에서 압도적인 성능을 기록하며 등장했다. AlexNet은 15.3%의 top-5 오류율을 달성했는데, 이는 2위를 기록한 26.2%보다 무려 10.9% 포인트나 낮은 수치였다.14 이처럼 경이로운 성능 차이는 단순한 개선이 아닌, 근본적인 패러다임의 전환을 의미했다. 데이터로부터 특징을 자동으로 학습하는 딥러닝 모델, 특히 깊은 합성곱 신경망(CNN)이 수작업 특징 공학 기반의 접근법을 완전히 능가할 수 있음을 명백히 입증한 것이다.1</p>
<p>AlexNet의 성공은 단순히 네트워크의 깊이를 늘린 것 이상의, 세 가지 핵심적인 방법론적 혁신에 기인한다.</p>
<p>첫째, <strong>ReLU(Rectified Linear Unit) 활성화 함수의 도입</strong>이다. 이전의 신경망들이 주로 사용했던 시그모이드(sigmoid)나 하이퍼볼릭 탄젠트(tanh) 함수는 그래디언트 소실 문제(vanishing gradient problem)에 취약했다. 이 함수들은 입력값이 특정 범위를 벗어나면 출력값의 변화가 거의 없어지고(saturating), 이로 인해 역전파 과정에서 그래디언트가 0에 가까워져 심층 네트워크의 학습이 어려워지는 문제가 있었다. 반면, ReLU는 <span class="math math-inline">f(x) = \max(0, x)</span> 형태로 정의되는 비포화(non-saturating) 함수로, 입력값이 양수일 경우 그래디언트가 항상 1로 유지된다.13 이 특성 덕분에 그래디언트 소실 문제를 효과적으로 완화하고, 시그모이드 계열 함수를 사용했을 때보다 학습 속도를 최대 6배까지 가속할 수 있었다.16 이는 6천만 개에 달하는 파라미터를 가진 깊은 네트워크의 학습을 현실적으로 가능하게 만든 결정적인 요인이었다.</p>
<p>둘째, <strong>드롭아웃(Dropout)을 이용한 정규화(regularization)</strong> 기법의 적용이다. AlexNet과 같이 파라미터 수가 매우 많은 모델은 훈련 데이터에 과적합(overfitting)될 위험이 크다. 드롭아웃은 훈련 과정에서 각 뉴런을 특정 확률(AlexNet에서는 0.5)로 임의로 비활성화(출력을 0으로 만듦)하는 기법이다.13 이는 매 훈련 스텝마다 다른 구조의 신경망을 앙상블(ensemble)하여 학습하는 것과 유사한 효과를 내어, 모델이 특정 뉴런의 조합에 과도하게 의존하는 것을 방지하고 더 강건한(robust) 특징을 학습하도록 유도한다.17 이 새로운 정규화 기법은 대규모 완전 연결 계층(fully-connected layers)에서 발생하는 과적합을 효과적으로 억제하는 데 매우 중요한 역할을 했다.</p>
<p>셋째, <strong>GPU를 활용한 병렬 연산</strong>이다. AlexNet의 훈련은 당시로서는 방대한 계산량을 요구했다. 저자들은 두 개의 NVIDIA GTX 580 GPU를 사용하여 훈련 시간을 획기적으로 단축했다.14 당시 GPU의 메모리 용량(각 3GB) 한계로 인해, 모델 아키텍처 자체를 두 개의 GPU에 나누어 병렬로 처리하도록 설계했다. 예를 들어, 특정 계층에서는 각 GPU가 전체 특징 맵(feature map)의 절반씩을 처리하고, 다음 계층으로 넘어갈 때 필요한 경우에만 GPU 간 통신을 수행했다.14 이는 단순히 훈련 속도를 높이는 것을 넘어, 당시의 하드웨어 제약 하에서 이러한 규모의 모델을 훈련하는 것을 가능하게 한 핵심적인 공학적 성취였다.</p>
<p>AlexNet의 아키텍처는 5개의 합성곱 계층과 3개의 완전 연결 계층, 총 8개의 학습 가능한 계층으로 구성된다. 입력 이미지는 <span class="math math-inline">227 \times 227 \times 3</span> 크기로 전처리되며, 각 계층을 거치며 특징을 추출하고 공간적 차원을 축소해 나간다. 최종적으로 1000개의 ImageNet 클래스에 대한 확률 분포를 출력하기 위해 소프트맥스(softmax) 함수가 사용된다.15 이 구조는 이후 등장하는 수많은 CNN 아키텍처의 원형이 되었다.</p>
<table><thead><tr><th>계층명</th><th>입력 크기</th><th>필터/커널 크기</th><th>스트라이드</th><th>패딩</th><th>필터/뉴런 수</th><th>출력 크기</th><th>파라미터 수</th></tr></thead><tbody>
<tr><td>Conv1</td><td><span class="math math-inline">227 \times 227 \times 3</span></td><td><span class="math math-inline">11 \times 11</span></td><td>4</td><td>0</td><td>96</td><td><span class="math math-inline">55 \times 55 \times 96</span></td><td>34,944</td></tr>
<tr><td>Pool1</td><td><span class="math math-inline">55 \times 55 \times 96</span></td><td><span class="math math-inline">3 \times 3</span></td><td>2</td><td>0</td><td>-</td><td><span class="math math-inline">27 \times 27 \times 96</span></td><td>0</td></tr>
<tr><td>Conv2</td><td><span class="math math-inline">27 \times 27 \times 96</span></td><td><span class="math math-inline">5 \times 5</span></td><td>1</td><td>2</td><td>256</td><td><span class="math math-inline">27 \times 27 \times 256</span></td><td>614,656</td></tr>
<tr><td>Pool2</td><td><span class="math math-inline">27 \times 27 \times 256</span></td><td><span class="math math-inline">3 \times 3</span></td><td>2</td><td>0</td><td>-</td><td><span class="math math-inline">13 \times 13 \times 256</span></td><td>0</td></tr>
<tr><td>Conv3</td><td><span class="math math-inline">13 \times 13 \times 256</span></td><td><span class="math math-inline">3 \times 3</span></td><td>1</td><td>1</td><td>384</td><td><span class="math math-inline">13 \times 13 \times 384</span></td><td>885,120</td></tr>
<tr><td>Conv4</td><td><span class="math math-inline">13 \times 13 \times 384</span></td><td><span class="math math-inline">3 \times 3</span></td><td>1</td><td>1</td><td>384</td><td><span class="math math-inline">13 \times 13 \times 384</span></td><td>1,327,488</td></tr>
<tr><td>Conv5</td><td><span class="math math-inline">13 \times 13 \times 384</span></td><td><span class="math math-inline">3 \times 3</span></td><td>1</td><td>1</td><td>256</td><td><span class="math math-inline">13 \times 13 \times 256</span></td><td>884,992</td></tr>
<tr><td>Pool3</td><td><span class="math math-inline">13 \times 13 \times 256</span></td><td><span class="math math-inline">3 \times 3</span></td><td>2</td><td>0</td><td>-</td><td><span class="math math-inline">6 \times 6 \times 256</span></td><td>0</td></tr>
<tr><td>FC6</td><td><span class="math math-inline">6 \times 6 \times 256</span></td><td>-</td><td>-</td><td>-</td><td>4096</td><td><span class="math math-inline">4096</span></td><td>37,748,736</td></tr>
<tr><td>FC7</td><td><span class="math math-inline">4096</span></td><td>-</td><td>-</td><td>-</td><td>4096</td><td><span class="math math-inline">4096</span></td><td>16,777,216</td></tr>
<tr><td>FC8</td><td><span class="math math-inline">4096</span></td><td>-</td><td>-</td><td>-</td><td>1000</td><td><span class="math math-inline">1000</span></td><td>4,096,000</td></tr>
<tr><td><strong>총합</strong></td><td></td><td></td><td></td><td></td><td></td><td></td><td><strong>~6,230만</strong></td></tr>
</tbody></table>
<p><strong>표 2: AlexNet 아키텍처 상세 명세</strong> 14</p>
<h3>2.2  심층 볼츠만 머신: 멀티모달 데이터의 생성 모델링</h3>
<p>AlexNet이 딥러닝의 강력한 판별(discriminative) 능력을 세상에 알렸다면, 같은 학회에서 발표된 Nitish Srivastava와 Ruslan Salakhutdinov의 논문 “Multimodal Learning with Deep Boltzmann Machines“는 딥러닝이 가진 생성(generative) 모델링의 깊이와 잠재력을 보여준 중요한 연구였다.22 이 연구는 딥러닝이 단순히 분류 과제를 넘어, 이미지와 텍스트처럼 통계적 속성이 전혀 다른 이종(heterogeneous) 데이터 간의 복잡한 관계를 학습하고 통합된 표현(unified representation)을 생성할 수 있음을 입증했다.</p>
<p>이 연구의 핵심은 심층 볼츠만 머신(Deep Boltzmann Machine, DBM)이라는 무방향성 확률 그래픽 모델을 사용하여 이미지와 텍스트 데이터의 결합 확률 분포 <span class="math math-inline">P(\text{image}, \text{text})</span>를 학습하는 데 있다.23 이는 각 데이터 양식(modality)을 다른 양식의 ’소프트 라벨’처럼 활용하여 풍부한 학습 신호를 얻는다는 아이디어에 기반한다. 예를 들어, 여러 이미지에 공통적으로 희귀한 단어가 태그되어 있다면, 그 이미지들은 동일한 객체를 나타낼 가능성이 높다. 반대로, 유사한 이미지에 다른 단어들이 사용되었다면 그 단어들은 비슷한 의미를 가질 수 있다.23 DBM은 이러한 상호 관계를 포착하여 데이터의 기저에 있는 공유된 의미론적 개념을 학습한다.</p>
<p>이 모델의 이론적 토대는 다양한 데이터 유형을 처리하기 위해 확장된 제한된 볼츠만 머신(Restricted Boltzmann Machine, RBM)에 있다. 실수 값의 조밀한(dense) 이미지 특징을 모델링하기 위해서는 가우시안 RBM(Gaussian RBM)을, 이산적이고 희소한(sparse) 단어 빈도수 벡터를 모델링하기 위해서는 복제된 소프트맥스 모델(Replicated Softmax Model)을 사용했다.22 이 두 종류의 RBM을 각 데이터 양식을 위한 빌딩 블록으로 사용하여 개별 DBM을 구성하고, 그 위에 공유된 은닉층(shared hidden layer)을 추가함으로써 두 양식을 통합하는 멀티모달 DBM을 구축했다.</p>
<p>이러한 생성 모델 접근법의 가장 큰 장점은 데이터의 일부가 누락되었을 때 이를 추론하고 생성하는 능력이다. 예를 들어, 이미지만 주어진 경우, 모델은 학습된 결합 분포를 바탕으로 조건부 확률 분포 <span class="math math-inline">P(\text{text} \vert \text{image})</span>로부터 샘플링하여 해당 이미지에 적합한 텍스트 태그를 생성할 수 있다. 반대로 텍스트 쿼리가 주어지면, <span class="math math-inline">P(\text{image} \vert \text{text})</span>를 통해 관련 이미지를 검색할 수 있다.22 이는 판별 모델인 AlexNet이 수행할 수 없는 고유한 기능으로, 딥러닝의 응용 범위를 정보 검색, 데이터 생성 등 더 넓은 영역으로 확장시켰다.</p>
<p>물론 DBM의 학습은 간단하지 않다. 모델의 가능도(likelihood)를 정확히 계산하는 것이 불가능(intractable)하기 때문에, 저자들은 평균장 추론(mean-field inference)과 MCMC 기반 확률적 근사(stochastic approximation)와 같은 복잡한 근사 기법을 사용하여 모델 파라미터를 학습시켰다.22 이러한 기술적 난이도에도 불구하고, 이 연구는 딥러닝이 단순한 패턴 인식을 넘어, 세상에 대한 보다 깊고 구조적인 이해를 가능하게 하는 생성 모델을 구축할 수 있음을 보여주었다는 점에서 큰 학문적 기여를 했다.</p>
<table><thead><tr><th>모델 구성 요소</th><th>에너지 함수 <span class="math math-inline">E(\mathbf{v}, \mathbf{h}; \theta)</span></th><th>변수 설명</th></tr></thead><tbody>
<tr><td><strong>Binary RBM</strong></td><td>$latex -\sum_{i,j} v_i W_{ij} h_j - \sum_i b_i v_i - \sum_j a_j h_j $</td><td><span class="math math-inline">\mathbf{v}</span>: 이진 가시 유닛 <span class="math math-inline">\mathbf{h}</span>: 이진 은닉 유닛</td></tr>
<tr><td><strong>Gaussian RBM</strong></td><td>$latex \sum_i \frac{(v_i - b_i)^2}{2\sigma_i^2} - \sum_{i,j} \frac{v_i}{\sigma_i} W_{ij} h_j - \sum_j a_j h_j $</td><td><span class="math math-inline">\mathbf{v}</span>: 실수 가시 유닛 <span class="math math-inline">\sigma_i</span>: 분산</td></tr>
<tr><td><strong>Replicated Softmax</strong></td><td>$latex -\sum_{k,j} v_k W_{kj} h_j - \sum_k b_k v_k - M \sum_j a_j h_j $</td><td><span class="math math-inline">v_k</span>: 단어 k의 빈도수 <span class="math math-inline">M = \sum_k v_k</span></td></tr>
</tbody></table>
<p><strong>표 3: 멀티모달 심층 볼츠만 머신(DBM)의 핵심 에너지 함수</strong> 22</p>
<p>NeurIPS 2012에서 발표된 이 두 편의 핵심 논문은 하나의 공통된 뿌리를 가지고 있다. AlexNet의 저자들과 멀티모달 DBM의 저자들은 모두 당시 토론토 대학교(University of Toronto) 소속이었다.12 이는 우연이 아니라, 제프리 힌튼과 루슬란 살라쿠트디노프와 같은 선구자들이 이끌던 특정 연구 그룹이 수년간 딥러닝과 생성 모델 연구에 매진해 온 결과물이었다. 당시 머신러닝 학계의 주류가 다른 방법론에 집중하고 있을 때, 토론토 대학교의 연구진은 심층 신경망의 가능성을 믿고 꾸준히 연구를 이어왔다. 따라서 NeurIPS 2012는 단순히 딥러닝이라는 기술의 승리를 넘어, 특정 학문적 생태계가 끈질긴 연구를 통해 하나의 과학 분야 전체를 어떻게 변화시킬 수 있는지를 보여주는 강력한 사례로 해석될 수 있다. 이 학회는 딥러닝이라는 아이디어를 수년간 육성해 온 지적 진원지의 존재를 세상에 각인시킨 사건이었다.</p>
<h2>3.  IROS 2012: 로봇 지능과 자율성의 진화</h2>
<p>2012년 10월, 포르투갈 빌라모라에서 개최된 IEEE/RSJ 지능형 로봇 및 시스템 국제학회(IROS 2012)는 당시 로봇 공학 연구의 최전선을 조망할 수 있는 중요한 장이었다.6 “삶의 질과 지속 가능한 발전을 위한 로보틱스“라는 주제 아래, 학회는 로봇이 물리적 세계와 상호작용하고, 경험을 통해 학습하며, 인간과 협력하는 능력에 대한 깊이 있는 논의로 가득 찼다.8 NeurIPS가 대규모 데이터로부터의 ’인식’에 초점을 맞추었다면, IROS는 물리적 ’행동’과 그 행동을 생성하는 지능에 대한 연구가 중심을 이루었다. 이 장에서는 IROS 2012에서 발표된 핵심 연구를 통해 당시 로봇 지능과 자율성의 진화 과정을 살펴본다.</p>
<h3>3.1  다목적 해법 공간에서의 동시적 운동 능력 학습</h3>
<p>IROS 2012에서 가장 주목받은 연구 중 하나는 Christian Daniel, Gerhard Neumann, Jan Peters가 발표한 “Learning Concurrent Motor Skills in Versatile Solution Spaces“였다. 이 논문은 IROS CoTeSys 인지 로보틱스 최우수 논문상(CoTeSys Cognitive Robotics Best Paper Award)을 수상했으며, 최우수 학생 논문상과 최우수 논문상의 최종 후보에도 오르는 등 그 학술적 우수성을 널리 인정받았다.27</p>
<p>이 연구는 기존 로봇 학습 방법론의 근본적인 한계에 대한 문제의식에서 출발한다. 전통적인 강화학습이나 모방학습은 주어진 과제에 대해 단 하나의 ‘최적’ 해법을 찾는 데 집중했다.29 예를 들어, 로봇이 공을 컵에 넣는 동작을 배울 때, 가장 성공 확률이 높은 단일 궤적을 학습하는 식이다. 그러나 이러한 접근법은 매우 취약(brittle)하다. 환경이 조금만 바뀌거나(예: 공의 무게 변화), 로봇의 상태가 변하거나(예: 관절의 마모), 혹은 학습된 해법이 특정 제약 조건으로 인해 불가능해지면, 로봇은 과제를 전혀 수행할 수 없게 되며 처음부터 다시 학습해야 하는 문제에 직면한다.29</p>
<p>Daniel 연구팀은 이러한 한계를 극복하기 위해, 단일 해법이 아닌 ’다목적 해법 공간(versatile solution space)’을 학습하는 새로운 강화학습 프레임워크를 제안했다. 이 접근법의 핵심은 로봇이 동일한 과제를 성공적으로 완수할 수 있는 여러 개의 서로 다른, 독립적인 전략(distinct solutions)을 동시에 학습하도록 하는 것이다.29 예를 들어, 논문에서 실험 과제로 사용된 테더볼(Tetherball) 게임에서 로봇은 공을 기둥 주위로 감기 위해 시계 방향으로 치는 전략과 반시계 방향으로 치는 전략을 동시에 학습한다.</p>
<p>이러한 다중 해법 학습은 로봇의 자율성과 강건성(robustness)을 극적으로 향상시킨다. 만약 주력으로 사용하던 전략이 어떤 이유로든 실패하거나 실행 불가능해지면, 로봇은 즉시 학습된 다른 대안 전략으로 전환하여 과제를 계속 수행할 수 있다.29 이는 재학습에 드는 막대한 비용 없이도 변화하는 환경에 유연하게 대처할 수 있는 능력을 부여한다. 방법론적으로 이 연구는 상대 엔트로피 정책 탐색(Relative Entropy Policy Search, REPS)과 같은 계층적 정책 탐색 알고리즘을 확장하여, 상위 정책이 여러 하위 정책(옵션) 중 하나를 선택하는 구조를 통해 다중 해법을 효과적으로 학습할 수 있음을 보였다.30 이 논문은 로봇 지능이 단순히 정해진 답을 찾는 것을 넘어, 다양한 가능성을 내포한 ‘해법의 공간’ 자체를 이해하고 활용하는 방향으로 나아가야 함을 제시했다는 점에서 중요한 의미를 가진다.</p>
<table><thead><tr><th>수상명</th><th>수상 논문</th><th>저자</th></tr></thead><tbody>
<tr><td><strong>IROS CoTeSys Cognitive Robotics Best Paper Award (Winner)</strong></td><td>Learning Concurrent Motor Skills in Versatile Solution Spaces</td><td>Christian Daniel, Gerhard Neumann, Jan Peters</td></tr>
<tr><td><strong>IROS 2012 Best Student Paper Award (Finalist)</strong></td><td>Learning Concurrent Motor Skills in Versatile Solution Spaces</td><td>Christian Daniel, Gerhard Neumann, Jan Peters</td></tr>
<tr><td><strong>IROS 2012 Best Paper Award (Finalist)</strong></td><td>Learning Concurrent Motor Skills in Versatile Solution Spaces</td><td>Christian Daniel, Gerhard Neumann, Jan Peters</td></tr>
<tr><td><strong>IROS Harashima Award for Innovative Technologies</strong></td><td>-</td><td>Dr. Christian Laugier</td></tr>
<tr><td><strong>IROS 2012 Best Video Award</strong></td><td>-</td><td>-</td></tr>
</tbody></table>
<p><strong>표 4: IROS 2012 주요 수상 내역</strong> 27</p>
<h3>3.2  인간-로봇 상호작용 및 서비스 로보틱스의 최신 동향</h3>
<p>IROS 2012의 전체적인 프로그램과 워크숍 세션들은 당시 로봇 공학계의 주요 관심사가 어디에 있었는지를 명확히 보여준다. 특히 “인간 환경에서의 보조 및 서비스 로보틱스(Assistance and Service Robotics in a Human Environment)“와 같은 워크숍은 인간과의 물리적, 사회적 상호작용을 위한 기술에 연구가 집중되고 있었음을 시사한다.32</p>
<p>주요 연구 주제들은 다음과 같이 요약될 수 있다. 첫째, <strong>촉각 및 햅틱 기술</strong>에 대한 연구가 활발했다. 로봇이 물체의 재질을 인식하거나33, 섬세한 조작을 수행하기 위해 부드러운 촉각 센서 어레이를 개발하는 연구33, 그리고 원격 조작 시 사용자에게 사실적인 힘 피드백을 제공하는 햅틱 렌더링 기술33 등이 발표되었다. 이는 로봇이 단순히 시각 정보에만 의존하는 것을 넘어, 물리적 접촉을 통해 세상을 이해하고 상호작용하는 능력을 갖추는 것이 중요하게 인식되고 있었음을 보여준다.</p>
<p>둘째, <strong>인간이 있는 환경에서의 자율 주행 및 조작</strong> 기술이 핵심 과제로 다루어졌다. 스마트 환경 내에서 인간형 로봇의 위치를 추정하고 사람들을 추적하며 안전하게 항해하는 기술, 그리고 복잡하고 정돈되지 않은 실제 환경에서 물체를 인식하고 집는 기술 등이 주요 연구 분야였다.32 이는 로봇의 활동 영역이 통제된 공장 환경을 벗어나, 예측 불가능한 요소가 많은 일상 공간으로 확장되고 있음을 의미한다.</p>
<p>셋째, <strong>인간을 위한 보조 및 서비스 로봇</strong>에 대한 구체적인 응용 연구가 다수 발표되었다. 특히 노약자나 장애인을 돕기 위한 로봇 기술이 중요한 축을 형성했다. 여기에는 쇼핑 카트 플랫폼, 전동 휠체어, 로봇 팔 등 개인의 이동성과 일상생활을 지원하는 다양한 형태의 보조 시스템이 포함되었다.32 이는 IROS 2012의 대주제였던 ’삶의 질 향상’이 단순한 구호가 아니라, 실제 연구 개발의 구체적인 목표로 작용하고 있었음을 보여주는 증거이다.</p>
<p>이러한 연구 동향들을 종합해 볼 때, 2012년 4분기의 로봇 공학계는 물리적 세계와의 상호작용, 즉 ’체화된 지능(embodied intelligence)’의 구현이라는 근본적인 문제에 깊이 천착하고 있었다. 이는 같은 시기 머신러닝 커뮤니티가 방대한 양의 정적 데이터를 기반으로 한 ‘인식’ 문제에 집중했던 것과는 뚜렷한 대조를 이룬다.</p>
<p>NeurIPS 2012에서 발표된 연구들은 주로 ImageNet과 같은 거대하고 정적인 데이터셋을 기반으로 한 인식 및 표현 학습에 초점을 맞추었다. AlexNet은 수백만 장의 레이블된 이미지를 사용하여 지도 학습을 수행했고, 멀티모달 DBM은 비지도 학습을 통해 데이터의 잠재 구조를 파악했다. 반면, IROS 2012의 첨단 연구들은 로봇이 물리적 환경과 직접 상호작용하며 스스로 데이터를 생성하고 이를 통해 행동을 학습하는 강화학습에 집중했다. 데이터의 규모 면에서도 극명한 차이가 있었다. AlexNet이 수백만 장의 이미지를 사용한 반면, 로봇 운동 능력 학습은 수백 번의 시행착오(trial)를 통해 이루어졌다.</p>
<p>이러한 차이는 2012년 당시 ‘AI/머신러닝’ 커뮤니티와 ‘로봇 공학’ 커뮤니티가 서로 평행하지만 상당 부분 분리된 궤도를 따라 발전하고 있었음을 시사한다. 딥러닝 ’혁명’은 이 시점에서는 아직 ’인식의 혁명’이었을 뿐, ’행동의 혁명’으로까지는 이어지지 못했다. 이러한 두 분야의 일시적 발산은 향후 10년간의 연구 과제를 예고하는 것이기도 했다. 딥러닝 기반의 강력한 인식 능력을 로봇의 행동 제어 문제에 접목하는 것, 즉 딥 강화학습(Deep Reinforcement Learning)과 같은 융합 연구의 등장은 바로 이 시점의 기술적 간극을 메우려는 노력의 필연적인 결과였다.</p>
<h2>4.  기업 연구소의 기술 혁신: 대규모 AI의 실현</h2>
<p>2012년 4분기는 학계의 이론적 돌파뿐만 아니라, 기업 연구소가 AI 기술을 전례 없는 규모로 확장하고 현실 세계에 적용하는 능력을 과시한 시기이기도 했다. 마이크로소프트와 구글은 각각 다른 방식으로 AI의 스케일 문제를 해결하며, 이론적 가능성을 실제 서비스와 시스템으로 전환하는 데 있어 핵심적인 역할을 수행했다. 이들의 노력은 AI가 더 이상 알고리즘의 우수성만으로 평가받는 분야가 아니라, 이를 뒷받침하는 대규모 컴퓨팅 시스템과 공학적 역량이 필수적인 분야로 진입했음을 알리는 신호탄이었다.</p>
<h3>4.1  Microsoft Research: 심층신경망 기반 실시간 음성-대-음성 번역의 시연</h3>
<p>2012년 10월 25일, 중국 톈진에서 열린 한 컨퍼런스에서 마이크로소프트 리서치의 수장이었던 릭 라시드(Rick Rashid)는 AI 역사에 길이 남을 시연을 선보였다.9 그는 무대 위에서 영어로 연설했고, 그의 목소리는 거의 실시간으로 중국어 음성으로 번역되어 청중에게 전달되었다. 더욱 놀라운 점은, 번역된 중국어 음성이 라시드 본인의 억양과 음색을 유지하고 있었다는 것이다.10 이 시연은 딥러닝, 특히 심층신경망(DNN)이 복잡한 실제 응용 분야에서 얼마나 강력한 성능을 발휘할 수 있는지를 대중과 연구계에 각인시킨 결정적인 사건이었다.</p>
<p>이 기술적 성취의 핵심에는 음성 인식의 음향 모델링(acoustic modeling)에 DNN을 적용한 것이 있었다. 이전까지 음성 인식 시스템은 주로 가우시안 혼합 모델(Gaussian Mixture Models, GMMs)에 기반을 두었는데, 마이크로소프트 연구진은 DNN으로 이를 대체함으로써 단어 오류율(word error rate)을 약 30%나 감소시키는 획기적인 성능 향상을 이루었다.36 DNN은 GMM보다 훨씬 더 복잡하고 미묘한 음성 패턴을 학습할 수 있었고, 이는 번역의 정확도를 높이는 데 결정적인 기여를 했다.</p>
<p>이 시연은 단일 기술의 성공이 아니라, 여러 AI 분야의 연구 성과를 하나의 실시간 시스템으로 통합한 시스템 공학의 승리이기도 했다. 라시드의 영어 음성을 텍스트로 변환하는 ‘음성 인식’, 영어 텍스트를 중국어 텍스트로 번역하는 ‘기계 번역’, 그리고 번역된 중국어 텍스트를 라시드의 목소리로 합성하는 ‘음성 합성’ 기술이 유기적으로 결합되어야만 가능했다.9 이는 수년간에 걸친 마이크로소프트 내 여러 연구소의 협력과 시스템 통합 노력의 결실이었다.</p>
<p>이 시연의 파급력은 상당했다. AlexNet의 ILSVRC 2012 결과가 학계에 알려지기 시작하던 시점에, 마이크로소프트의 시연은 DNN의 추상적인 힘을 일반 대중도 직관적으로 이해할 수 있는 구체적이고 강력한 형태로 보여주었다. 한때 공상 과학의 영역으로 여겨졌던 실시간 통역이 현실화될 수 있다는 가능성을 제시하며, AI 기술에 대한 기대감을 증폭시키는 ’스푸트니크 모멘트’와 같은 역할을 했다.38</p>
<h3>4.2  Google Research: 대규모 분산 딥 네트워크의 구축과 활용</h3>
<p>같은 시기, 구글 리서치는 AI의 또 다른 차원, 즉 ’규모의 한계’를 극복하는 문제에 집중하고 있었다. NeurIPS 2012에서 제프 딘(Jeff Dean) 등이 발표한 “Large Scale Distributed Deep Networks” 논문은 수십억 개의 파라미터를 가진 거대한 신경망을 어떻게 효율적으로 훈련시킬 수 있는지에 대한 공학적 해법을 제시했다.39 이 연구는 2012년 초에 유튜브 이미지 프레임에서 레이블 없이 고양이 얼굴을 스스로 학습해 화제가 되었던 ‘고양이 인식’ 신경망을 가능하게 한 기반 기술, ‘DistBelief’ 프레임워크를 상세히 설명했다.2</p>
<p>DistBelief의 핵심은 대규모 클러스터 환경에서 신경망 훈련을 병렬화하는 두 가지 혁신적인 아이디어에 있었다.</p>
<p>첫째는 **모델 병렬성(Model Parallelism)**이다. 이는 단일 신경망 모델이 너무 커서 하나의 머신 메모리에 담을 수 없을 때, 모델의 뉴런들을 여러 머신에 분산하여 배치하는 방식이다. 각 머신은 모델의 일부만을 계산하고, 필요에 따라 다른 머신과 통신하여 전체 계산을 완료한다.39</p>
<p>둘째는 **데이터 병렬성(Data Parallelism)**이다. 이는 동일한 모델을 여러 개의 복제본으로 만들어 각기 다른 데이터 배치(batch)를 동시에 처리하게 하는 방식이다. 각 복제본은 자신의 데이터로 그래디언트를 계산한 후, 이를 중앙 집중화된 ’파라미터 서버(parameter server)’로 보낸다. 파라미터 서버는 모든 복제본으로부터 받은 그래디언트를 취합하여 모델의 파라미터를 업데이트하고, 업데이트된 파라미터를 다시 모든 복제본에 전송한다.39</p>
<p>이 두 가지 병렬 처리 방식을 결합한 DistBelief 프레임워크는 수천 개의 CPU 코어를 활용하여 이전에는 상상할 수 없었던 규모의 신경망을 훈련하는 것을 가능하게 했다. 이는 AI 연구의 패러다임을 바꾸는 중요한 전환점이었다. 단순히 더 나은 알고리즘을 설계하는 것을 넘어, ’얼마나 더 큰 모델을, 얼마나 더 많은 데이터로 훈련시킬 수 있는가’가 성능을 결정하는 핵심 요소가 되었기 때문이다. 구글의 이 연구는 텐서플로우(TensorFlow)와 같은 후속 딥러닝 프레임워크의 사상적 기반이 되었으며, 오늘날 산업계에서 사용되는 대규모 AI 인프라의 청사진을 제시했다.</p>
<p>2012년 4분기에 나타난 이러한 학계와 산업계의 발전은 알고리즘과 시스템이 어떻게 함께 진화하는지를 명확히 보여준다. AlexNet의 성공은 소비자용 GPU라는 하드웨어의 발전과 최적화된 소프트웨어(CUDA)에 크게 의존했으며, 아키텍처 자체도 GPU 메모리라는 하드웨어 제약에 맞춰 설계되었다.14 반면, 구글의 DistBelief는 대규모 상용 CPU 클러스터라는 인프라를 활용한 소프트웨어적 해법을 제시했다. 마이크로소프트의 시연은 여러 복잡한 AI 컴포넌트를 실시간으로 통합하는 고도의 시스템 엔지니어링 역량을 보여주었다.</p>
<p>이 세 가지 사례는 2012년을 기점으로 AI 발전의 동력이 순수한 알고리즘의 혁신을 넘어, 그 알고리즘을 실행할 수 있는 계산 시스템과의 공생 관계 속에서 나온다는 사실을 분명히 했다. AI는 더 이상 순수 학문 분야에 머무르지 않고, 대규모 시스템 공학이 필수적인 분야로 변모하기 시작했다. ’더 나은 모델은 무엇인가?’라는 질문은 ’훨씬 더 큰 모델을 훈련시킬 시스템을 어떻게 구축할 것인가?’라는 질문과 불가분의 관계가 된 것이다.</p>
<h2>5. 결론: 새로운 시대의 초석</h2>
<p>2012년 4분기는 인공지능 역사에서 하나의 변곡점으로, 새로운 시대의 초석이 놓인 시기로 평가되어야 한다. 이 3개월 동안 학계와 산업계에서 동시다발적으로 일어난 일련의 사건들은 개별적인 성과를 넘어, 서로를 증폭시키고 보완하며 현대 AI 시대를 여는 거대한 흐름을 형성했다.</p>
<p>첫째, NeurIPS 2012에서 발표된 <strong>AlexNet은 딥러닝의 압도적인 경험적 우수성을 만천하에 증명</strong>했다.1 이는 컴퓨터 비전 분야의 오랜 패러다임이었던 수작업 특징 공학의 종말을 고하고, 데이터 기반의 심층 표현 학습 시대를 여는 상징적인 사건이었다. ReLU, 드롭아웃, GPU 활용과 같은 방법론적 혁신은 이후 딥러닝 모델 설계의 표준으로 자리 잡았다.</p>
<p>둘째, 마이크로소프트 리서치가 선보인 <strong>실시간 음성-대-음성 번역 시연은 딥러닝의 실용적 잠재력을 대중에게 각인</strong>시켰다.9 이는 딥러닝이 학술적 호기심을 넘어, 인간의 삶과 소통 방식을 근본적으로 변화시킬 수 있는 강력한 기술임을 보여준 생생한 증거였다.</p>
<p>셋째, 구글 리서치가 공개한 <strong>DistBelief 프레임워크는 산업적 규모의 AI를 위한 시스템 공학적 청사진을 제시</strong>했다.39 이는 AI의 발전이 알고리즘뿐만 아니라, 이를 뒷받침하는 대규모 분산 컴퓨팅 인프라에 의해 좌우됨을 명확히 했다.</p>
<p>넷째, IROS 2012에서 논의된 <strong>로봇의 자율적 운동 능력 학습은 AI의 지능이 가상 세계를 넘어 물리적 세계와의 상호작용으로 확장되어야 함을 상기</strong>시켰다.29 이는 인식(perception)의 혁신이 궁극적으로 행동(action)의 혁신으로 이어져야 한다는 미래의 과제를 제시했다.</p>
<p>이 네 가지 핵심적인 발전은 서로 다른 영역에서 이루어졌지만, 하나의 공통된 방향을 가리키고 있었다. 즉, **알고리즘의 혁신(AlexNet), 계산 능력의 확장(DistBelief), 그리고 야심 찬 응용(Microsoft Demo)**이 결합될 때 폭발적인 시너지가 발생한다는 것이다. 이 시점을 계기로 AI 분야에는 투자와 연구가 집중되는 선순환 구조가 만들어졌고, 이는 오늘날까지 이어지는 AI 발전의 원동력이 되었다.2</p>
<p>결론적으로, 2012년 4분기는 딥러닝이라는 강력한 도구가 학문적 검증을 마치고, 산업적 규모로 확장될 준비를 하며, 현실 세계의 복잡한 문제에 적용되기 시작한 결정적인 시기였다. 당시에는 아직 분리되어 있던 인식, 행동, 그리고 규모라는 세 가지 연구 흐름은 이후 10년간 서로 융합하고 발전하며 우리가 현재 경험하고 있는 AI 시대를 구축하는 견고한 초석이 되었다. 이 시기에 대한 깊이 있는 이해는 현재 AI 기술의 근원을 파악하고 미래의 발전 방향을 예측하는 데 있어 필수적이다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>AlexNet and ImageNet: The Birth of Deep Learning - Pinecone, https://www.pinecone.io/learn/series/image-search/imagenet/</li>
<li>2012: A Breakthrough Year for Deep Learning | by Bryan House - Medium, https://medium.com/neuralmagic/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73</li>
<li>AAAI Conferences Calendar, https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/download/2415/2283</li>
<li>neurips.cc, <a href="https://neurips.cc/Conferences/2012/Dates#:~:text=The%20Twenty-Sixth%20annual%20conference,at%20the%20Harrahs%20and%20Harveys.">https://neurips.cc/Conferences/2012/Dates#:~:text=The%20Twenty%2DSixth%20annual%20conference,at%20the%20Harrahs%20and%20Harveys.</a></li>
<li>2012 Dates and Deadlines - NeurIPS 2025, https://neurips.cc/Conferences/2012/Dates</li>
<li>researchr.org, <a href="https://researchr.org/publication/iros-2012#:~:text=researchers%20by%20researchers.-,2012%20IEEE%2FRSJ%20International%20Conference%20on%20Intelligent%20Robots%20and%20Systems,%2C%20October%207-12%2C%202012">https://researchr.org/publication/iros-2012#:~:text=researchers%20by%20researchers.-,2012%20IEEE%2FRSJ%20International%20Conference%20on%20Intelligent%20Robots%20and%20Systems,%2C%20October%207%2D12%2C%202012</a></li>
<li>IROS 2012 Photos - euRobotics, https://eu-robotics.net/iros-2012-photos/</li>
<li>The opening ceremony of IROS 2012. | Download Scientific Diagram - ResearchGate, https://www.researchgate.net/figure/The-opening-ceremony-of-IROS-2012_fig2_260700781</li>
<li>Microsoft Research Redmond: 2012 in Review - Microsoft Research, https://www.microsoft.com/en-us/research/blog/microsoft-research-redmond-2012-in-review/</li>
<li>Milestones on the Path to Skype Translator - Microsoft Research, https://www.microsoft.com/en-us/research/project/milestones-path-skype-translator/</li>
<li>NIPS 2012 Call For Papers, https://neurips.cc/Conferences/2012/CallForPapers</li>
<li>ImageNet Classification with Deep Convolutional Neural Networks, https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</li>
<li>[NIPS 2012] AlexNet: Review and Implementation | by Quan Hua - Medium, https://medium.com/@quanhua92/alexnet-review-and-implementation-e37a8e4dab54</li>
<li>AlexNet - Wikipedia, https://en.wikipedia.org/wiki/AlexNet</li>
<li>ImageNet Classification with Deep Convolutional Neural Networks, https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</li>
<li>AlexNet.pdf, https://cvml.ista.ac.at/courses/DLWT_W17/material/AlexNet.pdf</li>
<li>Introduction to The Architecture of Alexnet - Analytics Vidhya, https://www.analyticsvidhya.com/blog/2021/03/introduction-to-the-architecture-of-alexnet/</li>
<li>Deep Learning - AlexNet, https://www.doc.ic.ac.uk/~bkainz/teaching/DL/notes/AlexNet.pdf</li>
<li>Paper Explanation : ImageNet Classification with Deep Convolutional Neural Networks (AlexNet) - Mohit Jain, https://mohitjain.me/2018/06/06/alexnet/</li>
<li>A Closer Look at AlexNet, https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/tutorials/tut6_slides.pdf</li>
<li>AlexNet Architecture: A Complete Guide - Kaggle, https://www.kaggle.com/code/blurredmachine/alexnet-architecture-a-complete-guide</li>
<li>Multimodal Learning with Deep Boltzmann Machines - NIPS, https://papers.nips.cc/paper/4683-multimodal-learning-with-deep-boltzmann-machines</li>
<li>Multimodal Learning with Deep Boltzmann Machines, https://jmlr.org/papers/volume15/srivastava14b/srivastava14b.pdf</li>
<li>Multimodal Learning with Deep Boltzmann Machines - CMU School of Computer Science, https://www.cs.cmu.edu/~rsalakhu/papers/Multimodal_DBM.pdf</li>
<li>Multimodal Learning with Deep Boltzmann Machines, https://jmlr.org/papers/v15/srivastava14b.html</li>
<li>Multimodal Learning with Deep Boltzmann Machines | Request PDF - ResearchGate, https://www.researchgate.net/publication/267554204_Multimodal_Learning_with_Deep_Boltzmann_Machines</li>
<li>Christian Daniel, Gerhard Neumann, and Jan Peters: IROS CoTeSys Cognitive Robotics Best Paper Award, IROS 2012 Best Student Paper Award Finalist, and IROS 2012 Best Paper Award Finalist for “Learning Concurrent Motor Skills in Versatile Solution Spaces” at the International Conference on Intelligent Robot Systems (IROS) - Max Planck Institute for Intelligent Systems, https://is.mpg.de/awards/iros-cotesys-cognitive-robotics-best-paper-award</li>
<li>IROS Steering Committee, Awards Chair - Shigeki Sugano (Waseda University), https://ewh.ieee.org/soc/ras/conf/financiallycosponsored/IROS/2012/www.iros2012.org/site/sites/default/files/iros2012_AwardsResults.pdf</li>
<li>Learning Concurrent Motor Skills in Versatile Solution Spaces | Request PDF - ResearchGate, https://www.researchgate.net/publication/232710441_Learning_Concurrent_Motor_Skills_in_Versatile_Solution_Spaces</li>
<li>Information-Theoretic Motor Skill Learning - The Association for the Advancement of Artificial Intelligence, https://cdn.aaai.org/ocs/ws/ws1114/7190-30575-1-PB.pdf</li>
<li>News Awards | Empirical Inference - Max Planck Institute for Intelligent Systems, https://is.mpg.de/ei/post?page=4</li>
<li>IROS 2012 International Workshop on Assistance and Service Robotics in a Human Environment - e-Motion, https://emotion.inrialpes.fr/people/spalanzani/WorkshopIROS12/FW1_main.pdf</li>
<li>2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2012, Vilamoura, Algarve, Portugal, October 7-12, 2012 - Researchr, https://researchr.org/publication/iros-2012</li>
<li>IROS 2012 Accepted Paper List, https://papercopilot.com/paper-list/iros-paper-list/iros-2012-paper-list/</li>
<li>Hsiao-Wuen Hon Archives - Microsoft Research Blog, https://www.microsoft.com/en-us/research/blog/tag/hsiao-wuen-hon/</li>
<li>Microsoft Boosts Speed, Accuracy of Bing Voice Search | PCMag, https://www.pcmag.com/news/microsoft-boosts-speed-accuracy-of-bing-voice-search</li>
<li>speech synthesis Archives - Microsoft Translator Blog, https://www.microsoft.com/zh-cn/translator/blog/tag/speech-synthesis/</li>
<li>Speech-to-Speech Translations Stutter, But Researchers See Mellifluous Future, https://cacm.acm.org/news/speech-to-speech-translations-stutter-but-researchers-see-mellifluous-future/</li>
<li>Excellent Papers for 2012 - Google Research, https://research.google/blog/excellent-papers-for-2012/</li>
<li>A decade in deep learning, and what’s next - Google Blog, https://blog.google/technology/ai/decade-deep-learning-and-whats-next/</li>
<li>Using large-scale brain simulations for machine learning and A.I. - Google Blog, https://blog.google/technology/ai/using-large-scale-brain-simulations-for/</li>
<li>Imagenet classification with deep convolutional neural networks - ResearchGate, https://www.researchgate.net/publication/319770183_Imagenet_classification_with_deep_convolutional_neural_networks</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>