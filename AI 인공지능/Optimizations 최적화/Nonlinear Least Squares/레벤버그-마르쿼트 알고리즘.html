<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:레벤버그-마르쿼트 알고리즘</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>레벤버그-마르쿼트 알고리즘</h1>
                    <nav class="breadcrumbs"><a href="../../../index.html">Home</a> / <a href="../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../index.html">최적화 (Optimizations)</a> / <a href="index.html">비선형최소제곱문제 최적화</a> / <span>레벤버그-마르쿼트 알고리즘</span></nav>
                </div>
            </header>
            <article>
                <h1>레벤버그-마르쿼트 알고리즘</h1>
<h2>1. 부: 최적화 문제의 시작 - 비선형 최소제곱법</h2>
<h3>1.1  풀고자 하는 문제: 데이터 이면에 숨겨진 모델 찾기</h3>
<p>최적화의 여정은 하나의 근본적인 질문에서 시작된다: 주어진 데이터 이면에 숨겨진 패턴이나 법칙은 무엇인가? 우리는 종종 이 법칙을 수학적 ’모델’로 표현하고자 한다. 예를 들어, 어떤 화학 반응의 시간에 따른 농도 변화나, 인구의 성장 곡선, 혹은 로봇 팔의 움직임을 설명하는 모델을 생각할 수 있다.1 이 모델들은 보통 여러 개의 ’파라미터’를 포함하는데, 이 파라미터 값들이 모델의 구체적인 형태를 결정한다. 최적화의 본질은 바로 이 모델의 파라미터들을 조정하여, 모델의 예측이 실제 관측된 데이터와 가장 잘 부합하도록 만드는 과정이다.2</p>
<p>가장 흔한 최적화 문제 중 하나는 곡선 피팅(curve fitting) 또는 비선형 회귀(non-linear regression)이다.3 실험을 통해 얻은 한 쌍의 데이터 포인트 <span class="math math-inline">(t_i, y_i)</span>들이 있다고 가정해보자. 우리의 목표는 이 데이터 포인트들을 가장 잘 설명하는 비선형 모델 함수 <span class="math math-inline">y = f(t, \boldsymbol{\beta})</span>를 찾는 것이다. 여기서 <span class="math math-inline">\boldsymbol{\beta}</span>는 우리가 찾아야 할 모델의 파라미터 벡터다.3 ’가장 잘 설명한다’는 것은 보통 모델의 예측값 <span class="math math-inline">f(t_i,  \boldsymbol{\beta})</span>와 실제 측정값 <span class="math math-inline">y_i</span> 사이의 오차(error)를 최소화하는 것을 의미한다.</p>
<p>이해를 돕기 위해 선형 회귀와 비선형 회귀의 근본적인 차이를 짚고 넘어가자. 선형 회귀 모델, 예를 들어 <span class="math math-inline">y = \beta_0 + \beta_1 x</span>에서는 파라미터 <span class="math math-inline">\beta_1</span>이 1만큼 변할 때 <span class="math math-inline">y</span>의 변화량은 항상 <span class="math math-inline">x</span>로 일정하다. 즉, 파라미터의 영향력이 파라미터 자신의 값에 의존하지 않는다.5 이런 선형성 덕분에 우리는 해석적인 방법(closed-form solution)으로 오차를 최소화하는 파라미터를 한 번에 찾아낼 수 있다.</p>
<p>하지만 세상의 많은 현상은 비선형적이다. 예를 들어, 생물의 성장 곡선을 나타내는 지수 모델 <span class="math math-inline">y = \theta_1 e^{\theta_2 x}</span>를 생각해보자.5 여기서 파라미터 <span class="math math-inline">\theta_2</span>의 변화가 <span class="math math-inline">y</span>에 미치는 영향은 입력 변수 <span class="math math-inline">x</span>뿐만 아니라, 파라미터 <span class="math math-inline">\theta_1</span>과 <span class="math math-inline">\theta_2</span>의 현재 값에 따라서도 달라진다. 이처럼 파라미터에 대해 함수가 선형이 아닌 경우를 ’비선형 모델’이라고 부른다.1 이러한 비선형성 때문에, 대부분의 비선형 문제에서는 최적의 파라미터를 한 번에 계산해내는 마법 같은 공식이 존재하지 않는다. 대신, 우리는 초기 추정치에서 시작하여 점진적으로 더 나은 해를 찾아가는 ‘반복적인(iterative)’ 최적화 알고리즘에 의존해야만 한다.1 레벤버그-마르쿼트 알고리즘은 바로 이 비선형 문제들을 풀기 위해 태어난 강력한 반복적 해법 중 하나다.</p>
<h3>1.2  비선형 최소제곱법(Non-linear Least Squares, NLLS)의 수학적 정의</h3>
<p>비선형 최적화 문제를 수학적으로 명확하게 정의하는 것부터 시작하자. 이것이 우리가 앞으로 다룰 모든 알고리즘의 출발점이다. 비선형 최소제곱법(NLLS)은 <span class="math math-inline">m</span>개의 관측 데이터와 <span class="math math-inline">n</span>개의 미지 파라미터(<span class="math math-inline">m \ge n</span>이라는 가정이 일반적이다)를 포함하는 모델을 다룬다.6</p>
<p>먼저 ’잔차(residual)’라는 개념을 정의해야 한다. <span class="math math-inline">i</span>번째 관측 데이터 쌍 <span class="math math-inline">(x_i, y_i)</span>에 대해, 잔차 <span class="math math-inline">r_i</span>는 실제 관측값 <span class="math math-inline">y_i</span>와 현재 파라미터 <span class="math math-inline">\boldsymbol{\beta}</span>를 사용한 모델의 예측값 <span class="math math-inline">f(x_i, \boldsymbol{\beta})</span> 사이의 차이로 정의된다.9<br />
<span class="math math-display">
r_i(\boldsymbol{\beta}) = y_i - f(x_i, \boldsymbol{\beta})
</span><br />
우리가 가진 <span class="math math-inline">m</span>개의 모든 관측치에 대해 이 잔차들을 계산하여 하나의 벡터, 즉 잔차 벡터 <span class="math math-inline">\mathbf{r}(\boldsymbol{\beta})</span>를 만들 수 있다.<br />
<span class="math math-display">
\mathbf{r}(\boldsymbol{\beta}) = 
\begin{bmatrix}
r_1(\boldsymbol{\beta}) \\
r_2(\boldsymbol{\beta}) \\
\vdots \\
r_m(\boldsymbol{\beta})
\end{bmatrix}
</span><br />
NLLS의 목표는 이 잔차들의 크기를 종합적으로 최소화하는 것이다. 가장 널리 사용되는 방법은 ’잔차 제곱의 합(Sum of Squared Residuals, SSR)’을 최소화하는 것이다. 이 값을 비용 함수(cost function) 또는 목적 함수(objective function) <span class="math math-inline">S(\boldsymbol{\beta})</span>로 정의한다.3<br />
<span class="math math-display">
S(\boldsymbol{\beta}) = \sum_{i=1}^{m} r_i(\boldsymbol{\beta})^2 = \mathbf{r}(\boldsymbol{\beta})^T \mathbf{r}(\boldsymbol{\beta}) = ||\mathbf{r}(\boldsymbol{\beta})||_2^2
</span><br />
이 공식은 각 잔차를 제곱하여 모두 더함으로써, 양수와 음수 잔차가 서로 상쇄되는 것을 막고 모든 오차를 동등하게 고려하는 역할을 한다.11 우리의 최종 목표는 이 비용 함수 <span class="math math-inline">S(\boldsymbol{\beta})</span>를 최소로 만드는 파라미터 벡터 <span class="math math-inline">\boldsymbol{\beta}^*</span>를 찾는 것이다.</p>
<p>미적분학의 기본 원리에 따르면, 어떤 함수의 최소값은 그 함수의 그래디언트(gradient)가 0이 되는 지점에서 나타난다. 따라서 우리는 <span class="math math-inline">\nabla S(\boldsymbol{\beta}) = \mathbf{0}</span> 방정식을 풀면 된다. 하지만 모델 함수 <span class="math math-inline">f</span>가 파라미터 <span class="math math-inline">\boldsymbol{\beta}</span>에 대해 비선형이기 때문에, 그래디언트 방정식 역시 복잡한 비선형 연립방정식이 되어 직접 풀기가 거의 불가능하다.6 이것이 바로 우리가 경사 하강법, 가우스-뉴턴법, 그리고 레벤버그-마르쿼트법과 같은 반복적 해법을 필요로 하는 근본적인 이유다.</p>
<p>여기서 한 가지 중요한 점을 짚고 넘어가야 한다. NLLS 문제는 일반적인 최적화 문제 <span class="math math-inline">min f(x)</span>와는 다른, 매우 ‘구조화된(structured)’ 형태를 띤다. 비용 함수가 항상 ‘어떤 벡터의 <span class="math math-inline">L_2</span>-norm 제곱’ 형태라는 점이다. 이 특별한 구조는 그냥 주어진 것이 아니다. 이 구조 덕분에 우리는 비용 함수의 2차 미분 정보(헤시안 행렬)를 단지 1차 미분 정보(자코비안 행렬)만으로 매우 효과적으로 ’근사’할 수 있다. 이 근사야말로 가우스-뉴턴법과 레벤버그-마르쿼트 알고리즘의 심장과도 같은 핵심 아이디어다. 즉, NLLS 문제의 ‘구조’ 자체가 더 효율적이고 강력한 알고리즘의 탄생을 가능하게 한 것이다. 이 점을 이해하는 것은 왜 LM 알고리즘이 곡선 피팅이나 컴퓨터 비전의 번들 조정과 같은 특정 분야에서 절대적인 표준으로 자리 잡았는지를 이해하는 첫걸음이 될 것이다.</p>
<h2>2. 부: 두 거인의 어깨 위에서 - 경사 하강법과 가우스-뉴턴법</h2>
<p>레벤버그-마르쿼트(LM) 알고리즘은 독창적인 발명이라기보다는, 기존에 존재하던 두 가지 강력한 최적화 방법론, 즉 ’경사 하강법(Gradient Descent)’과 ’가우스-뉴턴법(Gauss-Newton)’의 장점을 지능적으로 결합한 진화의 산물이다.2 LM의 정수를 이해하기 위해서는 먼저 그 부모 격인 두 알고리즘의 원리와 장단점을 명확히 파악해야 한다.</p>
<h3>2.1  가장 기본적인 첫걸음: 경사 하강법 (Gradient Descent, GD)</h3>
<p>경사 하강법은 최적화 세계의 ’아담’과도 같은 가장 근본적인 알고리즘이다. 그 원리는 놀라울 정도로 직관적이다. 짙은 안개가 낀 산 정상에서 길을 잃었다고 상상해보자. 가장 빨리 하산하는 방법은 무엇일까? 바로 현재 위치에서 발밑을 더듬어 가장 가파른 내리막길 방향을 찾고, 그 방향으로 조심스럽게 한 걸음 내딛는 것이다. 이 과정을 계속 반복하면 언젠가는 산 아래 계곡(최소점)에 도달할 것이다.13</p>
<p>이 비유를 수학적으로 옮겨보자. 비용 함수 <span class="math math-inline">S(\boldsymbol{\beta})</span>라는 ’지형’이 있을 때, 현재 위치 <span class="math math-inline">\boldsymbol{\beta}_k</span>에서 가장 가파른 내리막 방향은 음의 그래디언트(negative gradient) 방향, 즉 <span class="math math-inline">-\nabla S(\boldsymbol{\beta}_k)</span>이다.13 따라서 경사 하강법의 업데이트 규칙은 현재 위치에서 이 방향으로 학습률(learning rate) <span class="math math-inline">\eta</span>만큼 이동하는 것이다.15<br />
<span class="math math-display">
\boldsymbol{\beta}_{k+1} = \boldsymbol{\beta}_k - \eta \nabla S(\boldsymbol{\beta}_k)
</span><br />
비선형 최소제곱 문제에서 비용 함수의 그래디언트는 <span class="math math-inline">\nabla S(\boldsymbol{\beta}) = 2\mathbf{J}^T\mathbf{r}</span>로 계산된다. 여기서 <span class="math math-inline">\mathbf{J}</span>는 잔차 벡터 <span class="math math-inline">\mathbf{r}</span>을 파라미터 <span class="math math-inline">\boldsymbol{\beta}</span>로 미분한 자코비안 행렬(Jacobian matrix)이고, <span class="math math-inline">\mathbf{r}</span>은 잔차 벡터다.2 따라서 NLLS 문제에 대한 경사 하강법 업데이트는 다음과 같이 표현할 수 있다.<br />
<span class="math math-display">
\boldsymbol{\beta}_{k+1} = \boldsymbol{\beta}_k - \alpha \mathbf{J}^T \mathbf{r}
</span><br />
여기서 <span class="math math-inline">\alpha = 2\eta</span>는 스텝 크기를 조절하는 상수다.</p>
<p><strong>장점:</strong></p>
<ul>
<li><strong>단순성과 보편성:</strong> 구현이 매우 간단하며, 함수가 미분 가능하다면 어떤 종류의 최적화 문제에도 적용할 수 있다.13</li>
<li><strong>안정적인 수렴:</strong> 적절한 학습률을 선택하고 함수가 좋은 성질(예: 볼록성)을 가지면, 지역 최소점(local minimum)으로의 수렴이 보장된다.13</li>
</ul>
<p><strong>단점:</strong></p>
<ul>
<li><strong>느린 수렴 속도:</strong> 경사 하강법은 ’선형 수렴(linear convergence)’하는데, 이는 해에 가까워질수록 수렴 속도가 현저히 느려짐을 의미한다.18</li>
<li><strong>지그재그 현상:</strong> 비용 함수의 등고선이 한쪽으로 길게 늘어진 좁은 타원 형태(ill-conditioned)일 경우, 그래디언트 방향은 최소점을 직접 가리키지 않고 계곡의 양쪽 벽을 반복적으로 오가는 ‘지그재그’ 경로를 그리게 된다. 이는 매우 비효율적인 탐색으로 이어진다.13</li>
<li><strong>학습률 민감도:</strong> 학습률 <span class="math math-inline">\eta</span>의 선택이 매우 중요하다. 너무 작으면 수렴에 영겁의 시간이 걸리고, 너무 크면 최적점을 지나쳐 버리거나 아예 발산해 버릴 수 있다.14</li>
</ul>
<p>경사 하강법은 느리지만 확실하게 나아가는 ’거북이’와 같다. 안정적이지만, 때로는 답답할 정도로 느리다.</p>
<h3>2.2  과감한 도약: 가우스-뉴턴법 (Gauss-Newton Method, GN)</h3>
<p>경사 하강법의 느린 속도에 대한 해답으로 등장한 것이 가우스-뉴턴법이다. 이 방법은 비선형 최소제곱 문제의 ’구조’를 적극적으로 활용하여 더 과감하고 빠른 걸음을 내딛는다.</p>
<p>가우스-뉴턴법의 핵심 아이디어는 각 반복 단계에서 복잡한 비선형 함수를 다루기 쉬운 ’선형 함수’로 근사하는 것이다.7 현재 파라미터 <span class="math math-inline">\boldsymbol{\beta}_k</span> 근방에서 잔차 함수 <span class="math math-inline">\mathbf{r}(\boldsymbol{\beta})</span>를 1차 테일러 전개를 이용해 선형으로 근사할 수 있다.<br />
<span class="math math-display">
\mathbf{r}(\boldsymbol{\beta}_k + \boldsymbol{\delta}) \approx \mathbf{r}(\boldsymbol{\beta}_k) + \mathbf{J}(\boldsymbol{\beta}_k)\boldsymbol{\delta}
</span><br />
여기서 <span class="math math-inline">\mathbf{J}(\boldsymbol{\beta}_k)</span>는 현재 위치에서의 자코비안 행렬이고, <span class="math math-inline">\boldsymbol{\delta}</span>는 우리가 찾아야 할 업데이트 스텝이다. 이제 이 선형 근사식을 원래의 비용 함수 <span class="math math-inline">S(\boldsymbol{\beta}) = ||\mathbf{r}(\boldsymbol{\beta})||^2</span>에 대입하면, 비용 함수는 업데이트 스텝 <span class="math math-inline">\boldsymbol{\delta}</span>에 대한 간단한 2차 함수(quadratic function)로 근사된다.<br />
<span class="math math-display">
(\boldsymbol{\beta}_k + \boldsymbol{\delta}) \approx ||\mathbf{r}_k + \mathbf{J}_k\boldsymbol{\delta}||^2
</span><br />
이 2차 함수를 최소화하는 <span class="math math-inline">\boldsymbol{\delta}</span>는 선형 최소제곱 문제를 푸는 것과 같으며, 그 해는 다음의 ’정규방정식(Normal Equations)’을 만족한다.9<br />
<span class="math math-display">
(\mathbf{J}_k^T \mathbf{J}_k) \boldsymbol{\delta} = -\mathbf{J}_k^T \mathbf{r}_k
</span><br />
이 선형 연립방정식을 풀어서 얻은 <span class="math math-inline">\boldsymbol{\delta}</span>를 이용해 파라미터를 업데이트한다: <span class="math math-inline">\boldsymbol{\beta}_{k+1} = \boldsymbol{\beta}_k + \boldsymbol{\delta}</span>.</p>
<p><strong>장점:</strong></p>
<ul>
<li><strong>2차 미분 불필요:</strong> 뉴턴법과 달리, 비용 함수의 실제 헤시안(2차 미분)을 계산할 필요가 없다. 자코비안(1차 미분)만으로 헤시안의 주요 부분(<span class="math math-inline">\mathbf{J}^T \mathbf{J}</span>)을 근사한다. 이는 계산 비용을 크게 절감시킨다.9</li>
<li><strong>빠른 수렴 속도:</strong> 잔차가 최종적으로 0에 가까워지는 문제(small residual problems)에서는 2차 수렴(quadratic convergence)에 가까운 매우 빠른 수렴 속도를 보인다.9 이는 해 근처에서 경사 하강법과는 비교할 수 없을 정도로 빠르게 최적해를 찾아냄을 의미한다.</li>
</ul>
<p><strong>단점:</strong></p>
<ul>
<li><strong><span class="math math-inline">\mathbf{J}^T \mathbf{J}</span>의 불안정성:</strong> 가우스-뉴턴법의 아킬레스건이다. 만약 자코비안 행렬 <span class="math math-inline">\mathbf{J}_k</span>의 열들이 선형 종속이거나 거의 그럴 경우, 행렬 <span class="math math-inline">\mathbf{J}_k^T \mathbf{J}_k</span>는 특이(singular) 행렬이 되거나 조건이 나쁜(ill-conditioned) 행렬이 된다. 이 경우 역행렬이 존재하지 않거나 수치적으로 불안정하여 업데이트 스텝 <span class="math math-inline">\boldsymbol{\delta}</span>를 계산할 수 없게 된다.9</li>
<li><strong>수렴 보장 안됨:</strong> 경사 하강법과 달리 수렴이 보장되지 않는다. 초기 추정치가 해에서 멀리 떨어져 있거나, 문제의 비선형성이 매우 클 경우 쉽게 발산할 수 있다.9</li>
</ul>
<p>가우스-뉴턴법은 빠르지만 무모한 ’토끼’와 같다. 조건이 좋을 때는 눈 깜짝할 사이에 결승선에 도착하지만, 예상치 못한 장애물을 만나면 쉽게 넘어져 버린다.</p>
<h3>2.3  비교 분석: 왜 새로운 알고리즘이 필요한가?</h3>
<p>경사 하강법과 가우스-뉴턴법은 마치 동전의 양면과 같다. 한쪽은 안정성을 얻는 대신 속도를 희생하고, 다른 한쪽은 속도를 얻는 대신 안정성을 포기한다.</p>
<table><thead><tr><th>특징</th><th>경사 하강법 (Gradient Descent)</th><th>가우스-뉴턴법 (Gauss-Newton)</th></tr></thead><tbody>
<tr><td><strong>기반 원리</strong></td><td>1차 미분 (그래디언트)</td><td>1차 미분 기반의 2차 근사 (자코비안)</td></tr>
<tr><td><strong>업데이트 방향</strong></td><td>가장 가파른 하강 방향</td><td>선형화된 문제의 최소제곱 해</td></tr>
<tr><td><strong>수렴 속도</strong></td><td>선형 (느림)</td><td>2차에 가까움 (빠름, 단 조건부)</td></tr>
<tr><td><strong>안정성</strong></td><td>높음 (수렴 보장)</td><td>낮음 (발산 위험)</td></tr>
<tr><td><strong>핵심 계산</strong></td><td>그래디언트 계산</td><td>자코비안 및 선형 시스템 풀이</td></tr>
<tr><td><strong>치명적 약점</strong></td><td>지그재그 현상, 느린 수렴</td><td><span class="math math-inline">\mathbf{J}^T \mathbf{J}</span>가 특이/ill-conditioned일 때 실패</td></tr>
<tr><td><strong>적합한 상황</strong></td><td>해에서 멀리 떨어져 있을 때</td><td>해에 가깝고 잔차가 작을 때</td></tr>
</tbody></table>
<p>이 명백한 트레이드오프는 새로운 알고리즘의 필요성을 명확히 보여준다. 이상적인 최적화 알고리즘은 상황에 따라 자신의 모습을 바꿀 수 있어야 한다. 즉, 최적해에서 멀리 떨어져 있어 지형이 험난할 때는 경사 하강법처럼 조심스럽고 안정적인 걸음을 내딛고, 최적해 근처에 도달하여 지형이 부드러운 2차 함수와 비슷해지면 가우스-뉴턴법처럼 빠르고 과감한 도약을 하는 ‘적응형(adaptive)’ 전략이 필요하다.12</p>
<p>이것이 바로 레벤버그-마르쿼트 알고리즘이 해결하고자 하는 핵심 과제이며, 그 탄생의 배경이다. LM은 두 거인의 어깨 위에 서서 더 멀리, 더 정확하게 보려는 시도다.</p>
<h2>3. 부: 레벤버그-마르쿼트 알고리즘의 모든 것</h2>
<p>레벤버그-마르쿼트(LM) 알고리즘은 경사 하강법의 안정성과 가우스-뉴턴법의 속도를 결합하려는 시도에서 탄생한, 비선형 최소제곱 문제 해결을 위한 정교한 해법이다. 이 알고리즘의 핵심은 두 방법 사이를 동적으로 ’보간(interpolation)’하는 영리한 메커니즘에 있다.2</p>
<h3>3.1  핵심 아이디어: 두 방법의 지능적인 결합</h3>
<p>LM 알고리즘의 천재성은 가우스-뉴턴의 정규방정식에 단 하나의 항, ’감쇠 항(damping term)’을 추가한 데서 비롯된다. 이 작은 변화가 알고리즘의 행동 전체를 극적으로 바꾼다.2</p>
<p>가우스-뉴턴법의 업데이트 스텝 <span class="math math-inline">\boldsymbol{\delta}</span>는 <span class="math math-inline">(\mathbf{J}^T \mathbf{J}) \boldsymbol{\delta} = -\mathbf{J}^T \mathbf{r}</span>을 풀어 구한다. LM은 여기에 감쇠 인자(damping parameter) <span class="math math-inline">\lambda</span> (람다)를 이용한 항을 추가하여 다음과 같은 ’증강된 정규방정식(augmented normal equations)’을 사용한다.3<br />
<span class="math math-display">
(\mathbf{J}^T \mathbf{J} + \lambda \mathbf{I}) \boldsymbol{\delta} = -\mathbf{J}^T \mathbf{r}
</span><br />
여기서 <span class="math math-inline">\mathbf{I}</span>는 단위 행렬(identity matrix)이다. 이 감쇠 인자 <span class="math math-inline">\lambda</span>가 바로 LM 알고리즘의 조종간 역할을 한다. <span class="math math-inline">\lambda</span>의 값에 따라 알고리즘은 경사 하강법과 가우스-뉴턴법 사이에서 자신의 정체성을 바꾼다.23</p>
<ul>
<li><strong><span class="math math-inline">\lambda</span>가 클 때 (경사 하강법 모드):</strong> <span class="math math-inline">\lambda</span> 값이 매우 커지면(<span class="math math-inline">\lambda \to \infty</span>), 행렬 <span class="math math-inline">(\mathbf{J}^T \mathbf{J} + \lambda \mathbf{I})</span>에서 <span class="math math-inline">\lambda \mathbf{I}</span> 항이 지배적인 역할을 하게 된다. 이 경우, 업데이트 스텝은 <span class="math math-inline">\boldsymbol{\delta} \approx -\frac{1}{\lambda}(\mathbf{J}^T \mathbf{r})</span>가 된다. 이는 방향이 음의 그래디언트(<span class="math math-inline">-\nabla S = -2\mathbf{J}^T\mathbf{r}</span>)와 같고, 스텝 크기가 <span class="math math-inline">\lambda</span>에 반비례하여 매우 작은, 전형적인 경사 하강법 스텝이다.2 이 모드는 현재 위치가 최적해에서 멀리 떨어져 있거나, 가우스-뉴턴 스텝이 실패했을 때 알고리즘이 발산하지 않고 안정적으로 비용 함수를 감소시키는 방향으로 나아가도록 보장해준다.</li>
<li><strong><span class="math math-inline">\lambda</span>가 작을 때 (가우스-뉴턴 모드):</strong> <span class="math math-inline">\lambda</span> 값이 0에 가까워지면(<span class="math math-inline">\lambda \to 0</span>), <span class="math math-inline">\lambda \mathbf{I}</span> 항은 무시할 수 있을 만큼 작아지고, 증강된 정규방정식은 원래의 가우스-뉴턴 정규방정식과 거의 동일해진다.2 이 모드는 최적해 근처의 잘 동작하는 영역에서 가우스-뉴턴법의 빠른 수렴 속도를 최대한 활용하기 위해 사용된다.</li>
</ul>
<p>이러한 하이브리드 동작은 ’신뢰 영역(Trust Region)’이라는 더 넓은 최적화 프레임워크 관점에서도 해석될 수 있다.26 각 반복 단계에서, 우리는 현재의 선형 근사 모델이 유효하다고 믿는 ’신뢰 영역’이라는 가상의 반경(</p>
<p><span class="math math-inline">\Delta_k</span>)을 설정한다. 그리고 이 영역 내에서 비용 함수를 가장 많이 줄이는 스텝을 찾는다. 감쇠 인자 <span class="math math-inline">\lambda</span>는 이 신뢰 영역의 크기와 간접적으로 연결되어 있다. 스텝이 성공적이면 모델을 더 신뢰할 수 있으므로 신뢰 영역을 넓히고(<span class="math math-inline">\lambda</span>를 줄이고), 스텝이 실패하면 모델을 덜 신뢰해야 하므로 신뢰 영역을 좁힌다(<span class="math math-inline">\lambda</span>를 늘린다). 이처럼 LM은 매 스텝마다 자신의 보폭과 방향을 데이터에 기반하여 스스로 조절하는 ‘지능형’ 알고리즘인 것이다.</p>
<h3>3.2  수학적 원리와 유도 과정</h3>
<p>LM 알고리즘의 발전 과정을 살펴보면, 실용적인 문제 해결에서 출발하여 점차 정교한 이론으로 발전해 나갔음을 알 수 있다. 이는 발견법(heuristic)과 이론(theory)의 절묘한 조화를 보여준다.</p>
<ul>
<li>
<p><strong>Levenberg의 제안 (1944):</strong> Kenneth Levenberg는 가우스-뉴턴법의 가장 큰 약점, 즉 <span class="math math-inline">\mathbf{J}^T \mathbf{J}</span> 행렬이 특이 행렬이 되어 스텝을 계산할 수 없는 문제를 해결하고자 했다.3 그의 아이디어는 간단했다. 행렬의 대각선에 작은 양수 값 <span class="math math-inline">\lambda</span>를 더해주는 것이다.<br />
<span class="math math-display">
(\mathbf{J}^T \mathbf{J} + \lambda \mathbf{I}) \boldsymbol{\delta} = -\mathbf{J}^T \mathbf{r}
</span><br />
수학적으로, 양의 준정부호(positive semi-definite) 행렬인 <span class="math math-inline">\mathbf{J}^T \mathbf{J}</span>에 양의 정부호(positive definite) 행렬인 <span class="math math-inline">\lambda \mathbf{I}</span>(<span class="math math-inline">\lambda &gt; 0</span>)를 더하면, 그 결과인 <span class="math math-inline">(\mathbf{J}^T \mathbf{J} + \lambda \mathbf{I})</span>는 항상 양의 정부호가 된다. 양의 정부호 행렬은 항상 역행렬이 존재하므로, 이 수정된 방정식은 언제나 유일한 해 <span class="math math-inline">\boldsymbol{\delta}</span>를 보장한다.21 이는 가우스-뉴턴법이 실패하는 상황에 대한 실용적이고 강력한 ’안전장치’를 마련한 것이다.</p>
</li>
<li>
<p><strong>Marquardt의 개선 (1963):</strong> Donald Marquardt는 Levenberg의 아이디어를 한 단계 더 발전시켰다.27 그는 두 가지 중요한 기여를 했다. 첫째, 그는</p>
</li>
</ul>
<p><span class="math math-inline">\lambda</span> 값을 고정하지 않고, 매 반복마다 스텝의 성공 여부에 따라 동적으로 조절하는 전략을 제안했다. 성공하면 <span class="math math-inline">\lambda</span>를 줄여 가우스-뉴턴에 가깝게 만들고, 실패하면 <span class="math math-inline">\lambda</span>를 늘려 경사 하강법에 가깝게 만드는 이 발견적 규칙은 LM 알고리즘의 적응성의 핵심이 되었다.11 둘째, 그는 파라미터들의 스케일이 크게 다를 때 발생하는 문제를 해결하기 위해, 단위 행렬</p>
<p><span class="math math-inline">\mathbf{I}</span> 대신 <span class="math math-inline">\mathbf{J}^T \mathbf{J}</span>의 대각 성분으로 구성된 행렬 <span class="math math-inline">\text{diag}(\mathbf{J}^T \mathbf{J})</span>을 사용하는 스케일링 기법을 제안했다.3<br />
<span class="math math-display">
  (\mathbf{J}^T \mathbf{J} + \lambda \, \text{diag}(\mathbf{J}^T \mathbf{J})) \boldsymbol{\delta} = -\mathbf{J}^T \mathbf{r}
</span><br />
이 스케일링은 그래디언트가 작은 방향(비용 함수가 평평한 방향)으로 더 큰 스텝을 내딛도록 유도하여, 좁고 긴 계곡 형태의 비용 함수에서 수렴을 가속하는 효과를 가져온다.</p>
<p>이처럼 LM 알고리즘은 처음에는 실용적인 ’땜질’처럼 보였던 아이디어에서 출발했지만, 나중에 신뢰 영역 방법론이라는 견고한 수학적 기반 위에서 설명될 수 있음이 밝혀졌다. 이는 잘 만들어진 발견법이 종종 깊은 이론적 통찰을 내포하고 있음을 보여주는 좋은 예다.</p>
<table><thead><tr><th><span class="math math-inline">\lambda</span> 값</th><th>알고리즘 행동</th><th>스텝의 특징</th><th>목적</th></tr></thead><tbody>
<tr><td><strong>크다 (e.g., <span class="math math-inline">10^4</span>)</strong></td><td>경사 하강법(GD)에 가까움</td><td>방향: <span class="math math-inline">-\nabla S</span> / 크기: 작음</td><td>안정성 확보, 발산 방지</td></tr>
<tr><td><strong>중간</strong></td><td>GD와 GN의 혼합</td><td>-</td><td>안정성과 속도의 균형</td></tr>
<tr><td><strong>작다 (e.g., <span class="math math-inline">10^{-3}</span>)</strong></td><td>가우스-뉴턴법(GN)에 가까움</td><td>방향: GN 스텝 / 크기: 큼</td><td>빠른 수렴</td></tr>
<tr><td><strong>0</strong></td><td>순수 가우스-뉴턴법</td><td>GN 스텝</td><td>가장 빠른 수렴 (성공 시)</td></tr>
</tbody></table>
<h3>3.3  알고리즘의 단계별 절차</h3>
<p>LM 알고리즘의 전체 흐름을 의사 코드(pseudo-code) 형태로 정리하면 다음과 같다. 이 절차는 알고리즘의 핵심 로직을 명확하게 보여준다.2</p>
<ol>
<li><strong>초기화:</strong></li>
</ol>
<ul>
<li>사용자로부터 초기 파라미터 추정치 <span class="math math-inline">\boldsymbol{\beta}_0</span>, 데이터 <span class="math math-inline">(x_i, y_i)</span>를 입력받는다.</li>
<li>초기 감쇠 인자 <span class="math math-inline">\lambda_0</span> (예: <span class="math math-inline">10^{-3}</span>), 업데이트 팩터 <span class="math math-inline">\nu</span> (예: <span class="math math-inline">10</span>), 그리고 수렴 판정을 위한 허용 오차들(<span class="math math-inline">\epsilon_1, \epsilon_2, \epsilon_3</span>)을 설정한다.</li>
<li>초기 파라미터에 대한 비용 <span class="math math-inline">S(\boldsymbol{\beta}_0)</span>를 계산한다.</li>
<li>반복 횟수 카운터 <span class="math math-inline">k=0</span>으로 설정한다.</li>
</ul>
<ol start="2">
<li><strong>반복 루프 시작:</strong> (수렴 조건이 만족되거나 최대 반복 횟수에 도달할 때까지)</li>
<li><strong>현재 상태 계산:</strong> 현재 파라미터 <span class="math math-inline">\boldsymbol{\beta}_k</span>에서 자코비안 행렬 <span class="math math-inline">\mathbf{J}_k</span>와 잔차 벡터 <span class="math math-inline">\mathbf{r}_k</span>를 계산한다. 근사 헤시안 <span class="math math-inline">\mathbf{A}_k = \mathbf{J}_k^T \mathbf{J}_k</span>와 그래디언트 벡터 <span class="math math-inline">\mathbf{g}_k = \mathbf{J}_k^T \mathbf{r}_k</span>를 구한다.</li>
<li><strong>업데이트 스텝 <span class="math math-inline">\boldsymbol{\delta}</span> 계산:</strong> 증강된 정규방정식 <span class="math math-inline">(\mathbf{A}_k + \lambda_k \mathbf{I}) \boldsymbol{\delta} = -\mathbf{g}_k</span>를 풀어 업데이트 스텝 <span class="math math-inline">\boldsymbol{\delta}</span>를 구한다. 이 단계가 LM 알고리즘의 주요 계산 병목 지점이다. 파라미터의 개수가 <span class="math math-inline">n</span>일 때, 이 <span class="math math-inline">n \times n</span> 선형 시스템을 푸는 데는 일반적으로 <span class="math math-inline">O(n^3)</span>의 계산 복잡도가 요구된다.28</li>
<li><strong>예상 파라미터 평가:</strong></li>
</ol>
<ul>
<li>새로운 파라미터 후보 <span class="math math-inline">\boldsymbol{\beta}_{new} = \boldsymbol{\beta}_k + \boldsymbol{\delta}</span>를 계산한다.</li>
<li>이 새로운 후보에 대한 비용 <span class="math math-inline">S(\boldsymbol{\beta}_{new})</span>를 계산한다.</li>
</ul>
<ol start="6">
<li><strong>스텝 평가 및 <span class="math math-inline">\lambda</span> 업데이트:</strong></li>
</ol>
<ul>
<li><strong>만약 <span class="math math-inline">S(\boldsymbol{\beta}_{new}) &lt; S(\boldsymbol{\beta}_k)</span> 라면 (스텝 성공):</strong></li>
<li>업데이트를 수용한다: <span class="math math-inline">\boldsymbol{\beta}_{k+1} = \boldsymbol{\beta}_{new}</span>.</li>
<li>현재의 선형 근사가 잘 맞았다는 의미이므로, 다음 스텝에서는 더 과감하게 움직이기 위해 감쇠 인자를 줄인다: <span class="math math-inline">\lambda_{k+1} = \lambda_k / \nu</span>.</li>
<li><strong>만약 <span class="math math-inline">S(\boldsymbol{\beta}_{new}) \ge S(\boldsymbol{\beta}_k)</span> 라면 (스텝 실패):</strong></li>
<li>업데이트를 거부하고 현재 파라미터를 유지한다: <span class="math math-inline">\boldsymbol{\beta}_{k+1} = \boldsymbol{\beta}_k</span>.</li>
<li>현재의 선형 근사가 현실과 맞지 않았다는 의미이므로, 다음 스텝에서는 더 보수적으로 움직이기 위해 감쇠 인자를 늘린다: <span class="math math-inline">\lambda_{k+1} = \lambda_k \cdot \nu</span>.</li>
</ul>
<ol start="7">
<li><strong>수렴 조건 확인:</strong> 다음 조건 중 하나라도 만족하면 루프를 종료한다.12</li>
</ol>
<ul>
<li>그래디언트 크기가 매우 작을 때: <span class="math math-inline">||\mathbf{g}_k||_\infty \le \epsilon_1</span>.</li>
<li>파라미터 변화량이 매우 작을 때: <span class="math math-inline">||\boldsymbol{\delta}||_2 \le \epsilon_2 (||\boldsymbol{\beta}_k||_2 + \epsilon_2)</span>.</li>
<li>비용 함수 값 자체가 매우 작을 때: <span class="math math-inline">S(\boldsymbol{\beta}_k) \le \epsilon_3</span>.</li>
<li>최대 반복 횟수(<span class="math math-inline">k_{max}</span>)에 도달했을 때.</li>
</ul>
<ol start="8">
<li><strong>종료:</strong> 최적화된 파라미터 <span class="math math-inline">\boldsymbol{\beta}_{k+1}</span>을 반환한다.</li>
</ol>
<p>이 단계별 절차는 LM 알고리즘이 어떻게 안정성과 속도 사이에서 외줄타기를 하는지를 구체적으로 보여준다. 성공과 실패의 피드백을 통해 감쇠 인자 <span class="math math-inline">\lambda</span>를 끊임없이 조절하며, 문제의 지형에 가장 적합한 방식으로 최적해를 향해 나아가는 것이다.</p>
<h2>4. 부: 실제 문제에 적용하기</h2>
<p>이론적 원리를 이해했다면, 이제 레벤버그-마르쿼트(LM) 알고리즘이 실제 세계의 문제들을 어떻게 해결하는지 구체적인 사례를 통해 살펴볼 차례다. LM은 특히 비선형 회귀, 컴퓨터 비전, 인공신경망 학습과 같은 분야에서 그 진가를 발휘한다.</p>
<h3>4.1  사례 연구 1: 비선형 회귀 (Non-linear Regression)</h3>
<p>LM 알고리즘의 가장 고전적이고 직관적인 적용 분야는 데이터 피팅, 즉 비선형 회귀다.3 실험 데이터에 비선형 모델을 맞추는 과정은 LM의 작동 방식을 시각적으로 이해하는 데 매우 효과적이다.</p>
<p>문제 설정:</p>
<p>생화학에서 효소의 반응 속도를 모델링하는 데 널리 쓰이는 Michaelis-Menten 방정식을 예로 들어보자.5 이 모델은 기질 농도 <span class="math math-inline">S</span>에 따른 반응 속도 <span class="math math-inline">R</span>을 다음과 같이 설명한다.<br />
<span class="math math-display">
R = \frac{V_{max} S}{K_M + S}
</span><br />
여기서 우리가 찾아야 할 파라미터는 최대 반응 속도 <span class="math math-inline">V_{max}</span>와 Michaelis 상수 <span class="math math-inline">K_M</span>이다. 즉, 파라미터 벡터는 <span class="math math-inline">\boldsymbol{\beta} = [V_{max}, K_M]^T</span>이다. 실험을 통해 여러 농도 <span class="math math-inline">S_i</span>에 대한 반응 속도 <span class="math math-inline">R_i</span> 데이터를 얻었다고 가정하자. 우리의 목표는 이 데이터에 가장 잘 맞는 <span class="math math-inline">V_{max}</span>와 <span class="math math-inline">K_M</span>을 찾는 것이다.</p>
<p><strong>구현 단계:</strong></p>
<ol>
<li>
<p><strong>모델 및 잔차 함수 정의:</strong> 모델 함수 <span class="math math-inline">f(\boldsymbol{\beta}, S_i) = \frac{\beta_1 S_i}{\beta_2 + S_i}</span>와 잔차 함수 <span class="math math-inline">r_i(\boldsymbol{\beta}) = R_i - f(\boldsymbol{\beta}, S_i)</span>를 정의한다.29</p>
</li>
<li>
<p><strong>자코비안 행렬 계산:</strong> 잔차 함수를 각 파라미터로 편미분하여 자코비안 행렬 <span class="math math-inline">\mathbf{J}</span>를 구한다.<br />
<span class="math math-display">
\mathbf{J}_{i,1} = \frac{\partial r_i}{\partial \beta_1} = - \frac{S_i}{\beta_2 + S_i}
</span></p>
<p><span class="math math-display">
\mathbf{J}_{i,2} = \frac{\partial r_i}{\partial \beta_2} = \frac{\beta_1 S_i}{(\beta_2 + S_i)^2}
</span></p>
</li>
</ol>
<p><strong>초기 추정치 설정:</strong> LM과 같은 반복 알고리즘은 시작점이 매우 중요하다. 좋은 초기 추정치는 수렴 속도를 높이고, 나쁜 추정치는 알고리즘을 엉뚱한 지역 최소점(local minimum)으로 이끌거나 수렴에 실패하게 할 수 있다.1 문제에 대한 사전 지식을 활용하거나, 모델을 선형화하여 대략적인 값을 구하는 등의 방법으로 합리적인 초기 추정치</p>
<p><span class="math math-inline">\boldsymbol{\beta}_0</span>를 설정해야 한다.</p>
<ol start="3">
<li><strong>LM 알고리즘 적용:</strong> 설정된 초기값과 데이터를 가지고 3.3절에서 설명한 LM 알고리즘을 반복적으로 적용한다. 각 반복마다 비용 함수 <span class="math math-inline">S(\boldsymbol{\beta})</span>의 값과 감쇠 인자 <span class="math math-inline">\lambda</span>의 변화를 관찰하면, 알고리즘이 어떻게 최적해를 찾아가는지 추적할 수 있다. 처음에는 <span class="math math-inline">\lambda</span>가 비교적 큰 값을 유지하며 안정적으로 탐색하다가, 해에 가까워지면 <span class="math math-inline">\lambda</span>가 급격히 작아지면서 가우스-뉴턴처럼 빠르게 수렴하는 전형적인 패턴을 관찰할 수 있다.2</li>
</ol>
<h3>4.2  사례 연구 2: 컴퓨터 비전의 핵심, 번들 조정 (Bundle Adjustment, BA)</h3>
<p>LM 알고리즘이 단순한 곡선 피팅을 넘어, 복잡하고 거대한 실제 문제에서 어떻게 사용되는지를 보여주는 가장 대표적인 예가 바로 컴퓨터 비전 분야의 번들 조정(Bundle Adjustment)이다. BA는 Structure from Motion (SfM)이나 시각적 SLAM(Simultaneous Localization and Mapping)과 같은 기술의 핵심적인 마지막 단계로, LM은 이 분야에서 사실상의 표준(de facto standard) 알고리즘으로 통한다.31</p>
<p>번들 조정이란 무엇인가?</p>
<p>여러 장의 사진(혹은 비디오 프레임)에서 공통으로 나타나는 특징점들(feature points)의 2D 이미지 좌표를 입력으로 받아, 이 모든 특징점들의 3D 공간 좌표와 각 사진을 찍은 카메라의 위치 및 방향(pose)을 동시에 최적화하는 거대한 비선형 최소제곱 문제다.32 ’번들(bundle)’이란 각 3D 점에서 각 카메라로 향하는 광선들의 묶음을 의미하며, 이 광선 묶음들을 조정하여 전체 모델을 일관성 있게 만든다는 뜻에서 ’번들 조정’이라는 이름이 붙었다.</p>
<p>최적화의 목표는 추정된 3D 점들을 각 카메라 모델을 통해 이미지 평면에 다시 투영(reprojection)했을 때 계산되는 2D 좌표와, 실제 이미지에서 관측된 2D 특징점의 좌표 사이의 오차, 즉 ’재투영 오차(reprojection error)’의 제곱 합을 최소화하는 것이다.32</p>
<p>왜 LM이 번들 조정에 최적인가?</p>
<p>BA는 수십만 개에서 수백만 개에 이르는 파라미터(모든 3D 점의 <span class="math math-inline">x, y, z</span> 좌표 + 모든 카메라의 위치 및 방향 파라미터)를 가질 수 있는 매우 큰 규모의 NLLS 문제다. 언뜻 보면 LM의 <span class="math math-inline">O(n^3)</span> 계산 복잡도 때문에 적용이 불가능해 보일 수 있다.</p>
<p>하지만 BA 문제의 자코비안 행렬에는 매우 특별하고 중요한 ’구조’가 숨어있다. 바로 ’희소성(sparsity)’이다.35 특정 3D 점은 전체 카메라 중 극히 일부에서만 관측된다. 마찬가지로, 특정 카메라는 전체 3D 점 중 일부만 촬영한다. 이로 인해 자코비안 행렬의 대부분의 원소는 0이 된다. LM 알고리즘을 이 희소 구조를 활용하도록 변형하면, 거대한</p>
<p><span class="math math-inline">\mathbf{J}^T \mathbf{J}</span> 행렬 전체를 메모리에 올리거나 직접 계산할 필요 없이, Schur 보수(Schur complement)와 같은 기법을 사용하여 훨씬 효율적으로 업데이트 스텝을 계산할 수 있다.32</p>
<p>이처럼 알고리즘의 성공은 단순히 알고리즘 자체의 우수성뿐만 아니라, 문제의 ’구조’를 얼마나 잘 파악하고 활용하느냐에 달려있다. BA의 희소 구조는 LM이 대규모 문제에서도 빛을 발할 수 있게 만든 핵심 열쇠다.</p>
<h3>4.3  사례 연구 3: 인공신경망 학습</h3>
<p>인공신경망(Artificial Neural Network, ANN)의 학습 과정 역시 비용 함수를 최소화하는 최적화 문제이므로, LM을 적용해 볼 수 있다. 특히 파라미터(가중치와 편향)의 수가 비교적 적은 소규모 및 중간 규모의 네트워크에서 LM은 강력한 성능을 보인다.23</p>
<p>문제 재구성:</p>
<p>신경망의 학습은 주어진 입력에 대한 네트워크의 출력과 실제 목표값(target) 사이의 오차 제곱합(mean squared error, MSE)을 최소화하는 과정으로 볼 수 있다. 이는 정확히 NLLS 문제의 형태를 띤다.</p>
<p><strong>장점:</strong></p>
<ul>
<li><strong>빠른 수렴:</strong> LM은 2차 정보를 활용하기 때문에, 1차 정보(그래디언트)만 사용하는 경사 하강법이나 그 변형들(예: Adam)보다 훨씬 적은 반복(epoch)으로 목표 오차 수준에 도달할 수 있다.23 특히 복잡한 에러 표면을 가진 문제에서 진동 없이 안정적으로 최소점을 찾아가는 능력이 뛰어나다.23 여러 연구에서 LM이 BFGS나 Adam과 같은 다른 최적화기보다 더 낮은 MSE를 더 빨리 달성했음을 보여준다.40</li>
<li><strong>안정성:</strong> LM은 경사 하강법의 안정성을 물려받았기 때문에, 가우스-뉴턴법처럼 쉽게 발산하지 않는다.23</li>
</ul>
<p><strong>단점:</strong></p>
<ul>
<li><strong>계산 복잡도와 메모리:</strong> LM의 가장 큰 한계점이다. 파라미터의 수를 <span class="math math-inline">n</span>이라 할 때, 자코비안 행렬의 크기는 <span class="math math-inline">(데이터 수) \times n</span> 이고, 근사 헤시안 <span class="math math-inline">\mathbf{J}^T \mathbf{J}</span>의 크기는 <span class="math math-inline">n \times n</span> 이다. 현대의 딥러닝 모델처럼 <span class="math math-inline">n</span>이 수백만, 수십억에 이르면 이 행렬들을 저장할 메모리도 부족할뿐더러, <span class="math math-inline">O(n^3)</span>에 달하는 선형 시스템 풀이 계산은 현실적으로 불가능하다.37</li>
<li><strong>확장성 부재:</strong> 이러한 이유로 LM은 대규모 데이터셋이나 거대한 딥러닝 모델의 학습에는 실용적이지 않다. 미니배치(mini-batch)를 사용하는 확률적 경사 하강법(SGD) 계열의 알고리즘들이 딥러닝의 표준이 된 것은 바로 이 확장성 문제 때문이다.42</li>
</ul>
<p>BA와 신경망 학습 사례의 대비는 중요한 교훈을 준다. 알고리즘의 우수성은 절대적인 것이 아니라 ’문제의 구조와 규모’에 따라 상대적으로 결정된다. BA의 ’희소성’이라는 구조는 LM의 약점을 보완해주었지만, 일반적인 신경망의 ’밀집성(density)’은 LM의 약점을 그대로 노출시켰다. 따라서 실제 문제 해결사는 다양한 알고리즘의 장단점을 이해하고, 주어진 문제에 가장 적합한 도구를 선택할 수 있는 안목을 갖추어야 한다.</p>
<h2>5. 부: 더 넓은 시야에서 - 다른 최적화 알고리즘과의 비교</h2>
<p>레벤버그-마르쿼트(LM) 알고리즘의 진정한 위치를 이해하려면, 이를 최적화라는 더 넓은 생태계 안에 놓고 다른 주요 알고리즘들과 비교해 보아야 한다. 특히 현대 머신러닝의 주역인 1차 최적화 방법(예: Adam)과, 또 다른 강력한 2차 정보 활용법인 유사-뉴턴법(예: BFGS)과의 비교는 LM의 특징과 장단점을 더욱 명확하게 부각시킨다.</p>
<h3>5.1  LM vs. 1차 최적화 (SGD, Adam)</h3>
<p>현대 딥러닝의 성공은 대규모 데이터와 거대한 모델을 효율적으로 학습시킬 수 있는 1차 최적화 알고리즘, 특히 Adam의 등장과 궤를 같이한다.44 LM과 Adam의 비교는 ’정보의 질’과 ‘계산 비용’ 사이의 근본적인 트레이드오프를 보여준다.</p>
<ul>
<li>
<p><strong>핵심 트레이드오프: ‘정보량’ vs. ‘계산 비용’</strong></p>
</li>
<li>
<p><strong>LM (2차 정보 활용):</strong> LM은 자코비안을 통해 비용 함수의 2차 곡률 정보(헤시안)를 근사하여 사용한다. 이 ‘고급 정보’ 덕분에 LM은 더 똑똑하고 직접적인 경로로 최소점을 찾아갈 수 있다. 마치 지형의 굴곡까지 파악하고 최단 경로를 계산하는 것과 같다. 하지만 이 정보를 얻고 활용하는 데는 막대한 계산 비용이 따른다. 각 스텝의 계산 복잡도는 파라미터 수 <span class="math math-inline">n</span>에 대해 <span class="math math-inline">O(n^3)</span>에 달한다.28</p>
</li>
<li>
<p><strong>Adam (1차 정보 활용):</strong> Adam은 오직 1차 미분 정보인 그래디언트와, 과거 그래디언트의 이동 평균(모멘텀)만을 사용한다.44 이는 지형의 기울기만 보고 다음 걸음을 결정하는 것과 같다. 각 스텝에 필요한 정보가 단순하기 때문에 계산 비용이</p>
</li>
</ul>
<p><span class="math math-inline">O(n)</span>으로 매우 낮다. 대신, 최적해에 도달하기까지 더 많은 스텝(반복)이 필요할 수 있다.45</p>
<ul>
<li>왜 딥러닝에서는 Adam이 지배적인가?</li>
</ul>
<p>답은 ’규모(scale)’에 있다. 현대 딥러닝 모델의 파라미터 수 <span class="math math-inline">n</span>은 수백만에서 수십억에 이른다. 이러한 규모에서 LM의 <span class="math math-inline">O(n^3)</span> 계산 비용과 <span class="math math-inline">O(n^2)</span> 메모리 요구량은 감당 불가능한 수준이다.37 반면, Adam의 계산 비용은</p>
<p><span class="math math-inline">n</span>에 선형적으로 비례하므로, 아무리 큰 모델이라도 학습을 진행할 수 있다.</p>
<ul>
<li>
<p><strong>성능 비교:</strong></p>
</li>
<li>
<p><strong>소규모 문제:</strong> 파라미터 수가 적은 문제(수백~수천 개)에서는 LM이 Adam보다 월등한 성능을 보이는 경우가 많다. 훨씬 적은 반복으로 훨씬 더 낮은 오차에 도달하며, 하이퍼파라미터 튜닝에 덜 민감하다.41</p>
</li>
<li>
<p><strong>대규모 문제:</strong> Adam과 같은 확률적 경사 하강법(SGD) 기반의 방법들은 대규모 데이터셋의 일부(미니배치)만 사용하여 파라미터를 업데이트한다. 이는 계산 효율성을 높일 뿐만 아니라, 학습 과정에 노이즈를 추가하여 좋지 않은 지역 최소점을 탈출하고 더 나은 일반화(generalization) 성능을 갖는 해를 찾는 데 도움을 줄 수 있다는 주장도 있다.42</p>
</li>
</ul>
<p>결론적으로 LM은 정밀 가공을 위한 ’공작기계’와 같고, Adam은 대량 생산을 위한 ’컨베이어 벨트’와 같다. 소량의 부품을 극도의 정밀도로 가공해야 할 때는 LM이 뛰어나지만, 수백만 개의 부품을 빠르게 생산해야 할 때는 Adam이 유일한 선택지다.</p>
<h3>5.2  LM vs. 유사-뉴턴법 (Quasi-Newton Methods, e.g., BFGS)</h3>
<p>LM과 마찬가지로 2차 정보를 활용하지만, 다른 방식으로 접근하는 알고리즘 그룹이 있다. 바로 유사-뉴턴법이며, 그중 가장 대표적인 것이 BFGS(Broyden-Fletcher-Goldfarb-Shanno) 알고리즘이다.47</p>
<ul>
<li><strong>문제 유형의 차이:</strong></li>
<li><strong>LM (특화형):</strong> LM은 비용 함수가 잔차 제곱의 합, 즉 <span class="math math-inline">S(\boldsymbol{\beta}) = ||\mathbf{r}(\boldsymbol{\beta})||^2</span> 형태인 비선형 최소제곱(NLLS) 문제에 ’특화’된 알고리즘이다. 헤시안을 <span class="math math-inline">\mathbf{J}^T \mathbf{J}</span>로 근사하는 핵심 아이디어는 오직 이 구조에서만 유효하다.30</li>
<li><strong>BFGS (범용형):</strong> BFGS는 NLLS뿐만 아니라 모든 종류의 ‘일반적인’ 비선형 최적화 문제(<span class="math math-inline">\min f(x)</span>)를 풀기 위해 설계된 범용 알고리즘이다.47</li>
<li><strong>헤시안 근사 방식의 차이:</strong></li>
<li><strong>LM:</strong> 매 반복마다 자코비안 <span class="math math-inline">\mathbf{J}</span>를 새로 계산하고, 이를 이용해 <span class="math math-inline">\mathbf{J}^T \mathbf{J}</span>라는 헤시안 근사치를 직접 구성한다.</li>
<li><strong>BFGS:</strong> 실제 헤시안이나 그 역행렬을 직접 계산하는 대신, 매 반복에서 계산된 그래디언트의 변화를 이용하여 헤시안의 역행렬을 점진적으로 ’업데이트’한다.6 이 방식은 헤시안을 직접 계산하고 역행렬을 구하는 것보다 계산적으로 훨씬 효율적이다(복잡도 <span class="math math-inline">O(n^2)</span>).</li>
<li><strong>성능 비교:</strong></li>
<li><strong>NLLS 문제:</strong> 문제 유형이 NLLS로 명확할 경우, 이 문제에 특화된 LM이 범용 알고리즘인 BFGS보다 더 빠르고 정확한 성능을 보이는 경향이 있다. 여러 비교 연구에서 LM이 BFGS보다 더 낮은 MSE를 달성했음을 보여준다.40</li>
<li><strong>일반 최적화 문제:</strong> 비용 함수가 잔차 제곱합 형태가 아닌 일반적인 문제에서는 LM을 사용할 수 없으며, BFGS가 표준적인 선택지 중 하나다.</li>
</ul>
<p>BFGS는 다양한 도구를 갖춘 ’만능 공구함’과 같고, LM은 특정 나사에 완벽하게 맞는 ’전용 드라이버’와 같다. 풀어야 할 문제가 명확한 NLLS라면 전용 드라이버인 LM이 더 효율적이다.</p>
<h3>5.3  종합 비교 분석</h3>
<p>지금까지 논의한 내용을 종합하여 주요 최적화 알고리즘들의 특징을 하나의 표로 정리하면 다음과 같다. 이 표는 각 알고리즘의 장단점과 적합한 사용처를 한눈에 파악하는 데 도움을 줄 것이다.</p>
<table><thead><tr><th>특징</th><th>Levenberg-Marquardt (LM)</th><th>Adam</th><th>BFGS</th></tr></thead><tbody>
<tr><td><strong>문제 유형</strong></td><td>비선형 최소제곱 (NLLS) 특화</td><td>일반 최적화 (주로 확률적)</td><td>일반 최적화 (주로 배치)</td></tr>
<tr><td><strong>사용 정보</strong></td><td>1차 미분 (자코비안)으로 2차 정보 근사</td><td>1차 미분 (그래디언트) + 모멘텀</td><td>1차 미분 (그래디언트) 변화로 2차 정보 근사</td></tr>
<tr><td><strong>계산 복잡도 (per-iteration)</strong></td><td>높음 (<span class="math math-inline">O(n^3)</span> 또는 희소성 활용 시 더 낮음)</td><td>낮음 (<span class="math math-inline">O(n)</span>)</td><td>중간 (<span class="math math-inline">O(n^2)</span>)</td></tr>
<tr><td><strong>수렴 속도</strong></td><td>빠름 (2차에 가까움)</td><td>느릴 수 있음 (1차)</td><td>빠름 (초선형, Superlinear)</td></tr>
<tr><td><strong>메모리 요구량</strong></td><td>높음 (<span class="math math-inline">\mathbf{J}^T \mathbf{J}</span> 저장)</td><td>낮음</td><td>중간 (헤시안 근사 행렬 저장, L-BFGS로 개선)</td></tr>
<tr><td><strong>주요 장점</strong></td><td>NLLS 문제에서 매우 높은 정확도와 빠른 수렴</td><td>대규모 데이터/모델에 대한 확장성</td><td>일반 문제에 대한 견고하고 빠른 수렴</td></tr>
<tr><td><strong>주요 단점</strong></td><td>대규모 문제에 비실용적</td><td>하이퍼파라미터에 민감, 최적해의 질 논란</td><td>NLLS 문제에 비특화</td></tr>
</tbody></table>
<h2>6. 참고 자료</h2>
<ol>
<li>4.1.4.2. Nonlinear Least Squares Regression - Information Technology Laboratory, accessed July 24, 2025, https://www.itl.nist.gov/div898/handbook/pmd/section1/pmd142.htm</li>
<li>The Levenberg-Marquardt algorithm for nonlinear least squares curve-fitting problems - Duke People, accessed July 24, 2025, https://people.duke.edu/~hpgavin/lm.pdf</li>
<li>Levenberg–Marquardt algorithm - Wikipedia, accessed July 24, 2025, <a href="https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm">https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm</a></li>
<li>Nonlinear Least Squares (Curve Fitting) - MATLAB &amp; Simulink - MathWorks, accessed July 24, 2025, https://www.mathworks.com/help/optim/nonlinear-least-squares-curve-fitting.html</li>
<li>Chapter 6 Non-Linear Regression | A Guide on Data Analysis, accessed July 24, 2025, https://bookdown.org/mike/data_analysis/non-linear-regression.html</li>
<li>Non-linear least squares - Wikipedia, accessed July 24, 2025, https://en.wikipedia.org/wiki/Non-linear_least_squares</li>
<li>4.7. Nonlinear least squares - Fundamentals of Numerical Computation - Toby Driscoll, accessed July 24, 2025, https://tobydriscoll.net/fnc-julia/nonlineqn/nlsq.html</li>
<li>en.wikipedia.org, accessed July 24, 2025, <a href="https://en.wikipedia.org/wiki/Non-linear_least_squares#:~:text=Non-linear%20least%20squares%20is,parameters%20(m%20%E2%89%A5%20n).">https://en.wikipedia.org/wiki/Non-linear_least_squares#:~:text=Non%2Dlinear%20least%20squares%20is,parameters%20(m%20%E2%89%A5%20n).</a></li>
<li>Gauss–Newton algorithm - Wikipedia, accessed July 24, 2025, <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm">https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm</a></li>
<li>Mastering Levenberg-Marquardt Algorithm - Number Analytics, accessed July 24, 2025, https://www.numberanalytics.com/blog/levenberg-marquardt-algorithm-optimization-guide</li>
<li>The Levenberg-Marquardt Algorithm, accessed July 24, 2025, https://sites.cs.ucsb.edu/~yfwang/courses/cs290i_mvg/pdf/LMA.pdf</li>
<li>A Brief Description of the Levenberg-Marquardt … - ICS-FORTH, accessed July 24, 2025, https://users.ics.forth.gr/~lourakis/levmar/levmar.pdf</li>
<li>Gradient descent - Wikipedia, accessed July 24, 2025, https://en.wikipedia.org/wiki/Gradient_descent</li>
<li>Gradient Descent Algorithm: How Does it Work in Machine Learning? - Analytics Vidhya, accessed July 24, 2025, https://www.analyticsvidhya.com/blog/2020/10/how-does-the-gradient-descent-algorithm-work-in-machine-learning/</li>
<li>An overview of gradient descent optimization algorithms - ruder.io, accessed July 24, 2025, https://www.ruder.io/optimizing-gradient-descent/</li>
<li>Gradient Descent Algorithm in Machine Learning - GeeksforGeeks, accessed July 24, 2025, https://www.geeksforgeeks.org/machine-learning/gradient-descent-algorithm-and-its-variants/</li>
<li>Nonlinear Least-Squares Problems with the Gauss-Newton and Levenberg-Marquardt Methods - Math@LSU, accessed July 24, 2025, <a href="https://www.math.lsu.edu/system/files/MunozGroup1%20-%20Presentation.pdf">https://www.math.lsu.edu/system/files/MunozGroup1%20-%20Presentation.pdf</a></li>
<li>Lec9p1, ORF363/COS323 - Princeton University, accessed July 24, 2025, https://www.princeton.edu/~aaa/Public/Teaching/ORF363_COS323/F14/ORF363_COS323_F14_Lec9.pdf</li>
<li>Approximate Gauss-Newton methods for nonlinear least squares problems - University of Reading, accessed July 24, 2025, https://www.reading.ac.uk/maths-and-stats/-/media/project/uor-main/schools-departments/maths/documents/0904pdf.pdf?la=en&amp;hash=45BCE1B5038E631F3DCAF7450E46B114</li>
<li>1 Nonlinear least squares 2 Newton and Gauss-Newton - Computer Science Cornell, accessed July 24, 2025, https://www.cs.cornell.edu/courses/cs4220/2023sp/lec/2023-04-10.pdf</li>
<li>METHODS FOR NON-LINEAR LEAST SQUARES … - DTU Informatics, accessed July 24, 2025, http://www2.imm.dtu.dk/pubdb/edoc/imm3215.pdf</li>
<li>Support/User Manual/Methods/Optimization Methods/Levenberg - Marquardt - COPASI, accessed July 24, 2025, https://copasi.org/Support/User_Manual/Methods/Optimization_Methods/Levenberg_-_Marquardt/</li>
<li>Levenberg–Marquardt Training - Auburn University, accessed July 24, 2025, https://www.eng.auburn.edu/~wilambm/pap/2011/K10149_C012.pdf</li>
<li>Levenberg-Marquardt algorithm explained - YouTube, accessed July 24, 2025, https://www.youtube.com/watch?v=dPZo74SbkeQ&amp;pp=0gcJCfwAo7VqN5tD</li>
<li>A Brief Description of the Levenberg-Marquardt Algorithm Implemened by levmar - ICS-FORTH, accessed July 24, 2025, http://users.ics.forth.gr/lourakis/levmar/levmar.pdf</li>
<li>Levenberg-Marquardt Method - NEOS Guide, accessed July 24, 2025, https://neos-guide.org/guide/algorithms/lmm/</li>
<li>Mastering Levenberg-Marquardt Algorithm - Number Analytics, accessed July 24, 2025, https://www.numberanalytics.com/blog/levenberg-marquardt-algorithm-guide</li>
<li>Gauss-Newton vs gradient descent vs Levenberg-Marquadt for least squared method, accessed July 24, 2025, https://mathoverflow.net/questions/257699/gauss-newton-vs-gradient-descent-vs-levenberg-marquadt-for-least-squared-method</li>
<li>Regularized Levenberg-Marquardt algorithm for nonlinear regression on small size datasets - GitHub, accessed July 24, 2025, https://github.com/flowel1/nonlinear-regression</li>
<li>Gauss-Newton Method Explained - Number Analytics, accessed July 24, 2025, https://www.numberanalytics.com/blog/gauss-newton-method-explained</li>
<li>Leveraging the Levenberg-Marquardt Method on Vanishing Point Estimation | by Oleg Boev, accessed July 24, 2025, https://medium.com/@olegboev/leveraging-the-levenberg-marquardt-method-on-vanishing-point-estimation-in-computer-vision-5b10668b1ad5</li>
<li>Bundle Adjustment in the Large - University of Washington, accessed July 24, 2025, https://homes.cs.washington.edu/~sagarwal/bal.pdf</li>
<li>A Graph Network Approach to Faster Optimization of Bundle Adjustment for Vehicular SLAM - CVF Open Access, accessed July 24, 2025, https://openaccess.thecvf.com/content/ICCV2021/papers/Tanaka_Learning_To_Bundle-Adjust_A_Graph_Network_Approach_to_Faster_Optimization_ICCV_2021_paper.pdf</li>
<li>bundleAdjustment - Adjust collection of 3-D points and camera poses - MATLAB, accessed July 24, 2025, https://www.mathworks.com/help/vision/ref/bundleadjustment.html</li>
<li>(PDF) Is Levenberg-Marquardt the Most Efficient Optimization Algorithm for Implementing Bundle Adjustment?. - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/publication/221111908_Is_Levenberg-Marquardt_the_Most_Efficient_Optimization_Algorithm_for_Implementing_Bundle_Adjustment</li>
<li>Bundle Adjustment, accessed July 24, 2025, https://www.cs.cmu.edu/~kaess/vslam_cvpr14/media/VSLAM-Tutorial-CVPR14-A13-BundleAdjustment.pdf</li>
<li>FAST COMPUTATIONAL APPROACH TO THE LEVENBERG-MARQUARDT ALGORITHM FOR TRAINING FEEDFORWARD NEURAL NETWORKS, accessed July 24, 2025, https://yadda.icm.edu.pl/baztech/element/bwmeta1.element.baztech-41a1ef60-a15f-4db1-a7d6-351248ea99bd/c/bilski_fast_computationa.pdf</li>
<li>www.researchgate.net, accessed July 24, 2025, <a href="https://www.researchgate.net/figure/A-comparison-of-the-performance-of-the-Adam-optimizer-an-algorithm-for-first-order_fig3_360640362#:~:text=The%20Levenberg-Marquardt%20(LM)%20algorithm%20achieves%20an%20improved%20MSE,BFGS%20algorithm%20after%2020%20epochs.&amp;text=We%20investigate%20the%20role%20of,to%20medium%20number%20of%20parameters.">https://www.researchgate.net/figure/A-comparison-of-the-performance-of-the-Adam-optimizer-an-algorithm-for-first-order_fig3_360640362#:~:text=The%20Levenberg%2DMarquardt%20(LM)%20algorithm%20achieves%20an%20improved%20MSE,BFGS%20algorithm%20after%2020%20epochs.&amp;text=We%20investigate%20the%20role%20of,to%20medium%20number%20of%20parameters.</a></li>
<li>Artificial Neural Networks: Understanding the Levenberg-Marquardt algorithm - MATLAB Answers - MathWorks, accessed July 24, 2025, https://www.mathworks.com/matlabcentral/answers/801696-artificial-neural-networks-understanding-the-levenberg-marquardt-algorithm</li>
<li>A COMPARATIVE STUDY OF BACK-PROPAGATION ALGORITHMS: LEVENBERG-MARQUART AND BFGS FOR THE FORMATION OF MULTILAYER NEURAL NETWORKS - SCIK Publishing Corporation, accessed July 24, 2025, https://scik.org/index.php/cmbn/article/download/7355/3478</li>
<li>A comparison of the performance of the Adam optimizer, an algorithm for, accessed July 24, 2025, https://www.researchgate.net/figure/A-comparison-of-the-performance-of-the-Adam-optimizer-an-algorithm-for-first-order_fig3_360640362</li>
<li>[D] Effectively using Levenberg–Marquardt algorithm on neural nets - Reddit, accessed July 24, 2025, https://www.reddit.com/r/MachineLearning/comments/xsrbp2/d_effectively_using_levenbergmarquardt_algorithm/</li>
<li>do optimization methods in deep learning applications matter? - arXiv, accessed July 24, 2025, https://arxiv.org/pdf/2002.12642</li>
<li>Why does Adam optimizer work so well? : r/learnmachinelearning - Reddit, accessed July 24, 2025, https://www.reddit.com/r/learnmachinelearning/comments/1gbqci5/why_does_adam_optimizer_work_so_well/</li>
<li>Improving Levenberg-Marquardt Algorithm for Neural Networks, accessed July 24, 2025, https://order-up-ml.github.io/papers/19.pdf</li>
<li>Matlab implementation of neural network is vastly superior to Keras variant - Stack Overflow, accessed July 24, 2025, https://stackoverflow.com/questions/48176457/matlab-implementation-of-neural-network-is-vastly-superior-to-keras-variant</li>
<li>Broyden–Fletcher–Goldfarb–Shanno algorithm - Wikipedia, accessed July 24, 2025, <a href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm">https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm</a></li>
<li>Comparing Minimizers - Mantid, accessed July 24, 2025, https://docs.mantidproject.org/v3.7.2/concepts/FittingMinimizers.html</li>
<li>A Comparative Study of Back-propagation Algorithms: Levenberg-Marquardt and BFGS for the Formation of Multilayer Neural Networks for Estimation of Fluoride - SciTePress, accessed July 24, 2025, https://www.scitepress.org/Papers/2021/107463/107463.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>