<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:16.1 생성(Generative)에서 행동(Action)으로 - 2025 에이전트 트렌드</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>16.1 생성(Generative)에서 행동(Action)으로 - 2025 에이전트 트렌드</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">트랜스포머 싱귤래리티 (The Transformer Singularity)</a> / <span>16.1 생성(Generative)에서 행동(Action)으로 - 2025 에이전트 트렌드</span></nav>
                </div>
            </header>
            <article>
                <h1>16.1 생성(Generative)에서 행동(Action)으로 - 2025 에이전트 트렌드</h1>
<p>2025-12-25, G30DR</p>
<h2>1.  서론: ’생성형 AI의 역설’을 넘어 에이전트 혁명으로</h2>
<p>2025년은 인공지능(AI) 기술의 역사에서 명확한 분기점으로 기록된다. 지난 몇 년간 전 세계 산업계는 텍스트, 이미지, 코드를 생성하는 ’생성형 AI(Generative AI)’의 놀라운 능력에 매료되었으나, 동시에 깊은 고민에 빠져 있었다. 맥킨지(McKinsey)가 지적한 ’생성형 AI의 역설(Gen AI Paradox)’이 바로 그것이다.1 기업의 약 80%가 생성형 AI를 도입했음에도 불구하고, 실질적인 수익 증대나 비용 절감과 같은 바텀라인(Bottom-line)에 미치는 영향은 미미했다. 이는 기존의 생성형 AI가 정보를 요약하거나 초안을 작성하는 등 수동적인 ‘비서(Co-pilot)’ 역할에 머물렀기 때문이다.</p>
<p>그러나 2025년, 우리는 AI가 단순히 콘텐츠를 생성하는 것을 넘어, 스스로 계획을 수립하고, 도구를 선택하며, 디지털 및 물리적 환경에서 실질적인 과업을 완수하는 ’에이전틱 AI(Agentic AI)’의 시대로 진입했다.2 이 새로운 패러다임은 ’생성(Generative)’에서 ’행동(Action)’으로의 거대한 전환을 의미한다. 가트너(Gartner)는 2028년까지 엔터프라이즈 소프트웨어의 33%가 에이전틱 AI를 포함할 것이며, 업무 의사결정의 15%가 자율적으로 이루어질 것이라 전망했다.4 이는 단순한 기술적 진보가 아니라, 인간과 기계의 협업 방식, 기업의 운영 모델, 그리고 노동의 본질을 재정의하는 구조적 변혁이다.</p>
<p>본 장에서는 2025년을 관통하는 에이전트 트렌드를 기술적 아키텍처, 오케스트레이션 프레임워크, 사용자 경험(UX), 그리고 산업별 적용 사례를 통해 심층적으로 분석한다. 대형 언어 모델(LLM)을 넘어선 대형 행동 모델(LAM)의 부상부터, 멀티 에이전트 시스템의 협업 방식, 그리고 이를 뒷받침하는 차세대 메모리 기술과 보안 거버넌스까지, 에이전트 기술의 현재와 미래를 포괄적으로 조망한다.</p>
<h2>2.  대형 행동 모델(LAM)과 인지 아키텍처의 진화</h2>
<h3>2.1  LLM의 한계와 LAM의 부상: 인식에서 실행으로</h3>
<p>2024년까지의 AI 모델이 텍스트 패턴을 학습하여 다음 단어를 예측하는 데 최적화된 ’확률적 앵무새’였다면, 2025년의 대형 행동 모델(Large Action Model, LAM)은 인간의 의도를 이해하고 이를 구체적인 행동 시퀀스로 변환하는 ’자율적 행위자’다.6 LLM은 “비행기 표를 예매하는 법을 알려줘“라는 질문에 절차를 설명하는 텍스트를 생성하지만, LAM은 실제 여행 사이트에 접속하여 날짜를 선택하고, 좌석을 지정하며, 결제까지 완료한다.</p>
<p>LAM의 기술적 핵심은 ’행동 표현(Action Representation)’과 ‘인터페이스 이해’ 능력에 있다. LAM은 시각적 입력(스크린샷 등)과 텍스트 입력을 동시에 처리하여, 웹 브라우저나 애플리케이션의 GUI 요소(버튼, 입력창, 메뉴 등)를 인식하고 조작한다.8 이는 AI가 API가 제공되지 않는 레거시 소프트웨어까지 제어할 수 있음을 의미하며, ‘범용성’ 측면에서 획기적인 도약을 이뤄냈다. 특히, 최신 LAM은 신경망(Neural Network)의 직관적 인식 능력과 심볼릭 AI(Symbolic AI)의 논리적 계획 능력을 결합한 ‘뉴로-심볼릭(Neuro-symbolic)’ 아키텍처를 채택하는 경향을 보인다.9 이를 통해 에이전트는 불확실한 환경에서도 목표를 잃지 않고 다단계 작업을 수행할 수 있는 견고성을 확보했다.</p>
<h3>2.2  기술적 난제 해결: PaTH Attention과 상태 추적</h3>
<p>LAM이 복잡한 작업을 수행하기 위해서는 긴 호흡의 작업 과정을 기억하고, 현재 상태(State)를 정확히 파악하는 능력이 필수적이다. 기존의 트랜스포머(Transformer) 아키텍처가 사용하는 ‘어텐션(Attention)’ 메커니즘은 문맥 전체를 한 번에 파악하는 데는 유리하지만, 작업 순서나 상태 변화와 같은 순차적 정보를 처리하는 데는 한계가 있었다.11</p>
<p>2025년 MIT와 IBM Watson AI 연구팀이 개발한 <strong>‘PaTH Attention(Position-aware Transformer Hybrid Attention)’</strong> 기술은 이러한 문제를 해결하는 중요한 열쇠가 되었다. 기존의 RoPE(Rotary Position Encoding) 방식이 토큰 간의 상대적 거리만을 고정적으로 계산했다면, PaTH Attention은 위치 정보를 문맥에 따라 적응적(Adaptive)으로 처리한다.11 이는 에이전트가 “A 작업을 먼저 하고, 그 결과가 B라면 C를 하라“와 같은 조건부 명령이나, 긴 코드 블록 내에서의 변수 상태 변화를 정확하게 추적할 수 있게 해 준다. 이러한 기술적 진보는 에이전트가 단순한 웹 서핑을 넘어, 복잡한 코딩 작업이나 금융 트랜잭션과 같이 높은 정확도가 요구되는 작업을 수행할 수 있는 기반이 되었다.</p>
<table><thead><tr><th><strong>구분</strong></th><th><strong>생성형 AI (Generative AI)</strong></th><th><strong>에이전틱 AI (Agentic AI / LAM)</strong></th></tr></thead><tbody>
<tr><td><strong>핵심 기능</strong></td><td>콘텐츠 생성 (텍스트, 이미지, 코드)</td><td>목표 지향적 행동 수행 및 의사결정</td></tr>
<tr><td><strong>작동 방식</strong></td><td>프롬프트에 대한 반응적(Reactive) 출력</td><td>목표 달성을 위한 능동적(Proactive) 계획 및 실행</td></tr>
<tr><td><strong>인터랙션</strong></td><td>인간이 지속적으로 개입 (Human-in-the-loop)</td><td>설정된 목표 하에 자율적 수행 (Human-on-the-loop)</td></tr>
<tr><td><strong>기술 스택</strong></td><td>대형 언어 모델 (LLM), 트랜스포머</td><td>대형 행동 모델 (LAM), 강화 학습, 뉴로-심볼릭 아키텍처</td></tr>
<tr><td><strong>결과물</strong></td><td>정보, 초안, 제안</td><td>예약 완료, 구매, 코드 배포, 이메일 발송</td></tr>
</tbody></table>
<h3>2.3  주요 빅테크의 에이전트 전략: 3파전 양상</h3>
<p>2025년 에이전트 기술 패권 경쟁은 OpenAI, Anthropic, 그리고 중국의 DeepSeek를 중심으로 3파전 양상을 띠고 있다.</p>
<ul>
<li><strong>OpenAI의 ‘Operator’ (CUA 모델):</strong> 2025년 1월 공개된 ’Operator’는 ‘컴퓨터 사용 에이전트(Computer-Using Agent, CUA)’ 모델을 기반으로 한다.12 GPT-4o의 시각적 인식 능력과 강화 학습을 결합한 Operator는 별도의 API 연동 없이도 인간이 사용하는 모든 웹사이트와 소프트웨어를 조작할 수 있다. 오픈테이블(OpenTable), 우버(Uber) 등과 협력하여 예약 및 구매 프로세스를 최적화했으며, 밈(Meme) 제작과 같은 창의적 도구 사용 능력까지 보여주며 ’범용 에이전트’의 가능성을 입증했다.13</li>
<li><strong>Anthropic의 ‘Computer Use’:</strong> Anthropic은 Claude 3.5 Sonnet에 컴퓨터 제어 API를 통합하여 개발자 생태계를 공략했다. 2025년 8월 데이터에 따르면, Claude를 활용한 코딩 작업 중 단순 코드 생성이 아닌 전체 기능을 구현하고 설계하는 복잡한 작업의 비중이 1.0%에서 9.9%로 급증했다.15 이는 개발자들이 에이전트에게 단순 보조가 아닌 엔지니어링 업무의 상당 부분을 위임하기 시작했음을 시사한다.</li>
<li><strong>DeepSeek-R1과 추론의 민주화:</strong> 중국의 DeepSeek은 추론(Reasoning) 능력에 특화된 ‘DeepSeek-R1’ 모델을 오픈소스로 공개하며 시장에 충격을 주었다.16 강화 학습(RL)을 통해 사고의 사슬(Chain-of-Thought)을 내재화한 이 모델은 서구권 모델 대비 현저히 낮은 훈련 비용(약 600만 달러 추정)으로 GPT-4o에 버금가는 추론 성능을 달성했다.17 이는 고성능 에이전트 구축의 진입 장벽을 낮추어, 전 세계적으로 다양한 특화 에이전트가 폭발적으로 증가하는 계기가 되었다.</li>
</ul>
<h2>3.  에이전틱 워크플로우와 오케스트레이션 프레임워크</h2>
<h3>3.1  멀티 에이전트 시스템(MAS): 협업이 만드는 지능</h3>
<p>단일 에이전트가 모든 작업을 처리하는 방식은 복잡성이 증가할수록 성능이 저하되는 한계가 있다. 2025년에는 이를 극복하기 위해 역할(Role)이 분담된 여러 에이전트가 협업하는 ’멀티 에이전트 시스템(Multi-Agent Systems)’이 표준 아키텍처로 자리 잡았다.18 예를 들어, 소프트웨어 개발 시 ‘기획자(PM) 에이전트’, ‘개발자(Developer) 에이전트’, ’테스터(QA) 에이전트’가 서로 대화하며 코드를 작성하고 검증하는 방식이다. 딜로이트는 멀티 에이전트 시스템이 단일 모델보다 복잡한 환경에서 월등한 성능을 발휘하며, 환각(Hallucination)을 줄이는 데도 효과적이라고 분석했다.18</p>
<h3>3.2  프레임워크의 통합과 진화: AutoGen에서 LangGraph까지</h3>
<p>2024년 난립했던 에이전트 개발 프레임워크들은 2025년 대통합과 전문화의 과정을 거쳤다.20</p>
<ul>
<li><strong>Microsoft Agent Framework (AutoGen + Semantic Kernel):</strong> 마이크로소프트는 연구 중심의 ’AutoGen’과 엔터프라이즈용 ’Semantic Kernel’을 통합하여 강력한 에이전트 생태계를 구축했다. 특히 ‘Magentic-One’ 시스템은 오케스트레이터(Orchestrator) 에이전트가 웹 서퍼(WebSurfer), 파일 서퍼(FileSurfer) 등 하위 에이전트를 지휘하는 계층적 구조를 통해 복잡한 장기 작업을 안정적으로 수행하는 표준 모델을 제시했다.21</li>
<li><strong>LangChain의 LangGraph 전환:</strong> 에이전트 개발의 사실상 표준이었던 LangChain은 복잡한 상태 관리(State Management)를 위해 그래프 기반의 ’LangGraph’로 중심축을 옮겼다.20 LangGraph는 에이전트의 워크플로우를 노드와 엣지로 시각화하고 제어할 수 있게 하여, 순환(Loop)과 분기(Branching)가 많은 로직에서의 디버깅 난이도를 획기적으로 낮췄다.</li>
<li><strong>CrewAI의 엔터프라이즈 약진:</strong> CrewAI는 직관적인 역할 기반(Role-based) 설계로 비개발자도 쉽게 멀티 에이전트 팀을 구성할 수 있게 하여 기업 시장에서 빠르게 성장했다. 실제 인간 조직도와 유사하게 에이전트 팀을 구성할 수 있다는 점이 큰 장점으로 작용했다.20</li>
</ul>
<table><thead><tr><th><strong>프레임워크</strong></th><th><strong>주요 특징</strong></th><th><strong>적합한 사용 사례</strong></th><th><strong>2025년 주요 변화</strong></th></tr></thead><tbody>
<tr><td><strong>Microsoft AutoGen</strong></td><td>대화형 멀티 에이전트, 높은 커스터마이징</td><td>복잡한 협업, 연구/실험적 프로젝트</td><td>Semantic Kernel과 통합, Magentic-One 아키텍처 도입</td></tr>
<tr><td><strong>LangGraph</strong></td><td>그래프 기반 상태 관리, 정밀한 제어</td><td>조건부 로직이 많은 복잡한 워크플로우</td><td>LangChain 생태계의 핵심으로 부상, 디버깅 도구 강화</td></tr>
<tr><td><strong>CrewAI</strong></td><td>역할(Role) 기반 협업, 낮은 진입 장벽</td><td>콘텐츠 제작, 마케팅 캠페인, 리서치 팀</td><td>엔터프라이즈 기능 강화, 주요 기업 도입 확대</td></tr>
<tr><td><strong>LlamaIndex</strong></td><td>데이터 인덱싱 중심, RAG 특화</td><td>문서 분석, 지식 기반 Q&amp;A 에이전트</td><td>에이전틱 RAG 워크플로우 강화</td></tr>
</tbody></table>
<h2>4.  메모리와 컨텍스트: 잊지 않는 에이전트(Persistent Memory)</h2>
<h3>4.1  GraphRAG와 지식 그래프 메모리</h3>
<p>에이전트가 일회성 도구를 넘어 장기적인 파트너가 되기 위해서는 ‘기억’ 능력이 필수적이다. 기존의 벡터 검색(Vector Search) 기반 RAG는 정보의 파편화된 검색에는 유용했으나, 정보 간의 연결성이나 전체적인 맥락을 파악하는 데는 한계가 있었다. 이를 해결하기 위해 2025년에는 지식 그래프(Knowledge Graph)를 활용한 <strong>‘GraphRAG’</strong> 기술이 에이전트 메모리의 핵심으로 부상했다.24</p>
<p>GraphRAG는 텍스트 데이터에서 엔티티와 관계를 추출하여 구조화된 지식 그래프를 구축한다. 마이크로소프트 리서치의 연구에 따르면, GraphRAG는 전체 데이터셋에 대한 포괄적인 질문(Global Sense-making)에 대해 기존 RAG보다 훨씬 우수한 성능을 보인다.25 더 나아가 Zep AI의 ’Graphiti’와 같은 시스템은 시간적 맥락(Temporal Context)을 포함하는 동적 지식 그래프를 구현하여, 에이전트가 사용자의 선호도 변화나 프로젝트 진행 상황에 따라 기억을 스스로 업데이트하고 진화시키는 ’메모리 진화(Memory Evolution)’를 가능하게 했다.24 이는 에이전트가 “저번 회의 때 말했던 그 이슈 어떻게 됐어?“와 같은 모호한, 그러나 맥락 의존적인 질문에 정확히 답변할 수 있게 만든다.</p>
<h2>5.  사용자 경험(UX)의 혁명: 프롬프트에서 위임(Delegation)으로</h2>
<h3>5.1  인텐트 중심 디자인(Intent-Based Design)과 생성형 UI</h3>
<p>에이전트의 도입은 UX 디자인의 패러다임을 ’화면 중심’에서 ’의도(Intent) 중심’으로 완전히바꾸어 놓았다. 사용자는 더 이상 앱 메뉴를 찾아 헤맬 필요 없이 자연어로 의도를 표현하고, 에이전트에게 실행 권한을 위임한다.26 이는 사용자가 모든 과정을 통제하는 ‘직접 조작(Direct Manipulation)’ 방식에서, 결과물만 확인하고 승인하는 ‘지능적 위임’ 방식으로의 전환을 의미한다.</p>
<p>이 과정에서 <strong>‘생성형 UI(Generative UI)’</strong> 기술이 주목받고 있다. Rabbit R1이나 최신 AI OS는 고정된 인터페이스 대신, 사용자의 요청과 상황에 맞춰 필요한 UI 요소를 실시간으로 생성한다.27 예를 들어 “주말 여행 갈 곳 추천해 줘“라고 말하면, 에이전트는 지도, 날씨 위젯, 호텔 예약 카드를 즉석에서 조합하여 화면에 띄운다. 이는 개인화(Personalization)의 극치이며, 사용자 인터페이스가 더 이상 디자이너에 의해 미리 정의된 것이 아니라 AI에 의해 유동적으로 만들어지는 것임을 보여준다.28</p>
<h3>5.2  투명성과 신뢰 설계</h3>
<p>에이전트가 자율적으로 행동할수록 사용자의 불안감은 커질 수 있다. 따라서 2025년의 UX 트렌드는 ’투명성(Transparency)’을 기능적 요소로 통합하는 것이다. 에이전트가 어떤 과정을 거쳐 결론에 도달했는지 보여주는 ’사고 로그(Thought Log)’나, 중요한 행동(결제, 전송 등) 직전에 사용자의 승인을 구하는 절차를 자연스럽게 UI에 녹여내는 것이 필수적이다.28</p>
<h2>6.  엔터프라이즈 에이전트 적용 사례와 ROI</h2>
<h3>6.1  금융(Finance): 자율 감사와 트랜잭션 처리</h3>
<p>금융 분야는 에이전트 도입이 가장 빠르고 효과적으로 이루어지고 있는 영역이다. 핀테크 기업 <strong>Ramp</strong>는 2025년 7월, 비용 관리 플랫폼에 에이전트 AI를 통합하여 놀라운 성과를 거두었다.30 이 에이전트는 단순히 영수증을 인식하는 것을 넘어, 회사의 복잡한 비용 정책 문서를 숙지하고, 제출된 경비가 정책에 부합하는지 자율적으로 감사(Audit)한다. 위반 사항이 발견되면 사용자에게 소명을 요청하거나 승인을 거절하고, 정상적인 건은 자동으로 환급 처리한다. 이는 기존의 RPA가 처리하지 못했던 ‘판단’ 영역을 자동화한 것으로, 재무팀의 업무 부하를 획기적으로 줄였다. 또한, JPMorgan Chase는 고객 상담부터 사기 탐지, 자산 관리 조언까지 에이전트 기술을 전방위적으로 도입하여 운영 효율성을 높이고 있다.31</p>
<h3>6.2  공급망(Supply Chain): 자율 대응 시스템</h3>
<p>공급망 관리는 예측 불가능한 변수가 많아 전통적인 자동화가 어려운 분야였다. 그러나 2025년의 에이전트 AI는 외부 데이터(날씨, 지정학적 뉴스, 유가 등)를 실시간으로 모니터링하고, 공급망 붕괴 조짐이 보이면 자율적으로 대응책을 수립한다.32 <strong>SAP</strong>와 <strong>Oracle</strong>은 공급망 에이전트를 통해 수요 급증 시 창고 배치를 자동으로 최적화하거나, 항구 혼잡 시 대체 운송 경로를 예약하는 시스템을 상용화했다.32 IDC에 따르면, 이러한 에이전트 기반 시스템 도입 기업은 투자 대비 평균 3.7배의 ROI를 달성하고 있으며, 이는 에이전트가 단순 비용 절감을 넘어 비즈니스 리스크를 관리하는 핵심 자산이 되었음을 증명한다.19</p>
<h2>7.  하드웨어와 엣지 에이전트: Rabbit R1의 진화</h2>
<p>2024년 초, 미완성의 모습으로 출시되어 비판받았던 <strong>Rabbit R1</strong>은 2025년에 들어서며 엣지(Edge) 에이전트 디바이스로서의 가능성을 다시금 보여주고 있다. Rabbit은 클라우드 의존도를 줄이고 기기 자체의 LAM 성능을 강화하는 업데이트를 지속해왔다.27 특히 **‘티치 모드(Teach Mode)’**는 사용자가 웹사이트에서의 행동 패턴을 한 번만 시연하면, 에이전트가 이를 학습하여 이후 자율적으로 수행하는 기능을 제공한다.27 이는 사용자가 복잡한 코딩 없이도 자신만의 에이전트 기능을 확장할 수 있는 ’개인화된 자동화’의 길을 열었다.</p>
<p>Rabbit R1의 사례는 AI 에이전트가 스마트폰 앱의 형태를 넘어, 전용 하드웨어를 통해 물리적 환경과 상호작용하는 ’앰비언트 인텔리전스(Ambient Intelligence)’로 진화하고 있음을 시사한다.34 스마트폰이 알림의 늪에 빠져 방해 요소가 된 반면, 에이전트 디바이스는 사용자의 의도에만 집중하여 작업을 처리하는 ’조용한 기술(Calm Technology)’을 지향한다.</p>
<h2>8.  보안, 거버넌스, 그리고 미래 과제</h2>
<h3>8.1  새로운 위협: 행동 인젝션(Action Injection)</h3>
<p>에이전트가 실제 세상에서 행동할 수 있게 되면서 보안 위협의 차원도 달라졌다. 과거의 ’프롬프트 인젝션’이 챗봇에게 나쁜 말을 시키는 수준이었다면, 에이전트 시대의 **‘행동 인젝션(Action Injection)’**은 AI를 조작하여 무단 송금, 데이터 삭제, 악성 이메일 발송 등 치명적인 결과를 초래할 수 있다.35 Anthropic은 에이전트 기술이 사이버 공격의 장벽을 낮추어, 기술적 지식이 부족한 범죄자도 정교한 랜섬웨어 공격 등을 수행할 수 있게 된 점을 경고했다.35</p>
<h3>8.2  아이덴티티 관리와 책임 있는 자율성</h3>
<p>이에 대응하여 마이크로소프트는 **‘Microsoft Entra Agent ID’**를 도입하여, AI 에이전트에게도 인간 직원과 같은 고유한 디지털 신원(Identity)을 부여했다.36 이를 통해 에이전트의 활동을 추적하고, 접근 권한을 세밀하게 제어(Zero Trust)하는 체계를 구축했다. 기업은 에이전트 도입 시 ‘책임 있는 자율성(Responsible Autonomy)’ 프레임워크를 수립해야 하며, 여기에는 인간의 감독 수준 설정, 데이터 출처 검증, 그리고 에이전트의 비윤리적 행동을 차단하는 안전 가드레일이 포함된다.37</p>
<h2>9.  결론: 노동의 미래와 AGI로의 여정</h2>
<p>2025년의 에이전트 트렌드는 ’생성’에서 ’행동’으로의 기술적 전환을 넘어, 우리 사회가 AI를 대하는 방식의 근본적인 변화를 요구한다. AI는 이제 질문에 답하는 도서관 사서가 아니라, 프로젝트를 맡길 수 있는 인턴 혹은 동료가 되었다. 가트너의 예측대로 2028년까지 업무의 상당 부분이 자율 에이전트에 의해 수행된다면, 인간의 역할은 실무자(Doer)에서 관리자(Manager)이자 지휘자(Orchestrator)로 이동할 것이다.4</p>
<p>이러한 변화는 범용 인공지능(AGI)으로 가는 여정에서 중요한 이정표다. 환경을 인식하고, 계획하며, 도구를 사용하여 문제를 해결하는 에이전트의 능력은 AGI의 핵심 요건과 맞닿아 있다.34 기업과 개인은 이제 AI를 ’어떻게 쓸 것인가’를 넘어, AI에게 ‘어디까지 맡길 것인가’, 그리고 ’어떻게 협업할 것인가’를 고민해야 할 시점이다. 2025년, 에이전트 혁명은 이미 시작되었으며, 그 파도는 거대하고 되돌릴 수 없는 흐름이 되었다.</p>
<h2>10. 참고 자료</h2>
<ol>
<li>Seizing the agentic AI advantage - McKinsey, https://www.mckinsey.com/capabilities/quantumblack/our-insights/seizing-the-agentic-ai-advantage</li>
<li>The agentic organization: A new operating model for AI | McKinsey, https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-agentic-organization-contours-of-the-next-paradigm-for-the-ai-era</li>
<li>The Rise of Agentic AI: From Conversation to Action | Insights &amp; Resources | Goodwin, https://www.goodwinlaw.com/en/insights/publications/2025/05/insights-technology-aiml-the-rise-of-agentic-ai-from-conversation</li>
<li>12월 25, 2025에 액세스, [https://slack.com/intl/fr-fr/resources/why-use-slack/gartner-top-strategic-technology-trends-for-2025-agentic-ai#:<sub>:text=Agentic%20AI%20will%20introduce%20a,made%20autonomously%20through%20agentic%20AI.](https://slack.com/intl/fr-fr/resources/why-use-slack/gartner-top-strategic-technology-trends-for-2025-agentic-ai#:</sub>:text=Agentic AI will introduce a, <a href="https://slack.com/intl/fr-fr/resources/why-use-slack/gartner-top-strategic-technology-trends-for-2025-agentic-ai#:~:text=Agentic%20AI%20will%20introduce%20a,made%20autonomously%20through%20agentic%20AI.">https://slack.com/intl/fr-fr/resources/why-use-slack/gartner-top-strategic-technology-trends-for-2025-agentic-ai#:~:text=Agentic%20AI%20will%20introduce%20a,made%20autonomously%20through%20agentic%20AI.</a></li>
<li>Gartner® Top Strategic Technology Trends for 2025: Agentic AI | Slack, https://slack.com/intl/fr-fr/resources/why-use-slack/gartner-top-strategic-technology-trends-for-2025-agentic-ai</li>
<li>From Generative to Agentic: Understanding the Shift in AI Paradigms - Core BTS, https://nri-na.com/from-generative-to-agentic-understanding-the-shifts-in-ai-paradigms/</li>
<li>Large Action Models - Emergent Mind, https://www.emergentmind.com/topics/large-action-models</li>
<li>What are Large Action Models? The Next Frontier in AI Decision-Making | DigitalOcean, https://www.digitalocean.com/resources/articles/large-action-models</li>
<li>Large Action Models (LAMs) With Examples and Challenges - Analytics Vidhya, https://www.analyticsvidhya.com/blog/2024/12/large-action-models/</li>
<li>The Next Generation of AI Agents: Large Action Models Explained - Gradient Flow, https://gradientflow.com/large-action-models-explained/</li>
<li>A new way to increase the capabilities of large language models | MIT News, https://news.mit.edu/2025/new-way-to-increase-large-language-model-capabilities-1217</li>
<li>Operator System Card | OpenAI, https://openai.com/index/operator-system-card/</li>
<li>Introducing Operator - OpenAI, https://openai.com/index/introducing-operator/</li>
<li>OpenAI’s Operator: The Future of AI-Powered Assistive Browsing - Indulge Media, https://indulge.digital/blog/openais-operator-future-ai-powered-assistive-browsing</li>
<li>How AI Is Transforming Work at Anthropic, https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic</li>
<li>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning - arXiv, https://arxiv.org/pdf/2501.12948</li>
<li>DeepSeek’s R1, AI Agent, and Everything Else [2025] - Voiceflow, https://www.voiceflow.com/blog/what-is-deepseek</li>
<li>Autonomous generative AI agents: Under development - Deloitte, https://www.deloitte.com/us/en/insights/industry/technology/technology-media-and-telecom-predictions/2025/autonomous-generative-ai-agents-still-under-development.html</li>
<li>Looking At The Crystal Ball: 2025 Predictions For Agentic AI - Forbes, https://www.forbes.com/councils/forbestechcouncil/2025/01/21/looking-at-the-crystal-ball-2025-predictions-for-agentic-ai/</li>
<li>The AI Agent Framework Landscape in 2025: What Changed and What Matters - Medium, https://medium.com/@hieutrantrung.it/the-ai-agent-framework-landscape-in-2025-what-changed-and-what-matters-3cd9b07ef2c3</li>
<li>Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks - Microsoft, https://www.microsoft.com/en-us/research/publication/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/</li>
<li>Multi-Agent AI EXPLAINED: How Magentic-One Works - YouTube, https://www.youtube.com/watch?v=RUDZZLtB08w</li>
<li>Tested 5 agent frameworks in production - here’s when to use each one : r/AI_Agents, https://www.reddit.com/r/AI_Agents/comments/1oukxzx/tested_5_agent_frameworks_in_production_heres/</li>
<li>A-MEM: Agentic Memory for LLM Agents - arXiv, https://arxiv.org/pdf/2502.12110</li>
<li>Graphiti: Knowledge Graph Memory for an Agentic World - Neo4j, https://neo4j.com/blog/developer/graphiti-knowledge-graph-memory/</li>
<li>User experience in the age of agentic delegation - TechCabal, https://techcabal.com/2025/12/24/user-experience-in-the-age-of-agentic-delegation/</li>
<li>One year later, the Rabbit R1 is actually good now — here’s why | Tom’s Guide, https://www.tomsguide.com/ai/one-year-later-the-rabbit-r1-is-actually-good-now-heres-why</li>
<li>AI Agents, UI Design Trends for Agents | Fuselab Creative, https://fuselabcreative.com/ui-design-for-ai-agents/</li>
<li>Designing for AI Agents: A human-centered approach for 2025 - Aubergine Solutions, https://www.aubergine.co/insights/designing-for-ai-agents</li>
<li>The Hottest Agentic AI Examples and Use Cases in 2025 - - Flobotics, https://flobotics.io/uncategorized/hottest-agentic-ai-examples-and-use-cases-2025/</li>
<li>Agentic AI in Finance [5 Case Studies][2025] - DigitalDefynd, https://digitaldefynd.com/IQ/agentic-ai-in-finance/</li>
<li>Agentic AI in the global supply chain - SAP, https://www.sap.com/sea/blogs/agentic-ai-in-global-supply-chain</li>
<li>Scaling supply chain resilience: Agentic AI for autonomous operations - IBM, https://www.ibm.com/thought-leadership/institute-business-value/en-us/report/supply-chain-ai-automation-oracle</li>
<li>Tech trends: 2026—2030, https://onlys.ky/tech-trends-2026-2030/</li>
<li>Detecting and countering misuse of AI: August 2025 - Anthropic, https://www.anthropic.com/news/detecting-countering-misuse-aug-2025</li>
<li>Microsoft extends Zero Trust to secure the agentic workforce, https://www.microsoft.com/en-us/security/blog/2025/05/19/microsoft-extends-zero-trust-to-secure-the-agentic-workforce/</li>
<li>AI Agent Trends of 2025: Entering the Agentic Era of Autonomous Intelligence, https://genesishumanexperience.com/2025/10/19/ai-agent-trends-of-2025-entering-the-agentic-era-of-autonomous-intelligence/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>