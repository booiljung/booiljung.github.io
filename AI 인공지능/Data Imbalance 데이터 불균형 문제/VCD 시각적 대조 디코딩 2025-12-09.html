<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:VCD (Visual Contrastive Decoding, 시각적 대조 디코딩)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>VCD (Visual Contrastive Decoding, 시각적 대조 디코딩)</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">데이터 불균형 문제 (Data Imbalance Problem)</a> / <span>VCD (Visual Contrastive Decoding, 시각적 대조 디코딩)</span></nav>
                </div>
            </header>
            <article>
                <h1>VCD (Visual Contrastive Decoding, 시각적 대조 디코딩)</h1>
<p>2025-12-09, G30DR</p>
<h2>1.  서론: 멀티모달 인공지능의 진화와 환각이라는 장벽</h2>
<h3>1.1  연구의 배경 및 대규모 비전-언어 모델(LVLM)의 현주소</h3>
<p>최근 인공지능 연구의 흐름은 텍스트를 처리하는 대규모 언어 모델(LLM)을 넘어, 시각 정보와 언어 정보를 동시에 이해하고 생성하는 대규모 비전-언어 모델(Large Vision-Language Models, 이하 LVLM)로 급격히 이동하고 있다. LLaVA, InstructBLIP, Qwen-VL, MiniGPT-4와 같은 모델들은 이미지를 입력받아 상세한 묘사를 생성하거나, 이미지 내용에 기반한 복잡한 추론을 수행하는 시각적 질의응답(Visual Question Answering, VQA) 작업에서 인간에 버금가는 성능을 보여주었다.1 이러한 모델들은 대개 시각적 인코더(Visual Encoder)가 추출한 이미지 특징을 LLM이 이해할 수 있는 임베딩 공간으로 투영하고, 이를 텍스트 프롬프트와 결합하여 자기회귀적(Autoregressive)으로 답변을 생성하는 구조를 띤다.</p>
<p>그러나 이러한 기술적 성취 이면에는 모델의 신뢰성을 근본적으로 위협하는 치명적인 결함이 존재한다. 바로 ‘객체 환각(Object Hallucination)’ 현상이다. 환각이란 모델이 주어진 시각적 맥락(이미지)에 존재하지 않는 객체, 속성, 또는 관계를 마치 실재하는 것처럼 확신을 가지고 생성하는 현상을 일컫는다.3 예를 들어, 텅 빈 거실 사진을 보고 “소파 위에 고양이가 앉아 있다“라고 묘사하거나, 식탁 위에 접시만 있는 이미지를 보고 “포크와 나이프가 놓여 있다“고 답변하는 식이다. 이는 단순한 오류를 넘어, 의료 진단, 자율 주행, 법적 증거 분석 등 고도의 정확성이 요구되는 실세계 어플리케이션(Real-world applications)에 LVLM을 도입하는 데 있어 가장 큰 걸림돌로 작용하고 있다.1</p>
<h3>1.2  환각 현상의 근원적 원인 분석</h3>
<p>학계에서는 LVLM이 겪는 환각의 원인을 규명하기 위해 다각적인 노력을 기울여 왔으며, 현재 주류를 이루는 이론은 크게 두 가지 요인의 상호작용으로 설명된다.</p>
<p>첫째, **통계적 편향(Statistical Bias)과 언어적 우선순위(Language Priors)**의 문제이다. LVLM의 두뇌 역할을 하는 LLM은 방대한 텍스트 데이터를 통해 사전 학습(Pre-training)되었기 때문에, 단어와 단어 사이의 공기(Co-occurrence) 패턴에 깊이 의존한다. 학습 데이터에서 ’식탁’과 ’포크’가 자주 함께 등장했다면, 모델은 이미지에 포크가 없더라도 ’식탁’이라는 단어를 생성한 직후 확률적으로 ’포크’를 생성하려는 강한 내적 충동(Internal Bias)을 가진다.2 이는 시각적 정보가 텍스트 생성 과정을 온전히 제어하지 못하고, 언어 모델의 강력한 사전 지식이 시각적 사실성을 압도할 때 발생한다.</p>
<p>둘째, **시각적 불확실성(Visual Uncertainty)**과 **시각-언어 불일치(Misalignment)**이다. 입력 이미지가 흐릿하거나, 객체가 가려져 있거나, 시각 인코더가 정보를 불완전하게 압축했을 때 모델은 부족한 시각 정보를 메우기 위해 자신의 내부 지식(Parametric Knowledge)에 더욱 의존하게 된다. 연구에 따르면, 시각적 정보가 불확실할수록 모델은 언어적 편향에 따라 답변을 생성하는 경향이 강해지며, 이는 곧 환각으로 이어진다.2</p>
<h3>1.3  기존 해결책의 한계와 VCD의 제안</h3>
<p>이러한 문제를 해결하기 위해 RLHF(Reinforcement Learning from Human Feedback)를 통한 미세 조정이나, 환각을 유발하지 않도록 데이터를 정제하는(Instruction Tuning) 방법들이 시도되었다. 그러나 이러한 접근법은 고품질의 데이터 구축 비용이 막대하며, 모델을 재학습시켜야 한다는 부담이 있다.5 또한, 빔 서치(Beam Search)와 같은 기존의 디코딩 전략은 생성문의 유창성을 높일 뿐 사실성(Faithfulness)을 보장하지 못하며, 오히려 언어적으로 그럴듯한 환각을 강화하는 부작용을 낳기도 한다.6</p>
<p>이러한 맥락에서 2024년 CVPR에서 발표된 **시각적 대조 디코딩(Visual Contrastive Decoding, VCD)**은 패러다임을 전환하는 해결책을 제시한다. VCD는 별도의 추가 학습이나 외부 데이터 없이, 추론(Inference) 단계에서 디코딩 전략을 수정하는 것만으로 환각을 획기적으로 줄일 수 있는 ‘훈련 없는(Training-free)’ 방법론이다. 본 보고서는 VCD의 이론적 메커니즘, 실험적 검증 결과, 그리고 이를 둘러싼 학계의 후속 논의를 심층적으로 분석한다.</p>
<hr />
<h2>2.  이론적 프레임워크: 대조 디코딩의 확장</h2>
<h3>2.1  텍스트 생성에서의 대조 디코딩 (Contrastive Decoding)</h3>
<p>VCD의 근간이 되는 ‘대조 디코딩(Contrastive Decoding, CD)’ 개념은 원래 자연어 처리(NLP) 분야에서 제안되었다. 이 기법은 ‘전문가(Expert)’ 모델의 확률 분포에서 ‘아마추어(Amateur)’ 모델의 확률 분포를 차감(Contrast)함으로써, 아마추어가 범하기 쉬운 상투적이고 편향된 오류를 제거하고 전문가만의 통찰력을 극대화한다는 아이디어에서 출발했다.7</p>
<p>수식적으로 이는 다음과 같이 표현된다:</p>
<p><span class="math math-display">\text{Logit}_{\text{CD}} = (1+\alpha)\text{Logit}_{\text{Expert}} - \alpha\text{Logit}_{\text{Amateur}}</span></p>
<p>여기서 <span class="math math-inline">\alpha</span>는 대조의 강도를 조절하는 하이퍼파라미터이다. 이 식을 통해 두 모델이 공통적으로 가지고 있는 편향(일반적인 언어 패턴)은 상쇄되고, 전문가 모델만이 포착한 정보가 강조된다.</p>
<h3>2.2 시각적 도메인으로의 확장: 무엇이 ’아마추어’인가?</h3>
<p>VCD 연구진은 이 개념을 LVLM에 적용하기 위해 핵심적인 질문을 던졌다. “LVLM에서 환각을 유발하는 ’아마추어’의 역할을 하는 것은 무엇인가?”</p>
<p>연구진의 가설은 **“시각적 정보가 손상된 상태의 모델”**이야말로 언어적 편향에만 의존하여 환각을 쏟아내는 ’아마추어’와 같다는 것이다.2 즉, 원본 이미지를 본 모델(Expert)과 의도적으로 왜곡된 이미지를 본 모델(Amateur)을 대조시키면, 언어적 편향은 제거되고 순수한 시각적 근거에 기반한 정보만 남을 것이라는 논리이다.</p>
<hr />
<h2>3. 시각적 대조 디코딩(VCD)의 핵심 메커니즘</h2>
<p>VCD는 크게 두 가지 단계로 구성된다. 첫째는 시각적 불확실성을 주입하여 환각을 유도하는 단계이고, 둘째는 이를 원본 분포와 대조하여 교정하는 단계이다. 여기에 생성된 문장의 타당성을 보장하기 위한 제약 조건이 추가된다.</p>
<h3>3.1 시각적 왜곡(Visual Distortion)을 통한 환각 유도</h3>
<p>VCD는 대조군(Negative Sample)을 생성하기 위해 원본 이미지 <span class="math math-inline">v</span>에 인위적인 노이즈를 주입하여 왜곡된 이미지 <span class="math math-inline">v&#39;</span>를 생성한다. 연구진은 단순한 픽셀 마스킹이나 블러링 대신, **확산 모델(Diffusion Model)**에서 사용되는 노이즈 스케줄링 방식을 차용하여 가우시안 노이즈(Gaussian Noise)를 주입하는 방식을 채택했다.1</p>
<p>왜곡된 이미지 <span class="math math-inline">v&#39;</span>는 다음과 같은 확산 과정을 통해 생성된다 1:</p>
<p><span class="math math-display">v&#39; = \text{AddNoise}(v, \text{step}=T)</span></p>
<p>여기서 <span class="math math-inline">T</span>는 노이즈의 강도를 결정하는 단계 수이다. 실험적으로 전체 1000단계 중 약 500단계(<span class="math math-inline">T=500</span>) 수준의 노이즈를 주입했을 때, 이미지의 의미론적 정보는 파괴되면서도 모델의 입력 형식은 유지되어 가장 효과적인 대조군이 생성됨이 밝혀졌다.8</p>
<p>왜곡된 이미지 <span class="math math-inline">v&#39;</span>가 입력되면, LVLM은 시각적 근거를 상실하게 된다. 이때 모델은 불확실성을 해소하기 위해 자신이 학습한 데이터의 통계적 패턴(언어적 우선순위)에 전적으로 의존하게 된다. 예를 들어, 질문이 “식탁 위에 무엇이 있는가?“라면, 시각 정보가 없는 모델은 학습 데이터에서 식탁과 자주 등장했던 “포크, 나이프, 접시” 등의 단어 확률을 높이게 된다. 이것이 바로 우리가 제거하고자 하는 ’환각 성분’이다.2</p>
<h3>2.2  대조적 분포(Contrastive Distribution) <span class="math math-inline">p_{vcd}</span>의 도출</h3>
<p>VCD는 원본 이미지 <span class="math math-inline">v</span>에 대한 로짓과 왜곡된 이미지 <span class="math math-inline">v&#39;</span>에 대한 로짓의 차이를 계산하여 새로운 확률 분포 <span class="math math-inline">p_{vcd}</span>를 정의한다. 구체적인 수식은 다음과 같다 1:</p>
<p><span class="math math-display">p_{vcd}(y \mid v, v&#39;, x) = \text{softmax}\left( (1+\alpha) \cdot \text{logit}_\theta(y \mid v, x) - \alpha \cdot \text{logit}_\theta(y \mid v&#39;, x) \right)</span></p>
<p>이 수식의 의미는 다음과 같이 해석된다:</p>
<ul>
<li><span class="math math-inline">\text{logit}_\theta(y \mid v, x)</span>: <strong>원본 분포.</strong> 정답 정보와 환각(언어적 편향)이 섞여 있다.</li>
<li><span class="math math-inline">\text{logit}_\theta(y \mid v&#39;, x)</span>: <strong>왜곡된 분포.</strong> 시각 정보는 없고 환각(언어적 편향)만이 극대화되어 있다.</li>
<li><strong>차감(-):</strong> 원본 분포에서 왜곡된 분포를 뺌으로써, 두 분포에 공통적으로 존재하는 ’언어적 편향’을 상쇄시킨다. 결과적으로 시각적 정보에 근거한 토큰의 확률은 상대적으로 높아지고, 단순히 언어적 습관에 의해 생성되려던 토큰의 확률은 억제된다.</li>
<li><span class="math math-inline">\alpha</span>: 대조의 강도를 조절하는 하이퍼파라미터로, 일반적으로 <span class="math math-inline">\alpha=1.0</span> 또는 <span class="math math-inline">\alpha=0.5</span>가 사용된다.8</li>
</ul>
<h3>3.3 적응형 타당성 제약 (Adaptive Plausibility Constraints, APC)</h3>
<p>단순히 두 로짓을 빼는 것만으로는 문제가 발생할 수 있다. 왜곡된 이미지에서도 우연히 정답 토큰의 확률이 높을 수 있는데(예: 아주 일반적인 문법적 요소), 이를 무조건 빼버리면 문법적으로 엉망인 문장이 생성되거나, 엉뚱한 단어(Low-probability token)의 확률이 비정상적으로 튀어 오르는 부작용이 생길 수 있다.2</p>
<p>이를 방지하기 위해 VCD는 **적응형 타당성 제약(Adaptive Plausibility Constraints)**을 도입한다. 이는 “원본 이미지를 보았을 때 충분히 신뢰할 수 있는 토큰들 중에서만 최종 답을 고르라“는 안전장치이다.</p>
<p>후보 토큰 집합(Candidate Set)인 <span class="math math-inline">\mathcal{V}_{\text{head}}</span>는 다음과 같이 정의된다 2:</p>
<p><span class="math math-display"> \mathcal{V}*{\text{head}}(y*{&lt;t}) = { y_t \in \mathcal{V} \mid p_\theta(y_t \mid v, x, y_{&lt;t}) \ge \beta \cdot \max_{w} p_\theta(w \mid v, x, y_{&lt;t}) }</span></p>
<ul>
<li>이 조건은 현재 단계에서 가장 확률이 높은 토큰의 확률 대비 <span class="math math-inline">\beta</span>배 이상인 토큰들만 남기고 나머지는 걸러낸다는 의미이다.</li>
<li>최종적으로 <span class="math math-inline">p_{vcd}</span>는 <span class="math math-inline">\mathcal{V}_{\text{head}}</span>에 속한 토큰에 대해서만 계산되며, 그 외의 토큰 확률은 0으로 처리된다.</li>
<li><span class="math math-inline">\beta</span>: 절단(Truncation) 임계값으로, 보통 <span class="math math-inline">\beta=0.1</span>이 사용된다. 이는 대조 디코딩이 지나치게 모험적인(implausible) 선택을 하는 것을 막고, 모델의 생성 능력을 합리적인 범위 내로 제한한다.8</li>
</ul>
<hr />
<h2>3.  실험적 검증 및 데이터 분석</h2>
<p>VCD의 유효성을 검증하기 위해 연구진은 LLaVA-1.5, InstructBLIP, Qwen-VL 등 대표적인 LVLM을 사용하여 광범위한 실험을 수행하였다. 주요 벤치마크로는 객체 환각을 평가하는 <strong>POPE</strong>, 전반적인 인지 능력을 평가하는 <strong>MME</strong> 등이 사용되었다.</p>
<h3>3.1  POPE 벤치마크: 환각 완화 성능의 정량적 평가</h3>
<p>POPE(Polling Object via Polling Strategy)는 이미지 내 객체 존재 여부를 “Yes/No“로 묻는 이진 분류 태스크로, 환각 평가의 표준으로 자리 잡았다. POPE는 데이터셋 구성 방식에 따라 세 가지 설정으로 나뉜다 3:</p>
<ol>
<li><strong>Random:</strong> 데이터셋에 있는 객체를 무작위로 질문.</li>
<li><strong>Popular:</strong> 데이터셋에서 빈번하게 등장하는 객체 위주로 질문 (빈도 편향 테스트).</li>
<li><strong>Adversarial:</strong> 이미지에는 없지만, 이미지에 있는 객체와 자주 함께 등장하는(Co-occurring) 객체를 질문. 이는 언어적 편향이 가장 강하게 작용하는 설정으로, 모델이 가장 취약한 부분이다.</li>
</ol>
<p>아래 표는 LLaVA-1.5 모델을 기준으로 한 POPE 벤치마크 결과이다.2</p>
<table><thead><tr><th><strong>벤치마크 설정 (Setting)</strong></th><th><strong>지표 (Metric)</strong></th><th><strong>일반 디코딩 (Regular)</strong></th><th><strong>VCD 적용 (VCD)</strong></th><th><strong>성능 향상 (Gain)</strong></th></tr></thead><tbody>
<tr><td><strong>POPE - Random</strong></td><td>F1 Score</td><td>83.06</td><td><strong>86.15</strong></td><td>+3.09</td></tr>
<tr><td><strong>POPE - Random</strong></td><td>Accuracy</td><td>78.96</td><td><strong>80.88</strong></td><td>+1.92</td></tr>
<tr><td><strong>POPE - Popular</strong></td><td>F1 Score</td><td>79.54</td><td><strong>83.07</strong></td><td>+3.53</td></tr>
<tr><td><strong>POPE - Popular</strong></td><td>Accuracy</td><td>72.75</td><td><strong>79.45</strong></td><td>+6.70</td></tr>
<tr><td><strong>POPE - Adversarial</strong></td><td>F1 Score</td><td>76.61</td><td><strong>80.88</strong></td><td>+4.27</td></tr>
<tr><td><strong>POPE - Adversarial</strong></td><td>Accuracy</td><td>78.96</td><td><strong>81.47</strong></td><td>+2.51</td></tr>
</tbody></table>
<p><strong>데이터 분석 및 인사이트:</strong></p>
<ul>
<li><strong>Adversarial 설정에서의 압도적 우위:</strong> VCD는 모든 설정에서 일반 디코딩을 상회하였으나, 특히 **Adversarial 설정에서 가장 큰 폭의 F1 점수 향상(+4.27)**을 보였다. 이는 VCD가 단순히 모델의 정확도를 높이는 것을 넘어, 환각의 핵심 기제인 ’동시 등장 편향(Co-occurrence bias)’을 효과적으로 억제하고 있음을 시사한다. 식탁을 보고 습관적으로 ’포크가 있다’고 답하는 경향이 VCD를 통해 교정된 것이다.</li>
<li><strong>일관된 성능 향상:</strong> LLaVA-1.5뿐만 아니라 Qwen-VL, InstructBLIP 등 다른 모델 아키텍처에서도 유사한 성능 향상이 관찰되었다. 예를 들어 InstructBLIP의 경우 POPE-Random 설정에서 F1 점수가 75.84에서 79.56으로 상승하였다.2</li>
</ul>
<h3>3.2  MME 벤치마크: 인지 능력과 환각의 균형</h3>
<p>MME(Multimodal Evaluation) 벤치마크는 환각뿐만 아니라 모델의 전반적인 인지(Perception) 및 인식(Cognition) 능력을 평가한다. 환각 억제 기법이 모델의 일반적인 묘사 능력을 저해해서는 안 된다는 점에서 중요한 지표이다.</p>
<ul>
<li><strong>LLaVA-1.5 MME Score:</strong> VCD 적용 시 일반 디코딩 대비 **약 +18%**의 총점 향상이 보고되었다.2</li>
<li>세부적으로는 객체의 존재(Existence), 수량(Count), 위치(Position), 색상(Color)을 묻는 Hallucination subset에서 큰 점수 상승이 있었다.</li>
<li>이는 VCD가 단순히 답변을 보수적으로 만드는(모든 질문에 No라고 답하게 하는) 것이 아니라, 시각적 정보를 더 정확하게 인지하도록 돕는다는 것을 의미한다. 원본 이미지의 로짓을 강조함으로써(1+<span class="math math-inline">\alpha</span>), 시각적 근거가 뚜렷한 정보에 대한 확신을 높여주기 때문이다.</li>
</ul>
<h3>3.3  정성적 사례 분석 (Qualitative Case Studies)</h3>
<p>실제 생성된 텍스트를 분석해보면 VCD의 작동 방식을 직관적으로 이해할 수 있다.1</p>
<ul>
<li><strong>사례 1 (부엌 장면):</strong> 이미지에는 식탁과 의자만 존재한다. 일반 디코딩(Regular)은 “식탁 위에 <strong>포크와 나이프</strong>가 차려져 있다“라고 묘사했다. 반면 VCD는 “식탁 위는 비어 있다“라고 정확하게 묘사했다. 왜곡된 이미지에서는 ’식탁’이라는 단어가 ’포크’를 유도하는 언어적 편향이 강하게 작용했지만, VCD 과정에서 이 편향이 상쇄되었기 때문이다.</li>
<li><strong>사례 2 (거리 장면):</strong> 일반 디코딩은 군중 속에 <strong>특정 색상의 옷을 입은 사람</strong>이 있다고 환각을 보였으나, VCD는 이를 수정하였다.</li>
</ul>
<hr />
<h2>4.  최신 연구 동향 및 비교 분석 (2024-2025)</h2>
<p>VCD 발표 이후, 이를 기반으로 하거나 이를 능가하기 위한 다양한 파생 연구들이 등장하였다. 이들과의 비교는 VCD의 위치를 더욱 명확히 해준다.</p>
<h3>4.1  VCD vs. ICD (Instruction Contrastive Decoding)</h3>
<p>VCD가 시각적 입력(Vision)에 노이즈를 주어 대조군을 만들었다면, <strong>ICD</strong>는 텍스트 지시문(Instruction)에 교란을 주어 대조군을 만드는 방식이다.3</p>
<ul>
<li><strong>접근법의 차이:</strong> ICD 연구진은 환각이 시각적 불확실성뿐만 아니라, 질문의 유형이나 지시문의 패턴에 의해서도 강화된다고 보았다. 따라서 질문에 오해의 소지가 있는 내용을 섞거나 변형하여 ‘함정’ 질문을 만들고, 이에 속아 넘어가는 모델(Amateur)과 원본 모델을 대조한다.</li>
<li><strong>성능 비교:</strong> 일부 실험에서 ICD는 VCD보다 높은 성능을 보이기도 했으나, VCD는 시각적 왜곡이라는 물리적 직관에 기반하고 있어 이미지 자체의 품질이 낮은 경우(저화질, 가려짐)에 더 강건한 특성을 보인다.11</li>
</ul>
<h3>4.2  VCD vs. AVISC (Attentional Vision Calibration)</h3>
<p><strong>AVISC</strong>는 VCD가 이미지 전체에 일률적인 가우시안 노이즈를 적용하는 것의 비효율성을 지적하며 등장했다.6</p>
<ul>
<li><strong>한계 지적:</strong> VCD처럼 이미지 전체를 망가뜨리면, 환각과 관련 없는 배경 정보까지 손실되어 모델의 전반적인 묘사 능력이 떨어질 수 있다.</li>
<li><strong>개선:</strong> AVISC는 주의(Attention) 메커니즘을 활용하여 환각이 발생할 확률이 높은 특정 이미지 패치나 토큰만을 선별적으로 보정한다. POPE 벤치마크에서 AVISC는 VCD 대비 약 2~5% 포인트 높은 F1 점수를 기록하며 최신 SOTA(State-of-the-art) 수준을 달성하였다.6 그러나 구현 복잡도는 VCD보다 높다.</li>
</ul>
<h3>4.3  VCD vs. SAVCD (Self-Augmented VCD)</h3>
<p>2025년 제안된 <strong>SAVCD</strong>는 VCD의 진화형으로 볼 수 있다.10</p>
<ul>
<li><strong>자가 증강(Self-Augmentation):</strong> 외부 노이즈(가우시안)를 쓰는 대신, 모델 자신이 생성한 신뢰도 정보를 바탕으로 더 정교한 왜곡(Distortion) 전략을 사용한다.</li>
<li><strong>성능:</strong> LLaVA-1.5 및 InstructBLIP 모델에서 VCD 대비 약 6~18%의 추가적인 성능 향상을 보였다. 특히 InstructBLIP 모델에서 VCD가 큰 효과를 보지 못했던 영역(Adversarial)에서도 SAVCD는 괄목할 만한 성과를 냈다. 이는 VCD의 “대조(Contrastive)” 철학이 유효하며, “무엇과 대조할 것인가“를 최적화함으로써 성능을 더 끌어올릴 수 있음을 시사한다.</li>
</ul>
<h3>4.4  VCD vs. M3ID (Multimodal Multi-Image Decoding)</h3>
<p>M3ID 역시 대조 디코딩의 일종이지만, 시각 정보를 아예 제거한(Blind model) 경우와 대조하거나, 다른 이미지를 보여주는 방식을 취한다.6 VCD는 노이즈가 섞인 이미지를 사용함으로써 ’완전한 정보 부재’보다는 ‘불확실한 정보’ 상황을 시뮬레이션한다는 점에서 차이가 있다. 실험 결과, VCD가 M3ID보다 미세하게 더 나은 일반화 성능을 보이는 경향이 있다.6</p>
<hr />
<h2>5.  비판적 고찰 및 한계점</h2>
<p>VCD가 환각 완화의 강력한 도구임은 분명하지만, 몇 가지 한계와 비판적 시각 또한 존재한다.</p>
<h3>5.1  계산 비용(Computational Overhead)의 문제</h3>
<p>VCD의 가장 큰 단점은 추론 속도이다. 하나의 토큰을 생성할 때마다 원본 이미지에 대한 연산과 왜곡된 이미지에 대한 연산, 즉 두 번의 순전파(Forward pass)가 필요하다. 이는 이론적으로 추론 시간을 2배로 증가시킨다.10</p>
<ul>
<li>실제 측정 결과, LLaVA-1.5 7B 모델 기준 초당 생성 토큰 수가 약 50% 감소하였다. 실시간성이 중요한 서비스에서는 도입이 부담스러울 수 있다. 이를 해결하기 위해 모든 토큰이 아닌, 불확실성이 높은 토큰에서만 선택적으로 VCD를 적용하는 연구가 필요하다.</li>
</ul>
<h3>5.2  보수적 답변 편향 (Conservative Bias)</h3>
<p>일부 연구 9는 VCD의 성능 향상이 실제 환각 감소보다는 “모델을 지나치게 신중하게 만드는 부작용“에서 기인한다고 비판한다.</p>
<ul>
<li>POPE 벤치마크는 “Yes/No” 답변 비중이 50:50이다. 그러나 VCD를 적용하면 모델이 불확실한 상황에서 무조건 “No“라고 답하는 경향이 강해져, 우연히 점수가 높아질 수 있다는 지적이다.</li>
<li>실제로 VCD 적용 후 “없다“라는 답변의 비율이 상승하는 현상이 관찰되었다. 이는 환각(없는 것을 있다고 함)을 줄이는 데는 효과적이지만, 있는 것을 없다고 하는 누락(Miss) 오류를 증가시킬 위험이 있다.</li>
</ul>
<h3>5.3  하이퍼파라미터 민감도</h3>
<p><span class="math math-inline">\alpha</span> (대조 강도)와 <span class="math math-inline">\beta</span> (타당성 제약) 값에 따라 성능 편차가 크다.8</p>
<ul>
<li><span class="math math-inline">\alpha</span>가 너무 크면 문법이 파괴되거나 문장이 반복되는 현상이 발생한다.</li>
<li><span class="math math-inline">\beta</span>가 너무 크면 창의적인 답변이 차단되고 뻔한 답변만 내놓게 된다.</li>
<li>최적의 파라미터는 모델 종류와 태스크에 따라 다르므로, 실제 적용 시 튜닝 과정이 필요하다.</li>
</ul>
<hr />
<h2>6.  결론 및 제언</h2>
<h3>6.1  연구 요약</h3>
<p>시각적 대조 디코딩(VCD)은 대규모 비전-언어 모델(LVLM)의 고질적인 문제인 객체 환각을 해결하기 위해 제안된 혁신적인 방법론이다. VCD는 **“시각적 정보가 불확실할 때 모델은 내부의 언어적 편향에 의존한다”**는 통찰을 바탕으로, 원본 분포와 시각적 노이즈가 주입된 왜곡된 분포를 대조하여 언어적 편향을 제거하고 시각적 사실성을 확보한다. 특히 적응형 타당성 제약(APC)을 통해 언어적 유창성을 유지하면서도 환각을 효과적으로 억제하는 균형을 달성하였다. 실험 결과, VCD는 POPE, MME 등 주요 벤치마크에서 별도의 학습 없이도 모델 성능을 유의미하게 향상시켰다.</p>
<h3>6.2  시사점 및 실무적 제언</h3>
<ol>
<li><strong>즉각적인 도입 가능성:</strong> VCD는 학습이 필요 없는(Training-free) 기법이므로, 이미 배포된 LVLM 파이프라인에 즉시 적용하여 신뢰성을 높일 수 있다. 특히 안전이 중요한 도메인에서 “Positive Hallucination”(없는 것을 있다고 함)을 억제하는 데 매우 유용하다.</li>
<li><strong>비용과 성능의 트레이드오프:</strong> 추론 비용이 2배로 증가한다는 점을 고려해야 한다. 실시간 채팅보다는 정밀한 이미지 분석이나 의료 영상 판독과 같이 정확도가 속도보다 중요한 분야에 적합하다.</li>
<li><strong>멀티모달 정렬의 새로운 시각:</strong> 단순히 모델을 크게 만들거나 데이터를 늘리는 것 외에, **디코딩 전략(Inference Strategy)**을 통해 모달리티 간의 불균형을 교정할 수 있다는 중요한 연구 방향을 제시했다.</li>
</ol>
<h3>6.3  향후 연구 방향</h3>
<p>향후 연구는 VCD의 높은 계산 비용을 줄이기 위한 경량화 기법(예: 조기 종료, 선택적 대조) 개발에 집중되어야 한다. 또한, 가우시안 노이즈보다 더 효과적으로 모델의 시각적 의존성을 끊어낼 수 있는 새로운 왜곡 기법(예: 적대적 섭동, 의미론적 마스킹)에 대한 탐구가 지속되어야 할 것이다. VCD는 LVLM의 신뢰성을 확보하기 위한 여정에서 중요한 이정표를 제시하였으며, SAVCD, AVISC와 같은 후속 연구들의 탄탄한 기반이 되고 있다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>DAMO-NLP-SG/VCD: [CVPR 2024 Highlight] Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding - GitHub, https://github.com/DAMO-NLP-SG/VCD</li>
<li>Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2024/papers/Leng_Mitigating_Object_Hallucinations_in_Large_Vision-Language_Models_through_Visual_Contrastive_CVPR_2024_paper.pdf</li>
<li>Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding - ACL Anthology, https://aclanthology.org/2024.findings-acl.937.pdf</li>
<li>Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding - arXiv, https://arxiv.org/html/2403.18715v1</li>
<li>Hallucinogen: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models - arXiv, https://arxiv.org/html/2412.20622v1</li>
<li>Don’t Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models - ACL Anthology, https://aclanthology.org/2025.findings-acl.99.pdf</li>
<li>CODE: Contrasting Self-generated Description to Combat Hallucination in Large Multi-modal Models - NIPS papers, https://proceedings.neurips.cc/paper_files/paper/2024/file/f1592b0d4ab737e18bb1899484d28d96-Paper-Conference.pdf</li>
<li>A. Detailed Experimental Settings B. Ablation Studies - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2024/supplemental/Leng_Mitigating_Object_Hallucinations_CVPR_2024_supplemental.pdf</li>
<li>The Mirage of Performance Gains: Why Contrastive Decoding Fails to Mitigate Object Hallucinations in MLLMs? - arXiv, https://arxiv.org/html/2504.10020v3</li>
<li>Self-Augmented Visual Contrastive Decoding - arXiv, https://arxiv.org/html/2510.13315v1</li>
<li>Delve into Visual Contrastive Decoding for Hallucination Mitigation of Large Vision-Language Models - arXiv, https://arxiv.org/html/2412.06775v1</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>