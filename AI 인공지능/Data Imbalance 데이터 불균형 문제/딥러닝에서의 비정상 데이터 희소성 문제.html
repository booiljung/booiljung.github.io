<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:딥러닝에서의 비정상 데이터 희소성 문제</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>딥러닝에서의 비정상 데이터 희소성 문제</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">데이터 불균형 문제 (Data Imbalance Problem)</a> / <span>딥러닝에서의 비정상 데이터 희소성 문제</span></nav>
                </div>
            </header>
            <article>
                <h1>딥러닝에서의 비정상 데이터 희소성 문제</h1>
<h2>1. 요약(Executive Summary)</h2>
<p>딥러닝 모델의 성공은 대규모의 잘 레이블링된 데이터에 크게 의존하지만, 현실 세계의 많은 중요 문제에서는 특정 클래스의 데이터, 특히 ‘비정상(abnormal)’ 데이터가 극도로 부족한 상황에 직면한다. 산불 탐지, 의료 진단, 금융 사기 방지, 산업 공정의 결함 검출과 같은 분야에서 이러한 데이터 불균형은 모델의 성능을 심각하게 저해하는 핵심적인 도전 과제이다. 본 안내서는 딥러닝 모델 훈련 시 발생하는 비정상 데이터의 희소성 문제를 해결하기 위한 다각적인 전략을 심층적으로 분석하고 고찰한다.</p>
<p>안내서는 먼저 데이터 불균형 문제의 근본적인 원인과 이것이 모델 학습에 미치는 편향된 영향을 정의하며, 특히 산불 탐지 사례를 통해 데이터 수집의 현실적인 어려움을 조명한다. 이어서 문제 해결을 위한 접근법을 네 가지 핵심 범주로 나누어 체계적으로 탐구한다. 첫째, 데이터 및 알고리즘 수준의 기초적인 조정 기법으로, 데이터 리샘플링의 한계와 비용 민감 학습(Cost-Sensitive Learning), 그리고 더 나아가 학습의 초점을 동적으로 조절하는 포컬 로스(Focal Loss)의 원리를 분석한다. 둘째, 소수의 데이터로부터 학습 능력을 극대화하는 고급 패러다임으로서, 정상 데이터만으로 학습하는 단일 클래스 분류(One-Class Classification)와 극소량의 샘플로 새로운 개념을 학습하는 퓨샷 러닝(Few-Shot Learning)을 다룬다. 셋째, 외부의 방대한 지식을 활용하는 전이 학습(Transfer Learning)의 강력한 잠재력을 구름과 연기의 물리적 유사성을 활용한 산불 탐지 고도화 사례를 통해 구체적으로 입증한다.</p>
<p>마지막으로, 본 안내서는 데이터 증강의 한계를 넘어 데이터 ’시뮬레이션’의 시대로 나아가는 최첨단 생성 모델(Generative Models) 기술에 집중한다. 생성적 적대 신경망(GANs)을 활용한 초기 성공 사례와 그 한계를 짚어보고, 현존하는 가장 강력한 기술인 확산 모델(Diffusion Models)이 어떻게 더 높은 품질과 제어 가능성을 바탕으로 비정상 데이터 생성의 새로운 지평을 열고 있는지 상세히 기술한다. 특히, 특정 영역에 원하는 이상 현상을 정교하게 합성하는 제어 가능한 이상 생성(Controllable Anomaly Synthesis) 프레임워크는 이 분야의 정점을 보여준다.</p>
<p>결론적으로, 본 안내서는 각 기술의 이론적 배경, 장단점, 계산 비용 및 이상적인 적용 시나리오를 종합적으로 비교 분석하여 실무자와 연구자에게 실질적인 가이드라인을 제공한다. 데이터 희소성 문제 해결의 기술적 흐름이 단순한 데이터 조작에서 출발하여, 외부 지식의 활용을 거쳐, 궁극적으로는 필요한 데이터를 정밀하게 시뮬레이션하는 방향으로 진화하고 있음을 명확히 제시하며, 이는 미래의 고신뢰성 인공지능 시스템 구축에 있어 핵심적인 전략적 방향이 될 것이다.</p>
<h2>2.  데이터 불균형의 근본적 도전 과제와 이상 탐지</h2>
<h3>2.1  데이터 불균형의 정의와 딥러닝 모델에 대한 영향</h3>
<p>데이터 불균형(Data Imbalance)은 특정 클래스에 속한 데이터의 수가 다른 클래스에 비해 현저히 많거나 적은 현상을 지칭한다.1 대부분의 표준적인 머신러닝 및 딥러닝 분류 알고리즘은 각 클래스의 데이터 비율이 비슷하다는 암묵적인 가정 하에 설계되었다.3 이 가정이 깨질 경우, 모델은 훈련 과정에서 다수 클래스(majority class)의 패턴에 과도하게 최적화되는 경향을 보인다. 결과적으로, 모델은 전체 정확도(accuracy)는 높게 나타날 수 있지만, 정작 중요한 소수 클래스(minority class)에 대한 예측 성능, 즉 재현율(recall)이 매우 저조해지는 심각한 편향 문제를 야기한다.4</p>
<p>이러한 편향은 모델이 소수 클래스가 가진 고유하고 중요한 패턴을 학습하지 못하고, 대신 대부분의 데이터를 다수 클래스로 예측하는 단순한 결정 경계(decision boundary)를 형성하게 만들기 때문이다.4 예를 들어, 99%의 데이터가 ’정상’이고 1%가 ’비정상’인 데이터셋에서 모델이 모든 입력을 ’정상’으로 예측하더라도 99%의 정확도를 달성할 수 있다. 하지만 이 모델은 비정상 상황을 단 한 건도 탐지하지 못하므로 실제적인 효용 가치가 없다.6 이처럼 데이터 불균형은 모델의 일반화 성능을 저해하고, 특히 우리가 탐지하고자 하는 대상이 소수 클래스일 때 치명적인 결과를 초래한다.7</p>
<h3>2.2  ‘비정상’ 데이터 희소성의 특수성</h3>
<p>일반적인 데이터 불균형 문제와 달리, 이상 탐지(Anomaly Detection) 분야에서 마주하는 ‘비정상’ 데이터의 희소성은 더욱 극단적이고 근본적인 성격을 띤다. 이는 단순히 데이터의 양적 불균형을 넘어, 정보의 본질적인 결핍 상태를 의미한다. 비정상 데이터는 다음과 같은 특성을 지닌다.</p>
<ul>
<li><strong>근본적 희귀성 (Fundamental Rarity):</strong> 산불, 희귀 질병, 신용카드 사기, 치명적인 산업 설비 고장 등은 본질적으로 드물게 발생하는 사건이다. 따라서 대규모의 비정상 데이터를 수집하는 것 자체가 현실적으로 불가능에 가깝다.2</li>
<li><strong>높은 수집 비용 및 위험:</strong> 비정상 데이터는 수집 과정에서 막대한 비용이나 위험을 수반할 수 있다. 예를 들어, 실제 산불 현장에서 고품질의 연기 이미지를 체계적으로 수집하는 것은 안전 문제와 예측 불가능성으로 인해 매우 어렵다.9</li>
<li><strong>다양성과 비정형성 (Diversity and Unpredictability):</strong> 비정상 상태는 매우 다양한 형태로 나타나며, 이전에 관측되지 않은 새로운 패턴으로 발생할 수 있다. 이는 한정된 수의 비정상 데이터만으로는 모든 가능한 이상 상태를 포괄하는 모델을 훈련시키기 어렵게 만든다.10</li>
</ul>
<p>이러한 특성 때문에 비정상 데이터 희소성 문제는 단순한 데이터 수집 노력만으로 해결될 수 없는 구조적인 한계를 가지며, 이는 후술할 고도화된 해결 전략의 필요성을 뒷받침한다.2</p>
<h3>2.3  문제의 재구성: 분류 문제에서 이상 탐지로</h3>
<p>데이터 불균형 문제를 해결하기 위한 첫 번째 패러다임 전환은, 문제를 전통적인 다중 클래스 ‘분류(Classification)’ 문제에서 ’이상 탐지(Anomaly Detection)’의 관점으로 재구성하는 것이다. 두 접근 방식은 목표에서 근본적인 차이를 보인다.</p>
<ul>
<li><strong>분류 (Classification):</strong> 주어진 여러 클래스(예: ‘정상’, ‘비정상’)를 명확하게 구분하는 경계면(decision boundary)을 찾는 것을 목표로 한다. 이 접근법은 모든 클래스에 대한 충분한 데이터가 존재하고, 각 클래스의 특징을 명확히 정의할 수 있을 때 효과적이다.11</li>
<li><strong>이상 탐지 (Anomaly Detection):</strong> 다수의 ‘정상(normal)’ 데이터가 형성하는 분포를 학습하고, 이 분포에서 벗어나는 패턴을 보이는 데이터를 ’비정상(abnormal)’으로 탐지하는 것을 목표로 한다.11 즉, “무엇이 비정상인가?“를 직접 정의하는 대신, “무엇이 정상인가?“를 정밀하게 정의하고 그 외의 모든 것을 비정상으로 간주하는 방식이다.10</li>
</ul>
<p>이러한 관점의 전환은 매우 중요하다. 비정상 데이터가 거의 또는 전혀 없는 상황에서도 모델을 훈련시킬 수 있는 길을 열어주기 때문이다. 예를 들어, 정상 데이터만으로 정상 데이터의 특징 공간을 감싸는 경계를 학습하는 단일 클래스 분류(One-Class Classification)와 같은 기법들이 바로 이 이상 탐지의 패러다임에 기반한다.13 따라서 많은 이상 탐지 모델링은 지도 학습(Supervised Learning)보다는 비지도 학습(Unsupervised Learning) 또는 준지도 학습(Semi-supervised Learning) 방식을 적극적으로 활용한다.8</p>
<h3>2.4  사례 연구: 산불 탐지에서의 데이터 수집 난제</h3>
<p>사용자가 제시한 산불 탐지 모델 훈련 사례는 비정상 데이터 희소성 문제를 명확하게 보여준다. 산불 연기 탐지 모델을 효과적으로 훈련시키기 위해서는 다양한 조건에서 촬영된 산불 연기 이미지가 대량으로 필요하지만, 현실에서는 다음과 같은 심각한 수집 난제에 부딪힌다.</p>
<ul>
<li><strong>예측 불가능성과 위험성:</strong> 산불은 예측 불가능하게 발생하며, 접근이 위험하여 체계적인 데이터 수집이 어렵다. 드론이나 CCTV를 활용하더라도 화재의 규모, 연기의 형태, 확산 방향 등을 통제할 수 없다.14</li>
<li><strong>환경적 변동성:</strong> 산불 연기의 시각적 특징은 조명 조건(낮, 밤, 황혼), 기상 상태(맑음, 흐림, 비), 지형, 식생의 종류에 따라 극심하게 변한다. 이러한 모든 변수를 포괄하는 데이터셋을 구축하는 것은 거의 불가능하다.15</li>
<li><strong>초기 단계 데이터의 부재:</strong> 산불 피해를 최소화하기 위해서는 발생 ‘초기’ 단계의 작은 연기를 탐지하는 것이 중요하지만, 이러한 순간을 포착한 데이터는 더욱 희귀하다.16</li>
</ul>
<p>이러한 현실적인 제약 조건 때문에 연구자들은 실제 연기 데이터 수집과 더불어, 연무기를 사용하여 인공적으로 연기를 발생시키거나 16, 일반 배경 이미지에 컴퓨터 그래픽으로 연기를 합성하는 등의 노력을 기울이고 있다. 그러나 이러한 방법들 역시 실제 산불 연기의 복잡하고 미묘한 특성을 완벽하게 재현하는 데에는 한계가 있다. 이처럼 산불 탐지 사례는 비정상 데이터의 절대적인 부족이 단순히 통계적 불균형을 넘어, 모델 성능을 좌우하는 근본적인 정보의 결핍 문제임을 명확히 보여주며, 이어지는 장들에서 논의될 다양한 해결 전략들의 실질적인 필요성을 강조한다.</p>
<h2>3.  기초적 접근법: 데이터 및 알고리즘 수준의 조정</h2>
<p>비정상 데이터 희소성 문제에 대응하는 가장 직관적이고 기초적인 방법론은 데이터 자체의 분포를 조정하거나, 모델의 학습 알고리즘을 수정하여 소수 클래스에 더 많은 가중치를 부여하는 것이다. 이러한 접근법들은 문제 해결의 출발점을 제시하지만, 각각 명확한 장단점과 한계를 지니고 있다.</p>
<h3>3.1  데이터 수준 전략: 리샘플링 기법에 대한 비판적 고찰</h3>
<p>데이터 수준의 전략은 훈련 데이터셋의 클래스 분포를 인위적으로 조정하여 균형을 맞추는 것을 목표로 한다. 대표적인 기법으로는 리샘플링(Resampling)이 있다.3</p>
<ul>
<li><strong>오버샘플링 (Over-sampling):</strong> 소수 클래스의 데이터를 무작위로 복제하여 그 수를 늘리는 방식이다. 구현이 간단하지만, 동일한 데이터를 반복적으로 학습하게 되므로 모델이 특정 소수 샘플에 과적합(overfitting)될 위험이 크다. 이는 모델이 소수 클래스의 매우 제한된 특징만을 학습하여 새로운, 보지 못한 비정상 데이터에 대한 일반화 성능이 떨어지는 결과로 이어진다.18</li>
<li><strong>언더샘플링 (Under-sampling):</strong> 다수 클래스의 데이터 중 일부를 무작위로 제거하여 소수 클래스와의 비율을 맞추는 방식이다. 과적합 위험은 줄일 수 있으나, 제거되는 다수 클래스 데이터에 포함된 유용하고 중요한 정보를 손실할 수 있다는 치명적인 단점이 있다. 이는 모델이 정상 상태의 다양성을 충분히 학습하지 못하게 만들어 오탐(false positive)의 가능성을 높일 수 있다.3</li>
</ul>
<p>이러한 단순 복제 및 제거의 한계를 극복하기 위해 SMOTE(Synthetic Minority Over-sampling Technique)와 같은 고급 기법이 제안되었다. SMOTE는 소수 클래스 데이터 포인트와 그 이웃 데이터 포인트들 사이에 새로운 합성 데이터를 생성하는 방식으로, 단순 복제보다 더 다양한 데이터를 만들어낸다.8 하지만 SMOTE 역시 특징 공간(feature space) 상에서 보간(interpolation)을 수행하기 때문에, 이미지 데이터와 같이 고차원적이고 복잡한 데이터에 적용할 경우 비현실적이거나 의미 없는 이미지를 생성할 수 있다는 한계를 가진다.</p>
<p>결론적으로, 리샘플링 기법은 문제에 대한 1차원적인 해결책을 제시한다. 이는 문제의 본질이 단순히 클래스 간의 ’수적 불균형’에 있다고 가정하지만, 실제 문제는 소수 클래스를 정의하는 ’정보의 부족’에 있다. 따라서 리샘플링은 근본적인 정보 결핍을 해결하지 못하며, 때로는 과적합이나 정보 손실과 같은 부작용을 낳을 수 있다.</p>
<h3>3.2  알고리즘 수준 전략: 학습 과정의 수정</h3>
<p>알고리즘 수준의 전략은 데이터셋 자체를 변경하는 대신, 모델의 학습 메커니즘을 수정하여 불균형 문제를 완화한다. 이는 데이터의 원본 분포를 유지하면서 모델이 소수 클래스에 더 집중하도록 유도하는 보다 정교한 접근법이다.</p>
<h4>3.2.1  비용 민감 학습: 오류의 가치 차등화</h4>
<p>비용 민감 학습(Cost-Sensitive Learning)은 각 클래스를 잘못 분류했을 때 발생하는 비용(cost)이 다르다는 현실적인 가정에서 출발한다.19 예를 들어, 산불 탐지에서 실제 산불(소수 클래스)을 놓치는 것(False Negative)의 비용은, 정상 상태를 산불로 오인하는 것(False Positive)의 비용보다 훨씬 크다. 비용 민감 학습은 이러한 비대칭적인 비용을 모델의 손실 함수(loss function)에 직접 반영한다.6</p>
<p>구체적으로, 소수 클래스에 속한 샘플을 잘못 분류할 경우 더 큰 페널티(가중치)를 부여한다. 예를 들어, 정상 클래스와 비정상 클래스의 비율이 9:1이라면, 손실 계산 시 비정상 클래스의 오류에 9배의 가중치를, 정상 클래스의 오류에 1배의 가중치를 부여하여 두 클래스의 오류가 전체 손실에 동등하게 기여하도록 조정할 수 있다.3 이 방식을 통해 모델은 자연스럽게 비용이 높은, 즉 더 중요한 소수 클래스의 분류 정확도를 높이는 방향으로 학습하게 된다.19 이 접근법은 데이터 분포를 변경하지 않으면서도 문제의 중요도를 모델에 직접 전달할 수 있다는 점에서 리샘플링보다 진일보한 방식으로 평가된다.</p>
<h4>3.2.2  포컬 로스: 어려운 예제에 대한 집중 학습</h4>
<p>포컬 로스(Focal Loss)는 비용 민감 학습에서 한 단계 더 나아가, 클래스 단위의 정적인 가중치 부여를 넘어 개별 샘플의 ’학습 난이도’에 따라 동적으로 가중치를 조절하는 혁신적인 손실 함수다.22 이 기법은 원래 극심한 클래스 불균형이 발생하는 객체 탐지(object detection) 문제를 해결하기 위해 제안되었지만, 그 원리는 이상 탐지에도 매우 효과적으로 적용된다.24</p>
<p>포컬 로스의 핵심 아이디어는, 훈련 과정에서 이미 모델이 쉽게 분류하는 샘플(easy examples)의 손실 기여도를 낮추고, 여전히 잘못 분류하고 있는 어려운 샘플(hard examples)에 학습을 집중시키는 것이다.23 표준적인 교차 엔트로피(Cross-Entropy) 손실 함수는 다음과 같이 정의된다.<br />
<span class="math math-display">
\text{CE}(p_t)=−\log(p_t)
</span><br />
여기서 <span class="math math-inline">p_t</span>는 모델이 정답 클래스에 대해 예측한 확률이다. 포컬 로스는 여기에 변조 계수(modulating factor) <span class="math math-inline">(1−p_t)^γ</span>를 추가한다.<br />
<span class="math math-display">
\text{FL}(p_t)=−α_t(1−p_t)^γ \log(p_t)
</span></p>
<ul>
<li><strong>변조 계수</strong><span class="math math-inline">(1−p_t)^γ</span>: 이 항이 포컬 로스의 핵심이다.</li>
<li>모델이 샘플을 <strong>쉽게</strong> 분류할 경우 (<span class="math math-inline">p_t</span>가 1에 가까움), <span class="math math-inline">(1−p_t)^γ</span>는 0에 가까워져 해당 샘플의 손실이 크게 감소한다.</li>
<li>모델이 샘플을 <strong>어렵게</strong> 분류할 경우 (<span class="math math-inline">p_t</span>가 0에 가까움), <span class="math math-inline">(1−p_t)^γ</span>는 1에 가까워져 원래의 교차 엔트로피 손실이 거의 그대로 유지된다.</li>
<li><strong>집중 파라미터</strong> <span class="math math-inline">γ (γ≥0)</span>: 이 값은 쉬운 예제의 손실을 얼마나 감소시킬지를 조절한다. <span class="math math-inline">γ</span>가 클수록 쉬운 예제의 영향력이 더욱 줄어든다 (<span class="math math-inline">γ=0</span>이면 표준 교차 엔트로피와 동일).23</li>
<li><strong>가중치 파라미터 <span class="math math-inline">α_t</span>:</strong> 이는 전통적인 비용 민감 학습처럼 클래스별 가중치를 부여하는 항으로, 포컬 로스와 함께 사용될 수 있다.24</li>
</ul>
<p>이러한 메커니즘을 통해 포컬 로스는 데이터 불균형 상황에서 압도적인 수를 차지하는 ’쉬운 정상 샘플’들이 전체 손실을 지배하고 학습을 방해하는 현상을 효과적으로 억제한다. 대신 모델은 소수의 ’어려운 비정상 샘플’과 ’분류 경계에 있는 정상 샘플’에 집중하여 학습 효율성과 성능을 극대화할 수 있다.25 이는 정적인 클래스 중요도에서 동적인 샘플 난이도로 문제 해결의 관점을 전환한 것으로, 알고리즘 수준 조정 기법의 정점에 있는 기술로 평가받는다.</p>
<h2>4.  희소성으로부터의 학습을 위한 고급 패러다임</h2>
<p>기초적인 데이터 및 알고리즘 조정 기법들이 기존의 분류 프레임워크 내에서 문제를 해결하려는 시도였다면, 더 진보된 패러다임들은 문제 자체를 재정의하거나 외부의 방대한 지식을 활용하여 데이터 희소성의 근본적인 한계를 극복하고자 한다. 이러한 접근법들은 비정상 데이터가 거의 또는 전혀 없는 상황에서도 효과적인 모델 구축을 가능하게 한다.</p>
<h3>4.1  단일 클래스 분류: ’정상’의 경계를 학습하다</h3>
<p>단일 클래스 분류(One-Class Classification, OCC)는 이상 탐지 문제에 대한 가장 급진적이면서도 강력한 해법 중 하나를 제시한다. 이 패러다임은 “무엇이 비정상인가?“를 학습하는 대신, “무엇이 정상인가?“를 정밀하게 모델링하는 데 모든 학습 역량을 집중한다.13 이 접근법의 가장 큰 장점은 훈련 과정에서 오직 ‘정상’ 데이터만을 필요로 한다는 점이다. 이는 비정상 데이터 수집이 불가능하거나 극도로 어려운 현실 세계의 문제에 완벽하게 부합한다.28</p>
<p>대표적인 단일 클래스 분류 알고리즘은 다음과 같다.</p>
<ul>
<li><strong>One-Class SVM (OC-SVM):</strong> 이 알고리즘은 고차원 특징 공간에서 원점(origin)과 정상 데이터 포인트들을 분리하는 최대 마진(maximum margin) 초평면(hyperplane)을 찾는다. 학습이 완료되면, 이 초평면을 기준으로 정상 데이터가 분포하는 영역이 정의되며, 이 영역 밖에 위치하는 새로운 데이터는 비정상으로 판정된다.29 즉, 정상 데이터들을 감싸는 경계를 설정하고, 그 경계 밖의 모든 것을 이상치로 간주하는 방식이다.30</li>
<li><strong>Deep SVDD (Support Vector Data Description):</strong> 딥러닝을 OC-SVM의 아이디어와 결합한 형태로, 신경망을 사용하여 입력 데이터를 모든 정상 데이터가 밀집되는 최소 부피의 초구(hypersphere) 내부로 매핑하도록 학습한다. 훈련된 네트워크에 새로운 데이터를 입력했을 때, 그 데이터의 표현이 초구 내부에 위치하면 정상, 외부에 위치하면 비정상으로 판단한다.13</li>
<li><strong>오토인코더 (Autoencoder) 기반 방법:</strong> 오토인코더는 입력을 저차원의 잠재 공간으로 압축하는 인코더(encoder)와, 이를 다시 원본 차원으로 복원하는 디코더(decoder)로 구성된 비지도 학습 모델이다.13 정상 데이터만으로 오토인코더를 훈련시키면, 모델은 정상 데이터의 핵심적인 특징을 학습하여 이를 잘 복원할 수 있게 된다. 그러나 훈련 데이터에서 보지 못한 패턴을 가진 비정상 데이터가 입력으로 들어오면, 모델은 이를 제대로 복원하지 못하고 큰 복원 오차(reconstruction error)를 발생시킨다. 이 복원 오차의 크기를 이상 점수(anomaly score)로 활용하여 정성과 비정상을 구분할 수 있다.13</li>
</ul>
<p>이러한 단일 클래스 분류 기법들은 비정상 데이터의 부재라는 제약을, 문제 정의를 변경함으로써 정면으로 돌파하는 혁신적인 접근법이다.</p>
<h3>4.2  퓨샷 러닝: 최소한의 샘플로 정보 습득 극대화</h3>
<p>퓨샷 러닝(Few-Shot Learning, FSL)은 인간이 단 몇 개의 예시만 보고도 새로운 개념을 학습하는 능력에서 영감을 받은 학습 패러다임이다.32 이는 비정상 데이터가 극소수(예: 5개 미만)만 존재하는, 단일 클래스 분류를 적용하기에는 애매하지만 지도 학습을 적용하기에는 턱없이 부족한 상황에 매우 적합하다.33 FSL의 핵심은 특정 작업에 대한 직접적인 학습이 아니라, 다양한 관련 작업들을 통해 ‘학습하는 방법’ 자체를 학습(meta-learning)하는 것이다.32</p>
<p>FSL은 주로 메트릭 러닝(Metric Learning) 기반의 접근법을 사용한다. 이는 입력 데이터를 특징 공간에 임베딩하여, 같은 클래스에 속하는 샘플들은 가깝게, 다른 클래스에 속하는 샘플들은 멀리 위치하도록 거리 함수를 학습하는 방식이다.35</p>
<ul>
<li><strong>샴 네트워크 (Siamese Network):</strong> 동일한 가중치를 공유하는 두 개의 신경망을 사용하여 입력 쌍의 유사도를 학습한다. 이를 통해 단 몇 개의 비정상 샘플이 주어져도, 새로운 데이터가 이 샘플들과 얼마나 유사한지를 측정하여 이상 여부를 판별할 수 있다.36</li>
<li><strong>프로토타입 네트워크 (Prototypical Network):</strong> 각 클래스를 대표하는 ‘프로토타입’ (해당 클래스 샘플들의 평균 임베딩)을 계산하고, 새로운 데이터가 어떤 클래스의 프로토타입에 가장 가까운지를 기준으로 분류한다.36</li>
</ul>
<p>산불 연기 탐지 분야에서 FSL과 메트릭 러닝을 결합한 연구는 매우 중요한 시사점을 제공한다. 기존의 방법들은 연기와 비연기를 구분하는 수준에 그쳐, 공장의 연기나 안개와 같은 비산불 연기로 인한 오경보가 잦았다. 한 연구에서는 FSL을 적용하여 극소수의 실제 산불 연기 데이터만으로 ’산불 연기’와 ’비산불 연기’를 구분하는 미세 식별(fine-grained recognition) 모델을 훈련시켰다. 그 결과, 제한된 데이터베이스에도 불구하고 93.75%라는 높은 산불 연기 식별 정확도를 달성했다.35 이는 FSL이 단순히 데이터 부족 문제를 해결하는 것을 넘어, 더 정교하고 세분화된 탐지 작업을 가능하게 함을 보여주는 강력한 사례이다.</p>
<h3>4.3  전이 학습: 축적된 지식의 재활용</h3>
<p>전이 학습(Transfer Learning)은 데이터 희소성 문제를 해결하는 가장 실용적이고 강력한 방법 중 하나로, 한 문제(source task)를 해결하기 위해 학습된 모델의 지식을 다른 관련 문제(target task)에 적용하는 기법이다.37 이는 대규모 데이터셋으로 사전 훈련된 모델이 이미지의 일반적인 특징(예: 선, 질감, 형태)을 이미 학습했으므로, 소량의 데이터만으로 특정 작업에 맞게 미세 조정(fine-tuning)하면 된다는 아이디어에 기반한다. 이를 통해 훈련 시간과 데이터 요구량을 획기적으로 줄일 수 있다.38</p>
<h4>4.3.1  사전 훈련과 미세 조정의 메커니즘</h4>
<p>전이 학습의 일반적인 과정은 다음과 같다.37</p>
<ol>
<li><strong>사전 훈련된 모델 선택:</strong> 해결하고자 하는 작업과 유사한 대규모 데이터셋(예: ImageNet)으로 이미 훈련된 강력한 모델(예: VGG, ResNet)을 선택한다.</li>
<li><strong>모델 구조 수정:</strong> 선택한 모델의 마지막 분류 레이어를 목표 작업에 맞게 수정한다. 예를 들어, 1000개의 클래스를 분류하던 ImageNet 모델의 마지막 레이어를 ’산불’과 ‘비산불’ 2개의 클래스를 분류하도록 변경한다.</li>
<li><strong>미세 조정 (Fine-tuning):</strong> 새로운 데이터셋(예: 소량의 산불 이미지)을 사용하여 모델의 일부 또는 전체 가중치를 재학습시킨다. 일반적으로 초기 레이어(일반적인 특징 학습)는 고정(freeze)하고, 후기 레이어(작업 특화적인 특징 학습)만 낮은 학습률로 미세 조정하여 기존에 학습된 지식을 보존하면서 새로운 작업에 적응시킨다.</li>
</ol>
<h4>4.3.2  심층 사례 연구: 구름 데이터셋을 활용한 산불 연기 탐지 고도화</h4>
<p>전이 학습의 위력을 가장 극적으로 보여주는 사례는 산불 연기 탐지에 구름 데이터셋을 활용한 연구이다.39 이 연구는 데이터 과학과 자연과학적 통찰력의 성공적인 융합을 보여준다.</p>
<ul>
<li><strong>문제 인식:</strong> 딥러닝 기반 연기 추출의 정확도는 높지만, 훈련용 연기 데이터셋이 절대적으로 부족하다는 한계가 있었다.</li>
<li><strong>핵심 아이디어:</strong> 연구진은 연기와 구름이 물리적으로 유사한 특성을 공유한다는 점에 주목했다. 두 객체 모두 빛의 파장과 비슷한 크기의 입자에 의해 발생하는 ’미 산란(Mie scattering)’을 일으키기 때문에, 가시광선 대역의 위성 영상에서 시각적으로 매우 유사하게 보인다. 반면, 구름 데이터는 연기 데이터에 비해 훨씬 방대하게 축적되어 있었다.</li>
<li><strong>전이 학습 적용:</strong> 연구팀은 대규모 공공 구름 데이터셋을 사용하여 U-Net 기반의 분할 모델을 사전 훈련시켰다. 이 모델은 ‘구름과 같은’ 객체의 시각적 특징을 추출하는 데 전문가가 된 셈이다. 그 후, 이 사전 훈련된 모델을 소규모의 실제 산불 연기 데이터셋으로 미세 조정했다.</li>
<li><strong>결과:</strong> 결과는 놀라웠다. 전이 학습을 적용하지 않았을 때 RGB 파장대역에서의 연기 추출 F1-score는 0.710에 불과했지만, 구름 데이터로 전이 학습을 적용한 후에는 <strong>0.839</strong>로 대폭 향상되었다. 이는 전이 학습이 수계(water body)를 연기로 오탐하던 문제를 해결하는 등 모델의 정밀도를 크게 개선했기 때문이다. 흥미롭게도, 컴퓨터 비전 분야의 범용 데이터셋인 ImageNet으로 전이 학습을 했을 때의 F1-score는 0.782로, 구름 데이터셋을 사용했을 때보다 성능이 낮았다.</li>
</ul>
<p>이 사례는 전이 학습의 성공이 단순히 큰 데이터셋을 사용하는 것을 넘어, 소스 도메인(구름)과 타겟 도메인(연기) 간의 ’의미론적, 물리적 유사성’이 얼마나 중요한지를 명확히 보여준다. 이는 데이터 희소성 문제 해결에 있어 도메인 지식의 중요성을 강조하는 강력한 증거이며, 외부 지식을 효과적으로 활용하는 것이 소량의 데이터를 보완하는 가장 효율적인 전략 중 하나임을 입증한다.</p>
<h2>5.  생성 모델의 최전선: 희소 데이터로부터 데이터 창조</h2>
<p>지금까지 논의된 방법들이 기존 데이터를 조정하거나 외부 지식을 활용하는 데 초점을 맞췄다면, 생성 모델(Generative Models)은 패러다임을 완전히 전환한다. 즉, 부족한 데이터를 직접 ‘만들어내는’ 것이다. 이 접근법은 데이터 증강(augmentation)을 넘어, 필요한 데이터를 정밀하게 시뮬레이션(simulation)하는 수준으로 발전하며 비정상 데이터 희소성 문제에 대한 가장 근본적인 해결책을 제시한다.</p>
<h3>5.1  데이터 증강을 위한 생성 모델의 도입</h3>
<p>생성 모델은 훈련 데이터의 잠재적 분포를 학습하여, 그 분포로부터 새로운 데이터를 샘플링할 수 있는 모델이다. 이를 통해 실제 데이터와 매우 유사하지만 완전히 새로운, 가상의 데이터를 무한정 생성할 수 있다.9 이는 단순히 기존 데이터를 변형하는 전통적인 증강 기법(회전, 자르기 등)을 뛰어넘어, 데이터셋의 근본적인 다양성을 높여 모델의 일반화 성능을 향상시키는 것을 목표로 한다.40 특히 비정상 데이터가 극도로 드문 경우, 잘 훈련된 생성 모델은 정보의 결핍을 직접적으로 메워주는 역할을 할 수 있다.41</p>
<h3>5.2  생성적 적대 신경망(GANs)을 이용한 이상 현상 합성</h3>
<p>생성적 적대 신경망(Generative Adversarial Networks, GANs)은 생성 모델 분야에 혁명을 일으킨 첫 주자이다. GAN은 두 개의 신경망, 즉 데이터를 생성하는 ’생성자(Generator)’와 생성된 데이터가 진짜인지 가짜인지를 판별하는 ’판별자(Discriminator)’가 서로 경쟁하며 학습하는 구조를 가진다.42 생성자는 판별자를 속이기 위해 점점 더 실제와 같은 데이터를 만들고, 판별자는 생성자를 간파하기 위해 점점 더 정교하게 진위를 구별하면서, 결국 생성자는 실제 데이터와 거의 구별할 수 없는 고품질의 데이터를 생성하게 된다.</p>
<h4>5.2.1  적용 사례: 산불 데이터셋 증강</h4>
<p>GAN은 산불 탐지 데이터셋 증강에 성공적으로 활용되었다.</p>
<ul>
<li>한 연구에서는 CycleGAN이라는 특정 GAN 아키텍처를 사용하여, 산불이 없는 산 이미지(소스 도메인)를 산불이 발생한 산 이미지(타겟 도메인)로 변환하는 작업을 수행했다. 이를 통해 다양한 배경과 형태를 가진 합성 산불 이미지를 대량으로 생성할 수 있었다. 이렇게 생성된 데이터를 훈련에 추가했을 때, DenseNet 기반의 산불 탐지 모델의 정확도는 96.7%에서 **98.3%**로, F1-score는 96.6에서 <strong>98.2</strong>로 유의미하게 향상되었다.40</li>
<li>또 다른 연구에서는 GAN으로 합성 산불 이미지를 생성하고, 이를 약지도 객체 탐지(Weakly Supervised Object Localization, WSOL) 기법과 결합하여 자동으로 바운딩 박스를 생성했다. 이 데이터로 YOLOv5s 모델을 훈련시킨 결과, 전통적인 증강 기법만을 사용했을 때보다 F1-score가 <strong>7.19%p</strong>, 평균 정밀도(AP)가 <strong>6.41%p</strong> 향상되는 성과를 거두었다.17</li>
</ul>
<p>이러한 사례들은 GAN이 비정상 데이터 부족 문제를 완화하는 데 효과적인 도구임을 입증한다.</p>
<h4>5.2.2  GAN 기반 접근법의 한계</h4>
<p>그러나 GAN은 여러 본질적인 한계를 가지고 있다.</p>
<ul>
<li><strong>훈련 불안정성:</strong> 생성자와 판별자 간의 균형을 맞추기 어려워 훈련 과정이 매우 불안정하고, 수렴시키기 위해 많은 노하우가 필요하다.44</li>
<li><strong>모드 붕괴 (Mode Collapse):</strong> 생성자가 판별자를 속이기 가장 쉬운 몇 가지 소수의 데이터만 반복적으로 생성하고, 훈련 데이터의 전체적인 다양성을 학습하지 못하는 현상이 발생할 수 있다.46</li>
<li><strong>품질과 다양성의 한계:</strong> 고해상도의 복잡하고 미세한 질감을 가진 이미지를 생성하는 데 어려움을 겪는 경우가 많다.</li>
</ul>
<p>이러한 한계점들은 특히 다양하고 예측 불가능한 패턴을 가진 비정상 데이터를 생성해야 하는 이상 탐지 분야에서 GAN의 활용을 제약하는 요인이 되었다.</p>
<h3>5.3  확산 모델: 합성 데이터의 새로운 표준</h3>
<p>최근 몇 년 사이, 확산 모델(Diffusion Models)은 GAN의 한계를 극복하며 이미지 생성 분야의 새로운 표준으로 자리 잡았다. 확산 모델은 GAN보다 월등히 높은 품질과 다양성을 갖춘 이미지를 안정적으로 생성할 수 있는 능력으로 주목받고 있다.44</p>
<h4>5.3.1  잡음 제거 확산 과정의 원리</h4>
<p>확산 모델의 작동 원리는 직관적으로 이해할 수 있는 두 단계 과정으로 구성된다.47</p>
<ol>
<li><strong>순방향 과정 (Forward Process / Diffusion):</strong> 원본 이미지에 점진적으로 가우시안 노이즈(Gaussian noise)를 수백에서 수천 단계에 걸쳐 추가하여, 이미지가 최종적으로 완전한 무작위 노이즈가 되도록 만드는 과정이다. 이 과정은 수학적으로 정해져 있으며, 학습이 필요 없다.</li>
<li><strong>역방향 과정 (Reverse Process / Denoising):</strong> 신경망(주로 U-Net 아키텍처)을 사용하여 순방향 과정의 정반대, 즉 완전한 노이즈에서 시작하여 점진적으로 노이즈를 제거해 나가면서 원본 이미지를 복원하는 방법을 학습한다. 이 ‘잡음 제거’ 과정을 완벽하게 학습한 모델은, 무작위 노이즈만 입력받아도 새로운 고품질 이미지를 생성할 수 있게 된다.49</li>
</ol>
<h4>5.3.2  GAN 대비 확산 모델의 장점</h4>
<p>확산 모델은 GAN에 비해 다음과 같은 명확한 장점을 가진다.</p>
<ul>
<li><strong>안정적인 훈련:</strong> 적대적 학습 과정이 없기 때문에 훈련이 매우 안정적이다.</li>
<li><strong>높은 품질과 다양성:</strong> 모드 붕괴 현상이 거의 발생하지 않으며, 훈련 데이터의 전체 분포를 훨씬 더 잘 학습하여 매우 사실적이고 다양한 샘플을 생성한다.44</li>
<li><strong>제어 용이성:</strong> 점진적인 잡음 제거 과정의 각 단계에 외부 조건(예: 텍스트 프롬프트, 마스크)을 주입하기 용이하여, 생성 과정을 정교하게 제어할 수 있는 잠재력이 크다.</li>
</ul>
<p>이러한 특성 덕분에 확산 모델은 복잡한 ‘정상’ 데이터의 분포를 정밀하게 모델링하고, 이를 기반으로 매우 사실적인 ‘비정상’ 데이터를 생성하는 데 이상적인 도구로 평가받고 있다.44</p>
<h4>5.3.3  제어 가능한 이상 생성: 차세대 기술</h4>
<p>확산 모델의 등장은 단순히 고품질 이미지를 생성하는 것을 넘어, 사용자가 원하는 이상 현상을 원하는 위치에, 원하는 특성대로 생성하는 <strong>제어 가능한 이상 생성(Controllable Anomaly Synthesis)</strong> 이라는 새로운 연구 분야를 열었다. 이는 데이터 증강을 넘어 특정 시나리오를 시뮬레이션하는 단계로의 진화를 의미한다.</p>
<p>최첨단 프레임워크들은 확산 모델의 제어 용이성을 극대화한다.</p>
<ul>
<li><strong>AnomalyControl:</strong> 이 프레임워크는 텍스트 프롬프트와 참조 이미지(text-image reference prompt)를 함께 사용하여, 텍스트와 이미지 양쪽에서 추출한 교차 모달 의미론적 특징(cross-modal semantic features)을 생성 과정의 가이드 신호로 활용한다. 이를 통해 “이 이미지의 이 부분에, 저 참조 이미지에 보이는 ’긁힘’과 같은 결함을 생성해줘“와 같은 정교한 제어가 가능해져, 생성된 이상의 사실성과 문맥적 적합성을 크게 향상시킨다.52</li>
<li><strong>MAGIC (Mask-Guided Diffusion Inpainting):</strong> 이 프레임워크는 확산 모델의 인페인팅(inpainting) 기능을 활용하는 데 특화되어 있다. 사용자가 정상 이미지 위에 이상 현상을 생성하고 싶은 영역을 마스크(mask)로 지정하면, 모델이 정확히 그 영역 안에만 이상 현상을 ‘그려 넣는다’. 이 방식은 정상적인 배경 영역을 완벽하게 보존하면서 이상의 위치, 크기, 형태를 픽셀 수준에서 정밀하게 제어할 수 있다는 강력한 장점을 가진다. 또한, 소수의 실제 이상 샘플만으로 모델을 미세 조정(fine-tuning)하여 특정 유형의 이상을 학습하고, 다양한 변형을 생성해낼 수 있다.46</li>
</ul>
<p>이러한 제어 가능한 생성 기술의 발전은, 더 이상 우리가 가진 데이터에 의존하는 것이 아니라, 모델의 취약점을 테스트하거나 특정 엣지 케이스(edge case)를 학습시키기 위해 필요한 데이터를 ’설계’하고 ’주문 생산’할 수 있는 시대로의 전환을 의미한다. 이는 비정상 데이터 희소성 문제에 대한 궁극적인 해결책이 될 잠재력을 지니고 있다.</p>
<h2>6.  종합 비교 분석 및 실용적 구현 방안</h2>
<p>지금까지 논의된 다양한 기술들은 비정상 데이터 희소성 문제에 대한 다각적인 해결책을 제시한다. 하지만 실제 프로젝트에 어떤 기술을 적용할지 결정하기 위해서는 각 방법론의 장단점, 요구 조건, 그리고 성능을 종합적으로 비교하고 실질적인 구현의 어려움을 이해하는 것이 필수적이다. 이 장에서는 실용적인 관점에서 각 기술들을 비교 분석하고, 정량적 벤치마크 결과를 통해 그 효과를 검증하며, 실제 구현 시 마주하게 될 현실적인 제약 조건들을 고찰한다.</p>
<h3>6.1  방법론 비교 프레임워크: 언제 어떤 기술을 선택할 것인가?</h3>
<p>최적의 기술 선택은 주어진 문제의 특성, 가용 데이터의 양과 종류, 그리고 프로젝트의 계산 자원 및 목표 성능에 따라 달라진다. 아래의 표는 본 안내서에서 논의된 주요 방법론들을 핵심적인 기준에 따라 비교하여 실무자들이 상황에 맞는 의사결정을 내릴 수 있도록 돕는다.</p>
<p><strong>Table 1: 희소한 비정상 데이터 처리를 위한 방법론 비교 분석</strong></p>
<table><thead><tr><th>기술</th><th>주요 메커니즘</th><th>비정상 데이터 요구량</th><th>계산 비용</th><th>핵심 장점</th><th>핵심 한계</th><th>이상적 사용 사례</th></tr></thead><tbody>
<tr><td><strong>리샘플링</strong></td><td>데이터 복제 또는 제거</td><td>일부</td><td>낮음</td><td>구현이 매우 간단하고 직관적임.</td><td>과적합 또는 정보 손실 위험이 큼.18</td><td>초기 베이스라인 모델 구축 또는 매우 간단한 불균형 문제.</td></tr>
<tr><td><strong>비용 민감 학습</strong></td><td>손실 함수에서 클래스별 오분류 비용 차등화</td><td>일부</td><td>낮음</td><td>데이터 분포를 변경하지 않고 클래스 중요도 반영 가능.19</td><td>모든 샘플에 동일한 가중치를 부여하여 학습 효율이 떨어질 수 있음.</td><td>클래스별 오분류 비용이 명확히 다를 때 (예: 금융 사기).</td></tr>
<tr><td><strong>포컬 로스</strong></td><td>쉬운 예제의 손실을 줄여 어려운 예제 학습에 집중</td><td>일부</td><td>낮음</td><td>극심한 불균형 상황에서 학습 효율을 극대화함.23</td><td>하이퍼파라미터(γ, α) 튜닝이 필요함.</td><td>다수의 쉬운 정상 샘플이 학습을 방해하는 경우 (예: 객체 탐지).</td></tr>
<tr><td><strong>단일 클래스 분류</strong></td><td>정상 데이터의 분포만을 학습하여 경계 설정</td><td>없음</td><td>중간</td><td>비정상 데이터가 전혀 없어도 모델 구축 가능.13</td><td>비정상의 구체적인 패턴을 학습하지 못함. 정상 데이터의 분포가 복잡할 경우 성능 저하.</td><td>정상 데이터는 풍부하지만 비정상 데이터 수집이 불가능한 경우.</td></tr>
<tr><td><strong>퓨샷 러닝</strong></td><td>메타러닝을 통해 극소수 샘플로 새로운 클래스 학습</td><td>극소수 (1~5개)</td><td>중간-높음</td><td>매우 적은 데이터로 새로운 유형의 이상 탐지 가능.34</td><td>다양한 관련 작업 데이터셋으로 사전 메타 학습이 필요함.</td><td>새로운 유형의 결함이 드물게 나타나는 산업 공정.</td></tr>
<tr><td><strong>전이 학습</strong></td><td>대규모 데이터셋으로 사전 훈련된 모델을 미세 조정</td><td>소량</td><td>중간</td><td>적은 데이터와 시간으로 매우 높은 성능 달성 가능.38</td><td>소스-타겟 도메인 간 관련성이 낮으면 효과가 미미함.38</td><td>유사한 특성을 가진 대규모 데이터셋이 존재하는 경우 (예: 구름–&gt;&gt;연기).</td></tr>
<tr><td><strong>GAN 기반 합성</strong></td><td>생성자와 판별자의 적대적 학습을 통해 데이터 생성</td><td>일부</td><td>높음</td><td>실제와 유사한 새로운 데이터 생성 가능.40</td><td>훈련 불안정, 모드 붕괴, 품질 제어의 어려움.44</td><td>데이터 다양성 증대가 주목표이며, 최고 수준의 사실성은 요구되지 않을 때.</td></tr>
<tr><td><strong>확산 모델 기반 합성</strong></td><td>점진적 잡음 제거 과정을 학습하여 고품질 데이터 생성</td><td>소량 (미세 조정 시)</td><td>매우 높음</td><td>현존 최고 수준의 사실성과 다양성, 안정적인 훈련, 높은 제어 가능성.44</td><td>훈련 및 추론에 막대한 계산 자원 필요.47</td><td>특정 시나리오 시뮬레이션 등 최고 성능과 정밀한 제어가 필요할 때.</td></tr>
</tbody></table>
<p>이 표는 문제 해결의 경로를 명확히 보여준다. 비정상 데이터가 전혀 없다면 단일 클래스 분류가 유일한 선택지일 수 있다. 극소수의 데이터만 있다면 퓨샷 러닝이 적합하다. 만약 관련된 대규모 데이터셋을 찾을 수 있다면 전이 학습이 가장 비용 효율적인 고성능 솔루션이 될 것이다. 마지막으로, 데이터셋을 근본적으로 강화하고 특정 시나리오를 시뮬레이션해야 할 필요가 있을 때, 확산 모델 기반의 데이터 합성이 가장 강력한, 그러나 가장 많은 자원을 요구하는 최첨단 해결책이 된다.</p>
<h3>6.2  MVTec-AD 벤치마크를 통한 정량적 성능 비교</h3>
<p>주장의 객관성을 확보하기 위해, 산업 이미지 이상 탐지 분야의 표준 벤치마크인 MVTec-AD 데이터셋 57에서의 정량적 성능 비교는 매우 중요하다. MVTec-AD는 다양한 산업 제품의 정상 이미지와 여러 유형의 결함이 포함된 비정상 이미지로 구성되어 있어, 이상 탐지 및 생성 모델의 성능을 종합적으로 평가하는 데 널리 사용된다.57</p>
<p>최근 연구들은 MVTec-AD 벤치마크에서 확산 모델 기반의 이상 생성 및 탐지 기법이 기존의 GAN 기반 기법이나 다른 접근법들을 능가하는 성능을 보여주고 있음을 일관되게 보고한다.60 아래 표는 주요 생성 모델 기반 방법론들의 성능을 요약한 것이다.</p>
<p><strong>Table 2: MVTec-AD 벤치마크에서의 이상 생성 모델 기반 탐지 성능 비교</strong></p>
<table><thead><tr><th>방법론</th><th>기반 모델</th><th>이상 탐지 AUROC (%)</th><th>이상 위치 특정 AP (%)</th><th>핵심 특징 및 결과</th></tr></thead><tbody>
<tr><td><strong>GANomaly</strong> 62</td><td>GAN</td><td>-</td><td>-</td><td>GAN과 오토인코더를 결합한 초기 재구성 기반 모델.</td></tr>
<tr><td><strong>CycleGAN 기반</strong> 40</td><td>GAN</td><td>98.3 (정확도)</td><td>-</td><td>산불 데이터셋에서 성능 향상을 보였으나, MVTec-AD에서는 최신 모델 대비 성능이 낮음.</td></tr>
<tr><td><strong>DiAD</strong> 61</td><td>Diffusion</td><td>99.0</td><td>52.6</td><td>다중 클래스 이상 탐지를 위한 확산 모델 프레임워크. 높은 탐지 성능을 보임.</td></tr>
<tr><td><strong>DualAnoDiff</strong> 60</td><td>Diffusion</td><td><strong>99.1</strong></td><td><strong>84.5</strong></td><td>전역/지역 이중 분기 구조로 이상 이미지와 마스크를 동시에 생성하여 일관성을 높임. 픽셀 수준 탐지에서 SOTA 달성.</td></tr>
<tr><td><strong>MAGIC</strong> 55</td><td>Diffusion</td><td>-</td><td>-</td><td>마스크 기반 인페인팅으로 배경을 보존하며 정밀한 이상 생성. 다운스트림 작업에서 기존 SOTA를 능가한다고 보고됨.</td></tr>
</tbody></table>
<p><em>주: AUROC(Area Under the ROC Curve)는 높을수록 좋으며, 이상 탐지(이미지 레벨) 성능을 나타낸다. AP(Average Precision)는 높을수록 좋으며, 이상 위치 특정(픽셀 레벨) 성능을 나타낸다. 모델별로 보고하는 메트릭이 다를 수 있어 일부 값은 비어있을 수 있다.</em></p>
<p>이러한 정량적 결과는 본 안내서의 핵심 주장, 즉 생성 모델 기술이 GAN에서 확산 모델로 진화하면서 이상 탐지 성능이 비약적으로 발전했음을 명백히 뒷받침한다. 특히 DualAnoDiff와 같은 최신 확산 모델 프레임워크는 픽셀 수준의 정밀한 위치 특정 작업에서 압도적인 성능을 보여주며, 이는 생성된 데이터의 품질과 사실성이 실제 모델 성능에 직결됨을 시사한다.</p>
<h3>6.3  실질적 장애물: 계산 비용, 하드웨어 요구사항, 훈련 시간</h3>
<p>최첨단 생성 모델, 특히 확산 모델의 뛰어난 성능 이면에는 막대한 계산 자원이라는 실질적인 장벽이 존재한다.</p>
<ul>
<li><strong>계산 비용 및 훈련 시간:</strong> 확산 모델은 수백에서 수천 번의 반복적인 잡음 제거 과정을 거치기 때문에, 단일 이미지를 생성하는 추론 시간조차 GAN에 비해 훨씬 길다. 모델을 처음부터 훈련시키는 것은 더욱 큰 비용을 요구하며, 대규모 데이터셋에서는 수일에서 수주가 소요될 수 있다.63 이는 신속한 프로토타이핑과 반복적인 실험을 어렵게 만드는 요인이다.</li>
<li><strong>하드웨어 요구사항 (VRAM):</strong> 대규모 확산 모델을 훈련하거나 미세 조정하기 위해서는 상당한 양의 GPU 비디오 메모리(VRAM)가 필수적이다. 일반적으로 최소 8-12GB의 VRAM이 권장되며, 고해상도 이미지나 더 큰 모델을 다루기 위해서는 24GB 이상의 VRAM을 갖춘 하이엔드 GPU가 필요할 수 있다.64 이러한 높은 하드웨어 요구사항은 개인 연구자나 소규모 팀에게는 상당한 진입 장벽으로 작용한다.66</li>
<li><strong>실용적 해결책:</strong> 이러한 문제를 완화하기 위해 학계와 산업계에서는 다음과 같은 전략을 적극적으로 채택하고 있다.</li>
</ul>
<ol>
<li><strong>사전 훈련된 모델 활용:</strong> Stable Diffusion과 같이 거대 기업이 막대한 자원을 투입하여 사전 훈련시킨 강력한 오픈소스 모델을 기반으로 활용한다.67</li>
<li><strong>효율적인 미세 조정 기법:</strong> 모델 전체를 재학습시키는 대신, LoRA(Low-Rank Adaptation), DreamBooth, Textual Inversion과 같은 파라미터 효율적 미세 조정(Parameter-Efficient Fine-Tuning, PEFT) 기법을 사용하여 적은 계산 자원으로도 모델을 특정 작업에 맞게 조정한다.67</li>
</ol>
<p>결론적으로, 현재 가장 강력한 성능을 제공하는 기술은 가장 많은 자원을 요구하는 기술과 일치하는 경향이 있다. 따라서 실무에서는 절대적인 최고 성능을 추구하기보다, 가용한 자원 내에서 최적의 성능을 낼 수 있는 균형점을 찾는 것이 중요하다. 이는 사전 훈련된 모델과 효율적인 미세 조정 기법의 결합이 현실적인 최적의 솔루션이 되는 경우가 많음을 의미한다.</p>
<h2>7.  결론 및 전략적 제언</h2>
<p>본 안내서는 딥러닝 모델 훈련 시 발생하는 비정상 데이터의 희소성이라는 근본적인 문제를 해결하기 위한 광범위한 기술적 스펙트럼을 심층적으로 분석했다. 분석을 통해, 이 문제에 대한 접근법이 단일 해결책이 아닌, 상황과 목적에 따라 선택해야 하는 다각적인 솔루션 공간을 형성하고 있음을 확인했다.</p>
<h3>7.1  연구 결과 종합: 다각적 솔루션 공간의 이해</h3>
<p>문제 해결의 여정은 데이터의 수적 불균형을 맞추려는 단순한 리샘플링에서 시작하여, 오분류의 비용을 차등화하는 비용 민감 학습과 학습의 초점을 동적으로 조절하는 포컬 로스로 진화했다. 이는 문제의 본질을 ’수의 불균형’에서 ’정보의 가치와 학습 난이도’로 더 깊이 이해하게 되었음을 보여준다.</p>
<p>더 나아가, 문제의 프레임을 전환하는 고급 패러다임들이 등장했다. 단일 클래스 분류는 비정상 데이터 없이 ’정상’의 정의만으로 문제를 해결했으며, 퓨샷 러닝은 극소수의 샘플로부터 학습 능력을 극대화했다. 특히, 전이 학습은 산불 연기 탐지 사례에서 입증되었듯이, 관련 도메인의 방대한 사전 지식을 이식함으로써 데이터 부족을 효과적으로 메우는 가장 실용적인 고성능 전략 중 하나로 자리매김했다.</p>
<p>궁극적으로, 기술의 최전선은 부족한 데이터를 보완하는 것을 넘어, 필요한 데이터를 능동적으로 창조하는 생성 모델로 나아가고 있다. GAN이 그 가능성을 열었지만, 훈련 불안정성과 품질의 한계를 보였다. 반면, 확산 모델은 현존하는 가장 사실적이고 다양한 데이터를 안정적으로 생성하며 새로운 시대를 열었다. 특히, AnomalyControl이나 MAGIC과 같은 제어 가능한 이상 생성 프레임워크의 등장은, 우리가 더 이상 데이터에 수동적으로 의존하는 것이 아니라, 모델 검증과 강화를 위해 필요한 데이터를 정밀하게 ’시뮬레이션’할 수 있게 되었음을 의미한다.</p>
<p>이러한 기술적 진화의 흐름은 명확하다: <strong>대규모 사전 훈련 모델(Foundation Models)을 기반으로, 외부 지식을 이식하거나(전이 학습), 필요한 데이터를 정밀하게 생성(확산 모델)하는 방향으로 수렴하고 있다.</strong></p>
<h3>7.2  실무자 및 연구자를 위한 제언</h3>
<p>이러한 분석을 바탕으로, 비정상 데이터 희소성 문제에 직면한 실무자와 연구자를 위해 다음과 같은 단계적이고 전략적인 접근법을 제언한다.</p>
<h4>7.2.1 실무자를 위한 제언</h4>
<ol>
<li><strong>1단계: 가장 비용 효율적인 솔루션부터 탐색하라 (전이 학습).</strong></li>
</ol>
<ul>
<li>새로운 모델을 처음부터 구축하기 전에, 해결하고자 하는 문제(예: 산불 연기)와 시각적, 물리적, 또는 의미론적으로 유사한 특성을 가진 대규모 데이터셋(예: 구름)이 존재하는지 먼저 탐색해야 한다. 만약 존재한다면, 해당 데이터셋으로 사전 훈련된 모델을 활용하는 전이 학습이 최소의 비용으로 최대의 성능을 얻을 수 있는 가장 강력한 출발점이다.39</li>
</ul>
<ol start="2">
<li><strong>2단계: 관련 데이터가 없다면 문제의 정의를 바꿔라 (단일 클래스 분류).</strong></li>
</ol>
<ul>
<li>적절한 소스 도메인을 찾을 수 없고, 비정상 데이터가 전혀 없는 상황이라면, 단일 클래스 분류 기법을 우선적으로 고려해야 한다. 오토인코더 기반의 재구성 오차를 측정하는 방식은 구현이 비교적 간단하면서도 효과적인 베이스라인을 제공할 수 있다.13</li>
</ul>
<ol start="3">
<li><strong>3단계: 최고의 성능과 강건성이 필요하다면 데이터를 시뮬레이션하라 (확산 모델).</strong></li>
</ol>
<ul>
<li>최고 수준의 탐지 성능이 요구되거나, 다양한 엣지 케이스에 대한 모델의 강건성을 확보해야 한다면, 사전 훈련된 확산 모델(예: Stable Diffusion)을 활용한 데이터 생성을 고려해야 한다. LoRA와 같은 효율적인 미세 조정 기법을 사용하여 소수의 실제 비정상 샘플을 모델에 학습시킨 후, 제어 가능한 생성 프레임워크를 통해 특정 시나리오에 맞는 고품질의 합성 비정상 데이터를 대량으로 생성할 수 있다. 이렇게 생성된 데이터로 훈련된 탐지 모델은 실제 환경에서 훨씬 더 높은 신뢰성을 보일 것이다.46</li>
</ul>
<h4>7.2.2 연구자를 위한 제언</h4>
<ol>
<li><strong>효율성 증진:</strong> 확산 모델의 가장 큰 장벽은 막대한 계산 비용이다. 더 적은 VRAM과 더 빠른 훈련/추론 시간을 요구하는 경량화된 확산 모델 아키텍처나, 더 효율적인 샘플링 및 미세 조정 기법에 대한 연구는 이 기술의 대중화를 위해 필수적이다.63</li>
<li><strong>제로샷 및 교차 도메인 합성:</strong> 현재의 생성 모델은 여전히 소수의 참조 샘플을 필요로 한다. 궁극적인 목표는 순전히 텍스트나 의미론적 설명만으로 새로운 도메인의 비정상 현상을 단 하나의 샘플도 없이(zero-shot) 생성하는 것이다. 이를 위해서는 시각적 특징과 언어적 개념을 더 깊이 연결하는 연구가 필요하다.70</li>
<li><strong>제어 가능성 및 해석 가능성 강화:</strong> 생성 과정을 더욱 정밀하게 제어하고, 왜 모델이 특정 형태의 이상을 생성했는지 해석할 수 있는 기술의 개발이 중요하다. 이는 생성된 데이터의 신뢰도를 높이고, 의료나 자율주행과 같이 안전이 중요한 분야에 적용하기 위한 핵심 과제이다.50</li>
<li><strong>향상된 벤치마크 구축:</strong> 현재의 벤치마크는 주로 탐지 정확도에 초점을 맞추고 있다. 앞으로는 생성된 비정상 데이터의 ‘사실성’, ‘다양성’, 그리고 ’유용성’을 정량적으로 평가할 수 있는 새로운 벤치마크와 평가 지표의 개발이 필요하다. 이는 생성 모델 연구의 올바른 방향을 제시하는 데 기여할 것이다.72</li>
</ol>
<p>비정상 데이터의 희소성은 앞으로도 많은 AI 시스템이 직면할 지속적인 도전 과제일 것이다. 그러나 본 안내서에서 분석한 바와 같이, 이 문제를 해결하기 위한 기술은 놀라운 속도로 발전하고 있으며, 특히 제어 가능한 생성 모델의 등장은 우리가 데이터의 한계를 극복하고 더 신뢰할 수 있으며 강건한 AI를 구축할 수 있다는 밝은 미래를 약속한다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>데이터 불균형에 대응하기_1 - Team QANDA, accessed July 19, 2025, <a href="https://blog.mathpresso.com/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%88%EA%B7%A0%ED%98%95%EC%97%90-%EB%8C%80%EC%9D%91%ED%95%98%EA%B8%B0-1-52af6aaebbf3">https://blog.mathpresso.com/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%88%EA%B7%A0%ED%98%95%EC%97%90-%EB%8C%80%EC%9D%91%ED%95%98%EA%B8%B0-1-52af6aaebbf3</a></li>
<li>불균형 데이터(Data Imbalance) 처리 및 해결 방법(2가지 측면), accessed July 19, 2025, <a href="https://bommbom.tistory.com/entry/%EB%B6%88%EA%B7%A0%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0Data-Imbalance-%EC%B2%98%EB%A6%AC-%EB%B0%8F-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95">https://bommbom.tistory.com/entry/%EB%B6%88%EA%B7%A0%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0Data-Imbalance-%EC%B2%98%EB%A6%AC-%EB%B0%8F-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95</a></li>
<li>[딥러닝] imbalanced data 학습 - 마음으로 이해하고 적었습니다 - 티스토리, accessed July 19, 2025, https://u-b-h.tistory.com/16</li>
<li>불균형 데이터 (imbalanced data) 처리를 위한 샘플링 기법 - Feel’s blog - 티스토리, accessed July 19, 2025, https://casa-de-feel.tistory.com/15</li>
<li>[데이터 전처리] 클래스 불균형 - 비용 민감 모델 활용 - velog, accessed July 19, 2025, <a href="https://velog.io/@seonydg/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC-%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%B6%88%EA%B7%A0%ED%98%95-%EB%B9%84%EC%9A%A9-%EB%AF%BC%EA%B0%90-%EB%AA%A8%EB%8D%B8">https://velog.io/@seonydg/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC-%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%B6%88%EA%B7%A0%ED%98%95-%EB%B9%84%EC%9A%A9-%EB%AF%BC%EA%B0%90-%EB%AA%A8%EB%8D%B8</a></li>
<li>불균형데이터의 비용민감학습을 통한 국방분야 이미지 분류 성능 향상에 관한 연구 - Korea Science, accessed July 19, 2025, https://koreascience.kr/article/JAKO202123755991605.pdf</li>
<li>불균형 데이터(Imbalanced Data) 머신러닝 Classification 문제점 해결방법, accessed July 19, 2025, <a href="https://datasciencediary.tistory.com/entry/%EB%B6%88%EA%B7%A0%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0-Imbalanced-Data-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-Classification-%EB%AC%B8%EC%A0%9C%EC%A0%90-%ED%95%B4%EA%B2%B0%EB%B0%A9%EB%B2%95">https://datasciencediary.tistory.com/entry/%EB%B6%88%EA%B7%A0%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0-Imbalanced-Data-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-Classification-%EB%AC%B8%EC%A0%9C%EC%A0%90-%ED%95%B4%EA%B2%B0%EB%B0%A9%EB%B2%95</a></li>
<li>[홀로서기 #08] 이상 탐지(Anomaly Detection) 베이직. - 매일 데이터와 가까워지는 곳, accessed July 19, 2025, https://go-for-data.tistory.com/entry/08-Anomaly-Detection-Basic-with-Unsupervised-learning</li>
<li>Data Augmentation Using Generative Adversarial Networks for Electrical Insulator Anomaly Detection | Request PDF - ResearchGate, accessed July 19, 2025, https://www.researchgate.net/publication/341758053_Data_Augmentation_Using_Generative_Adversarial_Networks_for_Electrical_Insulator_Anomaly_Detection</li>
<li>이상 감지 - Anomaly Detection - 인투더데이터 - Into the data, accessed July 19, 2025, https://intothedata.com/02.scholar_category/anomaly_detection/</li>
<li>머신러닝 기반 이상 탐지(Anomaly Detection) 기법의 종류, accessed July 19, 2025, <a href="https://nanunzoey.tistory.com/entry/%EC%9D%B4%EC%83%81-%ED%83%90%EC%A7%80Anomaly-Detection-%EA%B8%B0%EB%B2%95%EC%9D%98-%EC%A2%85%EB%A5%98">https://nanunzoey.tistory.com/entry/%EC%9D%B4%EC%83%81-%ED%83%90%EC%A7%80Anomaly-Detection-%EA%B8%B0%EB%B2%95%EC%9D%98-%EC%A2%85%EB%A5%98</a></li>
<li>repository.kihasa.re.kr, accessed July 19, 2025, <a href="https://repository.kihasa.re.kr/en/bitstream/201002/32608/1/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5(Machine%20Learning)%20%EA%B8%B0%EB%B0%98%20%EC%9D%B4%EC%83%81%20%ED%83%90%EC%A7%80(Anomaly%20Detection)%20%EA%B8%B0%EB%B2%95%20%EC%97%B0%EA%B5%AC-%20%EB%B3%B4%EA%B1%B4%EC%82%AC%ED%9A%8C%20%EB%B6%84%EC%95%BC%EB%A5%BC%20%EC%A4%91%EC%8B%AC%EC%9C%BC%EB%A1%9C.pdf">https://repository.kihasa.re.kr/en/bitstream/201002/32608/1/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5%28Machine%20Learning%29%20%EA%B8%B0%EB%B0%98%20%EC%9D%B4%EC%83%81%20%ED%83%90%EC%A7%80%28Anomaly%20Detection%29%20%EA%B8%B0%EB%B2%95%20%EC%97%B0%EA%B5%AC-%20%EB%B3%B4%EA%B1%B4%EC%82%AC%ED%9A%8C%20%EB%B6%84%EC%95%BC%EB%A5%BC%20%EC%A4%91%EC%8B%AC%EC%9C%BC%EB%A1%9C.pdf</a></li>
<li>이상 탐지(Anomaly Detection) - velog, accessed July 19, 2025, <a href="https://velog.io/@nadagyeong/%EC%9D%B4%EC%83%81-%ED%83%90%EC%A7%80Anomaly-Detection">https://velog.io/@nadagyeong/%EC%9D%B4%EC%83%81-%ED%83%90%EC%A7%80Anomaly-Detection</a></li>
<li>Edge AI 환경에서 실시간 산불연기 감지를 위한 딥러닝 모델 경량화 성능 분석 - RISS 검색 - 국내학술지논문 상세보기, accessed July 19, 2025, https://m.riss.kr/search/detail/DetailView.do?p_mat_type=1a0202e37d52c72d&amp;control_no=cbd92cb8f3fc7b3fb36097776a77e665</li>
<li>[논문 리뷰] Comprehensive and Comparative Analysis between Transfer Learning and Custom Built VGG and CNN-SVM Models for Wildfire Detection, accessed July 19, 2025, https://www.themoonlight.io/ko/review/comprehensive-and-comparative-analysis-between-transfer-learning-and-custom-built-vgg-and-cnn-svm-models-for-wildfire-detection</li>
<li>Journal Archive - Korean Institute of Information Technology, accessed July 19, 2025, https://ki-it.com/_common/do.php?a=full&amp;b=22&amp;bidx=3244&amp;aidx=36146</li>
<li>(PDF) Advanced wildfire detection using generative adversarial …, accessed July 19, 2025, https://www.researchgate.net/publication/364951478_Advanced_wildfire_detection_using_generative_adversarial_network-based_augmented_datasets_and_weakly_supervised_object_localization/download</li>
<li>A Comprehensive Survey on Imbalanced Data Learning - arXiv, accessed July 19, 2025, https://arxiv.org/pdf/2502.08960</li>
<li>불균형 데이터(Data Imbalance) 처리 - 모델 조정 방법(Cost-Sensitive,Focal loss,Novelty Detection - 데이널 『데이터 ∙ 분석 ∙ 지식소통』, accessed July 19, 2025, <a href="https://bommbom.tistory.com/entry/%EB%B6%88%EA%B7%A0%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0Data-Imbalance-%EC%B2%98%EB%A6%AC-%EB%AA%A8%EB%8D%B8-%EC%A1%B0%EC%A0%95-%EB%B0%A9%EB%B2%95Cost-SensitiveFocal-lossNovelty-Detection">https://bommbom.tistory.com/entry/%EB%B6%88%EA%B7%A0%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0Data-Imbalance-%EC%B2%98%EB%A6%AC-%EB%AA%A8%EB%8D%B8-%EC%A1%B0%EC%A0%95-%EB%B0%A9%EB%B2%95Cost-SensitiveFocal-lossNovelty-Detection</a></li>
<li>불균형 클래스 분류 다루기 - 코딩하는 오리 - 티스토리, accessed July 19, 2025, https://cori.tistory.com/168</li>
<li>Cost-sensitive learning in scikit-learn - YouTube, accessed July 19, 2025, https://www.youtube.com/watch?v=n21_An7Usyc</li>
<li>불균형 데이터 처리: Focal Loss - velog, accessed July 19, 2025, <a href="https://velog.io/@heomollang/%EB%B6%88%EA%B7%A0%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B2%98%EB%A6%AC-Focal-Loss">https://velog.io/@heomollang/%EB%B6%88%EA%B7%A0%ED%98%95-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B2%98%EB%A6%AC-Focal-Loss</a></li>
<li>[논문 리뷰] (RetinaNet) Focal Loss for Dense Object Detection - 단순하게 - 티스토리, accessed July 19, 2025, https://talktato.tistory.com/13</li>
<li>Use Focal Loss To Train Model Using Imbalanced Dataset - Lei Mao, accessed July 19, 2025, https://leimao.github.io/blog/Focal-Loss-Explained/</li>
<li>How to Fix Imbalanced Classes with Focal Loss | by Natthawat Phongchit | Medium, accessed July 19, 2025, https://medium.com/@natthawatphongchit/how-to-fix-imbalanced-classes-with-focal-loss-559de3ef94a3</li>
<li>6.4. Classification on imbalanced labels with focal loss - skscope, accessed July 19, 2025, https://skscope.readthedocs.io/en/0.1.7/gallery/Miscellaneous/focal-loss-with-imbalanced-data.html</li>
<li>Focused Anchors Loss: cost-sensitive learning of discriminative …, accessed July 19, 2025, http://proceedings.mlr.press/v101/baloch19a/baloch19a.pdf</li>
<li>Anomaly detection using one class neural networks (Raghavendra Chalapath, 2018), accessed July 19, 2025, https://blog.si-analytics.ai/18</li>
<li>Anomaly Detection using One-Class Neural Networks - IE가 어른이 …, accessed July 19, 2025, https://piscesue0317.tistory.com/60</li>
<li>[논문 리뷰] 이상치 탐지 | Deep SVDD, Deep One-Class Classification - 어쩌다통계 - 티스토리, accessed July 19, 2025, https://slowsteadystat.tistory.com/34</li>
<li>Deep One-Class Classification - 홍러닝 - 티스토리, accessed July 19, 2025, https://hongl.tistory.com/78</li>
<li>Object detection and classification using few-shot learning in smart agriculture: A scoping mini review - Frontiers, accessed July 19, 2025, https://www.frontiersin.org/journals/sustainable-food-systems/articles/10.3389/fsufs.2022.1039299/full</li>
<li>[Explainable Deep One-Class Classification] 논문 정리 - Deep러닝 - 티스토리, accessed July 19, 2025, https://ysco.tistory.com/7</li>
<li>[Paper Review] Deep Few Shot Anomaly Detection - YouTube, accessed July 19, 2025, https://www.youtube.com/watch?v=y1Gk93rv7JU</li>
<li>Few-Shot Fine-Grained Forest Fire Smoke Recognition Based on …, accessed July 19, 2025, https://pubmed.ncbi.nlm.nih.gov/36366081/</li>
<li>Fire detection using few shot learning algorithms. - ijrpr, accessed July 19, 2025, https://ijrpr.com/uploads/V6ISSUE4/IJRPR41454.pdf</li>
<li>[논문 리뷰] Utilizing Transfer Learning and pre-trained Models for …, accessed July 19, 2025, https://www.themoonlight.io/ko/review/utilizing-transfer-learning-and-pre-trained-models-for-effective-forest-fire-detection-a-case-study-of-uttarakhand</li>
<li>전이 학습이란 무엇인가요? - IBM, accessed July 19, 2025, https://www.ibm.com/kr-ko/think/topics/transfer-learning</li>
<li>딥러닝 기반 연기추출을 위한 구름 데이터셋의 전이학습에 대한 연구 …, accessed July 19, 2025, https://www.koreascience.kr/article/JAKO202231363928907.page?&amp;lang=ko</li>
<li>Wildfire-Detection Method Using DenseNet and CycleGAN Data …, accessed July 19, 2025, https://www.mdpi.com/2072-4292/12/22/3715</li>
<li>The Role of Synthetic Data in Enhancing Anomaly Detection Performance - Diffusion Model | by Shawn | Medium, accessed July 19, 2025, https://medium.com/@hexiangnan/the-role-of-synthetic-data-in-enhancing-anomaly-detection-performance-diffusion-model-6b386f3c210b</li>
<li>AnoGAN for Tabular Data: A Novel Approach to Anomaly Detection, accessed July 19, 2025, https://faculty.cs.gwu.edu/xiaodongqu/papers/HCII_2024_500_AnoGAN_Aditya.pdf</li>
<li>Detecting the Unseen: Anomaly Detection with GANs | by Francesco Saracco | Data Reply IT, accessed July 19, 2025, https://medium.com/data-reply-it-datatech/detecting-the-unseen-anomaly-detection-with-gans-8b20f3056a11</li>
<li>A Survey on Diffusion Models for Anomaly Detection - arXiv, accessed July 19, 2025, https://arxiv.org/html/2501.11430v3</li>
<li>Tackling Structural Hallucination in Image Translation with Local Diffusion, accessed July 19, 2025, https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/10498.pdf</li>
<li>MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation - arXiv, accessed July 19, 2025, https://arxiv.org/pdf/2507.02314</li>
<li>[Literature Review] Anomaly Detection and Generation with Diffusion Models: A Survey, accessed July 19, 2025, https://www.themoonlight.io/en/review/anomaly-detection-and-generation-with-diffusion-models-a-survey</li>
<li>Data generation via diffusion models for crowd anomaly detection - BMVA Archive, accessed July 19, 2025, https://bmva-archive.org.uk/bmvc/2024/workshops/SRBS/0005.pdf</li>
<li>Dynamic Addition of Noise in a Diffusion Model for Anomaly Detection - CVF Open Access, accessed July 19, 2025, https://openaccess.thecvf.com/content/CVPR2024W/VAND/papers/Tebbe_Dynamic_Addition_of_Noise_in_a_Diffusion_Model_for_Anomaly_CVPRW_2024_paper.pdf</li>
<li>Synthetic data generation by diffusion models | National Science Review - Oxford Academic, accessed July 19, 2025, https://academic.oup.com/nsr/advance-article/doi/10.1093/nsr/nwae276/7740777</li>
<li>A Survey on Diffusion Models for Anomaly Detection - arXiv, accessed July 19, 2025, https://arxiv.org/html/2501.11430v4</li>
<li>AnomalyControl: Learning Cross-modal Semantic Features for Controllable Anomaly Synthesis - ResearchGate, accessed July 19, 2025, https://www.researchgate.net/publication/386577406_AnomalyControl_Learning_Cross-modal_Semantic_Features_for_Controllable_Anomaly_Synthesis</li>
<li>[2412.06510] AnomalyControl: Learning Cross-modal Semantic Features for Controllable Anomaly Synthesis - arXiv, accessed July 19, 2025, https://arxiv.org/abs/2412.06510</li>
<li>AnomalyControl: Learning Cross-modal Semantic Features for Controllable Anomaly Synthesis - arXiv, accessed July 19, 2025, https://arxiv.org/html/2412.06510v1</li>
<li>MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation - arXiv, accessed July 19, 2025, https://arxiv.org/html/2507.02314v1</li>
<li>(PDF) MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation - ResearchGate, accessed July 19, 2025, https://www.researchgate.net/publication/393378295_MAGIC_Mask-Guided_Diffusion_Inpainting_with_Multi-Level_Perturbations_and_Context-Aware_Alignment_for_Few-Shot_Anomaly_Generation</li>
<li>CostFilter-AD: Enhancing Anomaly Detection through Matching Cost Filtering - ICML 2025, accessed July 19, 2025, https://icml.cc/virtual/2025/poster/46359</li>
<li>Daily Papers - Hugging Face, accessed July 19, 2025, <a href="https://huggingface.co/papers?q=real+anomalies">https://huggingface.co/papers?q=real%20anomalies</a></li>
<li>DualAD: Exploring Coupled Dual-Branch Networks for Multi-Class Unsupervised Anomaly Detection - MDPI, accessed July 19, 2025, https://www.mdpi.com/2079-9292/14/3/594</li>
<li>Dual-Interrelated Diffusion Model for Few-Shot Anomaly Image Generation - arXiv, accessed July 19, 2025, https://arxiv.org/html/2408.13509v3</li>
<li>A Diffusion-Based Framework for Multi-Class Anomaly Detection - ResearchGate, accessed July 19, 2025, https://www.researchgate.net/publication/379293798_A_Diffusion-Based_Framework_for_Multi-Class_Anomaly_Detection</li>
<li>Dissolving Is Amplifying: Towards Fine-Grained Anomaly Detection, accessed July 19, 2025, https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07681.pdf</li>
<li>PWD: Prior-Guided and Wavelet-Enhanced Diffusion Model for Limited-Angle CT, accessed July 19, 2025, https://www.researchgate.net/publication/393512024_PWD_Prior-Guided_and_Wavelet-Enhanced_Diffusion_Model_for_Limited-Angle_CT</li>
<li>DETAILED REPORT ON THE ADOPTION OF ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING IN CUSTOMS MARCH 2025, accessed July 19, 2025, https://www.wcoomd.org/-/media/wco/public/global/pdf/topics/facilitation/activities-and-programmes/smart-customs/public-version_detailed-report-on-the-adoption-of-ai-and-ml-in-customs.pdf</li>
<li>national conference on engineering innovations in emerging technologies (nceiet-2025), accessed July 19, 2025, https://ijsrst.com/paper/v12i15.pdf</li>
<li>Daily Papers - Hugging Face, accessed July 19, 2025, <a href="https://huggingface.co/papers?q=GPU+memory+management">https://huggingface.co/papers?q=GPU%20memory%20management</a></li>
<li>Synthetic Data Generation with Diffusion Models - Hugging Face …, accessed July 19, 2025, https://huggingface.co/learn/computer-vision-course/unit10/datagen-diffusion-models</li>
<li>Using diffusion models to generate synthetic data for real-life projects, accessed July 19, 2025, https://iblog.ridge-i.com/entry/2024/02/22/130409</li>
<li>Benchmarking of Anomaly Detection Methods for Industry 4.0: Evaluation, Ranking, and Practical Recommendations - ResearchGate, accessed July 19, 2025, https://www.researchgate.net/publication/391712838_Benchmarking_of_Anomaly_Detection_Methods_for_Industry_40_Evaluation_Ranking_and_Practical_Recommendations</li>
<li>(PDF) CUT: A Controllable, Universal, and Training-Free Visual …, accessed July 19, 2025, https://www.researchgate.net/publication/381122787_CUT_A_Controllable_Universal_and_Training-Free_Visual_Anomaly_Generation_Framework</li>
<li>M-3LAB/awesome-industrial-anomaly-detection - GitHub, accessed July 19, 2025, https://github.com/M-3LAB/awesome-industrial-anomaly-detection</li>
<li>(PDF) Continual-MEGA: A Large-scale Benchmark for Generalizable Continual Anomaly Detection - ResearchGate, accessed July 19, 2025, https://www.researchgate.net/publication/392335072_Continual-MEGA_A_Large-scale_Benchmark_for_Generalizable_Continual_Anomaly_Detection</li>
<li>Model Selection of Anomaly Detectors in the Absence of Labeled Validation Data, accessed July 19, 2025, https://openreview.net/forum?id=HW2lIdrvPb</li>
<li>Benchmarking Unsupervised Outlier Detection with Realistic Synthetic Data - ResearchGate, accessed July 19, 2025, https://www.researchgate.net/publication/350962443_Benchmarking_Unsupervised_Outlier_Detection_with_Realistic_Synthetic_Data</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>