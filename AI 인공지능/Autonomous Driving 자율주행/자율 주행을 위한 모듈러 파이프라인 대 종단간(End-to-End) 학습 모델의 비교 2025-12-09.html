<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:모듈러 파이프라인 대 종단간(End-to-End) 학습 모델의 비교</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>모듈러 파이프라인 대 종단간(End-to-End) 학습 모델의 비교</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">자율주행 (Autonomous Driving)</a> / <span>모듈러 파이프라인 대 종단간(End-to-End) 학습 모델의 비교</span></nav>
                </div>
            </header>
            <article>
                <h1>모듈러 파이프라인 대 종단간(End-to-End) 학습 모델의 비교</h1>
<p>2025-12-09, G30DR</p>
<h2>1.  서론: 결정론적 제어와 확률론적 직관의 충돌</h2>
<p>2024년과 2025년을 기점으로 자율주행 기술 생태계는 근본적인 철학적, 기술적 대분기(Great Divergence)를 맞이했다.1 지난 수십 년간 자율주행 시스템의 표준으로 자리 잡았던 <strong>모듈러 파이프라인(Modular Pipeline)</strong> 아키텍처는 인지, 판단, 제어라는 명확한 기능적 분업을 통해 발전해 왔다. 이는 복잡한 문제를 인간이 이해하고 검증할 수 있는 단위로 쪼개어 해결하려는 공학적 환원주의의 산물이다. 반면, 딥러닝 기술의 성숙과 함께 등장한 <strong>종단간(End-to-End, E2E) 학습</strong> 모델은 이러한 환원주의를 거부한다. 센서의 원시 데이터(Raw Data) 입력부터 차량의 제어 신호 출력까지를 하나의 거대한 신경망으로 연결하는 이 방식은, 명시적인 규칙 대신 데이터에 내재된 패턴을 학습하여 인간의 직관적 운전을 모사하려 한다.</p>
<p>Tesla의 FSD v12 업데이트가 기존의 30만 줄에 달하는 C++ 제어 코드를 제거하고 거대 신경망으로 대체한 사건은 이러한 패러다임 전환의 상징적인 이정표가 되었다.1 그러나 동시에 Waymo와 Mobileye 등은 여전히 검증 가능한 안전성을 이유로 모듈러 구조 혹은 하이브리드 접근법을 고수하며, E2E 방식의 ‘블랙박스(Black Box)’ 특성이 가진 위험성을 경고한다.</p>
<p>본 보고서는 이 두 가지 지배적인 아키텍처의 기술적 원리, 핵심 알고리즘, 그리고 각 방식이 내포한 장단점을 기술적, 산업적 관점에서 심층 분석한다. 특히 PID 및 MPC 제어 알고리즘부터 최신 UniAD 및 Hydra-MDP 모델에 이르기까지 구체적인 기술 요소를 해부하고, 안전성 검증(Verification &amp; Validation, V&amp;V)을 둘러싼 난제와 해결 방안을 모색함으로써 자율주행 기술의 미래를 조망한다.</p>
<h2>2.  모듈러 파이프라인(Modular Pipeline): 분할 정복을 통한 결정론적 안전성</h2>
<h3>2.1  아키텍처 철학 및 구조적 특성</h3>
<p>모듈러 파이프라인은 복잡한 자율주행 작업을 독립적인 기능을 수행하는 하위 시스템(Sub-system)들의 직렬 연결로 구성한다. 이 방식의 핵심 철학은 ’분할 정복(Divide and Conquer)’이다. 시스템 전체를 한 번에 해결하려 하기보다는, **인지(Perception), 측위(Localization), 예측(Prediction), 계획(Planning), 제어(Control)**라는 명확히 정의된 단계로 나누어 각 문제를 최적화한다.2</p>
<p>이 구조의 가장 큰 강점은 **해석 가능성(Interpretability)**과 **디버깅 용이성(Debuggability)**에 있다. 예를 들어 자율주행차가 급제동을 했을 때, 모듈러 시스템에서는 인지 모듈이 유령 장애물을 탐지했는지, 예측 모듈이 주변 차량의 경로를 잘못 예상했는지, 아니면 제어 모듈의 파라미터 튜닝이 잘못되었는지를 명확히 추적할 수 있다. 이는 ISO 26262와 같은 기능 안전 표준(Functional Safety Standards)을 준수하고 인증받는 데 있어 필수적인 요소로 작용한다.</p>
<h3>2.2  핵심 구성 요소별 기술 심층 분석</h3>
<h4>2.2.1  인지(Perception): 다중 센서 퓨전의 정교함</h4>
<p>모듈러 시스템의 인지 단계는 인간의 눈과 귀를 대신한다. LiDAR, Radar, Camera 등 다양한 모달리티(Modality)의 센서 데이터를 융합하여 주변 환경을 3차원으로 재구성한다.</p>
<ul>
<li><strong>센서 퓨전 전략:</strong> Waymo와 같은 선도 기업은 **중복성(Redundancy)**을 핵심 안전 원칙으로 삼는다. 13개의 카메라, 4개의 LiDAR, 6개의 레이더를 통합하여, 특정 센서가 안개나 역광 등으로 인해 불능 상태가 되더라도 다른 센서가 상호 보완할 수 있도록 설계한다.1</li>
<li><strong>객체 탐지 알고리즘:</strong> 초기에는 SVM(Support Vector Machine) 등의 고전적 머신러닝이 사용되었으나, 현재는 CNN(Convolutional Neural Networks)과 트랜스포머(Transformer) 기반의 딥러닝 모델이 주류를 이룬다. 이들은 카메라 이미지와 LiDAR 포인트 클라우드를 처리하여 보행자, 차량, 신호등을 식별하고 3D Bounding Box를 생성한다.</li>
</ul>
<h4>2.2.2  측위(Localization): 정밀지도(HD Map)와의 동기화</h4>
<p>인지된 환경 정보만으로는 자율주행이 불가능하다. 차량은 자신이 지구상의 어디에 있는지, 그리고 차선 내에서 정확히 어디에 위치하는지를 cm 단위로 파악해야 한다. 이를 위해 모듈러 방식은 **정밀지도(HD Map)**에 크게 의존한다.</p>
<ul>
<li><strong>핵심 알고리즘:</strong></li>
<li><strong>파티클 필터(Particle Filter):</strong> 차량의 위치를 확률 분포(입자들의 집합)로 표현하고, 센서 관측 값에 따라 입자들의 가중치를 갱신하며 위치를 추정한다. 이는 비선형 시스템에 강건하여 자율주행 측위의 표준처럼 사용된다.4</li>
<li><strong>SLAM(Simultaneous Localization and Mapping):</strong> 사전에 지도가 없는 환경에서 주행하며 지도를 작성함과 동시에 위치를 추정하는 기술이다. FastSLAM과 같은 알고리즘은 파티클 필터를 기반으로 하여 계산 효율성을 높였으나, 여전히 대규모 환경에서의 계산 비용 문제가 존재한다.6 최근에는 그래프 기반의 GraphSLAM이 최적화 문제 해결에 널리 쓰인다.</li>
<li><strong>한계점:</strong> HD 지도에 대한 의존성은 확장성(Scalability)의 족쇄가 된다. 도로 공사나 차선 변경 등 현실 세계의 변화가 지도에 즉각 반영되지 않을 경우(Map Rot), 심각한 안전 문제를 야기할 수 있으며, 전 세계 모든 도로의 HD 지도를 구축하고 유지보수하는 비용은 천문학적이다.</li>
</ul>
<h4>2.2.3  예측(Prediction) 및 계획(Planning): 규칙과 최적화의 결합</h4>
<p>주변 객체의 움직임을 예측하고 자차의 경로를 생성하는 단계는 자율주행의 두뇌에 해당한다.</p>
<ul>
<li><strong>예측(Prediction):</strong> 칼만 필터(Kalman Filter)를 사용하여 객체의 현재 속도와 방향을 추적하고, 이를 바탕으로 미래 궤적을 예측한다. 최근에는 RNN(Recurrent Neural Networks)이나 LSTM 등을 활용하여 주변 차량 간의 상호작용까지 고려한 확률적 예측 모델이 도입되고 있다.</li>
<li><strong>계획(Planning):</strong></li>
<li><strong>경로 계획(Mission Planning):</strong> A* 알고리즘 등을 사용하여 목적지까지의 전역 경로를 생성한다.</li>
<li><strong>행동 계획(Behavior Planning):</strong> 유한 상태 머신(Finite State Machine, FSM)을 사용하여 차선 변경, 추월, 정지 등의 고수준 의사결정을 내린다.</li>
<li><strong>동작 계획(Motion Planning):</strong> 구체적인 조향 및 속도 프로파일을 생성한다. 3차 다항식 곡선(Cubic Spline)이나 격자 기반(Lattice) 계획법이 사용되며, 승차감(Jerk 최소화)과 충돌 회피를 목적함수로 하는 최적화 문제를 푼다.3</li>
</ul>
<h4>2.2.4  제어(Control): PID에서 MPC로의 진화</h4>
<p>계획된 경로를 실제 차량의 물리적 움직임으로 변환하는 단계이다.</p>
<ul>
<li><strong>PID 제어기(Proportional-Integral-Derivative):</strong> 오차의 비례(P), 적분(I), 미분(D) 값을 조합하여 제어 입력을 계산한다. 구현이 간단하고 연산량이 적어 널리 쓰였으나, 차량의 동역학적 특성이나 미래의 도로 곡률을 미리 반영하지 못하는 ‘반응형’ 제어라는 한계가 있다. 고속 주행 시 오버슈트(Overshoot)나 진동이 발생할 수 있다.8</li>
<li><strong>모델 예측 제어(MPC, Model Predictive Control):</strong> 현대 자율주행 제어의 표준이다. 차량의 운동학적 모델(Kinematic Model) 또는 동역학적 모델(Dynamic Model)을 사용하여, 현재 상태에서 일정 시간(Horizon) 동안의 미래 거동을 예측하고, 제약 조건(최대 조향각, 타이어 마찰력 등)을 만족하면서 오차를 최소화하는 최적의 제어 입력을 실시간으로 계산한다.10 MPC는 예지(Look-ahead) 능력이 있어 곡선 도로 진입 전 미리 감속하는 등의 인간다운 운전이 가능하다.</li>
</ul>
<h3>2.3  모듈러 방식의 한계: 오차 전파와 정보 병목</h3>
<p>모듈러 아키텍처는 검증 가능성이라는 강력한 장점에도 불구하고 구조적 한계에 직면했다.</p>
<ol>
<li><strong>오차 전파(Error Propagation):</strong> 상위 모듈의 미세한 오류가 하위 모듈로 갈수록 증폭된다. 예를 들어, 인지 모듈이 장애물의 위치를 5cm 오차로 탐지하면, 예측 모듈은 궤적을 50cm 다르게 예측할 수 있고, 이는 제어 모듈에서 급격한 조향을 유발할 수 있다.12</li>
<li><strong>정보 병목(Information Bottleneck):</strong> 모듈 간 인터페이스는 사람이 정의한 데이터 포맷(예: 객체 목록, 차선 좌표)으로 제한된다. 이 과정에서 원시 센서 데이터에 포함된 미묘한 문맥 정보(Context)—예를 들어, 보행자의 시선이나 미세한 제스처—가 손실되거나 필터링되어 버린다.13</li>
<li><strong>최적화의 불일치:</strong> 각 모듈은 개별적인 목표(인지 정확도, 경로 최단 거리 등)를 위해 최적화되지만, 이것이 반드시 전체 주행의 안전성이나 승차감이라는 최종 목표와 일치하지 않을 수 있다.</li>
</ol>
<h2>3.  종단간(End-to-End) 자율주행: 데이터 중심의 통합과 직관의 모사</h2>
<h3>3.1  아키텍처 철학 및 역사적 맥락</h3>
<p>종단간(End-to-End, E2E) 자율주행은 모듈 간의 경계를 허물고, 센서 입력에서 제어 출력까지를 단일한 최적화 과정으로 통합하는 패러다임이다. 이는 “Photon-to-Control“이라고도 불리며, 입력 데이터와 출력 행동 사이의 복잡한 매핑 관계를 신경망이 스스로 학습하게 한다.</p>
<p>이 개념은 1989년 카네기 멜론 대학(CMU)의 ALVINN(Autonomous Land Vehicle In a Neural Network) 프로젝트에서 처음 시도되었다.15 당시에는 하드웨어 성능의 한계로 단순한 차선 유지 정도에 그쳤으나, GPU 기술의 비약적 발전과 심층 신경망(Deep Neural Networks)의 등장은 이 오래된 아이디어를 자율주행의 최전선으로 소환했다. NVIDIA의 DAVE-2 시스템은 CNN을 활용하여 이를 현대적으로 재구현한 초기 사례이다.14</p>
<h3>3.2  핵심 학습 방법론과 기술적 진보</h3>
<h4>3.2.1  모방 학습(Imitation Learning, IL): 전문가의 행동 복제</h4>
<p>가장 직관적인 E2E 학습 방법은 숙련된 인간 운전자의 주행 데이터를 수집하고, 신경망이 이를 흉내 내도록 가르치는 것이다. 이를 행동 복제(Behavior Cloning)라고 한다.</p>
<ul>
<li><strong>장점:</strong> 규칙으로 정의하기 어려운 인간의 미묘한 운전 기술(예: 끼어들기 타이밍, 비정형 도로 주행)을 학습할 수 있다.</li>
<li><strong>한계 - 공변량 변화(Covariate Shift):</strong> 학습 데이터에 없는 상황(예: 차선을 벗어난 상태)에 직면했을 때, 신경망이 복구하는 방법을 모르기 때문에 오차가 누적되어 궤도를 이탈하는 현상이다. 이를 해결하기 위해 DAgger(Dataset Aggregation)와 같은 알고리즘이 제안되었으나, 실시간 데이터 수집 비용이 높다는 단점이 있다.16</li>
</ul>
<h4>3.2.2  강화 학습(Reinforcement Learning, RL): 시행착오를 통한 초월</h4>
<p>강화 학습은 정답(인간의 행동)을 따라 하는 것이 아니라, 보상 함수(Reward Function)를 최대화하는 행동을 스스로 찾아내는 방식이다. 시뮬레이션 환경에서 에이전트가 수만 번의 시행착오를 겪으며 주행 정책(Policy)을 학습한다.</p>
<ul>
<li><strong>특징:</strong> 인간보다 더 효율적이거나 안전한 주행 전략을 발견할 가능성이 있다. Deep Q-Network(DQN)나 PPO(Proximal Policy Optimization) 등의 알고리즘이 활용된다.</li>
<li><strong>도전 과제:</strong> 현실 세계에서는 수만 번의 사고를 낼 수 없으므로(Sample Inefficiency), 시뮬레이션에서 학습한 정책을 현실로 옮길 때 발생하는 ’Sim-to-Real Gap’을 줄이는 것이 핵심 난제이다.17</li>
</ul>
<h4>3.2.3  최신 아키텍처: 트랜스포머와 통합적 쿼리 설계</h4>
<p>최근 E2E 연구는 단순한 CNN을 넘어 트랜스포머(Transformer) 아키텍처를 적극 도입하고 있다. **UniAD(Unified Autonomous Driving)**는 CVPR 2023에서 주목받은 모델로, 인지, 예측, 계획을 개별 모듈이 아닌 하나의 네트워크 내에서 계층적으로 통합했다.</p>
<ul>
<li><strong>쿼리(Query) 기반 통신:</strong> UniAD는 각 태스크 간의 연결을 벡터 형태의 ’쿼리’로 처리한다. 인지 단계의 쿼리가 예측 단계의 쿼리와 상호작용하고, 최종적으로 계획 쿼리에 영향을 미친다. 이는 모듈러 방식의 장점(구조화)을 유지하면서도 E2E의 장점(전역 최적화)을 취하는 형태로, 주행 계획(Planning)의 정확도를 높이는 방향으로 모든 하위 태스크가 동시에 학습(Joint Optimization)된다.18</li>
</ul>
<h3>3.3  주요 기업 및 프로젝트 사례 연구</h3>
<h4>3.3.1  Tesla FSD v12: 규칙 기반 코드의 종말</h4>
<p>Tesla는 E2E 방식의 가장 강력한 지지자이자 실천가이다. FSD v12는 기존의 규칙 기반(Rule-based) 제어 코드를 제거하고, 수십억 마일의 실제 주행 영상 데이터를 학습한 신경망으로 대체했다. 일론 머스크는 LiDAR와 Radar를 배제하고 오직 카메라(Vision)만으로 주행이 가능하다고 주장하며, 이를 통해 하드웨어 비용을 절감하고 시스템의 복잡도를 낮추었다.1 Tesla의 ’데이터 엔진(Data Engine)’은 사용자의 개입이 발생한 시점의 데이터를 수집하여 모델을 재학습시키는 선순환 구조를 통해 지속적으로 성능을 개선한다.</p>
<h4>3.3.2  Waabi: 생성형 AI와 해석 가능한 E2E</h4>
<p>Waabi는 E2E의 블랙박스 문제를 해결하기 위해 ’해석 가능한(Interpretable) E2E’를 표방한다. Waabi Driver는 내부적으로 중간 표현(Intermediate Representation)을 생성하여 의사결정의 근거를 추적할 수 있게 한다. 또한, ’Waabi World’라는 고도화된 시뮬레이터에 생성형 AI 기술을 접목하여, 현실에서는 수집하기 어려운 희귀한 사고 상황(Edge Case)을 가상으로 생성하고 학습시킨다. 이는 물리적 주행 테스트의 필요성을 줄이면서도 안전성을 확보하는 효율적인 전략이다.21</p>
<h4>3.3.3  Wayve와 NVIDIA: 거대 언어 모델의 융합</h4>
<p>영국의 Wayve는 거대 언어 모델(LLM)과 비전 모델을 결합한 LINGO 등을 개발하여, 자율주행차가 자신의 행동 이유를 자연어로 설명할 수 있게 한다. NVIDIA 역시 Hydra-MDP와 같은 모델을 통해 인식-예측-계획을 통합하고, CVPR 2024 챌린지에서 우승하며 기술력을 입증했다. 이들의 접근은 단순한 주행을 넘어, 복잡한 사회적 상호작용이 필요한 상황에서의 추론(Reasoning) 능력을 강화하는 데 초점을 맞춘다.24</p>
<h3>3.4  E2E 방식의 치명적 약점: 블랙박스와 검증 불가성</h3>
<p>E2E 시스템의 가장 큰 비판점은 내부 동작 원리를 완벽히 이해하기 어렵다는 점이다. 수십억 개의 파라미터가 얽혀 있는 신경망은 입출력 관계가 불투명하여, 사고 발생 시 원인 규명(Root Cause Analysis)이 매우 어렵다. 또한, 기존의 기능 안전 표준(ISO 26262)은 모듈 단위의 검증을 전제로 하기 때문에, E2E 시스템에 그대로 적용하기에는 한계가 있다.26 이는 규제 기관의 승인을 받는 데 있어 큰 걸림돌로 작용한다.</p>
<h2>4.  비교 분석 및 기술 융합의 현주소</h2>
<p>두 아키텍처의 특징을 비교 분석하면 다음과 같은 상반된 속성을 발견할 수 있다.</p>
<table><thead><tr><th><strong>비교 항목</strong></th><th><strong>모듈러 파이프라인 (Modular Pipeline)</strong></th><th><strong>종단간 학습 (End-to-End Learning)</strong></th></tr></thead><tbody>
<tr><td><strong>정보 처리 흐름</strong></td><td>순차적, 명시적 인터페이스 (Sequential)</td><td>병렬적, 통합적 (Parallel/Joint)</td></tr>
<tr><td><strong>최적화 목표</strong></td><td>각 모듈별 개별 최적화 (Local Optimization)</td><td>최종 주행 성능에 대한 전역 최적화 (Global Optimization)</td></tr>
<tr><td><strong>해석 가능성</strong></td><td><strong>높음</strong> (입출력 명확, 디버깅 용이)</td><td><strong>낮음</strong> (신경망 가중치 의존, 블랙박스)</td></tr>
<tr><td><strong>데이터 의존도</strong></td><td>중간 (알고리즘 튜닝 및 규칙 정의 중요)</td><td><strong>매우 높음</strong> (대규모 양질의 데이터 필수)</td></tr>
<tr><td><strong>확장성 (Scalability)</strong></td><td>낮음 (새로운 환경마다 HD 지도/규칙 필요)</td><td><strong>높음</strong> (데이터만 있으면 새로운 환경 적응 용이)</td></tr>
<tr><td><strong>일반화 (Generalization)</strong></td><td>정의되지 않은 상황(Unseen)에 취약</td><td>학습 데이터 분포 내에서 우수, 분포 외 상황 대응 가능성</td></tr>
<tr><td><strong>안전성 검증</strong></td><td>ISO 26262 등 표준 적용 및 형식 검증 용이</td><td>확률론적 검증, 쉐도우 모드 등 새로운 방법론 필요</td></tr>
<tr><td><strong>대표 주자</strong></td><td>Waymo, Mobileye(초기), Baidu Apollo</td><td>Tesla, Waabi, Wayve, Comma.ai, NVIDIA(최신)</td></tr>
</tbody></table>
<h3>4.1  하이브리드 아키텍처와 ’모듈러 E2E’의 부상</h3>
<p>최근 학계와 산업계는 이분법적 논쟁을 넘어 두 방식의 장점을 결합하는 방향으로 선회하고 있다. 이를 **모듈러 E2E(Modular End-to-End)**라고 부른다. 전체 시스템을 미분 가능한(Differentiable) 신경망 모듈로 구성하여 E2E처럼 전체 최적화(End-to-End Training)를 수행하되, 중간 단계에서 BEV, 객체 점유(Occupancy), 궤적(Trajectory) 등의 명시적인 표현을 출력하도록 강제하는 것이다.27</p>
<p>이 방식은 중간 출력을 통해 시스템이 무엇을 보고 어떻게 판단했는지 모니터링하고 디버깅할 수 있게 해주며(해석 가능성), 동시에 다운스트림 모듈이 업스트림 모듈의 풍부한 잠재 특징(Latent Feature)을 활용하여 정보 손실을 최소화할 수 있게 한다(성능 최적화).13 UniAD와 VAD(Vectorized Autonomous Driving) 등의 연구가 이러한 흐름을 주도하고 있으며, 이는 모듈러 방식의 구조적 안정성과 E2E 방식의 성능적 우위를 동시에 달성하려는 시도이다.</p>
<h3>4.2  Compound AI: Mobileye의 절충안</h3>
<p>Mobileye는 ’Compound AI’라는 개념을 제시하며, 거대 단일 모델 대신 여러 특화된 AI 모델을 유기적으로 결합하는 방식을 채택했다. 이는 마치 ChatGPT가 수학 연산을 위해 별도의 Python 코드를 생성하고 실행하는 것과 유사하다. Mobileye는 여기에 RSS(Responsibility-Sensitive Safety)라는 수학적 안전 모델을 결합하여, AI의 판단이 물리적으로 안전한 경계를 넘지 않도록 강제하는 ‘가드레일’ 전략을 취한다.15 이는 확률론적 AI의 불확실성을 결정론적 안전 규칙으로 보완하려는 현실적인 접근법이다.</p>
<h2>5.  안전성 검증(V&amp;V)의 패러다임 전환과 미래 과제</h2>
<h3>5.1  E2E 시스템 검증을 위한 새로운 방법론</h3>
<p>E2E 시스템의 안전성을 입증하는 것은 자율주행 상용화의 마지막 관문이다. 기존의 코드 라인 단위 테스트는 신경망 검증에 무용지물이다. 이에 따라 다음과 같은 새로운 검증 기법들이 연구되고 있다.</p>
<ol>
<li><strong>도달 가능성 분석(Reachability Analysis):</strong> 신경망의 입력에 미세한 섭동(Perturbation)이나 노이즈가 있을 때, 출력 제어 신호가 야기할 수 있는 차량의 모든 가능한 물리적 위치의 집합(Reachable Set)을 수학적으로 계산한다. 그리고 이 집합이 도로 경계나 장애물과 겹치지 않는지를 확인하여 안전성을 보장한다. 최근 연구는 신경망 연산자를 활용하여 이 분석의 효율성을 획기적으로 높였다.29</li>
<li><strong>신경망 강건성(Robustness) 검증:</strong> 적대적 공격(Adversarial Attack)—예를 들어, 표지판에 스티커를 붙여 오인식을 유도하는 행위—에 대해 신경망이 얼마나 견고한지를 평가하는 프레임워크가 개발되고 있다.31</li>
<li><strong>대규모 시뮬레이션 및 쉐도우 모드:</strong> Tesla는 고객 차량에서 실행되는 ’쉐도우 모드’를 통해, AI의 가상 판단과 인간 운전자의 실제 행동을 실시간으로 비교하고, 불일치가 발생하는 데이터를 집중적으로 수집하여 모델을 재학습시킨다. 이는 통계적 유의성을 확보하는 실용적인 검증 방식이다.1</li>
</ol>
<h3>5.2  거대 언어 모델(LLM)과 추론(Reasoning) 능력의 통합</h3>
<p>미래의 자율주행은 단순히 ‘보고 피하는’ 수준을 넘어, 상황을 ‘이해하고 추론하는’ 단계로 진화할 것이다. 최근 연구들은 LLM을 자율주행 시스템에 통합하여, 복잡한 교통 상황을 언어적으로 해석하고 상식(Common Sense)에 기반한 판단을 내리도록 하고 있다. 예를 들어, “경찰관이 수신호로 정지 신호를 무시하고 가라고 한다“는 비정형적이고 예외적인 상황을 처리하는 데 있어 LLM의 추론 능력은 핵심적인 역할을 할 것이다.24</p>
<h2>6.  결론: 필연적인 융합과 진화의 방향</h2>
<p>자율주행 기술의 발전사는 ’규칙’에서 ’학습’으로, ’모듈’에서 ’통합’으로 거대한 흐름이 이동하고 있음을 보여준다. 본 보고서의 분석 결과, 다음과 같은 결론을 도출할 수 있다.</p>
<p>첫째, <strong>단기적으로는 모듈러 및 하이브리드 방식이 우세할 것이다.</strong> 특히 로보택시(Robotaxi)와 같이 고도로 통제된 환경에서 L4 서비스를 제공하는 Waymo와 같은 기업들에게 있어, 안전성 입증과 규제 준수가 용이한 모듈러 아키텍처는 여전히 가장 합리적인 선택지이다.</p>
<p>둘째, <strong>장기적으로 일반 상용차(Consumer Vehicle)의 완전 자율주행(L5)을 위해서는 E2E 학습이 필수불가결하다.</strong> 전 세계의 다양한 도로 환경과 예측 불가능한 엣지 케이스를 모두 규칙으로 정의하거나 HD 지도로 커버하는 것은 불가능하다. 인간처럼 경험을 통해 일반화하는 능력을 갖춘 E2E 모델만이 이러한 복잡성을 감당할 수 있다. Tesla와 Waabi의 도전은 이러한 미래를 앞당기고 있다.</p>
<p>셋째, <strong>미래의 승자는 ‘설명 가능한 E2E’ 아키텍처가 될 것이다.</strong> E2E의 뛰어난 성능과 일반화 능력을 유지하면서도, 모듈러 방식의 장점인 해석 가능성과 디버깅 용이성을 확보하는 것이 기술 개발의 핵심 목표가 되어야 한다. UniAD와 같은 기획 중심(Planning-oriented) 프레임워크, 중간 표현을 활용한 모듈러 E2E, 그리고 LLM을 활용한 설명 가능한 AI 기술의 융합은 자율주행이 단순한 기계적 제어를 넘어 진정한 지능형 시스템으로 도약하는 열쇠가 될 것이다.</p>
<p>자율주행 기술은 이제 단순한 공학적 문제를 넘어, 인공지능이 인간의 직관과 추론 능력을 어디까지 대체할 수 있는지를 시험하는 거대한 실험장이 되었다. 이 대분기의 끝에서 우리는 더욱 안전하고 효율적인 이동의 자유를 맞이하게 될 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>The Great Divergence: How Tesla’s FSD v12 is Reshaping the …, <a href="https://skywork.ai/skypage/en/The-Great-Divergence:-How-Tesla&#x27;s-FSD-v12-is-Reshaping-the-Autonomous-Driving-Landscape/1948225395187372032">https://skywork.ai/skypage/en/The-Great-Divergence:-How-Tesla%27s-FSD-v12-is-Reshaping-the-Autonomous-Driving-Landscape/1948225395187372032</a></li>
<li>Control-Aware Prediction Objectives for Autonomous Driving | IEEE Conference Publication, https://ieeexplore.ieee.org/document/9811884/</li>
<li>Perception, Planning, Control, and Coordination for Autonomous Vehicles - MDPI, https://www.mdpi.com/2075-1702/5/1/6</li>
<li>Multi-robot Simultaneous Localization and Mapping using Particle Filters, https://www-robotics.jpl.nasa.gov/media/documents/howard_ijrr06.pdf</li>
<li>Benchmarking Particle Filter Algorithms for Efficient Velodyne-Based Vehicle Localization, https://www.mdpi.com/1424-8220/19/14/3155</li>
<li>FastSLAM 2.0: An Improved Particle Filtering Algorithm for Simultaneous Localization and Mapping that Provably Converges - IJCAI, https://www.ijcai.org/Proceedings/03/Papers/165.pdf</li>
<li>Integrating Modular Pipelines with End-to-End Learning: A Hybrid Approach for Robust and Reliable Autonomous Driving Systems - NIH, https://pmc.ncbi.nlm.nih.gov/articles/PMC11014112/</li>
<li>Comparative Study of MPC and PID Controllers in Autonomous Vehicle Application | Request PDF - ResearchGate, https://www.researchgate.net/publication/363256640_Comparative_Study_of_MPC_and_PID_Controllers_in_Autonomous_Vehicle_Application</li>
<li>PID vs. Other Control Methods: What’s the Best Choice? - RealPars, https://www.realpars.com/blog/pid-vs-advanced-control-methods</li>
<li>PID vs MPC in Autonomous Vehicles: Which one is better? - YouTube, https://www.youtube.com/watch?v=ONlYfX0xxvI</li>
<li>MPC vs PID - A Comprehensive Control Method Comparison - Petrotech, Inc., https://petrotechinc.com/mpc-vs-pid-a-comprehensive-control-method-comparison/</li>
<li>China’s 4-Stage Approach to End-to-end Autonomous Driving | by Shuai Chen | Medium, https://schen583.medium.com/chinas-4-stage-approach-to-end-to-end-autonomous-driving-b018b3c706ec</li>
<li>Kyle talks pros and cons of Waymo and Tesla approaches : r/SelfDrivingCars - Reddit, https://www.reddit.com/r/SelfDrivingCars/comments/1lkcco0/kyle_talks_pros_and_cons_of_waymo_and_tesla/</li>
<li>End-to-end Autonomous Driving: Challenges and Frontiers - arXiv, https://arxiv.org/html/2306.16927v2</li>
<li>Autonomous decisions: The bias-variance tradeoff in self-driving technology | Mobileye Blog, https://www.mobileye.com/blog/autonomous-decisions-the-bias-variance-tradeoff-in-self-driving-technology/</li>
<li>End-to-end Autonomous Driving using Deep Learning: A Systematic Review - arXiv, https://arxiv.org/pdf/2311.18636</li>
<li>Bridging the Gap Between Modular and End-to-end Autonomous Driving Systems - UC Berkeley EECS, https://www2.eecs.berkeley.edu/Pubs/TechRpts/2022/EECS-2022-79.pdf</li>
<li>OpenDriveLab/UniAD: [CVPR 2023 Best Paper Award] Planning-oriented Autonomous Driving - GitHub, https://github.com/OpenDriveLab/UniAD</li>
<li>[2212.10156] Planning-oriented Autonomous Driving - arXiv, https://arxiv.org/abs/2212.10156</li>
<li>Deep Dive: Tesla, Waymo, and the Great Sensor Debate | Contrary Research, https://research.contrary.com/deep-dive/tesla-waymo-and-the-great-sensor-debate</li>
<li>Waabi AI, https://waabi.ai/</li>
<li>Waabi raises $200M to launch fully driverless trucks in 2025, https://waabi.ai/insights/waabi-series-b-announcement</li>
<li>Waabi and Volvo demonstrate the future of autonomous trucking, https://www.volvoautonomoussolutions.com/en-en/news-and-insights/stories/2025/oct/waabi-and-volvo-demonstrate-the-future-of-autonomous-trucking.html</li>
<li>Chain-of-Thought for Autonomous Driving: A Comprehensive Survey and Future Prospects - arXiv, https://arxiv.org/html/2505.20223v1</li>
<li>End-to-End Autonomous Driving: A Bird’s-Eye View - DRIVE Labs Ep. 35 - YouTube, https://www.youtube.com/watch?v=06BXs-R-fQ8</li>
<li>Pros and cons of end-to-end learning in autonomous driving? : r/SelfDrivingCars - Reddit, https://www.reddit.com/r/SelfDrivingCars/comments/1e3g0kh/pros_and_cons_of_endtoend_learning_in_autonomous/</li>
<li>This article will help you clarify the differences in end-to-end architecture of autonomous driving - EEWORLD, https://en.eeworld.com.cn/news/qcdz/eic695754.html</li>
<li>Compound AI: The framework powering scalable autonomy | Mobileye Blog, https://www.mobileye.com/blog/compound-ai-the-framework-powering-scalable-autonomy/</li>
<li>Efficient Safety Verification of Autonomous Vehicles with Neural Network Operator, https://papers.cool/arxiv/2512.04557</li>
<li>Efficient Safety Verification of Autonomous Vehicles with Neural Network Operator - arXiv, https://arxiv.org/html/2512.04557v1</li>
<li>Verifying Robustness of Neural Networks in Vision-Based End-to-End Autonomous Driving, https://ieeexplore.ieee.org/document/10971936/</li>
<li>Autonomous driving: Modular pipeline Vs. End-to-end and LLMs | by Samer Attrah | Medium, https://medium.com/@samiratra95/autonomous-driving-modular-pipeline-vs-end-to-end-and-llms-642ca7f4ef89</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>