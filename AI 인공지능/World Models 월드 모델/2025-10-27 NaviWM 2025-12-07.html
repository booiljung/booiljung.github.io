<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:내비게이션 세계 모델(Navigation World Models, NWM)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>내비게이션 세계 모델(Navigation World Models, NWM)</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">월드 모델 (World Models)</a> / <span>내비게이션 세계 모델(Navigation World Models, NWM)</span></nav>
                </div>
            </header>
            <article>
                <h1>내비게이션 세계 모델(Navigation World Models, NWM)</h1>
<p>2025-12-07, G30DR</p>
<h3>0.1  서론: 내비게이션 세계 모델(NWM)의 필요성과 정의</h3>
<h4>0.1.1  자율 내비게이션의 패러다임 전환: 반응적 제어에서 예측적 시뮬레이션으로</h4>
<p>로봇 에이전트의 자율 내비게이션 능력은 시각-운동 기술의 기본 요소이다.1 기존의 내비게이션 기술은 경로 계획과 실행 과정에서 여러 한계에 직면한다. 전통적인 SLAM(Simultaneous Localization and Mapping) 기반의 경로 계획 알고리즘은 환경에 대한 완벽한 지식을 가정하고 최적 경로를 계산하는 데 집중하나, 이는 넓은 범위의 임무(국소화, 매핑, 장애물 회피)를 포괄하며 실제 환경 조건에 적응해야 하는 내비게이션의 본질을 모두 담아내지 못한다.3</p>
<p>한편, 모델 프리 강화 학습(Model-Free Reinforcement Learning, DRL)은 환경의 예측 불확실성에도 불구하고 반응적인 정책 업데이트에 전적으로 의존한다.4 이러한 접근법은 학습 과정에서 막대한 양의 가상 훈련, 빈번한 충돌, 그리고 대규모 계산 리소스를 요구하며, 샘플 효율성(Sample Efficiency)이 낮다는 근본적인 문제를 가진다.5 또한, 모델 프리 방법은 장기적인 시행 횟수를 크게 줄이는 데 한계를 보인다.6</p>
<p>모델 기반 강화 학습(MBRL) 프레임워크는 이러한 문제에 대한 해결책으로 부상하였다. MBRL은 환경의 동역학을 명시적으로 학습하여, 에이전트가 환경과의 직접적인 상호작용 없이 내부 시뮬레이션을 통해 행동 정책을 학습하고 계획을 수립하게 한다.6 이는 로봇이 먼저 중력과 같은 환경의 힘을 학습한 후, 이를 사용하여 행동을 결정하는 것과 유사한 방식으로 작동하며, 장기적인 시행 횟수를 현저히 줄이는 이점을 제공한다.6</p>
<h4>0.1.2  NWM의 개념적 정의 및 로보틱스에서의 역할 정립</h4>
<p>Navigation World Model (NWM)은 시각-운동 능력을 가진 에이전트의 기본 기술인 내비게이션을 위해 제안된 모델이다.1 NWM은 과거의 관찰 및 내비게이션 행동을 기반으로 미래의 시각적 관찰을 예측하는 <strong>제어 가능한 비디오 생성 모델</strong>로 정의된다.1 이 모델은 복잡한 환경 동태를 포착하기 위해 10억 개의 매개변수로 확장된 조건부 확산 변환기(Conditional Diffusion Transformer, CDiT)를 사용한다.1</p>
<p>NWM은 고정된 행동 정책을 학습하는 지도 학습 기반 방식과 달리, 다양한 제약 조건을 동적으로 포함하며 내비게이션 경로를 계획할 수 있는 유연한 도구이다.1 NWM은 낯선 환경에서도 단일 입력 이미지를 기반으로 목표 도달 경로를 ’상상’할 수 있는 능력을 갖춘다.1</p>
<p>NWM이 단순한 상태 벡터 예측이 아닌 <em>미래 시각 관찰</em>을 생성하는 모델이라는 점은 계획의 신뢰성을 비약적으로 향상하는 핵심 기술적 선택으로 분석된다. 에이전트가 특정 행동 시퀀스를 계획할 때, NWM은 그 결과로 나타날 미래 환경의 시각적 피드백을 픽셀 공간에서 합성할 수 있다.1 이러한 시각적 생성 능력은 계획된 궤적이 장애물과의 충돌이나 기타 시각적 제약을 위반하는지 여부를 디코딩된 이미지(시각화)를 통해 에이전트 내부적으로 검증하거나 외부적으로 검토하는 것을 가능하게 한다. 따라서 NWM은 모델 기반 계획의 검증 가능성(Verifiability)을 극대화하는 결과를 낳는다.</p>
<h3>0.2  이론적 기반: 모델 기반 강화 학습(MBRL)과 잠재 상태 모델링</h3>
<h4>0.2.1  MBRL 프레임워크 내에서의 세계 모델(World Model)의 기능</h4>
<p>세계 모델은 모델 기반 강화 학습의 핵심 요소로서, 환경의 동역학을 학습하여 환경의 압축된 공간적 및 시간적 표현을 구축하는 생성형 신경망 모델로 기능한다.4 세계 모델은 에이전트의 경험을 기반으로 환경의 동역학을 포착하는 딥 뉴럴 네트워크로, 미래 상태, 보상 및 내비게이션에 필수적인 기타 요소를 예측하도록 훈련된다.8 이 예측 능력은 환경과의 직접적인 상호작용 없이 내부 시뮬레이션을 가능하게 하며, 이를 통해 에이전트는 샘플 효율적인 결정을 내릴 수 있다.8</p>
<p>이러한 예측적 세계 모델의 우위성은 실증적으로 입증된다. DreamerV3 기반 에이전트가 TurtleBot3 LIDAR의 360도 판독 데이터셋을 사용한 내비게이션 태스크에서 100%의 성공률을 달성한 반면, 모델 프리 방법은 85% 미만에서 성능이 정체되었다.4 이 결과는 예측적 세계 모델을 학습된 잠재 표현과 통합하는 것이 고차원 센서 데이터로부터 더욱 효율적이고 견고한 내비게이션을 가능하게 함을 시사한다.4</p>
<h4>0.2.2  잠재 상태 표현 및 VAE의 역할</h4>
<p>NWM은 고차원 시각적 관찰 <span class="math math-inline">x</span>를 효율적인 저차원 잠재 벡터 <span class="math math-inline">z</span>로 압축하기 위해 VAE(Variational Autoencoder)를 핵심 구성 요소로 사용한다.1 VAE는 Vision 모델로서 기능하며, <span class="math math-inline">H \times W \times 3</span> 해상도를 가진 과거 <span class="math math-inline">m</span>개의 시각 관찰을 인코딩한다.1</p>
<p>VAE를 사용하는 이점은 압축된 잠재 공간에서 계산을 수행함으로써 학습 효율성을 높이는 동시에, 예측 결과를 다시 픽셀 공간으로 디코딩하여 시각화할 수 있다는 것이다.4 NWM은 Stable Diffusion에서 사용된 VAE 토크나이저를 채택하여 압축된 잠재 표현의 품질과 대규모 생성 모델과의 기술적 일관성을 확보한다.9</p>
<h4>0.2.3  대안 모델: Recurrent State-Space Model (RSSM) 기반 잠재 역학</h4>
<p>일부 모델 기반 DRL 프레임워크는 Recurrent State-Space Model (RSSM)을 활용하여 환경 동역학을 학습한다.10 RSSM은 시계열 비디오를 압축된 잠재 상태 <span class="math math-inline">s_{1:T}</span>로 설명하며, 이미지가 아닌 잠재 공간에서 자기 회귀적인 예측을 수행하여 장기적인 예측을 지원한다.10</p>
<p>DreamerNav와 같은 RSSM 기반 접근법은 동적 장애물 움직임과 부분 관찰 가능성(POMDP)이 존재하는 복잡한 실내 환경에서 특히 효과적이다.8 DreamerNav는 RSSM을 사용하여 확률적 및 결정론적 잠재 역학을 학습하며, 이를 통해 동적 환경에서 적응적인 실시간 결정을 내릴 수 있는 능력을 확보한다.8</p>
<p>NWM은 명시적인 구조화된 맵을 활용하지 않고도 우수한 내비게이션 성능을 달성하는데, 이는 자기 중심적 관점(egocentric view)에서의 다음 프레임 예측이라는 학습 목표가 에이전트의 내부 모델에 할당 중심적(allocentric) 표현, 즉 맵과 유사한 기하학적 추론 능력을 암시적으로 구축하도록 유도하기 때문이다.12 이 능력은 모델이 단순히 픽셀 변화를 예측하는 것이 아니라, 로봇의 움직임에 따른 3D 환경의 기하학적 변환 규칙을 내재화했다는 것을 의미한다. 이러한 암시적 공간 모델링은 기존의 명시적 맵 설계가 요구하는 엔지니어링 비용을 절감하는 동시에, 뛰어난 일반화 능력을 확보하는 NWM의 핵심 강점이다.13</p>
<h3>0.3  NWM의 핵심 아키텍처: Conditional Diffusion Transformer (CDiT) 기반 동적 예측 모델</h3>
<h4>0.3.1  대규모 데이터 학습 및 모델 확장</h4>
<p>NWM은 복잡한 환경 동태를 포착하기 위해 Conditional Diffusion Transformer (CDiT)를 사용하여 세계 모델 <span class="math math-inline">F</span>를 설계한다.1 이 모델은 로봇 및 인간 에이전트의 에고센트릭 비디오와 내비게이션 행동을 포함하는 다양한 데이터셋을 학습 데이터로 사용하며 1, 10억 개의 매개변수로 확장된 CDiT-XL 규모로 훈련된다.1</p>
<p>NWM은 기존의 다른 모델들과 달리, 태스크 또는 액션 임베딩을 사용하지 않고 다양한 환경 및 구현체에 걸쳐 단일 세계 모델을 훈련하는 것을 목표로 하며 9, 이는 모델 크기와 데이터에 효과적으로 확장하여 다중 환경에 적응할 수 있는 대규모 확산 변환기 모델을 가능하게 한다.14</p>
<h4>0.3.2  CDiT를 이용한 확률적 미래 상태 모델링</h4>
<p>NWM의 모델 훈련 과정에서 CDiT는 비디오 프레임 및 행동을 기반으로 미래 상태를 예측하는 세계 모델 <span class="math math-inline">F</span>로서 기능한다.1 <span class="math math-inline">F</span>는 과거 <span class="math math-inline">m</span>개의 시각 관찰로 인코딩된 잠재 상태 <span class="math math-inline">s_\tau</span>와 현재 행동 <span class="math math-inline">a_\tau</span>에 조건화하여 다음 잠재 상태 <span class="math math-inline">s_{\tau+1}</span>을 예측한다.9 행동은 변환 매개변수 <span class="math math-inline">u \in R^2</span> (전진/후진 및 좌우 이동 제어)와 회전 각도 <span class="math math-inline">\phi \in R</span>로 구성된다.1</p>
<p>CDiT는 노이즈가 추가된 상태 <span class="math math-inline">s_{\tau+1}^{(t)}</span>로부터 원래 상태 표현 <span class="math math-inline">s_{\tau+1}</span>을 복원하려고 시도하는 디노이징 신경망 모델 <span class="math math-inline">F_\theta</span>로 정의된다.12 이 과정은 시간적으로 자가 회귀적인 방법으로 각 행동 조건 하에 미래 상태를 확률적으로 모델링한다.1</p>
<h4>0.3.3  시간 동적 제어 및 인과적 학습</h4>
<p>연구진은 행동 모델링과 시간 동적 제어를 확장하기 위해 입력 행동에 시간 이동 <span class="math math-inline">k</span>를 추가하였다.1 이 시간 이동 <span class="math math-inline">k</span>를 통해 모델은 과거 상태에 기반하여 얼마나 먼 미래를 예측해야 하는지를 유연하게 조정할 수 있다.1</p>
<p>또한, 행동과 시간의 얽힘(entanglement) 문제를 극복하는 전략이 중요하다. 만약 특정 위치에 도달하는 시간이 일정하다면, 모델이 후속 행동을 무시하고 시간에만 의존하여 예측할 위험이 있다.15 이러한 문제를 완화하고 모델이 행동의 인과적 영향을 학습하도록 장려하기 위해, 훈련 중 각 상태에 대해 여러 목표(multiple goals)를 샘플링하는 전략을 사용하여 자연스러운 반사실적 사례를 유도한다.15</p>
<p>NWM의 CDiT 아키텍처는 제어 가능한 비디오 생성 모델로서 Novel View Synthesis (NVS) 방법론과 유사성을 공유한다.7 NWM은 ’내비게이션 행동’을 시점 변화를 위한 조건으로 사용하여, 행동 후의 새로운 시각적 관찰(다음 프레임)을 예측한다. 이 능력은 NWM이 단순히 2D 이미지를 예측하는 것을 넘어, 행동 조건 하에서 발생하는 <strong>3D 환경의 기하학적 변화와 시점 이동을 잠재적으로 모델링</strong>하고 있음을 나타낸다. 이러한 환경 변화에 대한 깊은 이해는 낯선 환경에서의 경로 상상력 및 시뮬레이션 능력을 기술적으로 뒷받침한다.</p>
<h3>0.4  예측 계획 및 최적화 메커니즘: 모델 예측 제어(MPC)</h3>
<h4>0.4.1  MPC 프레임워크의 통합 및 작동 원리</h4>
<p>NWM은 훈련 완료 후 Model Predictive Control (MPC) 프레임워크 내에서 경로 계획에 통합된다.9 MPC는 공정 산업 및 로봇 공학에서 널리 사용되는 다변수 제어 알고리즘으로 16, 내부 예측 모델을 사용하여 예측 범위(Prediction Horizon) 동안의 출력을 예측하고, 비용 함수 <span class="math math-inline">J</span>를 최소화하는 최적의 제어 행동 시퀀스를 찾는다.16 MPC의 주요 장점은 미래 사건을 예측하고 이에 따라 제어 행동을 조정할 수 있는 능력이다.16</p>
<p>NWM은 이 MPC 루프 내에서 내부 예측 모델로서 기능하며, NWM의 계획 설정은 특정 목표 상태에 도달하기 위한 최적의 행동 시퀀스를 탐색한다.9</p>
<h4>0.4.2  에너지 함수 <span class="math math-inline">E</span> 기반 최적화 및 제약 조건 통합</h4>
<p>NWM을 활용한 내비게이션 계획은 특정 목표 상태 <span class="math math-inline">s_T</span>에 도달하는 최적의 행동 시퀀스 <span class="math math-inline">a_{0}, \dots, a_{T-1}</span>를 찾는 문제로 정식화되며, 이는 에너지 함수 <span class="math math-inline">E</span>를 최소화하는 문제로 재구성된다.1</p>
<p>에너지 함수 <span class="math math-inline">E</span>는 예측된 최종 상태와 목표 상태 간의 유사성 스코어를 포함하는 동시에, 행동 및 상태 제약 조건 위반 시 큰 페널티를 부과하는 지표 함수 <span class="math math-inline">I(\cdot)</span>를 통합한다.9 NWM의 장점은 “왼쪽/오른쪽으로 이동 후 전진“과 같은 구체적인 행동 제약 조건을 계획 과정에 유연하게 통합할 수 있다는 것이다.1</p>
<p>NWM의 MPC 기반 계획은 에너지 함수에 제약 조건 페널티를 통합함으로써 자율 시스템의 안전성(Safety)과 규정 준수(Compliance)를 보장한다. MPC는 모델의 비선형성과 하드 제약(Hard Constraints)을 직접 처리할 수 있는 유연성을 제공한다.16 이 특성은 예측된 미래 궤적에서 충돌이나 비정상적인 움직임과 같은 제약 조건 위반이 발생할 경우 즉시 강력한 페널티를 부과하고 대안 경로를 탐색하게 함으로써, 복잡한 환경에서 로봇의 안전 운행을 근본적으로 지원한다.</p>
<h4>0.4.3  계획 및 평가 능력</h4>
<p>NWM은 훈련 완료 후 에너지 함수 <span class="math math-inline">E</span>의 최소화를 통해 목표 지점에 도달하는 데 가장 적합한 행동 시퀀스를 선택하고 평가할 수 있다.1 또한, NWM은 정책 평가(Ranking setup)에서도 활용되어, 기존 내비게이션 정책(예: NoMaD)이 제안한 궤적을 시뮬레이션하고 평가함으로써 최적인 경로를 선별하여 기존 정책의 성능을 향상시키는 데 기여할 수 있다.9</p>
<h3>0.5  첨단 내비게이션 세계 모델: OmniNWM 및 DreamerNav 심층 분석</h3>
<h4>0.5.1  OmniNWM: 전지적 파노라마 모델을 통한 자율 주행 시뮬레이션 혁신</h4>
<p>OmniNWM은 자율 주행 World Models의 핵심 요소인 상태(State), 행동(Action), 보상(Reward) 세 가지 차원의 한계를 극복하기 위해 제안된 전지적(omniscient) 파노라마 내비게이션 세계 모델이다.18</p>
<ol>
<li><strong>포괄적인 다중 모달 상태 생성:</strong> OmniNWM은 Panoramic Diffusion Transformer (PDiT)를 사용하여 RGB, 의미론(semantic), 깊이(metric depth), 그리고 **3D 점유 지도(3D occupancy)**를 포함하는 파노라마 비디오를 픽셀 수준 정렬 방식으로 공동 생성한다.18 또한, 유연한 포싱 전략(Flexible forcing strategy)을 도입하여 지면 진실(Ground-Truth) 시퀀스 길이 이상으로 고품질의 장기 자가 회귀 생성을 달성함으로써 장기 예측의 안정성을 확보한다.18</li>
<li><strong>정밀한 액션 제어: 정규화된 Plücker ray-map:</strong> OmniNWM은 입력 궤적(trajectory)을 픽셀 레벨 신호로 인코딩하는 <strong>정규화된 파노라마 Plücker ray-map 표현</strong>을 도입하였다.18 이는 파노라마 비디오 생성에 대한 매우 정밀하고 일반화 가능한 제어를 제공하며, 궤적이 생성 프로세스를 안내하는 데 사용된다.20</li>
<li><strong>통합된 보상 체계:</strong> 외부 보상 모델을 학습하는 대신, OmniNWM은 <strong>생성된 3D 점유 지도</strong>를 직접 활용하여 운전 준수 및 안전을 위한 규칙 기반의 밀집 보상(dense reward)을 정의한다.18 이 점유 기반 보상은 현실적인 운전 정책 평가를 위한 폐쇄 루프 내비게이션 평가를 가능하게 한다.19</li>
</ol>
<h4>0.5.2  DreamerNav: Recurrent State-Space Model 기반 동적 내비게이션</h4>
<p>DreamerNav는 DreamerV3 기반의 세계 모델을 확장한 프레임워크로, 복잡하고 동적인 실내 환경에서의 강건한 자율 내비게이션을 목표로 한다.8 이 모델은 부분 관찰 가능 마르코프 결정 과정(POMDP)으로 내비게이션을 정식화한다.8</p>
<p>DreamerNav는 에고센트릭 깊이 이미지와, 동적 장애물 위치 및 글로벌 A* 경로를 인코딩하는 구조화된 로컬 점유 맵을 통합하는 하이브리드 공간 인지 능력을 갖는다.8 Recurrent State-Space Model (RSSM)은 잠재 역학을 학습하여 혼잡하고 동적인 장면에서 장기적인 예측과 충돌 없는 경로 계획을 지원한다.8 특히, DreamerNav는 고충실도 시뮬레이션에서 훈련된 후, 재훈련 없이 두 가지 사족보행 로봇(quadrupedal robots)에 성공적으로 배포되어 로봇 플랫폼 독립성과 일반화 능력을 입증하였다.8</p>
<p>최신 NWM 모델들(OmniNWM, DreamerNav)은 단순한 2D 시각 예측을 넘어서, 3D 점유 지도 및 깊이 정보와 같은 다중 모달 공간 정보를 핵심 상태로 통합하고 있다. 이러한 기술적 수렴은 세계 모델이 환경 역학을 <strong>3차원 기하학적 제약</strong> 하에서 이해하도록 강제하는 결과로 나타난다. OmniNWM이 3D 점유 지도를 공동 생성하고 19, DreamerNav가 깊이 이미지와 로컬 점유 맵을 입력으로 통합하는 것은 8, 자율 내비게이션의 궁극적인 목표인 안전하고 충돌 없는 경로 계획을 달성하기 위해, 환경의 물리적 제약 조건을 모델의 잠재 상태에 필수적으로 포함해야 한다는 기술적 인식이 반영된 것이다.</p>
<p>다음 표는 주요 내비게이션 세계 모델 아키텍처의 특징을 비교 분석한 결과이다.</p>
<p>Table V.1. 내비게이션 세계 모델 아키텍처 비교 분석</p>
<table><thead><tr><th><strong>모델</strong></th><th><strong>핵심 동역학 모델</strong></th><th><strong>주요 관찰 입력/출력</strong></th><th><strong>주요 제어/계획 메커니즘</strong></th><th><strong>주요 혁신/특징</strong></th></tr></thead><tbody>
<tr><td>Navigation World Model (NWM)</td><td>Conditional Diffusion Transformer (CDiT) 1</td><td>에고센트릭 RGB 비디오 / 미래 시각 관찰 예측 1</td><td>Model Predictive Control (MPC) 9</td><td>행동 조건부 비디오 생성, 대규모 학습 (10억 개 매개변수) 7</td></tr>
<tr><td>DreamerNav (DreamerV3 확장)</td><td>Recurrent State-Space Model (RSSM) 8</td><td>깊이 이미지, 로컬 점유 지도 / 잠재 상태 및 보상 예측 8</td><td>하이브리드 글로벌-로컬 계획 (A* 결합) 8</td><td>동적 장애물 회피, 로봇 플랫폼 불가지론 8</td></tr>
<tr><td>OmniNWM</td><td>Panoramic Diffusion Transformer (PDiT) 18</td><td>파노라마 RGB, Semantic, Depth / 3D 점유, 미래 궤적 19</td><td>정규화된 Plücker Ray-map 기반 제어 20</td><td>다중 모달 공동 생성, 3D 점유 기반 밀집 보상 통합 18</td></tr>
</tbody></table>
<h3>0.6  기술적 난제, 한계 및 발전 방향</h3>
<h4>0.6.1  데이터셋 일반화 및 계산 제약</h4>
<p>NWM은 다양한 환경과 구현체에 걸쳐 단일 세계 모델을 훈련하는 것을 목표로 하지만 9, 이를 위해서는 대규모의 이종(Heterogeneous) 데이터셋이 필수적으로 요구된다.14 모델 기반 DRL 알고리즘은 모델 프리 접근법에 비해 샘플 효율성은 높으나, 여전히 방대한 학습 데이터에 의존해야 하며, 특히 훈련 과정에서 충돌 위험 및 막대한 계산 리소스 요구에 직면한다.5 또한, 확산 변환기 규모의 대형 모델을 훈련하는 데 필요한 계산 자원은 기술 확산에 있어 중요한 도전 과제이다.</p>
<h4>0.6.2  명시적 공간 표현과의 결합</h4>
<p>암시적 공간 맵을 사용하는 접근법은 메모리 효율성과 미세 목표 도달 정확도 측면에서 장점을 가질 수 있으나 21, 명시적 맵이 제공하는 장거리 계획의 안정성 및 기하학적 일관성 확보가 어려울 수 있다.13</p>
<p>따라서 미래의 NWM은 암시적 역학 학습의 유연성과 명시적 공간 정보의 구조적 견고성을 결합하는 하이브리드 시스템으로 진화할 것이다. DreamerNav가 글로벌 A* 경로를 로컬 점유 맵과 통합하는 것처럼 8, 모델은 유연한 예측 능력과 함께 구조화된 공간 정보를 활용하여 장거리 내비게이션의 일관성을 확보해야 한다.</p>
<h4>0.6.3  장기 예측 안정성 및 MPC 계산 효율성</h4>
<p>자가 회귀적 예측 방식의 본질적인 문제로, 장기 시퀀스에서는 예측 오류가 누적되어 성능이 저하된다. OmniNWM은 유연한 포싱 전략을 통해 장기 자가 회귀 생성의 안정성을 확보함으로써 이 문제를 부분적으로 완화하였다.18</p>
<p>또한, 계획에 사용되는 MPC는 계산 복잡성이 높아진다. 따라서 MPC의 계산 성능을 개선하기 위해서는 샘플 시간, 예측 범위(Prediction Horizon), 제어 범위(Control Horizon)를 신중하게 조정해야 한다.17 이 범위들은 최적화 문제의 변수 수를 결정하여 메모리와 계산량에 직접적인 영향을 미친다.</p>
<p>NWM이 모델 기반 강화 학습(MBRL)의 핵심으로서 갖는 가장 큰 전략적 가치는 **견고성(Robustness)**을 보장하는 능력에 있다. DreamerV3 기반 모델이 고차원 센서 환경에서 모델 프리 방법을 능가하는 성공률을 달성하고 4, DreamerNav가 동적 환경에 대한 뛰어난 적응성을 보이는 것은 8, 예측적 세계 모델이 로봇의 안전하고 신뢰할 수 있는 작동에 필수적임을 입증한다. NWM은 환경 역학을 시뮬레이션함으로써, 예측 불가능한 상황에 대해 사전에 ’대비’할 수 있는 내적 지능을 로봇에게 부여하며, 이는 로봇이 산업 및 일상 생활에서 필수적인 파트너가 되는 미래를 위한 핵심 기반 기술이다.22</p>
<h3>0.7  결론 및 전략적 권고 사항</h3>
<h4>0.7.1  NWM의 혁신성 종합</h4>
<p>Navigation World Model (NWM)은 과거 관찰 및 행동을 기반으로 미래 시각 관찰을 예측하는 제어 가능한 비디오 생성 모델로서, 내비게이션 분야에 혁신을 가져왔다. NWM은 10억 개의 매개변수를 가진 CDiT 아키텍처를 통해 환경 역학을 확률적으로 예측하며, MPC 프레임워크를 사용하여 제약 조건을 준수하는 최적의 행동 시퀀스를 계획한다.1 이러한 접근 방식은 장기적 계획, 고차원 센서 데이터의 처리, 그리고 환경 일반화 능력을 획기적으로 향상시키는 데 성공하였다.</p>
<h4>0.7.2  미래 연구 및 상용화 전략적 권고</h4>
<p>NWM 기술을 기반으로 하는 차세대 자율 내비게이션 시스템 구축을 위해 다음과 같은 전략적 방향을 권고한다.</p>
<ol>
<li><strong>다중 모달 공간 모델 구축:</strong> 자율 내비게이션 시스템 구축 시, 안전성과 현실성 검증 능력을 극대화하기 위해 OmniNWM이나 DreamerNav와 같이 깊이, 의미론, 3D 점유 정보를 통합하는 다중 모달 세계 모델을 채택하는 것을 최우선 과제로 설정해야 한다.18</li>
<li><strong>하이브리드 계획 도입을 통한 견고성 확보:</strong> 장거리 내비게이션의 일관성과 정확성을 보장하기 위해, 잠재 역학 모델(RSSM/CDiT)의 유연한 예측 능력과 글로벌 A* 경로와 같은 명시적 지도 정보의 구조적 견고성을 결합하는 하이브리드 계획 접근법을 도입해야 한다.8</li>
<li><strong>대규모 데이터 및 컴퓨팅 인프라 투자:</strong> NWM의 일반화 능력과 모델 예측의 견고성을 확보하기 위해서는 다양한 구현체와 환경 데이터를 포괄하는 대규모 이종 데이터셋 구축 및 확산 변환기 규모의 모델 학습을 지원할 수 있는 컴퓨팅 인프라에 대한 전략적 투자를 지속해야 한다.</li>
</ol>
<h4>0.7.3  NWM 연구의 최종 지향점</h4>
<p>NWM 연구는 행동을 인식하고 계획할 수 있는 자기 지도 학습 시스템의 문을 열며 12, 로봇이 고도의 자율성, 안전성, 그리고 효율성을 갖추어 산업 전반에 걸쳐 유비쿼터스 파트너로 기능하는 미래를 형성하는 데 결정적인 역할을 수행할 것이다.22 NWM은 모델 기반 계획의 예측적 견고성을 통해 로봇의 신뢰도를 향상시키는 핵심 기술로 자리매김할 것이다.</p>
<h2>1. 참고 자료</h2>
<ol>
<li>[논문 리뷰] Navigation World Models - Moonlight, https://www.themoonlight.io/ko/review/navigation-world-models</li>
<li>12월 7, 2025에 액세스, [https://www.amirbar.net/nwm/#:<sub>:text=Navigation%20is%20a%20fundamental%20skill,past%20observations%20and%20navigation%20actions.](https://www.amirbar.net/nwm/#:</sub>:text=Navigation is a fundamental skill, <a href="https://www.amirbar.net/nwm/#:~:text=Navigation%20is%20a%20fundamental%20skill,past%20observations%20and%20navigation%20actions.">https://www.amirbar.net/nwm/#:~:text=Navigation%20is%20a%20fundamental%20skill,past%20observations%20and%20navigation%20actions.</a></li>
<li>Path planning and navigation | Robotics and Bioinspired Systems Class Notes - Fiveable, https://fiveable.me/robotics-bioinspired-systems/unit-6/path-planning-navigation/study-guide/XcuFEKjTGalDWIXm</li>
<li>World Models for Autonomous Navigation of Terrestrial Robots from LIDAR observations, https://arxiv.org/html/2512.03429v1</li>
<li>Indoor Navigation: A Comparative Study of Traditional and Machine Learning Algorithms - CEUR-WS.org, https://ceur-ws.org/Vol-4044/short03.pdf</li>
<li>누군가 모델 프리와 모델 기반 강화 학습에 대해 좋은 예시를 들어서 설명해 줄 수 있나요? : r/reinforcementlearning - Reddit, https://www.reddit.com/r/reinforcementlearning/comments/xqbtmr/can_anyone_please_explain_modelfree_and/?tl=ko</li>
<li>[2412.03572] Navigation World Models - arXiv, https://arxiv.org/abs/2412.03572</li>
<li>DreamerNav: learning-based autonomous navigation in dynamic indoor environments using world models - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC12510832/</li>
<li>Navigation World Models | CVF Open Access, https://openaccess.thecvf.com/content/CVPR2025/papers/Bar_Navigation_World_Models_CVPR_2025_paper.pdf</li>
<li>A Background B Additional Related Work - NIPS papers, https://papers.nips.cc/paper_files/paper/2021/file/f490d0af974fedf90cb0f1edce8e3dd5-Supplemental.pdf</li>
<li>DreamerNav: learning-based autonomous navigation in dynamic indoor environments using world models - PubMed, https://pubmed.ncbi.nlm.nih.gov/41080712/</li>
<li>Navigation World Models - 프린이씨롯메 - 티스토리, https://hsejun07.tistory.com/m/458</li>
<li>[2308.05602] Object Goal Navigation with Recursive Implicit Maps - arXiv, https://arxiv.org/abs/2308.05602</li>
<li>Navigation World Models - arXiv, https://arxiv.org/html/2412.03572v2</li>
<li>Navigation World Models - arXiv, https://arxiv.org/html/2412.03572v1</li>
<li>Model predictive control - Wikipedia, https://en.wikipedia.org/wiki/Model_predictive_control</li>
<li>What Is Model Predictive Control? - MATLAB &amp; Simulink - MathWorks, https://www.mathworks.com/help/mpc/gs/what-is-mpc.html</li>
<li>[논문 리뷰] OmniNWM: Omniscient Driving Navigation World Models - Moonlight, https://www.themoonlight.io/ko/review/omninwm-omniscient-driving-navigation-world-models</li>
<li>OmniNWM: Omniscient Navigation World Models for Autonomous Driving - GitHub, https://github.com/Ma-Zhuang/OmniNWM</li>
<li>OmniNWM: Omniscient Driving Navigation World Models - arXiv, https://arxiv.org/html/2510.18313v1</li>
<li>LAMP: Implicit Language Map for Robot Navigation | IEEE Journals &amp; Magazine, https://ieeexplore.ieee.org/document/11197901/</li>
<li>로봇 기반 내비게이션 기술: 자율 이동성을 향한 과정 계획 - Reeman 뉴스, https://ko.reemanrobot.com/news/robot-base-navigation-technology-charting-a-c-71591828.html</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>