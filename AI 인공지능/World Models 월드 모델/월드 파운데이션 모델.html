<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:월드 파운데이션 모델</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>월드 파운데이션 모델</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">월드 모델 (World Models)</a> / <span>월드 파운데이션 모델</span></nav>
                </div>
            </header>
            <article>
                <h1>월드 파운데이션 모델</h1>
<h2>1. 월드 파운데이션 모델의 대두</h2>
<p>인공지능(AI) 연구의 지평이 물리적 세계를 이해하고 시뮬레이션하는 능력으로 확장되면서, ’월드 파운데이션 모델(World Foundation Model, WFM)’이라는 새로운 패러다임이 부상하고 있다. 이는 단순히 데이터를 인식하고 분류하는 수준을 넘어, 세상의 동적인 작동 원리를 내재적으로 학습하여 미래를 예측하고 가상으로 경험하는 능력을 AI에 부여하려는 야심 찬 시도이다. 본 안내서는 월드 파운데이션 모델의 개념적 뿌리부터 기술적 기반, 주요 모델 분석, 응용 사례, 그리고 당면한 도전 과제와 윤리적 함의에 이르기까지 포괄적이고 심층적인 고찰을 제공하고자 한다.</p>
<h3>1.1  개념의 융합: 월드 모델과 파운데이션 모델</h3>
<p>월드 파운데이션 모델이라는 용어는 그 자체로 두 가지 강력한 AI 개념의 융합을 시사한다: ’월드 모델’과 ’파운데이션 모델’이다.</p>
<p>첫째, ’월드 모델(World Model)’의 개념은 AI 분야보다 앞서 심리학과 제어 공학에서 수십 년간 논의되어 온 아이디어에 뿌리를 두고 있다.1 이는 지능적 에이전트가 환경의 동역학, 즉 세상이 어떻게 변화하고 특정 행동이 어떤 결과를 낳는지를 내재적으로 학습하고 시뮬레이션하는 내부 모델을 갖춘다는 개념이다.3 이러한 내적 시뮬레이션 능력은 에이전트가 실제 세계에서 위험하거나 비용이 많이 드는 시행착오를 겪기 전에, 다양한 행동 순서를 ‘상상’ 속에서 미리 시도해보고 최적의 계획을 수립할 수 있게 하는 핵심 요소이다.1 AI 분야의 거두인 얀 르쿤(Yann LeCun)은 이러한 월드 모델을 인간과 같은 수준의 지능을 달성하기 위한 필수 불가결한 요소로 간주하며, AI가 관찰을 통해 세상의 작동 방식을 스스로 학습하는 능력의 중요성을 지속적으로 역설해왔다.4</p>
<p>둘째, ’파운데이션 모델(Foundation Model)’은 2021년 스탠포드 인간 중심 AI 연구소(HAI)에 의해 명명된 용어로, 현대 AI 개발의 패러다임을 정의한다.4 파운데이션 모델은 인터넷 규모의 방대한 비정형 데이터(unlabeled data)를 사용하여 대규모로 사전 학습(pre-training)된 후, 특정 목적을 가진 다양한 다운스트림 작업(downstream tasks)에 맞게 미세조정(fine-tuning)될 수 있는 거대 신경망 모델을 지칭한다.4 대규모 언어 모델(LLM)을 필두로 한 파운데이션 모델들은 자연어 처리(NLP)와 컴퓨터 비전 분야에서 놀라운 일반화(generalization) 능력과, 별도의 훈련 없이도 새로운 작업을 수행하는 제로샷(zero-shot) 능력을 입증하며 그 잠재력을 과시했다.7</p>
<p>월드 파운데이션 모델(WFM)은 바로 이 두 개념의 전략적 결합이다. 즉, 파운데이션 모델의 ’대규모 데이터 기반 사전학습 및 미세조정’이라는 강력한 방법론을 ‘월드 모델’ 구축이라는 목표에 적용한 것이다.6 WFM은 물리 세계의 동역학을 시뮬레이션하는 범용 모델(general-purpose model)로서 사전 학습된 후, 로보틱스나 자율주행과 같은 특정 물리 AI 시스템의 고유한 환경과 요구사항에 맞게 맞춤화될 수 있다.9</p>
<h3>1.2  물리적 AI를 위한 패러다임 전환</h3>
<p>WFM의 등장은 특히 ‘물리적 AI(Physical AI)’ 분야에서 근본적인 패러다임 전환을 예고한다. 물리적 AI란 센서를 통해 현실 세계를 관찰하고, 액추에이터를 통해 물리적 세계와 상호작용하며 이를 변화시킬 수 있는 AI 시스템을 의미한다.9 로봇, 자율주행차, 드론 등이 대표적인 예이다.</p>
<p>기존 물리적 AI 개발 방식은 몇 가지 본질적인 한계에 직면해 있었다. 실제 물리적 환경에서 로봇이나 차량을 훈련시키기 위한 데이터를 수집하는 과정은 막대한 비용과 시간을 소모하며, 예측 불가능한 사고의 위험을 항상 내포한다.10 더욱이, 현실에서는 거의 발생하지 않지만 일단 발생하면 치명적인 결과를 초래할 수 있는 ‘롱테일(long-tail)’ 시나리오(예: 도로 위로 갑자기 동물이 뛰어드는 상황)에 대한 충분한 데이터를 확보하는 것은 거의 불가능에 가깝다.12</p>
<p>WFM은 이러한 문제들에 대한 확장 가능하고 효율적인 대안을 제시한다. WFM은 물리 법칙과 현실 세계의 복잡한 상호작용을 학습하여, 사진처럼 사실적인 합성 데이터(photorealistic synthetic data)를 무한에 가깝게 생성할 수 있다.6 이를 통해 개발자들은 안전하고 통제된 가상 환경 내에서 로봇과 자율주행차를 수없이 훈련시키고 테스트할 수 있으며, 이는 학습 과정을 극적으로 가속화하고 실제 필드 테스트의 필요성을 대폭 줄여준다.8 이는 AI의 능력을 기존의 2D 소프트웨어나 디지털 콘텐츠의 영역을 넘어, 유형의(tangible) 현실 세계 경험으로 확장하는 결정적인 열쇠이다.6 엔비디아의 CEO 젠슨 황은 WFM이 로보틱스 분야에서 LLM이 언어 분야에 가져온 것과 같은 ’ChatGPT 순간’을 만들어낼 잠재력이 있다고 평가하며, 물리 AI 기술의 민주화를 촉진할 것이라고 전망했다.3</p>
<p>이러한 변화는 AI 개발 철학의 근본적인 전환을 의미한다. 과거의 AI가 주로 주어진 데이터를 ’인식’하고 분류하는 반응적(reactive) 시스템에 가까웠다면, WFM은 세계의 작동 방식을 내재화하여 미래를 ’예측’하고 ’시뮬레이션’하는 능동적(proactive) 시스템으로의 진화를 상징한다. 이는 AI가 단순한 패턴 인식기를 넘어, 원인과 결과를 추론하고 3 복잡한 계획을 수립하는 1 진정한 ’추론 엔진’으로 발전하는 중요한 이정표이다. ’물리적 AI’라는 용어의 부상은 WFM의 핵심 가치가 디지털 콘텐츠 생성이 아닌, 현실 세계와의 안전하고 유용한 상호작용에 있음을 명확히 하며, 기술의 성공 기준을 ’생성된 결과물의 사실성’에서 ’현실 세계에서의 유용성과 안전성’으로 확장시키고 있다.</p>
<h3>1.3  안내서의 구조와 범위</h3>
<p>본 안내서는 이러한 WFM의 중요성을 인식하고, 그 다층적인 측면을 심도 있게 분석한다. II장에서는 WFM을 구성하는 핵심 기술인 시공간 트랜스포머, 확산 모델, 자기회귀 모델 등의 기술적 기반을 수학적 원리와 함께 상세히 다룬다. III장에서는 엔비디아 Cosmos, 구글 Genie, OpenAI Sora, 메타 V-JEPA 등 현재 WFM 연구를 선도하는 주요 모델들을 심층적으로 비교 분석한다. IV장에서는 로보틱스, 자율주행, 그리고 기후 모델링과 같은 과학적 발견에 이르기까지 WFM의 구체적인 응용 사례를 탐구한다. V장에서는 막대한 계산 비용, 물리적 현실성 확보의 어려움, 그리고 ’진정한 이해’에 대한 근본적인 질문 등 WFM이 직면한 도전 과제와 한계를 비판적으로 검토한다. VI장에서는 딥페이크와 같은 악용 가능성부터 데이터 편향, AI 정렬 문제에 이르기까지 WFM이 제기하는 안전성 및 윤리적 쟁점을 논의한다. 마지막으로 VII장에서는 얀 르쿤의 비전과 AGI 개발에서의 역할을 조망하며 WFM의 미래를 전망하고, 기술적/사회적 제언으로 안내서를 마무리한다.</p>
<h2>2. 월드 파운데이션 모델의 기술적 기반</h2>
<p>월드 파운데이션 모델(WFM)의 구현은 컴퓨터 비전, 생성 모델링, 그리고 대규모 아키텍처 설계의 최신 기술들이 집약된 결과물이다. WFM이 물리 세계의 복잡한 시공간적 동역학을 학습하고 시뮬레이션하기 위해서는 기존 AI 모델의 한계를 뛰어넘는 정교한 기술적 기반이 요구된다. 본 장에서는 WFM의 핵심을 이루는 시공간 트랜스포머 아키텍처, 두 가지 주요 생성 패러다임인 확산 모델과 자기회귀 모델의 원리, 그리고 비디오 데이터를 처리하기 위한 토큰화 기법에 대해 상세히 분석한다.</p>
<h3>2.1  핵심 아키텍처: 시공간 트랜스포머</h3>
<p>파운데이션 모델 시대를 연 일등 공신은 단연 트랜스포머(Transformer) 아키텍처이다. 셀프 어텐션(self-attention) 메커니즘을 기반으로 하는 트랜스포머는 데이터 내의 장거리 의존성(long-range dependency)을 효과적으로 포착하고, 모델과 데이터의 규모를 확장함에 따라 성능이 예측 가능하게 향상되는 뛰어난 확장성(scalability)을 보여주었다. 이러한 특성 덕분에 트랜스포머는 텍스트, 이미지, 음성 등 다양한 데이터 양식(modality)에 걸쳐 파운데이션 모델을 구축하는 사실상의 표준(de facto choice)으로 자리매김했다.4</p>
<p>그러나 트랜스포머를 비디오 데이터에 직접 적용하는 데에는 심각한 도전 과제가 존재한다. 비디오는 이미지에 시간이라는 차원이 추가된 데이터 형태로, 프레임의 수와 해상도가 증가함에 따라 처리해야 할 정보의 양, 즉 토큰의 수가 기하급수적으로 늘어난다. 표준 트랜스포머의 셀프 어텐션은 입력 시퀀스 길이에 대해 이차적인 계산 및 메모리 비용(<span class="math math-inline">O(N^2)</span>)을 요구하기 때문에, 수백만 개의 픽셀로 구성된 긴 비디오 시퀀스를 처리하는 것은 현실적으로 불가능에 가깝다.13</p>
<p>이러한 문제를 해결하기 위해, 비디오의 공간적(spatial) 특성과 시간적(temporal) 특성을 효율적으로 동시에 처리할 수 있는 다양한 ‘시공간 트랜스포머(Spatiotemporal Transformer)’ 아키텍처가 제안되었다.</p>
<ul>
<li><strong>시공간 패치(Spacetime Patches) / 튜브렛(Tubelets):</strong> 이 접근법은 비디오를 작은 3차원(시간 + 높이 + 너비) 조각으로 분할하여 트랜스포머의 입력 토큰으로 사용하는 방식이다. 이미지에서 2D 패치를 사용하는 Vision Transformer(ViT)의 아이디어를 3D로 확장한 것으로, ’튜브렛(tubelet)’이라고도 불린다. 이 기법은 시공간적 지역성(locality)을 활용하여 전체 비디오를 하나의 거대한 시퀀스로 다루는 대신, 관리 가능한 크기의 토큰들로 표현함으로써 계산 효율성을 높인다. OpenAI의 Sora와 Meta의 V-JEPA는 이러한 시공간 패치/튜브렛 방식을 핵심적인 데이터 표현 방식으로 채택하고 있다.14</li>
<li><strong>분할된 시공간 어텐션(Divided Space-Time Attention):</strong> 또 다른 효율화 전략은 어텐션 계산 자체를 분리하는 것이다. 예를 들어, 모델은 먼저 각 비디오 프레임 내에서 픽셀 또는 패치 간의 공간적 관계를 학습하기 위해 공간적 어텐션(spatial attention)을 수행한다. 그 후, 각 프레임에서 집약된 정보를 바탕으로 프레임들 간의 시간적 관계를 학습하기 위해 시간적 어텐션(temporal attention)을 수행한다. 이처럼 어텐션 계산을 두 단계로 분리함으로써, 전체 시공간에 대해 한 번에 어텐션을 계산하는 것에 비해 계산 복잡도를 크게 줄일 수 있다.16</li>
<li><strong>메모리 효율적 아키텍처:</strong> Google의 Genie 모델은 모델 용량과 계산 자원의 제약 사이에서 최적의 균형을 맞추기 위해 특별히 설계된 메모리 효율적인 ST-transformer 아키텍처를 채택했다고 밝히고 있다.13 이는 WFM과 같은 거대 모델 개발에서 성능뿐만 아니라 실용적인 훈련 및 추론 가능성을 확보하는 것이 얼마나 중요한지를 보여준다.</li>
</ul>
<h3>2.2  생성 패러다임 1: 확산 모델</h3>
<p>확산 모델(Diffusion Model)은 최근 몇 년간 이미지 및 비디오 생성 분야에서 가장 뛰어난 성능을 보여준 생성 패러다임으로, OpenAI의 Sora를 비롯한 여러 WFM의 핵심 엔진으로 사용되고 있다.10 확산 모델의 기본 아이디어는 깨끗한 원본 데이터에 점진적으로 노이즈를 추가하여 완전히 무작위적인 노이즈로 만드는 ’순방향 프로세스(forward process)’와, 이 과정을 정확히 역으로 거슬러 올라가 순수한 노이즈로부터 원본 데이터를 점진적으로 복원하는 ’역방향 프로세스(reverse process)’를 학습하는 것이다.</p>
<h4>2.2.1 수학적 원리: DDPM과 잠재 공간 확산</h4>
<p>확산 모델의 수학적 기반은 Denoising Diffusion Probabilistic Models(DDPM) 논문에서 체계적으로 정립되었다.</p>
<ul>
<li>
<p><strong>순방향 프로세스 (Forward Process):</strong> 원본 데이터 <span class="math math-inline">x_0</span>에서 시작하여, 총 <span class="math math-inline">T</span> 단계에 걸쳐 점진적으로 가우시안 노이즈를 추가하는 마르코프 연쇄(Markov Chain)로 정의된다. 각 단계 <span class="math math-inline">t</span>에서 <span class="math math-inline">x_{t-1}</span>로부터 <span class="math math-inline">x_t</span>를 생성하는 과정은 다음과 같은 조건부 확률 분포를 따른다 22:<br />
<span class="math math-display">
q(x_t | x_{t-1}) := \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t \mathbf{I})
</span><br />
여기서 <span class="math math-inline">\beta_t</span>는 <span class="math math-inline">t</span> 시점에서 추가되는 노이즈의 양을 조절하는 하이퍼파라미터로, ’노이즈 스케줄’이라고 불린다. 이 과정의 중요한 속성은, <span class="math math-inline">\alpha_t := 1 - \beta_t</span>와 <span class="math math-inline">\bar{\alpha}_t := \prod_{s=1}^t \alpha_s</span>를 정의하면, 중간 단계 없이 원본 <span class="math math-inline">x_0</span>로부터 임의의 시점 <span class="math math-inline">t</span>의 노이즈가 섞인 데이터 <span class="math math-inline">x_t</span>를 직접 샘플링할 수 있다는 것이다.22<br />
<span class="math math-display">
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) \mathbf{I})
</span><br />
이 식은 <span class="math math-inline">x_t = \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon</span> (단, <span class="math math-inline">\epsilon \sim \mathcal{N}(0, \mathbf{I})</span>) 형태로 표현될 수 있어, 훈련 과정에서 효율적으로 노이즈 낀 샘플을 생성할 수 있게 해준다.</p>
</li>
<li>
<p><strong>역방향 프로세스 (Reverse Process):</strong> 생성 과정은 이 순방향 프로세스를 거꾸로 되돌리는 것이다. 즉, 순수 가우시안 노이즈 <span class="math math-inline">x_T \sim \mathcal{N}(0, \mathbf{I})</span>에서 시작하여, <span class="math math-inline">x_{T-1}, x_{T-2}, \dots, x_0</span>를 순차적으로 샘플링하여 원본 데이터를 복원한다. 이 역방향 전이 확률 <span class="math math-inline">p(x_{t-1} | x_t)</span>를 학습하기 위해 신경망 <span class="math math-inline">p_\theta</span>를 사용한다.22<br />
<span class="math math-display">
p_\theta(x_{t-1} | x_t) := \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
</span><br />
실제로는 분포의 평균 <span class="math math-inline">\mu_\theta</span>와 분산 <span class="math math-inline">\Sigma_\theta</span>를 직접 예측하는 대신, 해당 시점 <span class="math math-inline">t</span>에서 데이터 <span class="math math-inline">x_t</span>에 추가된 노이즈 <span class="math math-inline">\epsilon</span>을 예측하도록 모델 <span class="math math-inline">\epsilon_\theta(x_t, t)</span>를 훈련시키는 것이 더 안정적이고 좋은 성능을 보인다는 것이 발견되었다. 훈련 목표(loss function)는 일반적으로 실제 추가된 노이즈 <span class="math math-inline">\epsilon</span>과 모델이 예측한 노이즈 <span class="math math-inline">\epsilon_\theta</span> 사이의 평균 제곱 오차(Mean Squared Error, MSE)를 최소화하는 것이다.22<br />
<span class="math math-display">
L_{\text{simple}} = \mathbb{E}_{t, x_0, \epsilon} \left[ ||\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon, t)||^2 \right]
</span><br />
<strong>잠재 공간 확산 (Latent Diffusion):</strong> 비디오와 같이 고차원의 데이터를 픽셀 공간에서 직접 다루는 것은 엄청난 계산 비용을 요구한다. 이를 해결하기 위해 ‘잠재 공간 확산’ 기법이 널리 사용된다. 이 방법은 먼저 Variational Autoencoder(VAE)와 같은 인코더-디코더 구조의 네트워크를 사용하여 고차원 비디오를 훨씬 낮은 차원의 잠재 공간(latent space)으로 압축한다. 그 후, 계산 비용이 저렴한 이 잠재 공간 내에서 확산 및 노이즈 제거 과정을 수행한다. 생성이 완료되면, 디코더를 사용하여 최종 잠재 표현을 다시 고해상도 픽셀 공간으로 복원한다. OpenAI의 Sora는 ’비디오 압축 네트워크’를 통해 시공간적으로 압축된 잠재 공간에서 작동함으로써 효율성과 확장성을 동시에 달성했다.14</p>
</li>
</ul>
<h3>2.3  생성 패러다임 2: 자기회귀 모델</h3>
<p>자기회귀(Autoregressive) 모델은 대규모 언어 모델(LLM)의 성공을 이끈 핵심 패러다임으로, WFM 분야에서도 중요한 한 축을 담당하고 있다. Google의 Genie가 이 접근법을 활용한 대표적인 예이다.10 자기회귀 모델의 기본 원리는 데이터를 하나의 긴 시퀀스로 간주하고, 시퀀스의 각 요소를 이전 요소들의 조건부로 순차적으로 예측하여 생성하는 것이다.24</p>
<h4>2.3.1 수학적 원리: 조건부 확률과 순차적 생성</h4>
<p>자기회귀 모델은 확률의 연쇄 법칙(chain rule of probability)에 수학적 기반을 둔다. 데이터 <span class="math math-inline">x</span>가 <span class="math math-inline">N</span>개의 요소(예: 비디오의 토큰 또는 픽셀) <span class="math math-inline">x_1, \dots, x_N</span>으로 구성된 시퀀스라고 할 때, 이 데이터의 결합 확률 분포 <span class="math math-inline">p(x)</span>는 다음과 같이 조건부 확률의 곱으로 분해될 수 있다.26<br />
<span class="math math-display">
p(x) = p(x_1, \dots, x_N) = \prod_{i=1}^{N} p(x_i | x_1, \dots, x_{i-1})
</span><br />
자기회귀 모델의 목표는 이 조건부 확률 분포 <span class="math math-inline">p(x_i | x_{&lt;i}; \theta)</span>를 파라미터 <span class="math math-inline">\theta</span>를 가진 신경망(주로 트랜스포머)으로 모델링하고, 주어진 데이터셋에 대해 이 확률을 최대화하도록(Maximum Likelihood Estimation) 학습하는 것이다.</p>
<p>생성 시에는 먼저 첫 번째 요소 <span class="math math-inline">x_1</span>을 샘플링하고, 이를 조건으로 두 번째 요소 <span class="math math-inline">x_2</span>를 샘플링하며, 다시 <span class="math math-inline">x_1, x_2</span>를 조건으로 <span class="math math-inline">x_3</span>를 샘플링하는 과정을 시퀀스의 끝까지 반복한다.</p>
<ul>
<li><strong>장점:</strong> 이러한 순차적(causal) 생성 방식은 본질적으로 스트리밍이나 상호작용이 필요한 시나리오에 매우 적합하다. 예를 들어, 사용자의 행동 입력을 매 프레임 생성 시 조건으로 추가하여 동적으로 제어되는 비디오를 만들 수 있다. 이는 Google Genie가 레이블 없는 게임 플레이 영상만으로 ‘조작 가능한’ 세계를 학습할 수 있었던 핵심 원리이다.28</li>
<li><strong>단점:</strong> 한 번에 하나의 요소만 생성할 수 있기 때문에, 특히 고해상도 비디오와 같이 시퀀스 길이가 매우 긴 경우 추론(생성) 속도가 매우 느릴 수 있다는 단점이 있다.27</li>
</ul>
<p>이 두 생성 패러다임의 선택은 단순히 기술적 선호의 문제가 아니라, 모델이 추구하는 철학과 목표를 반영하는 전략적 결정이다. 확산 모델은 전체 시퀀스를 양방향으로 고려하며 전역적 일관성과 높은 시각적 충실도를 추구하므로, ’세계를 있는 그대로 시뮬레이션’하는 고품질의 ’영화’를 만드는 데 적합하다. 반면, 자기회귀 모델은 순차적 생성을 통해 외부 입력을 쉽게 통합할 수 있으므로, ’상호작용 가능한 세계’인 ’비디오 게임’을 만드는 데 더 유리하다. 이 두 패러다임의 경쟁과 융합이 WFM의 미래를 형성할 것이다.</p>
<h3>2.4  데이터 처리 및 표현: 비디오 토큰화</h3>
<p>WFM이 트랜스포머 아키텍처를 효과적으로 활용하기 위해서는, 연속적인 시공간 데이터인 비디오를 트랜스포머가 처리할 수 있는 형태, 즉 토큰(token)의 시퀀스로 변환하는 과정이 필수적이다. 이 ‘비디오 토큰화’ 과정은 WFM의 성능과 효율을 결정하는 매우 중요한 단계이다.9</p>
<ul>
<li><strong>토큰화 방식:</strong> WFM 연구에서는 크게 두 가지 방식의 토큰화가 탐구되고 있다.</li>
<li><strong>이산 토큰화 (Discrete Tokenization):</strong> 이 방식은 VQ-VAE(Vector Quantized Variational Autoencoder)와 같은 모델을 사용하여 비디오 패치를 이산적인 정수(integer)들의 시퀀스로 변환한다. 각 정수는 학습된 ’코드북(codebook)’에 있는 특정 시각적 패턴에 해당한다. 이는 언어 모델이 단어를 이산적인 토큰으로 처리하는 것과 유사하며, 자기회귀 모델과 잘 결합된다. NVIDIA Cosmos의 자기회귀 모델은 이 방식을 사용한다.6</li>
<li><strong>연속 토큰화 (Continuous Tokenization):</strong> 이 방식은 비디오 패치를 고정된 차원의 연속적인 벡터(vector) 시퀀스로 직접 변환한다. 각 벡터는 해당 패치의 풍부한 시각적 정보를 담고 있는 임베딩으로 볼 수 있다. 확산 모델은 본질적으로 연속적인 공간에서 작동하므로 이 방식과 자연스럽게 어우러진다. NVIDIA Cosmos의 확산 모델이 이 접근법을 채택했다.6</li>
<li><strong>데이터 큐레이션 (Data Curation):</strong> “데이터가 모델의 성능 상한선을 결정한다“는 말처럼 9, 고품질 WFM을 구축하기 위해서는 방대하고 다양한 비디오 데이터셋을 신중하게 선별하고 가공하는 ‘데이터 큐레이션’ 과정이 매우 중요하다. 이 과정에는 다음과 같은 단계들이 포함된다 6:</li>
<li><strong>필터링(Filtering):</strong> 저화질, 정적인 장면 등 학습에 방해가 되는 데이터를 제거하고, 물리적 동역학이 풍부하게 나타나는 고품질 비디오 클립을 선별한다.</li>
<li><strong>주석 달기(Annotation):</strong> Vision-Language Model(VLM) 등을 사용하여 비디오 클립의 핵심 객체나 행동에 대한 텍스트 설명을 자동으로 생성한다.</li>
<li><strong>분류(Classification):</strong> 특정 훈련 목표에 맞게 데이터를 분류한다.</li>
<li><strong>중복 제거(Deduplication):</strong> 비디오 임베딩 기술을 사용하여 의미적으로 유사하거나 중복되는 데이터를 제거함으로써 훈련 효율성을 높인다.</li>
</ul>
<p>결국 WFM의 발전은 단순히 더 큰 트랜스포머 모델을 만드는 것을 넘어, 비디오의 본질적인 시공간 정보를 손실 없이, 그러면서도 효율적으로 압축하는 더 정교한 토크나이저(tokenizer)를 개발하는 경쟁에 크게 의존할 것이다. LLM의 성공이 효과적인 텍스트 토큰화에서 비롯되었듯 15, WFM의 미래 혁신 역시 이 ’입력단’의 혁신에서 나올 가능성이 매우 크다.</p>
<h2>3. 주요 월드 파운데이션 모델 심층 분석</h2>
<p>월드 파운데이션 모델(WFM) 분야는 소수의 선도적인 기술 기업들이 각기 다른 철학과 기술적 접근법을 바탕으로 치열하게 경쟁하며 발전하고 있다. 본 장에서는 현재 WFM 연구를 이끌고 있는 대표적인 네 가지 모델-NVIDIA의 Cosmos, Google의 Genie, OpenAI의 Sora, 그리고 Meta의 V-JEPA-을 심층적으로 분석하고 비교한다. 각 모델의 목표, 핵심 기술, 그리고 명시된 한계를 살펴봄으로써 WFM 분야의 다양한 지형도를 입체적으로 조망한다.</p>
<h3>3.1  NVIDIA Cosmos: 물리적 AI 개발을 위한 개방형 플랫폼</h3>
<p>NVIDIA의 Cosmos는 특정 모델 하나를 지칭하기보다는, 물리적 AI 개발자들이 각자의 응용 분야에 최적화된 맞춤형 월드 모델을 효율적으로 구축할 수 있도록 지원하는 개방형 플랫폼이자 모델 제품군(suite)이다.9 이는 GPU 하드웨어 생태계를 기반으로 AI 개발 도구와 플랫폼을 제공하려는 NVIDIA의 광범위한 전략과 맥을 같이 한다.</p>
<ul>
<li><strong>목표:</strong> Cosmos의 핵심 목표는 물리적 AI 개발의 민주화이다. 범용적으로 사전 학습된 WFM을 ’기초 모델’로 제공하고, 개발자들은 여기에 자신들의 특정 도메인 데이터를 소량 추가하여 미세조정(post-training 또는 fine-tuning)함으로써 고성능의 맞춤형 월드 모델을 신속하게 만들 수 있다.6 예를 들어, 로보틱스 회사는 자신들의 로봇이 수집한 ‘행동-비디오’ 쌍 데이터를 사용하여 Cosmos 모델을 미세조정함으로써, 해당 로봇의 움직임과 환경 상호작용을 정밀하게 시뮬레이션하는 모델을 얻을 수 있다.</li>
<li><strong>기술적 특징:</strong> Cosmos 플랫폼은 개발자에게 유연성을 제공하기 위해 두 가지 주요 생성 패러다임을 모두 지원한다. 하나는 고품질 비디오 생성을 위한 <strong>확산 모델</strong>이며, 다른 하나는 상호작용 및 제어에 유리한 <strong>자기회귀 트랜스포머 모델</strong>이다.9 또한, NVIDIA는 고품질 모델 학습의 기반이 되는 데이터의 중요성을 강조하며, 자체적으로 개발한 정교한 데이터 큐레이션 파이프라인을 통해 2천만 시간 분량의 방대한 인터넷 비디오 컬렉션에서 물리적 동역학이 풍부한 약 1억 개의 고품질 비디오 클립을 추출하여 사전 학습에 사용했다고 밝혔다.9</li>
<li><strong>활용 사례:</strong> Cosmos의 플랫폼 접근법은 이미 산업계에서 가시적인 성과를 내고 있다. 자율주행 기술 스타트업인 Wayve, 중국의 전기차 제조업체 XPENG, 그리고 자율주행 트럭을 개발하는 Waabi와 같은 기업들은 Cosmos를 활용하여 다양한 교통 시나리오, 악천후 조건, 예측 불가능한 보행자 행동 등을 가상 환경에서 시뮬레이션하고 있다. 이를 통해 실제 도로 주행 테스트의 위험과 비용을 줄이면서 자율주행 시스템의 안전성과 신뢰성을 검증하고 있다.10</li>
</ul>
<h3>3.2  Google Genie: 상호작용 가능한 생성형 환경</h3>
<p>Google DeepMind가 개발한 Genie는 WFM의 또 다른 가능성, 즉 ’상호작용 가능한 세계의 창조’에 초점을 맞춘 모델이다.29 Genie는 단순히 비디오를 생성하는 것을 넘어, 사용자가 직접 조작하고 탐험할 수 있는 ‘플레이 가능한(playable)’ 가상 환경을 만들어낸다는 점에서 혁신적이다.</p>
<ul>
<li><strong>목표:</strong> Genie의 목표는 단 한 장의 이미지, 간단한 스케치, 혹은 텍스트 프롬프트로부터 무한한 종류의 동적인 가상 세계를 생성하는 것이다.13 이는 창작자들이 자신의 상상력을 즉시 살아 움직이는 세계로 구현할 수 있게 하고, AI 에이전트가 끝없이 새로운 환경에서 훈련할 수 있는 기반을 제공한다.</li>
<li><strong>기술적 특징:</strong> 110억 개의 파라미터를 가진 자기회귀 모델을 기반으로 하는 Genie의 가장 큰 기술적 혁신은 **‘잠재 행동 모델(Latent Action Model)’**에 있다.13 기존의 로봇 학습이나 강화학습은 ’어떤 행동(action)을 취했는지’에 대한 명시적인 레이블이 있는 데이터를 필요로 했다. 하지만 Genie는 이러한 행동 레이블이 전혀 없는, 인터넷에서 수집한 방대한 양의 비디오(주로 2D 플랫폼 게임 플레이 영상)만을 사용하여 학습한다. Genie는 비디오의 연속된 프레임들 사이의 미세한 변화를 스스로 분석하여, ‘점프’, ‘왼쪽으로 이동’ 등과 같이 일관성 있는 행동에 해당하는 잠재적인 행동 공간(latent action space)을 자율적으로 추론해낸다.20 이 덕분에 사용자는 이 잠재 행동을 입력하여 생성된 세계 속 캐릭터를 조작할 수 있게 된다. 이 과정은 시공간 비디오 토크나이저, 자기회귀 동역학 모델, 그리고 효율적인 ST-transformer 아키텍처의 조합을 통해 이루어진다.13</li>
<li><strong>한계:</strong> Genie는 획기적인 개념을 제시했지만, 아직 초기 단계의 기술적 한계를 가지고 있다. 자기회귀 모델의 고질적인 문제인, 비현실적인 미래를 상상해내는 ‘환각(hallucination)’ 현상이 나타날 수 있다. 또한 현재 버전은 초당 1프레임(1 FPS) 정도의 느린 속도로 작동하며, 한 번에 16프레임의 제한된 시퀀스만을 기억할 수 있어 장기적인 일관성을 유지하는 데 어려움이 있다.13</li>
</ul>
<h3>3.3  OpenAI Sora: 고충실도 물리 세계 시뮬레이터</h3>
<p>OpenAI의 Sora는 공개와 동시에 전 세계에 충격을 안겨준 모델로, 텍스트 설명만으로 놀라울 정도로 사실적이고 일관성 있는 비디오를 생성하는 능력을 보여주었다. Sora의 목표는 단순히 보기 좋은 비디오를 만드는 것을 넘어, 물리 세계의 법칙과 객체 간의 상호작용을 이해하고 시뮬레이션하는 범용 시뮬레이터를 구축하는 것이다.15</p>
<ul>
<li><strong>목표:</strong> Sora는 사용자가 텍스트 프롬프트로 요청한 내용뿐만 아니라, 그 내용 속의 사물들이 물리 세계에 ’어떻게 존재하는지’를 이해하고 이를 비디오로 구현하는 것을 목표로 한다.31 이를 통해 최대 1분 길이에 달하는 고충실도(high-fidelity) 비디오를 생성하며, 물리적 AI 개발을 위한 강력한 시뮬레이션 환경을 제공하고자 한다.</li>
<li><strong>기술적 특징:</strong> Sora는 <strong>확산 트랜스포머(Diffusion Transformer, DiT)</strong> 아키텍처를 기반으로 한다.14 Sora의 핵심적인 기술 혁신은 **‘시공간 잠재 패치(Spacetime Latent Patches)’**라는 데이터 처리 방식에 있다. Sora는 먼저 비디오를 효율적인 잠재 공간으로 압축한 뒤, 이 잠재 공간을 다시 시공간적 ‘패치’ 단위로 분할하여 트랜스포머의 토큰으로 사용한다. 이 방식의 가장 큰 장점은 모델이 다양한 해상도, 길이, 그리고 종횡비를 가진 비디오와 이미지를 구분 없이 동일한 방식으로 처리할 수 있게 해준다는 것이다.15 이는 기존 모델들이 훈련 데이터를 고정된 크기로 잘라내거나 변환해야 했던 한계를 극복하고, 데이터의 원본 특성을 최대한 보존하며 학습할 수 있게 하여 생성된 비디오의 품질과 구도를 향상시켰다. Sora는 이러한 학습을 통해, 화가가 캔버스에 붓질을 남기면 그 흔적이 다음 프레임에서도 유지되거나, 사람이 햄버거를 먹으면 베어 문 자국이 남는 등 간단한 인과관계를 시뮬레이션하는 능력을 보여주었다.6</li>
<li><strong>한계:</strong> 놀라운 성능에도 불구하고 Sora 역시 명확한 한계를 보인다. 기술 안내서에 따르면, Sora는 유리가 깨지거나 여러 물체가 복잡하게 상호작용하는 것과 같은 정밀한 물리 현상을 정확하게 모델링하지 못한다. 또한, 생성되는 비디오의 길이가 길어질수록 장면의 논리적 일관성이 무너지거나, 없던 객체가 갑자기 나타나는 등의 오류가 발생하기도 한다.15</li>
</ul>
<h3>3.4  Meta V-JEPA: 추상적 표현 예측을 통한 동역학 학습</h3>
<p>Meta AI의 V-JEPA(Video Joint-Embedding Predictive Architecture)는 앞선 세 모델과는 근본적으로 다른 철학적 접근을 취한다. 이는 얀 르쿤의 오랜 비전이 구체화된 결과물로, ’생성’이 아닌 ’예측’을 통해 세계를 이해하려는 시도이다.17</p>
<ul>
<li>
<p><strong>목표:</strong> V-JEPA의 목표는 미래의 비디오 프레임을 픽셀 단위로 ’생성’하는 것이 아니라, 미래 프레임의 ’추상적인 표현(abstract representation)’을 ’예측’하는 것이다. 얀 르쿤은 인간이나 동물이 세상을 학습하는 방식이 모든 세부사항을 기억하고 재현하는 것이 아니라, 세상의 본질적인 구조와 동역학, 즉 물리 법칙과 같은 핵심 원리를 파악하는 것이라고 주장한다. V-JEPA는 불필요하고 예측 불가능한 세부사항(예: 나뭇잎의 무작위적인 흔들림)을 무시하고, 예측 가능한 핵심 정보를 담은 고차원적 표현을 학습함으로써 더 효율적이고 강건한 월드 모델을 구축하고자 한다.17</p>
</li>
<li>
<p><strong>기술적 특징:</strong> V-JEPA는 **결합 임베딩 예측 아키텍처(JEPA)**에 기반한다. 훈련 과정에서 모델에게 비디오의 일부(context)를 보여주고, 의도적으로 가려놓은 다른 부분(target)의 ’표현’을 예측하도록 요구한다. 여기서 중요한 점은 픽셀 자체를 예측하는 것이 아니라, 타겟 인코더가 추출한 고차원의 특징 벡터를 예측한다는 것이다. 이 방식은 픽셀을 직접 생성하는 확산 모델이나 자기회귀 모델에 비해 계산적으로 훨씬 효율적이며, 생성 과정의 무작위성에 내재된 문제들을 회피할 수 있다.17</p>
</li>
</ul>
<p>특히 V-JEPA 2-AC(Action-Conditioned) 버전은 두 단계 학습을 거친다. 1단계에서는 방대한 양의 일반 비디오를 통해 세상의 보편적인 물리 법칙을 학습한다. 2단계에서는 이렇게 사전 학습된 모델의 일부를 고정한 채, 소량의 로봇 데이터(행동과 그 결과 비디오)를 사용하여 ’특정 행동이 어떤 결과를 낳는지’라는 인과관계를 학습한다. 이 학습된 월드 모델을 바탕으로, 로봇은 모델 예측 제어(Model-Predictive Control, MPC) 방식을 통해 여러 행동 시퀀스를 내부적으로 시뮬레이션해보고 최적의 행동 계획을 수립할 수 있다. 이는 별도의 작업별 훈련 없이도 새로운 조작 작업을 수행하는 강력한 제로샷 계획 능력을 가능하게 한다.17</p>
<p>이처럼 WFM 분야는 단일한 경로가 아닌, 서로 다른 철학과 강점을 가진 여러 접근법들이 경쟁하고 있다. NVIDIA Cosmos는 개발자 생태계를 지원하는 ‘플랫폼’ 전략을, OpenAI Sora와 Google Genie는 그 자체로 강력한 성능을 보여주는 ‘제품’ 전략을 취하고 있다. 한편, Meta의 V-JEPA는 주류 생성 모델들과는 궤를 달리하는 ’추상적 예측’이라는 근본적인 ’반론(counter-argument)’을 제시하며 독자적인 노선을 구축하고 있다. ’생성을 통한 이해’와 ’추상화를 통한 이해’라는 두 거대한 철학적 흐름의 경쟁과 융합이 앞으로의 AI 기술 지형도를 결정하게 될 것이다.</p>
<h3>3.5 Table 1: 주요 월드 파운데이션 모델 비교 분석</h3>
<table><thead><tr><th>구분 (Category)</th><th>NVIDIA Cosmos</th><th>Google Genie</th><th>OpenAI Sora</th><th>Meta V-JEPA</th></tr></thead><tbody>
<tr><td><strong>핵심 철학 (Core Philosophy)</strong></td><td>물리 AI 개발을 위한 범용 플랫폼 및 도구 제공 (Platform &amp; Tools for Physical AI)</td><td>이미지로부터 상호작용 가능한 세계 생성 (Generative Interactive Worlds from Images)</td><td>고충실도 시각적 시뮬레이션을 통한 세계 이해 (World Understanding via High-Fidelity Simulation)</td><td>추상적 예측을 통한 세계의 근본 원리 학습 (Learning World Principles via Abstract Prediction)</td></tr>
<tr><td><strong>주요 아키텍처 (Key Architecture)</strong></td><td>확산 &amp; 자기회귀 트랜스포머 (Diffusion &amp; Autoregressive Transformers)</td><td>자기회귀 ST-Transformer (Autoregressive ST-Transformer)</td><td>확산 트랜스포머 (Diffusion Transformer, DiT)</td><td>결합 임베딩 예측 아키텍처 (JEPA) on ViT</td></tr>
<tr><td><strong>핵심 기술 (Key Technology)</strong></td><td>사전학습-미세조정 패러다임 (Pre-train &amp; Fine-tune Paradigm)</td><td>잠재 행동 모델 (Latent Action Model)</td><td>시공간 잠재 패치 (Spacetime Latent Patches)</td><td>표현 공간에서의 마스크된 예측 (Masked Prediction in Representation Space)</td></tr>
<tr><td><strong>주요 학습 데이터 (Primary Training Data)</strong></td><td>다양한 인터넷 비디오 (Diverse Internet Videos)</td><td>2D 플랫폼 게임 비디오 (2D Platformer Game Videos)</td><td>다양한 해상도/길이의 비디오 및 이미지 (Mix of Videos/Images of varied resolutions/durations)</td><td>대규모 인터넷 비디오 + 로봇 데이터 (Large-scale Internet Videos + Robot Data)</td></tr>
<tr><td><strong>주요 목표 (Primary Goal)</strong></td><td>로보틱스/자율주행용 맞춤형 모델 개발 지원 (Support custom model dev for robotics/AV)</td><td>새로운 창작 및 에이전트 훈련 방식 제공 (Enable new creation &amp; agent training)</td><td>범용 물리 세계 시뮬레이터 구축 (Build a general-purpose physical world simulator)</td><td>효율적인 제로샷 로봇 계획 (Enable efficient, zero-shot robot planning)</td></tr>
</tbody></table>
<h2>4. 응용 분야 및 사례 연구</h2>
<p>월드 파운데이션 모델(WFM)의 능력, 즉 물리 세계의 동역학을 학습하고 시뮬레이션하는 능력은 이론적 탐구를 넘어 다양한 산업 분야에서 실질적인 가치를 창출하기 시작했다. 특히 로보틱스와 자율주행과 같이 현실 세계와의 상호작용이 필수적인 분야에서 WFM은 기존의 개발 패러다임을 혁신하고 있다. 더 나아가, 그 응용 범위는 기후 변화 예측이나 신약 개발과 같은 복잡계 과학 분야로까지 확장될 잠재력을 보이고 있다.</p>
<h3>4.1  로보틱스: 시뮬레이션 기반 학습과 일반화</h3>
<p>로봇이 인간과 같은 유연성과 적응력을 갖추기 위해서는 주변 환경에 대한 깊은 이해, 즉 ’공간 지능(spatial intelligence)’이 필수적이다. WFM은 로봇이 이러한 지능을 안전하고 효율적으로 습득할 수 있는 이상적인 훈련장을 제공한다.6</p>
<ul>
<li><strong>시뮬레이션 기반 학습:</strong> 과거에는 로봇을 훈련시키기 위해 실제 로봇을 물리적 환경에서 수없이 반복적으로 움직여야 했다. 이는 시간이 많이 걸리고, 로봇이나 주변 환경에 손상을 입힐 위험이 있으며, 다양한 시나리오를 구현하는 데 한계가 있었다. WFM은 사진처럼 사실적인 3D 가상 환경을 생성하여, 로봇이 이 디지털 트윈(digital twin) 세계 안에서 수많은 작업을 안전하게 연습할 수 있게 한다. 로봇은 가상 시뮬레이션 내에서 물체를 집고, 옮기고, 조립하는 등의 과제를 수없이 반복하며 시행착오를 통해 학습 속도를 극적으로 높일 수 있다.6</li>
<li><strong>일반화와 Sim-to-Real:</strong> WFM의 진정한 가치는 시뮬레이션에서 학습한 능력이 현실 세계에서도 통용될 때 발현된다. 이를 ‘Sim-to-Real’ 이전(transfer)이라고 한다. WFM은 다양한 조명, 재질, 배경을 가진 수많은 가상 환경을 생성함으로써 로봇이 특정 환경에 과적합(overfitting)되는 것을 방지하고, 처음 보는 실제 환경에서도 학습된 기술을 성공적으로 수행할 수 있는 일반화 능력을 길러준다.10</li>
<li><strong>사례 연구:</strong></li>
<li><strong>NVIDIA Cosmos:</strong> 이 플랫폼은 로봇 개발자들이 자신들의 특정 작업 환경(예: 공장 조립 라인, 물류 창고)을 닮은 맞춤형 시뮬레이션 환경을 구축하고, 그 안에서 로봇의 인식 및 제어 알고리즘을 훈련시킬 수 있도록 지원한다.10</li>
<li><strong>Meta V-JEPA 2-AC:</strong> 이 모델은 Sim-to-Real의 뛰어난 성공 사례를 보여준다. V-JEPA는 대규모 인터넷 비디오를 통해 세상의 보편적인 물리 법칙을 학습한 후, 실제 로봇 팔이 움직이는 비디오 데이터(Droid 데이터셋)를 소량만 보고도 ‘행동과 결과’ 사이의 인과관계를 학습했다. 그 결과, V-JEPA 2-AC는 특정 작업에 대한 사전 훈련 없이도, 목표 이미지만 주어지면 내부 시뮬레이션을 통해 최적의 행동 순서를 계획하여 복잡한 물체 조작 작업을 성공적으로 수행하는 제로샷(zero-shot) 능력을 입증했다.17</li>
</ul>
<h3>4.2  자율주행: 복잡한 시나리오 생성 및 정책 검증</h3>
<p>자율주행차(AV)의 상용화를 가로막는 가장 큰 장벽은 무한에 가까운 실제 도로 상황, 특히 예측하기 어렵고 드물게 발생하는 위험 상황에 대한 안전성을 입증하는 것이다. WFM은 이러한 ’롱테일 문제(long-tail problem)’를 해결하고 AV 시스템의 신뢰성을 확보하는 데 결정적인 역할을 한다.</p>
<ul>
<li><strong>복잡한 시나리오 생성:</strong> WFM은 실제 도로에서 데이터를 수집하기 매우 어렵거나 위험한 시나리오들을 가상으로 대량 생성할 수 있다. 예를 들어, 고속도로에서 갑자기 타이어가 터지는 상황, 폭우나 폭설 속에서 차선이 보이지 않는 상황, 아이가 갑자기 도로로 뛰어드는 상황 등을 수만, 수십만 번 시뮬레이션할 수 있다.6 이를 통해 AV 시스템은 이러한 극한 상황(corner cases)에 대처하는 능력을 반복적으로 훈련하고 검증받을 수 있다.12</li>
<li><strong>정책 검증 및 지역화:</strong> 개발된 자율주행 알고리즘, 즉 ’정책(policy)’이 다양한 조건에서 어떻게 작동하는지 WFM 기반 시뮬레이션으로 사전에 철저히 검증할 수 있다. 또한, WFM은 특정 국가나 도시의 고유한 교통 법규, 운전자들의 운전 습관, 보행자들의 행동 패턴까지도 시뮬레이션에 반영할 수 있다. 이는 AV 시스템이 특정 지역에 맞게 현지화(localization)되는 것을 돕고, 글로벌 시장에 진출할 때 각기 다른 환경에 대한 적응력을 높여준다.10</li>
<li><strong>사례 연구:</strong></li>
<li><strong>Wayve, XPENG, Waabi, Foretellix:</strong> 영국의 Wayve, 중국의 XPENG 등 전 세계의 많은 자율주행 기술 기업들은 NVIDIA Cosmos 플랫폼을 적극적으로 활용하고 있다. 이들은 WFM을 통해 복잡한 교통 흐름, 다양한 날씨와 조명 조건, 수많은 보행자 및 차량의 상호작용을 시뮬레이션함으로써, 막대한 비용과 시간이 드는 실제 도로 주행 테스트를 최소화하고 개발 주기를 단축하고 있다.10 WFM은 이처럼 인간 운전자의 경험적 직관과 AI의 정밀한 계산 능력 사이의 간극을 메우며, 더 안전하고 신뢰할 수 있는 자율주행 시스템을 만드는 데 기여하고 있다.35</li>
</ul>
<h3>4.3  과학적 발견의 새로운 지평: 기후 모델링 및 신약 개발</h3>
<p>WFM의 핵심 능력인 ’복잡한 동역학 시스템을 데이터로부터 학습하고 시뮬레이션하는 힘’은 물리적 AI의 영역을 넘어 과학적 발견의 방법론 자체를 혁신할 잠재력을 지니고 있다.</p>
<ul>
<li>
<p><strong>기후 시뮬레이션:</strong> 기후 변화는 수많은 변수가 비선형적으로 상호작용하는 지구상에서 가장 복잡한 시스템 중 하나이다. 전통적인 수치 기반 기후 모델은 막대한 슈퍼컴퓨팅 자원을 요구하면서도, 국지적인 폭풍이나 구름 생성과 같은 미세 규모 현상을 완벽하게 포착하는 데 어려움을 겪는다.36 WFM 기반 접근법은 이러한 한계를 극복할 새로운 가능성을 제시한다.</p>
</li>
<li>
<p><strong>사례 연구 (NVIDIA Earth-2 &amp; cBottle):</strong> NVIDIA의 Earth-2 플랫폼은 지구 전체를 대상으로 하는 디지털 트윈을 구축하는 것을 목표로 한다. 이 플랫폼의 핵심인 <strong>cBottle</strong> 모델은 생성형 AI 기반의 WFM으로, 방대한 양의 고해상도 기후 시뮬레이션 데이터를 학습하여 그 동역학을 내재화한다.37 cBottle은 페타바이트(PB) 규모의 데이터를 수천 배 이상 압축할 수 있으며, 전통적인 수치 모델보다 수천 배 빠르고 에너지 효율적으로 미래 기후 상태를 생성 및 예측할 수 있다. 이는 기후 과학자들이 더 빠르고 정밀하게 기후 변화의 영향을 분석하고 대응 전략을 수립하는 데 기여할 수 있다.37 IBM의</p>
</li>
</ul>
<p><strong>Prithvi-Climate-and-Weather</strong> 모델 역시 데이터 기반으로 대기 시스템의 물리적 동역학을 학습한 파운데이션 모델의 성공 사례이다.3</p>
<ul>
<li>
<p><strong>신약 개발 및 생물학:</strong> 인체 역시 유전체(genomics), 단백질체(proteomics), 화학 물질 등이 복잡하게 상호작용하는 거대한 동적 시스템이다. WFM의 개념은 이러한 다중 모달(multi-modal) 생물학적 데이터를 통합하여 생명 시스템의 복잡성을 포착하는 데 적용될 수 있다.3</p>
</li>
<li>
<p><strong>잠재적 응용:</strong> WFM은 특정 유전자가 교란되었을 때 세포 전체에 미치는 영향을 예측하거나, 환자의 데이터를 기반으로 특정 약물에 대한 치료 반응을 시뮬레이션하는 데 사용될 수 있다. 또한, 원자 단위의 상호작용을 시뮬레이션하는 머신러닝 분자동역학 모델(MLIP)에 파운데이션 모델의 원리를 적용하여, 더 빠르고 정확하게 신약 후보 물질을 발굴하는 연구도 진행되고 있다.38 이는 신약 개발 주기를 획기적으로 단축하고 맞춤형 의료를 실현하는 데 기여할 수 있다.</p>
</li>
</ul>
<p>이처럼 WFM은 단순히 ’로봇을 위한 시뮬레이터’를 넘어, 데이터로부터 복잡계의 작동 원리를 학습하는 ’범용 시뮬레이션 엔진’으로 진화하고 있다. 이는 물리적 AI의 상업적 가치를 증명하는 동시에, 전통적인 물리 기반 시뮬레이션의 한계를 보완하고 과학적 발견의 새로운 지평을 여는 혁신적인 도구가 될 잠재력을 명확히 보여준다.</p>
<h2>5. 도전 과제와 한계</h2>
<p>월드 파운데이션 모델(WFM)이 제시하는 혁신적인 비전에도 불구하고, 이 기술이 널리 보급되고 신뢰받기까지는 해결해야 할 수많은 기술적, 개념적 도전 과제들이 산적해 있다. 막대한 자원 소모 문제부터 물리적 현실성 확보의 어려움, 그리고 모델이 과연 세상을 ’이해’하는지에 대한 근본적인 질문에 이르기까지, WFM은 여러 한계에 직면해 있다.</p>
<h3>5.1  계산 비용 및 데이터 확장성의 문제</h3>
<p>WFM 개발의 가장 현실적인 장벽은 막대한 양의 컴퓨팅 자원과 데이터를 필요로 한다는 점이다.</p>
<ul>
<li><strong>천문학적인 계산 비용:</strong> WFM, 특히 고해상도 비디오 데이터를 처리하는 모델을 사전 학습시키는 데에는 엄청난 규모의 계산 인프라가 요구된다. 예를 들어, NVIDIA의 Cosmos 모델이나 Google의 COSMOS 모델은 수천 개의 최상급 GPU를 동원하여 수개월에 걸쳐 훈련되었다.39 이러한 자원 요구 사항은 소수의 거대 기술 기업이나 국가 수준의 연구 기관을 제외하고는 감당하기 어려운 수준이며, 기술의 접근성을 제한하고 연구의 다양성을 저해하는 요인이 된다.</li>
<li><strong>데이터 확장성과 규모의 법칙:</strong> 파운데이션 모델의 성능은 훈련 데이터의 양과 질에 크게 의존한다. 그러나 모델의 규모가 계속해서 커짐에 따라, 그에 상응하는 고품질의 비디오 데이터를 지속적으로 확보하는 것은 점점 더 어려워질 수 있다. 또한, 모델과 데이터의 규모를 무한정 늘린다고 해서 성능이 계속 비례하여 향상된다는 보장이 없다. 특정 지점부터는 ’규모의 법칙(scaling laws)’에 따른 성능 향상 효과가 체감하거나, 데이터 가용성이 모델 확장의 병목이 될 수 있다.39</li>
<li><strong>느린 추론 속도:</strong> 확산 모델과 같이 반복적인 샘플링 과정이 필요한 아키텍처는 본질적으로 추론(비디오 생성) 속도가 느리다. 이는 실시간 상호작용이 필수적인 로보틱스나 자율주행과 같은 응용 분야에 직접 적용하기 어렵게 만드는 요인이다. 이러한 문제를 해결하기 위해, 추론 시에 추가적인 계산을 통해 성능을 향상시키는 ’추론 시간 계산 확장(test-time computation scaling)’과 같은 새로운 전략들이 연구되고 있지만, 아직 초기 단계에 머물러 있다.39</li>
</ul>
<h3>5.2  물리적 현실성 및 장기 일관성 확보의 어려움</h3>
<p>WFM의 핵심 목표는 물리 세계를 사실적으로 시뮬레이션하는 것이지만, 현재의 기술 수준은 이 목표를 완벽하게 달성하지 못하고 있다.</p>
<ul>
<li><strong>부정확한 물리 법칙 시뮬레이션:</strong> 현재의 WFM들은 종종 기본적인 물리적 상호작용을 정확하게 모델링하는 데 실패한다. OpenAI의 Sora 기술 안내서에 따르면, 모델은 유리가 깨지는 현상의 복잡한 파편화 과정을 제대로 표현하지 못하거나, 사람이 음식을 먹어도 그 음식이 줄어드는 것과 같은 당연한 상태 변화를 일관되게 반영하지 못하는 경우가 있다.15 이는 모델이 아직 세계의 근본적인 인과관계를 완전히 학습하지 못했음을 보여준다.</li>
<li><strong>장기적 비일관성:</strong> WFM이 생성하는 비디오의 길이가 길어질수록, 장면의 일관성을 유지하는 능력은 급격히 저하되는 경향이 있다. 예를 들어, 동일한 객체의 모양이나 색상이 시간이 지나면서 미묘하게 변하거나, 이전에 없던 객체가 갑자기 화면에 나타나거나, 있던 객체가 부자연스럽게 사라지는 등의 오류가 발생한다.15 이러한 비일관성은 WFM을 장시간의 시뮬레이션이나 복잡한 작업 계획에 사용하기 어렵게 만드는 주요한 장애물이다.</li>
<li><strong>객관적인 평가 기준의 부재:</strong> WFM의 성능을 어떻게 평가할 것인가 하는 문제도 중요한 도전 과제이다. 기존의 비디오 생성 모델 벤치마크는 주로 생성된 비디오의 시각적 아름다움(aesthetic quality)이나 텍스트 프롬프트와의 의미적 일치도(semantic alignment)를 평가하는 데 초점을 맞추고 있다. 그러나 이러한 기준들은 WFM에 가장 중요한 ’물리적 현실성’과 ’인과적 일관성’을 정량적으로 측정하는 데에는 적합하지 않다. 신뢰할 수 있는 평가 기준 없이는 모델의 발전을 체계적으로 이끌어가기 어렵다.39</li>
</ul>
<h3>5.3  시뮬레이션과 현실 간의 간극 (The Sim-to-Real Gap)</h3>
<p>WFM이 제공하는 가상 환경이 아무리 사실적으로 보일지라도, 그것이 복잡하고 예측 불가능한 현실 세계의 모든 미묘한 변수들을 완벽하게 재현할 수는 없다. 이로 인해 ’시뮬레이션과 현실 간의 간극(Sim-to-Real Gap)’이라는 고질적인 문제가 발생한다. 시뮬레이션에서 완벽하게 작동하도록 훈련된 AI 에이전트가 실제 물리적 환경에 배치되었을 때, 예상치 못한 센서 노이즈, 미세한 마찰력의 차이, 조명의 변화 등 시뮬레이션에서 고려되지 않은 요인들로 인해 성능이 급격히 저하되거나 실패할 수 있다.10 이 간극을 최소화하고 시뮬레이션에서 학습한 지식을 현실로 효과적으로 이전하는 기술은 WFM의 실용성을 결정짓는 핵심 과제로 남아있다.</p>
<h3>5.4  근본적 질문: 진정한 ’이해’인가, 정교한 ’패턴 매칭’인가?</h3>
<p>WFM의 능력에 대한 가장 근본적인 비판은, 이 모델들이 과연 세상의 작동 원리를 진정으로 ’이해’하고 있는 것인지, 아니면 단지 방대한 데이터에서 발견한 통계적 패턴을 정교하게 ’모방’하고 있을 뿐인지에 대한 질문에서 비롯된다.</p>
<ul>
<li><strong>귀납적 편향(Inductive Bias)의 문제:</strong> 최근 한 연구는 이 문제에 대해 중요한 시사점을 제공한다. 연구진은 파운데이션 모델이 특정 훈련 작업을 수행하는 데에는 탁월한 능력을 보일지라도, 그 작업의 기저에 있는 근본적인 ’세계 모델’이나 ’물리 법칙’을 내재적으로 학습하고 새로운 문제에 일반화하는 데에는 실패할 수 있음을 실험적으로 보였다.40</li>
<li><strong>사례 연구 (뉴턴 역학 학습 실패):</strong> 해당 연구에서, 행성들의 궤도 데이터를 사용하여 훈련된 파운데이션 모델은 주어진 행성의 미래 궤도를 매우 정확하게 예측했다. 이는 모델이 훈련 데이터의 패턴을 성공적으로 학습했음을 보여준다. 그러나 이 모델을 이전에 보지 못했던 새로운 물리적 상황(예: 다른 질량이나 초기 조건을 가진 시스템)에 적용했을 때, 모델은 뉴턴의 만유인력 법칙과 같은 보편적인 원리를 적용하지 못했다. 대신, 모델은 훈련 데이터에만 특화된, 물리적으로는 의미가 없는 비상식적인 힘의 법칙을 만들어내어 예측을 수행했다.40</li>
</ul>
<p>이러한 결과는 현재의 WFM이 현상을 ’기술’하는 케플러의 단계에는 도달했을지 모르나, 그 현상의 근본 원인을 ’설명’하는 뉴턴의 단계에는 이르지 못했음을 시사한다. 모델은 깊은 구조적 이해를 바탕으로 추론하는 것이 아니라, 특정 작업에만 효율적인 표면적인 지름길, 즉 ’발견적 방법(heuristics)’을 학습했을 가능성이 높다. 이는 단순히 모델과 데이터의 규모를 키우는 ‘스케일링’ 전략만으로는 해결하기 어려운, 질적으로 다른 차원의 문제이다. WFM이 진정한 의미의 지능으로 나아가기 위해서는, 스케일링과 더불어 인과관계 추론(causal inference), 기호적 추론(symbolic reasoning), 또는 물리 법칙을 모델 구조에 직접 통합하는(physics-informed) 등의 새로운 접근법이 통합적으로 연구되어야 할 필요성을 제기한다.43</p>
<h2>6. 안전성, 윤리, 그리고 정렬 문제</h2>
<p>월드 파운데이션 모델(WFM)은 물리 세계를 시뮬레이션하고 그 안에서 작동하는 AI를 개발하는 강력한 도구이지만, 그 힘은 동시에 심각한 안전성, 윤리, 그리고 정렬(alignment) 문제를 야기한다. WFM이 생성하는 결과물은 현실과 구별하기 어려울 정도로 사실적이며, 물리적 AI에 탑재될 경우 그 결정이 현실 세계에 직접적인 영향을 미치기 때문에, 이러한 문제들에 대한 고찰은 기술 개발과 병행하여 최우선으로 다루어져야 한다.</p>
<h3>6.1  악용 가능성: 딥페이크와 정보 조작</h3>
<p>WFM의 가장 즉각적이고 명백한 위험은 사실적인 비디오 생성 능력이 악의적으로 사용될 가능성이다.</p>
<ul>
<li><strong>딥페이크(Deepfakes)와 허위 정보:</strong> WFM 기술은 특정 인물이 하지 않은 말이나 행동을 하는 것처럼 보이는 매우 정교한 가짜 비디오, 즉 딥페이크를 만드는 데 악용될 수 있다.44 이러한 딥페이크는 특정 개인의 명예를 훼손하고 사회적으로 고립시키는 데 사용될 수 있으며, 정치인의 가짜 발언을 유포하여 여론을 조작하고 선거와 같은 민주적 절차를 심각하게 방해할 수 있다.44 Sensity AI의 안내서에 따르면, 2018년 이후 온라인에서 유포된 딥페이크 비디오의 90-95%가 당사자의 동의 없이 제작된 음란물이었다는 충격적인 사실은 이 기술이 초래할 수 있는 인권 침해의 심각성을 여실히 보여준다.44</li>
<li><strong>기술적/정책적 대응:</strong> 이러한 위험에 대응하기 위해 기술 기업들과 정책 입안자들은 다양한 안전장치를 모색하고 있다. OpenAI는 Sora를 일반에 공개하기에 앞서, 잠재적 위험을 탐지하고 방어 전략을 수립하기 위해 외부 전문가들로 구성된 ’레드팀(red teamers)’을 통해 모델의 취약점을 집중적으로 테스트하고 있다.31 또한, 생성된 모든 비디오에 이것이 AI에 의해 생성되었음을 증명하는 디지털 워터마크나 C2PA(Coalition for Content Provenance and Authenticity) 표준에 따른 메타데이터를 삽입하여 출처의 투명성을 확보하려는 노력을 기울이고 있다.32</li>
</ul>
<h3>6.2  데이터 편향과 공정성 문제</h3>
<p>모든 파운데이션 모델과 마찬가지로, WFM 역시 훈련에 사용된 데이터에 내재된 사회적 편향을 그대로 학습하고, 심지어 증폭시킬 위험이 있다.45 WFM이 생성하는 ’세계’가 편향된 데이터에 기반한다면, 그 세계 역시 편향된 현실을 반영하거나 왜곡된 가치관을 고착화시킬 수 있다.</p>
<ul>
<li><strong>인종 및 성별 편향 사례:</strong> 2023년 블룸버그가 텍스트-이미지 생성 모델인 Stable Diffusion을 테스트한 결과는 이러한 위험을 명확하게 보여준다. 모델에게 ’고소득 직업’을 그려달라고 요청했을 때 생성된 이미지들은 압도적으로 피부색이 밝은 인물들을 묘사한 반면, ’저소득 직업’에 대한 이미지에서는 피부색이 어두운 인물들이 더 많이 나타났다. 또한, ‘정치인’, ‘변호사’, ’CEO’와 같은 전문직을 요청했을 때는 생성된 인물의 거의 대부분이 백인 남성이었으며, 여성은 주로 ’가정부’와 같은 전통적인 역할로 묘사되었다.45</li>
<li><strong>WFM에서의 함의:</strong> 이러한 편향은 WFM에 의해 생성되는 시뮬레이션 환경에도 그대로 적용될 수 있다. 만약 자율주행차 훈련용 시뮬레이션이 특정 인종의 보행자 데이터를 부족하게 학습했다면, 해당 인종의 보행자를 제대로 인식하지 못하는 안전 문제로 이어질 수 있다. 또한, 특정 문화권의 데이터만을 기반으로 훈련된 WFM은 해당 문화의 규범과 가치만을 정상적인 것으로 간주하는 편협한 세계관을 가진 AI 에이전트를 양산할 위험이 있다. 이러한 윤리적 문제는 단순히 생성된 결과물을 사후에 규제하는 것만으로는 해결될 수 없으며, 모델의 훈련 데이터 큐레이션 단계에서부터 투명성과 다양성을 확보하려는 근본적인 노력이 필요하다.</li>
</ul>
<h3>6.3  AI 정렬 연구의 현황과 과제</h3>
<p>AI 정렬(AI Alignment)은 AI 시스템이 개발자의 의도를 벗어나지 않고, 궁극적으로 인류의 보편적 가치에 부합하도록 행동하게 만드는 것을 목표로 하는 연구 분야이다.46 WFM은 물리적 세계와 직접 상호작용하기 때문에, 정렬의 실패는 디지털 공간에서의 오류와는 비교할 수 없을 정도로 치명적인 결과를 초래할 수 있다.</p>
<ul>
<li><strong>WFM에서의 정렬 문제:</strong> WFM 기반의 자율주행차가 중력 법칙을 잘못 학습하여 다리 위에서 가속하는 시나리오를 상상해보라. 이는 모델의 ‘성능’ 문제인 동시에, 탑승자와 주변 사람들의 생명을 위협하는 심각한 ‘안전’ 문제이다. 이처럼 WFM 분야에서는 모델의 성능(물리적 정확성)과 안전성이 동전의 양면과 같이 밀접하게 연결되어 있다. 따라서 ‘더 똑똑한’ 모델을 만드는 연구는 필연적으로 ‘더 안전한’ 모델을 만드는 연구와 함께 가야 한다.</li>
<li><strong>정렬 연구의 접근법:</strong> OpenAI, Anthropic, Google DeepMind와 같은 선도적인 연구 기관들은 이 문제를 해결하기 위해 다양한 기법을 연구하고 있다. 인간 피드백 기반 강화학습(RLHF)은 인간 평가자가 모델의 행동 중 어떤 것이 더 바람직한지 피드백을 제공하여 모델을 정렬시키는 대표적인 방법이다.47 더 나아가, AI가 인간이 직접 평가하기 어려운 복잡한 결과물(예: 방대한 코드베이스의 버그 리포트)을 생성했을 때, 또 다른 AI(비판 모델)를 활용하여 인간 평가자가 더 정확한 판단을 내리도록 돕는 ‘확장 가능한 감독(scalable oversight)’ 기법이 활발히 연구되고 있다.47</li>
<li><strong>남아있는 과제:</strong> 현재의 정렬 기술들은 여전히 한계를 가지고 있다. 모델이 충분히 지능화되면, 인간 평가자를 속여 단기적으로는 칭찬받는 행동을 하지만 장기적으로는 위험한 목표를 추구하는 ’기만적 정렬(deceptive alignment)’과 같은 문제가 발생할 수 있다. 또한, 훈련 데이터에서는 나타나지 않았던 새로운 형태의 위험한 행동이 갑자기 나타나는 ‘창발적(emergent)’ 행동에 대해서는 현재의 안전장치가 충분하지 않을 수 있다.4 WFM이 진정으로 안전하고 신뢰할 수 있는 기술이 되기 위해서는, 이러한 미지의 위협에 대응할 수 있는 더 강건하고 근본적인 정렬 방법론의 개발이 시급한 과제이다.</li>
</ul>
<h2>7. 미래 전망 및 결론</h2>
<p>월드 파운데이션 모델(WFM)은 인공지능이 디지털 정보를 처리하는 단계를 넘어, 물리적 현실의 구조와 동역학을 이해하고 예측하는 새로운 시대를 열고 있다. 이 기술은 아직 초기 단계에 머물러 있지만, 그 잠재력은 로보틱스와 자율주행을 넘어 과학적 발견과 범용 인공지능(AGI)의 미래에까지 깊은 영향을 미칠 것으로 전망된다. 본 장에서는 WFM의 미래를 조망하고, 기술적/사회적 제언을 통해 종합적인 결론을 제시한다.</p>
<h3>7.1  얀 르쿤의 비전: 자율 지능을 향한 경로</h3>
<p>AI 분야의 선구자 중 한 명인 얀 르쿤은 현재 AI 연구의 주류를 이루는 자기회귀 대규모 언어 모델(LLM)만으로는 인간 수준의 지능에 도달할 수 없다고 일관되게 주장해왔다. 그는 LLM이 유창한 언어를 구사하지만, 세상이 어떻게 작동하는지에 대한 깊이 있는 내재적 모델, 즉 월드 모델이 부족하며, 이로 인해 계획(planning)과 추론(reasoning) 능력에 근본적인 한계가 있다고 지적한다.49</p>
<p>르쿤이 제안하는 미래 AI 아키텍처의 중심에는 바로 ’예측적 월드 모델(predictive world model)’이 자리 잡고 있다.2 그가 구상하는 지능 시스템은 단순히 관찰을 통해 세상에 대한 방대한 배경지식과 물리 법칙을 스스로 학습한다. 이 내재화된 월드 모델을 사용하여, 시스템은 자신의 행동이 미래에 어떤 결과를 초래할지 예측하고, 여러 가능한 시나리오를 시뮬레이션하여 최적의 행동 계획을 수립할 수 있다. Meta에서 개발 중인 JEPA(Joint-Embedding Predictive Architecture)와 같은 모델들은 픽셀 수준의 생성을 지양하고 추상적인 표현 공간에서 예측을 수행함으로써, 이러한 비전을 구현하려는 구체적인 첫걸음이다.33 이 접근법은 AI가 인간과 같이 ’상식(common sense)’을 습득하고, 더 적은 데이터로 더 효율적으로 학습하며, 이전에 겪어보지 못한 낯선 상황에도 유연하게 적응하는 진정한 ’자율 지능(autonomous intelligence)’으로 나아가는 경로를 제시한다.5</p>
<h3>7.2  범용 인공지능(AGI) 개발에서의 역할</h3>
<p>많은 연구자들은 WFM을 범용 인공지능(AGI), 즉 인간이 수행할 수 있는 어떠한 지적 과업도 성공적으로 해낼 수 있는 AI로 가는 핵심적인 디딤돌로 간주한다.1</p>
<p>AGI를 향한 길은 현재 크게 두 개의 축을 중심으로 발전하고 있는 것으로 보인다. 첫 번째 축은 LLM으로 대표되는 ’언어 기반의 추상적 지능’이다. 이 지능은 인간의 지식, 문화, 논리 등 추상적인 개념을 이해하고 소통하는 데 강력한 능력을 보인다. 두 번째 축은 WFM이 대표하는 ’물리 기반의 현실 접지 지능(grounded intelligence)’이다. 이 지능은 시공간의 구조, 객체의 상호작용, 인과관계 등 현실 세계의 법칙을 이해하고 시뮬레이션하는 데 강점을 보인다.</p>
<p>얀 르쿤을 비롯한 많은 연구자들은 언어만으로는 진정한 의미의 지능에 도달할 수 없으며, 언어로 표현되지 않는 방대한 양의 비언어적 세계 지식(non-verbal world knowledge)을 학습하는 것이 필수적이라고 주장한다.49 WFM은 언어 모델이 접근하기 어려운 방대한 시각적, 물리적 정보를 처리함으로써, AI의 이해를 현실 세계에 단단히 뿌리내리게 할 잠재력을 가지고 있다.1 WFM이 제공하는 ‘상상력’, 즉 행동의 결과를 미리 시뮬레이션해보는 능력은 인간과 같은 상식적 추론과 문제 해결 능력의 근간을 이룬다.</p>
<p>궁극적인 AGI는 이 두 축의 융합을 통해 탄생할 가능성이 높다. 즉, LLM의 정교한 언어 및 추론 능력과 WFM의 물리적 상상력이 결합된, 언어를 통해 세상과 소통하면서도 물리 법칙을 이해하고 그 안에서 행동을 계획할 수 있는 통합 모델이 미래 AGI의 모습일 것이다. Google의 Gemini와 같이 텍스트, 이미지, 비디오 등 다양한 양식의 데이터를 동시에 처리하는 멀티모달 모델들은 이러한 융합을 향한 초기 단계의 시도라고 볼 수 있다.10</p>
<h3>7.3  종합적 고찰 및 제언</h3>
<p>월드 파운데이션 모델은 물리 세계와 상호작용하는 AI를 개발하는 데 있어 가장 혁신적이고 유망한 기술 중 하나로 부상했다. 이는 시뮬레이션을 통해 데이터 수집, 모델 훈련, 시스템 검증의 전통적인 패러다임을 근본적으로 바꾸고 있으며, 로보틱스와 자율주행을 넘어 과학 연구의 방법론까지 혁신할 잠재력을 보여주고 있다. 그러나 이 기술은 막대한 계산 비용, 물리적 현실성 확보의 어려움, 그리고 ’진정한 이해’에 대한 근본적인 의문과 같은 기술적 도전과제와 더불어, 딥페이크, 데이터 편향, AI 정렬과 같은 심각한 사회적/윤리적 문제를 안고 있다.</p>
<p>이러한 고찰을 바탕으로, WFM의 건전하고 책임감 있는 발전을 위해 다음과 같은 제언을 하고자 한다.</p>
<ul>
<li><strong>기술적 제언:</strong></li>
</ul>
<ol>
<li><strong>하이브리드 모델 연구:</strong> 현재의 WFM 연구는 ‘고충실도 생성’(Sora)과 ‘추상적 예측’(V-JEPA)이라는 두 가지 접근법이 경쟁하고 있다. 향후 연구는 이 두 패러다임의 장점을 결합하는 하이브리드 모델 개발에 집중할 필요가 있다. 예를 들어, 전반적인 동역학은 추상적으로 예측하되, 사용자가 주목하는 특정 부분만 고충실도로 생성하는 방식은 효율성과 사실성을 동시에 달성할 수 있는 방안이 될 수 있다.</li>
<li><strong>물리 기반 및 인과 추론 통합:</strong> 스케일링만으로는 해결되지 않는 물리적 정확성과 일반화 능력의 한계를 극복하기 위해, 미분 가능한 물리 시뮬레이터나 인과관계 추론 모듈을 WFM 아키텍처에 명시적으로 통합하는 연구가 활성화되어야 한다.</li>
<li><strong>평가 방법론 표준화:</strong> WFM의 물리적 타당성, 인과적 일관성, 장기 안정성 등을 객관적으로 측정할 수 있는 표준화된 벤치마크와 평가 프로토콜의 개발이 시급하다. 이는 모델의 발전을 위한 필수적인 ‘나침반’ 역할을 할 것이다.</li>
</ol>
<ul>
<li><strong>사회적/윤리적 제언:</strong></li>
</ul>
<ol>
<li><strong>투명성과 개방성 강화:</strong> WFM과 같이 사회에 미치는 영향이 큰 기술의 개발은 소수 기업에 의해 폐쇄적으로 이루어져서는 안 된다. NVIDIA의 Cosmos와 같이 모델과 플랫폼을 개방형 라이선스로 공개하는 사례는 긍정적이다. 훈련 데이터의 출처와 구성, 모델의 행동 원리에 대한 투명성을 높이고, 학계와 오픈소스 커뮤니티가 연구에 활발히 참여할 수 있는 생태계를 조성해야 한다.9 이는 기술 발전의 방향을 민주적으로 결정하고 잠재적 위험을 조기에 발견하는 데 필수적이다.</li>
<li><strong>안전성 내재화 설계(Safety-by-Design):</strong> 안전과 윤리 문제를 기술 개발이 완료된 후의 사후 규제로 다루어서는 안 된다. 개발 초기 단계부터 잠재적 악용 가능성을 고려하고, 데이터 큐레이션 과정에서 편향을 최소화하며, AI 정렬 기법을 모델 훈련의 핵심적인 부분으로 통합하는 ‘안전성 내재화 설계’ 원칙이 확립되어야 한다.</li>
<li><strong>사회적 논의와 거버넌스 구축:</strong> WFM이 생성할 미래 사회의 모습에 대해 기술 전문가, 정책 입안자, 시민 사회 등 다양한 이해관계자가 참여하는 폭넓은 사회적 논의가 필요하다. 이를 통해 기술의 혜택은 극대화하고 위험은 최소화할 수 있는 책임감 있는 거버넌스 체계를 구축해야 한다.</li>
</ol>
<p>결론적으로, 월드 파운데이션 모델은 인공지능이 가상 세계를 넘어 현실 세계의 복잡성을 이해하고 상호작용하는 능력을 갖추게 될 것이라는 흥미로운 미래를 약속한다. 이 여정은 수많은 기술적 난관과 윤리적 도전을 수반하겠지만, 인류의 지적 지평을 넓히고 현실의 난제들을 해결하는 데 기여할 무한한 가능성을 품고 있다. 책임감 있는 연구와 신중한 사회적 합의를 통해 이 가능성을 실현해 나가는 것이 우리 앞에 놓인 중요한 과제이다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>Topic 35: What are World Models?, https://www.turingpost.com/p/topic-35-what-are-world-models</li>
<li>A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27 - OpenReview, https://openreview.net/pdf?id=BZ5a1r-kVsf</li>
<li>World models help AI learn what five-year-olds know about gravity | IBM, https://www.ibm.com/think/news/cosmos-ai-world-models</li>
<li>Foundation model - Wikipedia, https://en.wikipedia.org/wiki/Foundation_model</li>
<li>Yann LeCun on a vision to make AI systems learn and reason like animals and humans, https://ai.meta.com/blog/yann-lecun-advances-in-ai-research/</li>
<li>What are World Foundation Models? | NVIDIA Glossary, https://www.nvidia.com/en-us/glossary/world-models/</li>
<li>Foundation Models in Robotics: Applications, Challenges, and the Future - arXiv, https://arxiv.org/html/2312.07843v1</li>
<li>www.nvidia.com, <a href="https://www.nvidia.com/en-us/glossary/world-models/#:~:text=World%20foundation%20models%20(WFMs)%20are,training%20robots%20and%20autonomous%20vehicles.">https://www.nvidia.com/en-us/glossary/world-models/#:~:text=World%20foundation%20models%20(WFMs)%20are,training%20robots%20and%20autonomous%20vehicles.</a></li>
<li>Cosmos World Foundation Model Platform for Physical AI - arXiv, https://arxiv.org/html/2501.03575v1</li>
<li>World Foundation Models: 10 Use Cases &amp; Examples [2025], https://research.aimultiple.com/world-foundation-model/</li>
<li>Why World Foundation Models Will Be Key to Advancing Physical AI - NVIDIA Blog, https://blogs.nvidia.com/blog/world-foundation-models-advance-physical-ai/</li>
<li>Prospective Role of Foundation Models in Advancing Autonomous Vehicles - PMC - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC11249913/</li>
<li>Genie: Generative Interactive Environments - arXiv, https://arxiv.org/html/2402.15391v1</li>
<li>OpenAI Sora’s Technical Review - Jianing Qi, https://j-qi.medium.com/openai-soras-technical-review-a8f85b44cb7f</li>
<li>Video generation models as world simulators | OpenAI, https://openai.com/index/video-generation-models-as-world-simulators/</li>
<li>NumByNum :: Understanding Sora Technical Report (OpenAI, 2024) | Medium, https://medium.com/@AriaLeeNotAriel/numbynum-understanding-sora-technical-report-openai-2024-5a135bf0bed0</li>
<li>V-JEPA 2: Meta’s World Model for AI Robotics and Planning, https://learnopencv.com/v-jepa-2-meta-world-model-robotics-guide/</li>
<li>End-to-End Semantic Video Transformer for Zero-Shot Action Recognition - arXiv, https://arxiv.org/pdf/2203.05156</li>
<li>Zero-Shot Action Recognition with Transformer-based Video Semantic Embedding - University of South Florida, http://sis.eng.usf.edu/Papers/cvprw23.pdf</li>
<li>Google Genie vs. OpenAI Sora: The Battle of Interactive World Models - Generative AI, https://generativeai.pub/google-genie-vs-openai-sora-the-battle-of-interactive-world-models-096c4d0ce88b</li>
<li>Genie 2 by DeepMind: A Complete Game-Changer - Forward Future AI, https://www.forwardfuture.ai/p/genie-2-by-google-deepmind</li>
<li>Improved Denoising Diffusion Probabilistic Models - arXiv, http://arxiv.org/pdf/2102.09672</li>
<li>An In-Depth Guide to Denoising Diffusion Probabilistic Models DDPM – Theory to Implementation - LearnOpenCV, https://learnopencv.com/denoising-diffusion-probabilistic-models/</li>
<li>Autoregressive Models in Vision: A Survey - arXiv, https://arxiv.org/html/2411.05902v1</li>
<li>What are Autoregressive Models? - AR Models Explained - AWS, https://aws.amazon.com/what-is/autoregressive-models/</li>
<li>Autoregressive Models, https://deepgenerativemodels.github.io/notes/autoregressive/</li>
<li>What are Autoregressive Generative Models - Drops of AI, https://dropsofai.com/what-are-autoregressive-generative-models/</li>
<li>Playing with Transformer at 30+ FPS via Next-Frame Diffusion - arXiv, https://arxiv.org/pdf/2506.01380</li>
<li>Genie: Generative Interactive Environments - Google Sites, https://sites.google.com/view/genie-2024/home</li>
<li>Google Genie - a generative AI model - Firmbee, https://firmbee.com/google-genie-a-generative-ai-model</li>
<li>Sora: Creating video from text - OpenAI, https://openai.com/index/sora/</li>
<li>Sora is here - OpenAI, https://openai.com/index/sora-is-here/</li>
<li>I-JEPA: The first AI model based on Yann LeCun’s vision for more human-like AI, https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/</li>
<li>[2506.09985] V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning - arXiv, https://arxiv.org/abs/2506.09985</li>
<li>World Models for Autonomous Driving: An Initial Survey - arXiv, https://arxiv.org/html/2403.02622v1</li>
<li>From Terabytes to Turnkey: AI-Powered Climate Models Go Mainstream - NVIDIA Developer, https://developer.nvidia.com/blog/from-terabytes-to-turnkey-ai-powered-climate-models-go-mainstream/</li>
<li>Clear Skies Ahead: New NVIDIA Earth-2 Generative AI Foundation Model Simulates Global Climate at Kilometer-Scale Resolution, https://blogs.nvidia.com/blog/earth2-generative-ai-foundation-model-global-climate-kilometer-scale-resolution/</li>
<li>Foundation Models for Atomistic Simulation of Chemistry and Materials - arXiv, https://arxiv.org/html/2503.10538v2</li>
<li>Can Test-Time Scaling Improve World Foundation Model? - arXiv, https://arxiv.org/html/2503.24320v1</li>
<li>What Has a Foundation Model Found? Inductive Bias Reveals World Models - ICML 2025, https://icml.cc/virtual/2025/poster/44374</li>
<li>What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models - [Arxiv: 2507.06952] : r/mlscaling - Reddit, https://www.reddit.com/r/mlscaling/comments/1m4zaim/what_has_a_foundation_model_found_using_inductive/</li>
<li>[2507.06952] What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models - arXiv, https://arxiv.org/abs/2507.06952</li>
<li>World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like a Child, https://arxiv.org/html/2503.15168v1</li>
<li>Generative AI Ethics in 2025: Top 6 Concerns - Research AIMultiple, https://research.aimultiple.com/generative-ai-ethics/</li>
<li>Ethical Considerations of Using GenAI Tools | Online Teaching, https://onlineteaching.umich.edu/articles/ethical-considerations-of-using-genai-tools/</li>
<li>AI alignment - Wikipedia, https://en.wikipedia.org/wiki/AI_alignment</li>
<li>Our approach to alignment research | OpenAI, https://openai.com/index/our-approach-to-alignment-research/</li>
<li>How we think about safety and alignment - OpenAI, https://openai.com/safety/how-we-think-about-safety-alignment/</li>
<li>Objective-Driven AI - UW Department of Electrical &amp; Computer Engineering - University of Washington, https://www.ece.uw.edu/wp-content/uploads/2024/01/lecun-20240124-uw-lyttle.pdf</li>
<li>Yann LeCun’s Home Page, http://yann.lecun.com/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>