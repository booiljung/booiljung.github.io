<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:CLIMB (반복적 모델 구축을 위한 지속 학습, 2024-10-17)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>CLIMB (반복적 모델 구축을 위한 지속 학습, 2024-10-17)</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">작업 계획 (Task Planning)</a> / <span>CLIMB (반복적 모델 구축을 위한 지속 학습, 2024-10-17)</span></nav>
                </div>
            </header>
            <article>
                <h1>CLIMB (반복적 모델 구축을 위한 지속 학습, 2024-10-17)</h1>
<p>2025-12-07, G30DR</p>
<h2>1.  서론 (Introduction)</h2>
<p>로봇 공학의 궁극적인 목표 중 하나는 인간의 개입 없이 복잡하고 비정형화된 환경에서 자율적으로 작업을 수행할 수 있는 일반 목적의 로봇(General-Purpose Robot)을 개발하는 것이다. 이를 달성하기 위해서는 로봇이 주어진 자연어 명령을 해석하고, 환경의 물리적 상태를 인지하며, 논리적으로 타당한 행동 순서를 생성할 수 있는 작업 계획(Task Planning) 능력이 필수적이다. 과거 수십 년간 고전적인 작업 및 동작 계획(TAMP, Task and Motion Planning) 연구는 로봇의 지능적 행동을 구현하는 데 있어 중추적인 역할을 해왔다. 특히 PDDL(Planning Domain Definition Language)과 같은 기호적(Symbolic) 언어는 환경의 상태와 행동의 전제 조건(Preconditions), 효과(Effects)를 명시적으로 정의함으로써, 수학적으로 검증 가능하고 신뢰성 높은 계획을 수립하는 데 기여해 왔다.</p>
<p>그러나 이러한 고전적 접근 방식은 ’세계의 모델링’이라는 거대한 장벽에 부딪힌다. 복잡한 현실 세계의 모든 물리적 상호작용과 제약 조건을 사전에 정의된 규칙으로 완벽하게 기술하는 것은 불가능에 가깝기 때문이다. 환경은 끊임없이 변화하며, 로봇이 마주할 수 있는 작업의 종류는 무한하다. 따라서 사전에 고정된 도메인 지식(Fixed Domain Knowledge)에 의존하는 시스템은 새로운 상황에 유연하게 대처하지 못하고 쉽게 실패하는 경향이 있다. 이를 해결하기 위해 최근 딥러닝, 특히 거대 언어 모델(LLM, Large Language Models)의 방대한 지식과 추론 능력을 로봇 계획에 접목하려는 시도가 급증하고 있다. LLM은 인터넷 규모의 텍스트 데이터로부터 학습한 일반 상식을 바탕으로, 사용자의 자연어 명령을 로봇이 이해할 수 있는 형태의 계획으로 변환하는 데 탁월한 능력을 보인다.</p>
<p>하지만 LLM 역시 완벽한 해결책은 아니다. LLM은 물리적 세계에 실존(Grounding)하지 않는 텍스트 기반의 통계적 모델이기 때문에, 실제 환경의 물리적 제약을 무시하거나 실행 불가능한 계획을 생성하는 환각(Hallucination) 현상을 일으킬 수 있다. 즉, 기호적 계획의 ’신뢰성’과 LLM의 ‘유연성’ 사이에는 여전히 간극이 존재한다. 이러한 배경에서 등장한 <strong>CLIMB (Continual Learning for Iterative Model Building)</strong> 프레임워크는 이 두 세계를 연결하고, 더 나아가 로봇이 실패로부터 학습하여 스스로 도메인 모델을 구축해 나가는 지속 학습(Continual Learning)의 새로운 패러다임을 제시한다.1</p>
<p>본 보고서는 ICRA 2025에서 발표된 CLIMB 프레임워크를 중심으로, 언어 유도 기반의 작업 계획 기술이 어떻게 정적인 모델링의 한계를 극복하고 동적인 학습 시스템으로 진화하고 있는지를 심층적으로 분석한다. 특히 CLIMB가 제안하는 ‘반복적 모델 구축(Iterative Model Building)’ 메커니즘과 이를 검증하기 위해 고안된 ‘BlocksWorld++’ 벤치마크, 그리고 실험을 통해 입증된 정량적 성능 향상 결과를 상세히 기술한다. 본 문서는 로봇 공학 및 인공지능 분야의 전문가를 대상으로 작성되었으며, CLIMB의 기술적 아키텍처부터 실험적 검증, 그리고 향후 로봇 지능의 발전에 미칠 시사점까지 포괄적으로 다룬다.</p>
<h2>2.  관련 연구 및 이론적 배경 (Background and Related Work)</h2>
<p>CLIMB의 기술적 위치를 명확히 이해하기 위해서는 기호적 계획(Symbolic Planning)과 뉴럴 계획(Neural Planning), 그리고 이 둘을 결합하려는 뉴로-심볼릭(Neuro-Symbolic) 접근법의 흐름을 파악해야 한다.</p>
<h3>2.1  고전적 작업 계획과 지식 공학의 병목</h3>
<p>전통적인 로봇 계획 시스템은 STRIPS나 PDDL과 같은 정형화된 언어를 사용하여 도메인을 정의한다. 이 방식은 계획의 완전성(Completeness)과 최적성(Optimality)을 보장할 수 있다는 장점이 있지만, ‘지식 공학의 병목(Knowledge Engineering Bottleneck)’ 문제를 야기한다. 전문가가 모든 가능한 상태와 행동, 제약 조건을 수동으로 코딩해야 하기 때문이다. 이는 로봇이 통제된 공장 환경을 벗어나 가정이나 사무실과 같은 비정형 환경으로 진출하는 것을 가로막는 주요 요인이었다.</p>
<h3>2.2  LLM 기반 로봇 계획의 부상과 한계</h3>
<p>GPT-4와 같은 파운데이션 모델의 등장은 이러한 병목 현상을 해결할 수 있는 가능성을 열었다. LLM은 “사과를 깎아라“라는 명령을 “칼을 집는다 -&gt; 사과 근처로 이동한다 -&gt; 깎는다“와 같은 일련의 하위 작업으로 분해할 수 있는 상식적 추론 능력을 갖추고 있다. 초기 연구들은 LLM을 사용하여 직접 로봇 제어 코드를 생성하거나(Code as Policies), 자연어로 계획 단계를 생성하는 데 집중했다. 그러나 이러한 접근은 로봇의 센서 데이터(Perception)와 계획 단계(Action) 간의 연결고리, 즉 ’심볼 그라운딩(Symbol Grounding)’이 약하다는 근본적인 한계를 지닌다. LLM은 “무거운 물체는 깨지기 쉽다“는 텍스트적 지식은 있지만, 실제 로봇 팔이 느끼는 무게나 그립의 압력을 직접 이해하지는 못한다.</p>
<h3>2.3  뉴로-심볼릭 접근과 지속 학습</h3>
<p>CLIMB는 이러한 맥락에서 뉴로-심볼릭 접근법의 최전선에 위치한다. CLIMB는 LLM을 단순한 계획 생성기가 아닌, ’도메인 모델 생성기’로 활용한다. 즉, LLM이 직접 행동을 지시하는 대신, PDDL 형식의 도메인 파일(Domain File)과 문제 파일(Problem File)을 작성하게 하고, 실제 계획 수립은 검증된 기호적 플래너(Symbolic Planner)에게 위임한다. 더 중요한 점은 CLIMB가 ’지속 학습’을 도입했다는 것이다. 대부분의 LLM 기반 로봇 연구가 단발성 문제 해결(One-off task solving)에 그치는 반면, CLIMB는 로봇이 경험한 실패를 통해 PDDL 모델을 수정하고, 학습된 지식(새로운 술어, 수정된 제약 조건)을 저장하여 다음 작업에 활용한다. 이는 로봇이 환경과 상호작용하며 자신의 지식베이스를 점진적으로 확장해 나가는 진정한 의미의 학습 시스템을 구현하려는 시도이다.1</p>
<h2>3.  CLIMB 프레임워크 아키텍처 (CLIMB Framework Architecture)</h2>
<p>CLIMB의 아키텍처는 크게 인식, 추론, 계획, 실행, 그리고 학습의 루프를 형성하는 모듈들로 구성된다. 각 모듈은 독립적인 기능을 수행하면서도 유기적으로 통합되어, 자연어 명령을 구체적인 로봇 동작으로 변환하고 그 결과를 다시 지식으로 환원한다.</p>
<h3>3.1  아키텍처 개요</h3>
<p>시스템의 핵심은 <strong>반복적 모델 구축(Iterative Model Building)</strong> 루프이다. 사용자의 자연어 명령이 입력되면, CLIMB는 초기 PDDL 모델을 생성하여 계획을 수립하고 실행한다. 실행 중 오류가 발생하면, 시스템은 그 오류의 맥락을 포착하여 LLM에게 피드백을 제공하고, LLM은 이를 바탕으로 도메인 모델을 수정한다. 이 과정은 성공적인 실행이 완료될 때까지, 또는 정해진 반복 횟수 내에서 계속된다.2 모든 LLM 모듈은 OpenAI의 <code>gpt-4o-2024-08-06</code> 모델을 기반으로 구현되어 최신 언어 모델의 추론 능력을 활용한다.2</p>
<h3>3.2  세부 모듈 분석</h3>
<h4>3.2.1  문제 변환 및 도메인 생성기 (Problem Translation &amp; Domain Generation)</h4>
<p>이 모듈은 사용자의 자연어 명령과 환경에 대한 초기 설명을 입력받아 PDDL 도메인 파일(<code>domain.pddl</code>)과 문제 파일(<code>problem.pddl</code>)을 생성한다.</p>
<ul>
<li><strong>역할:</strong> 작업에 필요한 객체(Type), 술어(Predicate), 행동(Action)의 초기 정의를 내린다.</li>
<li><strong>특징:</strong> LLM의 상식에 의존하여 초기 모델을 제안한다. 예를 들어 “피라미드 쌓기“라는 작업에 대해 <code>on</code>, <code>clear</code>, <code>move</code> 등의 기본적인 술어와 액션을 정의한다.</li>
</ul>
<h4>3.2.2  술어 생성 및 검증 (Predicate Generation &amp; Verification)</h4>
<p>PDDL의 논리적 술어를 실제 로봇의 센서 데이터와 연결하는 ’그라운딩 함수(Grounding Function)’를 생성하는 단계이다.</p>
<ul>
<li><strong>역할:</strong> 파이썬(Python) 코드 형태의 그라운딩 함수를 생성하여, 카메라 이미지나 좌표 데이터로부터 현재 상태가 <code>(on blockA blockB)</code>인지 판별할 수 있게 한다.</li>
<li><strong>검증:</strong> 생성된 코드는 문법적 오류(Syntax Error)와 의미적 오류를 검증받는다. CLIMB는 구문 오류를 자동으로 감지하고 LLM을 통해 수정하는 디버깅 프로세스를 포함한다.2</li>
</ul>
<h4>3.2.3  기호적 계획기 (Symbolic Planner)</h4>
<p>생성된 PDDL 파일들을 입력으로 받아, 목표 상태(Goal State)에 도달하기 위한 행동 시퀀스(Plan Trace)를 생성한다. CLIMB는 검증된 외부 플래너(예: Fast Downward 등)를 사용하여 논리적으로 타당한 계획을 보장한다. 만약 계획 자체가 불가능하다고 판명되면, 이는 도메인 정의가 불충분하다는 신호로 간주되어 모델 수정 루프를 트리거한다.</p>
<h4>3.2.4  실행 및 인식 (Execution &amp; Perception)</h4>
<p>로봇은 계획된 행동을 물리적으로 수행한다. 이 과정에서 인식 모듈은 지속적으로 환경의 상태를 모니터링한다.</p>
<ul>
<li><strong>인식 시스템:</strong> 실제 하드웨어 실험에서는 손목에 장착된 카메라와 AprilTag2 마커를 사용하여 객체의 6D 포즈를 정밀하게 추적한다. 로봇은 각 행동을 수행한 후 홈 포지션으로 복귀하여 전체 장면을 다시 스캔함으로써, 시뮬레이션 환경(IsaacSim)에서 제공하는 Ground Truth 정보와 유사한 수준의 상태 정보를 획득한다.3</li>
<li><strong>실패 감지:</strong> 행동 수행 중 충돌이 발생하거나, 예상된 효과(Effect)가 나타나지 않을 경우 실행은 중단되고 실패 로그가 생성된다.</li>
</ul>
<h4>3.2.5  반복적 재프롬프팅 및 정제 (Iterative Reprompting and Refinement)</h4>
<p>CLIMB의 가장 독창적인 부분으로, 실패를 학습으로 전환하는 핵심 엔진이다.</p>
<ul>
<li><strong>메커니즘:</strong> “행동 A를 수행하려 했으나, 전제 조건 B가 충족되지 않아 실패했다” 또는 “행동 A 수행 후 상태가 C가 되어야 하는데 D가 되었다“와 같은 구체적인 실패 상황을 자연어로 기술하여 LLM에게 전달한다.</li>
<li><strong>모델 수정:</strong> LLM은 이 정보를 바탕으로 PDDL 도메인을 수정한다. 누락된 전제 조건을 추가하거나(예: 블록을 놓기 위해서는 바닥이 평평해야 한다), 잘못된 효과를 수정하거나, 아예 새로운 술어를 정의하여 모델의 표현력을 확장한다.</li>
<li><strong>지식 저장:</strong> 수정된 도메인 모델은 일회성으로 사라지는 것이 아니라, 지식베이스에 저장되어 향후 유사하거나 더 복잡한 작업에서 재사용된다. 이것이 CLIMB의 ’지속 학습’을 가능하게 하는 메커니즘이다.1</li>
</ul>
<h2>4.  실험 환경: BlocksWorld++ (Experimental Domain)</h2>
<p>CLIMB의 성능을 검증하기 위해 연구진은 기존의 표준 벤치마크를 확장한 <strong>BlocksWorld++</strong> 도메인을 새롭게 제안하였다.</p>
<h3>4.1  BlocksWorld++ 개발 배경</h3>
<p>표준 BlocksWorld는 기호적 계획 연구에서 널리 쓰이는 예제이지만, 현대의 로봇 계획 시스템, 특히 지속 학습과 모델 구축 능력을 평가하기에는 지나치게 단순하고 정적이다. 모든 규칙이 사전에 완벽하게 정의된 환경에서는 로봇이 ‘배울’ 것이 없기 때문이다. 따라서 CLIMB 연구진은 로봇이 환경과의 상호작용을 통해 숨겨진 규칙을 발견해야만 해결할 수 있는 더 복잡하고 현실적인 시나리오가 필요하다고 판단하였다.1</p>
<h3>4.2  도메인 특징 및 커리큘럼</h3>
<p>BlocksWorld++는 시뮬레이션(IsaacLab 기반)과 실제 하드웨어(Real Robot) 환경을 모두 포함하며, 난이도가 점진적으로 상승하는 커리큘럼(Curriculum)을 제공한다.</p>
<ol>
<li><strong>점진적 난이도:</strong></li>
</ol>
<ul>
<li>초기 단계: 단순한 블록 쌓기 (Stacking). 기본적인 <code>pick</code>, <code>place</code> 동작과 <code>holding</code>, <code>clear</code> 등의 술어 학습.</li>
<li>중기 단계: 특정 색상이나 순서를 고려한 배열.</li>
<li>후기 단계: 피라미드 건설, 다리 놓기(spanning) 등 비직관적인 물리적 제약이 포함된 작업. 예를 들어, 두 블록 위에 긴 블록을 걸치기 위해서는 아래 두 블록이 서로 인접(<code>adjacent</code>)해야 한다는 제약 조건 등이다.3</li>
</ul>
<ol start="2">
<li><strong>물리적-논리적 연계 (Sim-to-Real):</strong></li>
</ol>
<ul>
<li>BlocksWorld++는 시뮬레이션 환경과 실제 환경 간의 격차를 최소화하도록 설계되었다. 실제 로봇 환경에서도 시뮬레이션과 동일한 논리적 상태 공간을 추상화할 수 있도록 인식 시스템이 통합되어 있으며, 이를 통해 시뮬레이션에서 학습된 도메인 모델이 실제 로봇에도 그대로 적용될 수 있음을 검증한다.1</li>
</ul>
<h2>5.  실험 결과 및 분석 (Results and Analysis)</h2>
<p>CLIMB의 유효성은 BlocksWorld++ 도메인에서의 정량적 평가를 통해 입증되었다. 주요 평가 지표는 작업 성공률(Success Rate)과 PDDL 술어의 그라운딩 정확도(Predicate Grounding Accuracy)이다.</p>
<h3>5.1  작업 성공률의 비약적 향상</h3>
<p>실험은 초기 모델만을 사용하는 제로샷(Zero-shot) 설정과, CLIMB의 반복적 모델 구축 및 지속 학습을 적용한 퓨샷(Few-shot/Iterative) 설정으로 나누어 진행되었다.</p>
<table><thead><tr><th><strong>평가 설정 (Setting)</strong></th><th><strong>성공률 (Success Rate)</strong></th><th><strong>분석 (Analysis)</strong></th></tr></thead><tbody>
<tr><td><strong>제로샷 (Zero-shot)</strong></td><td>37%</td><td>LLM의 상식에만 의존한 초기 모델은 물리적 제약을 충분히 반영하지 못해 낮은 성공률을 보임.</td></tr>
<tr><td><strong>CLIMB (Continual Learning)</strong></td><td><strong>80%</strong></td><td>실행 피드백을 통한 반복적 모델 수정과 지속 학습을 통해 도메인 지식을 축적한 결과, 성공률이 2배 이상 향상됨.</td></tr>
</tbody></table>
<p>위 표의 결과는 CLIMB의 핵심 가설을 강력하게 뒷받침한다. 초기 LLM이 생성한 계획은 37%의 확률로만 성공했으나, 실패로부터 배우는 메커니즘을 도입하자 성능이 80%로 급상승했다. 이는 로봇이 단순히 사전에 주입된 지식을 사용하는 것이 아니라, 환경과 부딪히며 지식을 ’체화(Embody)’해 나가는 과정이 필수적임을 시사한다.2 특히, 베이스라인(지속 학습 없이 매번 초기화되는 플래너)과의 비교에서 CLIMB가 보여준 우월한 성능은 축적된 지식이 새로운 문제 해결에 효과적으로 전이됨을 보여준다.</p>
<h3>5.2  술어 그라운딩 성능 분석</h3>
<p>PDDL의 논리적 기호가 실제 센서 데이터와 얼마나 정확하게 매핑되는지를 나타내는 그라운딩 정확도 또한 CLIMB의 중요한 성과 지표이다. LLM이 생성한 초기 파이썬 함수들은 구문 오류나 논리적 결함을 포함하는 경우가 많았으나, CLIMB의 디버깅 및 수정 과정을 통해 정확도가 유의미하게 개선되었다.</p>
<p>다음은 BlocksWorld 도메인의 주요 술어에 대한 그라운딩 정확도 변화를 나타낸다.2</p>
<table><thead><tr><th><strong>술어 (Predicate)</strong></th><th><strong>제로샷 정확도 (Zero-Shot)</strong></th><th><strong>구문 수정 후 정확도 (With Syntax Fixing)</strong></th><th><strong>향상도 (Improvement)</strong></th><th><strong>설명 (Description)</strong></th></tr></thead><tbody>
<tr><td><code>on-table</code></td><td>0.95</td><td><strong>1.00</strong></td><td>+0.05</td><td>블록이 바닥에 있는지를 판단하는 비교적 단순한 시각적 특징.</td></tr>
<tr><td><code>on</code></td><td>0.25</td><td><strong>0.45</strong></td><td>+0.20</td><td>블록 A가 블록 B 위에 정확히 놓여있는지 판단. 상대적 위치 관계 파악의 어려움 존재.</td></tr>
<tr><td><code>holding</code></td><td>0.50</td><td><strong>0.65</strong></td><td>+0.15</td><td>그리퍼(Gripper)가 객체를 파지하고 있는지 판단.</td></tr>
<tr><td><code>arm-empty</code></td><td>0.10</td><td><strong>0.35</strong></td><td>+0.25</td><td><code>holding</code> 상태의 여집합(Complement) 관계 정의 필요.</td></tr>
<tr><td><code>clear</code></td><td>0.60</td><td><strong>0.80</strong></td><td>+0.20</td><td>블록 위에 다른 객체가 없는 상태.</td></tr>
</tbody></table>
<p><strong>심층 분석:</strong></p>
<ul>
<li><strong>높은 성능의 <code>on-table</code>:</strong> 절대 좌표계에서 Z축 높이만 확인하면 되는 단순한 술어이기에 LLM이 쉽게 정확한 코드를 생성한다.</li>
<li><strong>낮은 성능의 <code>on</code> 및 <code>arm-empty</code>:</strong> <code>on</code> 관계는 두 물체 간의 미세한 접촉과 정렬 상태를 판단해야 하므로 시각적 모호성이 크다. 또한 <code>arm-empty</code>는 <code>holding</code> 상태가 아님을 논리적으로 정의해야 하는데, 초기 LLM 생성 코드에서 이 논리적 반전(Negation)이나 센서 값 해석에 오류가 잦았음을 알 수 있다.</li>
<li><strong>수정 효과:</strong> 모든 술어에서 구문 수정 및 피드백 후 정확도가 상승했다. 이는 CLIMB가 코드 레벨의 오류뿐만 아니라, 물리적 의미(Semantics)에 대한 이해도 어느 정도 개선할 수 있음을 보여준다. 그러나 <code>on</code> 술어의 최종 정확도가 0.45에 머무른 것은 여전히 복잡한 공간 관계를 텍스트 기반 코드로 자동 생성하는 데에는 한계가 있음을 시사하며, 이는 향후 비전-언어 모델(VLM) 등의 도입 필요성을 암시한다.2</li>
</ul>
<h3>5.3  지속 학습과 지식 전이 (Continual Learning &amp; Knowledge Transfer)</h3>
<p>CLIMB의 진정한 가치는 단일 작업의 성공률 향상보다, 일련의 작업 시퀀스(Sequence of Tasks)를 수행하며 지식이 축적된다는 점에 있다. 커리큘럼 실험에서, 초반의 쉬운 작업에서 학습된 <code>adjacent</code> (인접함)와 같은 술어 제약 조건은 후반부의 복잡한 다리 놓기(Bridge Building) 작업에서 즉시 활용되었다. 지속 학습 기능이 없는 베이스라인 모델은 매번 동일한 실패를 반복하며 처음부터 다시 배워야 했던 반면, CLIMB는 이전의 실패를 기억하고 즉각적으로 올바른 계획을 수립하거나 탐색 공간을 줄이는 모습을 보였다.2</p>
<h2>6.  논의 (Discussion)</h2>
<h3>6.1  기호적 AI의 부활과 LLM의 역할</h3>
<p>CLIMB는 로봇 계획 분야에서 기호적 AI(Symbolic AI)와 뉴럴 AI(Neural AI)가 어떻게 상호 보완적으로 작용할 수 있는지를 보여주는 모범 사례이다. 순수 뉴럴 네트워크 방식(End-to-End Learning)은 데이터가 많이 필요하고 설명 불가능하다는 단점이 있고, 순수 기호적 방식은 유연성이 부족하다는 단점이 있다. CLIMB는 LLM을 ’번역기(Translator)’이자 ’제안자(Proposer)’로 활용하여 기호적 시스템의 유연성을 확보하고, PDDL을 통해 계획의 투명성과 검증 가능성을 유지한다. 이는 설명 가능한 AI(XAI)가 필수적인 로봇 안전(Robot Safety) 관점에서도 매우 중요한 접근이다.</p>
<h3>6.2  현실 세계의 불확실성과 그라운딩의 한계</h3>
<p>실험 결과에서 드러난 <code>on</code> 술어의 낮은 그라운딩 정확도는 여전히 해결해야 할 과제이다. 텍스트로 표현된 논리(<code>Block A is on Block B</code>)를 연속적인 센서 데이터(픽셀, 포인트 클라우드)와 완벽하게 일치시키는 것은 매우 어렵다. 현재 CLIMB는 GPT-4o가 생성한 파이썬 코드에 의존하고 있지만, 향후에는 시각적 이해도가 높은 VLM이나, 데이터로부터 직접 그라운딩 함수를 학습하는 뉴럴 서술자(Neural Predicates) 방식을 결합하여 이 정밀도를 높여야 할 것이다.</p>
<h3>6.3  확장성 및 일반화 가능성</h3>
<p>BlocksWorld++는 유용한 벤치마크이지만, 여전히 블록이라는 정형화된 객체를 다룬다. CLIMB 프레임워크가 요리, 청소, 조립 등 더 다양한 객체와 동적인 상호작용이 존재하는 일반 가정 환경으로 확장되기 위해서는 도메인 표현력의 확장이 필요하다. PDDL은 강력하지만 표현할 수 있는 물리적 현상에 한계가 있으므로, 더 유연한 표현 방식(예: PDDLStream, Probabilistic Planning)과의 통합이 고려되어야 한다.</p>
<h2>7.  결론 (Conclusion)</h2>
<p>본 보고서는 ICRA 2025에서 주목받은 <strong>CLIMB</strong> 프레임워크를 심층적으로 분석하였다. CLIMB는 대형 언어 모델의 지식과 로봇의 실행 피드백을 결합하여, 정적인 도메인 모델링의 한계를 극복하고 스스로 성장하는 작업 계획 시스템을 구현하였다.</p>
<p>연구의 핵심 기여는 다음과 같다.</p>
<ol>
<li><strong>반복적 모델 구축:</strong> 실패를 학습의 기회로 삼아 PDDL 도메인 모델을 동적으로 수정하고 확장하는 메커니즘을 제안하였다.</li>
<li><strong>지속 학습 프레임워크:</strong> 학습된 술어와 제약 조건을 저장하여 미래의 작업에 전이함으로써, 제로샷 대비 작업 성공률을 37%에서 80%로 대폭 향상시켰다.</li>
<li><strong>BlocksWorld++ 벤치마크:</strong> 시뮬레이션과 실제 환경을 아우르며 점진적 난이도를 제공하는 새로운 평가 환경을 구축하여, 지속 학습 알고리즘의 체계적인 검증을 가능하게 했다.</li>
</ol>
<p>CLIMB는 로봇이 인간의 언어를 이해하는 것을 넘어, 언어를 통해 세상의 구조를 이해하고 자신의 내부 모델을 끊임없이 갱신하는 ’적응형 지능(Adaptive Intelligence)’의 가능성을 보여주었다. 이는 향후 로봇이 사전에 정의되지 않은 미지의 환경에서 인간과 공존하며 협력하기 위해 반드시 갖추어야 할 핵심 기술이 될 것이다. 비록 복잡한 물리적 그라운딩의 정확도 향상이라는 과제가 남아있지만, 언어 모델과 기호적 추론의 결합이 로봇 공학의 난제를 해결하는 강력한 열쇠임을 입증했다는 점에서 본 연구의 의의는 매우 크다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building | Request PDF - ResearchGate, https://www.researchgate.net/publication/385010449_CLIMB_Language-Guided_Continual_Learning_for_Task_Planning_with_Iterative_Model_Building</li>
<li>CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building - arXiv, https://arxiv.org/html/2410.13756v1</li>
<li>CLIMB: Language-guided continual learning for robot task planning, https://plan-with-climb.github.io/</li>
<li>CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building | Request PDF - ResearchGate, https://www.researchgate.net/publication/395225956_CLIMB_Language-Guided_Continual_Learning_for_Task_Planning_with_Iterative_Model_Building</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>