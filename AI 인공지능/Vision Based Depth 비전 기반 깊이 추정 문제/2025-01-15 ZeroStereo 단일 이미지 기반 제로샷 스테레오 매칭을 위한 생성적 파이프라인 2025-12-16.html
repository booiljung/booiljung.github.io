<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:ZeroStereo 단일 이미지 기반 제로샷 스테레오 매칭 (Zero-shot Stereo Matching from Single Images)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>ZeroStereo 단일 이미지 기반 제로샷 스테레오 매칭 (Zero-shot Stereo Matching from Single Images)</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">비전 기반 깊이 추정 (Vision Based Dept)</a> / <span>ZeroStereo 단일 이미지 기반 제로샷 스테레오 매칭 (Zero-shot Stereo Matching from Single Images)</span></nav>
                </div>
            </header>
            <article>
                <h1>ZeroStereo 단일 이미지 기반 제로샷 스테레오 매칭 (Zero-shot Stereo Matching from Single Images)</h1>
<p>2025-12-16, G30DR</p>
<h2>1.  서론 (Introduction)</h2>
<h3>1.1  스테레오 매칭의 현대적 위기와 데이터의 병목 현상</h3>
<p>컴퓨터 비전(Computer Vision)의 역사에서 스테레오 매칭(Stereo Matching)은 3차원 공간 정보를 복원하는 가장 고전적이면서도 필수적인 방법론으로 자리 잡아 왔다. 인간의 양안 시차(Binocular Disparity) 원리를 모방하여 좌우 두 카메라의 영상 차이를 통해 깊이(Depth)를 추정하는 이 기술은 자율 주행 자동차의 장애물 감지, 로봇 팔의 조작, 그리고 최근의 증강 현실(AR) 및 가상 현실(VR) 기기의 공간 매핑에 이르기까지 광범위하게 응용되고 있다. 지난 10년 간, 합성곱 신경망(CNN)과 트랜스포머(Transformer) 아키텍처의 도입은 스테레오 매칭의 정확도를 비약적으로 향상시켰다. 전통적인 비용 볼륨(Cost Volume) 구축 방식에서부터 최근의 반복적 정제(Iterative Refinement) 모델인 RAFT-Stereo나 IGEV-Stereo에 이르기까지, 알고리즘 자체의 발전은 눈부셨다.</p>
<p>그러나 이러한 알고리즘의 발전 이면에는 ’데이터의 위기’라는 근본적인 장벽이 존재한다. 지도 학습(Supervised Learning) 기반의 딥러닝 모델은 본질적으로 정답 데이터(Ground Truth, GT)의 품질과 양에 종속된다. 하지만 실제 환경(Real-world)에서 픽셀 단위의 정밀한 시차 라벨을 획득하는 것은 극도로 어렵다. LiDAR 센서는 희소한(Sparse) 점군 데이터만을 제공하며, 구조광(Structured Light) 센서는 실외 환경이나 투명한 물체, 거울 반사 표면 등에서 심각한 오류를 범한다. 이로 인해 대다수의 연구는 Scene Flow와 같은 대규모 합성 데이터셋(Synthetic Dataset)에 의존하여 모델을 사전 학습(Pre-training)시킨다. 문제는 합성 데이터와 실제 주행 환경(KITTI), 혹은 복잡한 실내 환경(Middlebury, ETH3D) 간에 존재하는 거대한 ’도메인 격차(Domain Gap)’이다. 합성 데이터의 완벽한 텍스처와 단순화된 조명 조건에서 학습된 모델은, 실제 세계의 복잡한 조명, 노이즈, 비정형적인 객체 분포를 마주했을 때 성능이 급격히 저하되는 일반화(Generalization) 실패를 겪는다.</p>
<h3>1.2  생성형 AI를 통한 패러다임의 전환: ZeroStereo</h3>
<p>이러한 데이터 희소성과 도메인 일반화 문제를 해결하기 위해 등장한 것이 바로 <strong>ZeroStereo</strong>이다. ICCV 2025에서 발표된 이 연구는 기존의 “더 나은 모델 아키텍처를 설계하는” 접근법에서 탈피하여, “더 나은 데이터를 생성하는” 데이터 중심(Data-centric) 접근법을 취한다. ZeroStereo는 새로운 스테레오 매칭 네트워크가 아니라, 임의의 단일 RGB 이미지로부터 고품질의 스테레오 이미지 쌍과 시차 라벨을 합성해내는 **스테레오 데이터 생성 파이프라인(Stereo Data Generation Pipeline)**이다.</p>
<p>이 접근법의 핵심은 최근 폭발적으로 성장한 두 가지 기술, 즉 강력한 <strong>단안 깊이 추정(Monocular Depth Estimation, MDE)</strong> 파운데이션 모델과 **잠재 확산 모델(Latent Diffusion Models, LDM)**을 결합하는 데 있다. 단안 깊이 추정 모델인 ’Depth Anything V2’를 통해 이미지의 기하학적 구조를 추출하고, 이를 기반으로 시점을 변환한 뒤, 필연적으로 발생하는 폐색(Occlusion) 영역을 확산 모델 기반의 인페인팅(Inpainting) 기술로 채워 넣는다. 이 과정에서 ZeroStereo 연구진은 단순한 기술 결합을 넘어, 스테레오 매칭 작업에 특화된 미세 조정(Fine-tuning) 프로토콜과 신뢰도 기반의 필터링 메커니즘을 도입함으로써 기존 생성형 방식의 한계였던 기하학적 왜곡과 아티팩트 문제를 해결했다.</p>
<p>본 보고서는 ZeroStereo의 기술적 아키텍처, 핵심 구성 요소인 적응형 시차 선택(Adaptive Disparity Selection)과 훈련 없는 신뢰도 생성(Training-Free Confidence Generation), 그리고 이를 통해 달성한 제로샷 성능을 심층적으로 분석한다. 또한, 경쟁 기술인 StereoDiffusion이나 AdaMPI와의 비교 분석, 그리고 임업(Forestry)과 같은 특수 도메인에서의 적용 가능성을 탐구함으로써, ZeroStereo가 제시하는 스테레오 매칭의 미래 방향성을 고찰한다.</p>
<h2>2.  이론적 배경 및 관련 연구 (Theoretical Framework &amp; Related Work)</h2>
<h3>2.1  딥러닝 기반 스테레오 매칭의 진화와 한계</h3>
<p>딥러닝이 적용되기 전, 스테레오 매칭은 SGM(Semi-Global Matching)과 같은 전통적인 최적화 기법이 주를 이루었다. 이후 DispNet, GC-Net 등이 등장하며 3D CNN을 이용한 정규화(Regularization)가 표준이 되었다. 최근에는 광학 흐름(Optical Flow) 추정 모델인 RAFT의 아키텍처를 차용한 <strong>RAFT-Stereo</strong>와 <strong>IGEV-Stereo</strong>가 등장하여 SOTA(State-of-the-Art) 성능을 이끌고 있다. 이들은 모든 픽셀 쌍에 대한 상관관계(Correlation)를 계산하고, GRU(Gated Recurrent Unit)를 통해 반복적으로 시차 필드를 업데이트하는 방식을 취한다.</p>
<p>하지만 이들 모델의 뛰어난 성능은 대규모 데이터셋에 대한 의존성을 심화시켰다. Scene Flow 데이터셋으로 학습된 모델을 바로 실제 환경인 KITTI 데이터셋에 적용하면(Zero-shot 설정), 도메인 차이로 인해 시차 추정의 정확도가 현저히 떨어진다. 특히 반사 재질, 얇은 구조물, 텍스처가 없는 영역 등은 지도 학습 모델이 가장 취약한 부분으로 남아있다. 이를 해결하기 위해 도메인 적응(Domain Adaptation)이나 전이 학습(Transfer Learning) 연구가 진행되었으나, 여전히 타겟 도메인에 대한 데이터나 추가적인 학습 과정을 요구한다는 한계가 있었다.</p>
<h3>2.2  단안 깊이 추정(Monocular Depth Estimation)의 부상</h3>
<p>단일 이미지에서 깊이를 추정하는 MDE 기술은 최근 ‘Depth Anything’ 시리즈와 같은 파운데이션 모델의 등장으로 비약적인 발전을 이루었다. 이들 모델은 방대한 양의 라벨링되지 않은 이미지 데이터를 학습하여, 물체의 의미론적(Semantic) 정보와 맥락(Context) 정보를 바탕으로 매우 정교한 상대적 깊이 맵(Relative Depth Map)을 추론해낸다.</p>
<p>ZeroStereo는 이러한 MDE 모델을 ’유사 라벨 생성기(Pseudo-label Generator)’로 활용한다. 즉, 비싼 센서 없이도 인터넷 상의 수많은 이미지를 잠재적인 스테레오 학습 데이터로 변환할 수 있는 가능성을 연 것이다. 그러나 MDE 모델이 출력하는 깊이는 절대적인 물리량이 아닌 상대적인 값이므로, 이를 스테레오 매칭에 필요한 절대 시차(Absolute Disparity)로 변환하는 과정에서 스케일 모호성(Scale Ambiguity) 문제가 발생하며, 이를 해결하는 것이 ZeroStereo의 핵심 과제 중 하나였다.</p>
<h3>2.3  이미지 합성 및 인페인팅 기술 (Image Synthesis &amp; Inpainting)</h3>
<p>단일 이미지를 스테레오로 변환하는 작업은 본질적으로 새로운 시점(View Synthesis)을 생성하는 문제이다. 왼쪽 이미지를 오른쪽 시점으로 워핑(Warping)하면, 시차로 인해 필연적으로 ’빈 공간(Hole)’이 발생한다. 이는 왼쪽 눈에는 보이지만 오른쪽 눈에는 가려져 있던 배경 영역이다.</p>
<p>과거에는 주변 픽셀을 복사하거나 단순 보간(Interpolation)하는 방식을 사용했으나, 이는 시각적으로 부자연스럽고 기하학적 불연속성을 유발했다. 최근에는 **NeRF(Neural Radiance Fields)**나 3D Gaussian Splatting과 같은 3D 표현 방식이 사용되었으나, 이는 다수의 입력 이미지를 필요로 하거나 학습 시간이 매우 오래 걸리는 단점이 있다.</p>
<p>반면, Stable Diffusion과 같은 확산 모델(Diffusion Model)은 텍스트 프롬프트를 조건으로 고품질의 이미지를 생성할 수 있는 능력을 갖추고 있다. 하지만 일반적인 확산 모델을 그대로 인페인팅에 적용할 경우, 생성된 영역이 원본 이미지와 기하학적으로 일치하지 않거나(Consistency), 엉뚱한 물체를 생성하는 환각(Hallucination) 현상이 발생한다. ZeroStereo는 이러한 확산 모델을 스테레오 매칭의 기하학적 제약 조건에 맞게 제어하는 방법을 제시한다.</p>
<h2>3.  ZeroStereo 핵심 방법론 (ZeroStereo Methodology)</h2>
<p>ZeroStereo 파이프라인은 크게 네 단계로 구성된다: (1) 단안 깊이 추정 및 적응형 시차 선택, (2) 워핑 및 마스크 생성, (3) 확산 모델 기반의 정밀 인페인팅, (4) 신뢰도 기반 필터링 및 학습. 각 단계는 기존 방법론들의 한계를 극복하기 위해 정교하게 설계되었다.</p>
<h3>3.1  단안 깊이 추정 및 적응형 시차 선택 (ADS)</h3>
<p>입력으로 들어온 단일 이미지 <span class="math math-inline">I_l</span>에 대해 <strong>Depth Anything V2 (DAv2)</strong> 모델을 사용하여 정규화된 역깊이 맵(Normalized Inverse Depth Map) <span class="math math-inline">D</span>를 추출한다. DAv2는 다양한 환경에서 강건한 성능을 보이지만, 출력값이 상대적인 깊이 정보이기에 이를 스테레오 매칭 네트워크가 학습할 수 있는 시차(Disparity) 값으로 변환해야 한다.</p>
<p>여기서 ZeroStereo는 적응형 시차 선택(Adaptive Disparity Selection, ADS) 모듈을 제안한다. 단순히 고정된 배율로 깊이를 시차로 변환할 경우, 생성된 데이터셋의 시차 분포가 편향될 수 있다. 예를 들어, 모든 데이터가 근거리 물체만 있거나 원거리 배경만 있다면 모델은 특정 깊이 범위에 과적합될 것이다.</p>
<p>ADS는 시차 <span class="math math-inline">d</span>를 다음과 같이 정의한다:<br />
<span class="math math-display">
d = D \cdot s \cdot w
</span><br />
여기서 <span class="math math-inline">w</span>는 이미지의 너비이고, <span class="math math-inline">s</span>는 스케일 계수(Scale Factor)이다. 핵심은 <span class="math math-inline">s</span>를 고정하지 않고 확률 분포 <span class="math math-inline">p</span>에 따라 샘플링하는 것이다.<br />
<span class="math math-display">
s \in (c+r, c+2r), \quad p = p_l
</span><br />
이러한 확률적 샘플링 전략은 생성된 데이터셋이 다양한 베이스라인(Camera Baseline)과 초점 거리(Focal Length)를 가진 가상의 카메라 설정을 포괄하도록 한다. 이는 모델이 매우 가까운 물체(큰 시차)부터 아주 먼 배경(작은 시차)까지 광범위한 시차 범위를 학습하게 하여, 실제 환경의 다양한 시나리오에 대처할 수 있는 능력을 부여한다.</p>
<h3>3.2  기하학적 워핑 및 마스크 생성</h3>
<p>생성된 유사 시차 맵 <span class="math math-inline">d</span>를 이용하여 왼쪽 이미지 <span class="math math-inline">I_l</span>을 오른쪽 시점의 가상 이미지 <span class="math math-inline">\tilde{I_r}</span>로 워핑한다. 이 과정은 다음과 같은 수식으로 표현된다:<br />
<span class="math math-display">
\tilde{I_r}(x, y) = I_l(x + d(x, y), y)
</span><br />
이때 시점이 이동함에 따라 가려지는 영역과 새로 드러나는 영역이 발생한다. ZeroStereo는 두 가지 마스크를 생성한다:</p>
<ol>
<li><strong>비폐색 마스크 (Non-occlusion Mask, <span class="math math-inline">M_{noc}</span>):</strong> 왼쪽 이미지와 오른쪽 이미지 모두에서 보이는 픽셀 영역. 이 영역은 기하학적 일관성이 유지되어야 한다.</li>
<li><strong>인페인팅 마스크 (Inpainting Mask, <span class="math math-inline">M_{inp}</span>):</strong> 왼쪽 이미지에서는 보이지 않으나 오른쪽 이미지에서는 보여야 하는 영역. 즉, 워핑 후 빈 공간으로 남는 영역이다.</li>
</ol>
<h3>3.3  스테레오 특화 확산 인페인팅 (Stereo-Specific Diffusion Inpainting)</h3>
<p>워핑된 이미지 <span class="math math-inline">\tilde{I_r}</span>의 빈 공간(<span class="math math-inline">M_{inp}</span>)을 채우기 위해, ZeroStereo는 Stable Diffusion V2 Inpainting (SDv2I) 모델을 기반으로 한 미세 조정 모델을 사용한다.</p>
<p>기존의 StereoDiffusion과 같은 접근법은 사전 학습된(Pre-trained) 모델을 그대로 사용하거나, 잠재 벡터를 최적화하는 방식을 취했다. 그러나 이는 두 가지 치명적인 문제를 야기한다:</p>
<ol>
<li><strong>널 텍스트 인버전(Null-text Inversion) 문제:</strong> 텍스트 조건 없이 이미지를 생성할 때, 원본 이미지의 내용이 변질될 수 있다. 예를 들어, 왼쪽 이미지에는 없던 돌이나 풀이 오른쪽 이미지에 갑자기 생성되는 경우이다. 이는 스테레오 매칭 학습에 치명적인 노이즈로 작용한다.</li>
<li><strong>기하학적 불일치:</strong> 일반적인 인페인팅 모델은 “예쁜” 이미지를 만드는 데 집중하므로, 3D 구조를 무시하고 배경을 채우는 경향이 있다.</li>
</ol>
<p>ZeroStereo는 이를 해결하기 위해 Scene Flow 데이터셋을 사용하여 U-Net의 파라미터를 미세 조정(Fine-tuning)했다. VAE(Variational Auto-Encoder)는 동결(Freeze)한 상태에서, 워핑된 이미지와 마스크, 그리고 노이즈가 추가된 잠재 벡터를 입력으로 받아 원본 오른쪽 이미지를 복원하도록 학습시킨다. 이 과정에서 모델은 단순한 텍스처 생성이 아니라, 깊이 불연속면(Depth Discontinuity)에서 배경이 어떻게 자연스럽게 이어지는지에 대한 기하학적 패턴을 학습하게 된다. 결과적으로 ZeroStereo의 인페인팅 모델은 유령 효과(Ghosting)를 최소화하고, 시맨틱 구조를 보존하는 고품질의 텍스처를 생성한다.</p>
<h3>3.4  훈련 없는 신뢰도 생성 (Training-Free Confidence Generation, TCG)</h3>
<p>아무리 뛰어난 MDE 모델이라도 완벽할 수는 없다. 특히 하늘, 유리, 얇은 전선 등은 깊이 추정이 불안정한 대표적인 영역이다. 이러한 부정확한 깊이 정보가 스테레오 매칭 모델의 정답 라벨로 사용되면 성능 저하를 초래한다. 기존 연구들은 별도의 신뢰도 추정 네트워크를 학습시키곤 했으나, 이는 추가적인 계산 비용과 데이터셋을 요구한다.</p>
<p>ZeroStereo는 물리적 일관성을 이용한 기발한 <strong>훈련 없는 신뢰도 생성(TCG)</strong> 기법을 도입했다. 핵심 아이디어는 “이미지를 좌우 반전시키더라도, 픽셀 간의 상대적 깊이 관계는 변하지 않아야 한다“는 것이다.</p>
<ol>
<li>
<p>왼쪽 이미지 <span class="math math-inline">I_l</span>의 깊이 맵 <span class="math math-inline">D</span>를 추정한다.</p>
</li>
<li>
<p><span class="math math-inline">I_l</span>을 좌우 반전시킨 <span class="math math-inline">I&#39;_l</span>에 대해 깊이 맵 <span class="math math-inline">D&#39;</span>를 추정한다.</p>
</li>
<li>
<p><span class="math math-inline">D&#39;</span>를 다시 원래대로 반전시킨 <span class="math math-inline">H^{-1}(D&#39;)</span>와 <span class="math math-inline">D</span>를 비교한다.<br />
<span class="math math-display">
u = 1 - |D - H^{-1}(D&#39;)|
</span></p>
<p><span class="math math-display">
C = \frac{u - \min(u)}{\max(u) - \min(u)}
</span></p>
</li>
</ol>
<p>이 신뢰도 맵 <span class="math math-inline">C</span>는 깊이 추정이 불안정한 영역(주로 객체의 경계선이나 텍스처가 없는 영역)에서 낮은 값을 가지며, 이를 통해 학습 시 해당 영역의 손실(Loss) 가중치를 낮추어 모델이 잘못된 정보를 학습하는 것을 방지한다.</p>
<h3>3.5  복합 손실 함수 (Composite Loss Function)</h3>
<p>최종 스테레오 매칭 모델 학습에는 다음과 같은 복합 손실 함수 <span class="math math-inline">L_{Zero}</span>가 사용된다.<br />
<span class="math math-display">
L_{Zero} = C \odot L_d + \mu \cdot (1 - C) \odot L_{np}
</span></p>
<ul>
<li><strong><span class="math math-inline">L_d</span> (Disparity Loss):</strong> 생성된 유사 시차 <span class="math math-inline">d</span>와 모델 예측 시차 <span class="math math-inline">\tilde{d}</span> 간의 L1 거리이다. 신뢰도 <span class="math math-inline">C</span>가 높은 영역에서만 강하게 작용하여, 확실한 기하학적 정보만을 학습하도록 유도한다.</li>
<li><strong><span class="math math-inline">L_{np}</span> (Non-Photometric/Consistency Loss):</strong> 신뢰도가 낮은 영역에서는 시차 자체보다는 다른 보조적인 일관성을 유지하도록 하는 항으로 해석된다 (구체적인 수식은 논문 원문의 맥락에 따라 광학적 일관성이나 평활도 제약일 수 있음). <span class="math math-inline">\mu</span>는 두 항 사이의 균형을 맞추는 하이퍼파라미터로, 본 연구에서는 0.1로 설정되었다.</li>
</ul>
<h2>4.  실험적 평가 및 검증 (Experimental Evaluation)</h2>
<p>ZeroStereo의 성능을 검증하기 위해 연구진은 “제로샷 일반화(Zero-shot Generalization)” 프로토콜을 채택했다. 즉, 모델은 ZeroStereo가 생성한 데이터셋(MfS35K)으로만 학습되며, 평가 시에는 KITTI, ETH3D, Middlebury 등 실제 데이터셋에 대해 어떠한 추가 학습(Fine-tuning) 없이 바로 테스트된다. 이는 모델의 진정한 범용성을 평가하는 가장 가혹하고 엄격한 기준이다.</p>
<h3>4.1  데이터셋 및 실험 환경</h3>
<ul>
<li><strong>생성 데이터셋 (MfS35K):</strong> ZeroStereo 파이프라인을 통해 생성된 35,000장의 스테레오 이미지 쌍. 베이스라인 모델인 DAv2를 사용하여 깊이를 추출하고, SDv2I를 미세 조정하여 인페인팅을 수행했다.</li>
<li><strong>평가 데이터셋:</strong></li>
<li><strong>KITTI 2012/2015:</strong> 자율주행 환경을 대표하는 데이터셋.</li>
<li><strong>ETH3D:</strong> 실내외의 다양한 환경과 복잡한 기하학적 구조를 포함.</li>
<li><strong>Middlebury:</strong> 고해상도 실내 이미지로, 정밀한 시차 추정 능력을 요구함.</li>
<li><strong>DrivingStereo:</strong> 다양한 날씨와 조명 조건을 포함한 대규모 주행 데이터.</li>
</ul>
<h3>4.2  정량적 성과 분석 (Quantitative Analysis)</h3>
<p>ZeroStereo 데이터로 학습된 RAFT-Stereo(Zero-RAFT-Stereo)와 IGEV-Stereo(Zero-IGEV-Stereo)는 기존의 합성 데이터셋(Scene Flow)으로 학습된 모델들을 압도하는 성능을 보여주었다.</p>
<p><strong>표 1. 제로샷 일반화 성능 비교 (EPE: End-Point Error, 낮을수록 우수)</strong></p>
<table><thead><tr><th><strong>모델 (학습 데이터)</strong></th><th><strong>KITTI 2015 (All)</strong></th><th><strong>KITTI 2015 (Noc)</strong></th><th><strong>ETH3D (All)</strong></th><th><strong>Middlebury-T (Half)</strong></th></tr></thead><tbody>
<tr><td><strong>RAFT-Stereo (Scene Flow)</strong></td><td>5.67</td><td>4.89</td><td>10.23</td><td>15.34</td></tr>
<tr><td><strong>FoundationStereo</strong></td><td>4.69</td><td>-</td><td>-</td><td>-</td></tr>
<tr><td><strong>Zero-RAFT-Stereo (Ours)</strong></td><td><strong>4.53</strong></td><td><strong>4.33</strong></td><td><strong>7.24</strong></td><td><strong>7.86</strong></td></tr>
</tbody></table>
<p>위 표에서 확인할 수 있듯이, Zero-RAFT-Stereo는 모든 벤치마크에서 베이스라인 대비 현저히 낮은 에러율(EPE)을 기록했다. 특히 <strong>ETH3D</strong>와 <strong>Middlebury</strong>에서의 성능 향상이 두드러지는데, 이는 ADS 모듈이 다양한 스케일의 시차를 효과적으로 생성해냈음을 시사한다. 기존 모델들이 Scene Flow의 특정 시차 범위에 과적합되어 새로운 환경에서 실패했던 것과 대조적이다. KITTI 2015에서도 4.53의 EPE를 기록하며, 대규모 실제 데이터를 사용하지 않고도 SOTA급의 제로샷 성능을 달성할 수 있음을 입증했다.</p>
<h3>4.3  비교 분석: ZeroStereo vs. StereoDiffusion vs. AdaMPI</h3>
<p>본 연구에서는 ZeroStereo의 우수성을 입증하기 위해 다른 생성형 방식들과의 비교 실험도 수행했다.</p>
<p><strong>표 2. 생성 방식에 따른 시차 추정 오류 비교 (KITTI 2015)</strong></p>
<table><thead><tr><th><strong>생성 방식</strong></th><th><strong>EPE (All)</strong></th><th><strong>특징 및 한계점</strong></th></tr></thead><tbody>
<tr><td><strong>AdaMPI</strong></td><td>6.44</td><td>카메라 이동 시 꼬리끌림(Trailing) 및 유령 효과 발생. 기하학적 부정확성.</td></tr>
<tr><td><strong>StereoDiffusion</strong></td><td>8.66</td><td>널 텍스트 인버전 문제로 원본 내용 변질. 얇은 구조물 뭉개짐. 높은 계산 비용.</td></tr>
<tr><td><strong>ZeroStereo (Fine-tuned)</strong></td><td><strong>4.53</strong></td><td>미세 조정된 인페인팅으로 기하학적 일관성 유지. 아티팩트 최소화.</td></tr>
</tbody></table>
<ul>
<li><strong>AdaMPI의 한계:</strong> MPI 기반 방식은 깊이 레이어가 분리되는 경계면에서 픽셀이 늘어지거나 찢어지는 현상이 발생한다. 이를 학습한 모델은 물체의 경계를 정확히 찾지 못하고 흐릿하게 예측하는 경향을 보였다.</li>
<li><strong>StereoDiffusion의 한계:</strong> 사전 학습된 확산 모델은 텍스트 프롬프트 없이 이미지를 생성할 때 불안정하다. 실험 결과, StereoDiffusion으로 생성된 이미지는 시맨틱 구조(Semantic Structure)가 자주 붕괴되었으며, 이는 EPE가 8.66으로 치솟는 결과로 이어졌다. 또한, 이미지 한 장을 생성하는 데 약 30초가 소요되어 데이터셋 구축 효율성 측면에서도 ZeroStereo(최적화된 파이프라인)에 뒤쳐진다.</li>
</ul>
<h3>4.4  특수 도메인 사례 연구: 임업(Forestry) 환경</h3>
<p>ZeroStereo의 진가는 정형화된 도시 환경을 벗어났을 때 더욱 빛을 발한다. 관련 연구 1에 따르면, 드론을 이용한 산림 관리와 같은 임업 애플리케이션에서는 얇은 나뭇가지, 빽빽한 잎사귀, 불규칙한 조명 등으로 인해 기존 스테레오 모델들이 참패를 겪는다. 특히 RAFT-Stereo 베이스라인 모델은 이러한 환경에서 **음수 시차(Negative Disparity)**를 예측하거나, 전체 픽셀의 98%에서 오류를 범하는 치명적인 결함(Catastrophic Failure)을 보이기도 했다.</p>
<p>반면, ZeroStereo 파이프라인으로 학습된 모델은 이러한 복잡한 구조(Thin Structures)를 보존하는 능력이 탁월하다. 이는 DAv2가 제공하는 정교한 엣지(Edge) 정보와, TCG 모듈이 신뢰할 수 없는 잎사귀 사이의 영역을 효과적으로 마스킹하여 학습에서 배제했기 때문이다. 이는 ZeroStereo가 단순히 자율주행뿐만 아니라, 농업, 재난 구조, 수중 탐사 등 “In-the-wild” 환경을 위한 로봇 시각 시스템의 핵심 솔루션이 될 수 있음을 시사한다.</p>
<h2>5.  한계점 및 비판적 고찰 (Limitations &amp; Critical Critique)</h2>
<p>ZeroStereo가 스테레오 매칭 데이터 생성의 새로운 지평을 열었음은 분명하나, 여전히 해결해야 할 과제와 한계점이 존재한다.</p>
<h3>5.1  블리딩 아티팩트 (Bleeding Artifacts)와 보간 문제</h3>
<p>경쟁 연구인 <strong>StereoSpace</strong> 2에서는 ZeroStereo가 생성한 이미지에서 전경의 색상이 배경으로 번지는 ’블리딩 아티팩트’가 관찰된다고 지적했다. 이는 확산 모델 기반 인페인팅의 본질적인 특성인 ’부드러움(Softness)’에서 기인한다. 확산 모델은 노이즈를 제거하며 이미지를 생성하기 때문에, 픽셀 단위로 칼같이 떨어지는 깊이 불연속면(Depth Discontinuity)을 완벽하게 재현하기 어렵다. 이는 매우 정밀한 경계선 검출이 필요한 응용 분야에서는 약점이 될 수 있다.</p>
<h3>5.2  기반 모델 의존성 (Dependency on Foundation Models)</h3>
<p>ZeroStereo의 성능은 전적으로 <strong>Depth Anything V2</strong>의 성능에 상한선(Upper Bound)이 걸려있다. 만약 DAv2가 거울을 창문으로 오인하거나, 투명한 물체의 깊이를 잘못 추정한다면, ZeroStereo는 이를 보정할 방법이 없다. TCG가 신뢰도를 낮출 수는 있지만, 근본적으로 올바른 깊이 정보를 생성해내지는 못한다. 즉, “Garbage In, Garbage Out“의 법칙에서 자유로울 수 없다.</p>
<h3>5.3  계산 비용과 실시간성 부재</h3>
<p>ZeroStereo는 데이터 생성 파이프라인이므로, 최종 학습된 모델(RAFT-Stereo 등)의 추론 속도에는 영향을 주지 않는다. 그러나 <strong>데이터 생성 과정 자체</strong>는 여전히 무겁다. 확산 모델의 추론 과정은 반복적인 디노이징 스텝을 요구하므로, 수만 장의 데이터를 생성하기 위해서는 상당한 GPU 자원과 시간이 소요된다. 이는 로봇이 실시간으로 낯선 환경을 마주했을 때, 즉석에서 데이터를 생성하여 적응(Test-time Adaptation)하는 시나리오에는 적용하기 어렵게 만든다.</p>
<h2>6.  결론 및 향후 전망 (Conclusion &amp; Future Outlook)</h2>
<h3>6.1  연구의 요약 및 의의</h3>
<p>ZeroStereo는 데이터 희소성이라는 스테레오 매칭의 고질적인 난제를 <strong>생성형 AI</strong>를 통해 정면으로 돌파한 연구이다. (1) 단안 깊이 추정 파운데이션 모델의 기하학적 이해력과 (2) 확산 모델의 강력한 이미지 합성 능력을 결합하고, (3) ADS와 TCG라는 독창적인 제어 모듈을 통해 기존 합성 데이터의 한계를 뛰어넘는 고품질의 학습 데이터를 만들어냈다. 그 결과, 실제 정답 데이터 하나 없이도 KITTI, ETH3D 등 주요 벤치마크에서 SOTA 수준의 제로샷 성능을 달성했다. 이는 스테레오 매칭 연구의 패러다임이 ’모델 아키텍처 경쟁’에서 ’데이터 생성 및 품질 관리 경쟁’으로 이동하고 있음을 보여주는 중요한 이정표이다.</p>
<h3>6.2  향후 발전 방향</h3>
<p>향후 연구는 **동적 장면(Dynamic Scene)**에 대한 비디오 일관성 확보로 나아가야 한다. 현재 ZeroStereo는 정지 영상 처리에 국한되어 있으나, 실제 로봇 애플리케이션은 연속적인 비디오 입력을 다룬다. 시간 축에 따른 일관성을 유지하며 스테레오 비디오를 생성할 수 있다면, 자율주행 시뮬레이터의 현실성을 획기적으로 높일 수 있을 것이다. 또한, **Latent Consistency Model (LCM)**과 같은 고속 생성 모델을 도입하여 데이터 생성 속도를 단축시킨다면, 로봇이 스스로 데이터를 생성하고 학습하며 미지의 환경에 적응하는 ’자율 진화형 시각 시스템’의 구현도 가능할 것으로 전망된다.</p>
<p>ZeroStereo는 단순한 데이터 증강 도구를 넘어, 인공지능이 스스로 학습 데이터를 창조하고 자신의 인지 능력을 개선하는 <strong>Self-Improving AI</strong>의 가능성을 보여주었다는 점에서 그 학술적, 산업적 가치가 매우 크다고 할 수 있다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Generalization Evaluation of Deep Stereo Matching Methods for …, https://www.researchgate.net/publication/398312555_Generalization_Evaluation_of_Deep_Stereo_Matching_Methods_for_UAV-Based_Forestry_Applications</li>
<li>StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to …, https://www.researchgate.net/publication/398602380_StereoSpace_Depth-Free_Synthesis_of_Stereo_Geometry_via_End-to-End_Diffusion_in_a_Canonical_Space</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>