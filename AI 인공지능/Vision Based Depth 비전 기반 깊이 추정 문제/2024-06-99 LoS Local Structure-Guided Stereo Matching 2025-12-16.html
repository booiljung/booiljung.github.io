<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:LoS (Local Structure-Guided Stereo Matching)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>LoS (Local Structure-Guided Stereo Matching)</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">비전 기반 깊이 추정 (Vision Based Dept)</a> / <span>LoS (Local Structure-Guided Stereo Matching)</span></nav>
                </div>
            </header>
            <article>
                <h1>LoS (Local Structure-Guided Stereo Matching)</h1>
<p>2025-12-16, G30DR</p>
<h2>1.  서론 (Introduction)</h2>
<h3>1.1  스테레오 매칭의 기술적 배경과 난제</h3>
<p>스테레오 매칭(Stereo Matching)은 컴퓨터 비전 분야에서 가장 오랜 역사를 가진 핵심 문제 중 하나로, 정류(Rectified)된 두 장의 이미지(좌, 우)로부터 대응점(Correspondence)을 찾아 픽셀 단위의 시차(Disparity)를 추정하는 과정을 의미한다. 이를 통해 획득한 깊이(Depth) 정보는 자율 주행(Autonomous Driving), 로봇 공학(Robotics), 증강 현실(AR), 3차원 복원(3D Reconstruction) 등 공간 인지가 필수적인 다양한 응용 분야의 기반이 된다.1 이상적인 환경에서 스테레오 매칭은 에피폴라 기하학(Epipolar Geometry)에 의해 1차원 탐색 문제로 환원되지만, 실제 환경에서는 영상의 복잡성으로 인해 여전히 해결하기 어려운 난제들이 존재한다.</p>
<p>특히, 매칭의 모호함(Ambiguity)을 유발하는 ’도전적인 영역(Challenging Areas)’에서의 성능 저하는 스테레오 매칭 시스템의 신뢰성을 떨어뜨리는 주된 요인으로 작용한다. 이러한 영역은 크게 네 가지 범주로 분류된다.1 첫째, **가려짐 영역(Occluded Areas)**은 전경 객체에 의해 배경이 가려져 한쪽 뷰에서만 관측되는 영역으로, 대응점이 존재하지 않아 매칭 자체가 불가능하다. 둘째, **텍스처가 없는 영역(Textureless Areas)**은 흰 벽이나 도로 표면과 같이 픽셀 간의 구별이 어려운 균질한 영역으로, 잘못된 매칭(False Positive)이 발생하기 쉽다. 셋째, **반사 및 투명 표면(Reflective/Transparent Surfaces)**은 거울이나 유리창처럼 조명과 시점에 따라 겉보기(Appearance)가 달라지는 영역으로, 스테레오 매칭의 기본 가정인 광도 일관성(Photometric Consistency)을 위배한다. 넷째, **객체 경계(Object Boundaries)**는 깊이 불연속(Depth Discontinuity)이 발생하는 지점으로, 기존의 스무딩(Smoothing) 기법들이 경계를 뭉개버리는 오버 스무딩(Over-smoothing) 현상이 빈번하게 발생한다.</p>
<h3>1.2  기존 접근법의 한계와 패러다임의 변화</h3>
<p>딥러닝의 도입 이전에는 SGM(Semi-Global Matching)과 같은 최적화 기법이 주를 이루었으나, CNN(Convolutional Neural Networks)의 등장 이후 스테레오 매칭은 비약적인 발전을 이루었다. 초기 딥러닝 접근법은 주로 <strong>비용 볼륨 필터링(Cost Volume Filtering)</strong> 방식에 집중했다. GC-Net, PSMNet 등은 3D CNN을 활용하여 4D 비용 볼륨을 정규화하고 시차를 회귀하는 방식을 채택했다. 이 방식은 전역적인 컨텍스트를 잘 포착하지만, 3D 연산의 높은 메모리 소모량과 연산 비용으로 인해 고해상도 처리에 제약이 따르며, 미리 정의된 시차 범위(Pre-defined Disparity Range) 내에서만 추정이 가능하다는 구조적 한계를 지닌다.2</p>
<p>최근에는 광학 흐름(Optical Flow) 추정 모델인 RAFT(Recurrent All-Pairs Field Transforms)의 성공에 힘입어 <strong>반복적 최적화(Iterative Optimization)</strong> 방식이 새로운 표준으로 자리 잡았다. RAFT-Stereo나 CREStereo와 같은 모델들은 GRU(Gated Recurrent Unit)를 사용하여 시차 필드를 점진적으로 갱신하는 방식을 취한다.4 이 방식은 고정된 시차 범위의 제약 없이 연속적인 값을 추정할 수 있고 일반화 성능이 뛰어나다는 장점이 있다. 그러나 이러한 반복적 방법론 역시 도전적인 영역에서는 한계를 노출한다. 텍스처가 없거나 가려진 영역에서는 상관관계(Correlation) 신호가 약하거나 오염되어 있어, GRU가 올바른 방향으로 수렴하기 위해 수십 번 이상의 많은 반복(Iteration)을 필요로 하며, 이는 실시간성을 저해하는 요인이 된다.1</p>
<h3>1.3  LoS의 핵심 제안 및 연구 목적</h3>
<p>CVPR 2024에서 발표된 **LoS (Local Structure-Guided Stereo Matching)**는 기존 반복적 최적화 방법론의 한계를 극복하기 위해 제안되었다. LoS의 핵심 철학은 딥러닝 네트워크가 데이터로부터 암시적(Implicit)으로 구조를 학습하는 것에만 의존하지 않고, **국소 구조 정보(Local Structure Information, LSI)**를 명시적(Explicit)으로 정의하여 활용하는 데 있다.1</p>
<p>기존 연구들이 픽셀의 로컬 윈도우를 단순한 평면(Slant Plane)으로 가정하여 기하학적 제약을 가했던 것과 달리, LoS는 평면 가정의 한계를 넘어서는 더 정교한 구조 표현 방식을 도입했다. 또한, 신뢰할 수 있는 영역(Well-posed regions)의 정보를 불확실한 영역(Ill-posed regions)으로 효과적으로 전달하기 위한 <strong>국소 구조 기반 전파(Local Structure-Guided Propagation, LSGP)</strong> 모듈을 제안하였다.1 이는 텍스처가 없는 영역이나 가려진 영역의 시차를 주변의 확실한 구조 정보에 기반하여 보정함으로써, 수렴 속도를 높이고 경계 복원력을 획기적으로 개선한다.</p>
<p>본 보고서에서는 LoS의 기술적 원리, 네트워크 아키텍처, 학습 전략, 그리고 다양한 벤치마크에서의 실험적 성능을 심층적으로 분석한다. 또한, 2025년 최신 연구 동향(MonSter, DEFOM-Stereo 등)과 비교하여 LoS가 스테레오 매칭 기술 발전에 미친 영향과 그 위상을 재조명한다.</p>
<h2>2.  관련 연구 및 기술적 배경 (Related Work)</h2>
<h3>2.1  비용 볼륨 필터링 기반 방법론 (Filtering-based Methods)</h3>
<p>스테레오 매칭의 전통적인 딥러닝 파이프라인은 ’특징 추출 - 비용 볼륨 구축 - 비용 집계 - 시차 회귀’의 단계를 따른다. MC-CNN과 같은 초기 연구는 이미지 패치 간의 유사도를 측정하는 데 CNN을 사용했다. 이후 GC-Net과 PSMNet은 좌우 이미지 특징 맵을 연결(Concatenation)하여 4D 비용 볼륨을 생성하고, 이를 3D CNN(예: 3D Hourglass Network)으로 처리하여 비용 집계(Cost Aggregation)를 수행했다.3</p>
<ul>
<li><strong>3D CNN의 역할:</strong> 3D CNN은 비용 볼륨 내의 노이즈를 제거하고 공간적/시차적 맥락을 통합하여 매칭의 정확도를 높인다. 특히, 텍스처가 부족한 영역에서 주변 정보를 활용하여 값을 채워 넣는 역할을 한다.</li>
<li><strong>한계점:</strong> 3D 합성곱 연산은 <span class="math math-inline">O(D \times H \times W)</span>의 복잡도를 가지므로 메모리와 연산량이 매우 크다. 이는 고해상도 이미지 처리를 어렵게 만들고, 실시간 응용에 걸림돌이 된다. 또한, 비용 볼륨의 시차 차원(<span class="math math-inline">D</span>)이 고정되어 있어, 이를 초과하는 근거리 물체는 탐지할 수 없다.2</li>
</ul>
<h3>2.2  반복적 최적화 기반 방법론 (Optimization-based Methods)</h3>
<p>RAFT-Stereo의 등장은 3D CNN의 제약에서 벗어나는 계기가 되었다. 이 접근법은 전체 시차 범위에 대한 비용 볼륨을 한 번에 처리하는 대신, 현재 추정된 시차를 중심으로 좁은 범위의 상관관계(Correlation)를 조회(Lookup)하고, 이를 바탕으로 시차의 변화량(<span class="math math-inline">\Delta d</span>)을 예측하여 업데이트하는 방식을 취한다.7</p>
<ul>
<li><strong>다중 스케일 GRU (Multi-level GRU):</strong> RAFT-Stereo는 다양한 해상도의 GRU를 사용하여 큰 움직임과 미세한 디테일을 동시에 포착한다.</li>
<li><strong>일반화 성능:</strong> 고정된 시차 범위에 얽매이지 않으므로, 학습 데이터와 다른 시차 분포를 가진 새로운 환경(Domain Generalization)에서도 강건한 성능을 보인다.</li>
<li><strong>한계점:</strong> 최적화 기반 방법은 본질적으로 반복적이다. 특히 모호한 영역에서는 GRU가 정확한 해를 찾기 위해 많은 반복을 수행해야 하며, 이는 추론 시간 증가로 이어진다. 또한, 텍스처가 없는 영역에서는 상관관계 값 자체가 평탄(Flat)하여 유용한 그래디언트를 제공하지 못하는 경우가 많다.2</li>
</ul>
<h3>2.3  국소 구조(Local Structure)의 활용</h3>
<p>전통적인 컴퓨터 비전에서 ‘경사 평면(Slant Plane)’ 모델은 널리 사용되어 왔다. PatchMatch Stereo나 Superpixel 기반 방법들은 픽셀 그룹이 3D 공간상에서 평면을 이룬다고 가정하고, 평면의 파라미터(법선 벡터 등)를 추정하여 시차를 구했다.1 최근 딥러닝 연구들(예: HITNet)에서도 평면 가정을 도입하여 매칭 성능을 개선하려는 시도가 있었다.</p>
<p>그러나 단순한 평면 가정은 곡면(Curved Surface)이나 객체 경계와 같은 비평면(Non-planar) 구조를 정밀하게 표현하지 못한다는 단점이 있다. LoS는 이러한 평면 모델을 확장하여, 평면 성분뿐만 아니라 잔차 오프셋과 픽셀 간 관계까지 포함하는 포괄적인 국소 구조 정보(LSI)를 정의함으로써 이 문제를 해결하고자 했다.1</p>
<h2>3.  방법론 (Methodology): LoS의 핵심 기제 분석</h2>
<p>LoS는 기존 RAFT-Stereo의 반복적 프레임워크를 계승하되, 시차 업데이트 과정에 구조적 가이드를 주입하는 <strong>LSGP (Local Structure-Guided Propagation)</strong> 모듈을 통합하였다. 이 섹션에서는 LoS의 핵심 구성 요소인 LSI와 LSGP의 수학적 정의와 작동 원리를 상세히 분석한다.</p>
<h3>3.1  국소 구조 정보 (Local Structure Information, LSI)</h3>
<p>LoS는 픽셀 <span class="math math-inline">p=(h, w)</span>를 중심으로 하는 <span class="math math-inline">3 \times 3</span> 이웃 윈도우 <span class="math math-inline">N(p)</span> 내의 기하학적 구조를 설명하기 위해 LSI <span class="math math-inline">S(p)</span>를 도입한다. LSI는 단순히 시차 값만을 다루는 것이 아니라, 픽셀 간의 기하학적 연결성을 명시적으로 모델링한다. LSI는 다음과 같은 세 가지 요소로 정의된다: <span class="math math-inline">S = \{G, O, R\}</span>.1</p>
<ol>
<li><strong>시차 기울기 (Disparity Gradient, <span class="math math-inline">G</span>):</strong> <span class="math math-inline">H_p \times W_p \times 2</span> 차원 텐서로, 수평(<span class="math math-inline">x</span>) 및 수직(<span class="math math-inline">y</span>) 방향의 시차 변화율을 나타낸다. 이는 픽셀 <span class="math math-inline">p</span>에서의 접평면(Tangent Plane)을 1차적으로 근사한다. 기존의 Slant Plane 모델과 유사한 역할을 수행한다.</li>
<li><strong>시차 오프셋 (Disparity Offset, <span class="math math-inline">O</span>):</strong> <span class="math math-inline">H_p \times W_p \times 9</span> 차원 텐서이다. 중심 픽셀 <span class="math math-inline">p</span>와 이웃 픽셀 <span class="math math-inline">p_i \in N(p)</span> 사이의 시차 차이 중, 평면 모델(<span class="math math-inline">G</span>)로 설명되지 않는 잔차(Residual) 성분을 나타낸다. 즉, <span class="math math-inline">O</span>는 평면 위로 튀어나오거나 들어간 미세한 요철, 또는 곡면 성분을 보정하는 역할을 하여 비평면 구조를 정밀하게 표현한다.</li>
<li><strong>국소 관계 (Local Relations, <span class="math math-inline">R</span>):</strong> <span class="math math-inline">H_p \times W_p \times 9</span> 차원 텐서로, 중심 픽셀 <span class="math math-inline">p</span>와 이웃 픽셀 <span class="math math-inline">p_i</span> 간의 <strong>친밀도(Affinity)</strong> 또는 **신뢰도(Reliability)**를 나타낸다. 이는 정보 전파 시 어떤 이웃의 정보를 더 많이 받아들일지를 결정하는 가중치의 기초가 된다. <span class="math math-inline">R</span>은 이미지의 색상 유사도, 텍스처 정보 등을 바탕으로 네트워크가 학습한다.</li>
</ol>
<p>이 세 가지 요소를 결합하여, 중심 픽셀 <span class="math math-inline">p</span>에서 바라본 이웃 픽셀 <span class="math math-inline">p_i</span>의 시차 오프셋 <span class="math math-inline">o(p, p_i)</span>는 다음과 같이 모델링된다 1:<br />
<span class="math math-display">
o(p, p_i) = G(p) \cdot \Delta p_i + O(p, p_i)
</span><br />
여기서 <span class="math math-inline">\Delta p_i = p - p_i</span>는 픽셀 좌표 공간에서의 변위 벡터이다. 이 수식은 테일러 급수 전개(Taylor Series Expansion)와 유사한 형태를 띠며, 1차 항(<span class="math math-inline">G \cdot \Delta p_i</span>)에 고차 보정 항(<span class="math math-inline">O</span>)을 더하여 국소적인 기하학적 구조를 완벽에 가깝게 묘사한다.</p>
<h3>3.2  국소 구조 기반 전파 (Local Structure-Guided Propagation, LSGP)</h3>
<p>LSGP는 LoS의 핵심 엔진으로, 추정된 LSI를 활용하여 시차 맵(<span class="math math-inline">D</span>)과 불확실성 맵(<span class="math math-inline">\delta</span>)을 갱신하는 과정이다. 기존의 ConvGRU가 비용 볼륨의 정보에만 의존하여 시차를 업데이트했다면, LSGP는 픽셀 간의 구조적 관계를 이용하여 정보를 능동적으로 전파한다.1</p>
<h4>3.2.1  전파 메커니즘 (Propagation Mechanism)</h4>
<p><span class="math math-inline">k</span>번째 반복(Iteration) 단계에서 픽셀 <span class="math math-inline">p</span>의 시차 <span class="math math-inline">D_k(p)</span>와 불확실성 <span class="math math-inline">\delta_k(p)</span>는 이전 단계(<span class="math math-inline">k-1</span>)의 정보를 바탕으로 다음과 같이 업데이트된다:<br />
<span class="math math-display">
D_k(p) = \sum_{p_i \in N(p)} w_k(p, p_i) (D_{k-1}(p_i) + o(p, p_i))
</span></p>
<p><span class="math math-display">
\delta_k(p) = \sum_{p_i \in N(p)} w_k(p, p_i) \delta_{k-1}(p_i)
</span></p>
<p>여기서 <span class="math math-inline">w_k(p, p_i)</span>는 정규화된 전파 가중치(<span class="math math-inline">\sum w_k = 1</span>)이다. 이 식의 물리적 의미는 매우 직관적이다. 픽셀 <span class="math math-inline">p</span>의 새로운 시차 값은 주변 이웃 <span class="math math-inline">p_i</span>들이 가지고 있던 시차 값(<span class="math math-inline">D_{k-1}(p_i)</span>)에 구조적 차이(<span class="math math-inline">o(p, p_i)</span>)를 반영하여 보정한 후, 이를 가중 평균한 값으로 결정된다. 즉, 내 정보가 불확실할 때, 믿을 수 있는 이웃의 정보를 가져와서 나에게 맞게 수정하여 사용하는 것이다.</p>
<h4>3.2.2  선택적 전파와 가중치 산정 (Selective Propagation &amp; Weighting)</h4>
<p>무분별한 정보 전파는 오히려 정확한 경계 정보를 훼손할 수 있다(Over-smoothing). 이를 방지하기 위해 LoS는 불확실성(<span class="math math-inline">\delta</span>)에 기반한 <strong>선택적 전파 전략</strong>을 사용한다. 이웃 픽셀 집합 <span class="math math-inline">N(p)</span>를 두 그룹으로 나눈다 1:</p>
<ul>
<li><strong>저불확실성 집합 (<span class="math math-inline">N+</span>):</strong> <span class="math math-inline">\delta_{k-1}(p_i) \le \delta_{k-1}(p) + \epsilon</span>. 즉, 중심 픽셀 <span class="math math-inline">p</span>보다 신뢰도가 높거나 비슷한 이웃들이다. 이들의 정보는 유익하므로 전파에 포함시킨다.</li>
<li><strong>고불확실성 집합 (<span class="math math-inline">N-</span>):</strong> 불확실성이 중심 픽셀보다 현저히 높은 이웃들이다. 이들의 정보는 노이즈일 가능성이 높으므로 전파에서 제외한다.</li>
</ul>
<p>전파 가중치 <span class="math math-inline">w_k(p, p_i)</span>는 다음과 같이 계산된다:<br />
<span class="math math-display">
w_k(p, p_i) = \begin{cases} \frac{\exp(\hat{\delta}_{k-1}(p_i) \cdot r(p, p_i))}{\sum_{p_j \in N+} \exp(\hat{\delta}_{k-1}(p_j) \cdot r(p, p_j))} &amp; \text{if } p_i \in N+ \\ 0 &amp; \text{if } p_i \in N- \end{cases}
</span><br />
여기서 <span class="math math-inline">r(p, p_i) = R(p, p_i) - \max(R(p)) - 1</span>로 정의되며, 수치적 안정성을 위해 항상 음수 값을 갖도록 제한된다.1 이 수식은 불확실성 <span class="math math-inline">\delta</span>가 낮을수록, 그리고 관계 <span class="math math-inline">r</span>이 강할수록(0에 가까울수록) 더 큰 가중치를 부여한다. 결과적으로 LSGP는 “확실한 곳에서 불확실한 곳으로” 정보가 흐르게 하는 유향 그래프(Directed Graph)와 같은 역할을 수행하며, 텍스처가 없는 영역의 내부를 경계의 정보로 채우는(In-painting) 효과를 낸다.</p>
<h3>3.3  네트워크 아키텍처 및 구현 (Network Architecture)</h3>
<p>LoS 모델은 크게 초기화 단계와 최적화 단계로 구성된다.1</p>
<ol>
<li><strong>특징 추출 (Feature Extraction):</strong> 2D CNN 백본(Backbone)을 사용하여 입력 이미지로부터 특징 맵을 추출한다.</li>
<li><strong>초기화 단계 (Initialization Step):</strong> 1/4 해상도에서 초기 시차(<span class="math math-inline">D_0</span>), LSI(<span class="math math-inline">S_0</span>), 불확실성(<span class="math math-inline">\delta_0</span>)을 추정한다. 일부 구현에서는 단안 깊이(Monocular Depth) 추정 결과를 초기 값의 프라이어(Prior)로 활용하여 초기 수렴 속도를 높이기도 한다.10 초기화 단계에서도 1회의 LSGP를 수행하여 초기 맵의 품질을 개선한다.</li>
<li><strong>반복적 최적화 (Iterative Optimization):</strong> RAFT-Stereo와 유사한 다중 레벨 ConvGRU 구조를 사용하지만, 입출력이 확장되었다. GRU는 시차 잔차(<span class="math math-inline">\Delta D</span>)뿐만 아니라 LSI의 잔차(<span class="math math-inline">\Delta G, \Delta O</span>)와 불확실성(<span class="math math-inline">\delta</span>)을 매 반복마다 예측한다. 각 GRU 업데이트 직후 LSGP 모듈이 실행되어 시차 맵을 구조적으로 정제한다.</li>
<li><strong>업샘플링 (Upsampling):</strong> 최종적으로 1/4 해상도의 시차 맵을 원본 해상도로 복원한다. 이때 학습된 가중치를 이용한 볼록 업샘플링(Convex Upsampling)을 적용하여 미세한 경계 정보를 보존한다.</li>
</ol>
<h3>3.4  손실 함수 (Loss Function)</h3>
<p>LoS는 지도 학습(Supervised Learning)을 통해 훈련된다. 전체 반복 과정(<span class="math math-inline">N</span>번)에서 생성된 모든 중간 시차 맵 <span class="math math-inline">{D_1,..., D_N}</span>에 대해 정답(Ground Truth, <span class="math math-inline">D_{gt}</span>)과의 차이를 최소화하는 방향으로 학습이 진행된다. 총 손실 함수 <span class="math math-inline">L_{total}</span>은 다음과 같다 11:<br />
<span class="math math-display">
L_{total} = \sum_{i=1}^{N} \gamma^{N-i} \| D_i - D_{gt} \|_1
</span></p>
<ul>
<li><strong>Smooth L1 Loss:</strong> <span class="math math-inline">\| \cdot \|_1</span>은 이상치(Outlier)에 강건한 Smooth L1 Loss를 주로 사용한다.</li>
<li><strong>지수 가중치 감소 (Exponential Decay, <span class="math math-inline">\gamma</span>):</strong> <span class="math math-inline">\gamma</span>는 일반적으로 0.9로 설정된다. <span class="math math-inline">i</span>가 <span class="math math-inline">N</span>에 가까울수록, 즉 반복 후반부의 결과일수록 <span class="math math-inline">\gamma^{N-i}</span> 값이 커져 더 큰 가중치가 부여된다. 이는 최종 결과물의 정확도를 우선시하는 전략이다.</li>
<li><strong>LSI의 학습:</strong> 흥미로운 점은 <span class="math math-inline">G, O, R</span>과 같은 LSI 요소들에 대한 직접적인 정답(Ground Truth)이 없다는 것이다. 이들은 시차 정확도(<span class="math math-inline">D</span>)를 높이는 과정에서 역전파(Backpropagation)를 통해 간접적으로 학습된다. 즉, LSI는 시차 추정을 돕기 위한 잠재 변수(Latent Variable)로서 기능한다.</li>
</ul>
<h2>4.  실험 결과 및 성능 분석 (Experimental Analysis)</h2>
<p>LoS는 스테레오 매칭 분야의 주요 벤치마크인 Scene Flow, KITTI 2012/2015, Middlebury, ETH3D 등에서 평가되었으며, 특히 일반화 성능과 디테일 복원 능력에서 탁월한 성과를 입증했다.</p>
<h3>4.1  데이터셋 및 실험 환경</h3>
<ul>
<li><strong>Scene Flow:</strong> 35,000쌍 이상의 합성 이미지로 구성된 대규모 데이터셋으로, 모든 모델의 사전 학습(Pre-training)에 사용된다.</li>
<li><strong>KITTI 2012 &amp; 2015:</strong> 실제 도로 주행 환경에서 취득한 데이터셋으로, LiDAR로 획득한 희소한(Sparse) 정답을 제공한다. 반사 영역이나 얇은 객체(신호등, 표지판)가 많아 난이도가 높다.</li>
<li><strong>Middlebury 2014:</strong> 고해상도 실내 데이터셋으로, 복잡한 구조와 매우 높은 시차 범위를 가진다.</li>
<li><strong>ETH3D:</strong> 실내외 다양한 환경을 포함하며, 텍스처가 부족한 영역이 많아 저주파(Low-frequency) 정보 처리가 중요하다.</li>
</ul>
<p>학습 시 데이터 증강(Augmentation) 기법으로 비대칭 색상 변환(Asymmetric Chromatic Augmentation)과 무작위 삭제(Erasure) 등이 적용되어 모델의 강건성을 높였다.10</p>
<h3>4.2  정량적 성능 평가 (Quantitative Evaluation)</h3>
<p>다음은 주요 벤치마크에서의 성능 비교 결과이다. 표는 2024년 기준 최상위 모델들과의 비교를 보여준다 (수치가 낮을수록 우수함).</p>
<h4>4.2.1 표 1: KITTI 2015 벤치마크 성능 비교 (D1-all %)</h4>
<p>15</p>
<table><thead><tr><th><strong>Method</strong></th><th><strong>D1-bg (%)</strong></th><th><strong>D1-fg (%)</strong></th><th><strong>D1-all (%)</strong></th><th><strong>Runtime (s)</strong></th><th><strong>Environment</strong></th></tr></thead><tbody>
<tr><td>GwcNet</td><td>1.61</td><td>3.93</td><td>2.11</td><td>0.32</td><td>Nvidia Titan X</td></tr>
<tr><td>ACVNet</td><td>1.37</td><td>3.07</td><td>1.65</td><td>0.20</td><td>RTX 3090</td></tr>
<tr><td>CREStereo</td><td>1.54</td><td>2.86</td><td>1.69</td><td>0.41</td><td>RTX 3090</td></tr>
<tr><td>IGEV-Stereo</td><td>1.49</td><td>2.67</td><td>1.59</td><td>0.18</td><td>RTX 3090</td></tr>
<tr><td><strong>LoS (Ours)</strong></td><td><strong>1.52</strong></td><td><strong>2.81</strong></td><td><strong>1.65</strong></td><td><strong>0.40</strong></td><td><strong>RTX 3090</strong></td></tr>
<tr><td>MonSter (2025)</td><td>1.13</td><td>2.81</td><td>1.41</td><td>0.45</td><td>1 core @ 2.5Ghz</td></tr>
<tr><td>Wavelet-Stereo (2025)</td><td>1.14</td><td>2.60</td><td>1.38</td><td>0.58</td><td>1 core @ 2.5Ghz</td></tr>
</tbody></table>
<p><strong>분석:</strong></p>
<ul>
<li>LoS는 KITTI 2015에서 **D1-all 1.65%**를 기록하여, 당시 경쟁 모델인 ACVNet과 동등하며 CREStereo(1.69%)보다 우수한 성능을 보였다.</li>
<li>특히 주목할 점은 **D1-fg (전경 객체 오류율)**이다. LoS는 2.81%를 기록하여 움직이는 차량이나 보행자와 같은 동적 객체에 대해서도 안정적인 성능을 보였다. 이는 LSGP가 객체 경계에서의 오버 스무딩을 억제하고 디테일을 보존했기 때문이다.</li>
<li>2025년에 발표된 MonSter나 Wavelet-Stereo와 비교하면 약 0.2~0.3%p의 격차가 존재한다. 이는 최신 모델들이 단안 깊이 프라이어(Monocular Prior)나 주파수 분해(Frequency Decomposition)와 같은 새로운 패러다임을 도입했기 때문이나, LoS는 여전히 강력한 베이스라인으로서의 위치를 점하고 있다.16</li>
</ul>
<h4>4.2.2 표 2: ETH3D 및 Middlebury 벤치마크 성능 비교</h4>
<p>1</p>
<table><thead><tr><th><strong>Method</strong></th><th><strong>ETH3D (Bad 1.0 %)</strong></th><th><strong>Middlebury Half (Bad 2.0 %)</strong></th></tr></thead><tbody>
<tr><td>RAFT-Stereo</td><td>3.28</td><td>12.59</td></tr>
<tr><td>CREStereo</td><td>1.09</td><td>5.00</td></tr>
<tr><td>IGEV-Stereo</td><td>1.51</td><td>10.90</td></tr>
<tr><td><strong>LoS (Ours)</strong></td><td><strong>0.91</strong></td><td><strong>5.00 (approx)</strong></td></tr>
<tr><td>MonSter (2025)</td><td>0.46</td><td>7.05</td></tr>
</tbody></table>
<p><strong>분석:</strong></p>
<ul>
<li>LoS는 <strong>ETH3D 벤치마크</strong>에서 <strong>Bad 1.0</strong> 지표 기준 0.91%를 기록하며, CREStereo(1.09%)와 IGEV-Stereo(1.51%)를 제치고 최상위권 성적을 거두었다.16 ETH3D는 텍스처가 부족한 실내외 환경을 다수 포함하고 있어, LoS의 구조 기반 전파 전략이 텍스처리스 영역에서 얼마나 강력한지를 단적으로 보여준다.</li>
<li>Middlebury에서도 LoS는 매우 우수한 성능을 보였다. 특히 절반 해상도(Half-resolution) 평가에서 기존 방법들을 압도했다. 이는 고해상도 이미지의 복잡한 구조를 LSI가 효과적으로 모델링했음을 시사한다.</li>
</ul>
<h3>4.3  정성적 분석 (Qualitative Analysis)</h3>
<p>LoS의 진가는 수치보다 시각적 결과물에서 더욱 뚜렷하게 드러난다.1</p>
<ol>
<li><strong>가장자리 보존 (Edge Preservation):</strong> 얇은 기둥, 나뭇가지, 펜스 등 깊이 불연속이 심한 영역에서 기존 RAFT-Stereo는 경계를 뭉개거나(Blurring) 배경과 혼동하는 경향이 있었다. 반면 LoS는 LSGP를 통해 경계 정보를 인식하고(<span class="math math-inline">R</span> 텐서를 통해), 경계를 넘어선 정보 전파를 차단함으로써 날카로운(Sharp) 깊이 맵을 생성한다.</li>
<li><strong>텍스처리스 영역 복원 (Textureless Region Recovery):</strong> 흰 벽이나 아스팔트 도로와 같이 텍스처가 없는 영역에서 기존 모델들은 노이즈가 섞인 울퉁불퉁한 표면을 예측하곤 했다. LoS는 주변의 텍스처가 있는 영역(가령 벽의 모서리나 도로의 차선)으로부터 신뢰할 수 있는 깊이 정보를 전파받아(<span class="math math-inline">N+</span> 집합 활용), 매끄럽고 일관된 평면을 복원해낸다.</li>
<li><strong>반사 영역 처리 (Handling Reflections):</strong> 차량의 유리창이나 차체 표면의 반사광은 매칭을 방해하는 주요 요인이다. LoS는 기하학적 구조 정보에 기반하여 광도 일관성이 깨진 영역에서도 주변 구조와 어우러지는 합리적인 시차 값을 추정한다.</li>
</ol>
<h3>4.4  절제 연구 (Ablation Study)</h3>
<p>LoS 논문에서 수행한 절제 연구는 제안된 모듈들의 유효성을 입증한다.10</p>
<ul>
<li><strong>LSGP의 유무:</strong> LSGP를 제거하고 단순 ConvGRU만 사용했을 때, Middlebury 데이터셋에서 Bad 2.0 오류가 26.6% 이상 급증했다. 이는 LoS 성능 향상의 핵심 동력이 단순한 파라미터 증가가 아니라, 구조 기반의 명시적 전파 메커니즘에 있음을 보여준다.</li>
<li><strong>LSI 구성 요소의 영향:</strong> 시차 기울기(<span class="math math-inline">G</span>)만 사용하는 것보다, 오프셋(<span class="math math-inline">O</span>)과 관계(<span class="math math-inline">R</span>)를 모두 사용할 때 최적의 성능을 보였다. <span class="math math-inline">G</span>만으로는 평면 이외의 복잡한 곡면을 표현하기 어렵기 때문에, 오프셋 <span class="math math-inline">O</span>가 잔차를 보정해 주는 것이 필수적이다.</li>
<li><strong>반복 횟수 전략:</strong> GRU의 반복 횟수(<span class="math math-inline">N</span>)를 무작정 늘리는 것보다, LSGP 내부의 전파 횟수를 늘리는 것이 성능 대 연산 효율성 측면에서 더 유리한 것으로 나타났다.</li>
</ul>
<h2>5.  비교 분석 및 최신 연구 동향 (2025 Perspective)</h2>
<p>LoS는 2024년 시점에서 구조적 정보를 명시적으로 활용하는 새로운 패러다임을 제시하며 SOTA(State-of-the-Art)를 달성했다. 그러나 2025년 최신 연구들은 LoS의 접근법을 확장하거나 새로운 관점을 도입하여 성능을 더욱 끌어올리고 있다.</p>
<h3>5.1  LoS vs. IGEV-Stereo</h3>
<p>IGEV-Stereo는 **기하학 인코딩 볼륨(Geometry Encoding Volume)**을 도입하여 3D CNN의 장점(전역적 구조 파악)과 RAFT의 장점(반복적 정제)을 결합했다.18 IGEV는 비용 볼륨 자체를 강화하는 방식인 반면, LoS는 비용 볼륨 이후의 최적화 과정(Optimization Loop)에서 구조 정보를 주입하는 방식이다. KITTI 벤치마크에서는 두 모델이 엎치락뒤치락하지만, 메모리 효율성 측면에서는 3D CNN을 사용하는 IGEV보다 LoS가 더 유리할 수 있다.</p>
<h3>5.2  LoS vs. MonSter (2025)</h3>
<p>MonSter(Monocular Stereo)는 <strong>단안 깊이 추정(Monocular Depth Estimation)</strong> 네트워크의 결과를 강력한 프라이어(Prior)로 활용한다.17 LoS도 초기화 단계에서 단안 깊이 정보를 일부 활용하지만, MonSter는 이를 더 적극적으로 통합하여 스테레오 매칭이 실패하기 쉬운 가려짐 영역이나 텍스처리스 영역에서 획기적인 성능 향상을 이뤘다. 표 1에서 보듯 MonSter는 KITTI 2015 D1-all을 1.41%까지 낮추며 LoS(1.65%)와의 격차를 벌렸다. 이는 “구조 정보(Structure)“를 넘어 “의미론적 정보(Semantic/Prior)“의 결합이 차세대 트렌드임을 시사한다.</p>
<h3>5.3  LoS vs. DEFOM-Stereo 및 Wavelet-Stereo (2025)</h3>
<p>DEFOM-Stereo는 ’Depth Anything’과 같은 **파운데이션 모델(Foundation Model)**을 백본으로 사용하여 일반화 성능을 극대화했다.14 Wavelet-Stereo는 이미지와 비용 볼륨을 주파수 도메인으로 변환하여, 고주파(에지)와 저주파(평탄면) 성분을 분리 처리함으로써 수렴 불일치 문제를 해결했다.5</p>
<p>이러한 최신 연구들은 LoS가 제안한 “국소 구조의 명시적 활용“이라는 철학을 계승하면서도, 더 강력한 특징 추출기나 새로운 수학적 변환(Wavelet)을 도입하여 성능의 한계를 돌파하고 있다. 하지만 LoS가 제시한 **LSGP(전파 모듈)**의 개념은 여전히 유효하며, 많은 후속 연구들에서 변형된 형태로 차용되고 있다.</p>
<h2>6.  결론 및 향후 전망 (Conclusion)</h2>
<h3>6.1  연구 요약</h3>
<p>LoS(Local Structure-Guided Stereo Matching)는 스테레오 매칭의 고질적인 문제인 ’도전적인 영역(Ill-posed regions)’에서의 성능 저하를 해결하기 위해 **국소 구조 정보(LSI)**와 **국소 구조 기반 전파(LSGP)**라는 혁신적인 패러다임을 제시했다. 픽셀 간의 기하학적 관계를 기울기(<span class="math math-inline">G</span>), 오프셋(<span class="math math-inline">O</span>), 관계(<span class="math math-inline">R</span>)로 정교하게 모델링하고, 불확실성(<span class="math math-inline">\delta</span>)에 기반한 선택적 정보 전파를 수행함으로써, 텍스처가 없거나 구조가 복잡한 영역에서도 정확하고 일관된 시차를 추정해냈다.</p>
<h3>6.2  기술적 시사점</h3>
<p>LoS의 성공은 다음과 같은 기술적 통찰을 제공한다.</p>
<ol>
<li><strong>명시적 구조 모델링의 중요성:</strong> 딥러닝이 방대한 데이터로부터 모든 것을 암시적으로 학습할 수 있다는 믿음과 달리, 기하학적 제약 조건(Local Structure)을 네트워크 내부에 명시적으로 설계해 주는 것이 3D 비전 작업에서 효율적이고 정확함을 입증했다.</li>
<li><strong>불확실성(Uncertainty)의 능동적 활용:</strong> 단순히 값을 예측하는 것을 넘어, 예측의 신뢰도를 추정하고 이를 정보 흐름의 게이트(Gate)로 활용하는 메커니즘은 노이즈에 강건한 시스템을 구축하는 데 필수적이다.</li>
<li><strong>반복적 최적화의 진화:</strong> 단순한 잔차(Residual) 학습을 넘어, 반복 과정 내에 기하학적 전파(Propagation) 단계를 삽입함으로써 수렴 속도와 품질을 동시에 개선할 수 있음을 증명했다.</li>
</ol>
<h3>6.3  향후 연구 방향</h3>
<p>LoS 이후의 스테레오 매칭 기술은 단순히 더 깊은 네트워크를 쌓는 경쟁에서 벗어나, <strong>3D 기하학의 본질적 특성</strong>과 **외부 지식(Prior)**을 어떻게 효과적으로 융합할 것인가에 대한 고민으로 나아가고 있다. 향후에는 LoS의 구조적 접근법에 MonSter나 DEFOM과 같은 파운데이션 모델의 강력한 사전 정보가 결합되어, 인간의 인지 능력에 버금가는 강건한(Robust) 3D 지각 시스템으로 발전할 것으로 예상된다. 또한, 자율 주행과 같은 실시간 응용을 위해 LSGP와 같이 계산 효율적이면서도 고성능을 내는 경량화 모듈에 대한 연구가 지속될 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>LoS: Local Structure-Guided Stereo Matching - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2024/papers/Li_LoS_Local_Structure-Guided_Stereo_Matching_CVPR_2024_paper.pdf</li>
<li>LoS: Local Structure-Guided Stereo Matching - IEEE Computer Society, https://www.computer.org/csdl/proceedings-article/cvpr/2024/530000t746/20hQaCkDCM0</li>
<li>Optimizing 3D Convolutions on Stereo Matching for Resource …, https://kanazawa-u.repo.nii.ac.jp/record/62128/files/Full-N-1824042012-XIAO-JIANQIANG.pdf</li>
<li>fabiotosi92/Awesome-Deep-Stereo-Matching - GitHub, https://github.com/fabiotosi92/Awesome-Deep-Stereo-Matching</li>
<li>(PDF) A Wavelet-based Stereo Matching Framework for Solving …, https://www.researchgate.net/publication/392084957_A_Wavelet-based_Stereo_Matching_Framework_for_Solving_Frequency_Convergence_Inconsistency</li>
<li>Bilateral Grid Learning for Stereo Matching Networks, https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Bilateral_Grid_Learning_for_Stereo_Matching_Networks_CVPR_2021_paper.pdf</li>
<li>LoS: Local Structure-Guided Stereo Matching - IEEE Xplore, https://ieeexplore.ieee.org/iel8/10654794/10654797/10655701.pdf</li>
<li>DEFOM-Stereo: Depth Foundation Model Based Stereo Matching, https://arxiv.org/html/2501.09466v3</li>
<li>Efficient High-Resolution Stereo Matching Using Local Plane Sweeps, https://www.researchgate.net/publication/285985804_Efficient_High-Resolution_Stereo_Matching_Using_Local_Plane_Sweeps</li>
<li>LoS: Local Structure-guided Stereo Matching … - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2024/supplemental/Li_LoS_Local_Structure-Guided_CVPR_2024_supplemental.pdf</li>
<li>IAASNet: Ill-Posed-Aware Aggregated Stereo Matching Network for …, https://www.mdpi.com/2072-4292/17/21/3528</li>
<li>Learning Robust Stereo Matching in the Wild with Selective Mixture …, https://arxiv.org/html/2507.04631v1</li>
<li>Stereo Matching via Motif Correlation Graph - arXiv, <a href="https://arxiv.org/pdf/2411.12426">https://arxiv.org/pdf/2411.12426?</a></li>
<li>DEFOM-Stereo: Depth Foundation Model Based Stereo Matching, https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_DEFOM-Stereo_Depth_Foundation_Model_Based_Stereo_Matching_CVPR_2025_paper.pdf</li>
<li>KITTI Stereo 2015 - The KITTI Vision Benchmark Suite, https://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo</li>
<li>A Wavelet-based Stereo Matching Framework for Solving Frequency …, https://arxiv.org/html/2505.18024v1</li>
<li>MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real …, https://arxiv.org/html/2501.08643v2</li>
<li>High-Frequency Stereo Matching Network - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_High-Frequency_Stereo_Matching_Network_CVPR_2023_paper.pdf</li>
<li>LoS: Local Structure-Guided Stereo Matching | Request PDF, https://www.researchgate.net/publication/384143754_LoS_Local_Structure-Guided_Stereo_Matching</li>
<li>DEFOM-Stereo: Depth Foundation Model Based Stereo Matching, https://www.researchgate.net/publication/388080921_DEFOM-Stereo_Depth_Foundation_Model_Based_Stereo_Matching</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>