<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:7.1 복사(Copying) 작업과 회상(Recall) 능력의 한계 - Mamba vs Transformer</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>7.1 복사(Copying) 작업과 회상(Recall) 능력의 한계 - Mamba vs Transformer</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">MAMBA - 포스트 트랜스포머 시대의 도래</a> / <span>7.1 복사(Copying) 작업과 회상(Recall) 능력의 한계 - Mamba vs Transformer</span></nav>
                </div>
            </header>
            <article>
                <h1>7.1 복사(Copying) 작업과 회상(Recall) 능력의 한계 - Mamba vs Transformer</h1>
<h2>1.  서론: 시퀀스 모델링의 근원적 딜레마와 기억의 본질</h2>
<p>인공지능, 특히 자연어 처리(NLP) 분야에서 시퀀스 모델링의 역사는 ’기억(Memory)’과 ‘효율(Efficiency)’ 사이의 끊임없는 줄다리기 과정이었다. 이 장에서는 현대 딥러닝 아키텍처의 두 거두인 트랜스포머(Transformer)와 상태 공간 모델(State Space Models, SSM), 그중에서도 특히 맘바(Mamba) 아키텍처가 ’정보의 저장과 회상’이라는 근본적인 과제를 어떻게 다르게 접근하는지, 그리고 그로 인해 발생하는 맘바의 결정적인 한계점인 ‘복사(Copying)’ 능력의 부족에 대해 심도 있게 논의한다.</p>
<p>언어 모델이 수행하는 수많은 과제 중에서도 입력된 정보를 그대로 기억했다가 필요할 때 꺼내 쓰는 ‘복사’ 능력과, 과거의 특정 문맥을 참조하여 현재의 판단을 내리는 ‘회상(Recall)’ 능력은 지능의 가장 기초적이면서도 필수적인 요소이다.1 우리는 흔히 거대 언어 모델(LLM)이 고도의 추론이나 창의적인 작문을 수행한다고 생각하지만, 그 기저에는 방대한 문맥 윈도우(Context Window) 내에 존재하는 특정 단어, 고유명사, 지시 사항, 혹은 코드 스니펫을 정확하게 다시 불러오는 능력이 깔려 있다.2</p>
<p>트랜스포머 아키텍처는 ‘어텐션(Attention)’ 메커니즘을 통해 이 문제를 정공법으로 해결했다. 즉, 과거의 모든 정보를 버리지 않고 메모리에 보존하며, 필요할 때마다 전체를 다시 훑어보는 방식이다. 이는 정보의 손실을 원천적으로 차단하여 완벽에 가까운 복사 및 회상 능력을 제공하지만, 그 대가로 시퀀스 길이가 길어질수록 연산량과 메모리 사용량이 기하급수적으로(<span class="math math-inline">O(N^2)</span>) 증가하는 비용을 치러야 했다.3</p>
<p>반면, 맘바와 같은 SSM 계열 모델들은 효율성에 방점을 둔다. 이들은 인간의 뇌가 모든 순간을 기억하지 않고 현재의 상태(State)만을 유지하며 세상을 인지하듯, 과거의 모든 정보를 고정된 크기의 은닉 상태(Hidden State)로 압축하여 전달한다. 이를 통해 시퀀스 길이에 상관없이 선형적인(<span class="math math-inline">O(N)</span>) 추론 속도와 일정한 메모리 사용량을 달성했다.3 그러나 ’압축’은 필연적으로 ’손실’을 동반한다. “고정된 크기의 메모리에 무한한 스트림의 정보를 담을 수 있는가?“라는 정보 이론적 질문 앞에서, 맘바는 트랜스포머가 겪지 않는 구조적 한계에 봉착하게 된다.4</p>
<p>본 절에서는 맘바가 트랜스포머 대비 복사 작업과 연상 회상(Associative Recall) 작업에서 왜 취약할 수밖에 없는지, 그 이론적 배경과 실험적 증거들을 낱낱이 파헤친다. 특히 ‘Repeat After Me’ 연구와 ‘인덕션 헤드(Induction Heads)’ 이론을 중심으로, 맘바가 겪는 정보 병목 현상(Information Bottleneck)의 실체를 규명하고, 이를 극복하기 위해 등장한 맘바-2(Mamba-2) 및 하이브리드 모델들의 시도와 그 한계까지 포괄적으로 분석한다. 이는 단순한 모델 간 우열 가리기가 아니라, 인공지능이 ’기억’이라는 인지적 기능을 구현하는 방식에 대한 근본적인 탐구이다.</p>
<h2>2.  트랜스포머의 완전 기억: KV 캐시와 어텐션의 기하학</h2>
<p>맘바의 한계를 논하기에 앞서, 비교의 기준점이 되는 트랜스포머가 왜 복사 작업에서 타의 추종을 불허하는 성능을 보이는지, 그 메커니즘을 명확히 이해할 필요가 있다. 트랜스포머의 압도적인 회상 능력은 ’선택’이 아닌 ’전수 조사’에 기반한다.</p>
<h3>2.1  어텐션 메커니즘과 정보 보존의 무손실성</h3>
<p>트랜스포머의 핵심 연산인 셀프 어텐션(Self-Attention)은 입력 시퀀스의 각 토큰을 쿼리(Query), 키(Key), 밸류(Value) 벡터로 변환한다. 추론 시점(<span class="math math-inline">t</span>)에서 모델은 <span class="math math-inline">t</span> 이전의 모든 <span class="math math-inline">1</span>부터 <span class="math math-inline">t-1</span>까지의 토큰에 대한 키와 밸류 벡터를 ’KV 캐시(KV Cache)’라는 형태의 메모리에 온전히 보존한다.3<br />
<span class="math math-display">
Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V
</span><br />
이 수식은 단순해 보이지만, 정보 검색(Information Retrieval) 관점에서 강력한 함의를 지닌다. <span class="math math-inline">QK^T</span> 연산은 현재 시점의 쿼리와 과거의 모든 키 벡터 간의 유사도를 계산한다. 이는 일종의 ‘내용 기반 주소 지정(Content-based Addressing)’ 방식이다. 즉, “3번째에 있던 토큰을 가져와“가 아니라, “지금 내 문맥과 가장 관련이 깊은, 혹은 내가 찾고 있는 패턴을 가진 토큰을 가져와“라는 명령이 가능하다. 중요한 점은 이 과정에서 과거의 정보가 어떠한 압축도 거치지 않고 원본(투영된 벡터) 형태로 접근 가능하다는 것이다. 트랜스포머의 메모리 용량은 고정되어 있지 않고, 입력 시퀀스의 길이 <span class="math math-inline">L</span>이 늘어남에 따라 <span class="math math-inline">O(L)</span>로 선형적으로 증가한다. 이는 하드웨어 메모리가 허락하는 한, 트랜스포머는 과거의 어떤 시점에 등장했던 정보라도 100%의 해상도로 ’복사’하여 현재 시점으로 가져올 수 있음을 의미한다.4</p>
<h3>2.2  위치 정보와 내용 정보의 완벽한 분리 및 결합</h3>
<p>복사 작업, 특히 ’전화번호부 조회’나 ’긴 문자열 따라 하기’와 같은 작업에서 중요한 것은 ’무엇(What)’을 기억하는지 뿐만 아니라 ’어디(Where)’에 있었는지를 기억하는 것이다. 트랜스포머는 위치 인코딩(Positional Encoding)을 통해 각 토큰의 절대적, 상대적 위치 정보를 키 벡터에 명시적으로 주입한다. 따라서 어텐션 헤드는 “500 토큰 전에 등장했던 ’A’라는 글자 뒤에 있는 글자“와 같은 정밀한 연산을 수행할 수 있다.7</p>
<p>연구에 따르면, 아주 작은 크기의 트랜스포머 모델이라도 자신보다 10배, 심지어 100배 더 많은 파라미터를 가진 맘바 모델보다 단순 시퀀스 반복 작업에서 우수한 성능을 보인다.1 이는 파라미터 수의 문제가 아니라, 정보 접근 방식의 구조적 차이에서 기인한다. 트랜스포머에게 복사는 ’검색(Retrieval)’의 문제이지만, 맘바에게 복사는 ’압축과 복원(Compression and Decompression)’의 문제이기 때문이다. 검색은 원본이 보존되어 있다면 언제든 100% 정확할 수 있지만, 압축과 복원은 손실 가능성을 내포한다.</p>
<h3>2.3  인덕션 헤드(Induction Heads): 트랜스포머의 퓨샷 러닝 엔진</h3>
<p>트랜스포머의 복사 능력은 단순히 기계적인 반복을 넘어, ’인덕션 헤드’라는 특수한 회로를 통해 고차원적인 학습 능력으로 승화된다. 앤트로픽(Anthropic) 등의 연구진이 규명한 인덕션 헤드는 <code>[A]... [A] -&gt;</code>와 같은 패턴을 즉석에서 학습하고 실행하는 메커니즘이다.2</p>
<p>트랜스포머 내부에서 이 과정은 2개의 레이어에 걸친 어텐션 헤드의 협업으로 이루어진다:</p>
<ol>
<li><strong>이전 토큰 헤드(Previous Token Head):</strong> 첫 번째 레이어의 헤드가 현재 토큰 위치에서 바로 이전 토큰의 정보를 수집하여 현재 위치의 잔차 스트림(Residual Stream)에 기록한다.</li>
<li><strong>인덕션 헤드(Induction Head):</strong> 두 번째 레이어의 헤드가 이 정보를 쿼리로 사용하여, 과거에 동일한 토큰이 등장했던 위치를 찾는다(Key 매칭). 그리고 그 위치의 ‘다음 토큰’(Value, 실제로는 Shift된 Value) 정보를 가져온다.2</li>
</ol>
<p>이 메커니즘은 트랜스포머가 별도의 파인튜닝(Fine-tuning) 없이도 프롬프트 내에 주어진 예시를 보고 규칙을 유추하는 ’인컨텍스트 러닝(In-context Learning)’의 근간이 된다. 트랜스포머는 어텐션 맵(Attention Map)을 통해 과거의 특정 위치를 정확히 ’포인팅(Pointing)’할 수 있으므로, 이러한 연상 회상(Associative Recall) 작업이 자연스럽게, 그리고 매우 날카롭게(Sharp) 구현된다.13 반면, 뒤에서 다루겠지만 맘바와 같은 SSM이 이러한 메커니즘을 구현하기 위해서는 고정된 상태 벡터 내에 ‘현재 토큰’, ‘과거 토큰’, ’그 다음 토큰’의 관계를 모두 압축해 넣어야 하는 난제에 봉착하게 된다.</p>
<h2>3.  상태 공간 모델(SSM)의 이론적 한계: 비둘기집의 비극</h2>
<p>맘바를 포함한 모든 상태 공간 모델(SSM)과 순환 신경망(RNN)은 ’고정된 크기의 상태(Fixed-size State)’라는 태생적 제약 조건을 가진다. 이는 추론 속도를 <span class="math math-inline">O(1)</span>(토큰 당)로 만들고 메모리 사용량을 획기적으로 줄여주는 핵심 이점이지만, 동시에 정보 이론적 관점에서는 ‘복사’ 및 ‘회상’ 능력에 치명적인 족쇄가 된다.3</p>
<h3>3.1  상태 압축의 수학적 필연성과 병목</h3>
<p>SSM의 동작은 다음의 이산화된 상태 방정식으로 요약된다:<br />
<span class="math math-display">
h_t = \mathbf{\bar{A}}h_{t-1} + \mathbf{\bar{B}}x_t
</span></p>
<p><span class="math math-display">
y_t = \mathbf{C}h_t
</span></p>
<p>여기서 <span class="math math-inline">h_t</span>는 시간 <span class="math math-inline">t</span>에서의 은닉 상태(Hidden State)이며, <span class="math math-inline">x_t</span>는 입력이다. 핵심은 <span class="math math-inline">h_t</span>의 차원 <span class="math math-inline">N</span>(State Dimension)이 시퀀스 길이 <span class="math math-inline">L</span>과 무관하게 미리 정해진 상수(Constant)라는 점이다.3 예를 들어, 맘바 모델의 상태 차원이 <span class="math math-inline">N=128</span>이라 가정해보자. 입력 시퀀스의 길이가 1,000이든 1,000,000이든, 모델은 이 모든 과거의 이력을 오직 128차원의 벡터 안에 우겨 넣어야 한다.</p>
<p>이를 정보 이론의 ‘비둘기집 원리(Pigeonhole Principle)’ 혹은 섀넌의 ’채널 코딩 정리(Channel Coding Theorem)’에 비유할 수 있다. 입력 시퀀스가 가질 수 있는 정보의 총량(엔트로피)이 상태 벡터가 표현할 수 있는 정보의 용량(Capacity)을 초과하는 순간, 필연적으로 정보 손실이 발생한다.5 서로 다른 두 입력 시퀀스 <span class="math math-inline">S_1</span>과 <span class="math math-inline">S_2</span>가 동일한 상태 <span class="math math-inline">h</span>로 매핑되는 충돌(Collision)이 발생하면, 모델은 현재 상태 <span class="math math-inline">h</span>만 보고 과거가 <span class="math math-inline">S_1</span>이었는지 <span class="math math-inline">S_2</span>였는지 구분할 수 없게 된다. 구분할 수 없다는 것은 원본을 정확히 복원(복사)할 수 없음을 의미한다.</p>
<h3>3.2  선형 재귀(Linear Recurrence)와 정보 소실</h3>
<p>기존 RNN이나 맘바와 같은 모델은 새로운 정보가 들어올 때마다 기존 상태 <span class="math math-inline">h_{t-1}</span>에 행렬 <span class="math math-inline">\mathbf{\bar{A}}</span>를 곱하여 정보를 갱신한다. 만약 <span class="math math-inline">\mathbf{\bar{A}}</span>의 고윳값(Eigenvalue)이 1보다 작으면 과거 정보는 지수적으로 감쇠(Decay)하여 사라지고, 1보다 크면 발산한다. 1 근처로 유지한다 해도, 새로운 정보 <span class="math math-inline">x_t</span>가 계속 더해지면서(<span class="math math-inline">+\mathbf{\bar{B}}x_t</span>) 기존 정보에 ’간섭(Interference)’을 일으킨다.6</p>
<p>트랜스포머의 KV 캐시는 새로운 정보가 들어오면 ’새로운 방’을 만들어 저장하는 방식(Concatenation)이므로 간섭이 없다. 그러나 SSM은 ’하나의 방’에 계속 물건을 쌓아두는 방식(Summation/Update)이므로, 나중에 들어온 정보가 이전에 들어온 정보를 덮어쓰거나(Overwrite), 섞여버려(Mix) 개별 정보를 분리해내기 어렵게 만든다.6 이는 ’재앙적 망각(Catastrophic Forgetting)’의 미시적 형태로 볼 수 있으며, 맘바가 긴 시퀀스 끝에서 초반부의 구체적인 토큰을 기억해내지 못하는 주된 원인이 된다.18</p>
<h2>4.  ‘Repeat After Me’: 맘바의 복사 능력 실패에 대한 실증적 분석</h2>
<p>하버드 대학의 켐프너 연구소(Kempner Institute) 연구진이 발표한 ‘Repeat After Me: Transformers are Better than State Space Models at Copying’ 논문은 이러한 이론적 한계를 실험적으로 명확히 입증한 기념비적 연구이다.1 이 연구는 복잡한 언어 이해 능력이 아닌, 가장 기초적인 ‘복사’ 능력에서 두 모델 간의 격차를 정량화했다.</p>
<h3>4.1  실험 1: 단순 문자열 복사 (String Copying)</h3>
<p>연구진은 모델에게 임의의 문자열(예: “a b c d…”)을 입력으로 주고, 이를 그대로 출력하게 하는 과제를 부여했다.</p>
<ul>
<li><strong>트랜스포머:</strong> 매우 작은 크기의 모델이라도 몇 번의 에포크 만에 완벽하게 문자열을 복사하는 법을 학습했다. 어텐션 헤드가 “현재 위치 - <span class="math math-inline">k</span>“의 토큰을 보는 패턴을 쉽게 찾아냈기 때문이다.</li>
<li><strong>맘바(SSM):</strong> 트랜스포머와 비슷한 파라미터 수를 가진 맘바 모델은 이 단순한 작업을 수행하는 데 실패하거나, 성공하더라도 <strong>100배 이상의 학습 데이터</strong>를 필요로 했다.1</li>
<li><strong>해석:</strong> 맘바가 이 작업을 학습하기 위해서는 문자열의 순서와 값을 상태 벡터의 비선형적 역학 안에 인코딩해야 하는데, 이는 단순히 포인터를 이동시키는 트랜스포머의 방식보다 훨씬 어려운 최적화 문제이다. 맘바는 상태 공간 내에 복잡한 ’기억 회로’를 구축해야만 비로소 복사가 가능한데, 이를 위해서는 방대한 양의 예시를 통한 학습이 강제된다.1</li>
</ul>
<h3>4.2  실험 2: 일반화 실패 (Length Generalization Failure)</h3>
<p>더욱 심각한 문제는 ’길이 일반화’에서 드러났다. 훈련 시에 길이 50의 문자열만 보여주고, 테스트 시에 길이 100의 문자열을 복사하게 했을 때의 결과이다.</p>
<ul>
<li><strong>트랜스포머:</strong> 적절한 위치 임베딩(예: ALiBi 등)을 사용한 경우, 훈련 때 보지 못한 더 긴 시퀀스에 대해서도 높은 정확도를 유지했다. 이는 트랜스포머가 “복사 알고리즘(Algorithm)” 자체를 학습했음을 시사한다.1</li>
<li><strong>맘바:</strong> 훈련 길이를 벗어나는 순간 성능이 급격히 붕괴되었다. 맘바는 일반적인 복사 규칙을 학습한 것이 아니라, 훈련 데이터 길이 <span class="math math-inline">L=50</span>에 최적화된 상태 압축 패턴만을 학습했기 때문이다. <span class="math math-inline">L=100</span>이 되면 상태 용량이 초과되어 정보가 소실되거나, 학습되지 않은 상태 영역으로 진입하여 오류를 뿜어낸다.1</li>
</ul>
<h3>4.3  실험 3: 전화번호부 조회 (Phone-book Lookup)</h3>
<p>실제 응용과 더 가까운 ‘전화번호부 조회’ 실험(이름-전화번호 쌍을 나열한 후, 특정 이름을 주면 전화번호를 맞추는 과제)에서도 결과는 유사했다. 트랜스포머는 입력 길이가 길어져도 전화번호를 정확히 찾아냈지만, 맘바는 문맥 길이가 길어질수록 앞부분에 나온 정보(이름-전화번호)를 잊어버리거나, 다른 정보와 혼동하는 모습을 보였다.10</p>
<p>이러한 실험 결과들은 “고정된 메모리 크기를 가진 어떤 모델도 가변 메모리를 가진 트랜스포머와 같은 수준의 복사 능력을 가질 수 없다“는 이론적 명제를 뒷받침한다. 맘바의 상태 크기 <span class="math math-inline">N</span>을 키우면 성능이 향상되긴 하지만, 트랜스포머의 완벽한 회상 능력에 도달하기 위해서는 상태 크기가 시퀀스 길이에 비례하여(<span class="math math-inline">O(L)</span>) 커져야 하며, 이는 맘바가 내세우는 효율성 이점(<span class="math math-inline">O(1)</span> Inference)을 스스로 포기하는 모순에 빠지게 된다.4</p>
<h2>5.  인덕션 헤드와 연상 회상(Associative Recall)의 붕괴</h2>
<p>단순 복사를 넘어, LLM의 핵심 기능인 인컨텍스트 러닝(ICL)을 가능케 하는 **인덕션 헤드(Induction Heads)**와 <strong>연상 회상(Associative Recall)</strong> 작업에서의 성능 저하는 맘바의 아키텍처적 한계를 더욱 적나라하게 드러낸다.</p>
<h3>5.1  맘바의 인덕션 헤드 구현 난이도</h3>
<p>앞서 설명했듯 트랜스포머는 두 개의 어텐션 헤드 조합으로 인덕션 헤드를 직관적으로 구현한다. 그러나 맘바와 같은 SSM이 이를 수행하려면 훨씬 복잡한 과정을 거쳐야 한다.</p>
<ol>
<li>토큰 <code>[A]</code>가 들어왔을 때, 맘바는 이 토큰 자체뿐만 아니라 “이것이 <code>[A]</code>이다“라는 사실을 상태 <span class="math math-inline">h</span>에 기록해야 한다.</li>
<li>그 다음 토큰 <code>가 들어왔을 때, 맘바는 "방금 </code>[A]<code>가 지나갔으므로, </code>[A]<code>다음에</code>가 온다“는 관계(Bigram)를 상태 <span class="math math-inline">h</span>에 업데이트해야 한다.</li>
<li>시간이 한참 흘러 다시 <code>[A]</code>가 등장했을 때, 맘바는 현재 상태 <span class="math math-inline">h</span>에서 “과거에 <code>[A]</code> 뒤에 무엇이 왔었지?“라는 정보를 추출(Recall)해내야 한다.</li>
</ol>
<p>문제는 3번 단계이다. 상태 <span class="math math-inline">h</span>에는 <code>[A]</code>와 <code>의 관계뿐만 아니라, 그 사이에 들어온 수많은 다른 토큰들의 정보도 섞여 있다. 트랜스포머는 </code>[A]<code>라는 쿼리로 과거의 </code>[A]<code>위치를 정확히 '조준(Point)'하여</code>를 가져오지만, 맘바는 섞여 있는 상태 벡터(Mixed State Representation) 속에서 ``라는 정보를 ’정제’해내야 한다. 이는 바늘 찾기(Needle in a Haystack)와 유사하며, 상태 공간이 충분히 크지 않거나 비선형 변환이 정교하지 않으면 실패하기 쉽다.2</p>
<h3>5.2  다중 쿼리 연상 회상(MQAR)에서의 성능 격차</h3>
<p>단일 인덕션 헤드 작업(하나의 패턴 기억)은 맘바도 어느 정도 수행할 수 있다. 그러나 기억해야 할 패턴이 여러 개이고, 질문(Query)도 여러 번 주어지는 <strong>다중 쿼리 연상 회상(Multi-Query Associative Recall, MQAR)</strong> 작업에서는 맘바와 트랜스포머의 성능 격차가 벌어진다.11</p>
<table><thead><tr><th><strong>모델</strong></th><th><strong>상태 크기 / 파라미터</strong></th><th><strong>MQAR 성능 (정확도)</strong></th><th><strong>비고</strong></th></tr></thead><tbody>
<tr><td><strong>Transformer</strong></td><td>작은 모델</td><td><strong>~100%</strong></td><td>모델 크기에 상관없이 쉽게 학습</td></tr>
<tr><td><strong>Mamba-1</strong></td><td><span class="math math-inline">N=16</span></td><td><strong>~20% (실패)</strong></td><td>정보 용량 부족</td></tr>
<tr><td><strong>Mamba-1</strong></td><td><span class="math math-inline">N=64</span></td><td><strong>~60%</strong></td><td>상태 크기 증가 시 개선되나 여전히 부족</td></tr>
<tr><td><strong>Mamba-2</strong></td><td><span class="math math-inline">N=256</span></td><td><strong>~98%</strong></td><td>충분히 큰 상태 크기에서 트랜스포머에 근접</td></tr>
</tbody></table>
<p>위 표에서 볼 수 있듯이, 맘바(특히 초기 버전)는 MQAR 작업에서 트랜스포머에 비해 현저히 낮은 성능을 보인다.24 트랜스포머는 키-밸류 쌍을 독립적으로 저장하므로 서로 다른 패턴 간의 간섭(Interference)이 없지만, 맘바는 하나의 상태 벡터를 공유하므로 여러 패턴을 동시에 기억하려 할 때 서로의 정보를 지우거나 왜곡시키는 현상이 발생하기 때문이다.6</p>
<h3>5.3  학습 역학의 차이: 맘바의 느린 학습</h3>
<p>더욱 흥미로운 점은 학습 과정(Training Dynamics)의 차이이다. 트랜스포머는 학습 초기부터 급격하게 인덕션 헤드 패턴을 형성하며 성능이 올라가는 ’상전이(Phase Transition)’를 보이지만, 맘바는 훨씬 완만하고 느리게 학습된다.1</p>
<p>애플(Apple)과 기타 연구팀의 분석에 따르면, 맘바가 형성하는 ’어텐션 유사 패턴’은 트랜스포머의 날카로운(Sharp) 피크와 달리 뭉툭하고 분산된 형태를 띤다.13 이는 맘바가 정확한 위치를 특정하지 못하고 “대충 이쯤에 있었던 것 같은데” 식의 흐릿한 기억을 가지고 있음을 시사한다. 맘바가 트랜스포머 수준의 날카로운 회상을 하기 위해서는 훨씬 더 많은 학습 단계와 데이터가 필요하며, 이는 실무적인 관점에서 학습 효율성 저하로 이어진다.1</p>
<h2>6.  맘바(Mamba)의 선택적 스캔(Selective Scan)과 그 한계</h2>
<p>맘바는 기존 LTI(Linear Time Invariant) SSM들의 한계를 극복하기 위해 <strong>선택적 스캔(Selective Scan)</strong> 메커니즘을 도입했다. 이것이 복사 작업의 한계를 어느 정도 보완해주지만, 근본적인 해결책이 되지 못하는 이유를 분석한다.</p>
<h3>6.1  선택적 스캔: 필요한 것만 기억한다</h3>
<p>기존 SSM은 행렬 <span class="math math-inline">\mathbf{A}, \mathbf{B}, \mathbf{C}</span>가 고정되어 있어 모든 입력을 동일한 방식으로 처리했다. 반면 맘바는 입력 <span class="math math-inline">x_t</span>에 따라 파라미터 <span class="math math-inline">\Delta, \mathbf{B}, \mathbf{C}</span>가 변화한다.3</p>
<ul>
<li><strong>게이팅(Gating):</strong> <span class="math math-inline">\Delta</span> 파라미터는 일종의 게이트 역할을 한다. <span class="math math-inline">\Delta</span>가 크면 현재 입력을 상태에 많이 반영하고(Focus), 작으면 무시하거나 기존 상태를 유지한다(Forget/Ignore).</li>
<li><strong>선택적 복사(Selective Copying):</strong> 이 메커니즘 덕분에 맘바는 입력 시퀀스 중 잡음(Noise) 토큰은 무시하고, 중요한 정보 토큰만을 선별하여 상태에 저장하는 ‘선택적 복사’ 작업에서 기존 SSM 대비 월등한 성능을 보인다.25</li>
</ul>
<p>이는 맘바가 “무엇을 기억하고 무엇을 버릴지“를 동적으로 결정할 수 있게 해 주며, 제한된 상태 용량을 효율적으로 관리하는 데 큰 도움을 준다. 마치 제한된 노트 공간에 강의 내용을 받아 적을 때, 농담은 빼고 핵심만 적는 것과 같다.16</p>
<h3>6.2  압축할 수 없는 정보 앞에서의 무력함</h3>
<p>하지만 선택적 스캔은 ’압축 효율’을 높이는 기술이지, ’물리적 용량’을 늘리는 기술이 아니다. 만약 입력 시퀀스가 버릴 것이 하나도 없는 고밀도 정보(예: 암호화된 문자열, 랜덤한 숫자열, 압축된 데이터 스트림)로 구성되어 있다면 어떻게 될까?</p>
<p>이 경우 선택적 스캔은 작동하지 않는다. 모든 토큰이 중요하므로 모두 상태에 저장해야 하고, 결국 상태 용량 한계(State Capacity Limit)에 도달하여 가장 오래된 정보부터 소실되거나(Erasure), 정보들이 뭉개지는(Blurring) 현상이 발생한다.6</p>
<p>‘LIMIT’ 데이터셋이나 ‘고밀도 정보 검색’ 과제에서 맘바와 같은 SSM 모델들이 트랜스포머에 비해 현저히 낮은 성능을 보이는 이유가 바로 이것이다.19 트랜스포머는 정보의 중요도와 상관없이 일단 모든 KV를 저장해두고 나중에 선별(Post-selection)하는 반면, 맘바는 저장하는 순간에 선별(Pre-selection)해야 하는데, 선별할 수 없는 상황에서는 용량 부족으로 인한 정보 손실(Loss)을 피할 수 없다.16</p>
<h2>7.  맘바-2(Mamba-2)와 구조적 상태 공간 쌍대성(SSD): 부분적 해결과 남은 과제</h2>
<p>이러한 한계를 인지한 연구진은 2024년, **맘바-2(Mamba-2)**를 발표하며 **구조적 상태 공간 쌍대성(Structured State Space Duality, SSD)**이라는 새로운 이론을 제시했다. 이는 맘바의 복사 및 회상 능력을 한 단계 끌어올리는 계기가 되었다.24</p>
<h3>7.1  SSD와 행렬 믹서(Matrix Mixer)로의 진화</h3>
<p>SSD 이론의 핵심은 SSM의 순차적 연산(Recurrence)과 어텐션의 전역적 연산(Matrix Multiplication)이 수학적으로 연결되어 있다는 것이다. 맘바-2는 SSM을 일종의 구조화된 행렬 믹서(Structured Matrix Mixer), 구체적으로는 ’반분리 행렬(Semiseparable Matrix)’로 정의한다.31</p>
<p>이를 통해 맘바-2는 기존의 <span class="math math-inline">O(N)</span> 스캔 방식뿐만 아니라, GPU의 텐서 코어(Tensor Core)를 활용한 고효율 행렬 곱셈 방식으로도 연산이 가능해졌다. 이는 학습 속도를 획기적으로 높여주었을 뿐만 아니라, 상태 차원(<span class="math math-inline">N</span>)을 기존 맘바-1의 16~64 수준에서 64~256, 혹은 그 이상으로 크게 확장할 수 있는 길을 열어주었다.24</p>
<h3>7.2  향상된 MQAR 성능과 여전한 구조적 제약</h3>
<p>상태 차원(<span class="math math-inline">N</span>)의 증가는 곧 메모리 용량(’비둘기집’의 개수)의 증가를 의미한다. 덕분에 맘바-2는 앞서 언급한 MQAR(다중 쿼리 연상 회상) 작업에서 맘바-1보다 월등히 뛰어난 성능을 보이며, 특정 조건 하에서는 트랜스포머와 대등한 수준의 회상 능력을 보여준다.24 이는 “SSM은 회상을 못 한다“는 기존의 통념을 어느 정도 깨뜨린 성과이다.</p>
<p>그러나 맘바-2 역시 ’완벽한 어텐션’은 아니다.</p>
<ol>
<li><strong>반분리 행렬의 한계:</strong> 맘바-2의 어텐션 행렬(Matrix Mask)은 수학적으로 ‘반분리(Semiseparable)’ 구조를 가져야 한다. 이는 자유로운 형태의 어텐션 맵을 그릴 수 있는 트랜스포머(Full Attention Matrix)에 비해 표현력(Expressivity)의 제약이 있음을 의미한다.33</li>
<li><strong>선형 어텐션의 그림자:</strong> 맘바-2의 SSD 메커니즘은 본질적으로 ’선형 어텐션(Linear Attention)’의 변형이다. 선형 어텐션은 소프트맥스(Softmax) 어텐션에 비해 특정 정보에 집중하는 능력(Focusing ability)이 떨어진다는 것이 정설이다. 따라서 매우 정밀한 바늘 찾기(Passkey Retrieval) 작업에서는 여전히 순수 트랜스포머보다 성능이 떨어질 수 있다.8</li>
<li><strong>여전한 고정 상태:</strong> 상태 크기를 256이나 512로 늘린다 해도, 그것은 여전히 ’상수’이다. 입력 시퀀스가 수백만 토큰으로 늘어나면, 언젠가는 다시 용량 부족 문제에 직면하게 된다. 트랜스포머는(메모리가 허용하는 한) 이 한계가 없다.6</li>
</ol>
<h2>8.  정보 이론적 관점 심층 분석: 압축과 망각의 엔트로피</h2>
<p>맘바와 트랜스포머의 대결을 정보 이론(Information Theory) 관점에서 정리하면, 이는 **‘손실 압축(Lossy Compression)’ vs ‘무손실 보존(Lossless Retention)’**의 대결이다.</p>
<ul>
<li><strong>엔트로피 손실(Entropy Loss):</strong> 맘바의 레이어를 통과할 때마다 정보는 고정된 대역폭(상태 벡터)을 통과해야 한다. 섀넌의 정리에 따르면, 채널 용량보다 큰 엔트로피를 가진 신호가 통과하면 반드시 정보 손실(<span class="math math-inline">\Delta H &gt; 0</span>)이 발생한다. 이 손실은 비가역적(Irreversible)이므로, 깊은 레이어로 갈수록 초기의 상세 정보는 복구 불가능하게 사라진다.17</li>
<li><strong>간섭과 잡음:</strong> 트랜스포머의 어텐션은 쿼리에 맞는 정보만을 ’선택적’으로 읽어오기 때문에(Read), 다른 정보들의 간섭을 최소화한다. 반면 SSM의 상태 업데이트는 기존 상태에 새로운 정보를 ‘더하는(Add)’ 과정이므로, 정보들끼리 서로 섞이는 잡음(Noise)이 발생한다. 이를 해소하기 위해 맘바는 복잡한 비선형 게이팅을 사용하지만, 정보가 많아질수록 신호 대 잡음비(SNR)가 낮아져 정확한 회상을 방해한다.6</li>
<li><strong>재앙적 망각(Catastrophic Forgetting):</strong> SSM은 새로운 정보를 받아들이기 위해 오래된 정보를 지워야 한다(Exponential Decay). 맘바의 선택적 스캔은 중요한 정보를 덜 지우도록 조절하지만, 용량이 꽉 차면 중요하더라도 오래된 정보부터 희석될 수밖에 없다. 이는 맘바가 장기 문맥(Long Context)의 끝부분에서는 강하지만, 아주 초반부의 정보를 세밀하게 기억해내는 데 취약한 이유를 설명한다.6</li>
</ul>
<h2>9.  하이브리드 아키텍처: 현실적인 타협과 미래</h2>
<p>결국 순수한 SSM만으로는 물리적, 정보 이론적 한계로 인해 트랜스포머의 완벽한 복사 능력을 완전히 대체하기 어렵다는 것이 학계의 중론이다. 이에 따라 최근에는 두 아키텍처의 장점을 결합한 <strong>하이브리드(Hybrid)</strong> 모델이 가장 현실적인 대안으로 떠오르고 있다.</p>
<h3>9.1  맘바포머(MambaFormer)와 JRT-RNN</h3>
<p>**Jamba(AI21 Labs)**나 <strong>MambaFormer</strong>, <strong>JRT-RNN</strong>과 같은 모델들은 전체 레이어의 80~90%는 효율적인 맘바(SSM) 레이어로 구성하고, 나머지 10~20%는 트랜스포머(Attention) 레이어로 구성하는 방식을 채택한다.36</p>
<ul>
<li><strong>역할 분담:</strong> 맘바 레이어는 전체적인 문맥의 흐름과 구문론적 처리를 담당하여 연산 효율을 챙긴다. 중간중간 배치된 어텐션 레이어는 맘바가 놓친 세밀한 정보나, 아주 먼 과거의 특정 토큰을 ’회상’하는 역할을 담당한다.37</li>
<li><strong>성능:</strong> 실험 결과, 이러한 하이브리드 모델은 ‘희소 패리티(Sparse Parity)’ 문제나 복잡한 복사 작업에서 순수 트랜스포머와 대등한 성능을 보이면서도, 추론 속도와 메모리 효율은 순수 트랜스포머보다 훨씬 우수한 것으로 나타났다.36</li>
</ul>
<h3>9.2  델타넷(DeltaNet)과 명시적 메모리</h3>
<p>구글의 <strong>Titans</strong>나 <strong>DeltaNet</strong> 같은 최신 연구들은 SSM의 상태 업데이트 방식을 개선하여, 어텐션과 유사한 ‘명시적 메모리(Explicit Memory)’ 기능을 SSM에 주입하려 시도한다.19 이는 과거 데이터를 단순히 상태에 섞어버리는 것이 아니라, 키-밸류 형태의 메모리 슬롯에 기록하고 읽어오는 방식을 미분 가능한 형태로 구현한 것이다. 이는 SSM의 효율성을 유지하면서도 복사 능력을 획기적으로 개선하려는 시도이다.</p>
<h2>10.  결론 및 전망: 도구의 적재적소</h2>
<p>결론적으로 **“7.1 복사(Copying) 작업과 회상(Recall) 능력의 한계 - Mamba vs Transformer”**에 대한 답은 명확하다. <strong>복사와 정밀 회상에 있어서는 트랜스포머가 구조적으로 우월하며, 맘바는 태생적인 한계를 가진다.</strong> 이는 맘바가 못나서가 아니라, <span class="math math-inline">O(N)</span>이라는 효율성을 달성하기 위해 ’무한한 메모리 접근 권한’을 포기하고 ’압축’을 택했기 때문에 발생하는 기회비용이다.</p>
<p><strong>요약하자면:</strong></p>
<ol>
<li><strong>복사 한계:</strong> 고정 상태 크기를 가진 맘바는 정보 압축 손실로 인해 긴 시퀀스의 정확한 복사(Exact Copying)와 연상 회상(Associative Recall)에서 트랜스포머를 따라잡기 어렵다. 특히 학습 데이터 효율성이 100배 이상 떨어진다.</li>
<li><strong>맘바-2의 진보:</strong> SSD 기술과 상태 크기 확장을 통해 맘바-2는 이 격차를 상당히 줄였으나, 여전히 초대형 문맥이나 고밀도 정보 검색에서는 한계가 존재한다.</li>
<li><strong>하이브리드의 부상:</strong> 따라서 미래의 LLM은 순수 맘바보다는 맘바의 효율성과 트랜스포머의 회상 능력을 결합한 하이브리드 형태, 혹은 맘바-2 기반에 어텐션 메커니즘을 일부 차용한 형태가 주류가 될 가능성이 높다.</li>
</ol>
<p>저자가 집필 중인 서적에서는 맘바를 “트랜스포머의 완벽한 대체재“가 아니라, “효율성을 위해 정밀한 회상 능력을 일부 트레이드오프(Trade-off)한 강력한 대안“으로 기술하는 것이 타당하다. 법률 문서 분석이나 코드 생성과 같이 토큰 하나하나의 정확한 인용이 중요한 작업에서는 트랜스포머(또는 하이브리드)가, 긴 문서의 요약이나 흐름 파악, 실시간 대화 처리와 같이 전체적인 맥락과 속도가 중요한 작업에서는 맘바가 더 적합한 도구임을 명시해야 한다.</p>
<h2>11. 참고 자료</h2>
<ol>
<li>Repeat After Me: Transformers are Better than State Space Models at Copying, https://kempnerinstitute.harvard.edu/research/deeper-learning/repeat-after-me-transformers-are-better-than-state-space-models-at-copying/</li>
<li>Mamba: Linear-Time Sequence Modeling with Selective State Spaces - arXiv, https://arxiv.org/html/2312.00752v2</li>
<li>The Mamba Revolution: How State Space Models Are Challenging Transformers - Medium, https://medium.com/@aftab001x/the-mamba-revolution-how-state-space-models-are-challenging-transformers-4ad3b276b9a8</li>
<li>Repeat After Me: Transformers are Better than State Space Models at Copying Transformers are Better than State Space Models at Copying - arXiv, https://arxiv.org/html/2402.01032v1</li>
<li>[D] - Why MAMBA did not catch on? : r/MachineLearning - Reddit, https://www.reddit.com/r/MachineLearning/comments/1hpg91o/d_why_mamba_did_not_catch_on/</li>
<li>Stuffed Mamba: Oversized States Lead to the Inability to Forget - arXiv, https://arxiv.org/html/2410.07145v3</li>
<li>Repeat After Me: Transformers are Better than State Space Models at Copying [R] - Reddit, https://www.reddit.com/r/MachineLearning/comments/1aj9swv/repeat_after_me_transformers_are_better_than/</li>
<li>On the Tradeoffs of SSMs and Transformers | Goomba Lab, https://goombalab.github.io/blog/2025/tradeoffs/</li>
<li>Compared to self-attention, does Mamba not need multiple heads per layer? Or positional embeddings? · Issue #29 - GitHub, https://github.com/state-spaces/mamba/issues/29</li>
<li>Repeat After Me: Transformers are Better than State Space Models at Copying Transformers are Better than State Space Models at C - arXiv, https://arxiv.org/pdf/2402.01032</li>
<li>A Visual Guide to Mamba and State Space Models - Maarten Grootendorst, https://www.maartengrootendorst.com/blog/mamba/</li>
<li>Mamba Solves Key Sequence Tasks Faster Than Other AI Models | HackerNoon, https://hackernoon.com/mamba-solves-key-sequence-tasks-faster-than-other-ai-models</li>
<li>Mimetic Initialization Helps State Space Models Learn to Recall - arXiv, https://arxiv.org/html/2410.11135v1</li>
<li>Daily Papers - Hugging Face, <a href="https://huggingface.co/papers?q=induction+head">https://huggingface.co/papers?q=induction%20head</a></li>
<li>How Transformers Implement Induction Heads: Approximation and Optimization Analysis, https://arxiv.org/html/2410.11474v2</li>
<li>Mamba Explained - The Gradient, https://thegradient.pub/mamba-explained/</li>
<li>MemMamba: Rethinking Memory Patterns in State Space Model - arXiv, https://arxiv.org/html/2510.03279v1</li>
<li>MemMamba: Rethinking Memory Patterns in State Space Model - arXiv, https://arxiv.org/pdf/2510.03279</li>
<li>Titans + MIRAS: Helping AI have long-term memory - Google Research, https://research.google/blog/titans-miras-helping-ai-have-long-term-memory/</li>
<li>Mimetic Initialization Helps State Space Models Learn to Recall - OpenReview, https://openreview.net/forum?id=iVy7aRMb0K</li>
<li>Exploring the Limitations of Mamba in COPY and CoT Reasoning - arXiv, https://arxiv.org/html/2410.03810v3</li>
<li>[2410.03810] Exploring the Limitations of Mamba in COPY and CoT Reasoning - arXiv, https://arxiv.org/abs/2410.03810</li>
<li>Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism | OpenReview, https://openreview.net/forum?id=hWYisuBbp7</li>
<li>State Space Duality (Mamba-2) Part I - The Model | Tri Dao, https://tridao.me/blog/2024/mamba2-part1-model/</li>
<li>Mamba: Make Sequence Models Fast Again | by Dong-Keon Kim - Medium, https://medium.com/@kdk199604/mamba-make-sequence-models-fast-again-540245a49155</li>
<li>Beyond Attention: Mamba as a replacement for transformers | by Ben Spicer - Medium, https://medium.com/correll-lab/beyond-attention-mamba-as-a-replacement-for-transformers-5483b6e23a6e</li>
<li>Comprehensive Breakdown of Selective Structured State Space Model — Mamba (S5). | by Freedom Preetham | Autonomous Agents | Medium, https://medium.com/autonomous-agents/comprehensive-breakdown-of-selective-structured-state-space-model-mamba-s5-441e8b94ecaf</li>
<li>Mamba Model Blog - HackMD, https://hackmd.io/Btjp7ZMRQGCLh93n1vMAVw</li>
<li>google-deepmind/limit: On the Theoretical Limitations of Embedding-Based Retrieval, https://github.com/google-deepmind/limit</li>
<li>state-spaces/mamba: Mamba SSM architecture - GitHub, https://github.com/state-spaces/mamba</li>
<li>MAMBEV: ENABLING STATE SPACE MODELS TO LEARN BIRDS-EYE-VIEW REPRESENTATIONS - ICLR Proceedings, https://proceedings.iclr.cc/paper_files/paper/2025/file/f09567d1b1d611f12fc2cf4e23162915-Paper-Conference.pdf</li>
<li>MamBEV: Enabling State Space Models to Learn Birds-Eye-View Representations - arXiv, https://arxiv.org/html/2503.13858v2</li>
<li>Mamba 2 | PDF | Matrix (Mathematics) | Tensor - Scribd, https://www.scribd.com/document/748683510/mamba2</li>
<li>Mamba-2 is Out: Can it replace Transformers? | by Marko Vidrih | Medium, https://vidrihmarko.medium.com/mamba-2-is-out-can-it-replace-transformers-6cfb3372ea39</li>
<li>Characterizing the Behavior of Training Mamba-based State Space Models on GPUs - arXiv, https://arxiv.org/html/2508.17679v1</li>
<li>Just read twice: closing the recall gap for recurrent language models - Hazy Research, https://hazyresearch.stanford.edu/blog/2024-07-01-jrt</li>
<li>[Quick Review] Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks - Liner, https://liner.com/review/can-mamba-learn-how-to-learn-comparative-study-on-incontext</li>
<li>Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks - arXiv, https://arxiv.org/pdf/2402.04248</li>
<li>What’s Next for Mamba? Towards More Expressive Recurrent Update Rules - Songlin Yang, https://sustcsonglin.github.io/assets/pdf/talk_250117.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>