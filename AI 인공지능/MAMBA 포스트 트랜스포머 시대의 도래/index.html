<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:MAMBA - 포스트 트랜스포머 시대의 도래</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css?v=1772282415">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>MAMBA - 포스트 트랜스포머 시대의 도래</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">MAMBA - 포스트 트랜스포머 시대의 도래</a></nav>
                </div>
            </header>
            <article>
                <h1>MAMBA - 포스트 트랜스포머 시대의 도래</h1>
<p><img src="index1.png" alt="" /></p>
<h2>제1부: 시퀀스 모델링의 한계와 새로운 패러다임</h2>
<h3>제1장 트랜스포머 아키텍처의 구조적 병목</h3>
<ul>
<li><a href="1.1%20%EC%96%B4%ED%85%90%EC%85%98%20%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%EC%9D%98%20%EC%A0%9C%EA%B3%B1($O(N^2)$)%20%EB%B3%B5%EC%9E%A1%EB%8F%84%EC%99%80%20%EC%97%B0%EC%82%B0%20%EB%B9%84%EC%9A%A9.html">1.1 어텐션 메커니즘의 제곱(<span class="math math-inline">O(N^2)</span>) 복잡도와 연산 비용</a></li>
<li><a href="1.2%20KV%20%EC%BA%90%EC%8B%9C(Key-Value%20Cache)%20%EC%A6%9D%EA%B0%80%EC%99%80%20%EB%A9%94%EB%AA%A8%EB%A6%AC%20%EB%8C%80%EC%97%AD%ED%8F%AD%20%ED%95%9C%EA%B3%84.html">1.2 KV 캐시(Key-Value Cache) 증가와 메모리 대역폭 한계</a></li>
<li><a href="1.3%20%EA%B8%B4%20%EB%AC%B8%EB%A7%A5(Long%20Context)%20%EC%B2%98%EB%A6%AC%EC%9D%98%20%ED%9A%A8%EC%9C%A8%EC%84%B1%20%EC%A0%80%ED%95%98%EC%99%80%20%EC%B6%94%EB%A1%A0%20%EC%86%8D%EB%8F%84%20%EB%AC%B8%EC%A0%9C.html">1.3 긴 문맥(Long Context) 처리의 효율성 저하와 추론 속도 문제</a></li>
</ul>
<h3>제2장 상태 공간 모델(SSM)의 재발견</h3>
<ul>
<li><a href="2.1%20%EC%97%B0%EC%86%8D%20%EC%8B%9C%EA%B0%84%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%20%EC%9D%B4%EC%82%B0%ED%99%94(Discretization)%EC%99%80%20%EC%88%9C%ED%99%98%20%EC%8B%A0%EA%B2%BD%EB%A7%9D(RNN).html">2.1 연속 시간 시스템의 이산화(Discretization)와 순환 신경망(RNN)</a></li>
<li><a href="2.2%20%EC%9E%A5%EA%B8%B0%20%EC%9D%98%EC%A1%B4%EC%84%B1%20%EB%AC%B8%EC%A0%9C(Long-Range%20Dependency)%EC%99%80%20HiPPO%20%EC%9D%B4%EB%A1%A0.html">2.2 장기 의존성 문제(Long-Range Dependency)와 HiPPO 이론</a></li>
<li><a href="2.3%20S4(Structured%20State%20Spaces)%20%EB%8C%80%EA%B0%81%ED%99%94%EC%99%80%20%EC%BB%A8%EB%B3%BC%EB%A3%A8%EC%85%98%20%EA%B8%B0%EB%B0%98%20%ED%95%99%EC%8A%B5%20%EA%B0%80%EC%86%8D.html">2.3 S4(Structured State Spaces) 대각화와 컨볼루션 기반 학습 가속</a></li>
</ul>
<h2>제2부: MAMBA 아키텍처의 기술적 혁신 (Mamba-1)</h2>
<h3>제3장 선택적 상태 공간(Selective SSM)</h3>
<ul>
<li><a href="3.1%20%EC%84%A0%ED%98%95%20%EC%8B%9C%EA%B0%84%20%EB%B6%88%EB%B3%80(LTI)%20%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%20%ED%95%9C%EA%B3%84%EC%99%80%20%EC%9E%85%EB%A0%A5%20%EC%9D%98%EC%A1%B4%EC%A0%81(Input-Dependent)%20%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0.html">3.1 선형 시간 불변(LTI) 시스템의 한계와 입력 의존적(Input-Dependent) 파라미터</a></li>
<li><a href="3.2%20%EC%84%A0%ED%83%9D%EC%A0%81%20%EC%8A%A4%EC%BA%94(Selective%20Scan)%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EA%B3%BC%20%EC%A0%95%EB%B3%B4%EC%9D%98%20%EC%95%95%EC%B6%95%20%EB%B0%8F%20%EC%84%A0%EB%B3%84.html">3.2 선택적 스캔(Selective Scan) 알고리즘과 정보의 압축 및 선별</a></li>
<li><a href="3.3%20%ED%95%98%EB%93%9C%EC%9B%A8%EC%96%B4%20%EC%9D%B8%EC%8B%9D(Hardware-Aware)%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EA%B3%BC%20GPU%20%EB%A9%94%EB%AA%A8%EB%A6%AC%20%EA%B3%84%EC%B8%B5%20%EC%B5%9C%EC%A0%81%ED%99%94.html">3.3 하드웨어 인식(Hardware-Aware) 알고리즘과 GPU 메모리 계층 최적화</a></li>
</ul>
<h3>제4장 Mamba 시스템 구현</h3>
<ul>
<li><a href="4.1%20%EB%B3%91%EB%A0%AC%20%EC%8A%A4%EC%BA%94(Parallel%20Scan)%EC%9D%84%20%ED%86%B5%ED%95%9C%20%ED%95%99%EC%8A%B5%20%ED%9A%A8%EC%9C%A8%EC%84%B1%20%ED%99%95%EB%B3%B4.html">4.1 병렬 스캔(Parallel Scan)을 통한 학습 효율성 확보</a></li>
<li><a href="4.2%20Mamba%20%EB%B8%94%EB%A1%9D%20%EA%B5%AC%EC%A1%B0%20MLP%EC%99%80%20Attention%EC%9D%98%20%ED%86%B5%ED%95%A9%20%EB%B0%8F%20%EA%B0%84%EC%86%8C%ED%99%94.html">4.2 Mamba 블록 구조 - MLP와 Attention의 통합 및 간소화</a></li>
<li><a href="4.3%20%EC%88%98%EC%B9%98%EC%A0%81%20%EC%95%88%EC%A0%95%EC%84%B1%EA%B3%BC%20%EC%9E%AC%EA%B3%84%EC%82%B0(Recomputation)%20%EC%A0%84%EB%9E%B5.html">4.3 수치적 안정성과 재계산(Recomputation) 전략</a></li>
</ul>
<h2>제3부: 이론적 완성가 확장 (Mamba-2 &amp; Variants)</h2>
<h3>제5장 Mamba-2와 구조적 상태 공간 쌍대성(SSD)</h3>
<ul>
<li><a href="5.1%20SSM%EA%B3%BC%20%EC%84%A0%ED%98%95%20%EC%96%B4%ED%85%90%EC%85%98(Linear%20Attention)%EC%9D%98%20%EC%88%98%ED%95%99%EC%A0%81%20%EC%97%B0%EA%B2%B0%20(SSD%20%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC).html">5.1 SSM과 선형 어텐션(Linear Attention)의 수학적 연결 (SSD 프레임워크)</a></li>
<li><a href="5.2%20%ED%96%89%EB%A0%AC%20%EB%AF%B9%EC%84%9C(Matrix%20Mixer)%20%EC%9D%B4%EB%A1%A0%EA%B3%BC%20%EB%B8%94%EB%A1%9D%20%EB%B6%84%ED%95%B4%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html">5.2 행렬 믹서(Matrix Mixer) 이론과 블록 분해 알고리즘</a></li>
<li><a href="5.3%20%ED%85%90%EC%84%9C%20%EB%B3%91%EB%A0%AC%ED%99%94(Tensor%20Parallelism)%20%EC%A7%80%EC%9B%90%EA%B3%BC%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%20%ED%95%99%EC%8A%B5.html">5.3 텐서 병렬화(Tensor Parallelism) 지원과 대규모 클러스터 학습</a></li>
</ul>
<h3>제6장 도메인 특화 아키텍처</h3>
<ul>
<li><a href="6.1%20%5BVision%5D%20Vision%20Mamba%20(Vim)%20&amp;%20VSSD%20-%20%EC%8B%9C%EA%B0%81%EC%A0%81%20%EC%83%81%ED%83%9C%20%EA%B3%B5%EA%B0%84%20%EC%8C%8D%EB%8C%80%EC%84%B1%EA%B3%BC%20%EC%96%91%EB%B0%A9%ED%96%A5%20%EC%B2%98%EB%A6%AC.html">6.1 [Vision] Vision Mamba (Vim) &amp; VSSD - 시각적 상태 공간 쌍대성과 양방향 처리</a></li>
<li><a href="6.2%20%5BVideo%5D%20VideoMamba%20&amp;%20Dual%20Branch%20-%20%EC%8B%9C%EA%B3%B5%EA%B0%84%20%EB%AA%A8%EB%8D%B8%EB%A7%81%EA%B3%BC%20%EA%B2%8C%EC%9D%B4%ED%8A%B8%20%ED%81%B4%EB%9E%98%EC%8A%A4%20%ED%86%A0%ED%81%B0%20%ED%93%A8%EC%A0%84(GCTF).html">6.2 [Video] VideoMamba &amp; Dual Branch - 시공간 모델링과 게이트 클래스 토큰 퓨전(GCTF)</a></li>
<li><a href="6.3%20Caduceus%20&amp;%20PlantCaduceus%20-%20DNA%20%EC%84%9C%EC%97%B4%EC%9D%98%20%EC%83%81%EB%B3%B4%EC%A0%81%20%EB%93%B1%EB%B3%80%EC%84%B1%20%EB%B0%8F%20%EB%8B%A8%EC%9D%BC%20%EC%84%B8%ED%8F%AC%20%EB%B6%84%EC%84%9D(SC-MAMBA2).html">6.3 Caduceus &amp; PlantCaduceus - DNA 서열의 상보적 등변성 및 단일 세포 분석(SC-MAMBA2)</a></li>
<li><a href="6.4%20Mamba4Cast%20&amp;%20Affirm%20-%20%ED%8C%8C%EC%9A%B4%EB%8D%B0%EC%9D%B4%EC%85%98%20%EB%AA%A8%EB%8D%B8%EA%B3%BC%20%EC%A0%81%EC%9D%91%ED%98%95%20%ED%91%B8%EB%A6%AC%EC%97%90%20%ED%95%84%ED%84%B0.html">6.4 Mamba4Cast &amp; Affirm - 파운데이션 모델과 적응형 푸리에 필터</a></li>
<li><a href="6.5%20MKL%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20-%20UAV%20%EC%9C%84%ED%98%91%20%ED%83%90%EC%A7%80%EB%A5%BC%20%EC%9C%84%ED%95%9C%20Mamba-KAN-Liquid%20%EA%B2%B0%ED%95%A9%20%EB%AA%A8%EB%8D%B8.html">6.5 MKL 아키텍처 - UAV 위협 탐지를 위한 Mamba-KAN-Liquid 결합 모델</a></li>
</ul>
<h2>제4부: 하이브리드 아키텍처와 한계 극복</h2>
<h3>제7장 순수 SSM의 한계와 하이브리드 전략</h3>
<ul>
<li><a href="7.1%20%EB%B3%B5%EC%82%AC(Copying)%20%EC%9E%91%EC%97%85%EA%B3%BC%20%ED%9A%8C%EC%83%81(Recall)%20%EB%8A%A5%EB%A0%A5%EC%9D%98%20%ED%95%9C%EA%B3%84%20-%20Mamba%20vs%20Transformer.html">7.1 복사(Copying) 작업과 회상(Recall) 능력의 한계 - Mamba vs Transformer</a></li>
<li><a href="7.2%20Needle-in-a-Haystack%20(NIAH)%20%EC%84%B1%EB%8A%A5%20-%20%ED%95%98%EC%9D%B4%EB%B8%8C%EB%A6%AC%EB%93%9C%20%EB%AA%A8%EB%8D%B8%EC%9D%98%20%EC%9A%B0%EC%9C%84.html">7.2 Needle-in-a-Haystack (NIAH) 성능 - 하이브리드 모델의 우위</a></li>
<li><a href="7.3%20Jamba%20&amp;%20Granite%204.0%20-%20Attention-SSM%20%ED%95%98%EC%9D%B4%EB%B8%8C%EB%A6%AC%EB%93%9C%20%EB%B9%84%EC%9C%A8%EA%B3%BC%20%EC%84%B1%EB%8A%A5%20%EC%B5%9C%EC%A0%81%ED%99%94.html">7.3 Jamba &amp; Granite 4.0 - Attention-SSM 하이브리드 비율과 성능 최적화</a></li>
<li><a href="7.4%20MambaFormer%20-%20%ED%9D%AC%EC%86%8C%20%ED%8C%A8%EB%A6%AC%ED%8B%B0(Sparse%20Parity)%20%ED%95%99%EC%8A%B5%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EA%B2%B0%ED%95%A9%20%EA%B5%AC%EC%A1%B0.html">7.4 MambaFormer - 희소 패리티(Sparse Parity) 학습을 위한 결합 구조</a></li>
</ul>
<h3>제8장 인컨텍스트 러닝(ICL)의 새로운 이론 (2025)</h3>
<ul>
<li><a href="8.1%20%ED%85%8C%EC%8A%A4%ED%8A%B8%20%ED%83%80%EC%9E%84%20%ED%8A%B9%EC%A7%95%20%ED%95%99%EC%8A%B5(Test-Time%20Feature%20Learning)%20-%20Mamba%EC%9D%98%20ICL%20%EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%20%EA%B7%9C%EB%AA%85.html">8.1 테스트 타임 특징 학습(Test-Time Feature Learning) - Mamba의 ICL 메커니즘 규명</a></li>
<li><a href="8.2%20%EB%8B%A8%EC%9D%BC%20%EC%9D%B8%EB%8D%B1%EC%8A%A4%20%EB%AA%A8%EB%8D%B8(Single-Index%20Model)%20%ED%95%99%EC%8A%B5%EA%B3%BC%20%EB%B9%84%EC%84%A0%ED%98%95%20%EA%B2%8C%EC%9D%B4%ED%8C%85%EC%9D%98%20%EC%97%AD%ED%95%A0.html">8.2 단일 인덱스 모델(Single-Index Model) 학습과 비선형 게이팅의 역할</a></li>
<li><a href="8.3%20MambaExtend%20&amp;%20LongMamba%20-%20%ED%9B%88%EB%A0%A8%20%EC%97%86%EB%8A%94(Training-Free)%20%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8%20%ED%99%95%EC%9E%A5%EA%B3%BC%20%EA%B8%80%EB%A1%9C%EB%B2%8C%20%EC%B1%84%EB%84%90%20%ED%95%84%ED%84%B0%EB%A7%81.html">8.3 MambaExtend &amp; LongMamba - 훈련 없는(Training-Free) 컨텍스트 확장과 글로벌 채널 필터링</a></li>
</ul>
<h2>제5부: 2025년 기술 트렌드와 미래 전망</h2>
<h3>제9장 효율성의 극대화 - MoE와 양자화</h3>
<ul>
<li><a href="9.1%20BlackMamba%20-%20%EC%A0%84%EB%AC%B8%EA%B0%80%20%EB%AF%B9%EC%8A%A4(MoE)%EB%A5%BC%20%ED%86%B5%ED%95%9C%20%EC%B6%94%EB%A1%A0%20%EC%86%8D%EB%8F%84%20%EB%B0%8F%20%EB%B9%84%EC%9A%A9%20%EC%B5%9C%EC%A0%81%ED%99%94.html">9.1 BlackMamba - 전문가 믹스(MoE)를 통한 추론 속도 및 비용 최적화</a></li>
<li><a href="9.2%20%EC%96%91%EC%9E%90%ED%99%94(Quantization)%EC%9D%98%20%EB%82%9C%EC%A0%9C%20-%20%EC%95%84%EC%9B%83%EB%9D%BC%EC%9D%B4%EC%96%B4(Outlier)%20%EB%AC%B8%EC%A0%9C%EC%99%80%20%EC%88%98%EC%B9%98%20%EC%A0%95%EB%B0%80%EB%8F%84%20%EB%AF%BC%EA%B0%90%EC%84%B1.html">9.2 양자화(Quantization)의 난제 - 아웃라이어(Outlier) 문제와 수치 정밀도 민감성</a></li>
<li><a href="9.3%20%EC%B5%9C%EC%8B%A0%20%EA%B2%BD%EB%9F%89%ED%99%94%20%EA%B8%B0%EB%B2%95%20-%20%EB%B6%84%EB%A6%AC%ED%98%95%20%EC%8A%A4%EC%BC%80%EC%9D%BC%20%EC%96%91%EC%9E%90%ED%99%94(DSQ)%EC%99%80%20%ED%9A%A8%EC%9C%A8%EC%A0%81%20%EC%84%A0%ED%83%9D%EC%A0%81%20%EC%9E%AC%EA%B5%AC%EC%84%B1(ESG).html">9.3 최신 경량화 기법 - 분리형 스케일 양자화(DSQ)와 효율적 선택적 재구성(ESG)</a></li>
</ul>
<h3>제10장 포스트 트랜스포머 시대의 AI</h3>
<ul>
<li><a href="10.1%20%EB%AC%B4%ED%95%9C%20%EB%AC%B8%EB%A7%A5(Infinite%20Context)%20%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8%EC%99%80%20RAG%EC%9D%98%20%EB%8C%80%EC%B2%B4%20%EA%B0%80%EB%8A%A5%EC%84%B1.html">10.1 무한 문맥(Infinite Context) 에이전트와 RAG의 대체 가능성</a></li>
<li><a href="10.2%20%EB%B0%B0%ED%8F%AC%EC%99%80%20%EC%84%9C%EB%B9%99%20-%20vLLM%EC%9D%98%20Mamba%20%EC%A7%80%EC%9B%90%20%ED%98%84%ED%99%A9%20%EB%B0%8F%20ONNX%20TensorRT%20%EB%B3%80%ED%99%98%20%EC%9D%B4%EC%8A%88.html">10.2 배포와 서빙 - vLLM의 Mamba 지원 현황 및 ONNX/TensorRT 변환 이슈</a></li>
<li><a href="10.3%20%EA%B2%B0%EB%A1%A0%20-%20%EC%83%81%ED%98%B8%EB%B3%B4%EC%99%84%EC%A0%81%20%EC%9D%B4%EC%9B%90%EC%84%B1(Duality)%EA%B3%BC%20%ED%86%B5%ED%95%A9%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EC%9D%98%20%EB%AF%B8%EB%9E%98.html">10.3 결론 - 상호보완적 이원성(Duality)과 통합 아키텍처의 미래</a></li>
</ul>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>