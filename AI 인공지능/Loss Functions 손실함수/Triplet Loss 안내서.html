<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:Triplet Loss 안내서</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>Triplet Loss 안내서</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">손실함수 (Loss Functions)</a> / <span>Triplet Loss 안내서</span></nav>
                </div>
            </header>
            <article>
                <h1>Triplet Loss 안내서</h1>
<h2>1. 부: Triplet Loss의 원리와 수학적 기초</h2>
<h3>1.1  거리 학습(Metric Learning)의 서막: 왜 Triplet Loss가 필요한가?</h3>
<p>거리 학습(Metric Learning)은 기계 학습의 한 분야로, 단순히 데이터를 사전 정의된 범주로 분류하는 것을 넘어 데이터 포인트 간의 ‘유사도’ 또는 ’거리’를 학습하는 것을 목표로 한다.1 이 패러다임의 핵심은 입력 데이터(예: 이미지, 텍스트)를 고차원 공간에서 의미 있는 저차원의 벡터 공간, 즉 임베딩 공간(embedding space)으로 매핑하는 함수를 학습하는 것이다. 이 공간에서는 의미적으로 유사한 데이터 샘플들의 벡터 표현은 서로 가깝게 위치하고, 유사하지 않은 샘플들의 벡터는 멀리 떨어지게 된다.2 Triplet Loss는 이러한 거리 학습의 목표를 달성하기 위해 특별히 설계된 손실 함수이다.5</p>
<p>전통적인 딥러닝 분류 모델에서 널리 사용되는 Softmax 손실 함수는 정해진 수의 클래스에 대해 각 클래스에 속할 확률을 계산하는 방식으로 작동한다. 이는 훈련 데이터에 존재하는 클래스들로 구성된 ‘닫힌 집합(closed-set)’ 문제에서는 매우 효과적이다. 하지만 얼굴 인식, 이미지 검색, 개인 재식별과 같이 시스템이 운영되는 동안에도 계속해서 새로운 클래스(예: 새로운 사람, 새로운 객체)가 추가되는 ‘열린 집합(open-set)’ 문제에 직면하면 Softmax 기반 모델은 근본적인 한계에 부딪힌다. 새로운 클래스를 인식하기 위해서는 모델의 마지막 분류 레이어를 수정하고 전체 모델을 재학습해야 하는 비효율성이 발생하기 때문이다.6</p>
<p>이 지점에서 Triplet Loss는 분류에서 표현 학습(Representation Learning)으로의 중요한 패러다임 전환을 제시한다. Triplet Loss는 특정 클래스 레이블을 직접 예측하는 대신, 임베딩 공간의 ‘구조’ 자체를 학습하는 데 집중한다. 즉, ’같은 클래스에 속하는 샘플들은 서로 가깝게, 다른 클래스에 속하는 샘플들은 서로 멀게’라는 상대적인 거리 관계를 학습의 목표로 삼는다.5 이렇게 학습된 모델은 훈련 데이터에 존재하지 않았던 새로운 클래스의 데이터가 입력되더라도, 기존에 데이터베이스에 등록된 임베딩 벡터들과의 거리를 계산하여 유사도를 판별할 수 있다. 이는 모델의 재학습 없이도 시스템을 유연하게 확장할 수 있게 만들어주며, 대규모 실세계 인식 시스템이 요구하는 확장성과 일반화 성능을 만족시키는 핵심적인 역할을 한다.9 결국 Triplet Loss는 단순한 분류기를 넘어, 범용적으로 활용 가능한 ’유사도 측정기(similarity meter)’를 구축하는 것을 목표로 하며, 이는 현대 딥러닝 응용 분야에서 그 중요성이 날로 커지고 있다.</p>
<h3>1.2  핵심 구성 요소: 앵커, 포지티브, 네거티브</h3>
<p>Triplet Loss는 이름에서 알 수 있듯이, 세 개의 데이터 샘플로 구성된 ’트리플렛(triplet)’을 기본 단위로 하여 학습을 진행한다. 이 세 가지 핵심 구성 요소는 다음과 같이 정의된다.5</p>
<ul>
<li>
<p><strong>앵커 (Anchor, A):</strong> 기준점이 되는 샘플이다. 예를 들어, 특정 인물 ’A’의 얼굴 이미지 한 장이 앵커가 될 수 있다.</p>
</li>
<li>
<p><strong>포지티브 (Positive, P):</strong> 앵커와 동일한 클래스(identity)에 속하는 또 다른 샘플이다. 즉, 인물 ’A’의 다른 얼굴 이미지가 포지티브가 된다.</p>
</li>
<li>
<p><strong>네거티브 (Negative, N):</strong> 앵커와 다른 클래스에 속하는 샘플이다. 인물 ’B’의 얼굴 이미지가 네거티브가 될 수 있다.</p>
</li>
</ul>
<p>Triplet Loss의 학습 목표는 임베딩 공간 상에서 앵커(A)를 기준으로 포지티브(P)는 최대한 가깝게 끌어당기고, 네거티브(N)는 최대한 멀리 밀어내는 것이다.12 이를 통해, 학습이 완료된 임베딩 공간에서는 동일한 클래스에 속하는 샘플들은 조밀한 군집(cluster)을 형성하고, 서로 다른 클래스의 군집들은 명확하게 분리된다. 이 직관적인 목표는 수학적으로 앵커와 포지티브 간의 거리(<span class="math math-inline">d(A, P)</span>)가 앵커와 네거티브 간의 거리(<span class="math math-inline">d(A, N)</span>)보다 작아야 한다는 조건, 즉 <span class="math math-inline">d(A, P) &lt; d(A, N)</span>으로 표현될 수 있다. Triplet Loss는 이 조건을 만족시키도록 신경망의 가중치를 업데이트한다.</p>
<h3>1.3  수학적 정의: 손실 함수 완전 분해</h3>
<p>Triplet Loss의 학습 목표를 구체화한 수학적 공식은 다음과 같다. 이 공식은 N개의 트리플렛으로 구성된 배치에 대한 총 손실을 나타낸다.5</p>
<p><span class="math math-display">
L = \sum_{i=1}^{N} \max\left( \|f(x_i^a) - f(x_i^p)\|_2^2 - \|f(x_i^a) - f(x_i^n)\|_2^2 + \alpha, 0 \right)
</span><br />
이 수식은 여러 핵심 요소로 구성되어 있으며, 각 요소의 역할은 다음과 같다.</p>
<h4>1.3.1 거리 함수 (Distance Function)</h4>
<p>수식에서 <span class="math math-inline">f(x)</span>는 입력 데이터 x를 임베딩 공간의 벡터로 매핑하는 신경망 모델을 의미한다. <span class="math math-inline">||f(x_a) - f(x_p)||_2^2</span>와 <span class="math math-inline">||f(x_a) - f(x_n)||_2^2</span> 항은 각각 앵커-포지티브, 앵커-네거티브 임베딩 벡터 간의 제곱 유클리드 거리(Squared Euclidean Distance 또는 Squared L2 Norm)를 나타낸다.3 손실 함수는 첫 번째 항인 앵커-포지티브 거리를 최소화하고, 두 번째 항인 앵커-네거티브 거리를 최대화하는 방향으로 모델을 학습시킨다. 유클리드 거리가 가장 보편적으로 사용되지만, 문제의 특성에 따라 코사인 거리(Cosine Distance)와 같은 다른 거리 척도도 사용될 수 있다.18</p>
<h4>1.3.2 마진 (Margin, <span class="math math-inline">\alpha</span>)</h4>
<p>마진 <span class="math math-inline">\alpha</span>는 Triplet Loss에서 매우 중요한 역할을 하는 하이퍼파라미터이다. 마진의 존재는 단순히 <span class="math math-inline">d(A, P) &lt; d(A, N)</span>이라는 조건을 넘어, <span class="math math-inline">d(A, P) + \alpha &lt; d(A, N)</span>이라는 더 엄격한 제약 조건을 강제한다.14 즉, 네거티브 샘플이 포지티브 샘플보다 단순히 멀리 있는 것만으로는 부족하며, 최소한 <span class="math math-inline">\alpha</span>만큼의 ’안전 거리’를 두고 더 멀리 떨어져 있어야 함을 의미한다.</p>
<p>마진이 필요한 이유는 모델이 ’자명한 해(trivial solution)’에 빠지는 것을 방지하기 위함이다. 만약 마진이 없다면, 모델은 모든 입력을 하나의 동일한 점으로 매핑하는 <span class="math math-inline">f(x) = c</span>와 같은 함수를 학습할 수 있다. 이 경우 모든 샘플 간의 거리는 0이 되어 <span class="math math-inline">d(A, P) = d(A, N) = 0</span>이 되므로, 손실 함수의 조건(<span class="math math-inline">d(A, P) \leq d(A, N)</span>)을 쉽게 만족시키게 된다. 하지만 이러한 임베딩은 아무런 변별력을 갖지 못한다. 양수 값의 마진 <span class="math math-inline">\alpha</span>를 도입함으로써, 모델은 반드시 서로 다른 클래스를 분리시키는 유의미한 임베딩 공간을 학습하도록 강제된다.19 이 마진 값은 데이터셋의 특성과 난이도에 따라 신중하게 조정되어야 하는 중요한 하이퍼파라미터이다.</p>
<h4>1.3.3 <code>max(..., 0)</code> 함수의 역할</h4>
<p>수식의 <span class="math math-inline">\max(..., 0)</span> 부분은 힌지 손실(Hinge Loss)과 유사한 형태로, 계산된 손실 값이 0보다 작아지는 것을 방지한다.2 이 함수의 역할은 매우 중요하다. 만약 어떤 트리플렛이 이미 마진 조건을 충분히 만족하여 <span class="math math-inline">d(A, N) &gt; d(A, P) + \alpha</span>가 되면, <span class="math math-inline">(d(A, P) - d(A, N) + \alpha)</span> 항은 음수 값을 갖게 된다. 이때 <span class="math math-inline">\max(..., 0)</span> 함수는 최종 손실을 0으로 만든다.</p>
<p>이는 이미 잘 분리된 ‘쉬운(easy)’ 트리플렛에 대해서는 더 이상 모델의 가중치를 업데이트하지 않겠다는 의미이다. 즉, 손실이 0이므로 역전파 과정에서 그래디언트가 발생하지 않는다. 이 메커니즘 덕분에 모델은 학습 과정에서 마진 조건을 위반하는 ‘어려운(hard)’ 트리플렛에만 집중할 수 있게 되어, 학습 자원을 효율적으로 사용하고 더 빠르게 수렴할 수 있다.19</p>
<h2>2. 부: Triplet 마이닝: 학습 효율 극대화 전략</h2>
<h3>2.1  왜 마이닝이 중요한가?</h3>
<p>Triplet Loss를 효과적으로 사용하기 위해서는 ’트리플렛 마이닝(Triplet Mining)’이라는 과정이 필수적이다. 마이닝이 중요한 이유는 계산 효율성과 학습 효과라는 두 가지 측면에서 설명할 수 있다.</p>
<p>첫째, 계산 효율성 측면에서, 크기가 N인 데이터셋에서 생성할 수 있는 모든 가능한 트리플렛의 수는 대략 <span class="math math-inline">O(N^3)</span>에 비례한다.21 대규모 데이터셋의 경우 이는 천문학적인 숫자가 되며, 모든 트리플렛을 사용하여 학습하는 것은 현실적으로 불가능하다.</p>
<p>둘째, 학습 효과 측면에서, 무작위로 샘플링된 대부분의 트리플렛은 이미 마진 조건을 쉽게 만족하는 ’쉬운 트리플렛(easy triplets)’이다. 이러한 트리플렛들은 손실 값을 0으로 만들기 때문에, 모델의 파라미터를 업데이트하는 데 아무런 기여를 하지 못한다.14 즉, 대부분의 계산이 학습에 도움이 되지 않는 낭비로 이어진다. 따라서 학습을 가속화하고 모델이 어려운 경계 조건을 학습하여 높은 변별력을 갖추도록 하기 위해서는, 손실이 0보다 커서 유의미한 그래디언트를 생성하는 ‘어려운(hard)’ 또는 ‘준-어려운(semi-hard)’ 트리플렛을 효과적으로 선별하는 마이닝 과정이 반드시 필요하다.5</p>
<h3>2.2  오프라인(Offline) vs. 온라인(Online) 마이닝</h3>
<p>트리플렛 마이닝 전략은 크게 오프라인 방식과 온라인 방식으로 나눌 수 있다.</p>
<ul>
<li>
<p><strong>오프라인 마이닝 (Offline Mining):</strong> 이 방식은 본격적인 학습 시작 전이나 매 에폭(epoch)이 시작될 때, 전체 훈련 데이터셋을 대상으로 트리플렛을 미리 생성해두는 전략이다. 데이터셋 전체의 통계적 분포를 고려하여 잠재적으로 더 양질의 트리플렛을 선별할 수 있다는 장점이 있다.26 하지만 전체 데이터셋에 대해 임베딩을 계산하고 거리를 비교해야 하므로 계산 비용이 매우 높다. 더 큰 문제점은, 학습이 진행됨에 따라 모델의 가중치가 계속 업데이트되는데, 초기에 생성된 ‘어려운’ 트리플렛이 나중에는 ‘쉬운’ 트리플렛이 되어버릴 수 있다는 점이다. 이처럼 모델의 변화에 동적으로 대응하지 못하는 한계가 있다.15</p>
</li>
<li>
<p><strong>온라인 마이닝 (Online Mining):</strong> 이 방식은 학습 과정에서 각 미니배치(mini-batch)가 모델에 입력될 때마다, 해당 배치 내의 샘플들을 사용하여 실시간으로 트리플렛을 구성하는 전략이다. 계산이 현재의 미니배치 내에서만 이루어지므로 훨씬 효율적이다. 또한, 항상 현재 모델의 상태를 기준으로 가장 도전적인 트리플렛을 동적으로 찾아내기 때문에 학습을 효과적으로 가속화할 수 있다.28 Google의 FaceNet 논문에서 이 전략이 제안된 이후, 대부분의 현대적인 거리 학습 방법론에서는 온라인 마이닝을 표준으로 채택하고 있다.3</p>
</li>
</ul>
<h3>2.3  Triplet의 세 가지 유형: Easy, Hard, Semi-Hard</h3>
<p>온라인 마이닝을 이해하기 위해서는 먼저 임베딩 공간에서 앵커(A), 포지티브(P), 네거티브(N)의 상대적 위치에 따라 트리플렛을 세 가지 유형으로 분류해야 한다. 이 분류는 앵커-포지티브 거리(<span class="math math-inline">d(A, P)</span>)와 앵커-네거티브 거리(<span class="math math-inline">d(A, N)</span>), 그리고 마진(<span class="math math-inline">\alpha</span>)을 기준으로 이루어진다.17</p>
<ul>
<li>
<p><strong>Easy Triplets:</strong> 이 트리플렛은 <span class="math math-inline">d(A, N) &gt; d(A, P) + \alpha</span> 조건을 만족한다. 즉, 네거티브 샘플이 포지티브 샘플보다 마진 값 이상으로 이미 멀리 떨어져 있는 경우이다. 이 경우 손실 함수 값은 0이 되므로, 학습에 아무런 기여를 하지 않는다.</p>
</li>
<li>
<p><strong>Hard Triplets:</strong> 이 트리플렛은 <span class="math math-inline">d(A, N) &lt; d(A, P)</span> 조건을 만족한다. 즉, 네거티브 샘플이 포지티브 샘플보다 앵커에 더 가까이 있는, 모델이 명백히 잘못 판단하고 있는 가장 어려운 경우이다. 이론적으로는 가장 많은 정보를 담고 있어 학습에 가장 효과적일 것 같지만, 실제로는 몇 가지 문제를 야기할 수 있다. 학습 초기에 너무 어려운 샘플(예: 잘못 레이블링된 데이터, 품질이 매우 낮은 이미지 등 이상치)에만 집중하게 되면 모델이 불안정해지거나, 모든 임베딩을 한 점으로 수렴시키는 ‘모델 붕괴(model collapse)’ 현상을 유발하며 잘못된 지역 최적해(local minima)에 빠질 위험이 있다.23</p>
</li>
<li>
<p><strong>Semi-Hard Triplets:</strong> 이 트리플렛은 <span class="math math-inline">d(A, P) &lt; d(A, N) &lt; d(A, P) + \alpha</span> 조건을 만족한다. 즉, 네거티브 샘플이 포지티브 샘플보다는 멀리 있지만, 마진으로 설정된 ‘안전 거리’ 안쪽에 위치하여 여전히 0보다 큰 손실 값을 생성하는 경우이다. 이 트리플렛들은 모델에게 충분히 도전적인 과제를 제공하면서도, Hard Triplets가 유발할 수 있는 학습 불안정성을 피할 수 있는 ’최적의 난이도’를 가진다고 여겨진다. FaceNet 논문에서 이 Semi-Hard Triplets를 선택하는 전략을 제안했으며, 많은 연구에서 안정적이고 효과적인 학습을 위해 이 전략을 채택하고 있다.5</p>
</li>
</ul>
<h3>2.4  온라인 마이닝 핵심 전략</h3>
<p>온라인 마이닝은 미니배치 내에서 어떤 트리플렛을 선택하여 손실 계산에 사용할지에 따라 여러 구체적인 전략으로 나뉜다.</p>
<ul>
<li>
<p><strong>Batch All:</strong> 이 전략은 가장 직관적인 접근법이다. 미니배치 내에서 생성 가능한 모든 유효한 트리플렛을 고려한다. 그 후, 손실 값이 0이 되는 Easy Triplets를 제외하고, 손실이 0보다 큰 모든 트리플렛(즉, 모든 Hard Triplets와 Semi-Hard Triplets)의 손실 값을 계산하여 평균을 낸다.14 이 방법은 배치 내의 유용한 정보를 최대한 활용한다는 장점이 있지만, 배치 크기가 커질수록 고려해야 할 트리플렛의 수가 기하급수적으로 늘어나 계산 비용이 매우 높아질 수 있다.</p>
</li>
<li>
<p><strong>Batch Hard:</strong> 이 전략은 효율성을 극대화하기 위해 각 앵커 샘플에 대해 가장 정보량이 많은 트리플렛 하나만을 선택한다. 구체적으로, 각 앵커에 대해 배치 내에서 가장 멀리 있는 포지티브(hardest positive)와 가장 가까이 있는 네거티브(hardest negative)를 찾아 하나의 트리플렛을 구성한다.24 배치 크기가</p>
</li>
</ul>
<p>N이라면 N개의 가장 도전적인 트리플렛이 생성된다. 이 방법은 학습 초기 수렴 속도를 크게 높일 수 있지만, 앞서 언급했듯이 이상치나 노이즈가 섞인 가장 어려운 샘플에만 집중하게 되어 모델이 불안정해지거나 붕괴될 위험이 있다.34</p>
<ul>
<li><strong>Semi-Hard Negative Mining:</strong> FaceNet에서 제안된 핵심 전략으로, Batch Hard의 불안정성을 완화하기 위해 고안되었다. 이 전략은 각 앵커-포지티브 쌍(A,P)에 대해, 네거티브 샘플 N을 선택할 때 Semi-Hard 조건(<span class="math math-inline">d(A, P) &lt; d(A, N) &lt; d(A, P) + \alpha</span>)을 만족하는 것들 중에서만 고른다. 이는 너무 쉬운 네거티브와 너무 어려운 네거티브를 모두 배제하고, 학습에 가장 이상적인 난이도를 가진 네거티브를 선택함으로써 안정성과 효율성 사이의 균형을 맞추는 접근법이다.3</li>
</ul>
<p>이러한 온라인 마이닝 전략의 성공은 단순히 알고리즘 자체의 우수성에만 달려있지 않다. 전략이 효과적으로 작동하기 위한 ‘환경’, 즉 미니배치의 구성이 매우 중요하다. 만약 미니배치가 충분히 크지 않거나 다양성이 부족하다면, ‘배치 내에서 가장 어려운’ 샘플이라 할지라도 전체 데이터셋 관점에서는 전혀 어렵지 않은 샘플일 수 있다. 이 때문에 FaceNet 연구에서는 1800개라는 매우 큰 배치 크기를 사용했으며, 각 배치에 P개의 클래스에서 각각 K개의 이미지를 샘플링하는 ‘PK 샘플링’ 방식을 도입했다.4 이러한 배치 구성 전략은 각 앵커에 대해 충분한 수의 포지티브 및 네거티브 후보군이 항상 배치 내에 존재하도록 보장함으로써, 온라인 마이닝이 전역적인 관점에서도 유의미한 어려운 트리플렛을 찾을 확률을 극대화한다. 따라서, 효과적인 온라인 마이닝을 위해서는 알고리즘과 함께 배치 구성 전략을 신중하게 설계해야 한다.</p>
<p><strong>표 1: Triplet 마이닝 전략 비교</strong></p>
<table><thead><tr><th>전략 (Strategy)</th><th>트리플렛 선택 방식 (Triplet Selection Method)</th><th>장점 (Advantages)</th><th>단점 (Disadvantages)</th></tr></thead><tbody>
<tr><td><strong>Batch All</strong></td><td>미니배치 내에서 가능한 모든 유효한 트리플렛을 생성. 단, 손실이 0인 ’Easy Triplets’는 제외하고 손실을 계산.</td><td>- 배치 내 모든 유용한 정보를 최대한 활용함.<br>- 가장 직관적이고 간단한 접근 방식.</td><td>- 배치 크기가 커지면 고려할 트리플렛 수가 기하급수적으로 증가.<br>- 계산 비용이 매우 높음.</td></tr>
<tr><td><strong>Batch Hard</strong></td><td>각 앵커(Anchor)에 대해 가장 먼 포지티브(Hardest Positive)와 가장 가까운 네거티브(Hardest Negative)를 선택하여 하나의 트리플렛을 구성.</td><td>- 학습 초기 수렴 속도를 크게 높일 수 있음.<br>- 가장 정보량이 많은 샘플에 집중하여 효율성을 극대화함.</td><td>- 이상치(outlier)나 노이즈에 민감함.<br>- 가장 어려운 샘플에만 집중하여 모델 학습이 불안정해지거나 붕괴될 위험이 있음.</td></tr>
<tr><td><strong>Semi-Hard Negative Mining</strong></td><td>각 앵커-포지티브(A, P) 쌍에 대해, 네거티브(N)가 <code>d(A, P) &lt; d(A, N) &lt; d(A, P) + α</code> 조건을 만족하는 경우에만 선택.</td><td>- 너무 쉽거나 너무 어려운 샘플을 배제하여 학습 안정성을 높임.<br>- 안정성과 효율성 사이의 좋은 균형을 이룸.<br>- <strong>FaceNet</strong>에서 제안된 핵심 전략.</td><td>- 효과적인 샘플을 찾기 위해 미니배치의 구성(크기, 다양성)이 매우 중요함.<br>- 조건에 맞는 네거티브가 배치 내에 없을 수도 있음.</td></tr>
</tbody></table>
<p><em><strong>배치 구성의 중요성</strong>: 어떤 온라인 마이닝 전략을 사용하든, 미니배치가 충분히 크고 다양하게 구성되지 않으면 효과가 떨어질 수 있다. 특히 <strong>Semi-Hard</strong>나 <strong>Batch Hard</strong> 전략은 배치 내에 유의미하고 도전적인 네거티브 샘플이 포함되어야만 제대로 작동한다. 이를 위해 FaceNet에서는 PK 샘플링 방식과 함께 매우 큰 배치 크기를 사용하여 문제를 해결했다.</em></p>
<h2>3. 부: 주요 적용 분야 및 심층 사례 연구</h2>
<p>Triplet Loss는 그 유연성과 강력한 표현 학습 능력 덕분에 다양한 컴퓨터 비전 및 기계 학습 분야에서 핵심적인 도구로 자리 잡았다. 특히, 클래스의 수가 많거나 지속적으로 변하는 ‘열린 집합’ 문제에서 그 진가를 발휘한다.</p>
<h3>3.1  얼굴 인식 (Face Recognition)</h3>
<p>Triplet Loss가 가장 성공적으로 적용되고 널리 알려지게 된 계기는 바로 얼굴 인식 분야이다. 수백만, 수억 명의 사람들을 구별해야 하는 이 문제에서 Triplet Loss는 탁월한 해결책을 제시했다.</p>
<h4>3.1.1 사례 연구: Google의 FaceNet 심층 분석</h4>
<p>2015년 발표된 Google의 FaceNet 논문은 Triplet Loss를 딥러닝 기반 얼굴 인식의 주류 기술로 끌어올린 기념비적인 연구이다.3 FaceNet의 성공은 다음과 같은 핵심 아이디어에 기반한다.</p>
<ul>
<li>
<p><strong>임베딩 직접 최적화:</strong> 이전의 딥러닝 기반 얼굴 인식 방법들은 대부분 Softmax 손실 함수로 다수의 인물을 분류하는 모델을 학습시킨 뒤, 마지막 분류 레이어 이전의 ‘병목(bottleneck)’ 레이어를 특징 벡터로 사용하는 간접적인 방식을 취했다. FaceNet은 이러한 접근법에서 벗어나, 얼굴 이미지를 128차원의 컴팩트한 유클리드 공간으로 직접 매핑하는 임베딩 함수 자체를 Triplet Loss를 통해 종단간(end-to-end)으로 최적화했다.3 이 임베딩 공간에서는 두 벡터 간의 L2 거리가 곧 두 얼굴의 유사도를 직접적으로 나타내도록 학습된다.</p>
</li>
<li>
<p><strong>네트워크 아키텍처:</strong> FaceNet은 당시 최신 기술이었던 GoogLeNet(Inception-v1)과 ZFNet 기반의 심층 컨볼루션 신경망(CNN)을 기본 구조로 사용했다.6 특히, 모델의 마지막 부분에 L2 정규화(L2 Normalization) 레이어를 추가하여 모든 얼굴 임베딩 벡터의 길이를 1로 만들었다. 이는 모든 임베딩이 반지름이 1인 다차원 초구(hypersphere) 표면에 분포하도록 강제함으로써, 학습을 안정화하고 거리 계산을 용이하게 만드는 효과를 가져왔다.3</p>
</li>
<li>
<p><strong>핵심 기여 - 온라인 마이닝:</strong> FaceNet의 가장 중요한 기여 중 하나는 대규모 데이터셋에서 Triplet Loss를 효과적으로 학습시키기 위한 ‘온라인 Semi-Hard Negative 마이닝’ 전략을 제안한 것이다.3 이 전략은 앞서 2부에서 설명한 바와 같이, 학습의 안정성과 효율성을 동시에 확보하여 수백만 장의 얼굴 이미지 데이터셋에서도 모델이 성공적으로 수렴할 수 있도록 만들었다.</p>
</li>
<li>
<p><strong>성과:</strong> 이러한 혁신적인 접근법을 통해 FaceNet은 당시 얼굴 인식 분야의 표준 벤치마크였던 LFW(Labeled Faces in the Wild) 데이터셋에서 99.63%라는 전례 없는 정확도를 달성하며, Triplet Loss 기반 거리 학습의 압도적인 성능을 증명했다.3</p>
</li>
</ul>
<h3>3.2  개인 재식별 (Person Re-identification, Re-ID)</h3>
<p>개인 재식별(Re-ID)은 쇼핑몰, 공항 등 여러 대의 CCTV 카메라가 설치된 환경에서, 서로 시야가 겹치지 않는 다른 카메라에 포착된 동일 인물을 찾아내는 기술이다. 이 문제는 동일 인물이라도 카메라의 위치, 각도, 조명 조건에 따라 외형이 크게 달라 보이고, 다른 인물이라도 비슷한 옷차림을 할 수 있어 매우 도전적인 과제이다.</p>
<p>Triplet Loss는 이러한 Re-ID 문제에 매우 효과적인 해결책을 제공한다. 동일 인물의 이미지들(포지티브 쌍)로부터 추출된 임베딩 벡터들은 서로 가깝게, 다른 인물의 이미지들(네거티브 쌍)로부터 추출된 벡터들은 서로 멀어지도록 학습함으로써, 자세, 조명, 가림(occlusion) 등 다양한 외형 변화에 강인한(robust) 특징 표현을 학습할 수 있다.37 Re-ID 분야에서는 기본적인 Triplet Loss를 넘어, 비디오 시퀀스 전체를 하나의 집합(set)으로 보고 집합 간의 거리를 측정하는 ’Set Augmented Triplet Loss’나, 어려운 샘플에 더 높은 가중치를 부여하는 ’Hard-Aware Point-to-Set(HAP2S) Loss’와 같이 문제의 특성에 맞게 변형된 다양한 Triplet 기반 손실 함수들이 활발히 연구되고 있다.37</p>
<h3>3.3  이미지 검색 (Image Retrieval)</h3>
<p>내용 기반 이미지 검색(Content-Based Image Retrieval, CBIR)은 사용자가 제시한 쿼리 이미지와 시각적으로 유사한 이미지들을 대규모 데이터베이스에서 찾아주는 기술이다. Triplet Loss는 이 분야의 핵심 엔진으로 사용된다.</p>
<p>학습 단계에서는 특정 카테고리의 이미지들을 동일 클래스로 간주하여 Triplet Loss로 모델을 학습시킨다. 예를 들어, ‘고양이’ 이미지들을 포지티브로, ‘강아지’ 이미지를 네거티브로 사용하여, 모델이 ’고양이’라는 개념에 대한 강인한 임베딩을 학습하도록 한다. 검색 단계에서는, 사용자가 쿼리 이미지(예: 특정 품종의 고양이 사진)를 입력하면, 학습된 모델이 이 이미지를 임베딩 벡터로 변환한다. 그 후, 데이터베이스에 미리 저장된 수백만 장의 이미지 임베딩 벡터들 중에서 쿼리 벡터와 유클리드 거리 또는 코사인 거리가 가장 가까운 벡터들을 찾아 해당 이미지들을 검색 결과로 반환한다. 이 방식은 텍스트 태그 없이 이미지의 시각적 내용만으로 정확한 검색을 가능하게 한다.40</p>
<h3>3.4  기타 응용</h3>
<p>Triplet Loss의 기본 원리인 ’유사도 기반 공간 학습’은 위에서 언급한 대표적인 분야 외에도 다양한 문제에 적용될 수 있다.</p>
<ul>
<li>
<p><strong>이상 탐지 (Anomaly Detection):</strong> 정상적인 데이터들의 임베딩 분포를 조밀하게 학습시킨 후, 이 분포에서 멀리 떨어진 임베딩을 가진 새로운 데이터를 이상치(anomaly)로 탐지할 수 있다. 예를 들어, 공장 생산 라인에서 정상 제품 이미지만으로 모델을 학습시킨 뒤, 불량품 이미지가 들어왔을 때 그 임베딩이 정상 분포에서 크게 벗어나는 것을 통해 불량을 판별할 수 있다.43</p>
</li>
<li>
<p><strong>추천 시스템 (Recommendation Systems):</strong> 사용자나 상품을 임베딩 공간의 벡터로 표현하고, Triplet Loss를 이용해 유사한 취향을 가진 사용자나 비슷한 속성을 가진 상품들이 임베딩 공간에서 가깝게 위치하도록 학습할 수 있다. 예를 들어, &lt;사용자 A, 사용자 A가 선호한 상품, 사용자 A가 선호하지 않은 상품&gt;과 같은 트리플렛을 구성하여 개인화된 추천 모델을 만들 수 있다.43</p>
</li>
</ul>
<p>이처럼 Triplet Loss는 특정 도메인에 국한되지 않고, 데이터 간의 상대적 유사성을 학습하는 것이 중요한 모든 문제에 적용될 수 있는 범용적이고 강력한 도구이다.</p>
<h2>4. 부: 주요 딥러닝 프레임워크 구현 가이드</h2>
<p>Triplet Loss, 특히 온라인 마이닝 전략을 구현하는 것은 몇 가지 핵심적인 기술 요소를 필요로 한다. 여기서는 PyTorch와 TensorFlow라는 두 가지 주요 딥러닝 프레임워크를 사용하여 Triplet Loss를 구현하는 방법을 상세히 안내한다.</p>
<h3>4.1  PyTorch를 이용한 구현</h3>
<p>PyTorch는 유연한 계산 그래프와 풍부한 라이브러리를 제공하여 Triplet Loss 구현에 널리 사용된다.</p>
<h4>4.1.1 기본 구현: <code>nn.TripletMarginLoss</code></h4>
<p>PyTorch는 <code>torch.nn.TripletMarginLoss</code>라는 내장 모듈을 제공한다. 이 모듈은 Triplet Loss의 기본 공식을 구현하고 있지만, 사용 방식에 주의가 필요하다.44</p>
<pre><code class="language-Python">import torch
import torch.nn as nn

# margin=1.0, L2 norm (p=2)
triplet_loss_fn = nn.TripletMarginLoss(margin=1.0, p=2)

# 입력은 (anchor, positive, negative) 텐서 형태여야 함
# 각 텐서의 shape는 (N, D) - N: 배치 크기, D: 임베딩 차원
anchor_embeddings = torch.randn(32, 128)
positive_embeddings = torch.randn(32, 128)
negative_embeddings = torch.randn(32, 128)

loss = triplet_loss_fn(anchor_embeddings, positive_embeddings, negative_embeddings)
print(loss)
</code></pre>
<p><code>nn.TripletMarginLoss</code>는 이미 구성된 앵커, 포지티브, 네거티브 임베딩 텐서를 각각 입력으로 받는다. 이는 트리플렛이 데이터 로딩 시점에 미리 결정되어야 함을 의미하며, 따라서 이 모듈을 그대로 사용하는 것은 ‘오프라인 마이닝’ 방식에 가깝다.45 온라인 마이닝을 구현하기 위해서는 데이터 로더에서 동적으로 트리플렛을 샘플링하는 복잡한 로직을 구현하거나, 아래에 설명할 커스텀 손실 함수를 직접 정의해야 한다.</p>
<h4>4.1.2 온라인 마이닝 직접 구현 (Batch Hard 전략 예시)</h4>
<p>온라인 마이닝, 특히 Batch Hard 전략을 직접 구현하는 것이 더 일반적이고 효과적이다. 구현은 다음 단계로 이루어진다.</p>
<ol>
<li>
<p><strong>쌍별 거리 행렬 계산:</strong> 배치 내 모든 임베딩 벡터 간의 거리를 효율적으로 계산한다. 반복문을 사용하는 대신 행렬 연산을 활용하는 것이 성능에 매우 중요하다.15</p>
</li>
<li>
<p><strong>유효 쌍 마스크 생성:</strong> 레이블 정보를 바탕으로 어떤 쌍이 포지티브 쌍이고 어떤 쌍이 네거티브 쌍인지 나타내는 불리언(boolean) 마스크를 생성한다.15</p>
</li>
<li>
<p><strong>Hardest 샘플 선택:</strong> 생성된 거리 행렬과 마스크를 이용해 각 앵커에 대한 가장 어려운 포지티브(가장 먼 포지티브)와 가장 어려운 네거티브(가장 가까운 네거티브)를 찾는다.24</p>
</li>
<li>
<p><strong>손실 계산:</strong> 선택된 거리들을 이용해 최종 Triplet Loss를 계산한다.</p>
</li>
</ol>
<p>아래는 Batch Hard 전략을 구현한 PyTorch 코드 예시이다.</p>
<pre><code class="language-Python">import torch
import torch.nn.functional as F

def batch_hard_triplet_loss(labels, embeddings, margin, squared=False):
    """    Batch Hard Triplet Loss 구현.    - labels: (N,) shape의 레이블 텐서    - embeddings: (N, D) shape의 임베딩 텐서    - margin: 손실 함수에 사용될 마진 값    - squared: 거리 계산 시 제곱 유클리드 거리를 사용할지 여부    """
    # 1. 쌍별 거리 행렬 계산
    # pairwise_dist.shape: (N, N)
    pairwise_dist = torch.cdist(embeddings, embeddings, p=2)
    if squared:
        pairwise_dist = pairwise_dist.pow(2)

    # 2. 유효 쌍 마스크 생성
    # mask_anchor_positive.shape: (N, N)
    mask_anchor_positive = (labels.unsqueeze(1) == labels.unsqueeze(0)).float()
    mask_anchor_positive.fill_diagonal_(0) # 자기 자신과의 쌍은 제외

    # 3. Hardest Positive 선택
    # anchor_positive_dist.shape: (N, N)
    # 포지티브 쌍이 아닌 곳은 0으로 만들어 max 계산에 영향 없도록 함
    anchor_positive_dist = mask_anchor_positive * pairwise_dist
    # hardest_positive_dist.shape: (N,)
    hardest_positive_dist, _ = torch.max(anchor_positive_dist, dim=1)

    # 4. Hardest Negative 선택
    # mask_anchor_negative.shape: (N, N)
    mask_anchor_negative = (labels.unsqueeze(1)!= labels.unsqueeze(0)).float()

    # 네거티브 쌍이 아닌 곳은 큰 값으로 채워 min 계산 시 선택되지 않도록 함
    max_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)
    anchor_negative_dist = pairwise_dist + max_dist * (1.0 - mask_anchor_negative)
    # hardest_negative_dist.shape: (N,)
    hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1)

    # 5. 손실 계산
    # 손실이 0보다 큰 (유효한) 트리플렛만 필터링
    loss = F.relu(hardest_positive_dist - hardest_negative_dist + margin)

    # 유효한 트리플렛들의 평균 손실을 반환
    num_non_zero_losses = (loss &gt; 0).sum()
    if num_non_zero_losses == 0:
        return torch.tensor(0.0)

    return loss.sum() / num_non_zero_losses

# 예시 데이터
embeddings = torch.rand(10, 128) # 5개 클래스, 클래스당 2개 샘플
labels = torch.tensor()
margin = 0.5

loss = batch_hard_triplet_loss(labels, embeddings, margin)
print(loss)
</code></pre>
<h3>4.2  TensorFlow를 이용한 구현</h3>
<p>TensorFlow에서도 PyTorch와 유사한 방식으로 Triplet Loss를 구현할 수 있다.</p>
<h4>4.2.1 <code>tensorflow_addons</code> 활용 (Deprecated)</h4>
<p>과거에는 <code>tensorflow-addons</code> 라이브러리가 온라인 마이닝을 내장한 편리한 손실 함수를 제공했다. <code>tfa.losses.TripletSemiHardLoss</code>는 입력으로 전체 임베딩 배치와 레이블을 받아 내부적으로 Semi-Hard 트리플렛을 자동으로 마이닝하고 손실을 계산해 주었다.47</p>
<pre><code class="language-Python"># 이 코드는 tensorflow_addons가 설치된 환경에서 작동합니다.
# 현재 이 라이브러리는 개발이 중단되었습니다.
import tensorflow as tf
import tensorflow_addons as tfa

model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss=tfa.losses.TripletSemiHardLoss(margin=1.0)
)
</code></pre>
<p>이 방식은 매우 간편하지만, <code>tensorflow-addons</code> 프로젝트가 2024년 5월 이후로 유지보수가 중단되었으므로 새로운 프로젝트에서는 사용을 권장하지 않는다.</p>
<h4>4.2.2 커스텀 구현</h4>
<p>현재 TensorFlow 2.x 환경에서는 온라인 마이닝을 직접 구현하는 것이 표준적인 방법이다. 로직은 PyTorch 구현과 매우 유사하며, TensorFlow의 행렬 연산 함수들을 사용한다.4</p>
<pre><code class="language-Python">import tensorflow as tf

def batch_hard_triplet_loss_tf(labels, embeddings, margin, squared=False):
    """    TensorFlow를 이용한 Batch Hard Triplet Loss 구현    """
    # 1. 쌍별 거리 행렬 계산
    pairwise_dist = tf.reduce_sum(tf.square(tf.expand_dims(embeddings, 1) - tf.expand_dims(embeddings, 0)), axis=2)
    if not squared:
        # 수치 안정성을 위해 epsilon 추가
        pairwise_dist = tf.sqrt(pairwise_dist + 1e-6)

    # 2. 유효 쌍 마스크 생성
    labels = tf.reshape(labels, [-1, 1])
    mask_anchor_positive = tf.cast(tf.equal(labels, tf.transpose(labels)), tf.float32)
    mask_anchor_positive = mask_anchor_positive - tf.linalg.diag(tf.ones(tf.shape(labels)))

    # 3. Hardest Positive 선택
    anchor_positive_dist = mask_anchor_positive * pairwise_dist
    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1)

    # 4. Hardest Negative 선택
    mask_anchor_negative = 1.0 - mask_anchor_positive

    max_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)
    anchor_negative_dist = pairwise_dist + max_dist * (1.0 - mask_anchor_negative)
    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1)

    # 5. 손실 계산
    loss = tf.maximum(0.0, hardest_positive_dist - hardest_negative_dist + margin)

    # 유효한 트리플렛들의 평균 손실을 반환
    num_non_zero_losses = tf.cast(tf.math.count_nonzero(loss), tf.float32)
    loss = tf.reduce_sum(loss) / (num_non_zero_losses + 1e-6)

    return loss

# 예시 데이터
embeddings_tf = tf.random.uniform(shape=(10, 128))
labels_tf = tf.constant()
margin_tf = 0.5

loss_tf = batch_hard_triplet_loss_tf(labels_tf, embeddings_tf, margin_tf)
print(loss_tf)
</code></pre>
<h3>4.3  구현 시 공통 고려사항</h3>
<ul>
<li>
<p><strong>임베딩 L2 정규화:</strong> 많은 경우, 임베딩 벡터를 L2 정규화하여 단위 벡터로 만드는 것이 학습 안정성과 성능에 도움이 된다. 이는 모든 임베딩이 동일한 스케일을 갖도록 하여 거리 계산이 벡터의 방향에만 집중되도록 한다.3 모델의 마지막 레이어에 L2 정규화 층을 추가하는 방식으로 쉽게 구현할 수 있다.</p>
</li>
<li>
<p><strong>수치 안정성:</strong> 유클리드 거리를 계산할 때 제곱근(<code>sqrt</code>) 연산을 사용하게 되는데, 만약 두 벡터가 정확히 일치하여 거리가 0이 되면 역전파 시 그래디언트가 무한대(<code>NaN</code>)가 될 수 있다. 이를 방지하기 위해 제곱근을 취하기 전에 아주 작은 양수 값(epsilon, 예: <code>1e-6</code>)을 더해주는 기법이 널리 사용된다.4</p>
</li>
<li>
<p><strong>배치 구성:</strong> 앞서 <code>Insight 2</code>에서 심도 있게 다루었듯이, 온라인 마이닝의 성능은 미니배치의 구성에 크게 의존한다. 학습 데이터셋에서 배치를 구성할 때, 각 배치에 충분한 수의 클래스와 클래스당 충분한 수의 샘플이 포함되도록 하는 PK 샘플링과 같은 전략을 사용하는 것이 매우 중요하다.</p>
</li>
</ul>
<h2>5. 부: 심층 비교 분석: Triplet Loss와 경쟁자들</h2>
<p>Triplet Loss는 거리 학습 분야에서 큰 성공을 거두었지만, 유일한 해결책은 아니다. 그 효과를 정확히 이해하기 위해서는 주요 경쟁 손실 함수들과의 비교 분석이 필수적이다.</p>
<h3>5.1  Triplet Loss vs. Contrastive Loss</h3>
<p>Contrastive Loss는 Triplet Loss 이전에 널리 사용되던 대표적인 쌍(pair) 기반 거리 학습 손실 함수이다.</p>
<ul>
<li>
<p><strong>핵심 원리:</strong> Contrastive Loss는 두 개의 샘플로 구성된 ’쌍’을 입력으로 받는다. 이 쌍은 동일한 클래스에 속하는 ’포지티브 쌍’과 서로 다른 클래스에 속하는 ’네거티브 쌍’으로 나뉜다. 손실 함수는 포지티브 쌍의 임베딩 간 거리는 최소화하고(이상적으로는 0), 네거티브 쌍의 임베딩 간 거리는 특정 마진(<span class="math math-inline">m</span>) 값보다 커지도록 학습시킨다.5</p>
</li>
<li>
<p><strong>장단점 비교:</strong> Triplet Loss는 Contrastive Loss에 비해 덜 탐욕적인(less greedy) 접근법으로 평가받는다. Contrastive Loss는 모든 포지티브 쌍의 거리를 0으로 만들려는 경향이 있다. 이는 동일 클래스 내에 존재하는 자연스러운 데이터의 분산(intra-class variance)까지 억제하여, 모든 샘플을 하나의 점으로 수렴시키려는 과도한 제약을 가할 수 있다. 반면, Triplet Loss는 세 샘플 간의 ’상대적 거리’에만 초점을 맞춘다. 즉, 네거티브 샘플이 포지티브 샘플보다 마진 이상으로 멀어지기만 하면 손실이 0이 되므로, 포지티브 샘플들을 무조건 한 점으로 모을 필요가 없다. 이 덕분에 Triplet Loss는 클래스 내의 자연스러운 데이터 분포를 어느 정도 허용하면서 더 유연하고 강인한 임베딩 공간을 학습할 수 있다.2</p>
</li>
</ul>
<h3>5.2  Triplet Loss vs. Softmax 기반 Loss (ArcFace, CosFace)</h3>
<p>최근 얼굴 인식과 같은 분야에서는 Triplet Loss와 같은 전통적인 거리 학습 손실 함수 대신, Softmax 손실 함수를 변형한 새로운 형태의 손실 함수들이 최첨단 성능을 달성하고 있다. 대표적인 예가 ArcFace와 CosFace이다.</p>
<ul>
<li>
<p><strong>근본적 차이:</strong> Triplet Loss가 샘플들 간의 직접적인 거리 관계를 최적화하는 ‘거리 학습’ 접근법이라면, ArcFace와 CosFace는 각 샘플을 정해진 클래스로 ’분류’하는 문제를 풀면서 간접적으로 우수한 임베딩 공간을 학습하는 ‘분류 기반 거리 학습’ 접근법이다.</p>
</li>
<li>
<p><strong>ArcFace/CosFace 원리:</strong> 이 손실 함수들은 모델의 마지막 레이어에서 계산되는 특정 샘플의 임베딩 벡터(<span class="math math-inline">x_i</span>)와 그 샘플의 정답 클래스에 해당하는 가중치 벡터(<span class="math math-inline">W_{y_i}</span>) 사이의 각도(<span class="math math-inline">\theta_{y_i}</span>)를 직접적으로 제어한다. 이들은 기존 Softmax 손실이 사용하는 코사인 유사도(<span class="math math-inline">\cos(\theta_{y_i})</span>)에 직접 ‘각도 마진’(ArcFace) 또는 ‘코사인 마진’(CosFace)을 추가한다. 예를 들어, ArcFace는 손실 계산 시 <span class="math math-inline">\cos(\theta_{y_i})</span> 대신 <span class="math math-inline">\cos(\theta_{y_i} + m)</span>을 사용한다. 이 추가된 마진은 모델이 동일 클래스의 임베딩들을 해당 클래스의 가중치 벡터 주변으로 더욱 조밀하게 모으고(intra-class compactness), 다른 클래스의 가중치 벡터로부터는 더 멀리 떨어뜨리도록(inter-class separability) 강제하는 역할을 한다.7</p>
</li>
<li>
<p><strong>장단점 비교:</strong></p>
</li>
<li>
<p><strong>Triplet Loss:</strong> 오픈셋 문제에 강하며, 트리플렛 마이닝을 통해 어떤 샘플에 집중하여 학습할지 정교하게 제어할 수 있다는 장점이 있다. 하지만 마이닝 과정 자체가 복잡하고 추가적인 계산 비용을 요구하며, 잘못된 마이닝 전략은 학습 불안정성을 초래할 수 있다.7</p>
</li>
<li>
<p><strong>ArcFace/CosFace:</strong> 학습 과정이 매우 안정적이고 수렴 속도가 빠르다. 복잡한 샘플링 전략 없이도, Softmax의 특성상 매 업데이트마다 모든 클래스를 암묵적인 ’네거티브’로 고려하기 때문에 매우 효율적이다. 하지만 기본적으로는 훈련 데이터에 존재하는 클래스로 구성된 닫힌셋 문제에 최적화되어 있으며, 클래스의 수가 수백만 개 이상으로 늘어날 경우 가중치 행렬(<span class="math math-inline">W</span>)의 크기가 너무 커져 메모리 문제를 유발할 수 있다.7</p>
</li>
</ul>
<p>이 두 접근법은 단순히 경쟁 관계에 있다기보다는, 거리 학습의 진화 과정을 보여주는 상호 보완적인 관계로 이해할 수 있다. Triplet Loss가 ’마진을 통한 클래스 분리’라는 핵심 아이디어를 제시했다면, ArcFace와 CosFace는 그 아이디어를 더 안정적이고 효율적인 분류 프레임워크 내에서 구현하는 데 성공한 것으로 볼 수 있다. Softmax 기반 손실 함수는 매 학습 단계에서 하나의 포지티브 클래스와 나머지 모든 네거티브 클래스 간의 관계를 자연스럽게 고려하므로, 명시적인 네거티브 샘플링 과정 없이도 효과적인 ‘글로벌’ 마이닝을 수행하는 것과 유사한 효과를 낸다. 따라서 문제의 특성, 데이터셋의 크기, 가용 계산 자원 등을 종합적으로 고려하여 적절한 손실 함수를 선택하는 것이 중요하다.7</p>
<p>다음은 본문 내용을 바탕으로 주요 거리 학습 손실 함수를 비교한 표입니다.</p>
<p><strong>표 2: 주요 거리 학습 손실 함수 비교</strong></p>
<table><thead><tr><th>특징</th><th>Triplet Loss</th><th>ArcFace / CosFace (Softmax 기반 Loss)</th></tr></thead><tbody>
<tr><td><strong>기본 접근법</strong></td><td><strong>거리 학습 (Metric Learning)</strong><br>샘플 간의 직접적인 거리 관계를 최적화합니다.</td><td><strong>분류 기반 거리 학습 (Classification-based)</strong><br>분류 문제를 풀면서 간접적으로 임베딩 공간을 학습합니다.</td></tr>
<tr><td><strong>핵심 원리</strong></td><td>앵커(Anchor), 포지티브(Positive), 네거티브(Negative) 샘플 세 쌍의 거리를 이용해 마진(margin)을 확보합니다.</td><td>임베딩 벡터와 정답 클래스의 가중치 벡터 사이 각도에 직접 <strong>각도 마진(ArcFace)</strong> 또는 **코사인 마진(CosFace)**을 추가하여 클래스 간 분리도를 높입니다.</td></tr>
<tr><td><strong>장점</strong></td><td>• <strong>오픈셋(Open-set) 문제</strong>에 강합니다.<br>• <strong>정교한 샘플링 제어</strong>: 트리플렛 마이닝을 통해 학습 대상을 세밀하게 조절할 수 있습니다.</td><td>• <strong>안정적인 학습 및 빠른 수렴</strong>: 훈련 과정이 매우 안정적이고 수렴 속도가 빠릅니다.<br>• <strong>높은 효율성</strong>: 복잡한 샘플링 없이 매 단계에서 모든 클래스를 암묵적 네거티브로 활용합니다.</td></tr>
<tr><td><strong>단점</strong></td><td>• <strong>복잡성 및 추가 비용</strong>: 샘플을 찾는 마이닝 과정이 복잡하고 계산 비용이 많이 듭니다.<br>• <strong>학습 불안정성</strong>: 마이닝 전략에 따라 학습이 불안정해질 수 있습니다.</td><td>• <strong>클로즈드셋(Closed-set) 문제</strong>에 최적화되어 있습니다.<br>• <strong>메모리 문제</strong>: 클래스 수가 수백만 개 이상으로 늘어나면 가중치 행렬(W) 크기로 인해 메모리 부담이 커질 수 있습니다.</td></tr>
<tr><td><strong>샘플링 전략</strong></td><td><strong>명시적 샘플 마이닝 필요</strong><br>(Triplet Mining)</td><td><strong>암묵적 글로벌 마이닝</strong><br>(별도의 네거티브 샘플링 과정 불필요)</td></tr>
</tbody></table>
<h2>6. 부: 고급 주제 및 향후 연구 방향</h2>
<p>Triplet Loss는 그 자체로도 강력하지만, 실제 적용 과정에서는 몇 가지 도전 과제가 존재하며, 이를 해결하기 위한 다양한 고급 기법과 확장 연구가 진행되고 있다.</p>
<h3>6.1  학습 불안정성 문제: 벡터 붕괴(Vector Collapse)</h3>
<p>벡터 붕괴는 Triplet Loss, 특히 Batch Hard 마이닝 전략을 사용할 때 발생할 수 있는 심각한 학습 실패 현상이다. 이는 모델이 모든 입력 데이터에 대해 동일한 임베딩 벡터(또는 매우 작은 영역 내의 벡터)를 출력하도록 학습되는 문제이다.34</p>
<p>이 현상이 발생하는 메커니즘은 다음과 같다. 만약 모델이 모든 임베딩을 동일하게 출력하면, 앵커-포지티브 거리(<span class="math math-inline">d(A, P)</span>)와 앵커-네거티브 거리(<span class="math math-inline">d(A, N)</span>)가 모두 0이 된다. 이 경우, 각 트리플렛에 대한 손실 값은 <span class="math math-inline">\max(0 - 0 + \alpha, 0) = \alpha</span>가 되어 마진 값으로 고정된다. 손실이 더 이상 변하지 않으므로 그래디언트가 0에 가까워지고, 모델은 이 자명하지만 쓸모없는 해에서 더 이상 학습을 진행하지 못하고 멈추게 된다.34</p>
<p>이 문제를 해결하기 위한 한 가지 방안은 손실 함수에 추가적인 페널티 항을 도입하는 것이다. 예를 들어, 계산된 손실 값을 배치 내에서 선택된 가장 어려운 네거티브들의 평균 거리(<code>hardest_negative_dists.mean()</code>)로 나누어주는 방법을 사용할 수 있다. 이 경우, 네거티브 간 거리가 0에 가까워지며 벡터 붕괴가 일어나려고 할 때, 분모가 0에 가까워지면서 손실 값이 폭발적으로 증가하게 된다. 이 큰 페널티는 모델이 붕괴 상태에 머무르지 않고 벗어나도록 강제하는 역할을 한다.34</p>
<h3>6.2  마진의 동적 조절: 적응형 마진(Adaptive Margin)</h3>
<p>기본적인 Triplet Loss에서는 모든 트리플렛에 대해 고정된 마진 <span class="math math-inline">\alpha</span>를 사용한다. 하지만 이는 모든 클래스 쌍 간의 구별 난이도가 동일하다고 가정하는 것으로, 비효율적일 수 있다. 예를 들어, 얼굴 표정 인식 문제에서 ’슬픔’과 ’두려움’은 시각적으로 매우 유사하여 구별하기 어렵지만, ’행복’과 ’두려움’은 상대적으로 구별하기 쉽다. 이 경우, 유사한 클래스 쌍에는 더 큰 마진을 적용하여 확실한 분리를 유도하고, 명확히 다른 클래스 쌍에는 작은 마진을 적용하는 것이 더 합리적일 수 있다.54</p>
<p>이러한 아이디어에서 출발한 것이 ‘적응형 마진(Adaptive Margin)’ 기법이다. 이 기법은 각 트리플렛을 구성하는 클래스들의 관계나, 데이터에 부여된 평점(rating)과 같은 추가 정보를 활용하여 각 트리플렛에 가장 적합한 마진 값을 동적으로 계산한다.54 예를 들어, 클래스 간의 평균 거리를 기반으로 마진을 업데이트하거나, 두 클래스의 유사도에 반비례하는 마진을 설정할 수 있다. 이러한 동적 마진 조절은 모델이 데이터의 미묘한 구조를 더 잘 학습하도록 도와 성능 향상에 기여할 수 있다.</p>
<h3>6.3  Triplet Loss의 확장</h3>
<p>Triplet Loss의 기본 철학은 유지하면서 그 한계를 극복하기 위한 다양한 확장된 손실 함수들이 제안되었다.</p>
<ul>
<li>
<p><strong>Quadruplet Loss:</strong> 이 손실 함수는 기존의 트리플렛(A, P, N)에 또 다른 네거티브 샘플(<span class="math math-inline">N_2</span>, 단 <span class="math math-inline">N_1</span>과 다른 클래스)을 추가하여 4개의 샘플, 즉 ’쿼드러플렛(quadruplet)’을 사용한다. 기존 Triplet Loss의 제약 조건에 더해, 동일 클래스 내 거리(<span class="math math-inline">d(A, P)</span>)가 서로 다른 네거티브 클래스 간의 거리(<span class="math math-inline">d(N_1, N_2)</span>)보다 작아야 한다는 추가적인 제약 조건을 도입한다. 이를 통해 클래스 내 분산은 더욱 줄이고, 클래스 간 분산은 더욱 크게 만들도록 학습을 유도한다.12</p>
</li>
<li>
<p><strong>N-Pair Loss:</strong> 이 손실 함수는 하나의 앵커-포지티브 쌍에 대해 여러 개(<span class="math math-inline">N-1</span>개)의 네거티브 샘플을 동시에 고려한다. 이는 매 학습 단계에서 모델에게 더 풍부한 비교 대상을 제공함으로써, 그래디언트 신호를 강화하고 학습 효율을 높이는 효과를 가져온다. 사실상 하나의 포지티브 클래스와 다수의 네거티브 클래스를 분류하는 문제와 유사한 형태로 학습이 진행된다.12</p>
</li>
<li>
<p><strong>Triplet-Center Loss:</strong> 이 방법은 트리플렛을 구성할 때 개별 네거티브 ’샘플’을 사용하는 대신, 각 클래스의 임베딩 벡터들의 평균인 ‘클래스 중심(class center)’ 벡터를 사용한다. 손실 함수는 앵커 샘플이 자신의 포지티브 클래스 중심에는 가깝고, 다른 모든 네거티브 클래스 중심에는 멀어지도록 학습시킨다. 이를 통해 매번 어려운 네거티브 샘플을 찾아야 하는 복잡한 마이닝 과정 없이도 안정적인 학습이 가능하다는 장점이 있다.57</p>
</li>
</ul>
<p>이러한 확장 연구들은 Triplet Loss가 제시한 거리 학습의 기본 원리가 여전히 활발한 연구 주제이며, 더 정교하고 강력한 표현 학습을 위해 끊임없이 발전하고 있음을 보여준다.</p>
<h2>7. 결론</h2>
<p>Triplet Loss는 딥러닝 기반 거리 학습 분야에서 하나의 이정표를 세운 강력하고 직관적인 손실 함수이다. 단순히 데이터를 분류하는 것을 넘어, 데이터 간의 의미적 유사성을 포착하는 임베딩 공간을 학습하는 능력은 얼굴 인식, 개인 재식별, 이미지 검색 등 수많은 ‘열린 집합’ 문제에 대한 효과적인 해결책을 제시했다.</p>
<p>본 보고서는 Triplet Loss의 수학적 원리부터 시작하여, 그 성능을 좌우하는 핵심 요소인 트리플렛 마이닝 전략, 특히 온라인 마이닝의 다양한 접근법을 심층적으로 분석했다. 또한, FaceNet과 같은 기념비적인 연구를 통해 실제 응용 분야에서 Triplet Loss가 어떻게 성공적으로 활용되었는지 살펴보았으며, PyTorch와 TensorFlow를 이용한 구체적인 구현 가이드를 제공했다.</p>
<p>더 나아가, Contrastive Loss, ArcFace, CosFace 등 주요 경쟁 손실 함수들과의 비교를 통해 Triplet Loss의 장단점과 그 위상을 객관적으로 조명했다. 이를 통해 Triplet Loss가 가진 상대적 거리 학습의 유연성과 마이닝 과정의 복잡성이라는 양면을 이해할 수 있었다. 마지막으로, 벡터 붕괴, 적응형 마진, 그리고 Quadruplet Loss와 같은 고급 주제 및 확장 연구들을 통해 Triplet Loss가 여전히 진화하고 있는 현재진행형 기술임을 확인했다.</p>
<p>결론적으로, Triplet Loss는 효과적인 표현 학습을 위한 근본적인 아이디어를 제공하며, 그 원리를 이해하는 것은 현대 딥러닝, 특히 컴퓨터 비전 분야의 연구자와 개발자에게 필수적인 소양이라 할 수 있다. 비록 학습의 불안정성이나 마이닝의 복잡성과 같은 도전 과제가 존재하지만, 이를 극복하기 위한 다양한 전략과 변형 모델들이 지속적으로 제안되고 있는 만큼, Triplet Loss와 그로부터 파생된 아이디어들은 앞으로도 거리 학습 분야의 발전에 중요한 기여를 할 것으로 전망된다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>en.wikipedia.org, <a href="https://en.wikipedia.org/wiki/Triplet_loss#:~:text=The%20triplet%20loss%20function%20minimizes,designed%20to%20support%20metric%20learning.">https://en.wikipedia.org/wiki/Triplet_loss#:~:text=The%20triplet%20loss%20function%20minimizes,designed%20to%20support%20metric%20learning.</a></li>
<li>Triplet Loss Function - Giskard, https://www.giskard.ai/glossary/triplet-loss-function</li>
<li>FaceNet: A Unified Embedding for Face Recognition and Clustering, https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf</li>
<li>Triplet Loss and Online Triplet Mining in TensorFlow | Olivier Moindrot blog, https://omoindrot.github.io/triplet-loss</li>
<li>Triplet loss - Wikipedia, https://en.wikipedia.org/wiki/Triplet_loss</li>
<li>Summary for FaceNet: A Unified Embedding for Face Recognition and Clustering | by Anil Chandra Naidu Matcha | Medium, https://medium.com/@anilmatcha/summary-for-facenet-a-unified-embedding-for-face-recognition-and-clustering-cfe878027a3d</li>
<li>ArcFace: Additive Angular Margin Loss for Deep Face Recognition - CVF Open Access, https://openaccess.thecvf.com/content_CVPR_2019/papers/Deng_ArcFace_Additive_Angular_Margin_Loss_for_Deep_Face_Recognition_CVPR_2019_paper.pdf</li>
<li>Face verification: what’s the advantage of the triplet loss function? : r/learnmachinelearning, https://www.reddit.com/r/learnmachinelearning/comments/7iwykr/face_verification_whats_the_advantage_of_the/</li>
<li>Using Triplet Loss for Face Recognition Systems - DEV Community, https://dev.to/endlessmessages/using-triplet-loss-for-face-recognition-systems-ne5</li>
<li>What is Triplet Loss? Its Purpose in Training ML Models - Deepchecks, https://www.deepchecks.com/glossary/triplet-loss/</li>
<li>www.v7labs.com, <a href="https://www.v7labs.com/blog/triplet-loss#:~:text=Triplet%20loss%20is%20a%20way,a%20dissimilar%20item%20(negative).">https://www.v7labs.com/blog/triplet-loss#:~:text=Triplet%20loss%20is%20a%20way,a%20dissimilar%20item%20(negative).</a></li>
<li>Day 24/100: Triplet Loss — Learning Through Comparison, One Trio at a Time - Medium, https://medium.com/@sebuzdugan/day-24-100-triplet-loss-learning-through-comparison-one-trio-at-a-time-4d59b1330078</li>
<li>The intuition of Triplet Loss. Getting an essence of how loss is… | by Susmith Reddy | Analytics Vidhya, https://medium.com/analytics-vidhya/triplet-loss-b9da35be21b8</li>
<li>Triplet Loss: Intro, Implementation, Use Cases - V7 Labs, https://www.v7labs.com/blog/triplet-loss</li>
<li>Triplet Loss - Advanced Intro - Qdrant, https://qdrant.tech/articles/triplet-loss/</li>
<li>Triplet Loss with Keras and TensorFlow - PyImageSearch, https://pyimagesearch.com/2023/03/06/triplet-loss-with-keras-and-tensorflow/</li>
<li>(PDF) Triplet Loss - ResearchGate, https://www.researchgate.net/publication/357529033_Triplet_Loss</li>
<li>WilliamYWY/TripletLoss-note: Notes about triplet loss - GitHub, https://github.com/WilliamYWY/TripletLoss-note</li>
<li>Triplet loss intuition? : r/MLQuestions - Reddit, https://www.reddit.com/r/MLQuestions/comments/113wl2t/triplet_loss_intuition/</li>
<li>Triplet Loss - why bother maximizing with 0 - DeepLearning.AI, https://community.deeplearning.ai/t/triplet-loss-why-bother-maximizing-with-0/756567</li>
<li>A Theoretically Sound Upper Bound on the Triplet Loss for Improving the Efficiency of Deep Distance Metric Learning - CVF Open Access, https://openaccess.thecvf.com/content_CVPR_2019/papers/Do_A_Theoretically_Sound_Upper_Bound_on_the_Triplet_Loss_for_CVPR_2019_paper.pdf</li>
<li>Smart Mining for Deep Metric Learning, https://cs.adelaide.edu.au/~carneiro/publications/smart-mining-deep.pdf</li>
<li>Correcting the Triplet Selection Bias for Triplet Loss - CVF Open Access, https://openaccess.thecvf.com/content_ECCV_2018/papers/Baosheng_Yu_Correcting_the_Triplet_ECCV_2018_paper.pdf</li>
<li>Triplet Loss — Deep Learning - FR, https://perso.esiee.fr/~chierchg/deep-learning/tutorials/metric/metric-2.html</li>
<li>Hard negative examples are hard, but useful - European Computer Vision Association, https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590120.pdf</li>
<li>Offline versus Online Triplet Mining based on Extreme Distances of Histopathology Patches, https://www.researchgate.net/publication/342733497_Offline_versus_Online_Triplet_Mining_based_on_Extreme_Distances_of_Histopathology_Patches</li>
<li>Offline versus Online Triplet Mining based on Extreme Distances of Histopathology Patches | Mark Crowley | University of Waterloo, https://uwaterloo.ca/scholar/mcrowley/publications/offline-versus-online-triplet-mining-based-extreme-distances-histopathology</li>
<li>Online Triplet Mining - Artificial Intelligence, https://schneppat.com/online-triplet-mining.html</li>
<li>schneppat.com, <a href="https://schneppat.com/online-triplet-mining.html#:~:text=Triplet%20mining%20can%20be%20done,as%20computational%20efficiency%20and%20adaptability.">https://schneppat.com/online-triplet-mining.html#:~:text=Triplet%20mining%20can%20be%20done,as%20computational%20efficiency%20and%20adaptability.</a></li>
<li>How Does Triplet Loss and Online Triplet Mining Work? - Sanjaya’s Blog, https://sanjayasubedi.com.np/deeplearning/online-triplet-mining/</li>
<li>[1503.03832] FaceNet: A Unified Embedding for Face Recognition and Clustering - arXiv, https://arxiv.org/abs/1503.03832</li>
<li>Triple Down on Robustness: Understanding the Impact of Adversarial Triplet Compositions on Adversarial Robustness - MDPI, https://www.mdpi.com/2504-4990/7/1/14</li>
<li>Semi-Hard Triplet Mining - Artificial Intelligence, https://schneppat.com/semi-hard-triplet-mining.html</li>
<li>Triplet Loss: Vector Collapse Prevention - Quaterion documentation, https://quaterion.qdrant.tech/tutorials/triplet_loss_trick</li>
<li>[D] Preventing Triplet networks from collapse : r/MachineLearning - Reddit, https://www.reddit.com/r/MachineLearning/comments/88by8i/d_preventing_triplet_networks_from_collapse/</li>
<li>Review — FaceNet: A Unified Embedding for Face Recognition and Clustering | by Sik-Ho Tsang, https://sh-tsang.medium.com/review-facenet-a-unified-embedding-for-face-recognition-and-clustering-7b360d2a85e4</li>
<li>Set Augmented Triplet Loss for Video Person Re-Identification, https://openaccess.thecvf.com/content/WACV2021/papers/Fang_Set_Augmented_Triplet_Loss_for_Video_Person_Re-Identification_WACV_2021_paper.pdf</li>
<li>Person Re-Identification by Multi-Channel Parts-Based CNN With Improved Triplet Loss Function - CVF Open Access, https://openaccess.thecvf.com/content_cvpr_2016/papers/Cheng_Person_Re-Identification_by_CVPR_2016_paper.pdf</li>
<li>Hard-Aware Point-to-Set Deep Metric for Person Re-identification - CVF Open Access, https://openaccess.thecvf.com/content_ECCV_2018/papers/Rui_Yu_Hard-Aware_Point-to-Set_Deep_ECCV_2018_paper.pdf</li>
<li>All You Need to Know About Training Image Retrieval Models - arXiv, https://arxiv.org/html/2503.13045v1</li>
<li>Bayesian Triplet Loss: Uncertainty Quantification in Image Retrieval - DTU Orbit, https://orbit.dtu.dk/files/263985253/Bayesian_Triplet_Loss.pdf</li>
<li>[2303.08398] A Triplet-loss Dilated Residual Network for High-Resolution Representation Learning in Image Retrieval - arXiv, https://arxiv.org/abs/2303.08398</li>
<li>Introduction to Triplet Loss | Baeldung on Computer Science, https://www.baeldung.com/cs/triplet-loss</li>
<li>TripletMarginLoss — PyTorch 2.8 documentation, https://docs.pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html</li>
<li>Online Triplet Mining - TripletMarginLoss - PyTorch Forums, https://discuss.pytorch.org/t/online-triplet-mining-tripletmarginloss/158468</li>
<li>Triplet Loss - Advanced Intro - Towards Data Science, https://towardsdatascience.com/triplet-loss-advanced-intro-49a07b7d8905/</li>
<li>TensorFlow Addons Losses: TripletSemiHardLoss, https://www.tensorflow.org/addons/tutorials/losses_triplet</li>
<li>Implementation of triplet loss in TensorFlow - GitHub, https://github.com/omoindrot/tensorflow-triplet-loss</li>
<li>Losses - PyTorch Metric Learning, https://kevinmusgrave.github.io/pytorch-metric-learning/losses/</li>
<li>Day 3 — Loss Functions in Contrastive Learning: A Deep Dive | by …, https://medium.com/@deepsiya10/day-3-loss-functions-in-contrastive-learning-a-deep-dive-426a38525e2d</li>
<li>What are the advantages of using a triplet loss function over a contrastive loss? How would you decide which to use? - Quora, https://www.quora.com/What-are-the-advantages-of-using-a-triplet-loss-function-over-a-contrastive-loss-How-would-you-decide-which-to-use</li>
<li>Exploring Other Face Recognition Approaches (Part 2) — ArcFace, https://medium.com/analytics-vidhya/exploring-other-face-recognition-approaches-part-2-arcface-88cda1fdfeb8</li>
<li>[D] To use triplet loss or not when classes labels are given. Question about theoretical/experimental expectations. : r/MachineLearning - Reddit, https://www.reddit.com/r/MachineLearning/comments/dtczgt/d_to_use_triplet_loss_or_not_when_classes_labels/</li>
<li>Outlier-Suppressed Triplet Loss with Adaptive Class-Aware Margins for Facial Expression Recognition - GitHub Pages, https://wcxie.github.io/Weicheng-Xie/pdf/ICIP2019.pdf</li>
<li>[2107.06187] Deep Ranking with Adaptive Margin Triplet Loss - arXiv, https://arxiv.org/abs/2107.06187</li>
<li>Deep Ranking with Adaptive Margin Triplet Loss - arXiv, https://arxiv.org/pdf/2107.06187</li>
<li>Triplet-Center Loss for Multi-View 3D Object Retrieval - CVF Open Access, https://openaccess.thecvf.com/content_cvpr_2018/papers/He_Triplet-Center_Loss_for_CVPR_2018_paper.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>