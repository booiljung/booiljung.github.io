<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:비전-언어-액션(VLA) 모델의 아키텍처적 완결성, 설명 가능성 및 런타임 제어 보증 (2025-12-12)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>비전-언어-액션(VLA) 모델의 아키텍처적 완결성, 설명 가능성 및 런타임 제어 보증 (2025-12-12)</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="index.html">작업 계획 (Task Planning) + VLA</a> / <span>비전-언어-액션(VLA) 모델의 아키텍처적 완결성, 설명 가능성 및 런타임 제어 보증 (2025-12-12)</span></nav>
                </div>
            </header>
            <article>
                <h1>비전-언어-액션(VLA) 모델의 아키텍처적 완결성, 설명 가능성 및 런타임 제어 보증 (2025-12-12)</h1>
<p>2025-12-12, G30DR</p>
<h2>1.  서론: 로봇 제어의 거대 모델 패러다임과 기술적 난제</h2>
<p>인공지능 연구의 최전선은 이제 텍스트와 이미지를 이해하는 것을 넘어, 물리적 세계와 상호작용하는 <strong>임바디드 AI(Embodied AI)</strong> 로 이동하고 있다. 그 중심에는 대규모 언어 모델(LLM)의 추론 능력과 시각적 인지 능력을 로봇의 물리적 제어와 결합한 <strong>비전-언어-액션(Vision-Language-Action, VLA)</strong> 모델이 존재한다. 구글 딥마인드(Google DeepMind)의 RT-2(Robotic Transformer 2)와 같은 VLA 모델은 웹 스케일(Web-scale)의 데이터에서 학습된 범용적인 지식을 로봇 제어 정책(Policy)으로 전이(Transfer)시킴으로써, 기존 로봇 공학이 해결하지 못했던 비정형 환경에서의 일반화(Generalization) 문제를 해결할 열쇠로 평가받는다.1</p>
<p>그러나 이러한 거대 모델의 도입은 로봇 공학계에 새로운, 그리고 매우 심각한 기술적 질문들을 던지고 있다. 기존의 로봇 제어 시스템은 인지, 계획, 제어가 명확히 분리된 모듈형 파이프라인(Modular Pipeline)을 따랐기에 각 단계의 검증이 가능했다. 반면, 수십억 개의 파라미터를 가진 거대 신경망이 센서 입력부터 행동 출력까지를 전담하는 VLA 모델은 그 내부 작동 원리를 알 수 없는 ‘블랙박스(Black-box)’ 특성을 가진다. 이는 물리적 안전이 최우선인 로봇 시스템에 있어 치명적인 위험 요소가 될 수 있다.</p>
<p>본 보고서는 귀하가 제기한 세 가지 핵심적인 기술 질문—(1) <strong>VLA는 진정한 End-to-End(E2E) 시스템인가?</strong>, (2) <strong>설명 가능한 AI(XAI)로서 기능할 수 있는가?</strong>, (3) <strong>행동 생성 직전(Action 앞단)에서 런타임 보증(RTA)을 주입할 수 있는가?</strong>—에 대해 현존하는 연구 문헌과 기술 보고서를 망라하여 심층적으로 분석한다. 본 분석은 단순한 답변을 넘어, 신경망의 토큰화 메커니즘, 생각의 사슬(Chain-of-Thought)이 가진 인식론적 한계, 그리고 제어 이론(Control Theory)과 딥러닝의 하이브리드 결합을 통한 안전망 구축 전략을 상세히 기술한다.</p>
<pre><code class="language-mermaid">graph TD
    Traditional["Traditional Robotics"] -- "Modular Pipeline" --&gt; Modules["Perception -&gt; Planning -&gt; Control"]
    Modules -- "Verifiable" --&gt; Safe["Verifiable Safety"]

    New["Embodied AI Frontier"] -- "Action as Language" --&gt; VLA["VLA Model (e.g., RT-2)"]
    VLA -- "Web-scale Knowledge" --&gt; Generalization["Generalization in Unstructured Env"]

    VLA -- "End-to-End Neural Net" --&gt; BlackBox["Black-box Characteristic"]
    BlackBox -- "Unknown Internal State" --&gt; Risk["Critical Safety Risks"]
</code></pre>
<h2>2.  VLA 아키텍처의 본질적 해부: End-to-End(E2E) 인가?</h2>
<p>VLA 모델이 “End-to-End(E2E)“인가에 대한 질문은 현대 로봇 학습(Robot Learning)의 아키텍처적 정체성을 규명하는 가장 중요한 질문이다. 분석 결과, VLA는 <strong>데이터 처리 및 정책 생성(Policy Generation) 관점에서는 완전한 E2E</strong>이나, **물리적 구동(Physical Actuation) 및 제어 루프 관점에서는 ‘의사(Pseudo) E2E’ 또는 ‘계층적(Hierarchical) E2E’**로 정의하는 것이 타당하다. 이 구분은 시스템의 실시간성(Real-time)과 안전성을 설계할 때 결정적인 역할을 한다.</p>
<h3>2.1  신경망 내부의 E2E: 픽셀에서 토큰까지의 통합</h3>
<p>RT-2, OpenVLA, Octo와 같은 최신 VLA 모델들의 가장 혁신적인 특징은 **“행동을 또 다른 언어로 취급한다(Actions as Language)”**는 패러다임의 전환이다.1 이는 입력부터 출력까지 어떠한 명시적인 상태 추정(State Estimation)이나 기호적 계획(Symbolic Planning) 없이 단일 신경망이 처리함을 의미한다.</p>
<pre><code class="language-mermaid">graph LR
    subgraph "2.1 Neural Network Internal E2E"
        InputImg("RGB Image Stream") &amp; InputTxt("Text Command") --&gt; Backbone("VLM Backbone (PaLM-E, PaLI-X)")
        
        subgraph "Latent Space Processing"
            Backbone --&gt; ViT("ViT (Patch Embeddings)")
            Backbone --&gt; Tokenizer("Text Tokenizer")
            ViT &amp; Tokenizer --&gt; Align("Cross-Attention (Implicit Alignment)")
        end
        
        Align --&gt; ActionLogits("Action Logits")
        ActionLogits -- "Uniform Discretization" --&gt; Tokens("Discrete Action Tokens (e.g., '1 128 91...')")
        Tokens --&gt; Detoken("De-tokenization") --&gt; PhysicalCmd("Physical Command (Target Pose)")
    end
</code></pre>
<h4>2.1.1  멀티모달 입력 공간의 융합</h4>
<p>전통적인 로봇 파이프라인에서는 카메라 이미지가 객체 감지기(Object Detector)를 거쳐 “빨간 컵: (x=0.5, y=0.2, z=0.8)“과 같은 구조화된 상태 정보로 변환된 후 플래너에 입력되었다. 그러나 VLA 아키텍처는 이러한 중간 표현을 거부한다.</p>
<ul>
<li><strong>입력 통합 (Input Integration):</strong> 로봇 카메라의 고해상도 RGB 이미지 스트림과 자연어 명령어(예: “식탁 위에서 멸종된 동물을 집어라”)가 VLM의 백본(Backbone)인 PaLM-E(12B) 또는 PaLI-X(55B)에 직접 주입된다.1</li>
<li><strong>잠재 공간의 정렬 (Latent Alignment):</strong> 이미지는 Vision Transformer(ViT)를 통해 패치(Patch) 단위의 임베딩 시퀀스로 변환되고, 텍스트는 텍스트 토크나이저를 통해 토큰화된다. 이 두 양식(Modality)은 트랜스포머의 동일한 고차원 임베딩 공간에 투영되어 상호작용한다.4 이 과정에서 시각 정보와 언어 정보의 융합은 모델 내부의 어텐션 메커니즘(Cross-Attention)에 의해 암시적으로(Implicitly) 수행된다.</li>
</ul>
<h4>2.1.2  행동 토큰화(Action Tokenization)와 출력 생성</h4>
<p>E2E 처리의 핵심은 연속적인 물리적 공간(Continuous Physical Space)을 트랜스포머가 처리할 수 있는 이산적인 토큰 공간(Discrete Token Space)으로 변환하는 <strong>토큰화 전략</strong>에 있다. 이 과정은 VLA가 E2E 모델로 기능하게 하는 결정적인 기술적 도약이다.</p>
<ul>
<li><strong>균등 이산화 (Uniform Discretization):</strong> RT-2는 로봇의 행동 공간을 6-DoF(위치 및 회전)와 그리퍼 개폐를 포함한 차원으로 정의하고, 각 차원을 256개의 구간(bin)으로 균등하게 나눈다.2 예를 들어, 엔드 이펙터의 x축 속도가 -1.0에서 +1.0 사이라면, 특정 속도 값은 0부터 255 사이의 정수 토큰으로 매핑된다. 이 정수들은 언어 모델의 기존 어휘(Vocabulary) 중 가장 덜 쓰이는 토큰을 덮어쓰거나(overloading), 별도의 전용 숫자 토큰으로 할당되어 처리된다.</li>
<li><strong>출력 시퀀스:</strong> 모델의 출력은 “Pick up the apple“과 같은 텍스트가 아니라, “1 128 91 241 5 101…“과 같은 일련의 정수열로 나온다. 이는 디토큰화(De-tokenization) 과정을 거쳐 “x축 +0.1m 이동, y축 -0.05m 이동…“이라는 물리적 명령으로 변환된다.3</li>
</ul>
<p>이 과정에서 별도의 경로 계획(Path Planning) 알고리즘이나 역운동학(Inverse Kinematics) 솔버가 신경망 <em>내부</em>에 명시적으로 존재하지 않으며, 신경망이 방대한 데이터로부터 입력(픽셀)과 출력(행동) 간의 매핑 함수를 내재적으로 학습한다. 따라서 <strong>인지-판단-행동 생성의 전 과정이 단일 모델 내에서 수행된다는 점에서는 완벽한 E2E</strong>이다.</p>
<pre><code class="language-mermaid">graph LR
    subgraph "2.1.2 Action Tokenization Detail"
        Physical("Continuous Physical Signal (e.g., Velocity: +0.35m/s)")
        
        subgraph "Discretization Process"
            Range("Define Range: [-1.0, +1.0]") 
            Bins("Divide into 256 Bins") 
            Map("Mapping Function")
        end
        
        Physical --&gt; Range --&gt; Bins --&gt; Map
        
        Map -- "Quantization" --&gt; IntToken("Integer Token ID: '172'")
        IntToken -- "Embedding Lookup" --&gt; Vector("Token Embedding Vector")
        Vector --&gt; Transformer("Input to Transformer Layers")
    end
</code></pre>
<h3>2.2  제어 시스템의 계층성: 주파수 불일치와 “의사(Pseudo) E2E”</h3>
<p>그러나 시스템 엔지니어링 관점에서 “VLA가 로봇 모터의 전압(Voltage)이나 전류(Current)를 직접 제어하는가?“라고 묻는다면 답은 명백히 **‘아니오’**이다. 여기서 VLA의 E2E 특성은 한계를 맞이하며, 계층적 제어 구조로 전환된다.</p>
<pre><code class="language-mermaid">sequenceDiagram
    autonumber
    title "2.2 Hierarchical Control &amp; Frequency Mismatch"
    participant User as User/Environment
    participant VLA as VLA Model&lt;br&gt;(High-Level Policy)
    participant Buffer as Command&lt;br&gt;Interface
    participant LLC as Low-Level&lt;br&gt;Controller
    participant Robot as Robot&lt;br&gt;Motors

    User-&gt;&gt;VLA: Visual/Text&lt;br&gt;Input
    Note over VLA: Heavy Computation&lt;br&gt;(Inference)
    VLA-&gt;&gt;Buffer: Action Tokens&lt;br&gt;(Update: 1~5Hz)
    
    loop High Frequency&lt;br&gt;Control Loop (1kHz)
        Buffer-&gt;&gt;LLC: Current&lt;br&gt;Target Waypoint
        LLC-&gt;&gt;LLC: PID / Impedance&lt;br&gt;Control Calc
        LLC-&gt;&gt;Robot: Motor&lt;br&gt;Torque / Voltage
        Robot--&gt;&gt;LLC: State Feedback
    end
    
    Note over LLC, Robot: "Ensures smooth motion &amp; stability"
</code></pre>
<h4>2.2.1  추론 속도와 제어 주기의 불일치 (The Frequency Mismatch)</h4>
<p>로봇 팔이 부드럽고 안전하게, 그리고 떨림 없이 움직이기 위해서는 최소 **100Hz에서 1kHz(초당 1000회)**의 제어 루프가 필요하다.6 반면, 수백억 개의 파라미터를 가진 RT-2와 같은 거대 모델은 추론에 막대한 연산 비용이 소요되어, 일반적으로 <strong>1Hz에서 5Hz(초당 1~5회)</strong> 정도의 속도로만 행동 토큰을 생성할 수 있다.2</p>
<p>이러한 주파수의 거대한 간극(Mismatch)은 VLA가 직접 모터를 제어할 수 없음을 의미한다. 0.2초(5Hz)마다 한 번씩 갱신되는 명령으로 모터를 구동하면 로봇은 심각하게 진동하거나 불안정해진다.</p>
<h4>2.2.2  하위 제어기(Low-Level Controller)의 필수적 개입</h4>
<p>따라서 VLA 시스템은 필연적으로 **계층적 구조(Hierarchical Structure)**를 채택한다.</p>
<ol>
<li><strong>상위 레벨 (VLA):</strong> 1~5Hz로 동작하며, 현재 상황을 인지하고 대략적인 ’목표 지점(Waypoint)’이나 ’목표 델타 포즈(Delta Pose)’를 행동 토큰으로 출력한다. 이는 전략적 판단에 해당한다.</li>
<li><strong>하위 레벨 (Controller):</strong> VLA가 출력한 목표 지점을 입력으로 받아, 1kHz의 고속 주기로 모터의 토크(Torque)를 조절한다. 여기에는 전통적인 <strong>PID 제어기</strong>, <strong>임피던스 제어기(Impedance Controller)</strong>, 또는 **운영 공간 제어기(Operational Space Controller)**가 사용된다.6</li>
</ol>
<p>즉, VLA 모델은 <strong>“비주얼-모터 정책(Visuomotor Policy)”</strong> 역할을 수행하는 E2E 모델이지만, 전체 시스템은 **“VLA 두뇌 + 고전 제어기 척수”**가 결합된 형태이다. RT-2의 기술 문서에서도 모델의 출력이 “로봇 액션“으로 디토큰화되어 “Closed loop control“을 가능하게 한다고 명시되어 있으나 1, 이는 하드웨어 API(예: Franka Interface)를 거치는 것을 전제로 한다.</p>
<h3>2.3  행동 공간의 표준화와 RT-X 데이터셋</h3>
<p>VLA의 E2E 특성을 강화하기 위한 노력 중 하나는 데이터셋의 통합이다. <strong>RT-X 데이터셋</strong>과 <strong>Open X-Embodiment</strong> 프로젝트는 서로 다른 형태(Embodiment)를 가진 로봇들의 데이터를 통합하여 하나의 거대 모델을 학습시킨다.8</p>
<ul>
<li><strong>표준화된 행동 공간:</strong> Franka Panda(7축), WidowX(6축) 등 서로 다른 로봇의 데이터를 섞어서 학습하기 위해, 행동 공간을 **7차원 벡터 (x, y, z, roll, pitch, yaw, gripper opening)**로 표준화한다.</li>
<li><strong>함의:</strong> 이는 VLA가 특정 로봇의 관절 각도(Joint Position)를 직접 학습하기보다는, 로봇의 손끝(End-effector)이 공간상에서 어떻게 움직여야 하는지에 대한 추상적인 기하학적 명령을 학습함을 의미한다. Octo 모델 9이나 OpenVLA 역시 이러한 방식을 따르며, 이는 VLA가 하드웨어 추상화 계층(HAL) 위에서 동작하는 E2E 소프트웨어임을 재확인시켜준다.</li>
</ul>
<p><strong>요약: VLA는 신경망 아키텍처상으로는 입력부터 행동 생성까지의 E2E 모델이 맞다. 그러나 물리적 제어 루프의 관점에서는 고주파 하위 제어기에 명령을 하달하는 상위 레벨 정책기이며, 따라서 전체 시스템은 계층적이다.</strong></p>
<pre><code class="language-mermaid">graph TD
    subgraph "2.3 RT-X Data Standardization"
        SourceA("Source: Franka Emika (7-DoF)")
        SourceB("Source: WidowX (6-DoF)")
        SourceC("Source: Google Robot (Mobile)")
        
        subgraph "Standardization Layer"
            MapA("Map to End-Effector Space")
            MapB("Align Coordinate Frames")
            MapC("Normalize Action Range")
        end
        
        SourceA --&gt; MapA
        SourceB --&gt; MapB
        SourceC --&gt; MapC
        
        MapA &amp; MapB &amp; MapC --&gt; Unified("Unified 7-DoF Action Vector (x, y, z, r, p, y, gripper)")
        Unified --&gt; Training("Training One Giant VLA Model")
    end
</code></pre>
<h2>3.  XAI(Explainable AI) 가능성: 언어적 추론과 그 신뢰성의 딜레마</h2>
<p>사용자가 제기한 “XAI 가능한가?“라는 질문은 VLA 모델의 투명성과 신뢰성을 검증하는 데 있어 핵심적이다. 분석 결과, VLA는 기존 로봇 시스템 대비 <strong>획기적으로 향상된 설명 가능성</strong>을 제공하지만, 그 설명의 **진실성(Faithfulness)**에 대해서는 심각한 학술적 우려가 제기되고 있다.</p>
<h3>3.1  Chain-of-Thought (CoT) 추론: 언어적 설명의 혁명</h3>
<p>VLA의 백본인 LLM/VLM은 <strong>생각의 사슬(Chain-of-Thought, CoT)</strong> 능력을 로봇 제어에 도입함으로써, 로봇이 “왜” 그런 행동을 했는지 자연어로 설명할 수 있게 만들었다.1</p>
<h4>3.1.1  의미론적 추론(Semantic Reasoning)과 설명</h4>
<p>RT-2 연구진은 모델이 행동 토큰을 생성하기 전에 텍스트로 추론 과정을 먼저 출력하도록 유도할 수 있음을 보였다.</p>
<ul>
<li><strong>사례 분석:</strong> “피곤한 사람에게 줄 음료를 골라라“라는 모호한 명령에 대해, 기존 로봇은 사전에 정의된 규칙이 없다면 멈춰 섰을 것이다. 그러나 RT-2는 다음과 같은 내부 독백(Monologue)을 텍스트로 출력한다.</li>
</ul>
<blockquote>
<p><em>“피곤한 사람은 에너지가 필요하다. -&gt; 에너지 드링크에는 카페인이 들어 있어 깨어나는 데 도움이 된다. -&gt; 책상 위에 캔커피와 물, 사과가 있다. -&gt; 캔커피는 에너지 드링크의 일종이다. -&gt; 따라서 캔커피를 집겠다.”</em> 1</p>
</blockquote>
<ul>
<li><strong>XAI적 가치:</strong> 이러한 중간 단계의 텍스트 생성은 모델이 **‘무엇(What)’**을 하려고 하는지 뿐만 아니라, **‘어떤 논리(Why)’**로 그 결론에 도달했는지를 명시적으로 보여준다. 이는 블랙박스 모델의 내부를 언어라는 창을 통해 들여다보는 강력한 XAI 메커니즘이다.</li>
</ul>
<pre><code class="language-mermaid">graph TD
    subgraph "3.1 Semantic Reasoning (CoT)"
        Cmd("Command: Pick drink for tired person") --&gt; Step1("Reasoning 1: Tired person needs energy")
        Step1 --&gt; Step2("Reasoning 2: Energy drinks contain caffeine")
        Step2 --&gt; Step3("Perception: Canned coffee detected on desk")
        Step3 --&gt; Step4("Reasoning 3: Coffee is a type of energy drink")
        Step4 --&gt; Conclusion("Decision: Pick Canned Coffee")
        Conclusion --&gt; Action("Action: Generate Grip Tokens")
    end
</code></pre>
<h4>3.1.2  시각적 CoT (Visual Chain-of-Thought)</h4>
<p>텍스트만으로는 로봇의 공간적 움직임을 설명하기 어렵다는 한계를 극복하기 위해, <strong>CoT-VLA</strong>와 같은 최신 연구는 <strong>시각적 설명</strong> 기능을 도입했다.11</p>
<ul>
<li><strong>중간 목표 이미지 생성 (Sub-goal Generation):</strong> “서랍을 열어라“라는 명령을 받으면, 모델은 행동을 시작하기 전에 ’로봇 손이 서랍 손잡이를 잡고 있는 미래의 이미지’를 먼저 생성(Generation)하여 사용자에게 보여준다. 그 후, 해당 상태에 도달하기 위한 행동 토큰을 생성한다.</li>
<li><strong>직관적 검증:</strong> 사용자는 로봇이 생성한 이미지를 통해 “아, 이 로봇이 엉뚱하게 책상 다리를 잡으려는 게 아니라 손잡이를 잡으려 하는구나“라고 즉각적으로 의도를 파악하고 검증할 수 있다.</li>
</ul>
<h3>3.2  어텐션 맵(Attention Map)과 내부 시각화</h3>
<p>VLA는 트랜스포머 기반이기에 **어텐션 메커니즘(Attention Mechanism)**을 시각화하여 모델의 관심 영역을 추적할 수 있다.13</p>
<ul>
<li><strong>크로스 어텐션(Cross-Attention) 시각화:</strong> 텍스트 명령어의 특정 단어(예: “빨간 컵”)가 이미지의 어느 패치(Patch)와 강하게 연결되어 있는지 히트맵(Heatmap)으로 표현 가능하다.</li>
<li><strong>오류 진단:</strong> 만약 로봇이 컵을 집지 못하고 실패했을 때, 어텐션 맵이 컵이 아닌 엉뚱한 배경을 가리키고 있다면, 이는 제어의 문제가 아니라 <strong>인지(Perception)의 실패</strong>임을 명확히 진단할 수 있다. 이는 개발자와 운영자에게 매우 유용한 디버깅 정보를 제공한다.</li>
</ul>
<pre><code class="language-mermaid">graph TD
    subgraph "3.3 Faithfulness Crisis"
        Input("Input Stimulus") --&gt; Model("VLA Model Internal State")
        
        Model --&gt; Split{"Path Dissociation"}
        
        Split -- "Language Head" --&gt; TextOut("Text Output (Explanation)")
        TextOut --&gt; Ethical("Text: 'Stopping to avoid collision'")
        
        Split -- "Action Head" --&gt; ActOut("Action Output (Policy)")
        ActOut -- "Different Causality" --&gt; Dangerous("Action: 'Full Speed Forward'")
        
        Ethical &lt;--&gt; Dangerous -.-&gt; Discord("Unfaithfulness / Post-hoc Rationalization")
    end
</code></pre>
<h3>3.3  CoT의 신뢰성(Faithfulness) 위기: 사후 합리화의 함정</h3>
<p>그러나 VLA의 XAI 기능에는 치명적인 약점이 존재하며, 이는 안전 필수(Safety-critical) 시스템에서 VLA를 맹신해서는 안 되는 이유가 된다. 바로 <strong>비충실성(Unfaithfulness)</strong> 또는 <strong>사후 합리화(Post-hoc Rationalization)</strong> 문제이다.14</p>
<h4>3.3.1  언어와 행동의 해리 (Dissociation)</h4>
<p>연구 결과에 따르면, LLM이 생성한 설명(CoT)이 실제 출력(행동)의 인과적 원인과 일치하지 않는 경우가 빈번하다.</p>
<ul>
<li><strong>편향 실험 (Biasing Experiment):</strong> 15의 연구에서, 모델에게 정답과 무관한 편향된 힌트를 주었을 때 모델은 그 편향에 따라 오답을 냈다. 그러나 CoT에서는 그 편향 때문이라고 말하는 대신, 억지 논리를 만들어내며 자신의 오답을 정당화했다.</li>
<li><strong>로봇 제어에서의 위험성:</strong> VLA가 텍스트로는 *“사람과의 충돌을 피하기 위해 정지합니다”*라고 훌륭한 윤리적 설명을 출력하면서, 실제 행동 토큰 생성 헤드(Action Head)는 <strong>전속력으로 전진</strong>하는 토큰을 생성할 수 있다. 이는 언어 생성 경로와 행동 생성 경로가 신경망의 마지막 단에서 분기되기 때문에 발생할 수 있는 현상이다.</li>
</ul>
<h4>3.3.2  환각(Hallucination)과 물리적 현실의 괴리</h4>
<p>VLA는 물리 시뮬레이터가 아니다. 모델이 설명하는 물리적 인과관계(“이 레버를 당기면 저 문이 열릴 것이다”)는 실제 물리 엔진의 연산 결과가 아니라, 인터넷 텍스트 데이터에서 학습된 확률적 서술일 뿐이다. 따라서 모델은 물리적으로 불가능한 행동을 계획하고도, 텍스트로는 매우 그럴듯한(Plausible) 이유를 댈 수 있다.</p>
<p><strong>결론: VLA는 CoT와 시각적 생성을 통해 ‘가능성’ 있는 XAI 기능을 제공한다. 그러나 이 설명은 모델의 실제 행동 원인과 다를 수 있는 ’그럴듯한 사후 합리화’일 위험이 크다. 따라서 XAI는 운영자의 이해를 돕는 보조 도구로만 사용되어야 하며, 시스템의 안전을 보증하는 수단(Certification)으로 간주되어서는 안 된다.</strong></p>
<h2>4.  Action 앞단에서 RTA(Runtime Assurance)를 주입할 수 있는가?</h2>
<p>사용자의 가장 실용적이고 기술적인 질문인 “Action 앞단에서 RTA를 주입할 수 있는가?“에 대한 답은 **“가능할 뿐만 아니라, 실전 배포를 위해서는 반드시 주입해야 한다”**는 것이다. 이를 <strong>안전 필터(Safety Filter)</strong>, <strong>실드(Shielding)</strong>, 또는 **가디언(Guardian)**이라고 부르며, 확률적 모델의 불확실성을 통제하는 최후의 보루 역할을 한다.</p>
<pre><code class="language-mermaid">graph TD
    Step1("VLA Inference") --&gt; Nominal("Nominal Control Input (Unverified)")

    subgraph "Safety Filter (Golden Zone)"
        Nominal --&gt; Check{"Safety Set Check h(x) &gt;= 0"}
        Check -- "Safe" --&gt; Bypass("Pass Through")
        Check -- "Unsafe" --&gt; Solver("QP Solver (CBF)")
        Solver -- "Optimization" --&gt; Correct("Modulated Safe Input u*")
    end

    Bypass &amp; Correct --&gt; Controller("Low-Level Controller")
    Controller --&gt; Robot("Robot Hardware")
</code></pre>
<h3>4.1  RTA 주입의 최적 위치: 아키텍처적 접근</h3>
<p>RTA는 VLA 파이프라인의 <strong>디토큰화(De-tokenization) 직후, 하위 제어기(Low-Level Controller) 입력 직전</strong>에 위치하는 것이 가장 효과적이며 일반적이다.5</p>
<p><strong>[표 1] VLA 파이프라인 내 RTA 주입 지점 비교</strong></p>
<table><thead><tr><th><strong>단계</strong></th><th><strong>데이터 형태</strong></th><th><strong>RTA 적용 가능성</strong></th><th><strong>특징 및 한계</strong></th></tr></thead><tbody>
<tr><td><strong>1. 입력 단계</strong></td><td>이미지, 텍스트</td><td>가능 (Input Filtering)</td><td>“위험한 명령 거부“는 가능하나, 환각에 의한 오작동은 막을 수 없음.</td></tr>
<tr><td><strong>2. 모델 내부</strong></td><td>임베딩 벡터</td><td>어려움 (Safe Decoding)</td><td>20의 SafeDec 처럼 Logit을 마스킹할 수 있으나, 모델 구조 의존적임.</td></tr>
<tr><td><strong>3. Action 앞단</strong></td><td><strong>물리 명령 (속도, 위치)</strong></td><td><strong>최적 (Safety Filter)</strong></td><td><strong>모델 불가지론적(Model-agnostic). 물리적 제약을 수학적으로 강제 가능.</strong></td></tr>
<tr><td><strong>4. 실행 단계</strong></td><td>모터 토크</td><td>하드웨어 리미트</td><td>최후의 수단(Emergency Stop). 지능적인 회피 기동은 불가능.</td></tr>
</tbody></table>
<p>따라서 질문한 “Action 앞단“은 3번 단계에 해당하며, 이곳이 안전을 위한 ’골든 존(Golden Zone)’이다.</p>
<h3>4.2  핵심 구현 기술: 제어 장벽 함수(CBF)</h3>
<p>단순한 규칙 기반(Rule-based) 필터를 넘어, 현대 제어 이론을 접목한 고도화된 RTA 기술들이 VLA에 적용되고 있다. 그 중 가장 대표적인 것이 **제어 장벽 함수(Control Barrier Functions, CBF)**이다.21</p>
<h4>4.2.1  CBF의 수학적 원리와 작동 방식</h4>
<p>CBF는 로봇의 상태 공간(State Space, <span class="math math-inline">\mathcal{X}</span>) 내에 **안전 집합(Safe Set, <span class="math math-inline">\mathcal{C}</span>)**을 정의한다.</p>
<ul>
<li><strong>정의:</strong> 안전 집합은 함수 <span class="math math-inline">h(x) \geq 0</span> 으로 정의된다. 여기서 <span class="math math-inline">h(x)</span>는 장애물까지의 거리나 속도 제한 여유분 등을 의미한다.</li>
<li><strong>작동 원리:</strong> VLA가 생성한 명목 제어 입력(Nominal Control Input, <span class="math math-inline">u_{nom}</span>)이 안전 집합을 벗어나려 할 때(<span class="math math-inline">\dot{h}(x)</span>가 충분히 크지 않을 때), CBF는 다음의 2차 계획법(Quadratic Programming, QP) 문제를 실시간으로 풀어 안전한 제어 입력 <span class="math math-inline">u^*</span>를 도출한다.</li>
</ul>
<p><span class="math math-display">
u^* = \operatorname*{argmin}_{u} \| u - u_{nom} \|^2
</span></p>
<p><span class="math math-display">
\text{subject to } \frac{\partial h}{\partial x} f(x) + \frac{\partial h}{\partial x} g(x) u \geq -\alpha(h(x))
</span></p>
<ul>
<li><strong>해석:</strong> 위 수식은 “VLA가 원했던 행동(<span class="math math-inline">u_{nom}</span>)과 최대한 비슷하게 행동하되, 안전 장벽(<span class="math math-inline">h(x)</span>)을 침범하지 않는 조건(부등식 제약)을 반드시 만족하라“는 뜻이다.</li>
<li><strong>효과:</strong> 이 과정은 VLA 모델을 재학습할 필요 없이(Training-free), 수학적으로 안전을 보증(Formally Verify)한다. 모델이 “벽으로 돌진해“라고 명령해도, CBF 필터가 이를 “벽 바로 앞에서 정지” 또는 “벽을 타고 미끄러짐“으로 0.001초 만에 변환한다.22</li>
</ul>
<pre><code class="language-mermaid">graph TD
    subgraph "4.2.1 CBF Optimization Logic"
        Start("Input: Nominal Control u_nom") --&gt; State("Get Current Robot State x")
        State --&gt; CalcH("Calculate Barrier Value h(x)")
        CalcH --&gt; CheckH{"Is h(x) decreasing too fast? (Safety Violation)"}
        
        CheckH -- "No (Safe)" --&gt; OutputNom("Output: u* = u_nom")
        
        CheckH -- "Yes (Unsafe)" --&gt; QP_Setup("Setup Quadratic Programming (QP)")
        
        subgraph "QP Solver"
            Obj("Minimize: ||u - u_nom||^2")
            Constraint("Subject to: L_f h(x) + L_g h(x)u &gt;= -alpha(h(x))")
            Solve("Compute u*")
        end
        
        QP_Setup --&gt; Obj --&gt; Constraint --&gt; Solve
        Solve --&gt; OutputSafe("Output: Modified u*")
    end
</code></pre>
<h3>4.3  SafeVLA와 예측 안전 필터 (Predictive Safety Filter)</h3>
<p>단순한 반응형(Reactive) 필터의 한계를 극복하기 위해, 예측 제어(MPC)를 결합한 연구도 진행되고 있다.</p>
<ul>
<li>SafeVLA 24: 이 연구는 학습 단계에서 제약을 주는 것(Constrained Learning)뿐만 아니라, 추론 단계에서의 안전 필터링을 강조한다. 특히 <strong>SafeDec</strong> 20과 같은 기법은 토큰 생성 단계(Decoding)에서 안전 제약(STL: Signal Temporal Logic)을 위반하는 토큰의 확률(Logit)을 0으로 만들어버리는 방식이다. 이는 물리적 필터보다 더 앞단인 **‘신경망의 생각 과정’**에 RTA를 주입하는 시도이다.</li>
<li><strong>예측 필터 (Predictive Filter):</strong> VLA의 낮은 추론 속도(1~5Hz)로 인한 지연(Latency) 문제를 해결하기 위해, VLA의 명령을 미래로 시뮬레이션(Rollout)해보고, 1초 뒤에 충돌이 예상되면 미리 개입하는 방식이다.19</li>
</ul>
<h3>4.4  언어 조건부 RTA (Language-Conditioned Safety)</h3>
<p>최근 연구는 <strong>자연어 제약 조건</strong>을 RTA에 통합하려 한다.26</p>
<ul>
<li><strong>시나리오:</strong> 사용자가 “천천히 컵을 집어라, 단 <strong>물이 쏟아지지 않게(Don’t spill)</strong>“라고 명령한다.</li>
<li><strong>작동 메커니즘:</strong></li>
</ul>
<ol>
<li><strong>Language Module:</strong> LLM이 “물이 쏟아지지 않게“라는 텍스트를 해석하여, RTA 모듈의 파라미터(예: 최대 가속도 제한, 엔드 이펙터 기울기 허용 범위)를 동적으로 엄격하게 설정한다.</li>
<li><strong>RTA Module:</strong> 설정된 파라미터를 기반으로 VLA의 행동을 필터링한다.</li>
</ol>
<ul>
<li>이는 VLA의 ’의미론적 이해력’과 RTA의 ’수학적 강제력’을 결합하는 하이브리드 접근 방식이다.</li>
</ul>
<pre><code class="language-mermaid">sequenceDiagram
    autonumber
    title "4.4 Language-Conditioned RTA Interaction"
    participant User as "User Command"
    participant LLM as "LLM / VLA Parser"
    participant RTA as "Safety Filter (CBF)"
    participant Policy as "Action Policy"
    participant Robot as "Robot Actuator"

    User-&gt;&gt;LLM: "Pour water,&lt;br&gt;but do not spill&lt;br&gt;(Constraint)"
    
    par Parallel Processing
        LLM-&gt;&gt;Policy: "Generate&lt;br&gt;Pouring Actions"
        LLM-&gt;&gt;RTA: "Extract Constraint:&lt;br&gt;Max Tilt Angle &lt; 5 deg"
    end
    
    RTA-&gt;&gt;RTA: "Update Barrier Function h(x) parameters"
    
    loop Control Loop
        Policy-&gt;&gt;RTA: "Nominal Action&lt;br&gt;(u_nom)"
        RTA-&gt;&gt;RTA: "Check: Does u_nom&lt;br&gt;violate Tilt &lt; 5?"
        alt Violation Detected
            RTA-&gt;&gt;RTA: "Solve QP -&gt; Get u_safe"
            RTA-&gt;&gt;Robot: "Execute u_safe&lt;br&gt;(Restricted Tilt)"
        else Safe
            RTA-&gt;&gt;Robot: "Execute u_nom"
        end
    end
</code></pre>
<h3>4.5  RTA 주입의 현실적 비용: Latency Overhead</h3>
<p>RTA를 주입할 때 가장 큰 걸림돌은 **계산 비용과 지연 시간(Latency)**이다.19 VLA 모델 추론에 이미 많은 GPU 자원이 사용되는데, 복잡한 최적화(QP)를 풀어야 하는 CBF나 MPC를 추가하면 제어 루프가 느려질 수 있다. 이를 해결하기 위해 <strong>Fast Tokenization</strong> 28이나, GPU 병렬 처리를 통한 고속 충돌 검사(GSplat Collision Check) 22 등의 경량화 기술이 필수적으로 동반되어야 한다.</p>
<h2>5.  결론 및 향후 전망: 신뢰할 수 있는 VLA를 향하여</h2>
<p>본 보고서는 VLA 모델의 아키텍처적 특성, 설명 가능성, 그리고 안전 보증 기술을 종합적으로 분석하였다. 결론적으로 VLA는 로봇 제어의 패러다임을 혁신하고 있으나, 그 자체만으로는 안전을 담보할 수 없는 ’불완전한 천재’와 같다. 따라서 실전 배포를 위해서는 다음과 같은 전략적 접근이 필요하다.</p>
<ol>
<li><strong>E2E의 재정의:</strong> VLA는 ’인지에서 정책까지’의 E2E 모델로 활용하되, 물리적 실행은 검증된 고주파 제어기(Controller)에게 위임하는 <strong>계층적 아키텍처</strong>를 표준으로 삼아야 한다. RT-X와 같은 데이터셋 표준화 노력은 이러한 추상화를 가속화할 것이다.</li>
<li><strong>XAI의 역할 한정:</strong> CoT와 시각적 설명은 모델의 ’의도’를 파악하고 디버깅하는 도구로 매우 유용하다. 그러나 **비충실성(Unfaithfulness)**의 위험이 상존하므로, 이를 안전 인증(Certification)의 근거로 사용해서는 안 되며, 운영자의 감독을 돕는 보조 수단(Assistant)으로 활용해야 한다.</li>
<li><strong>RTA의 필수화:</strong> 사용자가 질문한 <strong>’Action 앞단’의 RTA 주입은 선택이 아닌 필수</strong>이다. 제어 장벽 함수(CBF)와 같은 수학적 안전 필터는 확률적 AI 모델이 물리적 세계에 해를 끼치지 않도록 막는 유일한 확정적 방어선이다.</li>
</ol>
<p>향후 연구는 **“신뢰할 수 있는 VLA (Trustworthy VLA)”**로 수렴할 것이다. 이는 VLA의 창의적인 문제 해결 능력과 제어 이론의 엄격한 안전성을 결합하는 방향, 즉 <strong>“생각은 자유롭게(VLA), 행동은 안전하게(RTA)”</strong> 하는 하이브리드 시스템으로 진화할 것으로 전망된다.</p>
<pre><code class="language-mermaid">mindmap
  root(("Trustworthy VLA Strategy"))
    Architecture
      ("Hierarchical E2E")
      ("VLA as High-Level Policy")
      ("Controller as Low-Level Execution")
      ("Hardware Abstraction (RT-X)")
    Explainability
      ("Auxiliary Tool Only")
      ("Debugging Intent")
      ("Aware of Hallucination")
      ("Not for Certification")
    Runtime_Assurance
      ("Mandatory Injection")
      ("Mathematical Guarantee (CBF)")
      ("Action Pre-processing")
      ("Model-Agnostic Filter")
    Future_Hybrid
      ("Free Thinking (VLA)")
      ("Safe Acting (RTA)")
</code></pre>
<h3>5.1 [부록] 핵심 요약 데이터 시트</h3>
<table><thead><tr><th><strong>분석 항목</strong></th><th><strong>결론 (요약)</strong></th><th><strong>핵심 기술 및 근거</strong></th><th><strong>RTA/XAI 적용 전략</strong></th></tr></thead><tbody>
<tr><td><strong>E2E 여부</strong></td><td><strong>Visuomotor E2E</strong></td><td>신경망 내부는 E2E, 시스템 전체는 계층적 (VLA+Controller) 1</td><td>추론 속도(1-5Hz)와 제어 속도(1kHz) 간의 브릿지 필요</td></tr>
<tr><td><strong>XAI 가능성</strong></td><td><strong>가능 (주의 요망)</strong></td><td>Chain-of-Thought, Visual CoT, Attention Map 1</td><td>설명의 비충실성(Hallucination/Post-hoc)을 인지하고 보조 도구로만 활용</td></tr>
<tr><td><strong>RTA 주입</strong></td><td><strong>가능 및 필수</strong></td><td>Action Decoding 후단에 <strong>CBF(제어 장벽 함수)</strong> 필터 주입 21</td><td>수학적 최적화(QP)를 통해 물리적 제약을 강제하여 모델의 불확실성 차단</td></tr>
</tbody></table>
<pre><code class="language-mermaid">graph TD
    subgraph Pase1["Phase 1: Pre-training"]
        Web("Web-scale Data (Text/Image)") --&gt; Base("Base VLM Training")
    end

    subgraph Pase2["Phase 2: Robot Fine-tuning"]
        RTX("RT-X Robot Data") --&gt; CoT_Train("Co-training with CoT Data")
        Base &amp; RTX &amp; CoT_Train --&gt; FinalModel("VLA Policy Model")
    end

    subgraph Pase3["Phase 3: Deployment (Runtime)"]
        FinalModel --&gt; ActionGen("Action Generation")
        ActionGen --&gt; Safety("Safety Filter (RTA)")
        Safety --&gt; Act("Physical Actuation")
    end       
</code></pre>
<h2>6. 참고 자료</h2>
<ol>
<li>RT-2: Vision-Language-Action Models, https://robotics-transformer2.github.io/</li>
<li>RT-2: Vision-Language-Action Models Transfer Web Knowledge to …, https://proceedings.mlr.press/v229/zitkovich23a/zitkovich23a.pdf</li>
<li>RT-2: Vision-Language-Action Models Transfer Web Knowledge to …, https://www.cs.utexas.edu/~yukez/cs391r_fall2023/slides/pre_10-24_Ming.pdf</li>
<li>Large VLM-based Vision-Language-Action Models for Robotic …, https://arxiv.org/html/2508.13073v1</li>
<li>(PDF) Reproducing RT-2: A Case Study in Deploying Vision …, https://www.researchgate.net/publication/395465812_Reproducing_RT-2_A_Case_Study_in_Deploying_Vision-Language-Action_Models_on_Open-Source_Hardware</li>
<li>Control Modes — Robotic Development Kit (RDK) documentation, https://www.flexiv.com/software/rdk/manual/control_modes.html</li>
<li>Redundancy-Aware Action Spaces for Robot Learning - IEEE Xplore, https://ieeexplore.ieee.org/iel8/7083369/10561888/10560461.pdf</li>
<li>A tutorial note on collecting simulated data for vision-language …, https://arxiv.org/html/2508.06547v1</li>
<li>Octo: An Open-Source Generalist Robot Policy - SciSpace, https://scispace.com/pdf/octo-an-open-source-generalist-robot-policy-3t5668mqca.pdf</li>
<li>RT-2: New model translates vision and language into action, https://deepmind.google/blog/rt-2-new-model-translates-vision-and-language-into-action/</li>
<li>CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language …, https://arxiv.org/html/2503.22020v1</li>
<li>CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language …, https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_CoT-VLA_Visual_Chain-of-Thought_Reasoning_for_Vision-Language-Action_Models_CVPR_2025_paper.pdf</li>
<li>The Rise of Vision-Language-Action Models in Robotics - Marvik, https://www.marvik.ai/blog/from-words-to-actions-the-rise-of-vision-language-action-models-in-robotics</li>
<li>What is faithful chain-of-thought reasoning and why is it useful for AI …, https://bluedot.org/blog/faithful-chain-of-thought</li>
<li>Unfaithful Explanations in Chain-of-Thought Prompting - Miles Turpin, https://www.milesturp.in/Unfaithful-Explanations-in-Chain-of-Thought-Prompting/</li>
<li>Chain-of-Thought Reasoning In The Wild Is Not Always Faithful - arXiv, https://arxiv.org/html/2503.08679v4</li>
<li>A Closer Look at Bias and Chain-of-Thought Faithfulness of Large …, https://aclanthology.org/2025.findings-emnlp.723.pdf</li>
<li>Cyber Resilience of Connected and Autonomous … - ROSA P, https://rosap.ntl.bts.gov/view/dot/86379/dot_86379_DS1.pdf</li>
<li>Language-Conditioned Safety Filtering for Robot Navigation - arXiv, https://arxiv.org/html/2511.05889v1</li>
<li>SafeDec: Constrained Decoding for Safe Autoregressive Generalist…, https://openreview.net/forum?id=dLO7MhVbbB</li>
<li>Safe Control using Vision-based Control Barrier Function (V-CBF), https://www.semanticscholar.org/paper/Safe-Control-using-Vision-based-Control-Barrier-Abdi-Raja/3f9b43c1d56ab97663488cee67ec6b7b5cd47cad</li>
<li>SAFER-Splat: A Control Barrier Function for Safe Navigation … - arXiv, https://arxiv.org/html/2409.09868v1</li>
<li>Safety Guarantees for Uncertain Dynamical Systems - UC Berkeley, https://escholarship.org/content/qt3k17c3mt/qt3k17c3mt.pdf</li>
<li>Towards Safety Alignment of Vision-Language-Action Model … - arXiv, https://arxiv.org/abs/2503.03480</li>
<li>SafeVLA: Towards Safety Alignment of Vision-Language-Action …, https://arxiv.org/html/2503.03480v1</li>
<li>Language-Conditioned Safety Filtering for Robot Navigation, https://www.researchgate.net/publication/397479581_From_Words_to_Safety_Language-Conditioned_Safety_Filtering_for_Robot_Navigation</li>
<li>RoboMonkey: Scaling Test-Time Sampling and Verification for …, https://scalingintelligence.stanford.edu/pubs/robomonkey.pdf</li>
<li>Efficient Action Tokenization for Vision-Language-Action Models, https://www.physicalintelligence.company/download/fast.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>