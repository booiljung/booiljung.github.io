<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:4.4 학습에 유리한 액추에이터 (Actuators for Learning)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>4.4 학습에 유리한 액추에이터 (Actuators for Learning)</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 4. 하드웨어와 AI의 공진화 (Co-Evolution)</a> / <a href="index.html">4.4 학습에 유리한 액추에이터 (Actuators for Learning)</a> / <span>4.4 학습에 유리한 액추에이터 (Actuators for Learning)</span></nav>
                </div>
            </header>
            <article>
                <h1>4.4 학습에 유리한 액추에이터 (Actuators for Learning)</h1>
<h2>1.  서론: 로봇 학습과 구동 시스템의 패러다임 전환</h2>
<p>로봇 공학의 역사에서 제어 이론과 하드웨어 설계는 불가분의 관계를 맺으며 발전해 왔다. 과거의 로봇 제어, 특히 산업용 매니퓰레이터의 제어는 정해진 궤적을 오차 없이 추종하는 위치 제어(Position Control)가 주를 이루었다. 이를 위해 액추에이터는 높은 감속비(High Gear Ratio)를 통해 막대한 토크를 생성하고, 시스템의 강성(Stiffness)을 극대화하여 외란에 흔들리지 않는 견고함을 갖추는 방향으로 진화했다. 이러한 ‘강한’ 액추에이터는 정밀도 측면에서는 우수했지만, 외부 환경과의 접촉이나 충돌이 빈번한 동적 작업에서는 치명적인 약점을 노출했다.</p>
<p>최근 딥러닝(Deep Learning)과 강화학습(Reinforcement Learning, RL)이 로봇 제어의 새로운 지평을 열면서, 액추에이터에게 요구되는 덕목 또한 근본적으로 변화하고 있다. 강화학습 기반의 제어 정책(Policy)은 로봇이 환경과 끊임없이 상호작용하며 시행착오를 통해 최적의 행동을 학습하는 과정을 거친다. 이 과정에서 로봇은 수만 번의 넘어짐과 충돌을 겪어야 하며, 시뮬레이션상에서 학습한 정책이 실제 물리 세계에서도 동일하게 작동하도록 보장하는 ‘Sim-to-Real’ 정합성이 무엇보다 중요해졌다.</p>
<p>따라서 ’학습에 유리한 액추에이터’란 단순히 효율이 높거나 힘이 센 구동기가 아니다. 그것은 학습 알고리즘이 예측 가능한 선형적인 동역학을 가지며(Linear Dynamics), 고빈도의 제어 명령을 지연 없이 수행할 수 있는 대역폭(Bandwidth)을 갖추고, 예상치 못한 충격으로부터 스스로를 보호할 수 있는 물리적 유연성(Physical Compliance)을 내재한 시스템을 의미한다. 본 장에서는 강화학습의 관점에서 액추에이터가 갖춰야 할 핵심적인 물리적 특성을 분석하고, 준직구동(Quasi-Direct Drive, QDD), 직렬 탄성 액추에이터(Series Elastic Actuator, SEA), 그리고 최근 주목받는 가변 강성(Variable Stiffness) 및 소프트 액추에이터 기술이 로봇 학습과 어떻게 상호작용하며 진화하고 있는지 심층적으로 논한다.</p>
<h2>2.  학습 효율성을 결정짓는 액추에이터의 물리적 특성</h2>
<p>강화학습 에이전트, 특히 PPO(Proximal Policy Optimization)나 SAC(Soft Actor-Critic)와 같은 알고리즘이 실제 로봇 하드웨어에서 성공적으로 동작하기 위해서는 액추에이터가 제공하는 물리적 정보의 질과 제어의 반응성이 보장되어야 한다. 이를 평가하는 핵심 지표들은 다음과 같다.</p>
<h3>2.1  토크 투명성(Torque Transparency)과 역구동성(Backdrivability)</h3>
<p>토크 투명성은 액추에이터의 입력(전류)과 출력(토크) 사이의 관계가 얼마나 명확하고 방해 요소가 없는지를 나타낸다. 전통적인 고감속비 액추에이터(예: 파동 기어, 사이클로이드 드라이브 등)는 감속기 내부의 높은 마찰과 비선형성으로 인해 모터 전류만으로는 출력단의 실제 토크를 추정하기 어렵다. 이는 강화학습 에이전트가 환경과의 접촉 힘(Contact Force)을 정확히 인지하지 못하게 만들어, 상태 추정(State Estimation)의 불확실성을 높이는 결과를 초래한다.1</p>
<p>반면, 역구동성이 높은 액추에이터는 출력단에서 가해지는 외력이 모터의 회전자(Rotor)로 손실 없이 전달된다. 이는 별도의 고가 힘/토크 센서(F/T Sensor) 없이도 모터의 전류(Current) 측정만으로 외부 충돌이나 접촉을 감지할 수 있게 한다. 이러한 특성을 ’고유 수용성(Proprioception)’이라 부르며, 이는 강화학습에서 관측 공간(Observation Space)의 신뢰도를 높이는 결정적인 요소다.2 MIT Cheetah 프로젝트에서 제안된 설계 원칙에 따르면, 높은 토크 투명성을 가진 액추에이터는 임피던스 제어(Impedance Control)를 통해 가상의 스프링-댐퍼 시스템을 정교하게 구현할 수 있어, 학습된 정책이 다양한 지형에 유연하게 적응하도록 돕는다.4</p>
<h3>2.2  반사 관성(Reflected Inertia)과 충격 완화</h3>
<p>액추에이터의 반사 관성 <span class="math math-inline">J_{ref}</span>는 모터 자체의 관성 <span class="math math-inline">J_{motor}</span>에 기어비 <span class="math math-inline">N</span>의 제곱을 곱한 값으로 정의된다 (<span class="math math-inline">J_{ref} \approx N^2 J_{motor}</span>). 기어비가 높을수록 반사 관성은 기하급수적으로 증가하며, 이는 로봇이 외부 충격을 받았을 때 마치 거대한 질량을 가진 물체처럼 반응하게 만든다.<br />
<span class="math math-display">
\tau_{impact} \propto J_{ref} \cdot \ddot{\theta}
</span><br />
위 식에서 볼 수 있듯이, 반사 관성이 크면 지면과의 충돌 시 발생하는 충격 토크 <span class="math math-inline">\tau_{impact}</span>가 매우 커져 기어 파손을 유발하거나 로봇의 자세를 불안정하게 만든다.1 강화학습 기반의 보행 제어(Locomotion Control)에서는 발을 내딛는 순간의 충격 처리가 핵심 과제 중 하나다. 반사 관성이 낮은 액추에이터는 충격 에너지를 기구적으로 흡수하거나 모터의 회전으로 변환하여 흘려보낼 수 있다(Impact Mitigation). 이는 에이전트가 과감한 탐험(Exploration)을 시도할 수 있는 하드웨어적 안전망을 제공하며, 시뮬레이션과 실제 환경 간의 충돌 역학 차이를 줄여 Sim-to-Real 전이 성능을 향상시킨다.4</p>
<h3>2.3  대역폭(Bandwidth)과 제어 응답성</h3>
<p>대역폭은 액추에이터가 얼마나 빠른 주파수의 제어 명령을 물리적으로 구현할 수 있는지를 의미한다. 강화학습으로 학습된 정책은 종종 인간이 설계한 제어기보다 훨씬 고주파수(High-frequency) 성분을 포함하거나 급격한 토크 변화를 요구한다. 만약 액추에이터의 대역폭이 낮다면, 정책이 출력한 빠른 제어 신호는 하드웨어 단에서 필터링(Filtering)되어 무시되거나 위상 지연(Phase Lag)을 발생시킨다.7</p>
<p>시뮬레이터에서는 이러한 대역폭 제한을 완벽하게 모사하기 어렵기 때문에, 대역폭이 낮은 액추에이터는 본질적으로 Sim-to-Real Gap을 유발한다. 따라서 학습에 유리한 액추에이터는 전기적 시상수(Inductance)와 기계적 관성을 최소화하여, 정책의 판단을 즉각적으로 물리적 움직임으로 변환할 수 있어야 한다. 특히 급격한 방향 전환이나 점프와 같은 폭발적인 동작(Explosive Motion)을 학습하기 위해서는 넓은 대역폭 확보가 필수적이다.9</p>
<h2>3.  고유 수용성 액추에이터 (Proprioceptive Actuator)와 준직구동(QDD)</h2>
<p>현재 4족 보행 로봇과 고성능 로봇 팔 연구에서 ’사실상의 표준(De Facto Standard)’으로 자리 잡은 기술은 바로 준직구동(Quasi-Direct Drive, QDD) 액추에이터다. 이는 ’고유 수용성 액추에이터(Proprioceptive Actuator)’라고도 불리며, 기어비를 최소화하면서도 필요한 토크를 확보하는 설계 철학을 바탕으로 한다.</p>
<h3>3.1  QDD의 기계적 설계 원칙</h3>
<p>QDD는 전통적인 고감속비(50:1 ~ 200:1) 시스템과 직구동(Direct Drive, 1:1) 시스템의 장점을 결합한 형태다. 일반적으로 6:1에서 10:1 사이의 낮은 감속비를 가진 단일 단계 유성 기어(Single-stage Planetary Gear)와, 직경이 크고 토크 밀도가 높은 BLDC 모터(Gap Radius가 큰 Outrunner 또는 Frameless Motor)를 조합하여 구성한다.1</p>
<table><thead><tr><th><strong>특성</strong></th><th><strong>전통적 액추에이터 (High Gear Ratio)</strong></th><th><strong>직구동 (Direct Drive)</strong></th><th><strong>준직구동 (QDD)</strong></th></tr></thead><tbody>
<tr><td><strong>기어비 (<span class="math math-inline">N</span>)</strong></td><td><span class="math math-inline">N &gt; 50</span> (파동 기어 등)</td><td><span class="math math-inline">N = 1</span></td><td><span class="math math-inline">N \approx 6 \sim 10</span></td></tr>
<tr><td><strong>반사 관성</strong></td><td>매우 높음 (<span class="math math-inline">N^2</span>)</td><td>매우 낮음</td><td>낮음 (최적화 영역)</td></tr>
<tr><td><strong>백래시</strong></td><td>존재 (기어 종류에 따라 다름)</td><td>없음</td><td>최소화 가능</td></tr>
<tr><td><strong>토크 투명성</strong></td><td>낮음 (마찰 큼)</td><td>매우 높음</td><td>높음</td></tr>
<tr><td><strong>물리적 유연성</strong></td><td>낮음 (강성 높음)</td><td>높음</td><td>높음 (제어 가능)</td></tr>
</tbody></table>
<p>위 표에서 볼 수 있듯이, QDD는 기어비를 낮춤으로써 마찰과 반사 관성을 획기적으로 줄인다. 이는 모터의 전자기적 힘이 기어박스의 방해를 거의 받지 않고 출력단으로 전달됨을 의미한다.</p>
<h3>3.2  강화학습 관점에서의 QDD의 강점</h3>
<ol>
<li><strong>정밀한 토크 제어와 Sim-to-Real:</strong> QDD는 마찰이 적고 선형적인 특성을 가지므로, 시뮬레이터에서 단순한 모터 모델(DC 모터 방정식)만으로도 실제 거동을 매우 정확하게 예측할 수 있다. 이는 RL 에이전트가 시뮬레이션에서 학습한 토크 제어 정책을 실제 로봇에 적용했을 때 발생하는 오차를 최소화한다.2</li>
<li><strong>임피던스 학습의 용이성:</strong> QDD는 기계적 임피던스가 낮아, 소프트웨어적으로 강성과 감쇠를 조절하는 가상 컴플라이언스(Virtual Compliance) 구현에 최적화되어 있다. 강화학습을 통해 로봇이 상황에 맞는 최적의 강성(Stiffness)과 감쇠(Damping)를 학습하게 할 때, 하드웨어의 방해 없이 제어기 수준에서 의도한 물성을 그대로 발현할 수 있다.3</li>
<li><strong>에너지 회생과 효율성:</strong> 보행 로봇이 내리막길을 걷거나 감속할 때, QDD는 역구동성이 좋아 운동 에너지를 전기 에너지로 회생(Regeneration)시킬 수 있다. KAIST의 RAIBO2 로봇은 이러한 QDD의 특성을 활용하여 강화학습 기반 제어기로 풀코스 마라톤을 완주하는 기록을 세웠으며, 내리막길에서 에너지를 회수하여 효율을 극대화했다는 점이 입증되었다.11</li>
</ol>
<h3>3.3  최신 연구 사례: MIT Cheetah와 KAIST Hound</h3>
<p><strong>MIT Cheetah</strong> 시리즈는 QDD 기술의 효시와도 같다. Wensing et al. (2017)은 “Proprioceptive Actuator Design“이라는 논문을 통해, 충격 완화와 고대역폭 물리 상호작용을 위한 QDD 설계 원칙을 정립했다.4 이들은 기어비를 낮추고 모터의 공극 반경(Air Gap Radius)을 키워 토크 밀도를 높이는 방식이 동적 보행 로봇에 필수적임을 증명했다.</p>
<p><strong>KAIST의 Hound</strong> 로봇은 여기서 한 걸음 더 나아가, 강화학습을 통해 고속 주행을 달성했다. Shin et al. (2023)은 QDD 액추에이터의 **동적 토크 한계(Dynamic Torque Limit)**를 고려한 학습 프레임워크를 제안했다.9 기존 RL 연구들이 모터의 최대 토크만을 제약조건으로 두었다면, 이 연구는 모터의 속도가 빨라질수록 낼 수 있는 토크가 줄어드는 물리적 특성(역기전력 등)을 시뮬레이션에 정밀하게 반영했다. 결과적으로 Hound 로봇은 6.5m/s라는 놀라운 속도로 주행에 성공했으며, 이는 QDD 하드웨어와 물리적 제약을 고려한 학습 알고리즘의 결합이 얼마나 강력한지를 보여준다.</p>
<h3>3.4  QDD의 한계</h3>
<p>QDD는 탁월한 동적 성능을 제공하지만, 절대적인 토크 생성 능력은 고감속비 액추에이터에 비해 부족할 수 있다. 따라서 무거운 하중을 지탱해야 하는 휴머노이드 로봇의 무릎이나 허리 관절에는 여전히 한계가 존재한다. 이를 극복하기 위해 최근에는 QDD와 유사한 투명성을 가지면서도 토크를 높인 사이클로이드 기반의 액추에이터나, 학습 기반의 오차 보정 기술을 접목하는 연구가 진행되고 있다.2</p>
<h2>4.  직렬 탄성 액추에이터 (Series Elastic Actuator, SEA)</h2>
<p>SEA는 모터와 부하(Load) 사이에 의도적으로 탄성체(스프링)를 직렬로 배치한 구조다. 이는 로봇 하드웨어 자체에 물리적인 ’쿠션’을 제공하는 것으로, ANYmal 초기 모델이나 NASA의 발키리(Valkyrie) 로봇 등에 채택되었다.13</p>
<h3>4.1  SEA의 동역학적 특성과 모델링</h3>
<p>SEA의 핵심 아이디어는 스프링의 변위(<span class="math math-inline">\Delta x</span>)를 측정하여 힘(<span class="math math-inline">F = k \Delta x</span>)을 제어하는 것이다. 이는 힘 센서의 노이즈 문제를 해결하고 충격을 흡수하는 데 탁월하다. 동역학적으로 SEA는 시스템에 낮은 주파수의 공진(Resonance) 모드를 도입한다.</p>
<p>강화학습 관점에서 SEA는 **내재적 안전성(Intrinsic Safety)**을 제공한다. 학습 초기 단계(Exploration)에서 에이전트가 과도한 토크를 출력하거나 급격한 움직임을 시도하더라도, 스프링이 이를 물리적으로 댐핑(Damping)해주어 기어박스와 링크를 보호한다.15 또한, 인간과 상호작용하는 협동 로봇(Cobot)이나 재활 로봇의 경우, SEA의 유연성은 예측 불가능한 인간의 움직임에 안전하게 반응할 수 있는 기반이 된다.</p>
<h3>4.2  학습에서의 장점: 에너지 효율과 강건성</h3>
<p>SEA는 주기적인 운동(Periodic Motion), 예를 들어 걷기나 뛰기 동작에서 에너지 효율을 극대화할 수 있다. 강화학습 에이전트가 시스템의 고유 진동수(Natural Frequency)에 맞춰 움직이도록 학습되면, 스프링에 저장된 탄성 에너지를 적절한 타이밍에 방출하여 적은 모터 토크로도 큰 힘을 낼 수 있다.14 이는 자연계의 동물이 근건(Tendons)을 활용하는 원리와 유사하다.</p>
<p>최근 연구에서는 모델 프리(Model-Free) RL을 SEA 제어에 적용하여, 복잡한 비선형 스프링 특성이나 마찰을 명시적으로 모델링하지 않고도 정밀한 힘 제어를 달성한 사례가 보고되었다. 예를 들어, SEA가 장착된 펜듈럼 시스템에서 PPO 알고리즘을 사용하여 PID 제어보다 우수한 추적 성능과 안정성 마진을 확보한 연구가 있다.16</p>
<h3>4.3  학습에서의 단점과 극복 과제</h3>
<p>그러나 SEA는 <strong>제어 대역폭의 저하</strong>라는 명확한 단점을 가진다. 탄성체로 인해 고주파수 명령 전달이 지연되거나 감쇠되기 때문에, 폭발적인 반응이 필요한 고동적(High-dynamic) 작업 학습에는 불리할 수 있다.17 또한, 스프링의 진동을 억제하기 위한 제어 노력이 추가로 필요하며, 시뮬레이션에서 실제 스프링의 비선형성(Non-linearity)을 완벽히 모사하기 어려워 Sim-to-Real Gap이 커질 수 있다.</p>
<p>이러한 이유로 최근 ANYmal 로봇 시리즈는 다리 관절에는 충격 흡수가 좋은 SEA를 사용하더라도, 팔이나 휠과 같이 정밀하고 빠른 제어가 필요한 부분에는 QDD 방식(DynaDrive)을 도입하는 하이브리드 접근을 취하고 있다.13</p>
<h2>5.  가변 강성(VSA) 및 이중 강성 액추에이터(BSA)</h2>
<p>단순히 힘을 제어하는 것을 넘어, 관절의 강성(Stiffness) 자체를 실시간으로 조절할 수 있는 가변 강성 액추에이터(Variable Stiffness Actuator, VSA)는 ’임바디드 AI(Embodied Intelligence)’의 핵심 요소로 부상하고 있다.</p>
<h3>5.1  형태학적 연산 (Morphological Computation)</h3>
<p>VSA나 소프트 액추에이터는 제어 알고리즘이 담당해야 할 연산의 일부를 하드웨어의 물성에 위임(Offloading)하는 ’형태학적 연산’을 가능하게 한다.19 예를 들어, 로봇 손이 물체를 잡을 때, 모든 손가락 관절을 정밀하게 제어하는 대신 손가락의 강성을 낮추면 물체의 형상에 맞춰 자연스럽게 감싸 쥐는 동작이 가능하다.</p>
<p>강화학습의 관점에서 이는 <strong>제어 차원(Control Dimensionality)의 축소</strong>와 <strong>탐색 공간(Search Space)의 효율화</strong>를 의미한다.21 수십 개의 자유도를 가진 로봇을 제어할 때, 강성이라는 상위 레벨의 파라미터를 조절함으로써 복잡한 궤적 생성 문제를 단순화할 수 있는 것이다. 이는 학습에 필요한 샘플 수(Sample Efficiency)를 줄이는 데 크게 기여한다.23</p>
<h3>5.2  이중 강성 구동 (Bi-Stiffness Actuation, BSA)</h3>
<p>최근 ICRA 2024 등에서 주목받은 <strong>BSA(Bi-Stiffness Actuation)</strong> 개념은 VSA의 실용적인 발전 형태다.25 BSA는 로봇이 폭발적인 힘을 내야 하는 순간(예: 던지기, 점프)에는 강한 강성으로 에너지를 전달하고, 충격을 흡수하거나 유연한 대응이 필요한 순간에는 낮은 강성으로 전환하는 메커니즘을 말한다.</p>
<p>기존의 VSA가 복잡한 기구부로 인해 무겁고 제어가 어려웠던 반면, BSA는 타이밍에 맞춰 강성 모드를 스위칭하는 방식으로 단순화되었다. 강화학습은 이러한 ’스위칭 타이밍(Timing of Energy Transfer)’을 학습하는 데 탁월한 성능을 발휘한다. 연구 결과에 따르면, BSA가 적용된 로봇 팔은 강화학습을 통해 최적의 에너지 방출 시점을 학습함으로써, 기존 강체 액추에이터보다 훨씬 적은 에너지로 더 멀리 물체를 던지거나 빠르게 움직일 수 있음이 입증되었다.25</p>
<h2>6.  소프트 및 인공 근육 액추에이터</h2>
<p>전통적인 모터 기반 액추에이터를 넘어, 공압 인공 근육(Pneumatic Artificial Muscle, PAM)이나 유전 탄성체 액추에이터(Dielectric Elastomer Actuator, DEA)와 같은 소프트 액추에이터들도 학습 기반 제어의 새로운 대상으로 떠오르고 있다.</p>
<h3>6.1  유체 구동 인공 근육 (Fluidic Artificial Muscles)</h3>
<p>맥키벤(McKibben) 근육으로 대표되는 유체 구동 근육은 가볍고 출력이 높으며 본질적으로 유연하다.28 이러한 액추에이터는 복잡한 히스테리시스(Hysteresis)와 비선형성을 가지기 때문에, 고전적인 모델 기반 제어(Model-based Control)로는 제어하기가 매우 까다롭다. 바로 이 지점에서 강화학습의 강점이 발휘된다.</p>
<p>강화학습은 시스템의 명확한 수학적 모델 없이도 입출력 데이터만으로 제어 정책을 학습할 수 있다(Model-free RL). 최근 연구에서는 유체 근육의 비선형성을 딥러닝 모델로 근사하거나, 아예 하드웨어 상에서 직접 RL을 수행하여 정밀한 위치 및 힘 제어를 달성하는 사례가 늘고 있다.30 특히 ‘가변 모집(Variable Recruitment)’ 기법을 통해 근육 섬유의 개입을 조절함으로써 제어 차원을 낮추는 연구는 생체 모방 로봇의 학습 효율을 높이는 중요한 단서가 된다.20</p>
<h3>6.2  유전 탄성체 액추에이터 (Dielectric Elastomer Actuators, DEA)</h3>
<p>DEA는 전압을 가하면 수축하거나 이완하는 ‘인공 근육’ 소재로, 반응 속도가 빠르고 에너지 밀도가 높다.32 DEA를 활용한 소프트 로봇은 자유도가 무한대에 가까워 제어 난이도가 극도로 높지만, 강화학습을 통해 이러한 복잡성을 극복하려는 시도가 진행 중이다. 예를 들어, 다층(Multi-layer) DEA 구조를 가진 소프트 그리퍼의 파지 동작을 학습시키거나, DEA 기반의 곤충 로봇이 비정형 환경에서 이동하는 정책을 학습하는 연구들이 있다.34</p>
<h2>7.  액추에이터 모델링과 Sim-to-Real 전략: Actuator Net</h2>
<p>아무리 우수한 물리적 특성을 가진 액추에이터라 하더라도, 시뮬레이션 모델이 실제와 다르다면 강화학습 정책은 현실에서 실패할 수밖에 없다. 따라서 ’학습에 유리한 액추에이터’의 마지막 퍼즐은 바로 <strong>정밀한 모델링 가능성</strong>이다.</p>
<h3>7.1  단순 모델의 한계와 Actuator Net의 등장</h3>
<p>전통적인 시뮬레이터(Gazebo, MuJoCo 등)는 액추에이터를 이상적인 DC 모터나 단순한 PD 제어기로 가정한다. 그러나 실제 액추에이터는 기어의 마찰, 통신 지연, 배터리 전압 강하, 모터 드라이버의 내부 로직 등 수많은 비선형 요소를 포함한다. 이 간극(Reality Gap)을 메우기 위해 Hwangbo et al. (2019)은 <strong>Actuator Net</strong>이라는 개념을 제안했다.36</p>
<p>Actuator Net은 실제 액추에이터의 입출력 데이터(명령, 현재 속도, 출력 토크 등)를 수집하여 이를 심층 신경망(DNN)으로 학습시킨 블랙박스 모델이다. 이 신경망 모델을 물리 엔진 내의 액추에이터 블록으로 대체함으로써, 시뮬레이션의 신뢰도를 획기적으로 높일 수 있다. ANYmal 로봇의 경우, Actuator Net을 도입하여 강화학습만으로 복잡한 지형에서의 보행을 성공시켰으며, 이는 하드웨어의 복잡성을 데이터 기반 모델링으로 정복한 대표적인 사례다.13</p>
<h3>7.2  비지도 학습 기반 Actuator Net (UAN)</h3>
<p>최근 Fey et al. (2025)는 고가의 토크 센서가 없는 로봇 팔이나 저가형 하드웨어에서도 Actuator Net을 활용할 수 있는 **Unsupervised Actuator Net (UAN)**을 제안했다.38 UAN은 토크 데이터 없이도 관절의 위치 오차(Position Error)와 속도 오차의 이력(History)을 통해 액추에이터의 역학을 추정하고 보정 토크를 생성한다.</p>
<p>이러한 접근은 하드웨어 설계 시 완벽한 투명성을 확보하지 못하더라도, 학습 단계에서 소프트웨어적으로 이를 보정할 수 있음을 시사한다. 즉, ’학습에 유리한 액추에이터’는 물리적으로 완벽한 하드웨어일 수도 있지만, <strong>데이터를 통해 그 특성을 쉽게 파악하고 모델링할 수 있는 하드웨어</strong>를 의미하기도 한다.</p>
<h3>7.3  BaRiFlex: 하드웨어와 학습의 공진화</h3>
<p>IROS 2024에서 최우수 논문상을 수상한 <strong>BaRiFlex</strong> 그리퍼는 하드웨어 설계가 학습 알고리즘의 성능을 어떻게 극대화할 수 있는지 보여주는 완벽한 예시다.41 이 그리퍼는 유연한 핀-레이(Fin-Ray) 구조와 강성 링크를 결합하여 충돌에 대한 내성(Collision Robustness)을 확보했다.</p>
<p>강화학습 기반의 조작(Manipulation) 학습 시, 에이전트는 필연적으로 물체나 바닥과 강하게 충돌하며 학습한다. BaRiFlex와 같은 유연한 액추에이터/그리퍼는 이러한 충돌 에너지를 하드웨어적으로 흡수하여 로봇의 파손을 막고, 정밀한 위치 제어 없이도 물체를 감싸 쥘 수 있게 함으로써 학습의 초기 진입 장벽을 낮춘다. 이는 하드웨어의 ’물리적 지능’이 학습 알고리즘의 ’계산적 부담’을 덜어주는 상호보완적 관계를 잘 보여준다.</p>
<h2>8.  결론 및 요약</h2>
<p>강화학습을 위한 액추에이터는 더 이상 단순한 동력원이 아니다. 그것은 에이전트가 세상을 인식하는 감각 기관(Proprioception)이자, 의도를 물리력으로 변환하는 인터페이스이며, 학습 과정의 시행착오를 받아주는 안전망이다.</p>
<p>본 장의 논의를 종합하면, 학습에 유리한 액추에이터는 다음과 같은 계층적 특성을 갖는다.</p>
<ol>
<li><strong>물리적 투명성 (QDD):</strong> 낮은 기어비와 관성을 통해 Sim-to-Real 간극을 원천적으로 줄이고, 고빈도 제어를 가능케 한다. 이는 현재 4족 보행 및 고성능 조작 로봇의 주류 기술이다.</li>
<li><strong>내재적 유연성 (SEA, Soft):</strong> 하드웨어적인 탄성을 통해 안전과 에너지 효율을 제공한다. 모델링은 어렵지만 안전한 탐험과 형태학적 연산을 통한 제어 차원 축소를 가능하게 한다.</li>
<li><strong>데이터 기반 모델링 가능성 (Actuator Net):</strong> 하드웨어의 비선형성을 데이터로 정복하여, 시뮬레이션의 충실도를 높이는 소프트웨어적 보완 기술이다.</li>
</ol>
<p>미래의 로봇 시스템 설계자는 하드웨어 스펙만을 고려하는 것이 아니라, 해당 액추에이터가 강화학습 알고리즘과 어떻게 상호작용할지, 시뮬레이션 모델링은 얼마나 용이한지, 그리고 물리적 지능을 통해 계산 비용을 얼마나 절감할 수 있는지를 종합적으로 판단해야 한다. 이러한 ‘하드웨어-AI 공진화(Co-evolution)’ 관점이야말로 차세대 지능형 로봇 개발의 핵심 열쇠가 될 것이다.</p>
<p><strong>표 4.4.1 강화학습 관점에서의 주요 액추에이터 비교</strong></p>
<table><thead><tr><th><strong>액추에이터 유형</strong></th><th><strong>대표 구조</strong></th><th><strong>학습(RL) 관점의 장점</strong></th><th><strong>학습(RL) 관점의 단점 및 과제</strong></th><th><strong>주요 적용 사례</strong></th></tr></thead><tbody>
<tr><td><strong>QDD (준직구동)</strong></td><td>BLDC + 저감속 유성기어 (<span class="math math-inline">N&lt;10</span>)</td><td>- 높은 투명성 및 역구동성 - 정밀한 토크 제어 (Sim-to-Real 용이) - 높은 충격 저항성 및 대역폭</td><td>- 절대 토크 부족 (고하중 작업 제한) - 열 관리 필요 (상시 토크 유지 시)</td><td>MIT Cheetah, KAIST Hound, ANYmal (Limb)</td></tr>
<tr><td><strong>SEA (직렬 탄성)</strong></td><td>모터 + 기어 + 스프링</td><td>- 내재적 안전성 (충돌 보호) - 주기적 운동 시 에너지 효율 (공진) - 안정한 힘 제어</td><td>- 제어 대역폭 제한 (고동적 운동 불리) - 모델링 복잡성 (비선형 스프링) - 진동 제어 난이도</td><td>ANYmal (Joint), Valkyrie, 재활 로봇</td></tr>
<tr><td><strong>VSA / BSA</strong></td><td>가변 강성 메커니즘</td><td>- 형태학적 연산 (제어 차원 축소) - 상황별 최적 강성 학습 (던지기 등) - 에너지 저장 및 방출 최적화</td><td>- 기구적 복잡성 및 무게 증가 - 상태 추정(State Estimation) 난해</td><td>DLR Hand Arm System, 최신 연구용 로봇 팔</td></tr>
<tr><td><strong>Soft / PAM / DEA</strong></td><td>공압, 유전체, 유연 소재</td><td>- 극강의 충돌 강건성 - 비정형 물체 파지 용이 (Self-adaption)</td><td>- 높은 히스테리시스 및 비선형성 - 정밀 모델링 및 시뮬레이션 난항 - 느린 반응 속도 (공압의 경우)</td><td>소트프 그리퍼 (BaRiFlex), 생체 모방 로봇</td></tr>
</tbody></table>
<p>1</p>
<h2>9. 참고 자료</h2>
<ol>
<li>Why Quasi Direct Drives? - Pulsar HRI, https://pulsarhri.com/technology/why-quasi-direct-drives/</li>
<li>Cycloidal Quasi-Direct Drive Actuator Designs with Learning-based Torque Estimation for Legged Robotics - arXiv, https://arxiv.org/html/2410.16591v2</li>
<li>What is Quasi Direct Drive actuation? And why does it seem to be the default choice for quadruped robotics? - Reddit, https://www.reddit.com/r/robotics/comments/kvaam2/what_is_quasi_direct_drive_actuation_and_why_does/</li>
<li>High speed trot-running: Implementation of a hierarchical controller using proprioceptive impedance control on the MIT Cheetah | Request PDF - ResearchGate, https://www.researchgate.net/publication/281470451_High_speed_trot-running_Implementation_of_a_hierarchical_controller_using_proprioceptive_impedance_control_on_the_MIT_Cheetah</li>
<li>Ch. 2 - Let’s get you a robot - Robotic Manipulation, https://manipulation.csail.mit.edu/robot.html</li>
<li>Direct Drive Hands: Force-Motion Transparency in Gripper Design - Robotics, https://roboticsproceedings.org/rss15/p53.pdf</li>
<li>Reinforcement-learning-based actuator selection method for active flow control | Journal of Fluid Mechanics - Cambridge University Press &amp; Assessment, https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/reinforcementlearningbased-actuator-selection-method-for-active-flow-control/05F50B677ADA6370A23562981D32D625</li>
<li>DiAReL: Reinforcement Learning With Disturbance Awareness for Robust Sim2Real Policy Transfer in Robot Control - IEEE Xplore, https://ieeexplore.ieee.org/iel8/87/4389040/11270848.pdf</li>
<li>Reinforcement Learning for Bipedal Jumping: Integrating Actuator Limits and Coupled Tendon Dynamics - MDPI, https://www.mdpi.com/2227-7390/13/15/2466</li>
<li>Cycloidal Quasi-Direct Drive Actuator Designs with Learning-Based Torque Estimation for Legged Robotics - IEEE Xplore, https://ieeexplore.ieee.org/document/11127436/</li>
<li>raibo - KAIST NEWS CENTER, https://www.kaist.ac.kr/newsen/html/news/?skey=keyword&amp;sval=RAIBO</li>
<li>Actuator-Constrained Reinforcement Learning for High-Speed Quadrupedal Locomotion, https://arxiv.org/html/2312.17507v1</li>
<li>Actuators – Robotic Systems Lab | ETH Zurich, https://rsl.ethz.ch/robots-media/actuators.html</li>
<li>Series Elastic Actuators - Mechanical, Industrial, and Manufacturing Engineering, https://mime.engineering.oregonstate.edu/research/drl/_documents/hurst_2020.pdf</li>
<li>Robust Force Control of Series Elastic Actuators - MDPI, https://www.mdpi.com/2076-0825/3/3/182</li>
<li>Real-Time Model-Free Deep Reinforcement Learning for Force Control of a Series Elastic Actuator - ResearchGate, https://www.researchgate.net/publication/369946621_Real-Time_Model-Free_Deep_Reinforcement_Learning_for_Force_Control_of_a_Series_Elastic_Actuator</li>
<li>Real-Time Model-Free Deep Reinforcement Learning for Force Control of a Series Elastic Actuator - arXiv, https://arxiv.org/pdf/2304.04911</li>
<li>Comparative anatomy of quadruped robots and animals: a review - ResearchGate, https://www.researchgate.net/publication/361404568_Comparative_anatomy_of_quadruped_robots_and_animals_a_review</li>
<li>Multifunctional physical reservoir computing in soft tensegrity robots - AIP Publishing, https://pubs.aip.org/aip/cha/article-pdf/doi/10.1063/5.0273567/20626443/083111_1_5.0273567.pdf</li>
<li>TWISTED AND COILED POLYMER ACTUATORS: DESIGN, MECHANICS, AND BIOMIMETICS By Diego R. Higueras-Ruiz A Dissertation Submitted in P - OpenKnowledge@NAU, http://openknowledge.nau.edu/5637/1/Higueras-Ruiz_2021_twisted_coiled_polymer_actuators_design_mechanics_b.pdf</li>
<li>The effects of motor modularity on performance, learning and generalizability in upper-extremity reaching: a computational analysis - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC7328389/</li>
<li>Coupled exoskeleton assistance simplifies control and maintains metabolic benefits: A simulation study | PLOS One - Research journals, https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0261318</li>
<li>Deep Reinforcement Learning for Soft, Flexible Robots: Brief Review with Impending Challenges - MDPI, https://www.mdpi.com/2218-6581/8/1/4</li>
<li>Soft DAgger: Sample-Efficient Imitation Learning for Control of Soft Robots - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC10574889/</li>
<li>ICRA 2024: MIRMI scientists receive Best Paper Award, https://www.mirmi.tum.de/en/mirmi/news/research/article/icra-2024-mirmi-scientists-receive-best-paper-award/</li>
<li>A Novel Variable Stiffness Suspension System for Improved Stability and Control of Tactile Mobile Manipulators | DARKO, https://darko-project.eu/wp-content/uploads/papers/2024/A_Novel_Variable_Stiffness_Suspension_System_for_Improved_Stability_and_Control_of_Tactile_Mobile_Manipulators.pdf</li>
<li>Optimally Controlling the Timing of Energy Transfer in Elastic Joints: Experimental Validation of the Bi-Stiffness Actuation Concept | Request PDF - ResearchGate, https://www.researchgate.net/publication/374823334_Optimally_Controlling_the_Timing_of_Energy_Transfer_in_Elastic_Joints_Experimental_Validation_of_the_Bi-Stiffness_Actuation_Concept</li>
<li>Efficiency testing of hydraulic artificial muscles with variable recruitment using a linear dynamometer - Journal of Photonics for Energy - SPIE Digital Library, https://photonicsforenergy.spiedigitallibrary.org/conference-proceedings-of-spie/9429/942916/Efficiency-testing-of-hydraulic-artificial-muscles-with-variable-recruitment-using/10.1117/12.2084460.full</li>
<li>Characterization and Analysis of Extensile Fluidic Artificial Muscles - Semantic Scholar, https://pdfs.semanticscholar.org/4faa/e183d24829952e4b51fef376e8f6b768d641.pdf</li>
<li>Modeling of Actuation Force, Pressure and Contraction of Fluidic Muscles Based on Machine Learning - MDPI, https://www.mdpi.com/2227-7080/12/9/161</li>
<li>(a) Overview of a fluidic artificial muscle. Top: exploded view;… - ResearchGate, https://www.researchgate.net/figure/a-Overview-of-a-fluidic-artificial-muscle-Top-exploded-view-bottom-assembly-A_fig1_348908847</li>
<li>Recent Advances in Dielectric Elastomer Actuator-Based Soft Robots: Classification, Applications, and Future Perspectives - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC12651945/</li>
<li>Dielectric Elastomer Actuator for Soft Robotics Applications and Challenges - MDPI, https://www.mdpi.com/2076-3417/10/2/640</li>
<li>Soft Robotic Gripper Based on Multi-Layers of Dielectric Elastomer Actuators - Fuji Technology Press, https://www.fujipress.jp/jrm/rb/robot003300040968/</li>
<li>Dielectric Elastomer Actuator Driven Soft Robotic Structures With Bioinspired Skeletal and Muscular Reinforcement - Frontiers, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2020.510757/full</li>
<li>Cycloidal Quasi-Direct Drive Actuator Designs with Learning-based Torque Estimation for Legged Robotics - arXiv, https://arxiv.org/html/2410.16591v1</li>
<li>High-Performance Reinforcement Learning on Spot: Optimizing Simulation Parameters with Distributional Measures - RAI Institute, https://rai-inst.com/wp-content/uploads/2025/05/ICRA_2025__High_Performance_Reinforcement_Learning_on_Spot__Optimizing_Simulation_Parameters_with_Distributional_Measures-1.pdf</li>
<li>Bridging the Sim-to-Real Gap for Athletic Loco-Manipulation Nolan Fey - DSpace@MIT, https://dspace.mit.edu/bitstream/handle/1721.1/163694/fey-nolanfey-sm-eecs-2025-thesis.pdf?sequence=1&amp;isAllowed=y</li>
<li>Bridging the Sim-to-Real Gap for Athletic Loco-Manipulation - arXiv, https://arxiv.org/html/2502.10894v1</li>
<li>BRIDGING THE SIM-TO-REAL GAP FOR ATHLETIC … - OpenReview, https://openreview.net/pdf/18ee61b8e52abd9e4ccc7d482ef24d7aa8b52b0e.pdf</li>
<li>News Archives - MARCH, https://march.postech.ac.kr/news/</li>
<li>BaRiFlex: A Robotic Gripper with Versatility and Collision Robustness for Robot Learning, https://robin-lab.cs.utexas.edu/bariflex/static/pdfs/BaRiFlex.pdf</li>
<li>BaRiFlex: A Robotic Gripper with Versatility and Collision Robustness for Robot Learning, https://ieeexplore.ieee.org/document/10802024/</li>
<li>19th Electrorheological Fluids and Magnetorheological Suspensions - ERMR 2025 - Concordia University, https://ermr2025.encs.concordia.ca/ERMR2025ConferenceBook.pdf</li>
<li>An All-Soft Variable Impedance Actuator Enabled by Embedded Layer Jamming - shape lab - Stanford University, https://shape.stanford.edu/research/VariableImpedanceActuator/Do_TMECH_2022.pdf</li>
<li>Legged Robots: Actuators Comparation | Medium, https://mab-robotics.medium.com/how-to-choose-the-proper-actuator-for-a-legged-robot-664e341ea308</li>
<li>Impact of Static Friction on Sim2Real in Robotic Reinforcement Learning - arXiv, https://arxiv.org/pdf/2503.01255</li>
<li>Impact of Static Friction on Sim2Real in Robotic Reinforcement Learning - arXiv, https://arxiv.org/html/2503.01255</li>
<li>MorphVAE: Advancing Morphological Design of Voxel-Based Soft Robots with Variational Autoencoders, https://ojs.aaai.org/index.php/AAAI/article/view/28904/29720</li>
<li>Design of a Quasi-Direct Drive Actuator with Embedded Pulley for a Compact, Lightweight, and High-Bandwidth Exosuit - MDPI, https://www.mdpi.com/2076-0825/12/1/21</li>
<li>Direct-drive Hands: Making Robot Hands Transparent and Reactive to Contacts, https://www.ri.cmu.edu/app/uploads/2022/05/ankitb_thesis_final.pdf</li>
<li>Variable Stiffness Actuators: Review on Design and Components - ResearchGate, https://www.researchgate.net/publication/284218270_Variable_Stiffness_Actuators_Review_on_Design_and_Components</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>