<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:7.5.2 씬(Scene) 레벨의 파지 생성: 복잡하고 정돈되지 않은 환경(Cluttered Scene)에서의 충돌 회피</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>7.5.2 씬(Scene) 레벨의 파지 생성: 복잡하고 정돈되지 않은 환경(Cluttered Scene)에서의 충돌 회피</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 7. 행동을 위한 지각: 어포던스와 포즈 (Perception for Action: Affordance & Pose)</a> / <a href="index.html">7.5 파지 검출과 생성 (Grasp Detection & Generation)</a> / <span>7.5.2 씬(Scene) 레벨의 파지 생성: 복잡하고 정돈되지 않은 환경(Cluttered Scene)에서의 충돌 회피</span></nav>
                </div>
            </header>
            <article>
                <h1>7.5.2 씬(Scene) 레벨의 파지 생성: 복잡하고 정돈되지 않은 환경(Cluttered Scene)에서의 충돌 회피</h1>
<h2>1.  서론: 비정형 환경에서의 파지 계획과 충돌의 본질</h2>
<p>로봇 조작(Robotic Manipulation)의 역사에서 ’빈 픽킹(Bin Picking)’이나 ’정돈되지 않은 환경(Cluttered Scene)’에서의 파지 작업은 항상 난제로 분류되어 왔다. 정형화된 제조 라인과 달리, 비정형 환경은 물체들이 무작위로 쌓여 있거나(Piled), 서로 빽빽하게 맞물려 있는(Packed) 상태를 포함한다. 이러한 환경에서 로봇이 수행해야 할 ’파지(Grasping)’는 단순히 타겟 물체의 6자유도(6-DoF) 포즈를 계산하는 기하학적 문제를 넘어선다. 이는 로봇 팔(Manipulator)과 그리퍼(Gripper)라는 물리적 실체가 복잡한 장애물들 사이를 비집고 들어가, 주변 환경을 훼손하거나 붕괴시키지 않으면서 목표물만을 정확하게 타격해야 하는 고도의 ‘동적 상호작용 계획(Dynamic Interaction Planning)’ 문제로 귀결된다.</p>
<p>전통적인 분석적 접근법(Analytical Approaches)은 이 문제를 해결하기 위해 씬(Scene)을 구성하는 모든 물체의 정확한 3D CAD 모델과 포즈가 사전에 주어졌다고 가정하였다. 이 가정 하에서 충돌 회피(Collision Avoidance)는 RRT(Rapidly-exploring Random Tree)나 PRM(Probabilistic Roadmaps)과 같은 샘플링 기반 경로 계획 알고리즘을 통해 명시적으로 수행되었다. 그러나 이러한 접근은 두 가지 치명적인 한계를 갖는다. 첫째, 실세계의 비정형 환경에서는 미지의 물체(Unknown Objects)가 다수 존재하며, 센서 노이즈와 가려짐(Occlusion)으로 인해 완벽한 상태 추정(State Estimation)이 불가능하다. 둘째, 물체가 빽빽하게 밀집된 상황에서는 명시적인 충돌 검사(Collision Checking)에 소요되는 연산 비용이 기하급수적으로 증가하여 실시간 제어를 어렵게 만든다.</p>
<p>따라서 현대의 씬 레벨 파지 생성 연구는 딥러닝을 활용하여 이러한 한계를 극복하는 방향으로 진화하고 있다. 핵심은 ’충돌 회피’를 별도의 후처리(Post-processing) 단계가 아닌, 파지 생성 네트워크의 추론 과정에 내재화(Implicitly Encode)하거나, 미분 가능한 비용 함수(Differentiable Cost Function)로 정의하여 파지 포즈와 접근 경로를 동시에 최적화하는 것이다. 최근의 연구들은 전체 공간을 복셀(Voxel)로 해석하는 볼륨 기반 접근법, 포인트 클라우드 상에서 직접 파지 가능성을 추론하는 접촉 기반 접근법, 그리고 기하학적 위상(Topology)과 거리 장(Distance Fields)을 학습하는 암시적 신경망 표현(Implicit Neural Representations) 등으로 분화하며 발전하고 있다. 본 장에서는 이러한 최신 기술적 방법론들을 심층적으로 분석하고, 각 접근법이 복잡한 클러터 환경에서의 충돌 문제를 어떻게 해결하고 있는지 고찰한다.</p>
<h2>2.  볼륨 기반 파지 네트워크(Volumetric Grasping Network)와 공간적 추론</h2>
<p>복잡한 환경에서 충돌을 회피하는 가장 직관적이면서도 강력한 방법은 로봇이 작업할 3D 공간 전체의 점유(Occupancy) 상태와 기하학적 구조를 통째로 이해하는 것이다. 이 접근법은 개별 물체를 분할(Segmentation)하거나 식별하는 난해한 과정을 우회하고, 씬 전체를 하나의 3D 볼륨으로 간주하여 ’파지 가능한 공간(Affordance Map)’을 직접 탐색한다.</p>
<h3>2.1 TSDF(Truncated Signed Distance Function) 기반의 씬 표현과 VGN</h3>
<p>**Volumetric Grasping Network (VGN)**은 이러한 철학을 대표하는 연구로, 씬의 기하학적 정보를 <strong>절단된 부호 거리 함수(TSDF, Truncated Signed Distance Function)</strong> 형태로 입력받는다. TSDF는 공간을 균일한 격자(Grid)로 나누고, 각 복셀(Voxel)에 대해 가장 가까운 물체 표면까지의 거리를 부호와 함께 저장한다. 표면 앞쪽의 빈 공간은 양수(+), 물체 내부는 음수(-) 값을 가지며, 표면 근처의 특정 거리(Truncation distance) 내에서만 값을 유지한다.</p>
<p>이 TSDF 표현 방식이 씬 레벨 파지, 특히 충돌 회피에 있어 갖는 기술적 우위는 명확하다:</p>
<ol>
<li><strong>공간의 명시적 구분:</strong> TSDF는 물체가 존재하는 영역(Occupied)과 비어 있는 영역(Free)을 수학적으로 명확히 구분한다. 이는 신경망이 “어디가 비어 있어서 그리퍼가 진입할 수 있는가?“를 학습하는 데 있어 가장 직접적인 단서를 제공한다.</li>
<li><strong>데이터 융합과 노이즈 강인성:</strong> 단일 시점의 깊이(Depth) 이미지는 센서 노이즈와 가려짐(Occlusion)에 취약하다. VGN은 TSDF 통합(Integration) 과정을 통해 여러 시점의 데이터를 하나의 볼륨으로 융합함으로써, 센서 노이즈를 평활화(Smoothing)하고 가려진 영역의 정보를 일부 보완한다. 이는 클러터 환경에서 물체의 형상을 더 온전하게 파악하게 해 준다.</li>
</ol>
<h3>2.2 VGN의 충돌 회피 메커니즘: 내재적 학습(Implicit Learning)</h3>
<p>VGN은 3D 합성곱 신경망(3D CNN) 아키텍처를 채택하고 있으며, 입력된 TSDF 볼륨(<span class="math math-inline">40^3</span> 크기 등)으로부터 동일한 해상도의 출력 볼륨을 생성한다. 출력 볼륨의 각 복셀은 해당 위치가 파지 중심점(Grasp Center)이 될 때의 <strong>파지 품질(Grasp Quality, <span class="math math-inline">Q</span>)</strong>, 그리퍼의 <strong>회전(Orientation, <span class="math math-inline">R</span>)</strong>, 그리고 **폭(Width, <span class="math math-inline">W</span>)**을 예측한다.</p>
<p>여기서 VGN의 독창적인 충돌 회피 전략이 드러난다. VGN은 명시적인 충돌 감지 알고리즘(예: GJK 알고리즘)을 실행하지 않는다. 대신, 대규모 물리 시뮬레이션(Physics Simulation)을 통해 생성된 데이터셋을 학습한다. 이 데이터셋에서 그리퍼가 물체나 바닥과 충돌하는 모든 파지 시도는 ’실패(Failure)’로 레이블링되어 품질 점수 <span class="math math-inline">Q=0</span>을 부여받는다. 반대로, 충돌 없이 접근하여 물체를 들어 올리는 데 성공한 경우에만 높은 품질 점수(<span class="math math-inline">Q=1</span>)를 얻는다.</p>
<p>결과적으로 VGN은 **“충돌이 발생하는 위치와 자세는 낮은 품질 점수를 갖는다”**는 규칙을 데이터로부터 귀납적으로 학습한다. 이는 충돌 검사라는 기하학적 연산을 신경망의 추론 과정에 통합(Amortized)시킨 것으로 해석할 수 있다. 실험 결과, VGN은 명시적 충돌 검사 없이도 실제 로봇을 이용한 클러터 제거(Clutter Removal) 실험에서 92%의 물체 제거율(Clearance Rate)을 달성하였다. 더 놀라운 점은 이러한 계획 과정이 단 10ms 내외에 완료된다는 것이다. 이러한 초고속 추론 능력은 로봇이 동적인 환경 변화나 외란에 즉각적으로 반응하는 폐루프(Closed-loop) 제어를 가능하게 하여, 예상치 못한 충돌 상황에서도 신속하게 회복(Recovery)할 수 있는 유연성을 제공한다.</p>
<h3>2.3 GIGA(Grasp detection via Implicit Geometry and Affordance): 연속적 표현으로의 확장</h3>
<p>VGN은 혁신적이었으나, 복셀 해상도(Voxel Resolution)라는 구조적 한계에 봉착했다. <span class="math math-inline">30^3</span> 또는 <span class="math math-inline">40^3</span> 그리드는 얇은 물체나 매우 좁은 틈새를 표현하기에는 너무 거칠다(Coarse). 이를 해결하기 위해 등장한 **GIGA(Grasp detection via Implicit Geometry and Affordance)**는 씬 표현을 이산적인(Discrete) 복셀에서 연속적인(Continuous) 암시적 함수(Implicit Function)로 확장하였다.</p>
<p>GIGA는 딥러닝 기반의 암시적 표현(Deep Implicit Representation)을 사용하여 3D 공간상의 임의의 연속적인 좌표(Continuous Coordinate) <span class="math math-inline">(x, y, z)</span>에 대해 TSDF 값(기하학적 형상)과 파지 품질(Affordance)을 동시에 질의(Query)하고 예측한다.</p>
<ul>
<li><strong>고해상도 충돌 경계 탐색:</strong> GIGA는 고정된 그리드에 얽매이지 않기 때문에, 물체와 물체 사이의 미세한 경계면이나 그리퍼가 가까스로 통과할 수 있는 좁은 공간에 대해서도 무한한 해상도로 충돌 여부와 파지 가능성을 평가할 수 있다.</li>
<li><strong>멀티 태스크 학습의 이점:</strong> GIGA는 씬의 형상 복원(Reconstruction)과 파지 감지(Grasp Detection)를 동시에 학습한다. 연구에 따르면, 정확한 형상 이해는 충돌 없는 파지를 생성하는 데 필수적인 선행 조건이며, 두 작업의 특징(Feature)을 공유함으로써 클러터 환경에서의 파지 성능이 상호 보완적으로 향상된다.</li>
</ul>
<table><thead><tr><th><strong>특성</strong></th><th><strong>VGN (Volumetric Grasping Network)</strong></th><th><strong>GIGA (Implicit Geometry &amp; Affordance)</strong></th></tr></thead><tbody>
<tr><td><strong>공간 표현</strong></td><td>이산적 복셀 그리드 (Discrete Voxel Grid)</td><td>연속적 암시적 함수 (Continuous Implicit Function)</td></tr>
<tr><td><strong>입력 데이터</strong></td><td>TSDF Volume</td><td>TSDF + Point Coordinates</td></tr>
<tr><td><strong>해상도</strong></td><td>고정 해상도 (제한적)</td><td>무한 해상도 (이론상)</td></tr>
<tr><td><strong>충돌 처리</strong></td><td>학습된 품질 점수 (Implicit)</td><td>학습된 품질 점수 + 형상 복원</td></tr>
<tr><td><strong>추론 속도</strong></td><td>매우 빠름 (~10ms)</td><td>쿼리 수에 비례 (상대적으로 느림)</td></tr>
<tr><td><strong>주요 강점</strong></td><td>실시간 폐루프 제어 가능</td><td>정밀한 파지 및 형상 이해</td></tr>
</tbody></table>
<h2>3.  포인트 클라우드 기반 접근법: 표면 위상과 접촉점 추론</h2>
<p>볼륨 기반 접근법이 ’빈 공간’을 포함한 전체 공간을 해석하려는 시도라면, 포인트 클라우드 기반 접근법은 관측된 물체의 ‘표면(Surface)’ 데이터 자체에 집중한다. 이 방식은 불필요한 빈 공간에 대한 연산을 배제하여 효율성을 높이고, 6자유도(6-DoF) 파지 포즈를 물체 표면의 구체적인 점(Point)과 연관 지어 생성함으로써 직관적인 충돌 회피를 유도한다.</p>
<h3>3.1 Contact-GraspNet: 씬 포인트의 잠재적 접촉점화</h3>
<p><strong>Contact-GraspNet</strong>은 입력된 3D 포인트 클라우드의 각 점을 잠재적인 파지 접촉점(Contact Point)으로 간주하고, 이를 중심으로 파지 기구학(Grasp Kinematics)을 전개한다. 이 접근법은 복잡한 다단계 파지 파이프라인(후보 생성 -&gt; 필터링 -&gt; 점수 매기기)을 단일 단계(End-to-End)로 축소하여, 각 포인트에 대해 6-DoF 파지 포즈와 파지 폭을 직접 예측한다.</p>
<ul>
<li><strong>차원 축소(Dimensionality Reduction)와 루팅(Rooting):</strong> 전체 6-DoF 파지 포즈를 예측하는 것은 탐색 공간이 너무 넓어 학습이 어렵다. Contact-GraspNet은 파지 포즈를 관측된 포인트에 ’루팅(Rooting)’시킴으로써 문제를 4-DoF(접촉점을 중심으로 한 3-DoF 회전 + 1-DoF 파지 폭) 예측 문제로 단순화했다. 이는 충돌 없는 파지를 찾기 위한 탐색 효율을 극대화한다.</li>
<li><strong>충돌 없는 분포의 학습:</strong> 이 네트워크는 1,700만 개 이상의 대규모 시뮬레이션 파지 데이터셋(ACRONYM 등)을 통해 학습된다. 학습 과정에서 물리 시뮬레이터를 통해 검증된 ‘충돌 없고 안정적인’ 파지만이 긍정 샘플(Positive Sample)로 사용된다. 따라서 네트워크는 주어진 씬의 국소적인 기하학(Local Geometry)을 분석하여, 물리적으로 도달 가능하고 주변 장애물과 간섭하지 않는 파지 분포(Distribution)를 생성하도록 훈련된다.</li>
<li><strong>로컬 영역 크롭(Local Region Crop) 전략:</strong> 추론 시, Contact-GraspNet은 전체 씬을 한 번에 처리하는 대신 관심 영역을 중심으로 로컬 포인트 클라우드를 크롭하여 처리할 수 있다. 이는 인스턴스 분할(Instance Segmentation)과 결합될 때 더욱 강력해지는데, 타겟 물체 주변의 장애물 정보를 고해상도로 유지하면서 미세한 충돌 가능성을 배제하는 필터링(Filter Grasp Contacts) 과정을 수행할 수 있기 때문이다.</li>
</ul>
<p>실험 결과, Contact-GraspNet은 구조화된 클러터(Structured Clutter) 환경에서 미지의 물체에 대해 90% 이상의 파지 성공률을 달성했으며, 기존의 최신 기술(SOTA) 대비 실패율을 절반으로 줄이는 성과를 보였다.</p>
<h3>3.2 Graspness: 기하학적 단서를 통한 충돌 위험의 조기 차단</h3>
<p>복잡한 환경에서 모든 포인트가 파지 후보가 될 수는 없다. 특히 물체끼리 겹쳐 있어 그리퍼가 접근하기 어려운 영역, 즉 충돌 위험이 매우 높은 영역(Occluded or Tight Regions)을 미리 식별하고 배제할 수 있다면 전체적인 계산 효율과 파지 성공률을 높일 수 있다. 이러한 필요성에서 제안된 개념이 **‘Graspness’**이다.</p>
<p>Graspness는 특정 표면 영역이 ’파지 가능한지(Graspable)’를 나타내는 저수준의 기하학적 척도(Low-level Geometric Cue)이다.</p>
<ul>
<li><strong>충돌 검색의 근사화(Approximation):</strong> Graspness 모델은 포인트 클라우드 상에서 “이 지점에 그리퍼가 접근했을 때 주변과 충돌하지 않을 확률이 얼마나 되는가?“를 점수화한다. 이는 물체의 오목한 부분이나 다른 물체에 의해 꽉 끼인 부분(Packed areas)에 낮은 점수를 부여한다.</li>
<li><strong>단계적 필터링(Cascaded Filtering):</strong> Graspness는 파지 생성 파이프라인의 초기 단계에서 작동한다. 파지 생성 네트워크(GSNet 등)가 본격적인 포즈 회귀(Regression)를 수행하기 전에, Graspness 점수가 낮은 영역을 미리 ’마스킹(Masking)’하여 제외한다. 이는 네트워크가 충돌 위험이 높은 영역에서 억지로 파지를 생성하려다 실패하는 경우를 방지하고, 계산 자원을 파지 성공 확률이 높은 영역에 집중하게 만든다.</li>
<li><strong>NGS(Normalized Grasp Space):</strong> 최근 연구는 Graspness 개념을 확장하여 **NGS(Normalized Grasp Space)**를 제안했다. 이는 씬의 복잡한 기하학적 정보를 정규화된 공간으로 변환하여, 물체의 방향이나 위치에 상관없이 파지 관련 영역(Grasp-relevant Region)을 일관되게 정의하고 충돌 가능성을 평가한다. 이를 통해 복잡한 클러터 환경에서도 20% 이상의 성능 향상과 50 FPS의 실시간 추론 속도를 달성하였다.</li>
</ul>
<h2>4.  암시적 신경망 표현과 궤적 최적화 (Neural Fields &amp; Trajectory Optimization)</h2>
<p>앞선 방법들이 “어떤 파지 포즈가 좋은가?“를 예측하는 데 집중했다면, 최근의 파격적인 연구 흐름은 파지 문제를 “어떻게 도달할 것인가?“를 포함한 <strong>연속적인 최적화(Continuous Optimization)</strong> 문제로 재정의하고 있다. 이 접근법은 파지 포즈의 선정과 로봇 팔의 이동 경로(Trajectory) 생성을 분리하지 않고, 충돌 회피라는 제약 조건을 하나의 통합된 비용 함수(Cost Function)로 다룬다.</p>
<h3>4.1 Neural Grasp Distance Fields (NGDF): 파지 다양체 거리의 미분 가능성</h3>
<p>**Neural Grasp Distance Fields (NGDF)**는 파지 가능한 모든 유효한 6-DoF 포즈들의 집합을 연속적인 **다양체(Manifold)**로 정의하고, 임의의 쿼리 포즈(Query Pose)에서 이 다양체까지의 **‘거리(Distance)’**를 예측하는 신경망이다.</p>
<p>기존 방식이 파지 후보군을 이산적으로 샘플링(Discrete Sampling)하고 그중 하나를 선택하는 방식이었다면, NGDF는 현재의 그리퍼 위치에서 “가장 가까운 유효한 파지 포즈까지 얼마나, 어느 방향으로 이동해야 하는가?“에 대한 미분 가능한 가이드를 제공한다. 이는 충돌 회피를 위한 경로 계획에 혁명적인 변화를 가져왔다.</p>
<ul>
<li>
<p><strong>공동 최적화(Joint Optimization) 프레임워크:</strong> NGDF를 활용하면 파지 계획과 모션 계획을 다음과 같은 단일 최적화 문제로 통합할 수 있다.</p>
<p><span class="math math-display">\min_{\xi} J(\xi) = w_{grasp} \cdot \phi_{NGDF}(\xi_{T}) + w_{smooth} \cdot \mathcal{L}_{smooth}(\xi) + w_{obs} \cdot \mathcal{L}_{obs}(\xi)</span></p>
<p>여기서 <span class="math math-inline">\xi</span>는 로봇의 궤적, <span class="math math-inline">\xi_{T}</span>는 궤적의 끝점(파지 포즈), <span class="math math-inline">\phi_{NGDF}</span>는 NGDF가 예측한 파지 다양체까지의 거리 비용, <span class="math math-inline">\mathcal{L}_{obs}</span>는 장애물과의 충돌 비용(주로 SDF 기반)이다.</p>
</li>
<li>
<p><strong>동적 목표 수정:</strong> 이 최적화 과정에서 경사 하강법(Gradient Descent)을 수행하면, 로봇은 장애물과의 충돌(<span class="math math-inline">\mathcal{L}_{obs}</span>)을 피하기 위해 궤적을 수정할 뿐만 아니라, 최종 파지 목표(<span class="math math-inline">\xi_{T}</span>) 자체를 파지 다양체 위에서 유연하게 미끄러뜨리며(Slide) 변경한다. 즉, 장애물 때문에 특정 부위를 잡기 힘들다면, 네트워크는 자연스럽게 장애물이 없는 다른 파지 부위로 목표를 유도한다. 실험 결과, 이 방식은 파지 포즈를 고정해두고 경로를 찾는 기존 방식(Decoupled Planning) 대비 실행 성공률을 63%나 향상시켰다.</p>
</li>
</ul>
<h3>충돌 확률장(Collision Probability Fields)과 NeRF의 활용</h3>
<p>암시적 표현의 또 다른 축은 **NeRF(Neural Radiance Fields)**를 활용한 충돌 확률의 계산이다. 기존의 SDF나 복셀 맵은 센서 데이터가 불완전할 경우 결정론적(Deterministic) 오류를 범하기 쉽다. 반면, NeRF 기반 접근법은 씬의 불확실성을 확률적으로 모델링할 수 있다.</p>
<ul>
<li><strong>GraspNeRF:</strong> 소수의 RGB 이미지만으로 씬의 NeRF 표현을 구축하고, 이를 기반으로 투명하거나 반사되는 물체(Transparent/Specular Objects)가 포함된 까다로운 클러터 환경에서도 강건한 파지를 생성한다. 일반적인 깊이 센서가 실패하는 영역에서도 NeRF는 밀도(Density) 정보를 통해 물체의 존재를 추론해낸다.</li>
<li><strong>확률적 충돌 검사:</strong> 최근 연구는 NeRF의 밀도 필드를 포아송 점 과정(Poisson Point Process)으로 변환하여, 로봇이 특정 궤적을 지날 때의 **충돌 확률(Collision Probability)**을 엄밀하게 계산한다. 이를 **기회 제약 경로 계획(Chance-Constrained Trajectory Optimization)**에 적용하면, 사용자가 설정한 안전 확률(예: 99% 안전 보장)을 만족하는 파지 경로를 생성할 수 있다. 이는 단순한 기하학적 거리(Distance)를 넘어 통계적인 안전성을 보장한다는 점에서 진보된 개념이다.</li>
</ul>
<h2>7.5.2.5 고급 기하학적 위상과 안전성: CADGrasp와 Sparse IBS</h2>
<p>복잡한 환경에서의 파지 성공은 단순히 충돌을 피하는 것(Collision Avoidance)을 넘어, 물체와의 안정적인 접촉(Contact)을 형성하는 것(Contact Generation)에 달려 있다. 특히 다지(Multi-fingered) 핸드를 사용할 때는 손가락들과 물체, 그리고 주변 환경 간의 기하학적 위상(Topology) 관계를 정교하게 모델링해야 한다.</p>
<h3>Sparse IBS (Interaction Bisector Surface)</h3>
<p><strong>CADGrasp</strong> 연구팀은 복잡한 씬에서 다지 핸드의 파지 최적화를 위해 **Sparse IBS(Interaction Bisector Surface)**라는 혁신적인 중간 표현(Intermediate Representation)을 제안하였다. IBS는 두 기하학적 객체(여기서는 로봇 손과 환경) 사이의 거리가 동일한 점들의 집합, 즉 일반화된 보로노이 다이어그램(Voronoi Diagram)의 경계면이다.</p>
<p>이 Sparse IBS 표현이 충돌 회피에 강력한 이유는 다음과 같다:</p>
<ol>
<li><strong>충돌과 접촉의 이중적 가이드:</strong> IBS는 로봇 손과 씬 사이의 ‘완충 막(Buffer Membrane)’ 역할을 한다. 파지를 위해서는 손가락 끝(Fingertips)이 IBS를 뚫고 물체 표면에 닿아야 하지만(접촉 유도), 손바닥이나 손가락 마디는 IBS를 넘어서는 안 된다(충돌 방지). 이 기하학적 제약 조건을 에너지 함수로 정의하면 매우 정교한 최적화가 가능하다.</li>
<li><strong>씬 분리(Scene-Decoupled) 효율성:</strong> 전체 씬의 형상을 완벽하게 복원하는 것은 불필요하고 비용이 많이 든다. Sparse IBS는 로봇 손과 상호작용하는 국소적인 영역의 기하학적 관계만을 인코딩하므로, 씬의 복잡도와 무관하게 효율적인 연산이 가능하다.</li>
<li><strong>확산 모델을 통한 생성:</strong> CADGrasp는 고차원적인 Sparse IBS를 예측하기 위해 **점유 확산 모델(Occupancy-Diffusion Model)**을 사용한다. 이 모델은 입력 포인트 클라우드로부터 복셀 수준의 조건부 가이드를 받아, 충돌 없는 안전한 접근 경로와 최적의 접촉면을 형성하는 IBS를 생성해낸다. 시뮬레이션 및 실제 로봇 실험(Flexiv Rizon-4 + Leap Hand)에서 CADGrasp는 복잡한 클러터 환경에서도 93.8%라는 압도적인 파지 성공률을 기록하였다.</li>
</ol>
<h3>벡터 뉴런(Vector Neurons)과 회전 등변성(Equivariance)</h3>
<p>클러터 환경에서는 물체들이 제각기 다른 방향으로 무작위로 놓여 있다. 기존의 CNN이나 PointNet 기반 모델들은 물체가 회전하면 그 특징(Feature) 값도 변해버리기 때문에, 파지 네트워크가 “이 각도로 접근하면 충돌한다“는 사실을 학습하기 위해 모든 회전 케이스를 데이터로 경험해야 했다(Data Augmentation).</p>
<p>**VN-OccNet (Vector Neuron Occupancy Network)**과 같은 연구는 **회전 등변성(SE(3)-Equivariance)**을 보장하는 신경망 구조를 도입하여 이 문제를 근본적으로 해결한다.</p>
<ul>
<li><strong>벡터 특징의 보존:</strong> 벡터 뉴런은 스칼라(Scalar) 활성화 함수 대신 3D 벡터 연산을 사용하여, 입력 포인트 클라우드가 회전하면 네트워크 내부의 특징 벡터들도 동일하게 회전하도록 강제한다.</li>
<li><strong>충돌 회피 전략의 일반화:</strong> 이를 통해 네트워크는 특정 방향에서의 충돌 회피 전략을 한 번만 학습하면, 물체가 어떤 임의의 방향으로 놓여 있더라도 좌표계 변환 없이 동일한 상대적 기하학적 관계를 유지하며 안전한 파지를 생성할 수 있다. 이는 데이터 증강 없이도 학습 효율을 극대화하고, 미지의 자세(Pose)를 가진 물체에 대해서도 강건한(Robust) 충돌 회피 성능을 보장한다.</li>
</ul>
<h2>7.5.2.6 형태 완성(Shape Completion)과 보이지 않는 영역의 위험 관리</h2>
<p>클러터 환경의 가장 큰 적은 ’가려짐(Occlusion)’이다. 센서 시야에서 가려진 물체의 뒷면이나 깊은 곳에 장애물이 있다면, 현재의 관측 정보만으로는 충돌 없는 파지를 보장할 수 없다. 이를 극복하기 위해 <strong>형태 완성(Shape Completion)</strong> 기술이 파지 생성 파이프라인의 핵심 요소로 통합되고 있다.</p>
<h3>PCF-Grasp와 SIRGN: 상상을 통한 안전 확보</h3>
<p><strong>PCF-Grasp (Point Completion to Feature Grasp)</strong> 프레임워크는 불완전한 포인트 클라우드를 입력받아, 먼저 전체 형상을 추론 및 복원(Completion)한 후 이를 바탕으로 파지를 계획한다.</p>
<ul>
<li><strong>형상 특징의 전이(Feature Transfer):</strong> 단순히 시각적으로만 형상을 채우는 것이 아니다. 복원된 형상의 잠재 특징(Latent Feature)을 파지 생성 네트워크에 직접 주입하여, “보이지 않는 뒷면에 무엇이 있을지“에 대한 기하학적 추론을 가능하게 한다.</li>
<li><strong>SIRGN (Semantic Instance Reconstruction Grasp Network):</strong> 이 연구는 씬 내의 인접한 물체들을 개별 인스턴스로 분리하고 각각을 복원함으로써, 물체 사이의 좁은 틈새에 그리퍼를 넣을 때 옆 물체와 충돌할 가능성을 더욱 정밀하게 계산한다.</li>
<li><strong>실제 효과:</strong> 이러한 ‘상상(Imagination)’ 기반 접근법은 로봇이 “눈에 보이는 것“만 믿고 움직이다 발생하는 충돌 사고를 획기적으로 줄여준다. 실험 결과, 형태 완성 기능을 통합한 방법론은 그렇지 않은 경우(베이스라인)보다 리얼 월드 실험에서 17.8% 더 높은 파지 성공률을 기록하며 그 실효성을 입증하였다.</li>
</ul>
<h2>7.5.2.7 비교 분석 및 결론</h2>
<p>지금까지 살펴본 복잡한 환경에서의 씬 레벨 파지 생성 및 충돌 회피 기술들은 각기 다른 철학과 장단점을 가지고 있다. 다음 표는 주요 접근법들의 특징을 비교 요약한 것이다.</p>
<table><thead><tr><th><strong>접근법 (Approach)</strong></th><th><strong>대표 모델 (Key Models)</strong></th><th><strong>충돌 회피 메커니즘 (Mechanism)</strong></th><th><strong>장점 (Pros)</strong></th><th><strong>단점 (Cons)</strong></th></tr></thead><tbody>
<tr><td><strong>Volumetric</strong></td><td>VGN, GIGA</td><td>TSDF 기반 점유 학습, 품질 점수 페널티</td><td>전체 공간 이해, 초고속 추론(10ms)</td><td>해상도 제한(VGN), 메모리 소모</td></tr>
<tr><td><strong>Point-based</strong></td><td>Contact-GraspNet</td><td>포인트별 파지 확률 학습, 4-DoF 루팅</td><td>높은 자유도, 빈 공간 연산 배제 효율성</td><td>가려진 영역 정보 부재, 노이즈 민감</td></tr>
<tr><td><strong>Neural Fields</strong></td><td>NGDF</td><td>파지 다양체 거리(Distance) 미분 최적화</td><td>경로-파지 동시 최적화, 연속적 해상도</td><td>최적화 시간 소요, 초기값 의존성</td></tr>
<tr><td><strong>Geometric</strong></td><td>CADGrasp (IBS)</td><td>상호작용 경계면(IBS) 명시적 모델링</td><td>정밀한 접촉/충돌 제어, 높은 성공률</td><td>복잡한 2단계 추론 과정, 연산량</td></tr>
<tr><td><strong>Completion</strong></td><td>PCF-Grasp</td><td>형태 복원 후 특징 전이</td><td>가려짐(Occlusion) 극복, 높은 안전성</td><td>느린 처리 속도, 환각(Hallucination) 위험</td></tr>
</tbody></table>
<p>결론적으로, 7.5.2절의 분석은 로봇 파지 기술이 ’정적인 분석’에서 ’동적인 학습’으로, ’이산적인 선택’에서 ’연속적인 최적화’로 진화하고 있음을 보여준다.</p>
<ol>
<li><strong>명시적 검사에서 암시적 추론으로:</strong> VGN과 Contact-GraspNet 등은 충돌 검사를 별도의 기하학적 연산이 아닌 신경망의 ’직관(Intuition)’으로 내재화하여 실시간성을 확보했다.</li>
<li><strong>기하학적 이해의 심화:</strong> Vector Neurons를 통한 회전 불변성 확보, Sparse IBS를 통한 미세 위상 제어, NeRF를 통한 확률적 밀도 추론 등은 로봇이 공간을 이해하는 깊이가 단순한 좌표 인식을 넘어 물리적 상호작용의 본질을 파악하는 단계로 나아가고 있음을 시사한다.</li>
<li><strong>통합적 최적화:</strong> NGDF와 같은 연구는 파지와 경로 계획의 경계를 허물며, 충돌 회피를 포함한 모든 제약 조건을 하나의 수학적 프레임워크 안에서 우아하게 해결하려는 시도이다.</li>
</ol>
<p>향후 연구는 이러한 기술들을 융합하여 더욱 동적인 환경(예: 움직이는 컨베이어 벨트 위의 클러터)에 대응하거나, 시각 정보뿐만 아니라 <strong>촉각(Tactile)</strong> 정보를 실시간으로 피드백 받아 충돌 직전의 미세한 힘 조절까지 수행하는 방향으로 발전할 것으로 전망된다. 또한, 3D Gaussian Splatting과 같은 차세대 렌더링 기술이 접목되어 실시간성과 정밀도의 한계를 다시 한번 돌파할 가능성이 높다.</p>
<h4><strong>참고 자료</strong></h4>
<ol>
<li>Score-Based Generative Models as Trajectory Priors for Motion …, 2월 1, 2026에 액세스, https://www.ias.informatik.tu-darmstadt.de/uploads/Team/JoaoCarvalho/thesi_mark_SBMMotionPlanning.pdf</li>
<li>Volumetric Grasping Network: Real-time 6 DOF Grasp Detection in …, 2월 1, 2026에 액세스, https://www.research-collection.ethz.ch/server/api/core/bitstreams/8af7843d-3b9e-426d-9589-9c46d58f9d30/content</li>
<li>Neural Implicit Swept Volume Models for Fast Collision Detection, 2월 1, 2026에 액세스, https://arxiv.org/html/2402.15281v3</li>
<li>Benchmarking Target-driven Object Grasping under Occlusions - arXiv, 2월 1, 2026에 액세스, https://arxiv.org/html/2407.06168v1</li>
<li>Contact-GraspNet: Efficient 6-DoF Grasp Generation in Cluttered …, 2월 1, 2026에 액세스, https://research.nvidia.com/publication/2021-03_contact-graspnet-efficient-6-dof-grasp-generation-cluttered-scenes</li>
<li>NVlabs/contact_graspnet: Efficient 6-DoF Grasp Generation … - GitHub, 2월 1, 2026에 액세스, https://github.com/NVlabs/contact_graspnet</li>
<li>Neural Grasp Distance Fields for Robot Manipulation, 2월 1, 2026에 액세스, https://par.nsf.gov/servlets/purl/10433352</li>
<li>Neural Grasp Distance Fields for Robot Manipulation - arXiv, 2월 1, 2026에 액세스, https://arxiv.org/html/2211.02647v3</li>
<li>ethz-asl/vgn: Real-time 6 DOF grasp detection in clutter. - GitHub, 2월 1, 2026에 액세스, https://github.com/ethz-asl/vgn</li>
<li>Real-time 6 DOF Grasp Detection in Clutter, 2월 1, 2026에 액세스, https://proceedings.mlr.press/v155/breyer21a/breyer21a.pdf</li>
<li>A Multi-Level Similarity Approach for Single-View Object Grasping, 2월 1, 2026에 액세스, https://arxiv.org/html/2507.11938v1</li>
<li>Contact-graspnet: Efficient 6-dof grasp generation in cluttered scenes, 2월 1, 2026에 액세스, https://elib.dlr.de/145798/1/Contact-GraspNet.pdf</li>
<li>Graspness Discovery in Clutters for Fast and Accurate Grasp Detection, 2월 1, 2026에 액세스, https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Graspness_Discovery_in_Clutters_for_Fast_and_Accurate_Grasp_Detection_ICCV_2021_paper.pdf</li>
<li>Active Perception for Grasp Detection via Neural Graspness Field, 2월 1, 2026에 액세스, https://proceedings.neurips.cc/paper_files/paper/2024/file/4364fef031fdf7bfd9d1c9c56b287084-Paper-Conference.pdf</li>
<li>Region-aware Grasp Framework with Normalized Grasp Space for …, 2월 1, 2026에 액세스, https://arxiv.org/html/2406.01767v3</li>
<li>6-DoF Grasp Detection in Clutter with Enhanced Receptive Field …, 2월 1, 2026에 액세스, https://arxiv.org/html/2407.01209v2</li>
<li>NeuGrasp: Generalizable Neural Surface Reconstruction with … - arXiv, 2월 1, 2026에 액세스, https://arxiv.org/html/2503.03511v1</li>
<li>Collision Avoidance Through Neural Implicit Probabilistic Scenes, 2월 1, 2026에 액세스, https://arxiv.org/html/2302.12931v3</li>
<li>Learning Contact and Collision Aware General Dexterous Grasping …, 2월 1, 2026에 액세스, https://neurips.cc/virtual/2025/poster/119309</li>
<li>Learning Contact and Collision Aware General Dexterous Grasping …, 2월 1, 2026에 액세스, https://arxiv.org/html/2601.15039v1</li>
<li>Learning Contact and Collision Aware General Dexterous Grasping …, 2월 1, 2026에 액세스, https://www.themoonlight.io/review/cadgrasp-learning-contact-and-collision-aware-general-dexterous-grasping-in-cluttered-scenes</li>
<li>Learning Contact and Collision Aware General Dexterous Grasping …, 2월 1, 2026에 액세스, https://www.themoonlight.io/en/review/cadgrasp-learning-contact-and-collision-aware-general-dexterous-grasping-in-cluttered-scenes</li>
<li>An Intuitive Multi-Frequency Feature Representation for SO(3), 2월 1, 2026에 액세스, https://openreview.net/forum?id=5JWAOLBxwp</li>
<li>efficient 3D scene understanding for robust language-directed …, 2월 1, 2026에 액세스, https://arxiv.org/html/2407.21267v1</li>
<li>A Graph-Based SE(3)-invariant Approach to Grasp Detection, 2월 1, 2026에 액세스, https://ieeexplore.ieee.org/iel7/10160211/10160212/10160728.pdf</li>
<li>to Intra-operative Registration in Image-guided Liver Interventions, 2월 1, 2026에 액세스, https://arxiv.org/html/2505.19518v1</li>
<li>PCF-Grasp: Converting Point Completion to Geometry Feature to …, 2월 1, 2026에 액세스, https://arxiv.org/html/2504.16320v2</li>
<li>PCF-Grasp: Converting Point Completion to Geometry Feature to …, 2월 1, 2026에 액세스, https://arxiv.org/html/2504.16320v1</li>
<li>A Linkage-Driven Underactuated Robotic Hand for Adaptive …, 2월 1, 2026에 액세스, https://www.researchgate.net/publication/370823534_A_Linkage-Driven_Underactuated_Robotic_Hand_for_Adaptive_Grasping_and_In-Hand_Manipulation</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>