<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:7.3.1 보지 못한 물체(Unseen Objects) 다루기: 기하학적 유사성과 위상적 불변성</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>7.3.1 보지 못한 물체(Unseen Objects) 다루기: 기하학적 유사성과 위상적 불변성</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 7. 행동을 위한 지각: 어포던스와 포즈 (Perception for Action: Affordance & Pose)</a> / <a href="index.html">7.3 범주 수준의 일반화와 NOCS (Category-Level Generalization & NOCS)</a> / <span>7.3.1 보지 못한 물체(Unseen Objects) 다루기: 기하학적 유사성과 위상적 불변성</span></nav>
                </div>
            </header>
            <article>
                <h1>7.3.1 보지 못한 물체(Unseen Objects) 다루기: 기하학적 유사성과 위상적 불변성</h1>
<h2>1.  서론: 폐쇄형 시스템에서 개방형 세계로의 전환</h2>
<p>현대 로봇 공학 및 컴퓨터 비전 분야에서 가장 중요하고도 난이도 높은 과제 중 하나는 훈련 데이터에 존재하지 않았던, 즉 ’보지 못한 물체(Unseen Objects)’를 인식하고 조작하는 능력의 확보이다. 과거의 6D 포즈 추정(6D Pose Estimation) 기술은 주로 LINEMOD나 T-LESS와 같은 벤치마크 데이터셋을 기반으로, 사전에 3D CAD 모델이 주어진 특정 인스턴스(Instance)만을 다루는 ’폐쇄형 시스템(Closed-set System)’에 머물러 있었다. 이러한 시스템은 제어된 공장 환경에서는 유효할지 모르으나, 가정용 서비스 로봇이나 비정형 물류 현장, 그리고 증강 현실(AR)과 같이 예측 불가능한 ’개방형 세계(Open World)’에서는 그 한계가 명확하다.</p>
<p>보지 못한 물체를 다루기 위해서는 기존의 ’템플릿 매칭’이나 ‘인스턴스별 회귀’ 방식을 넘어서는 새로운 패러다임이 필요하다. 이는 물체의 고유한 정체성(Identity)을 텍스처나 색상과 같은 표면적 특징(Appearance)에 의존하는 것이 아니라, 물체의 본질적인 형상과 구조적 특성에 기반하여 추론하는 능력을 요구한다. 본 절에서는 이러한 추론을 가능하게 하는 두 가지 핵심 축인 **기하학적 유사성(Geometric Similarity)**과 **위상적 불변성(Topological Invariance)**에 대해 심층적으로 논의한다.</p>
<p>2024년과 2025년의 최신 연구 동향은 지도 학습(Supervised Learning)의 한계를 극복하기 위해 대규모 파운데이션 모델(Foundation Models)을 활용한 제로 샷(Zero-shot) 기하학적 매칭과, 물체의 구조적 위상을 명시적으로 모델링하는 그래프 신경망(Graph Neural Networks, GNN)의 결합으로 나아가고 있다. 또한, 추론 단계에서 실시간으로 모델을 적응시키는 테스트 시간 적응(Test-Time Adaptation, TTA) 기술의 등장은 ’학습’과 ’추론’의 경계를 허물며 미지 물체 대응 능력을 획기적으로 향상시키고 있다. 본 보고서는 이러한 기술적 진보를 바탕으로, 보지 못한 물체의 6D 포즈를 추정하고 이를 로봇 조작(Manipulation)에 활용하기 위한 이론적 배경과 최신 방법론을 포괄적으로 분석한다.</p>
<h2>2.  기하학적 유사성(Geometric Similarity): 형태의 보편적 대응</h2>
<p>기하학적 유사성은 관측된 미지 물체와 시스템이 보유한 기하학적 지식(범주형 템플릿 혹은 일반화된 형상 특징) 사이의 대응 관계를 수립하는 척도이다. 보지 못한 물체는 학습된 텍스처가 없기 때문에, 시스템은 오직 깊이(Depth) 정보나 3D 형상 정보, 혹은 파운데이션 모델이 추출한 기하학적 임베딩에 의존하여 “이 물체가 무엇과 닮았는지”, 그리고 “어떤 자세를 취하고 있는지“를 판단해야 한다.</p>
<h3>2.1  지역적 형상 기술자(Local Shape Descriptors)와 매칭 메커니즘</h3>
<p>CAD 모델이 없는 상황에서 물체를 인식하는 가장 전통적이면서도 강력한 방법은 국소적인 형상 특징(Local Shape Features)을 이용하는 것이다. 이는 물체 전체의 전역적 형상이 아닌, 표면의 곡률, 법선 벡터(Normal Vector)의 분포, 점들 간의 상대적 위치 관계 등을 암호화하여 <span class="math math-inline">SE(3)</span> 변환(회전 및 이동)에 불변하는 특징 벡터를 생성하는 기술이다.</p>
<p><strong>포인트별 특징 인코딩(Point-wise Feature Encoding)</strong> 미지 물체는 점군(Point Cloud) <span class="math math-inline">P = {p_i \in \mathbb{R}^3}</span>으로 표현될 수 있다. 기하학적 유사성을 계산하기 위해 시스템은 각 점 <span class="math math-inline">p_i</span>를 고차원 특징 공간 <span class="math math-inline">\mathcal{F}</span>로 매핑하는 함수 <span class="math math-inline">\Phi: \mathbb{R}^3 \to \mathbb{R}^d</span>를 학습한다. 이상적인 함수 <span class="math math-inline">\Phi</span>는 물체의 포즈가 변하더라도 동일한 물리적 지점에 대해서는 유사한 특징 벡터 <span class="math math-inline">f_i</span>를 출력해야 한다. 과거에는 PPF(Point Pair Features)와 같은 핸드크래프트(Hand-crafted) 특징이 주를 이루었으나, 최근 연구들은 딥러닝 기반의 기술자(Descriptor)를 활용한다. 의 연구에 따르면, SO(3)-불변(Invariant) 특징을 추출하기 위해 전역 형상 기술자를 먼저 추출한 후, 이를 기반으로 각 점의 지역적 형상 변환(Local Shape Transform)을 동적으로 예측하는 방식이 제안되었다. 이는 의미적으로(Semantically) 대응되는 점들이 서로 다른 인스턴스 간에도 유사한 지역 기술자를 갖도록 유도하여, 같은 범주 내의 다른 물체(예: 모양이 다른 두 개의 머그컵) 간에도 밀집 대응(Dense Correspondence)을 가능하게 한다.</p>
<p><strong>그래프 어텐션 네트워크(GAT)를 통한 특징 집계</strong> 단순한 지역 특징은 텍스처가 없는(Texture-less) 물체나 형상이 단조로운 평면 영역에서 모호성을 가질 수 있다. 이를 해결하기 위해 <strong>OnePose</strong> 및 **OnePose++**와 같은 프레임워크는 그래프 어텐션 네트워크(Graph Attention Networks, GAT)를 도입하여 시각적 위치 추정 파이프라인을 혁신하였다. OnePose의 핵심은 2D 이미지 특징과 3D 형상 특징 간의 상호 작용을 모델링하는 것이다.</p>
<ol>
<li><strong>특징 추출:</strong> 쿼리 이미지와 참조 이미지들로부터 SuperPoint와 같은 CNN 기반 추출기를 통해 2D 키포인트와 기술자를 추출한다.</li>
<li><strong>3D 특징 리프팅:</strong> 참조 이미지들의 2D 특징을 SfM(Structure from Motion)으로 재구성된 희소 3D 점군에 투영하여 초기 3D 기술자를 생성한다.</li>
<li><strong>그래프 어텐션:</strong> 3D 점들을 그래프의 노드로 간주하고, GAT를 통해 인접한 점들의 기하학적 정보를 집계(Aggregation)한다. 이를 통해 각 3D 점은 자신의 지역적 기하 정보뿐만 아니라 주변의 문맥 정보까지 포함하는 강력한 기술자를 갖게 된다.</li>
<li><strong>매칭 및 포즈 추정:</strong> 쿼리 이미지의 2D 특징과 집계된 3D 특징 간의 유사도를 계산하여 매칭을 수행하고, PnP-RANSAC 알고리즘을 통해 6D 포즈를 산출한다.</li>
</ol>
<p>수학적으로, 2D 쿼리 특징 <span class="math math-inline">\tilde{F}_{2D}</span>와 3D 모델 특징 <span class="math math-inline">\tilde{F}_{3D}</span> 사이의 매칭 점수 행렬 <span class="math math-inline">S</span>는 다음과 같이 내적과 스케일링을 통해 정의된다 :<br />
<span class="math math-display">
S(j, q) = \frac{1}{\tau} \langle \tilde{F}_{3D}(j), \tilde{F}_{2D}(q) \rangle
</span><br />
여기서 <span class="math math-inline">\tau</span>는 온도 매개변수이며, 최종 매칭 확률은 이중 소프트맥스(Dual-Softmax) 연산을 통해 상호 최적(Mutual Nearest Neighbor) 조건을 만족하는 쌍을 선별하는 데 사용된다.</p>
<h3>2.2  파운데이션 모델 기반의 제로 샷 기하학적 앵커링</h3>
<p>2024년과 2025년에 이르러, 컴퓨터 비전 분야는 특정 데이터셋에 과적합된 모델을 학습시키는 방식에서 벗어나, 웹 스케일 데이터로 사전 학습된 **비전 파운데이션 모델(Vision Foundation Models, VFMs)**을 활용하는 방향으로 급격히 선회하고 있다. DINOv2나 MASt3R와 같은 모델들은 별도의 미세 조정(Fine-tuning) 없이도 보지 못한 물체에 대해 놀라울 정도의 기하학적 일관성을 보여준다.</p>
<p><strong>FreeZe: 훈련이 필요 없는(Training-Free) 포즈 추정</strong> <strong>FreeZe</strong> 방법론은 기하학적 파운데이션 모델(Geometric Foundation Model)과 비전 파운데이션 모델을 결합하여, 과도한 학습 과정 없이 미지 물체의 포즈를 추정하는 획기적인 접근법을 제시한다. 이 방법은 미지 물체의 3D CAD 모델이 주어졌을 때(혹은 레퍼런스 스캔이 있을 때), 이를 렌더링하여 비전 모델(DINOv2)을 통해 2D 특징을 추출하고, 동시에 3D 형상 자체에서 기하학적 특징(GeDi 등)을 추출한다. 중요한 점은 쿼리 이미지(RGB)와 3D 모델(Point Cloud)이라는 서로 다른 모달리티(Modality)를 다룸에도 불구하고, 파운데이션 모델의 강력한 특징 표현력을 통해 공통된 특징 공간에서의 매칭이 가능하다는 것이다. FreeZe는 이를 통해 BOP 벤치마크의 7개 핵심 데이터셋에서 별도의 학습 없이도 기존의 지도 학습 모델들을 상회하는 성능을 기록하였다. 이는 기하학적 유사성이 더 이상 픽셀 수준의 텍스처 매칭이 아니라, 고차원 의미론적(Semantic) 및 기하학적 공간에서의 정렬 문제로 진화했음을 시사한다.</p>
<p><strong>MASt3R와 Pos3R: 3D 일관성 활용</strong> <strong>Pos3R</strong>는 <strong>MASt3R</strong>라는 3D 파운데이션 모델을 활용한다. MASt3R는 이미지 쌍(Stereo Pair)이 주어졌을 때 밀집된 3D 대응점(Dense Correspondence)을 생성하도록 훈련된 모델이다. Pos3R는 미지 물체의 3D 모델을 중심으로 가상의 구(Sphere) 상에 카메라를 배치하여 약 40개의 템플릿 이미지를 렌더링한다. 그 후, 입력된 쿼리 이미지를 이 40개의 템플릿과 MASt3R를 통해 매칭시킨다. 이 과정에서 MASt3R는 단순히 2D 이미지를 비교하는 것이 아니라, 내부적으로 3D 기하학적 일관성을 유지하는 특징맵을 생성하기 때문에, 물체의 회전(특히 Out-of-plane Rotation)이 심한 경우에도 강건한 대응점을 찾아낸다. 이렇게 확보된 2D-3D 대응점들을 바탕으로 PnP 알고리즘을 수행하면, 추가적인 학습 없이도 매우 정밀한 6D 포즈를 얻을 수 있다. 이는 기하학적 유사성 판단의 주체가 ’학습된 가중치’에서 ’사전 학습된 기하학적 지능’으로 옮겨갔음을 보여주는 사례이다.</p>
<p><strong>Geo6DPose: 기하학적 필터링</strong> 단순히 파운데이션 모델의 특징만을 신뢰하는 것은 위험할 수 있다. 시각적 특징은 조명이나 반사에 의해 오염될 수 있기 때문이다. <strong>Geo6DPose</strong>는 이를 보완하기 위해 ‘기하학적 필터링(Geometric Filtering)’ 전략을 도입한다. 파운데이션 모델이 제안한 대응점 후보군에 대해, 3D 공간상에서의 강체 변환(Rigid Transformation) 제약 조건을 위배하는 매칭들을 사전에 제거한다. 즉, 시각적 유사성이 높더라도 기하학적 구조(점들 간의 거리 비율 등)가 일치하지 않으면 오매칭으로 간주하는 것이다.</p>
<h3>2.3  렌더링 기반 비교(Render-and-Compare)와 특징 매칭의 융합</h3>
<p>미지 물체 포즈 추정에서 기하학적 유사성을 활용하는 방식은 크게 두 가지 흐름으로 나뉘며, 최근에는 이 둘을 융합하는 시도가 늘고 있다.</p>
<table><thead><tr><th><strong>접근 방식</strong></th><th><strong>메커니즘</strong></th><th><strong>장점</strong></th><th><strong>단점</strong></th><th><strong>대표 연구</strong></th></tr></thead><tbody>
<tr><td><strong>렌더링 기반 비교 (Render-and-Compare)</strong></td><td>추정된 포즈로 물체의 3D 모델을 렌더링한 후, 입력 이미지와 픽셀/특징 단위의 차이(Error)를 계산하여 이를 최소화하는 방향으로 포즈를 반복 수정(Refinement)함.</td><td>매우 높은 정밀도를 달성할 수 있음. 텍스처가 없는 물체라도 윤곽선(Contour)이나 깊이 정보를 통해 정렬 가능.</td><td>초기 포즈가 틀리면 국소 최적해(Local Minima)에 빠지기 쉬움. 렌더링 비용으로 인해 속도가 느릴 수 있음.</td><td>MegaPose, Gen6D</td></tr>
<tr><td><strong>특징 매칭 (Feature Matching)</strong></td><td>입력 이미지와 템플릿/모델 간의 키포인트(Keypoint)나 밀집 특징(Dense Feature) 대응 관계를 직접 찾아 PnP로 포즈를 계산함.</td><td>한 번의 추론(Single-shot)으로 포즈를 얻을 수 있어 빠름. 파운데이션 모델의 강력한 기술자를 활용 가능.</td><td>반복되는 패턴이나 형상이 모호한 물체에서 오매칭(Outlier)이 발생할 수 있음.</td><td>OnePose, FreeZe, Pos3R</td></tr>
</tbody></table>
<p><strong>Gen6D</strong>는 이 두 방식의 장점을 결합한 하이브리드 접근법을 취한다. 먼저 객체 검출기(Detector)와 시점 선택기(Viewpoint Selector)를 통해 가장 유사한 레퍼런스 이미지를 찾아 대략적인 포즈를 초기화한다(특징 매칭적 요소). 그 후, 포즈 정제기(Pose Refiner)가 렌더링된 이미지와 입력 이미지 간의 차이를 줄여나간다. 특히 Gen6D는 미지 물체에 대해서도 일반화된 이미지 유사도 메트릭을 학습하여, CAD 모델 없이도 소수의 레퍼런스 이미지만으로 작동하는 ‘모델 프리(Model-free)’ 환경을 구축하였다.</p>
<h2>3.  위상적 불변성(Topological Invariance): 구조적 견고함의 원천</h2>
<p>기하학적 유사성이 물체의 ’수치적 형상(Metric Shape)’을 다룬다면, <strong>위상적 불변성</strong>은 연속적인 변형(Deformation) 하에서도 보존되는 물체의 ’연결성(Connectivity)’과 ’구조(Structure)’를 다룬다. 미지 물체, 특히 범주 수준(Category-level)의 포즈 추정에서 위상적 정보는 기하학적 정보보다 훨씬 더 강력한 단서가 된다. 예를 들어, ’손잡이가 달린 컵’은 그 크기나 비율이 제각각일지라도 ’하나의 구멍(Hole)을 가진 덩어리’라는 위상적 특성을 공유하며, 이는 컵을 그릇(Bowl)과 구분 짓는 결정적인 불변량이다.</p>
<h3>3.1  위상수학적 이론 배경: 호몰로지와 지속성</h3>
<p>컴퓨터 비전에서 위상적 불변성을 다루기 위한 주된 수학적 도구는 <strong>대수적 위상수학(Algebraic Topology)</strong>, 그중에서도 **지속 호몰로지(Persistent Homology)**이다.</p>
<p><strong>위상 공간과 호메오모피즘(Homeomorphism)</strong> 두 위상 공간 <span class="math math-inline">X</span>와 <span class="math math-inline">Y</span> 사이에 연속이고 역함수도 연속인 전단사 함수(Homeomorphism)가 존재할 때, 두 공간은 위상동형(Homeomorphic)이라고 한다. 6D 포즈 추정에서 우리는 미지 물체의 관측된 부분 점군(Partial Point Cloud)이 전체 모델의 어떤 부분과 위상적으로 동형인지를 찾아내야 한다. 위상적 불변량(Topological Invariants)은 이러한 변환에 대해 변하지 않는 성질들이다.</p>
<p><strong>베티 수(Betti Numbers)와 필트레이션(Filtration)</strong></p>
<p>3차원 공간의 물체는 베티 수로 그 위상적 특징을 요약할 수 있다.</p>
<ul>
<li><span class="math math-inline">\beta_0</span>: 연결 성분(Connected Components)의 개수</li>
<li><span class="math math-inline">\beta_1</span>: 터널(Tunnel) 혹은 구멍(Hole)의 개수 (예: 도넛의 구멍, 컵의 손잡이)</li>
<li><span class="math math-inline">\beta_2</span>: 빈 공간(Void)의 개수 (예: 풍선 내부의 공간)</li>
</ul>
<p><strong>지속 호몰로지</strong>는 데이터 포인트(점군)들 사이의 거리를 매개변수 <span class="math math-inline">\epsilon</span> (Filtration parameter)으로 하여, <span class="math math-inline">\epsilon</span>을 0부터 증가시킬 때 위상적 특징(구멍 등)이 언제 생겨나고(Birth) 언제 사라지는지(Death)를 추적한다. 이를 통해 **지속성 다이어그램(Persistence Diagram)**을 그릴 수 있으며, 이 다이어그램에서 수명이 긴(High persistence) 특징은 실제 물체의 구조적 특징으로, 수명이 짧은 특징은 노이즈로 간주한다.</p>
<h3>3.2  TG-Pose: 위상과 기하의 결합</h3>
<p>최근 발표된 <strong>TG-Pose (Topology and Geometry Pose)</strong> 프레임워크는 이러한 위상적 분석을 6D 포즈 추정에 직접적으로 통합한 선구적인 연구이다. 기존의 기하학적 방법론들은 폐색(Occlusion)이나 센서 노이즈로 인해 점군이 유실되면 급격한 성능 저하를 겪는다. 예를 들어, 컵의 손잡이 부분이 가려지면 기하학적 매칭은 실패하기 쉽다. 그러나 TG-Pose는 위상적 정보를 통해 이를 보완한다.</p>
<p><strong>TG-Pose의 핵심 아키텍처:</strong></p>
<ol>
<li><strong>포즈 민감형 특징 추출(Pose-Sensitive Feature Extraction):</strong> 포인트넷(PointNet) 등의 인코더를 통해 기하학적 특징을 추출한다.</li>
<li><strong>위상 특징 예측기(Topological Feature Predictor, TopoPre):</strong> 입력된 불완전한 점군으로부터 물체 전체의 위상적 특징(지속성 다이어그램 등)을 예측한다. 이는 네트워크가 “비록 지금은 가려져서 안 보이지만, 이 물체는 구조적으로 손잡이(구멍)를 가지고 있어야 한다“는 위상적 추론을 수행하게 한다.</li>
<li><strong>대칭성 재구성(Symmetry Reconstruction):</strong> 위상적 불변성은 대칭 물체의 보이지 않는 뒷면을 복원하는 데 강력한 가이드를 제공한다. 기하학적 정보만으로는 표면의 연속성을 보장하기 어렵지만, 위상적 제약 조건(Topological Constraints)을 걸어줌으로써 구멍이 막히거나 표면이 찢어지는 현상을 방지할 수 있다.</li>
<li><strong>교차 클라우드 변환(Cross-Cloud Transformation):</strong> 관측된 부분 점군과 범주형 템플릿 간의 위상적 특징을 정렬하여, 기하학적 정렬의 초기값을 보정한다.</li>
</ol>
<p>TG-Pose의 실험 결과는 위상적 정보가 단순한 보조 수단이 아니라, 심각한 폐색 상황에서 물체의 정체성을 유지하고 포즈를 안정화하는 데 필수적인 요소임을 증명한다.</p>
<h3>3.3  그래프 신경망(GNN)을 통한 위상 모델링</h3>
<p>위상적 구조를 딥러닝 모델에 구현하는 가장 효과적인 방법 중 하나는 **그래프 신경망(GNN)**을 사용하는 것이다. 물체를 그래프 <span class="math math-inline">G=(V, E)</span>로 표현하면, 노드 <span class="math math-inline">V</span>는 물체의 키포인트나 표면 패치가 되고, 엣지 <span class="math math-inline">E</span>는 이들 간의 연결성(인접 관계)을 나타낸다.</p>
<p><strong>CheckerPose와 GNN 기반의 밀집 키포인트 위치화</strong> <strong>CheckerPose</strong>는 입력 이미지에서 3D 키포인트의 위치를 추정하기 위해 GNN을 활용한다. 이 방법은 먼저 감지된 키포인트들로 k-NN 그래프를 구성하고, GNN을 통해 특징을 전파(Message Passing)한다. 이 과정에서 가려져서 보이지 않는 키포인트의 위치를 주변의 보이는 키포인트들과의 위상적 관계(그래프 상의 연결 구조)를 통해 추론해낸다. 즉, GNN은 물체의 “보이지 않는 구조“를 그래프의 연결성을 통해 복원하며, 이는 위상적 불변성을 학습하는 과정과 동일하다.</p>
<p><strong>SE(3)-등변(Equivariant) GNN</strong> 6D 포즈 추정에서 GNN을 사용할 때의 핵심 요구사항은 <strong>SE(3)-등변성</strong>이다. 물체가 3D 공간에서 회전하면, 그래프의 노드 특징들도 그에 맞춰 회전해야 한다. <strong>SGSPose</strong>와 같은 최신 연구는 리 대수(Lie Algebra)를 GNN의 레이어에 통합하여, 그래프의 위상적 학습이 3D 강체 변환(Rigid Body Transformation)과 수학적으로 일관성을 유지하도록 설계되었다. 이는 위상적 구조 학습이 기하학적 변환에 대해 강건함을 보장해준다.</p>
<h2>4.  골격 기반 표현(Skeleton-Based Representations)과 로봇 조작</h2>
<p>위상적 불변성의 또 다른 중요한 응용 분야는 물체를 **골격(Skeleton)**이나 **중심축(Medial Axis)**으로 추상화하여 표현하는 것이다. 이는 특히 관절이 있는 물체(Articulated Objects)나 형상이 복잡한 미지 물체를 로봇이 조작(Handling)해야 할 때 필수적이다.</p>
<h3>4.1  미지 물체의 골격 추출</h3>
<p>표면 메쉬(Surface Mesh)는 데이터 양이 많고 노이즈에 민감한 반면, 골격은 물체의 위상적 구조(Topology)를 1차원 그래프 형태로 압축하여 표현한다. 미지 물체에 대해 골격을 추출하는 것은 물체의 ’조작 가능한 부위’를 파악하는 것과 직결된다.</p>
<ul>
<li><strong>StSkel (Straight Skeleton) 방법:</strong> 탑다운(Top-down) 그리핑 시나리오에서, <strong>StSkel</strong> 알고리즘은 물체의 2D 마스크로부터 직선 골격(Straight Skeleton)을 추출한다. 이 골격의 분기점(Junctions)과 능선(Ridges)은 물체의 질량이 집중된 중심부를 나타내며, 로봇 그리퍼가 안정적으로 파지할 수 있는 후보 지점이 된다.</li>
<li><strong>딥러닝 기반 골격화:</strong> <strong>Keypoint-GraspNet</strong>이나 <strong>CheckerPose</strong>와 같은 딥러닝 모델들은 물체의 표면이 아닌 위상학적으로 중요한 키포인트(골격의 끝점이나 교차점)를 직접 회귀하도록 학습된다. 이는 물체의 전체 형상을 모르더라도 “어디를 잡아야 하는지“에 대한 구조적 단서를 제공한다.</li>
</ul>
<h3>4.2  위상적 매듭(Topological Braids)과 조작 경로 계획</h3>
<p>로봇이 미지 물체를 조작하거나 복잡한 환경에서 얽혀 있는 물체를 풀어낼 때, 위상수학의 **매듭 이론(Knot Theory)**과 <strong>브레이드(Braid)</strong> 개념이 적용된다.</p>
<ul>
<li><strong>위상적 얽힘(Topological Entanglement):</strong> 다수의 로봇 팔이 협업하거나 전선과 같은 유연한 물체를 다룰 때, 로봇 팔과 물체 사이의 관계는 위상적 얽힘으로 표현된다. **와인딩 넘버(Winding Number)**나 **링킹 넘버(Linking Number)**와 같은 위상 불변량은 로봇의 궤적이 물체를 몇 번 감았는지, 혹은 얽힘 없이 안전하게 빠져나갈 수 있는지를 수치적으로 나타낸다.</li>
<li><strong>불변성을 이용한 제어:</strong> 의 연구에서는 이러한 위상 불변량을 제어 신호로 사용하여, 로봇이 미지 물체들 사이를 통과할 때 위상적 충돌(꼬임)을 회피하도록 학습시키는 강화학습 아키텍처를 제안한다. 이는 기하학적 거리 측정만으로는 감지하기 어려운 ‘구조적 갇힘’ 상태를 위상적 계산을 통해 해결하는 사례이다.</li>
</ul>
<h3>4.3  범주 수준 골격 그래프 (2G-GCN)</h3>
<p>범주 수준의 물체 조작, 특히 인간-물체 상호작용(HOI) 인식에서는 <strong>2G-GCN</strong>과 같은 계층적 그래프 모델이 사용된다. 이 모델은 인간의 골격과 물체의 대략적인 중심 골격을 1차 레벨 그래프로 모델링하고, 이들 사이의 상호작용을 2차 레벨 그래프로 모델링한다. 이를 통해 시스템은 보지 못한 물체라 할지라도, 인간이 그 물체의 ‘손잡이’ 위상 부위를 잡고 있다는 구조적 관계를 파악하여 물체의 기능과 포즈를 역추적할 수 있다.</p>
<h2>5.  테스트 시간 적응(Test-Time Adaptation): 기하와 위상의 실시간 동기화</h2>
<p>아무리 뛰어난 파운데이션 모델이나 위상학적 추론이라도, 완전히 새로운 형태의 물체 앞에서는 오차를 보일 수 있다. 이를 해결하기 위한 최전선의 기술이 바로 **테스트 시간 적응(Test-Time Adaptation, TTA)**이다. TTA는 추론 단계에서 입력된 미지 물체의 데이터를 이용하여 모델의 가중치를 실시간으로 업데이트함으로써, 기하학적/위상적 표현을 해당 인스턴스에 맞게 동기화한다.</p>
<h3>5.1  TTAPose: 자기 지도 학습을 통한 정제</h3>
<p><strong>TTAPose</strong>는 미지 물체 포즈 추정을 위한 TTA의 대표적인 프레임워크이다.</p>
<ol>
<li><strong>초기 추정:</strong> 일반화된 포즈 추정기(예: MatchU)가 범용 기하 특징을 바탕으로 거친(Coarse) 포즈를 추정한다.</li>
<li><strong>자기 지도 손실(Self-Supervised Loss):</strong> 정답 레이블(Ground Truth)이 없으므로, <strong>엔트로피 최소화(Entropy Minimization)</strong> 기법을 사용한다. 올바른 포즈 추정은 특징 맵 상에서 불확실성이 낮은(Low Entropy) 명확한 반응을 보여야 한다는 가정하에, 모델이 스스로 확신을 갖는 방향으로 가중치를 갱신한다.</li>
<li><strong>교사-학생(Teacher-Student) 프레임워크:</strong> ‘교사’ 네트워크는 현재의 추정치를 바탕으로 정제된 가짜 레이블(Pseudo-label)을 생성하고, ‘학생’ 네트워크는 이를 학습한다. 이 과정을 반복하며 모델은 미지 물체의 구체적인 기하학적 디테일과 위상적 구조에 점진적으로 적응해 나간다.</li>
</ol>
<h3>5.2  뉴럴 분석-합성(Neural Analysis-by-Synthesis)</h3>
<p>또 다른 적응 방식은 <strong>뉴럴 분석-합성</strong>이다. 이 방식은 잠재 공간(Latent Space) 상에서 물체의 형상 코드(Shape Code)를 최적화한다. 범주형 평균 형상(Mean Shape)에서 시작하여, 입력 이미지와 렌더링된 이미지의 차이를 최소화하는 변형(Deformation) 필드를 학습한다. 이때 위상적 불변성은 변형 과정에서 물체의 구멍이 막히거나 찢어지지 않도록 하는 정규화(Regularization) 항으로 작용하여, 물리적으로 타당한 형상을 유지하도록 돕는다.</p>
<h2>6.  결론 및 요약</h2>
<p>보지 못한 물체(Unseen Objects)의 6D 포즈 추정과 조작은 컴퓨터 비전이 해결해야 할 난제 중 하나이며, 이를 극복하기 위해서는 <strong>기하학적 유사성</strong>의 정밀함과 <strong>위상적 불변성</strong>의 견고함이 유기적으로 결합되어야 한다.</p>
<p>본 절에서 살펴본 주요 방법론들의 비교는 다음과 같다.</p>
<table><thead><tr><th><strong>방법론 (Methodology)</strong></th><th><strong>기하학적 접근 (Geometric Approach)</strong></th><th><strong>위상학적 접근 (Topological Approach)</strong></th><th><strong>미지 물체 대응의 핵심 강점</strong></th></tr></thead><tbody>
<tr><td><strong>OnePose / OnePose++</strong></td><td>2D-3D 특징 매칭 및 GAT 기반 집계</td><td>키포인트 그래프 구조를 통한 암묵적 위상 활용</td><td>CAD 모델 불필요; SfM을 통해 임의의 물체 즉시 대응 가능</td></tr>
<tr><td><strong>FreeZe / Pos3R</strong></td><td>파운데이션 모델(DINO, MASt3R)의 범용 특징 활용</td><td>(직접적 위상 활용 없음, 밀집 대응에 의존)</td><td>완전한 제로 샷(Zero-shot); 학습 과정 전무; 웹 스케일 지식 활용</td></tr>
<tr><td><strong>TG-Pose</strong></td><td>포즈 민감형 기하 인코딩</td><td>지속 호몰로지(Persistent Homology) 및 위상 특징 예측기</td><td>폐색 및 노이즈에 극도로 강건함; 대칭 물체의 구조적 복원 우수</td></tr>
<tr><td><strong>CheckerPose</strong></td><td>밀집 키포인트 이진 코딩</td><td>GNN을 통한 키포인트 간 상호작용 및 비가시 영역 추론</td><td>점진적 정제(Progressive Refinement); 가려진 부분의 위치 추론 가능</td></tr>
<tr><td><strong>TTAPose</strong></td><td>기술자(Descriptor) 매칭</td><td>(적응 과정에서 형상 위상 학습)</td><td>테스트 시점에 미지 물체의 고유 특성에 맞춰 모델 스스로 진화</td></tr>
<tr><td><strong>StSkel / 2G-GCN</strong></td><td>2D 윤곽선 기반</td><td>직선 골격(Straight Skeleton) 및 계층적 상호작용 그래프</td><td>로봇 조작(Grasping)을 위한 구조적 파지점 제공</td></tr>
</tbody></table>
<p>결론적으로, 미래의 6D 포즈 추정 시스템은 <strong>통합된 뉴로-심볼릭(Neuro-Symbolic) 표현</strong>으로 나아갈 것이다. 여기서는 MASt3R와 같은 모델이 제공하는 연속적인 기하학적 다양체(Manifold)가 TG-Pose나 GNN이 처리하는 이산적인 위상 불변량에 의해 제약되고 구조화된다. 더 나아가 TTAPose와 같은 적응형 알고리즘이 실시간으로 이 표현을 다듬음으로써, 로봇은 처음 보는 물체라 할지라도 인간과 유사한 직관적이고 구조적인 이해를 바탕으로 능숙하게 다룰 수 있게 될 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>TTAPose: Test-Time Adaptation for Unseen Object Pose Estimation, https://ieeexplore.ieee.org/iel8/7083369/10969146/10976352.pdf</li>
<li>FreeZe, https://andreacaraffa.github.io/freeze/</li>
<li>Progressive Dense Keypoint Localization for Object Pose Estimation …, https://openaccess.thecvf.com/content/ICCV2023/papers/Lian_CheckerPose_Progressive_Dense_Keypoint_Localization_for_Object_Pose_Estimation_with_ICCV_2023_paper.pdf</li>
<li>Invariant Semantic Correspondence via Local Shape Transform, https://openaccess.thecvf.com/content/CVPR2024/papers/Park_Learning_SO3-Invariant_Semantic_Correspondence_via_Local_Shape_Transform_CVPR_2024_paper.pdf</li>
<li>OnePose: One-Shot Object Pose Estimation without CAD Models, http://www.cad.zju.edu.cn/home/gfzhang/papers/OnePose/onepose.pdf</li>
<li>OnePose: One-Shot Object Pose Estimation Without CAD Models, https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.pdf</li>
<li>Keypoint-Free One-Shot Object Pose Estimation without CAD Models, https://proceedings.neurips.cc/paper_files/paper/2022/file/e43f900f571de6c96a70d5724a0fb565-Paper-Conference.pdf</li>
<li>Fast Zero-Shot 6D Object Pose Estimation via Geometry-Filtered …, https://www.researchgate.net/publication/398602244_Geo6DPose_Fast_Zero-Shot_6D_Object_Pose_Estimation_via_Geometry-Filtered_Feature_Matching</li>
<li>Pos3R: 6D Pose Estimation for Unseen Objects Made Easy, https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Pos3R_6D_Pose_Estimation_for_Unseen_Objects_Made_Easy_CVPR_2025_paper.pdf</li>
<li>One View, Many Worlds: Single-Image to 3D Object Meets … - arXiv, https://arxiv.org/html/2509.07978v1</li>
<li>Gen6D: Generalizable Model-Free 6-DoF Object Pose Estimation …, https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920297.pdf</li>
<li>1월 29, 2026에 액세스, [https://www.researchgate.net/publication/380921585_TG-Pose_Delving_Into_Topology_and_Geometry_for_Category-Level_Object_Pose_Estimation#:<sub>:text=Category%2Dlevel%206D%20object%20pose,in%20occlusion%20and%20noisy%20environments.](https://www.researchgate.net/publication/380921585_TG-Pose_Delving_Into_Topology_and_Geometry_for_Category-Level_Object_Pose_Estimation#:</sub>:text=Category-level 6D object pose, <a href="https://www.researchgate.net/publication/380921585_TG-Pose_Delving_Into_Topology_and_Geometry_for_Category-Level_Object_Pose_Estimation#:~:text=Category-level%206D%20object%20pose,in%20occlusion%20and%20noisy%20environments.">https://www.researchgate.net/publication/380921585_TG-Pose_Delving_Into_Topology_and_Geometry_for_Category-Level_Object_Pose_Estimation#:~:text=Category%2Dlevel%206D%20object%20pose,in%20occlusion%20and%20noisy%20environments.</a></li>
<li>TG-Pose: Delving Into Topology and Geometry for Category-Level …, https://ieeexplore.ieee.org/document/10539316/</li>
<li>TG-Pose: Delving Into Topology and Geometry for Category-Level …, https://ieeexplore.ieee.org/iel7/6046/10384483/10539316.pdf</li>
<li>Persistent Homology based Graph Convolution Network for Fine …, https://www.researchgate.net/publication/358918172_Persistent_Homology_based_Graph_Convolution_Network_for_Fine-grained_3D_Shape_Segmentation</li>
<li>Recent trends, applications, and perspectives in 3D shape similarity …, https://iris.cnr.it/retrieve/47de1e51-11e9-4286-bc99-bb03ef9928fc/prod_337118-doc_184722.pdf</li>
<li>Persistent homology: theory and practice | Request PDF, https://www.researchgate.net/publication/303162234_Persistent_homology_theory_and_practice</li>
<li>SGSPose: Neuromorphic-Geometric 6D Pose Estimation Through …, https://ieeexplore.ieee.org/iel8/6287639/11323511/11338761.pdf</li>
<li>A Survey on 3D Skeleton-Based Action Recognition Using Learning …, https://pmc.ncbi.nlm.nih.gov/articles/PMC11096730/</li>
<li>(PDF) Skeletal descriptions of shape provide unique perceptual …, https://www.researchgate.net/publication/334071111_Skeletal_descriptions_of_shape_provide_unique_perceptual_information_for_object_recognition</li>
<li>(PDF) 2D Skeleton-Based Keypoint Generation Method for Grasping …, https://www.researchgate.net/publication/377836509_2D_Skeleton-Based_Keypoint_Generation_Method_for_Grasping_Objects_with_Roughly_Uniform_Height_Variation</li>
<li>Autonomous Object Grasping with Fetch Robot:, https://robotics.shanghaitech.edu.cn/sites/default/data/2025-04/robotics2024project-fetch-object-grasping.pdf</li>
<li>Topology-Driven Anti-Entanglement Control for Soft Robots, https://www.preprints.org/manuscript/202510.2421/v1</li>
<li>Winding Through: Crowd Navigation via Topological Invariance - arXiv, https://arxiv.org/pdf/2109.05084</li>
<li>Geometric Visual Fusion Graph Neural Networks for Multi-Person …, https://hubertshum.com/publications/eswa2025mphoi/files/eswa2025mphoi.pdf</li>
<li>Geometry-Informed Graph Neural Networks for Multi-Person Human …, http://hubertshum.com/others/thesistanqiuqiao.pdf</li>
<li>Category Level Object Pose Estimation via Neural Analysis-by …, https://www.researchgate.net/publication/346874730_Category_Level_Object_Pose_Estimation_via_Neural_Analysis-by-Synthesis</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>