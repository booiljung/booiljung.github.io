<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.5.2 iMAP과 NICE-SLAM: 계층적 특징 그리드의 활용</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.5.2 iMAP과 NICE-SLAM: 계층적 특징 그리드의 활용</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 5. 뉴럴 3D 표현과 렌더링 (Neural 3D Representations)</a> / <a href="index.html">5.5 Neural SLAM: 밀도 높은 지도의 실시간 작성</a> / <span>5.5.2 iMAP과 NICE-SLAM: 계층적 특징 그리드의 활용</span></nav>
                </div>
            </header>
            <article>
                <h1>5.5.2 iMAP과 NICE-SLAM: 계층적 특징 그리드의 활용</h1>
<h3>0.1  서론: 신경망 기반 SLAM의 패러다임 전환과 암시적 표현의 대두</h3>
<p>로봇 공학 및 컴퓨터 비전 분야에서 동시적 위치 추정 및 지도 작성(SLAM: Simultaneous Localization and Mapping) 기술은 자율 시스템의 공간 지능을 구현하는 핵심 요소이다. 과거의 SLAM 시스템은 주로 특징점(Keypoint) 기반의 희소(Sparse) 지도 작성이나, 복셀(Voxel) 및 서펠(Surfel) 기반의 직접적(Direct) 밀집(Dense) 지도 작성 방식에 의존해 왔다. 그러나 최근 딥러닝 기술의 비약적인 발전, 특히 좌표 기반 신경망 표현(Coordinate-based Neural Representation)의 등장은 3차원 공간을 데이터로서 다루는 방식에 근본적인 패러다임 전환을 가져왔다. 이러한 흐름의 중심에는 2020년 발표된 NeRF(Neural Radiance Fields)가 있으며, 이는 3차원 장면을 신경망의 가중치(Weights) 내에 연속적인 함수(Continuous Function) 형태로 압축하여 저장하는 ’암시적 표현(Implicit Representation)’의 가능성을 입증하였다.</p>
<p>암시적 표현은 기존의 이산적(Discrete) 표현 방식이 갖는 해상도 제약과 메모리 비효율성을 극복할 수 있는 잠재력을 지니고 있다. 이산적 표현은 공간 해상도를 높이기 위해 메모리 사용량이 3제곱으로 증가하는 ’차원의 저주’를 겪는 반면, 신경망은 복잡한 표면 정보를 파라미터 내에 효율적으로 압축할 수 있기 때문이다. 또한, 신경망의 보간(Interpolation) 능력은 관측되지 않은 영역에 대해서도 기하학적으로 타당한 추론(Inpainting)을 가능하게 하여, 로봇의 경로 계획(Path Planning)이나 조작(Manipulation) 작업에 있어 더욱 안전하고 완전한 환경 정보를 제공한다.1</p>
<p>하지만 이러한 암시적 표현을 실시간성이 필수적인 SLAM 시스템에 통합하는 것은 결코 쉬운 과제가 아니다. NeRF와 같은 모델은 단일 장면을 학습하는 데 수 시간에서 수일이 소요되는 오프라인 최적화 과정을 거치기 때문이다. 로봇이 미지의 환경을 탐색하며 실시간으로 데이터를 수집하고 학습해야 하는 SLAM의 특성상, 신경망은 지속적으로 들어오는 새로운 데이터에 적응해야 하며, 이 과정에서 과거에 학습한 정보를 잊어버리는 ‘재앙적 망각(Catastrophic Forgetting)’ 문제에 직면하게 된다. 또한, 제한된 연산 자원 내에서 초당 수십 프레임의 추적 속도와 실시간 맵 업데이트를 동시에 달성해야 하는 계산 효율성 문제 또한 주요한 장벽이었다.2</p>
<p>본 절에서는 이러한 난제들을 극복하고 최초의 실시간 신경망 SLAM 시스템을 구현한 “iMAP: Implicit Mapping and Positioning in Real-Time” 1과, 이를 계층적 특징 그리드(Hierarchical Feature Grid) 구조로 확장하여 대규모 환경에서의 확장성(Scalability)과 정밀도(Fidelity)를 확보한 “NICE-SLAM: Neural Implicit Scalable Encoding for SLAM” 4에 대해 심층적으로 분석한다. 이 두 연구는 단일 다층 퍼셉트론(MLP) 구조에서 하이브리드 특징 그리드 구조로의 진화를 보여주며, 최신 SOTA(State-of-the-Art) 로봇 인공지능 기술이 어떻게 기하학적 제약 조건과 딥러닝의 표현력을 융합하고 있는지를 명확히 보여주는 사례이다.</p>
<h3>0.2  iMAP: 단일 MLP 기반의 실시간 암시적 매핑의 구조와 원리</h3>
<p>iMAP은 RGB-D 카메라를 사용하여 실시간으로 밀집 3D 지도를 생성하고 카메라의 위치를 추적하는 최초의 완전한 신경망 기반 SLAM 시스템으로, 그 의의가 매우 크다. iMAP의 핵심 철학은 전체 3차원 장면을 하나의 거대한 MLP(Multi-Layer Perceptron)로 표현하고, 이를 실시간으로 최적화하여 위치 추정과 지도 작성을 동시에 수행하는 것이다.</p>
<h4>0.2.1  장면 표현을 위한 암시적 신경망 (Implicit Neural Scene Representation)</h4>
<p>iMAP 시스템의 중추는 3차원 좌표 <span class="math math-inline">\mathbf{p} = (x, y, z)</span>를 입력으로 받아 해당 위치의 색상 <span class="math math-inline">\mathbf{c} = (r, g, b)</span>와 체적 밀도(Volume Density) <span class="math math-inline">\sigma</span>를 출력하는 완전 연결 신경망(Fully-connected Neural Network) <span class="math math-inline">F_\theta</span>이다.<br />
<span class="math math-display">
F_\theta(\gamma(\mathbf{p})) \rightarrow (\mathbf{c}, \sigma)
</span><br />
여기서 <span class="math math-inline">\gamma(\cdot)</span>는 저주파수 편향(Spectral Bias)을 극복하고 고주파수 세부 정보를 포착하기 위해 입력 좌표를 고차원 공간으로 매핑하는 위치 인코딩(Positional Encoding) 함수이다.1 기존의 밀집 SLAM 방식들이 3차원 공간을 포인트 클라우드나 서펠 리스트로 관리했던 것과 달리, iMAP은 장면 전체를 약 1MB 크기의 작은 MLP 파라미터 <span class="math math-inline">\theta</span> 안에 압축하여 저장한다. 이는 메모리 효율성 측면에서 혁신적이며, 신경망의 연속적인 특성 덕분에 맵의 해상도가 고정되지 않고(Infinite Resolution), 확대 시에도 깨짐 없는 표면을 표현할 수 있게 한다.1</p>
<h4>0.2.2  실시간 추적 및 매핑을 위한 병렬 프로세스 (Parallel Tracking and Mapping)</h4>
<p>iMAP은 실시간 성능을 확보하기 위해 PTAM(Parallel Tracking and Mapping) 1의 아키텍처를 계승하여 추적(Tracking)과 매핑(Mapping)을 별도의 스레드로 분리하여 병렬로 수행한다.</p>
<ul>
<li>추적 프로세스 (Tracking Process, 10Hz+):</li>
</ul>
<p>추적 스레드는 매 프레임마다 현재 카메라의 6자유도(6-DoF) 포즈 <span class="math math-inline">T_{wc}</span>를 추정한다. 이때 MLP 네트워크 파라미터 <span class="math math-inline">\theta</span>는 고정(Frozen)된 상태로 유지되며, 오직 카메라 포즈만이 최적화 변수가 된다. 현재 추정된 포즈에서 렌더링된 이미지와 실제 입력된 RGB-D 이미지 간의 광도(Photometric) 및 기하학적(Geometric) 오차를 최소화하는 방향으로 포즈가 업데이트된다. iMAP은 약 10Hz 이상의 속도로 추적을 수행하여 로봇의 빠른 움직임에도 대응할 수 있도록 설계되었다.1</p>
<ul>
<li>매핑 프로세스 (Mapping Process, 2Hz):</li>
</ul>
<p>매핑 스레드는 상대적으로 낮은 빈도(약 2Hz)로 실행되며, 전역 지도(Global Map)인 MLP 네트워크 자체를 업데이트한다. 이 과정에서 ’키프레임(Keyframe)’이라는 개념이 중요하게 작용한다. 시스템은 전체 입력 프레임 중 정보량이 풍부하고 시점이 다른 프레임들을 키프레임으로 선별하여 ’메모리 뱅크(Memory Bank)’에 저장한다. 매핑 프로세스는 이 키프레임 세트 전체에 대해 렌더링 오차를 계산하고, 이를 최소화하도록 네트워크 가중치 <span class="math math-inline">\theta</span>와 모든 키프레임의 포즈를 동시에 최적화(Joint Optimization)한다.1</p>
<h4>0.2.3  정보 이득 기반의 능동적 샘플링 (Information-Guided Active Sampling)</h4>
<p>단일 MLP로 전체 장면을 실시간 학습할 때 가장 큰 병목 현상은 렌더링과 역전파(Backpropagation)에 소요되는 연산 비용이다. 이미지의 모든 픽셀에 대해 이를 수행하는 것은 현재의 하드웨어로 불가능하다. iMAP은 이를 해결하기 위해 정보 이론에 입각한 ‘능동적 샘플링(Active Sampling)’ 전략을 도입하였다.</p>
<p>iMAP은 이미지 전체를 균일하게 학습하는 대신, 현재 네트워크가 잘 표현하지 못하는 영역, 즉 정보 이득이 높은 영역에 연산 자원을 집중한다. 이를 위해 각 키프레임 이미지를 그리드로 나누고, 각 그리드 셀의 렌더링 손실(Loss) 통계를 계산한다. 손실이 높은 영역은 기하학적으로 복잡하거나, 새로운 물체가 등장했거나, 혹은 네트워크가 잊어버리기 시작한 영역일 가능성이 높다. iMAP은 이러한 고손실 영역에서 더 많은 픽셀을 확률적으로 샘플링하여 학습 배치를 구성한다.1 이 전략은 희소한 샘플링만으로도 전체 장면의 디테일을 빠르게 학습하고 수렴 속도를 획기적으로 높이는 핵심 기여점이다.</p>
<h4>0.2.4  iMAP의 구조적 한계: 재앙적 망각과 확장성 문제</h4>
<p>iMAP은 혁신적인 시도였음에도 불구하고, 단일 MLP를 전역 장면 표현(Global Scene Representation)으로 사용함에 따른 명확한 한계를 노출하였다.</p>
<ul>
<li><strong>재앙적 망각 (Catastrophic Forgetting):</strong> 신경망은 본질적으로 새로운 데이터를 학습할 때 기존 가중치를 변경하려는 성질이 있다. SLAM 환경에서 로봇이 새로운 방으로 이동하여 새로운 장면을 학습하면, 네트워크는 이전 방의 형상 정보를 덮어쓰거나 잊어버리는 경향을 보인다. iMAP은 이를 방지하기 위해 과거의 모든 키프레임을 리플레이 버퍼(Replay Buffer)에 넣고 지속적으로 함께 학습시키는 방식을 택했다.1 그러나 탐색 영역이 넓어질수록 키프레임 수가 증가하고, 제한된 연산 자원 내에서 리플레이해야 할 데이터의 양이 감당할 수 없을 정도로 늘어나게 된다. 이는 결국 맵의 품질 저하로 이어진다.</li>
<li><strong>표현력의 병목 (Capacity Bottleneck):</strong> 단일 MLP는 고정된 용량(Capacity)을 가진다. 맵의 크기가 커지거나 장면의 디테일이 복잡해질수록, 제한된 파라미터로 모든 정보를 표현하기 어려워진다. 결과적으로 텍스처가 뭉개지거나(Over-smoothing), 미세한 기하학적 구조가 평탄화되는 현상이 발생한다. 이는 정밀한 조작이나 인식이 필요한 로봇 애플리케이션에서 치명적일 수 있다.4</li>
<li><strong>전역 업데이트의 비효율성:</strong> 국소적인 영역(예: 책상 위)의 변화를 학습하기 위해서도 전체 네트워크 가중치를 업데이트해야 하므로, 업데이트의 영향이 맵 전체에 파급될 수 있다. 이는 대규모 환경으로의 확장을 가로막는 주요 원인이 된다.</li>
</ul>
<h3>0.3  NICE-SLAM: 계층적 특징 그리드를 통한 확장성 및 정밀도 확보</h3>
<p>NICE-SLAM(“NICE-SLAM: Neural Implicit Scalable Encoding for SLAM” 4)은 iMAP이 직면한 확장성과 정밀도 문제를 근본적으로 해결하기 위해 제안된 시스템이다. NICE-SLAM의 핵심 아이디어는 단일 거대 MLP 대신, 3차원 공간을 명시적으로 분할하는 **계층적 특징 그리드(Hierarchical Feature Grids)**와 이를 처리하는 작은 MLP 디코더들을 결합한 하이브리드 표현 방식을 채택한 것이다.</p>
<h4>0.3.1  계층적 특징 그리드 아키텍처 (Hierarchical Feature Grid Architecture)</h4>
<p>NICE-SLAM은 장면 정보를 신경망 가중치가 아닌, 3차원 공간상의 격자(Grid) 점들에 저장된 ‘잠재 특징 벡터(Latent Feature Vector)’ 형태로 분산 저장한다. 이 구조는 다해상도(Multi-resolution) 접근 방식을 취하며, 다음과 같은 세 가지 레벨의 그리드로 구성된다.4</p>
<ul>
<li><strong>거친 레벨 그리드 (Coarse-level Grid, <span class="math math-inline">\phi^{coarse}</span>):</strong> 매우 낮은 해상도의 복셀 그리드로, 장면의 전반적인 구조(벽, 천장, 바닥 등 거시적 기하학)를 포착한다. 이 레벨은 관측되지 않은 영역에 대한 형상을 예측(Hole-filling)하고, 빠른 카메라 움직임이나 프레임 손실 시에도 추적을 잃지 않도록 돕는 전역적인 안내자 역할을 한다. NICE-SLAM은 이 레벨을 통해 iMAP과 유사한 예측 능력을 유지하면서도 강건성을 확보한다.</li>
<li><strong>중간 레벨 그리드 (Mid-level Grid, <span class="math math-inline">\phi^{mid}</span>):</strong> 중간 해상도의 그리드로, 가구와 같은 물체의 일반적인 형상을 표현한다.</li>
<li><strong>미세 레벨 그리드 (Fine-level Grid, <span class="math math-inline">\phi^{fine}</span>):</strong> 고해상도 그리드로, 물체의 텍스처, 모서리, 작은 요철 등 고주파수 세부 정보를 정밀하게 저장한다.</li>
</ul>
<p>각 레벨의 특징 벡터들은 해당 위치의 3차원 좌표에 대해 삼선형 보간(Trilinear Interpolation)을 통해 추출되며, 이후 각각에 대응하는 작은 MLP 디코더(<span class="math math-inline">f_{coarse}, f_{mid}, f_{fine}</span>)를 통과하여 점유도(Occupancy) 값으로 변환된다. 최종적인 점유도 <span class="math math-inline">o(\mathbf{p})</span>는 각 레벨의 출력을 합산하는 잔차(Residual) 연결 방식으로 구성된다.<br />
<span class="math math-display">
o(\mathbf{p}) = f_{coarse}(\mathbf{p}, \phi^{coarse}) + f_{mid}(\mathbf{p}, \phi^{mid}) + f_{fine}(\mathbf{p}, \phi^{fine})
</span><br />
이러한 계층적 구조는 시스템이 거시적인 구조부터 미세한 디테일가지 단계적으로 학습하도록 유도하며, 단일 MLP가 겪는 스펙트럼 편향(Spectral Bias) 문제를 구조적으로 완화한다.4</p>
<h4>0.3.2  국소적 업데이트를 통한 확장성 실현 (Local Updates and Scalability)</h4>
<p>NICE-SLAM의 가장 혁신적인 기여는 <strong>국소적 업데이트(Local Updates)</strong> 메커니즘에 있다. iMAP이 새로운 데이터를 학습할 때 전체 네트워크를 업데이트해야 했던 것과 달리, NICE-SLAM은 현재 카메라의 시야(View Frustum) 내에 존재하는 그리드 특징 벡터들만을 선택적으로 최적화한다.4</p>
<p>이 방식은 다음과 같은 결정적인 이점을 제공한다:</p>
<ul>
<li><strong>연산 효율성:</strong> 맵의 전체 크기가 아무리 커져도, 한 번의 업데이트 단계에서 최적화해야 할 파라미터(특징 벡터)의 수는 현재 보이는 영역의 크기에 비례하므로 일정하게 유지된다. 이는 대규모 아파트 단지나 건물 전체와 같은 넓은 공간에서도 일정한 속도로 실시간 SLAM을 수행할 수 있게 한다.4</li>
<li><strong>재앙적 망각의 근원적 해결:</strong> 정보가 공간적으로 분리된 그리드 셀에 저장되므로, 부엌을 매핑하는 동안 거실에 해당하는 그리드 셀은 업데이트되지 않는다. 따라서 물리적으로 떨어진 공간의 정보가 서로 간섭하지 않아 재앙적 망각 문제가 자연스럽게 해결된다.</li>
</ul>
<h4>0.3.3  사전 학습된 기하학적 사전 정보의 활용 (Pre-trained Geometric Priors)</h4>
<p>iMAP이 매번 처음부터(From Scratch) 장면을 학습해야 했던 반면, NICE-SLAM은 <strong>사전 학습된 디코더</strong>를 활용한다. ‘ConvONet’ 8 등의 연구에서 영감을 받아, 다양한 실내 환경 데이터셋에서 기하학적 특징을 추출하는 방법을 미리 학습한 디코더를 초기값으로 사용한다. 이는 학습 초기 단계에서부터 기하학적으로 타당한 표면을 생성하도록 유도하며, 수렴 속도를 높이고 노이즈가 많은 관측 데이터에서도 안정적인 복원을 가능하게 한다. 특히 미세 레벨 디코더는 학습 과정에서 고정하거나 미세 조정(Fine-tuning)하는 전략을 통해 일반화 성능과 특화 성능 사이의 균형을 맞춘다.4</p>
<h4>0.3.4  최적화 및 추적 전략</h4>
<p>NICE-SLAM 역시 iMAP과 유사하게 추적과 매핑 스레드를 분리하여 운영하지만, 최적화 대상이 다르다. 추적 시에는 특징 그리드를 고정한 채 카메라 포즈만을 업데이트하고, 매핑 시에는 키프레임 포즈와 함께 <strong>특징 그리드의 값</strong>을 업데이트한다. 이때, 최적화는 픽셀 단위의 광도 손실(Photometric Loss)과 깊이 손실(Geometric Loss)을 최소화하는 방향으로 이루어진다.<br />
<span class="math math-display">
\mathcal{L} = \mathcal{L}_{photo} + \lambda \mathcal{L}_{geo}
</span><br />
여기서 깊이 손실 <span class="math math-inline">\mathcal{L}_{geo}</span>는 렌더링된 깊이와 센서 측정 깊이 간의 L1 차이를 사용하며, 이는 기하학적 구조를 빠르게 잡아주는 핵심 제약 조건이 된다. NICE-SLAM은 특히 렌더링 시 발생하는 계산 비용을 줄이기 위해, 의미 있는 표면 근처에서만 샘플링을 수행하는 효율적인 레이 마칭(Ray Marching) 전략을 사용한다.4</p>
<h3>0.4  iMAP과 NICE-SLAM의 심층 비교 분석 및 평가</h3>
<p>이 절에서는 두 시스템의 아키텍처, 성능, 그리고 실제 로봇 응용 관점에서의 장단점을 심층적으로 비교 분석한다. 이를 위해 Replica, ScanNet 등의 표준 벤치마크 데이터셋에서의 정량적 결과를 참조한다.</p>
<h4>0.4.1  아키텍처 및 메모리 효율성 비교</h4>
<table><thead><tr><th><strong>비교 항목</strong></th><th><strong>iMAP</strong></th><th><strong>NICE-SLAM</strong></th></tr></thead><tbody>
<tr><td><strong>장면 표현 방식</strong></td><td>단일 MLP (전역적 암시적 함수)</td><td>계층적 특징 그리드 + 소형 MLP (국소적)</td></tr>
<tr><td><strong>파라미터 특성</strong></td><td>고정 크기 (약 1MB, Compact)</td><td>맵 크기에 비례하여 증가 (수십 MB 이상)</td></tr>
<tr><td><strong>업데이트 메커니즘</strong></td><td>전역 업데이트 (모든 가중치 변경)</td><td>국소 업데이트 (시야 내 그리드만 변경)</td></tr>
<tr><td><strong>데이터 의존성</strong></td><td>전체 키프레임 리플레이 필수</td><td>현재 및 인접 키프레임만 필요</td></tr>
<tr><td><strong>공간 확장성</strong></td><td>방(Room) 규모로 제한됨</td><td>대규모(Apartment) 환경으로 확장 가능</td></tr>
<tr><td><strong>학습 초기화</strong></td><td>무작위 초기화 (From Scratch)</td><td>사전 학습된 기하학적 사전 정보 활용</td></tr>
</tbody></table>
<p>iMAP은 극도로 적은 메모리(약 1MB 이하)로 방 하나를 표현할 수 있다는 점에서 메모리 제약이 심한 소형 로봇이나 임베디드 시스템에 유리할 수 있다. 그러나 이는 표현력의 한계로 직결된다. 반면 NICE-SLAM은 그리드 구조로 인해 메모리 사용량이 맵의 크기에 비례하여 증가하지만, 현대의 GPU 메모리 용량을 고려할 때 감당 가능한 수준이며, 그 대가로 훨씬 높은 정밀도와 확장성을 제공한다.11</p>
<h4>0.4.2  재구성 품질 (Reconstruction Quality) 및 정밀도</h4>
<p>정량적 평가 지표인 깊이 L1 오차(Depth L1), 정확도(Accuracy), 완성도(Completeness) 측면에서 NICE-SLAM은 iMAP을 압도한다. Replica 데이터셋 실험 결과, NICE-SLAM은 평균 3.53cm의 깊이 오차를 기록한 반면, iMAP은 7.64cm를 기록하여 약 2배 이상의 정밀도 차이를 보였다.9</p>
<ul>
<li><strong>세밀함(Detail)과 선명도(Sharpness):</strong> iMAP 결과물은 벽과 바닥의 연결부위나 작은 물체의 모서리가 둥글게 뭉개지는 ‘과도한 평활화(Over-smoothing)’ 현상을 보인다. 이는 단일 MLP가 저주파수 성분을 우선적으로 학습하는 경향 때문이다. 반면 NICE-SLAM은 미세 레벨 그리드가 고주파수 정보를 전담하여 처리하므로, 책상의 다리나 물체의 질감과 같은 디테일을 훨씬 선명하게 복원한다.14</li>
<li><strong>완성도(Completeness):</strong> NICE-SLAM은 89.33%의 완성도 비율을 보인 반면 iMAP은 66.60%에 그쳤다. 이는 NICE-SLAM이 국소적인 디테일을 놓치지 않고 맵에 반영함을 의미한다.</li>
</ul>
<h4>0.4.3  추적 강건성 (Tracking Robustness) 및 예측 능력</h4>
<p>두 시스템 모두 암시적 표현의 장점인 ’예측 능력(Predictive Ability)’을 공유한다. 즉, 관측되지 않은 물체의 뒷면이나 가려진 영역에 대해 구멍(Hole)을 남기지 않고 부드럽게 채워진(Watertight) 표면을 생성한다.</p>
<ul>
<li><strong>프레임 손실 대응:</strong> 로봇이 빠르게 회전하거나 통신 문제로 프레임이 손실되는 상황에서, NICE-SLAM의 거친 레벨 그리드는 훌륭한 기하학적 추정치를 제공하여 추적 실패를 방지한다. 실험적으로 프레임이 대거 손실된 시나리오에서 iMAP은 추적을 놓치고 맵이 망가지는 반면, NICE-SLAM은 거친 그리드의 정보를 바탕으로 포즈를 성공적으로 복구하는 강건함을 보였다.4</li>
<li><strong>동적 환경:</strong> iMAP과 NICE-SLAM 모두 기본적으로 정적 환경을 가정하지만, NICE-SLAM은 국소적 업데이트 특성 덕분에 움직이는 물체가 지나간 자리에 잘못된 흔적(Ghosting)이 남아도 해당 영역이 다시 관측되면 빠르게 수정될 수 있다. 반면 iMAP은 한 번 잘못 학습된 정보가 전체 네트워크에 영향을 미쳐 복구가 더 어렵다.4</li>
</ul>
<h4>0.4.4  계산 복잡도와 실시간성 분석</h4>
<ul>
<li><strong>iMAP:</strong> 추적(10Hz)과 매핑(2Hz) 속도를 유지하는 것이 목표이다. 그러나 맵이 커질수록 리플레이 버퍼에서 샘플링해야 하는 키프레임의 다양성이 증가해야 하므로, 정보 유지를 위한 연산 부담이 커진다. 즉, 맵의 크기가 커지면 실시간성을 유지하기 위해 학습 품질을 희생해야 하는 트레이드오프가 발생한다.</li>
<li><strong>NICE-SLAM:</strong> 그리드 기반의 국소적 업데이트는 맵의 전체 크기와 무관하게 일정한(Constant) 연산 부하를 보장한다. 이는 대규모 환경 탐색 시 로봇의 제어 루프를 안정적으로 유지하는 데 필수적인 특성이다. 단, 복셀 그리드를 관리하고 쿼리하는 과정에서 발생하는 메모리 접근 오버헤드는 iMAP보다 클 수 있다.9</li>
</ul>
<h3>0.5  기술적 심층 분석: 손실 함수와 최적화 역학</h3>
<p>두 시스템의 성능 차이를 만드는 근본적인 원인은 최적화 과정의 역학(Dynamics)에 있다. 이를 수학적으로 더 깊이 들여다볼 필요가 있다.</p>
<p>두 시스템 모두 다음과 같은 형태의 손실 함수를 최소화한다.<br />
<span class="math math-display">
\mathcal{L} = \sum_{\mathbf{r} \in \mathcal{R}} \left( |\hat{\mathbf{C}}(\mathbf{r}) - \mathbf{C}_{gt}(\mathbf{r})| + \lambda |\hat{D}(\mathbf{r}) - D_{gt}(\mathbf{r})| \right)
</span><br />
여기서 <span class="math math-inline">\mathcal{R}</span>은 샘플링된 광선(Ray)의 집합이다. 차이점은 그래디언트의 흐름에 있다.</p>
<ul>
<li>
<p>iMAP의 그래디언트 흐름:<br />
<span class="math math-display">
\frac{\partial \mathcal{L}}{\partial \theta} = \sum_{\mathbf{r}} \frac{\partial \mathcal{L}}{\partial \hat{\mathbf{C}}} \frac{\partial \hat{\mathbf{C}}}{\partial \theta} + \dots
</span><br />
iMAP에서는 모든 픽셀의 오차가 단일 파라미터 세트 <span class="math math-inline">\theta</span>로 역전파된다. 이는 서로 다른 위치의 정보들이 <span class="math math-inline">\theta</span>를 공유하며 경쟁(Interference)하게 만든다. 이 경쟁은 학습을 불안정하게 만들고 망각을 유발하는 주원인이다.</p>
</li>
<li>
<p>NICE-SLAM의 그래디언트 흐름:<br />
<span class="math math-display">
\frac{\partial \mathcal{L}}{\partial \phi_i} = \sum_{\mathbf{r} \in \mathcal{V}_i} \frac{\partial \mathcal{L}}{\partial \hat{\mathbf{C}}} \frac{\partial \hat{\mathbf{C}}}{\partial \phi_i} + \dots
</span><br />
NICE-SLAM에서는 특정 복셀 <span class="math math-inline">i</span>를 통과하는 광선들만이 해당 복셀의 특징 벡터 <span class="math math-inline">\phi_i</span>에 그래디언트를 전달한다 (<span class="math math-inline">\mathcal{V}_i</span>는 복셀 <span class="math math-inline">i</span>를 통과하는 광선 집합). 이는 전체 최적화 문제를 수만 개의 작은 독립적인 최적화 문제로 분해(Decouple)하는 효과를 낳는다. 이러한 분해는 수렴 속도를 비약적으로 높이고 상호 간섭을 제거하여 학습의 안정성을 보장한다.</p>
</li>
</ul>
<h3>0.6  한계점 및 향후 발전 방향</h3>
<p>iMAP과 NICE-SLAM은 신경망 기반 SLAM의 획기적인 발전을 이끌었지만, 여전히 해결해야 할 과제들이 존재하며 이는 후속 연구들의 동기가 되고 있다.</p>
<ol>
<li><strong>순수 RGB SLAM의 어려움과 깊이 의존성:</strong> 두 시스템 모두 깊이(Depth) 센서 입력에 크게 의존한다. 깊이 정보는 기하학적 구조를 직접적으로 제약하여 수렴을 돕는 결정적인 역할을 한다. 깊이 센서 없이 RGB 이미지만으로 작동하는 경우(NICER-SLAM 등), 깊이의 모호성(Ambiguity)으로 인해 수렴이 매우 어렵고 시간이 오래 걸린다.17</li>
<li><strong>동적 객체 처리의 한계:</strong> 여전히 움직이는 사람이나 물체는 맵에 노이즈를 남기거나 추적 오차를 유발한다. 최근 연구들은 의미론적 분할(Semantic Segmentation)이나 광학 흐름(Optical Flow)을 결합하여 동적 객체를 마스킹(Masking)하거나 별도로 추적하는 방향으로 발전하고 있다.18</li>
<li><strong>메모리 효율성의 추가 개선:</strong> NICE-SLAM의 밀집 그리드는 빈 공간(Free Space)에도 특징 벡터를 할당하므로 메모리 낭비가 있다. 이를 개선하기 위해 복셀 해싱(Voxel Hashing) 기법을 적용한 Sparse NICE-SLAM 20이나 옥트리(Octree) 기반의 접근법(ESLAM, Vox-Fusion) 21 등이 제안되어 메모리 효율과 검색 속도를 동시에 개선하고 있다.</li>
<li><strong>고속 동작 및 이벤트 카메라 결합:</strong> 매우 빠른 움직임에서는 RGB 이미지의 모션 블러(Motion Blur)로 인해 추적이 실패할 수 있다. 이를 극복하기 위해 마이크로초 단위의 해상도를 가진 이벤트 카메라(Event Camera)를 NICE-SLAM 구조에 통합하여 초고속 SLAM을 구현하려는 시도(EvenNICER-SLAM)가 등장하고 있다.22</li>
</ol>
<h3>0.7  결론: 공간 AI를 향한 진화</h3>
<p>iMAP이 신경망을 이용한 실시간 SLAM의 ’가능성’을 증명했다면, NICE-SLAM은 이를 ’확장 가능하고 실용적인 수준’으로 끌어올린 이정표적인 기술이다. iMAP의 전역적 MLP 표현 방식에서 NICE-SLAM의 <strong>계층적 특징 그리드</strong> 방식으로의 전환은, 딥러닝 모델이 3차원 공간 정보를 다루는 방식이 ’기억(Memorization)’에서 ’구조적 표현(Structured Representation)’으로 진화했음을 의미한다.</p>
<p>이러한 기술적 진보는 로봇이 단순히 자신의 위치를 파악하는 수준을 넘어, 환경을 밀집되고 연속적이며 의미론적으로 풍부하게 이해하는 ’공간 AI(Spatial AI)’로 나아가는 토대를 마련하였다. 향후 로봇 제어 시스템은 이러한 고정밀 암시적 지도를 활용하여 복잡한 비정형 환경에서도 정밀한 조작(Manipulation)과 안전한 내비게이션을 수행할 수 있을 것으로 기대된다. 특히 특징 그리드에 의미론적 정보(Semantics)나 물리적 속성(Physics)을 추가로 임베딩함으로써, 로봇이 환경과 상호작용하는 능력을 비약적으로 향상시키는 연구가 가속화될 것이다.</p>
<h2>1. 참고 문헌 요약 (주요 논문)</h2>
<ul>
<li>1 Sucar et al., “iMAP: Implicit Mapping and Positioning in Real-Time”, ICCV 2021.</li>
<li>4 Zhu et al., “NICE-SLAM: Neural Implicit Scalable Encoding for SLAM”, CVPR 2022.</li>
<li>1 Sucar et al., “iMAP: Implicit Mapping and Positioning in Real-Time”, arXiv preprint, 2021. (Detailed analysis)</li>
<li>13 Wang et al., “Co-SLAM: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM”, CVPR 2023.</li>
</ul>
<h2>2. 참고 자료</h2>
<ol>
<li>iMAP: Implicit Mapping and Positioning in Real-Time, https://openaccess.thecvf.com/content/ICCV2021/papers/Sucar_iMAP_Implicit_Mapping_and_Positioning_in_Real-Time_ICCV_2021_paper.pdf</li>
<li>An Efficient Strategy for Catastrophic Forgetting Reduction in … - MDPI, https://www.mdpi.com/2079-9292/12/10/2265</li>
<li>Understanding Catastrophic Forgetting and Remembering in …, https://openreview.net/forum?id=Pvqe_hQEXTJ</li>
<li>NICE-SLAM: Neural Implicit Scalable Encoding for SLAM, https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_NICE-SLAM_Neural_Implicit_Scalable_Encoding_for_SLAM_CVPR_2022_paper.pdf</li>
<li>iMAP: Implicit Mapping and Positioning in Real-Time - Edgar Sucar, https://edgarsucar.github.io/iMAP/</li>
<li>arXiv:2112.12130v1 [cs.CV] 22 Dec 2021, https://arxiv.org/pdf/2112.12130</li>
<li>NICE-SLAM: Neural Implicit Scalable Encoding for SLAM, https://pengsongyou.github.io/media/nice-slam/NICE-SLAM.pdf</li>
<li>NICE-SLAM: Neural Implicit Scalable Encoding for SLAM, https://neuralfields.cs.brown.edu/paper_312.html</li>
<li>NICE-SLAM: Neural Implicit Scalable Encoding for SLAM - Liner, https://liner.com/review/niceslam-neural-implicit-scalable-encoding-for-slam</li>
<li>Supplementary Material for NICE-SLAM: Neural Implicit Scalable …, https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_NICE-SLAM_Neural_Implicit_CVPR_2022_supplemental.pdf</li>
<li>NGEL-SLAM: Neural Implicit Representation-based Global … - arXiv, https://arxiv.org/html/2311.09525v2</li>
<li>MeSLAM: Memory Efficient SLAM based on Neural Fields - arXiv, https://arxiv.org/pdf/2209.09357</li>
<li>Supplementary Material Co-SLAM: Joint Coordinate and Sparse …, https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Co-SLAM_Joint_Coordinate_CVPR_2023_supplemental.pdf</li>
<li>NICE-SLAM - Songyou Peng, https://pengsongyou.github.io/nice-slam</li>
<li>[PDF] NICE-SLAM: Neural Implicit Scalable Encoding for SLAM, https://www.semanticscholar.org/paper/NICE-SLAM%3A-Neural-Implicit-Scalable-Encoding-for-Zhu-Peng/18ba8f0efb362e08903e8e35b062e2c69126e371</li>
<li>[CVPR’22] NICE-SLAM: Neural Implicit Scalable Encoding for SLAM, https://github.com/cvg/nice-slam</li>
<li>NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM, https://www.cvlibs.net/publications/Zhu2024THREEDV.pdf</li>
<li>arXiv:2311.11016v3 [cs.RO] 28 Mar 2024, https://arxiv.org/pdf/2311.11016</li>
<li>Multi-MLPs Neural Implicit Representation SLAM for Dynamic …, https://ieeexplore.ieee.org/iel8/6287639/10820123/10879339.pdf</li>
<li>[PDF] NICE-SLAM with Adaptive Feature Grids - Semantic Scholar, https://www.semanticscholar.org/paper/eb641b8343093d0909a546956d22b61f1d3c0a5c</li>
<li>(PDF) ESLAM: Efficient Dense SLAM System Based on Hybrid …, https://www.researchgate.net/publication/365633132_ESLAM_Efficient_Dense_SLAM_System_Based_on_Hybrid_Representation_of_Signed_Distance_Fields</li>
<li>EvenNICER-SLAM: Event-based Neural Implicit Encoding SLAM, https://arxiv.org/html/2410.03812v1</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>