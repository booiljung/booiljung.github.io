<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.7 로봇 제어와 행동을 위한 뉴럴 표현</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.7 로봇 제어와 행동을 위한 뉴럴 표현</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 5. 뉴럴 3D 표현과 렌더링 (Neural 3D Representations)</a> / <a href="index.html">5.7 로봇 제어와 행동을 위한 뉴럴 표현</a> / <span>5.7 로봇 제어와 행동을 위한 뉴럴 표현</span></nav>
                </div>
            </header>
            <article>
                <h1>5.7 로봇 제어와 행동을 위한 뉴럴 표현</h1>
<p>전통적인 로봇 공학의 패러다임에서 ‘인식(Perception)’, ‘계획(Planning)’, ’제어(Control)’는 명확히 구분된 모듈로 취급되었다. 인식 모듈이 센서 데이터를 처리하여 상태(State)를 추정하면, 계획 모듈이 경로를 생성하고, 제어 모듈이 이를 추종하는 계층적 구조는 지난 수십 년간 로봇 소프트웨어 아키텍처의 표준이었다. 그러나 이러한 이산적이고 모듈화된 접근 방식은 각 단계 간의 정보 손실과 오차 전파 문제를 야기한다. 특히 비정형 환경에서의 복잡한 상호작용이나 고차원 데이터를 다룰 때, 명시적인 상태 추정(Explicit State Estimation)은 종종 병목 현상을 일으킨다.</p>
<p>최근 등장한 뉴럴 필드(Neural Fields)와 암시적 표현(Implicit Representations)은 이러한 고전적 파이프라인의 경계를 허물고 있다. 3D 공간을 연속적인 함수로 매개변수화하는 뉴럴 표현은 미분 가능성(Differentiability)이라는 강력한 수학적 특성을 제공한다. 이는 인식에서 제어에 이르는 전체 과정을 하나의 최적화 문제로 통합할 수 있게 하며, 시각적 피드백을 제어 신호로 직접 역전파(Backpropagation)하는 종단간(End-to-End) 학습을 가능하게 한다.</p>
<p>본 장에서는 뉴럴 표현이 로봇의 행동 생성과 제어 이론을 어떻게 재정의하고 있는지 심층적으로 분석한다. 정밀한 위치 추정을 위한 역전파 기반의 최적화 기법부터, 충돌 없는 궤적 생성을 위한 뉴럴 SDF(Signed Distance Functions), 동적 조작을 위한 3D Gaussian Splatting(3DGS)의 응용, 그리고 미분 가능한 물리학 시뮬레이션과의 통합에 이르기까지, 최신 SOTA(State-of-the-Art) 기술들의 이론적 배경과 실용적 가치를 포괄적으로 다룬다.</p>
<h2>1.  뉴럴 필드 기반의 6DoF 자세 추정 및 최적화</h2>
<p>로봇이 환경 내에서 자신의 위치와 자세(Pose)를 파악하는 것은 자율 행동의 전제 조건이다. 전통적인 위치 추정은 특징점(Feature Point) 매칭이나 ICP(Iterative Closest Point) 알고리즘에 의존했으나, 이는 텍스처가 부족하거나 반사가 심한 표면에서 강인하지 못했다. 뉴럴 필드는 ’합성을 통한 분석(Analysis-by-Synthesis)’이라는 새로운 패러다임을 제시하며, 렌더링된 이미지와 관측된 이미지의 차이를 최소화하는 최적화 문제로 자세 추정을 공식화한다.</p>
<h3>1.1  iNeRF: 역전파를 통한 자세의 정밀 보정</h3>
<p>iNeRF(Inverting Neural Radiance Fields)는 사전 학습된 NeRF 모델을 고정(Freeze)한 상태에서 카메라의 6자유도(6DoF) 자세를 추정하는 선구적인 연구이다. 일반적인 NeRF 학습이 카메라 자세 <span class="math math-inline">T</span>와 이미지 <span class="math math-inline">I</span>를 알고 장면 파라미터 <span class="math math-inline">\Theta</span>를 최적화하는 과정이라면, iNeRF는 <span class="math math-inline">\Theta</span>와 관측된 이미지 <span class="math math-inline">I_{obs}</span>가 주어졌을 때 최적의 자세 <span class="math math-inline">\hat{T}</span>를 역으로 추론한다.</p>
<p>이 문제는 다음과 같은 최적화 수식으로 표현된다.<br />
<span class="math math-display">
\hat{T} = \underset{T \in SE(3)}{\text{argmin}} \sum_{r \in \mathcal{R}} \mathcal{L}(C(r \vert T, \Theta), C_{obs}(r))
</span><br />
여기서 <span class="math math-inline">\mathcal{R}</span>은 샘플링된 광선(Ray)의 집합, <span class="math math-inline">C(r \vert T, \Theta)</span>는 자세 <span class="math math-inline">T</span>에서 렌더링된 픽셀 색상, <span class="math math-inline">C_{obs}(r)</span>는 실제 관측된 픽셀 색상, <span class="math math-inline">\mathcal{L}</span>은 손실 함수(주로 MSE)를 의미한다. 핵심은 NeRF의 볼륨 렌더링 과정이 미분 가능하다는 점이다. 따라서 픽셀 단위의 잔차(Residual)로부터 카메라 자세 <span class="math math-inline">T</span>에 대한 기울기(Gradient) <span class="math math-inline">\nabla_T \mathcal{L}</span>을 직접 계산하여 경사 하강법(Gradient Descent)으로 자세를 보정할 수 있다.</p>
<h4>1.1.1 Lie 대수 기반의 자세 업데이트</h4>
<p>수학적으로 카메라의 자세는 <span class="math math-inline">SE(3)</span> 공간에 존재하므로, 단순한 행렬 덧셈으로 업데이트할 수 없다. iNeRF는 Lie 대수 <span class="math math-inline">\mathfrak{se}(3)</span> 상에서 파라미터 업데이트를 수행한 후 지수 맵(Exponential Map)을 통해 <span class="math math-inline">SE(3)</span>로 변환하는 방식을 취한다.<br />
<span class="math math-display">
T_{i+1} = \exp(\xi^\wedge) T_i
</span><br />
여기서 <span class="math math-inline">\xi \in \mathbb{R}^6</span>는 최적화 단계에서의 업데이트 벡터(트위스트)이며, <span class="math math-inline">\wedge</span> 연산자는 벡터를 왜대칭 행렬(Skew-symmetric matrix)로 변환한다. 이러한 방식은 회전 행렬의 직교성(Orthogonality)을 보장하면서 자연스러운 최적화 궤적을 생성한다.</p>
<p>iNeRF 연구진은 효율적인 최적화를 위해 ‘관심 영역 샘플링(Interest Region Sampling)’ 전략을 도입했다. 전체 이미지를 렌더링하는 대신, 객체가 존재하거나 엣지(Edge)와 같이 정보량이 많은 영역의 픽셀만을 선별적으로 샘플링함으로써, 계산 비용을 줄이면서도 수렴 속도를 높였다. 실험 결과, iNeRF는 텍스처가 없는 물체나 복잡한 형상을 가진 물체에 대해서도 기존의 특징점 기반 방식보다 우수한 추정 성능을 보였다.</p>
<h3>1.2  초기화 민감성 문제와 몬테카를로 접근법</h3>
<p>경사 하강법 기반의 자세 추정은 초기값(Initialization)에 매우 민감하다는 고질적인 문제를 안고 있다. 초기 추정 자세가 실제 자세와 너무 동떨어져 있으면, 렌더링된 이미지와 관측 이미지 간의 겹치는 영역(Overlap)이 없어 기울기가 0이 되거나 잘못된 국소 최적해(Local Minima)에 빠지기 쉽다. 이는 볼륨 렌더링의 비용 함수가 자세 파라미터에 대해 매우 비볼록(Non-convex)하기 때문이다.</p>
<p>이를 해결하기 위해 몬테카를로(Monte Carlo) 샘플링과 분리된 최적화(Decoupled Optimization) 기법이 제안되었다.</p>
<ol>
<li><strong>가설 생성 및 평가:</strong> 입력된 초기 자세 주변으로 회전과 평행 이동에 무작위 노이즈를 추가하여 <span class="math math-inline">K</span>개의 가설 자세군을 생성한다. 이후 각 자세에서 저해상도 이미지를 렌더링하거나 특징점 매칭 점수를 계산하여 가장 유망한 가설을 선택한다.</li>
<li><strong>회전과 평행 이동의 분리:</strong> 회전(Rotation)과 평행 이동(Translation)은 이미지 상에서 픽셀을 이동시키는 양상이 다르다. 이를 하나의 손실 함수로 묶으면 최적화의 균형이 무너지기 쉽다. 따라서 회전 최적화에는 소실점이나 평행선과 같은 기하학적 특징을 강조하는 손실 함수를, 평행 이동에는 픽셀 간 평균 거리 손실을 적용하는 등 목적 함수를 분리하여 수렴 안정성을 높인다.</li>
</ol>
<h3>1.3  RGB-D 융합을 통한 강인성 확보: BID-NeRF</h3>
<p>RGB 이미지만을 사용할 경우, 조명 변화나 텍스처가 없는 단색 표면에서 위치 추정의 모호성(Ambiguity)이 발생할 수 있다. 로봇은 주행 중 벽면이나 바닥과 같이 특징이 부족한 환경을 자주 마주치기 때문에 이는 치명적일 수 있다. BID-NeRF와 같은 연구는 깊이(Depth) 정보를 통합하여 이러한 문제를 해결한다.<br />
<span class="math math-display">
\mathcal{L}(T) = \mathcal{L}_{RGB}(T) + \lambda \mathcal{L}_{Depth}(T)
</span><br />
여기서 <span class="math math-inline">\mathcal{L}_{Depth}</span>는 렌더링된 깊이 값과 센서로 측정된 깊이 값 사이의 차이를 나타낸다. NeRF는 밀도(Density) <span class="math math-inline">\sigma</span>를 통해 깊이 기댓값을 미분 가능한 형태로 산출할 수 있다.<br />
<span class="math math-display">
\hat{d}(r) = \sum_{i=1}^N T_i (1 - \exp(-\sigma_i \delta_i)) t_i
</span><br />
깊이 정보는 기하학적 구속 조건(Geometric Constraint)을 강력하게 제공하므로, 텍스처가 없는 영역에서도 최적화가 올바른 방향으로 진행되도록 유도한다. 실험 결과, 깊이 정보를 통합했을 때 수렴 속도가 비약적으로 향상되었으며, 초기 위치 오차가 큰 경우에도 성공적으로 자세를 복원할 수 있었다.</p>
<h2>2.  안전한 내비게이션을 위한 뉴럴 SDF와 궤적 최적화</h2>
<p>로봇이 동적인 환경에서 이동할 때 가장 중요한 요소는 충돌 회피(Collision Avoidance)이다. 뉴럴 필드, 특히 부호 있는 거리 함수(Signed Distance Function, SDF)는 공간 내 임의의 점에 대해 가장 가까운 장애물까지의 거리를 연속적인 값으로 제공함으로써 궤적 최적화 문제를 획기적으로 단순화한다.</p>
<h3>2.1  연속적 충돌 비용 함수로서의 Neural SDF</h3>
<p>전통적인 방식은 점유 격자 지도(Occupancy Grid Map)나 복셀 맵을 사용했다. 이러한 이산적 표현은 해상도의 한계로 인해 계단 현상이 발생하며, 최적화 과정에서 미분 불가능한 지점이 생겨 경사 기반 방식(Gradient-based Method)을 적용하기 어려웠다. 반면, 신경망으로 학습된 Neural SDF는 공간 전체에 대해 <span class="math math-inline">C^1</span> 연속성을 가지며 미분 가능한 거리 값을 반환한다.</p>
<p>SDF 값 <span class="math math-inline">f(x)</span>는 표면 내부에서 음수, 외부에서 양수 값을 가진다. 이를 이용하여 충돌 비용 함수 <span class="math math-inline">J_{collision}</span>을 정의할 수 있다.<br />
<span class="math math-display">
J_{collision}(\mathbf{q}) = \sum_{t} \max(0, \epsilon - \text{SDF}(\text{FK}(\mathbf{q}_t)))
</span><br />
여기서 <span class="math math-inline">\mathbf{q}_t</span>는 시간 <span class="math math-inline">t</span>에서의 로봇 관절 각도, <span class="math math-inline">\text{FK}(\cdot)</span>는 순기구학(Forward Kinematics) 함수, <span class="math math-inline">\epsilon</span>은 안전 마진이다. 이 비용 함수는 미분 가능하므로, 최적화 알고리즘(예: iLQR, TrajOpt)은 SDF의 기울기 <span class="math math-inline">\nabla_x \text{SDF}(x)</span>를 이용하여 충돌을 회피하는 방향으로 궤적을 수정할 수 있다. 특히 SDF의 기울기는 장애물 표면의 법선 벡터(Normal Vector)에 해당하므로, 로봇을 장애물로부터 밀어내는 최적의 방향을 제시한다.</p>
<h3>2.2  듀얼 모드 파이프라인과 합성 SDF</h3>
<p>로봇 자체의 형상 또한 복잡하기 때문에, 로봇과 환경 간의 충돌을 정밀하게 검사하는 것은 계산 비용이 높다. 이를 해결하기 위해 로봇의 SDF와 환경의 SDF를 분리하여 처리하는 ’듀얼 모드 파이프라인(Dual Mode Pipeline)’이 제안되었다.</p>
<ul>
<li><strong>로봇 신체 SDF (Robot Body SDF):</strong> 로봇의 링크(Link)들은 강체이므로, 각 링크에 대한 SDF를 오프라인에서 미리 학습하거나 근사할 수 있다. 링크 좌표계에서의 SDF는 관절 각도에 따라 변하지 않으므로 매우 빠르게 조회 가능하다.</li>
<li><strong>장면 SDF (Scene SDF):</strong> 환경은 동적으로 변할 수 있으므로 실시간 센서 데이터로부터 업데이트되어야 한다.</li>
</ul>
<p>합성 SDF(Composite SDF) 기법은 환경을 여러 개의 독립적인 객체나 구역으로 나누어 각각 SDF를 추정하고, 전체 SDF를 개별 SDF들의 최소값으로 근사한다.<br />
<span class="math math-display">
\text{SDF}_{env}(x) \approx \min_i (\text{SDF}_i(x))
</span><br />
이 방식은 전체 맵을 매번 재학습할 필요 없이, 움직이는 장애물이나 새로 관측된 영역에 대한 SDF만 국소적으로 갱신하면 되므로 실시간 제어 루프(Control Loop) 내에서 사용하기에 적합하다. 연구 결과에 따르면, 이러한 합성 접근법은 수백 Hz의 주기로 갱신이 가능하여 로봇 팔의 실시간 회피 기동이나 고속 드론의 비행에 적용될 수 있다.</p>
<h3>2.3  뉴럴 NMPC: 잠재 공간을 이용한 맵리스 내비게이션</h3>
<p>모델 예측 제어(MPC)는 미래의 상태를 예측하여 최적의 제어 입력을 생성하는 기법이다. 뉴럴 SDF를 MPC와 결합한 ’Neural NMPC’는 명시적인 지도 작성 없이도 센서 데이터만으로 안전한 주행을 가능하게 한다.</p>
<p>이 시스템은 VAE(Variational Auto-Encoder) 구조를 활용한다. 인코더는 깊이(Depth) 이미지나 라이다 데이터를 저차원의 잠재 벡터(Latent Vector) <span class="math math-inline">z</span>로 압축한다. 디코더인 MLP 네트워크는 이 잠재 벡터와 쿼리 위치 <span class="math math-inline">x</span>를 입력받아 SDF 값을 예측한다.<br />
<span class="math math-display">
\text{SDF}_\theta(x \vert z_{obs})
</span><br />
NMPC의 최적화 문제 제약 조건으로 <span class="math math-inline">\text{SDF}*\theta(x_k \vert z_k) \ge r*{robot}</span>을 설정하면, 컨트롤러는 현재 관측된 잠재 벡터 <span class="math math-inline">z_{obs}</span>를 바탕으로 충돌 없는 미래 궤적을 계획한다. 실험에서 Neural NMPC는 숲과 같은 비정형 환경에서도 위치 추정 오차(Drift)나 센서 노이즈에 강인함을 보였으며, 약 10ms의 짧은 연산 시간으로 100Hz 이상의 제어 주기를 달성하였다. 이는 로봇이 복잡한 지도를 유지 관리할 필요 없이, 직관적인(Intuitive) 공간 이해를 바탕으로 반응형 행동을 수행할 수 있음을 시사한다.</p>
<h3>2.4  3DGS 기반의 안전 폴리토프(Safe Polytopes) 생성</h3>
<p>최근 부상한 3D Gaussian Splatting(3DGS)을 궤적 계획에 활용하려는 시도 또한 활발하다. 3DGS는 공간을 타원체 형태의 가우시안들로 채우는데, 이 가우시안들이 점유하지 않은 빈 공간(Free Space)을 찾는 것이 핵심이다. ‘안전 폴리토프(Safe Polytopes)’ 기법은 가우시안들 사이의 비어 있는 영역을 일련의 볼록 다면체(Convex Polytopes)로 정의하여 안전한 이동 통로(Corridor)를 구축한다.</p>
<p>기존의 포인트 클라우드는 희소성(Sparsity)으로 인해 장애물 사이에 가짜 통로가 생길 위험이 있었으나, 가우시안 스플랫은 부피를 가진 타원체로 장애물을 커버하므로 충돌 기하학을 더 보수적이고 안전하게 표현할 수 있다. 드론과 같은 고속 이동 로봇은 생성된 폴리토프 회랑(Corridor) 내부를 통과하도록 제약 조건을 설정함으로써, 3DGS 맵 내에서 매우 빠른 속도로 비행하면서도 안전을 보장받을 수 있다.</p>
<h2>3.  로봇 조작과 상호작용을 위한 뉴럴 필드</h2>
<p>로봇 팔을 이용한 조작(Manipulation) 작업은 단순히 충돌을 피하는 것을 넘어, 물체와의 접촉(Contact)을 유도하고 물리적 상태를 변화시키는 고차원적인 행동을 요구한다. 뉴럴 필드는 물체의 형상뿐만 아니라 파지 가능성(Affordance)이나 동역학적 반응까지 연속 함수로 모델링하여 조작 지능을 고도화하고 있다.</p>
<h3>3.1  NGDF: 파지 매니폴드의 연속적 학습</h3>
<p>전통적인 파지 합성(Grasp Synthesis)은 물체 표면에서 파지 후보군을 샘플링하고 점수를 매기는 이산적인 방식을 취했다. 반면, Neural Grasp Distance Fields(NGDF)는 파지 학습을 거리 함수 학습 문제로 재정의한다. NGDF는 로봇 엔드 이펙터의 6D 자세 <span class="math math-inline">T_{ee}</span>를 입력으로 받아, 해당 물체에 대해 유효한 파지 자세들의 집합인 ’파지 매니폴드(Grasp Manifold)’까지의 거리를 출력한다.<br />
<span class="math math-display">
f_{NGDF}(T_{ee}) = d(T_{ee}, \mathcal{M}_{grasp})
</span><br />
여기서 <span class="math math-inline">d=0</span>이 되는 지점(Zero Level Set)이 바로 성공적인 파지가 가능한 자세들이다. 이 표현 방식의 가장 큰 장점은 파지 계획을 궤적 최적화와 매끄럽게 결합할 수 있다는 점이다. 로봇의 궤적 최적화 비용 함수에 NGDF 항을 추가하면, 로봇은 장애물을 피하는 동시에 자연스럽게 파지 가능한 자세로 수렴하는 궤적을 생성하게 된다. 이는 별도의 파지 계획 단계 없이 접근(Reach)과 파지(Grasp)를 동시에 최적화하는 통합된 프레임워크를 제공한다. 실험 결과, NGDF는 학습하지 않은 물체 형상이나 자세에 대해서도 높은 일반화 성능을 보였으며, 시뮬레이션과 실제 로봇 환경 모두에서 파지 성공률을 크게 향상시켰다.</p>
<h3>3.2  ManiGaussian: 동적 조작을 위한 가우시안 월드 모델</h3>
<p>정적인 물체를 잡는 것을 넘어, 로봇이 물체를 밀거나(Pushing) 재배치하는 동적 조작을 위해서는 시간의 흐름에 따른 장면의 변화를 예측해야 한다. 3DGS는 명시적인 입자(Particle) 기반 표현 덕분에 변형이나 이동을 모델링하기에 적합하다. ManiGaussian과 같은 연구는 동적 가우시안 스플래팅(Dynamic Gaussian Splatting)을 통해 로봇 조작 중 발생하는 장면 변화를 모델링한다.</p>
<p>이 프레임워크는 ’가우시안 월드 모델(Gaussian World Model)’을 핵심으로 한다.</p>
<ol>
<li><strong>상태 인코딩:</strong> 현재 관측된 이미지와 가우시안 상태를 잠재 특징으로 인코딩한다.</li>
<li><strong>변형 예측(Deformation Prediction):</strong> 로봇의 행동 <span class="math math-inline">a_t</span>가 주어졌을 때, 가우시안 파라미터(위치, 회전 등)의 변화량 <span class="math math-inline">\Delta \Theta</span>를 예측하는 신경망을 학습한다.</li>
<li><strong>미래 장면 생성:</strong> 예측된 파라미터로 미래 시점의 장면을 렌더링하고, 이를 실제 관측과 비교하여 물리적 인과관계를 학습한다.</li>
</ol>
<p><span class="math math-display">
\Theta_{t+1} = \Theta_t + \text{DynamicsNet}(\Theta_t, a_t)
</span></p>
<p>이러한 접근은 로봇이 자신의 행동이 환경에 미칠 시각적, 물리적 결과를 미리 시뮬레이션해볼 수 있게 한다. 예를 들어, 책상 위의 물건을 밀었을 때 가우시안들이 어떻게 흩어질지를 예측함으로써, 시각적 피드백 기반의 정교한 모델 예측 제어(MPC)가 가능해진다.</p>
<h3>3.3  POGS: 지속적인 객체 추적과 언어 기반 조작</h3>
<p>공장이나 가정과 같은 비정형 환경에서는 CAD 모델이 없는 임의의 물체를 다루어야 한다. POGS(Persistent Object Gaussian Splat) 시스템은 3DGS를 활용하여 객체 중심(Object-centric)의 지속적인 추적과 조작을 지원한다.</p>
<p>POGS는 전체 장면을 하나의 덩어리로 학습하는 대신, 객체별로 분할된 가우시안 클러스터를 관리한다. 각 가우시안에는 색상 정보 외에도 DINO나 CLIP과 같은 VLM(Vision-Language Model)에서 추출한 의미론적 특징(Semantic Features)이 임베딩된다.</p>
<ul>
<li><strong>지속적 추적:</strong> 물체가 이동하거나 로봇에 의해 조작될 때, 해당 객체의 가우시안 그룹에만 강체 변환(Rigid Transform)을 적용하여 전체 장면을 다시 학습하지 않고도 실시간으로 상태를 갱신한다.</li>
<li><strong>언어 명령 수행:</strong> “드라이버를 집어줘“와 같은 자연어 명령이 들어오면, 임베딩된 의미론적 특징과 텍스트 쿼리를 비교하여 해당 물체의 가우시안을 식별하고 6DoF 자세를 추정한다.</li>
</ul>
<p>실험에서 POGS는 로봇이 물체를 잡고 흔들거나 사람이 물체 위치를 임의로 바꿀 때도 강인하게 추적을 유지했으며, 이를 바탕으로 ’Tool Servoing’과 같은 정밀 조작 작업을 수행했다. 이는 정적인 3D 스캔을 넘어, 로봇과 상호작용하며 실시간으로 동기화되는 ’디지털 트윈’의 구현 가능성을 보여준다.</p>
<h3>3.4  능동적 시각(Active Vision)과 불확실성 기반 탐색</h3>
<p>로봇이 한 시점에서만 환경을 관측하면 가려진 영역(Occlusion)이나 깊이 정보의 불확실성이 남게 된다. FisherRF와 같은 연구는 뉴럴 필드의 불확실성을 정량화하여 ’다음 최적 시점(Next Best View)’을 결정하는 능동적 시각 기술을 제안한다.</p>
<ul>
<li><strong>피셔 정보(Fisher Information):</strong> 렌더링된 픽셀 값이 모델 파라미터에 대해 얼마나 민감한지를 나타내는 피셔 정보를 계산하여, 정보 획득량을 최대화하는 카메라 위치로 로봇 팔을 이동시킨다.</li>
<li><strong>깊이 불확실성:</strong> RGB 색상뿐만 아니라 깊이 추정의 불확실성을 고려하여, 기하학적으로 모호한 영역을 해소하는 방향으로 뷰를 선택한다.</li>
</ul>
<p>이러한 능동적 탐색은 제한된 뷰(Sparse views) 상황에서도 3DGS나 NeRF의 품질을 빠르게 향상시키며, 로봇이 스스로 환경에 대한 이해도를 높이는 자율성을 부여한다.</p>
<h2>4.  미분 가능한 물리학과 시뮬레이션의 통합 (Differentiable Physics)</h2>
<p>뉴럴 표현이 로봇 제어에 가져온 가장 혁신적인 변화 중 하나는 시뮬레이션의 미분 가능화(Differentiability)이다. 렌더링에서부터 물리학 엔진, 그리고 제어기까지의 모든 파이프라인이 미분 가능하다면, 최종 작업의 오차(예: 물체를 떨어뜨림)를 입력 단(예: 모터 토크, 파지 위치)까지 역전파하여 제어 정책을 직접 최적화할 수 있다.</p>
<h3>4.1  Dr. Robot: 미분 가능한 로봇 자기 모델</h3>
<p>Dr. Robot(Differentiable Rendering of Robots)은 로봇의 자기 자신(Self-model)을 3DGS로 표현하고, 기구학(Kinematics)과 렌더링을 완전히 미분 가능하게 만든 시스템이다.</p>
<ul>
<li><strong>임시적 선형 블렌드 스키닝(Implicit Linear Blend Skinning, LBS):</strong> 로봇의 관절이 움직일 때, 링크 표면에 해당하는 3D 가우시안들이 어떻게 이동하고 변형되는지를 LBS 알고리즘을 통해 미분 가능하게 연결한다. 이는 기존의 그래픽스 엔진에서 사용되던 스키닝 기술을 가우시안 스플래팅에 적용한 것이다.</li>
<li><strong>시각-제어 최적화:</strong> 로봇이 특정 시각적 목표(예: 텍스트 프롬프트 “로봇이 컵을 잡고 있는 모습”)를 달성하도록, 이미지 그래디언트를 관절 각도 제어 신호로 직접 역전파한다.</li>
</ul>
<p>이 기술은 로봇이 자신의 형태와 시각적 외관을 스스로 이해하고, 별도의 명시적 보상 함수 설계 없이도 시각적 목표를 달성하는 행동을 생성할 수 있게 한다. 예를 들어, 생성형 AI가 만든 “설거지를 하는 로봇” 이미지를 목표로 주면, Dr. Robot은 렌더링된 자신의 모습과 목표 이미지의 차이를 줄이는 방향으로 관절 각도를 최적화하여 행동을 생성한다. 이는 VLM과 로봇 제어를 연결하는 강력한 인터페이스 역할을 한다.</p>
<h3>4.2  DiSECt와 DANO: 물성 추정과 접촉 시뮬레이션</h3>
<p>뉴럴 필드는 물체의 기하학적 형상뿐만 아니라 물리적 속성(질량, 마찰계수, 탄성 등)을 추정하는 데에도 활용된다. DiSECt는 미분 가능한 절단 시뮬레이터(Differentiable Cutting Simulator)로, 로봇이 칼로 식재료를 자를 때 발생하는 힘의 프로파일을 분석하여 물체의 강성이나 점성을 역추정하고, 이를 바탕으로 에너지를 최소화하는 최적의 절단 동작을 학습한다. 여기서 SDF는 칼과 물체 사이의 접촉면을 정밀하게 모델링하는 데 사용된다.</p>
<p>DANO(Dynamics-Augmented Neural Object)는 뉴럴 필드에 동역학적 속성을 부여하여 미분 가능한 물리 엔진 내에서 시뮬레이션할 수 있게 한다. 물체의 밀도 필드(Density Field)를 질량 밀도로 해석하여 질량 중심과 관성 모멘트를 계산하고, 두 뉴럴 물체 간의 충돌 시 발생하는 침투 깊이(Interpenetration depth)를 볼륨 적분으로 계산하여 접촉력을 모델링한다.<br />
<span class="math math-display">
F_{contact} \propto \int \phi_A(x) \phi_B(x) dx
</span><br />
이러한 미분 가능한 접촉 모델은 로봇이 복잡한 조립 작업이나 비정형 물체 조작 시 발생하는 물리적 상호작용을 예측하고 제어하는 데 필수적이다. 특히, 시뮬레이션에서 학습된 정책을 실제 세계로 전이(Sim-to-Real)할 때 발생하는 간극(Gap)을 줄이는 데 큰 기여를 한다. 실제 로봇의 센서 데이터와 시뮬레이션 결과의 차이를 역전파하여 시뮬레이터의 물리 파라미터(마찰계수 등)를 온라인으로 보정(System Identification)할 수 있기 때문이다.</p>
<h2>5.  실시간 제어를 위한 성능 비교와 기술적 도전</h2>
<p>로봇 제어 루프(Control Loop)는 일반적으로 위치 제어의 경우 1kHz, 궤적 계획의 경우 수십 Hz 이상의 고속 연산을 요구한다. 초기 NeRF 모델들은 렌더링과 추론에 수 초가 소요되어 실시간 제어에 적용하기 어려웠으나, 3DGS와 하드웨어 가속 기술의 발전으로 이러한 장벽이 빠르게 허물어지고 있다.</p>
<h3>5.1  NeRF 대 3DGS: 제어 관점에서의 비교 분석</h3>
<p>NeRF와 3DGS는 각각 장단점이 뚜렷하며, 로봇 제어의 목적에 따라 선택적으로 사용된다.</p>
<table><thead><tr><th><strong>특성</strong></th><th><strong>NeRF (Neural Radiance Fields)</strong></th><th><strong>3DGS (3D Gaussian Splatting)</strong></th></tr></thead><tbody>
<tr><td><strong>표현 방식</strong></td><td>암시적(Implicit), MLP 신경망 가중치</td><td>명시적(Explicit), 3D 가우시안들의 집합</td></tr>
<tr><td><strong>렌더링 속도</strong></td><td>느림 (Ray Marching 필요)</td><td><strong>매우 빠름</strong> (Tile-based Rasterization, &gt;30fps)</td></tr>
<tr><td><strong>메모리 효율</strong></td><td>높음 (신경망 가중치만 저장, 수 MB)</td><td>낮음 (수백만 개 가우시안, 수백 MB~GB)</td></tr>
<tr><td><strong>연속성</strong></td><td>완전 연속 (Continuous, 미분 용이)</td><td>반연속 (Semi-continuous, 입자 기반)</td></tr>
<tr><td><strong>동적 환경</strong></td><td>학습 시간이 오래 걸려 실시간 갱신 어려움</td><td><strong>부분 업데이트 및 변형 용이 (POGS 등)</strong></td></tr>
<tr><td><strong>주요 응용</strong></td><td>고정밀 위치 추정, 오프라인 맵핑</td><td>실시간 내비게이션, 시각 서보잉, 동적 조작</td></tr>
</tbody></table>
<p>3DGS는 타일 기반 래스터화(Tile-based Rasterization)를 사용하여 고화질 이미지를 실시간으로 렌더링할 수 있어, 시각적 피드백이 필요한 비주얼 서보잉(Visual Servoing)이나 SLAM에 훨씬 유리하다. 실험 결과, 3DGS는 복잡한 실내 환경에서도 NeRF 대비 10배 이상의 렌더링 속도와 더 적은 노이즈를 보였다. 반면, NeRF는 메모리 사용량이 적고 완전한 연속 함수로서의 이론적 우아함을 가지며, 조명 변화(View-dependent effects)를 모델링하는 데 강점이 있어 정밀한 오프라인 분석이나 고정된 환경의 맵핑에 여전히 유효하다.</p>
<h3>5.2  하이브리드 접근법: SplatSDF</h3>
<p>최근에는 3DGS의 속도와 SDF의 기하학적 정밀함을 결합한 하이브리드 접근법인 SplatSDF가 제안되었다. 3DGS를 사용하여 빠르게 장면의 대략적인 구조와 색상을 학습하고, 이를 SDF-NeRF의 학습 가이드로 사용하여 기하학적 수렴 속도를 높이는 방식이다.</p>
<p>이 방식은 3DGS의 가우시안 분포를 SDF 네트워크의 입력 임베딩으로 활용하거나, 가우시안으로부터 추정된 깊이/법선 정보를 SDF 학습의 감독 신호(Supervision signal)로 사용한다. 이를 통해 로봇은 3DGS의 빠른 탐색 능력과 SDF의 정밀한 충돌 검사 능력을 동시에 활용할 수 있다. 실험 결과, SplatSDF는 기존 SDF-NeRF 대비 3배 이상 빠른 수렴 속도를 보이면서도 더 정교한 표면 재구성을 달성했다.</p>
<h3>5.3  엣지 배포와 경량화</h3>
<p>로봇에 탑재된 임베디드 컴퓨터(NVIDIA Jetson, Orin 등)에서 이러한 무거운 모델을 구동하기 위한 경량화 연구도 필수적이다.</p>
<ul>
<li><strong>해시 인코딩(Hash Encoding):</strong> Instant-NGP와 같이 공간을 해시 테이블로 매핑하여 학습 파라미터를 줄이고 캐시 적중률을 높여 추론 속도를 극대화한다.</li>
<li><strong>적응형 밀도 제어(Adaptive Density Control):</strong> 3DGS의 경우, 정보량이 적은 영역의 가우시안을 제거(Pruning)하거나 복잡한 영역에 추가(Densification)하여 가우시안 개수를 최적화함으로써 메모리와 연산량을 조절한다.</li>
<li><strong>가속화된 커널:</strong> CUDA 기반의 최적화된 래스터화 커널이나 텐서 코어(Tensor Core)를 활용하여 행렬 연산 속도를 높인다.</li>
</ul>
<p>이러한 기술적 진보는 로봇이 고성능 워크스테이션과 무선으로 통신하는 방식(Offboard processing)을 넘어, 온보드(Onboard)에서 실시간으로 뉴럴 필드를 학습하고 추론하며 자율적으로 행동하는 완전한 자율성을 향해 나아가게 한다.</p>
<h2>6.  요약 및 전망</h2>
<p>5.7장에서 살펴본 바와 같이, 뉴럴 표현은 로봇 제어와 행동 생성의 근간을 근본적으로 변화시키고 있다. 과거의 로봇이 이산적인 지도와 기하학적 알고리즘에 의존하여 ’보고-생각하고-행동(See-Think-Act)’하는 순차적 처리를 했다면, 뉴럴 필드 기반의 로봇은 연속적이고 미분 가능한 함수 공간 내에서 인식과 행동을 동시에 최적화한다.</p>
<p>iNeRF와 같은 기술은 텍스처가 없는 극한 환경에서도 정밀한 위치 추정을 가능하게 했으며, Neural SDF와 Neural NMPC는 복잡한 비정형 환경에서의 안전하고 유려한 주행을 실현했다. NGDF와 동적 가우시안 스플래팅(ManiGaussian, POGS)은 로봇이 물체와 상호작용하며 물리적 세계를 변화시키는 조작 지능을 한 단계 끌어올렸다. 또한, Dr. Robot과 같은 미분 가능한 시뮬레이션 기술은 로봇이 자신의 신체를 이해하고 시각적 목표를 행동으로 직결시키는 새로운 학습 파라다임을 제시했다.</p>
<p>앞으로는 정적인 강체 환경을 넘어, 천, 액체, 변형체와 같은 복잡한 물리적 대상을 실시간으로 모델링하고 제어하는 방향으로 뉴럴 필드 기술이 확장될 것이다. 또한, 대규모 언어 모델(LLM) 및 시각-언어 모델(VLM)과의 결합을 통해, 로봇이 인간의 언어적 지시를 이해하고 뉴럴 필드 상에서 의미론적 추론을 수행하여 행동을 계획하는 ‘뉴로-심볼릭(Neuro-Symbolic)’ 제어 시스템으로 발전할 것으로 전망된다. 뉴럴 표현은 단순한 시각화를 넘어, 로봇이 물리 세계를 이해하고 기억하며 행동하는 ’두뇌의 일부’로 자리 잡고 있다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Inverting Neural Radiance Fields for Pose Estimation - DSpace@MIT, https://dspace.mit.edu/bitstream/handle/1721.1/143603/2012.05877.pdf?sequence=2&amp;isAllowed=y</li>
<li>iNeRF: Inverting Neural Radiance Fields for Pose Estimation, https://neuralfields.cs.brown.edu/paper_96.html</li>
<li>Radiance Field-Based Pose Estimation via Decoupled Optimization …, https://openaccess.thecvf.com/content/WACV2025/papers/Lu_Radiance_Field-Based_Pose_Estimation_via_Decoupled_Optimization_Under_Challenging_Initial_WACV_2025_paper.pdf</li>
<li>RGB-D image pose estimation with inverted Neural Radiance Fields, <a href="https://neural-fields.xyz/CameraReadys/15/BID-NeRF:%20RGB-D%20image%20pose%20estimation%20with%20inverted%20Neural%20Radiance%20Fields.pdf">https://neural-fields.xyz/CameraReadys/15/BID-NeRF:%20RGB-D%20image%20pose%20estimation%20with%20inverted%20Neural%20Radiance%20Fields.pdf</a></li>
<li>Neural Fields in Robotics: A Survey - arXiv, https://arxiv.org/html/2410.20220v1</li>
<li>Continuous Implicit SDF Based Any-Shape Robot Trajectory …, https://ieeexplore.ieee.org/iel7/10341341/10341342/10342104.pdf</li>
<li>Differentiable Composite Neural Signed Distance Fields for Robot …, https://arxiv.org/html/2502.02664v1</li>
<li>Predicted Composite Signed-Distance Fields for Real-Time Motion …, https://cdn.aaai.org/ojs/16010/16010-40-19503-1-2-20210517.pdf</li>
<li>Neural NMPC through Signed Distance Field Encoding for Collision …, https://arxiv.org/abs/2511.21312</li>
<li>Neural NMPC through Signed Distance Field Encoding for Collision …, https://www.researchgate.net/publication/398025684_Neural_NMPC_through_Signed_Distance_Field_Encoding_for_Collision_Avoidance</li>
<li>ntnu-arl/sdf-nmpc - GitHub, https://github.com/ntnu-arl/sdf-nmpc</li>
<li>Neural SDF-MPC (NMPC) - Unified Autonomy Stack, https://ntnu-arl.github.io/unified_autonomy_stack/nmpc/</li>
<li>Safe Real-Time Robot Navigation in Gaussian Splatting Maps - arXiv, https://arxiv.org/html/2403.02751v3</li>
<li>Neural Grasp Distance Fields for Robot Manipulation - arXiv, https://arxiv.org/html/2211.02647v3</li>
<li>ManiGaussian: Dynamic Gaussian Splatting for Multi-task Robotic …, https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05194.pdf</li>
<li>Persistent Object Gaussian Splat (POGS) for Tracking Human … - arXiv, https://arxiv.org/html/2503.05189v1</li>
<li>Persistent Object Gaussian Splat (POGS) for Tracking Human and …, https://autolab.berkeley.edu/assets/publications/media/2025-ICRA-POGS-CRv5.pdf</li>
<li>Guiding Vision and Touch with FisherRF for 3D Gaussian Splatting, https://arm.stanford.edu/next-best-sense</li>
<li>Active Vision Imitation Learning with Sparse-View Gaussian Splatting, https://arxiv.org/html/2511.18140v1</li>
<li>Differentiable Robot Rendering - GitHub, https://raw.githubusercontent.com/mlresearch/v270/main/assets/liu25a/liu25a.pdf</li>
<li>A Differentiable Simulation Engine for Autonomous Robotic Cutting, https://www.roboticsproceedings.org/rss17/p067.pdf</li>
<li>Differentiable Physics Simulation of Dynamics-Augmented Neural …, https://msl.stanford.edu/papers/le_cleach_differentiable_2023.pdf</li>
<li>Real-to-Sim Robot Eval with 3D Gaussian Splatting - YouTube, https://www.youtube.com/watch?v=fUwYNyt6ZI8</li>
<li>by-Side Comparison of NeRF and Gaussian Splatting Under …, https://www.preprints.org/manuscript/202504.1068/v1/download</li>
<li>Comparative Assessment of Neural Radiance Fields and 3D … - MDPI, https://www.mdpi.com/1424-8220/25/10/2995</li>
<li>Gaussian splatting vs. photogrammetry vs. NeRFs - Teleport by Varjo, https://teleport.varjo.com/blog/photogrammetry-vs-nerfs-gaussian-splatting-pros-and-cons</li>
<li>SplatSDF: Boosting Neural Implicit SDF via Gaussian Splatting Fusion, https://www.researchgate.net/publication/386112743_SplatSDF_Boosting_Neural_Implicit_SDF_via_Gaussian_Splatting_Fusion</li>
<li>3D Gaussian Splatting in Robotics: A Survey - arXiv, https://arxiv.org/html/2410.12262v2</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>