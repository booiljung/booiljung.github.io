<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.4.4 로봇 탑재를 위한 경량화 및 SLAM 적용 가능성</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.4.4 로봇 탑재를 위한 경량화 및 SLAM 적용 가능성</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 5. 뉴럴 3D 표현과 렌더링 (Neural 3D Representations)</a> / <a href="index.html">5.4 실시간 렌더링의 게임 체인저: 3D Gaussian Splatting (3DGS)</a> / <span>5.4.4 로봇 탑재를 위한 경량화 및 SLAM 적용 가능성</span></nav>
                </div>
            </header>
            <article>
                <h1>5.4.4 로봇 탑재를 위한 경량화 및 SLAM 적용 가능성</h1>
<p>로봇 공학, 특히 자율 주행 및 조작(Manipulation) 분야에서 환경을 정밀하게 인지하고 표현하는 기술은 시스템의 지능을 결정짓는 핵심 요소이다. 최근 컴퓨터 비전 분야에서 등장한 <em>3D Gaussian Splatting (3DGS)</em> 은 기존의 <em>Neural Radiance Fields (NeRF)</em> 가 가졌던 연산 효율성의 한계를 극복하고, 실시간에 가까운 렌더링 속도와 사진과 같은(Photorealistic) 품질을 동시에 제공함으로써 로봇 인지 시스템의 새로운 패러다임을 제시하고 있다. 그러나 3DGS를 제한된 컴퓨팅 자원을 가진 엣지(Edge) 디바이스나 모바일 로봇에 탑재하기 위해서는 데이터의 방대함과 연산 복잡도라는 두 가지 큰 장벽을 넘어야 한다. 본 절에서는 로봇 시스템에 3DGS를 적용하기 위해 필수적인 경량화 기술과 하드웨어 최적화 전략을 심층적으로 분석하고, 이를 기반으로 한 최신 SLAM(Simultaneous Localization and Mapping) 및 내비게이션 기술의 현황과 적용 가능성을 포괄적으로 논의한다.</p>
<h2>1.  로봇 엣지 환경과 3DGS의 구조적 제약</h2>
<p>3DGS는 씬(Scene)을 수백만 개의 3차원 가우시안(Gaussian) 타원체로 표현하는 명시적(Explicit) 표현 방식을 취한다. 각 가우시안은 위치(Position, <span class="math math-inline">\mu</span>), 공분산(Covariance, <span class="math math-inline">\Sigma</span>), 불투명도(Opacity, <span class="math math-inline">\alpha</span>), 그리고 시점에 따른 색상 변화를 표현하는 구면 조화 함수(Spherical Harmonics, SH) 계수를 포함한다. 이러한 표현 방식은 미분 가능한 래스터화(Rasterization)를 통해 고속 렌더링을 가능하게 하지만, 로봇 하드웨어 관점에서는 다음과 같은 본질적인 문제를 야기한다.</p>
<p>첫째, <strong>메모리 대역폭 및 저장 공간의 한계</strong>이다. 일반적인 3DGS 모델은 수 기가바이트(GB)에서 수십 기가바이트에 달하는 VRAM을 요구한다. 예를 들어, 대규모 씬을 고해상도로 복원할 경우 가우시안의 수는 수천만 개로 급증하며, 이는 NVIDIA Jetson Orin과 같은 임베디드 GPU의 메모리 용량을 초과하기 쉽다.1 특히 로봇은 운영체제(OS), 제어 루프, 센서 드라이버 등 다양한 프로세스를 동시에 구동해야 하므로, 시각적 표현에만 모든 메모리를 할당할 수 없다.</p>
<p>둘째, <strong>실시간 전송 및 대역폭 병목</strong>이다. 클라우드 기반의 로봇 시스템이나 다중 로봇 협업 시나리오에서는 로봇이 수집한 맵 데이터를 서버로 전송하거나 다른 로봇과 공유해야 한다. 압축되지 않은 3DGS 데이터는 전송 대역폭을 심각하게 점유하여 실시간 협업 SLAM을 불가능하게 만든다.3</p>
<p>셋째, <strong>비정형 데이터 구조로 인한 연산 비효율성</strong>이다. 3DGS는 정규화된 그리드 구조가 아닌 비정형 포인트 클라우드 형태를 띠므로, GPU의 메모리 접근 패턴이 불규칙하다. 이는 캐시 미스(Cache Miss)를 유발하고 병렬 처리 효율을 저하시키는 원인이 된다. 특히 래스터화 과정에서의 깊이 정렬(Depth Sorting) 단계는 전체 파이프라인의 병목 구간으로 작용한다.5</p>
<p>따라서 로봇 탑재를 위해서는 원본 3DGS 알고리즘을 그대로 사용하는 것이 아니라, 데이터의 크기를 줄이고 연산 효율을 극대화하는 경량화 기술이 선행되어야 한다.</p>
<h2>2.  3D 가우시안 경량화 및 압축 기술</h2>
<p>최신 연구들은 3DGS의 경량화를 위해 크게 <strong>가지치기(Pruning)</strong>, <strong>벡터 양자화(Vector Quantization)</strong>, **구조적 최적화(Structural Optimization)**의 세 가지 접근 방식을 취하고 있다.</p>
<h3>2.1  적응형 가지치기 및 밀도 제어 (Adaptive Pruning and Density Control)</h3>
<p>가우시안의 개수는 렌더링 속도와 메모리 사용량에 가장 직접적인 영향을 미치는 인자이다. 따라서 렌더링 품질에 기여도가 낮은 가우시안을 효과적으로 선별하여 제거하는 기술이 핵심적이다.</p>
<ol>
<li>해상도 및 기여도 기반 가지치기 (Resolution-Aware Pruning):</li>
</ol>
<p>Reducing the Memory Footprint of 3D Gaussian Splatting 6 연구와 Optimized Minimal Gaussians (OMG) 3 연구는 가우시안의 중요도를 평가하는 새로운 지표를 도입하였다. 단순히 불투명도(Opacity)가 낮은 가우시안을 제거하는 기존 방식을 넘어, 렌더링된 이미지 상에서의 기여도와 투영된 화면 공간(Screen Space)에서의 크기를 고려한다. 너무 작아서 픽셀 단위에 미치지 못하거나, 너무 커서 기하학적 세부 사항을 표현하지 못하는 가우시안을 제거함으로써, 시각적 품질 저하 없이 가우시안의 수를 50% 이상 감축할 수 있다.3</p>
<ol start="2">
<li>앵커 기반 희소성 유도 (Anchor-based Sparsity):</li>
</ol>
<p>Scaffold-GS 7는 씬 전체를 무수히 많은 개별 가우시안으로 표현하는 대신, 희소한 ‘앵커(Anchor)’ 포인트를 기반으로 가우시안들을 동적으로 생성하는 방식을 제안한다. 앵커는 씬의 대략적인 구조를 잡고, 뷰 프러스텀(View Frustum) 내에서 필요한 가우시안 속성을 앵커의 특징(Feature)으로부터 디코딩한다. 이 방식은 저장해야 할 파라미터 수를 획기적으로 줄일 뿐만 아니라, 뷰에 따라 가우시안의 밀도를 동적으로 조절할 수 있어 로봇이 주시하지 않는 영역의 연산 부하를 최소화한다.</p>
<ol start="3">
<li>불투명도 정규화 (Opacity Regularization):</li>
</ol>
<p>Compact3D 8와 CompGS 9는 학습 손실 함수(Loss Function)에 가우시안의 불투명도를 0으로 유도하는 정규화 항을 추가한다. 이는 최적화 과정에서 불필요한 ‘유령(Ghost)’ 가우시안들이 자연스럽게 소멸하도록 유도하며, 최종적으로 남는 유효 가우시안의 수를 줄여 스토리지 효율을 높인다.</p>
<h3>2.2  벡터 양자화 및 코드북 기반 압축 (Codebook-based Quantization)</h3>
<p>3DGS 데이터의 용량을 차지하는 주된 요소는 고차원 구면 조화 함수(SH) 계수와 고정밀 부동소수점 좌표이다. 이를 압축하기 위해 벡터 양자화(Vector Quantization, VQ) 기법이 널리 적용되고 있다.</p>
<ol>
<li>K-means 클러스터링 및 인덱싱:</li>
</ol>
<p>Compact3D 8 및 Reduced 3DGS 6는 모든 가우시안의 색상 및 공분산 파라미터를 그대로 저장하는 대신, K-means 알고리즘을 통해 <span class="math math-inline">K</span>개의 대표값(Codebook)을 추출한다. 각 가우시안은 32비트 실수형 데이터 대신 해당 코드북의 인덱스(예: 8비트 정수)만을 저장한다. 이를 통해 원본 대비 20배에서 최대 45배에 이르는 압축률을 달성하며, 디스크 저장 공간을 획기적으로 절약한다.9</p>
<ol start="2">
<li>SH 계수 증류 및 차원 축소:</li>
</ol>
<p>LightGaussian 4은 고차 SH 계수가 모바일 디바이스에서 과도한 메모리 대역폭을 소모한다는 점에 주목한다. 이 연구는 고차 SH 정보를 더 낮은 차수의 SH 또는 더 컴팩트한 표현으로 변환하는 지식 증류(Distillation) 기법을 사용한다. 또한 ‘VecTree’ 양자화 기법을 통해 속성별로 최적화된 비트 폭(Bit-width)을 할당하여, 15배 이상의 압축률과 200 FPS 이상의 렌더링 속도를 달성하였다.</p>
<ol start="3">
<li>엔트로피 인코딩 및 하프 플로트(Half-float) 활용:</li>
</ol>
<p>인덱싱된 데이터는 Huffman 코딩이나 Run-Length Encoding(RLE)과 같은 엔트로피 압축을 통해 추가적으로 크기를 줄일 수 있다. 또한, 위치 및 척도(Scale) 정보를 float32 대신 float16(Half-precision)으로 저장함으로써 정밀도 손실을 최소화하면서 메모리 사용량을 절반으로 줄이는 기법이 Reduced 3DGS 등에서 표준적으로 사용된다.6</p>
<h3>2.3  하드웨어 가속 및 구조적 최적화 (Hardware Acceleration)</h3>
<p>소프트웨어 레벨의 경량화만으로는 로봇의 실시간 처리 요구사항을 완벽히 충족하기 어렵다. 이에 따라 3DGS 전용 하드웨어 가속기 및 GPU 최적화 연구가 활발히 진행되고 있다.</p>
<ol>
<li>FPGA 기반 가속기 (HyperGS):</li>
</ol>
<p>HyperGS 2는 3DGS의 병목인 정렬(Sorting)과 래스터화 단계를 하드웨어적으로 가속하기 위한 아키텍처를 제안한다. 병렬 처리가 가능한 대규모 정렬 유닛(Sorting Unit)을 설계하여 깊이 정렬 시간을 단축하고, 래스터화 유닛을 파이프라인화하여 데이터 처리량을 극대화했다. 실험 결과, 해당 가속기는 NVIDIA Jetson GPU 대비 전력 소모를 84배 절감하고 44배 향상된 성능을 보였으며, 19.2GB/s의 낮은 메모리 대역폭으로도 40 FPS 이상의 렌더링을 구현하여 엣지 디바이스에서의 3DGS 활용 가능성을 입증했다.</p>
<ol start="2">
<li>타일 기반 부하 분산 (Tile-based Load Balancing):</li>
</ol>
<p>LS-Gaussian 10은 화면을 타일로 분할하고 각 타일의 가우시안 밀도에 따라 작업 부하(Workload)를 예측하여 GPU 스레드에 동적으로 할당한다. 이는 Jetson AGX Orin과 같은 모바일 GPU 아키텍처에서 스레드 간의 유휴 시간(Idle time)을 최소화하여 평균 5.41배의 속도 향상을 이끌어냈다.</p>
<ol start="3">
<li>대규모 환경을 위한 스트리밍 (Streaming Architecture):</li>
</ol>
<p>로봇이 탐사하는 환경이 커질수록 맵 데이터는 GPU 메모리를 초과하게 된다. DiskChunGS 11는 씬을 공간적으로 분할된 ’청크(Chunk)’로 관리하고, 현재 로봇의 카메라 시야(Frustum)에 들어오는 청크만을 디스크에서 VRAM으로 비동기 로딩하는 방식을 채택했다. 이를 통해 수 킬로미터에 달하는 대규모 환경(KITTI 데이터셋 등)을 제한된 메모리를 가진 Jetson Orin에서도 실시간으로 렌더링할 수 있는 확장성을 확보했다.</p>
<table><thead><tr><th><strong>기술 분류</strong></th><th><strong>대표 연구</strong></th><th><strong>핵심 메커니즘</strong></th><th><strong>로봇 적용 시 이점</strong></th></tr></thead><tbody>
<tr><td><strong>가지치기</strong></td><td>OMG 3, Reduced 3DGS 6</td><td>기여도/해상도 기반 비중요 가우시안 제거</td><td>연산량 감소, FPS 증가</td></tr>
<tr><td><strong>양자화</strong></td><td>Compact3D 8, CompGS 9</td><td>K-means 코드북, 인덱싱 저장</td><td>맵 데이터 전송 효율 증대 (45배 압축)</td></tr>
<tr><td><strong>구조적 압축</strong></td><td>Scaffold-GS 7</td><td>앵커 포인트 기반 속성 디코딩</td><td>저장 공간 절약, 뷰 적응형 렌더링</td></tr>
<tr><td><strong>하드웨어 가속</strong></td><td>HyperGS 5</td><td>FPGA 정렬/래스터화 유닛 병렬화</td><td>저전력 구동, 배터리 효율 극대화</td></tr>
<tr><td><strong>메모리 관리</strong></td><td>DiskChunGS 11</td><td>청크 기반 동적 VRAM 로딩</td><td>대규모 맵 확장성(Scalability) 확보</td></tr>
</tbody></table>
<h2>3.  3DGS 기반 SLAM: 구조, 알고리즘 및 성능 비교</h2>
<p>로봇 자율 주행의 근간이 되는 SLAM 시스템에 3DGS를 적용하려는 시도는, 기존의 포인트 클라우드나 복셀(Voxel), 메쉬(Mesh) 기반 맵이 가지는 시각적 품질의 한계와 NeRF 기반 SLAM이 가지는 느린 속도 문제를 동시에 해결하고자 한다. 3DGS 기반 SLAM은 크게 <strong>트래킹(Tracking)</strong>, <strong>매핑(Mapping)</strong>, **맵 관리(Map Management)**의 세 가지 모듈로 구성된다.</p>
<h3>3.1  3DGS SLAM의 핵심 아키텍처</h3>
<ol>
<li>트래킹 (Camera Tracking):</li>
</ol>
<p>현재 3DGS 맵을 렌더링한 이미지와 로봇 카메라의 입력 이미지 사이의 광도 오차(Photometric Error)를 최소화하는 방향으로 카메라의 6-DoF 포즈(Pose)를 최적화한다. 3DGS의 빠른 렌더링 속도 덕분에 수백 Hz의 주기로 포즈 업데이트가 가능하며, 이는 급격한 움직임이나 동적인 환경에서도 강건한 추적 성능을 보장한다.</p>
<ol start="2">
<li>매핑 및 밀도화 (Mapping and Densification):</li>
</ol>
<p>새로운 영역이 관측되거나 기존 영역의 디테일이 부족할 경우, 가우시안을 추가(Cloning/Splitting)하거나 속성을 업데이트한다. SLAM에서는 사전 학습된 데이터가 없기 때문에, 입력되는 비디오 스트림에 맞춰 점진적으로(Incremental) 가우시안을 생성하고 최적화하는 전략이 필수적이다.</p>
<ol start="3">
<li>키프레임 선정 및 관리 (Keyframe Selection):</li>
</ol>
<p>모든 프레임을 맵 업데이트에 사용하면 연산 부하가 과도해지므로, 씬의 변화가 크거나 새로운 정보가 많은 프레임을 키프레임으로 선정하여 최적화를 수행한다.12</p>
<h3>3.2  주요 3DGS SLAM 알고리즘 분석</h3>
<h4>3.2.1 ) SplaTAM: Splat, Track &amp; Map</h4>
<p><em>SplaTAM</em> 13은 RGB-D 센서를 활용하는 3DGS SLAM의 대표적인 연구로, 명시적인 볼륨 표현을 실시간 최적화에 적용한 선구적인 사례이다.</p>
<ul>
<li><strong>실루엣 마스크(Silhouette Mask) 활용</strong>: 3DGS는 빈 공간(Empty Space)을 명시적으로 ’비어있음’으로 표현하지 않고 가우시안이 없는 상태로 둔다. <em>SplaTAM</em>은 유효한 밀도가 존재하는 영역을 구분하는 실루엣 마스크를 생성하여, 트래킹 시 불필요한 영역의 노이즈가 포즈 추정에 악영향을 주는 것을 방지한다.</li>
<li><strong>성능</strong>: 기존의 암시적 표현(Implicit Representation) 기반 SLAM 대비 카메라 포즈 추정 정확도와 맵 재구성 품질에서 2배 이상의 성능을 기록했으며, 400 FPS 이상의 압도적인 렌더링 속도를 달성하여 실시간 로봇 애플리케이션에 적합함을 증명했다.</li>
</ul>
<h4>3.2.2 ) GS-SLAM: Dense Visual SLAM</h4>
<p><em>GS-SLAM</em> 12은 적응형 확장 전략과 정교한 트래킹 기법을 통해 맵의 완전성(Completeness)과 정확성을 높이는 데 주력한다.</p>
<ul>
<li><strong>적응형 3D 가우시안 확장</strong>: 기하학적 오차와 렌더링 오차를 동시에 고려하여, 새로운 기하학적 구조가 발견된 곳에 효율적으로 가우시안을 추가한다. 또한, 노이즈가 심하거나 최적화가 덜 된 가우시안을 제거하는 가지치기 전략을 병행하여 맵의 품질을 유지한다.</li>
<li><strong>Coarse-to-Fine 트래킹</strong>: 초기에는 저해상도에서 대략적인 포즈를 추정하고, 점차 고해상도로 정밀하게 포즈를 보정하는 방식을 사용하여 연산 시간을 단축하면서도 강건한 트래킹을 수행한다. Replica 데이터셋에서 평균 386 FPS의 렌더링 속도를 기록하였다.</li>
</ul>
<h4>3.2.3 ) MonoGS: Monocular Gaussian SLAM</h4>
<p>대부분의 로봇이 RGB-D 센서를 탑재하지만, 드론이나 저가형 로봇은 단안(Monocular) RGB 카메라만을 사용할 수 있다. <em>MonoGS</em> 18는 깊이 정보 없이 RGB 이미지만으로 3DGS SLAM을 수행한다.</p>
<ul>
<li><strong>기하학적 정규화</strong>: 깊이 정보의 부재로 인한 척도 모호성(Scale Ambiguity)과 깊이 추정의 불안정성을 해결하기 위해, 기하학적 코드북과 정규화 항을 도입하여 3차원 구조의 일관성을 강제한다.</li>
<li><strong>한계 및 극복</strong>: 단안 방식은 RGB-D 방식에 비해 트래킹 정확도가 떨어질 수밖에 없으나, 최근 연구에서는 사전 학습된 깊이 추정 네트워크(Depth Prior)를 결합하거나 관성 측정 장치(IMU)를 융합하여 성능을 개선하고 있다.21</li>
</ul>
<h3>3.3  성능 비교 평가</h3>
<p>다음 표는 주요 3DGS SLAM 알고리즘과 기존 방식들의 성능을 Replica 및 TUM-RGBD 데이터셋을 기준으로 비교한 것이다.18 수치는 평균 절대 궤적 오차(ATE, cm)와 렌더링 속도(FPS), 그리고 구조적 유사도(SSIM)를 포함한다.</p>
<table><thead><tr><th><strong>알고리즘</strong></th><th><strong>센서 타입</strong></th><th><strong>ATE (cm) ↓</strong></th><th><strong>Rendering FPS ↑</strong></th><th><strong>SSIM ↑</strong></th><th><strong>특징 및 비고</strong></th></tr></thead><tbody>
<tr><td><strong>SplaTAM</strong> 14</td><td>RGB-D</td><td><strong>0.36</strong></td><td>400+</td><td>0.86~0.95</td><td>고품질 매핑, 실루엣 마스크, 높은 연산 요구량</td></tr>
<tr><td><strong>GS-SLAM</strong> 12</td><td>RGB-D</td><td>0.50</td><td>386</td><td>0.92</td><td>적응형 확장, 빠른 트래킹, 균형 잡힌 성능</td></tr>
<tr><td><strong>MonoGS</strong> 19</td><td>RGB</td><td>0.58</td><td>&lt; 10 (Full System)</td><td>0.85</td><td>단안 카메라 지원, 하드웨어 제약 시 유리</td></tr>
<tr><td><strong>Point-SLAM</strong></td><td>RGB-D</td><td>0.52</td><td>&lt; 5</td><td>0.80~0.90</td><td>포인트 기반, 렌더링 속도 느림</td></tr>
<tr><td><strong>NICE-SLAM</strong></td><td>RGB-D</td><td>1.80+</td><td>&lt; 2</td><td>0.80</td><td>NeRF 기반, 매우 느린 속도, 엣지 구동 불가</td></tr>
</tbody></table>
<p><strong>분석 및 시사점</strong>:</p>
<ul>
<li><strong>속도 혁명</strong>: 3DGS 기반 SLAM(SplaTAM, GS-SLAM)은 기존 NeRF 기반 SLAM(NICE-SLAM)이나 포인트 기반 SLAM 대비 수십 배에서 수백 배 빠른 렌더링 속도를 보여준다. 이는 로봇이 고속으로 이동하거나 급격히 회전하는 상황에서도 트래킹을 잃지 않게(Tracking Loss 방지) 하는 결정적인 요인이다.</li>
<li><strong>정확도와 자원의 트레이드오프</strong>: <em>SplaTAM</em>은 가장 높은 정확도를 보이지만 메모리 사용량이 많을 수 있다. 반면, <em>GS-SLAM</em>은 속도와 정확도 사이의 균형을 유지한다. 엣지 디바이스에서는 <em>MonoGS</em>와 같이 센서 의존도를 낮추거나, 앞서 언급한 경량화 기법(Compact3D 등)을 SLAM 파이프라인에 통합하여 메모리 효율을 높이는 전략이 필요하다.</li>
<li><strong>동적 환경 대응</strong>: 최근 <em>DyGS-SLAM</em>과 같은 연구들은 동적 객체(사람, 이동하는 차량 등)가 존재하는 환경에서도 강건한 SLAM을 수행하기 위해 동적 가우시안과 정적 가우시안을 분리하여 관리하는 방법을 제안하고 있다.24</li>
</ul>
<h2>4.  로봇 내비게이션 및 물리적 조작을 위한 응용</h2>
<p>SLAM을 통해 맵이 작성되었다면, 로봇은 이를 바탕으로 목적지까지 이동(Navigation)하거나 물체를 조작(Manipulation)해야 한다. 3DGS는 시각적으로 우수하지만, 물리적 상호작용을 위한 충돌 모델이나 의미론적 정보가 부족하다는 한계가 있다. 이를 극복하기 위한 최신 연구 동향은 다음과 같다.</p>
<h3>4.1  안전한 자율 주행을 위한 Splat-Nav</h3>
<p><em>Splat-Nav</em> 25는 3DGS 맵을 로봇의 경로 계획(Path Planning)에 직접 활용하는 프레임워크다.</p>
<ul>
<li><strong>확률적 충돌 검사</strong>: 가우시안은 명확한 경계면(Surface)이 없는 확률 분포이다. <em>Splat-Nav</em>는 가우시안의 99% 신뢰 구간(Confidence Interval)을 점유 공간으로 간주하여 충돌 가능성을 평가한다.</li>
<li><strong>안전 통로 생성</strong>: 직접적인 충돌 검사는 비용이 많이 들고 미분 불가능하므로, <em>Splat-Nav</em>는 ’안전 이동 통로(Safe Corridor)’를 정의하는 폴리토프(Polytope)를 생성하고, 이 내부에서 베지어 곡선(Bézier Curve)을 이용하여 부드러운 경로를 생성한다.</li>
<li><strong>성능</strong>: 온보드 RGB 카메라만으로 25Hz 이상의 상태 추정(Splat-Loc)과 2Hz 이상의 경로 재계획(Splat-Plan)을 수행하며, 이는 기존 NeRF 기반 내비게이션 대비 한 차수(Order of magnitude) 빠른 처리 속도이다.</li>
</ul>
<h3>4.2  6-DoF 조작을 위한 GraspSplats 및 언어 기반 상호작용</h3>
<p>로봇 팔을 이용한 파지(Grasping) 및 조작 작업에서는 물체의 정확한 형상 인식과 의미론적 이해가 필수적이다.</p>
<ul>
<li><strong>GraspSplats</strong> 27: 3DGS에 언어-비전 모델(CLIP 등)의 임베딩을 통합하여, 사용자의 자연어 명령(예: “컵의 손잡이를 잡아라”)을 이해하고 해당 부위의 가우시안을 식별한다. <em>GraspSplats</em>는 가우시안의 기하학적 정보를 활용하여 6-DoF 파지 포즈를 밀리초(ms) 단위로 제안하며, 포인트 트래커를 통해 물체가 움직이거나 변형되어도 실시간으로 파지 지점을 추적한다. 이는 정적인 씬에 국한되었던 기존 방법론을 넘어 동적 조작의 가능성을 열었다.</li>
<li><strong>ManiGaussian</strong> 29: 로봇의 행동에 따른 환경의 변화를 예측하기 위해 3DGS 기반의 월드 모델(World Model)을 구축한다. 이는 강화학습 에이전트가 미래의 상태를 시각적으로 시뮬레이션하고 최적의 행동을 학습하는 데 활용된다.</li>
</ul>
<h3>4.3  물리 엔진과의 통합 및 디지털 트윈</h3>
<p><em>High-Fidelity Digital Twin</em> 30 연구 등은 3DGS 데이터를 물리 엔진(Unity, ROS2 MoveIt, PhysX)이 이해할 수 있는 형태로 변환하는 데 주력한다.</p>
<ul>
<li><strong>충돌 메쉬 생성</strong>: 3DGS의 가우시안 클라우드에서 등위면(Isosurface) 추출 알고리즘(Marching Cubes 등)을 적용하거나, 가시성 기반 필터링을 통해 노이즈(Floaters)를 제거하고 충돌 검사가 가능한 메쉬(Mesh)를 실시간으로 생성한다.</li>
<li><strong>물리 속성 부여</strong>: <em>PhysGaussian</em> 31과 같이 가우시안 자체에 질량, 탄성, 마찰 계수 등의 물리적 속성을 부여하여, 별도의 메쉬 변환 없이도 물리 시뮬레이션과 렌더링이 동시에 가능한 통합 표현법이 연구되고 있다.</li>
</ul>
<h2>5.  결론 및 향후 전망</h2>
<p>3D Gaussian Splatting은 로봇의 공간 인지 능력을 시각적 리얼리즘과 실시간성이라는 두 축에서 혁신적으로 발전시키고 있다. 수 기가바이트에 달하는 데이터 크기와 불규칙한 메모리 접근 패턴은 초기 로봇 적용의 걸림돌이었으나, <strong>가지치기(Pruning)</strong>, <strong>벡터 양자화(VQ)</strong>, <strong>FPGA/ASIC 기반 하드웨어 가속</strong> 기술의 발전으로 엣지 디바이스에서도 충분히 구동 가능한 수준에 도달하였다.</p>
<p>SLAM 분야에서는 <em>SplaTAM</em>, <em>GS-SLAM</em> 등의 연구를 통해 3DGS가 단순한 렌더링 도구를 넘어 정밀한 위치 추정과 맵 생성의 핵심 엔진으로 작동할 수 있음이 입증되었다. 특히 400 FPS에 육박하는 렌더링 속도는 고속 드론 비행이나 급격한 회피 기동 중에도 안정적인 트래킹을 가능하게 한다. 나아가 <em>GraspSplats</em>와 <em>Splat-Nav</em>는 3DGS 맵이 로봇의 물리적 상호작용과 경로 계획에 직접적으로 기여할 수 있는 길을 열었다.</p>
<p>향후 연구는 <strong>분산형 다중 로봇 SLAM (Distributed Multi-robot SLAM)</strong>, <strong>의미론적 3DGS (Semantic 3DGS)</strong>, 그리고 **물리-렌더링 통합 모델 (Physics-integrated Rendering)**로 확장될 것이다. 특히 로봇 운영체제(ROS)와의 표준화된 통합과 glTF와 같은 개방형 포맷으로의 3DGS 표준화가 가속화됨에 따라, 3DGS는 차세대 로봇 공간 지능(Spatial Intelligence)을 위한 범용 미들웨어로 자리 잡을 것으로 전망된다.</p>
<h1>5.4.4 로봇 탑재를 위한 경량화 및 SLAM 적용 가능성</h1>
<p>로봇 공학, 특히 자율 주행 및 조작(Manipulation) 분야에서 환경을 정밀하게 인지하고 표현하는 기술은 시스템의 지능을 결정짓는 핵심 요소이다. 최근 컴퓨터 비전 분야에서 등장한 <em>3D Gaussian Splatting (3DGS)</em> 은 기존의 <em>Neural Radiance Fields (NeRF)</em> 가 가졌던 연산 효율성의 한계를 극복하고, 실시간에 가까운 렌더링 속도와 사진과 같은(Photorealistic) 품질을 동시에 제공함으로써 로봇 인지 시스템의 새로운 패러다임을 제시하고 있다. 그러나 3DGS를 제한된 컴퓨팅 자원을 가진 엣지(Edge) 디바이스나 모바일 로봇에 탑재하기 위해서는 데이터의 방대함과 연산 복잡도라는 두 가지 큰 장벽을 넘어야 한다. 본 절에서는 로봇 시스템에 3DGS를 적용하기 위해 필수적인 경량화 기술과 하드웨어 최적화 전략을 심층적으로 분석하고, 이를 기반으로 한 최신 SLAM(Simultaneous Localization and Mapping) 및 내비게이션 기술의 현황과 적용 가능성을 포괄적으로 논의한다.</p>
<h2>1.  로봇 엣지 환경과 3DGS의 구조적 제약</h2>
<p>3DGS는 씬(Scene)을 수백만 개의 3차원 가우시안(Gaussian) 타원체로 표현하는 명시적(Explicit) 표현 방식을 취한다. 각 가우시안은 위치(Position, <span class="math math-inline">\mu</span>), 공분산(Covariance, <span class="math math-inline">\Sigma</span>), 불투명도(Opacity, <span class="math math-inline">\alpha</span>), 그리고 시점에 따른 색상 변화를 표현하는 구면 조화 함수(Spherical Harmonics, SH) 계수를 포함한다. 이러한 표현 방식은 미분 가능한 래스터화(Rasterization)를 통해 고속 렌더링을 가능하게 하지만, 로봇 하드웨어 관점에서는 다음과 같은 본질적인 문제를 야기한다.</p>
<p>첫째, <strong>메모리 대역폭 및 저장 공간의 한계</strong>이다. 일반적인 3DGS 모델은 수 기가바이트(GB)에서 수십 기가바이트에 달하는 VRAM을 요구한다. 예를 들어, 대규모 씬을 고해상도로 복원할 경우 가우시안의 수는 수천만 개로 급증하며, 이는 NVIDIA Jetson Orin과 같은 임베디드 GPU의 메모리 용량을 초과하기 쉽다.1 특히 로봇은 운영체제(OS), 제어 루프, 센서 드라이버 등 다양한 프로세스를 동시에 구동해야 하므로, 시각적 표현에만 모든 메모리를 할당할 수 없다.</p>
<p>둘째, <strong>실시간 전송 및 대역폭 병목</strong>이다. 클라우드 기반의 로봇 시스템이나 다중 로봇 협업 시나리오에서는 로봇이 수집한 맵 데이터를 서버로 전송하거나 다른 로봇과 공유해야 한다. 압축되지 않은 3DGS 데이터는 전송 대역폭을 심각하게 점유하여 실시간 협업 SLAM을 불가능하게 만든다.3</p>
<p>셋째, <strong>비정형 데이터 구조로 인한 연산 비효율성</strong>이다. 3DGS는 정규화된 그리드 구조가 아닌 비정형 포인트 클라우드 형태를 띠므로, GPU의 메모리 접근 패턴이 불규칙하다. 이는 캐시 미스(Cache Miss)를 유발하고 병렬 처리 효율을 저하시키는 원인이 된다. 특히 래스터화 과정에서의 깊이 정렬(Depth Sorting) 단계는 전체 파이프라인의 병목 구간으로 작용한다.5</p>
<p>따라서 로봇 탑재를 위해서는 원본 3DGS 알고리즘을 그대로 사용하는 것이 아니라, 데이터의 크기를 줄이고 연산 효율을 극대화하는 경량화 기술이 선행되어야 한다.</p>
<h2>2.  3D 가우시안 경량화 및 압축 기술</h2>
<p>최신 연구들은 3DGS의 경량화를 위해 크게 <strong>가지치기(Pruning)</strong>, <strong>벡터 양자화(Vector Quantization)</strong>, **구조적 최적화(Structural Optimization)**의 세 가지 접근 방식을 취하고 있다.</p>
<h3>2.1  적응형 가지치기 및 밀도 제어 (Adaptive Pruning and Density Control)</h3>
<p>가우시안의 개수는 렌더링 속도와 메모리 사용량에 가장 직접적인 영향을 미치는 인자이다. 따라서 렌더링 품질에 기여도가 낮은 가우시안을 효과적으로 선별하여 제거하는 기술이 핵심적이다.</p>
<ol>
<li>해상도 및 기여도 기반 가지치기 (Resolution-Aware Pruning):</li>
</ol>
<p>Reducing the Memory Footprint of 3D Gaussian Splatting 6 연구와 Optimized Minimal Gaussians (OMG) 3 연구는 가우시안의 중요도를 평가하는 새로운 지표를 도입하였다. 단순히 불투명도(Opacity)가 낮은 가우시안을 제거하는 기존 방식을 넘어, 렌더링된 이미지 상에서의 기여도와 투영된 화면 공간(Screen Space)에서의 크기를 고려한다. 너무 작아서 픽셀 단위에 미치지 못하거나, 너무 커서 기하학적 세부 사항을 표현하지 못하는 가우시안을 제거함으로써, 시각적 품질 저하 없이 가우시안의 수를 50% 이상 감축할 수 있다.3</p>
<ol start="2">
<li>앵커 기반 희소성 유도 (Anchor-based Sparsity):</li>
</ol>
<p>Scaffold-GS 7는 씬 전체를 무수히 많은 개별 가우시안으로 표현하는 대신, 희소한 ‘앵커(Anchor)’ 포인트를 기반으로 가우시안들을 동적으로 생성하는 방식을 제안한다. 앵커는 씬의 대략적인 구조를 잡고, 뷰 프러스텀(View Frustum) 내에서 필요한 가우시안 속성을 앵커의 특징(Feature)으로부터 디코딩한다. 이 방식은 저장해야 할 파라미터 수를 획기적으로 줄일 뿐만 아니라, 뷰에 따라 가우시안의 밀도를 동적으로 조절할 수 있어 로봇이 주시하지 않는 영역의 연산 부하를 최소화한다.</p>
<ol start="3">
<li>불투명도 정규화 (Opacity Regularization):</li>
</ol>
<p>Compact3D 8와 CompGS 9는 학습 손실 함수(Loss Function)에 가우시안의 불투명도를 0으로 유도하는 정규화 항을 추가한다. 이는 최적화 과정에서 불필요한 ‘유령(Ghost)’ 가우시안들이 자연스럽게 소멸하도록 유도하며, 최종적으로 남는 유효 가우시안의 수를 줄여 스토리지 효율을 높인다.</p>
<h3>2.2  벡터 양자화 및 코드북 기반 압축 (Codebook-based Quantization)</h3>
<p>3DGS 데이터의 용량을 차지하는 주된 요소는 고차원 구면 조화 함수(SH) 계수와 고정밀 부동소수점 좌표이다. 이를 압축하기 위해 벡터 양자화(Vector Quantization, VQ) 기법이 널리 적용되고 있다.</p>
<ol>
<li>K-means 클러스터링 및 인덱싱:</li>
</ol>
<p>Compact3D 8 및 Reduced 3DGS 6는 모든 가우시안의 색상 및 공분산 파라미터를 그대로 저장하는 대신, K-means 알고리즘을 통해 <span class="math math-inline">K</span>개의 대표값(Codebook)을 추출한다. 각 가우시안은 32비트 실수형 데이터 대신 해당 코드북의 인덱스(예: 8비트 정수)만을 저장한다. 이를 통해 원본 대비 20배에서 최대 45배에 이르는 압축률을 달성하며, 디스크 저장 공간을 획기적으로 절약한다.9</p>
<ol start="2">
<li>SH 계수 증류 및 차원 축소:</li>
</ol>
<p>LightGaussian 4은 고차 SH 계수가 모바일 디바이스에서 과도한 메모리 대역폭을 소모한다는 점에 주목한다. 이 연구는 고차 SH 정보를 더 낮은 차수의 SH 또는 더 컴팩트한 표현으로 변환하는 지식 증류(Distillation) 기법을 사용한다. 또한 ‘VecTree’ 양자화 기법을 통해 속성별로 최적화된 비트 폭(Bit-width)을 할당하여, 15배 이상의 압축률과 200 FPS 이상의 렌더링 속도를 달성하였다.</p>
<ol start="3">
<li>엔트로피 인코딩 및 하프 플로트(Half-float) 활용:</li>
</ol>
<p>인덱싱된 데이터는 Huffman 코딩이나 Run-Length Encoding(RLE)과 같은 엔트로피 압축을 통해 추가적으로 크기를 줄일 수 있다. 또한, 위치 및 척도(Scale) 정보를 float32 대신 float16(Half-precision)으로 저장함으로써 정밀도 손실을 최소화하면서 메모리 사용량을 절반으로 줄이는 기법이 Reduced 3DGS 등에서 표준적으로 사용된다.6</p>
<h3>2.3  하드웨어 가속 및 구조적 최적화 (Hardware Acceleration)</h3>
<p>소프트웨어 레벨의 경량화만으로는 로봇의 실시간 처리 요구사항을 완벽히 충족하기 어렵다. 이에 따라 3DGS 전용 하드웨어 가속기 및 GPU 최적화 연구가 활발히 진행되고 있다.</p>
<ol>
<li>FPGA 기반 가속기 (HyperGS):</li>
</ol>
<p>HyperGS 2는 3DGS의 병목인 정렬(Sorting)과 래스터화 단계를 하드웨어적으로 가속하기 위한 아키텍처를 제안한다. 병렬 처리가 가능한 대규모 정렬 유닛(Sorting Unit)을 설계하여 깊이 정렬 시간을 단축하고, 래스터화 유닛을 파이프라인화하여 데이터 처리량을 극대화했다. 실험 결과, 해당 가속기는 NVIDIA Jetson GPU 대비 전력 소모를 84배 절감하고 44배 향상된 성능을 보였으며, 19.2GB/s의 낮은 메모리 대역폭으로도 40 FPS 이상의 렌더링을 구현하여 엣지 디바이스에서의 3DGS 활용 가능성을 입증했다.</p>
<ol start="2">
<li>타일 기반 부하 분산 (Tile-based Load Balancing):</li>
</ol>
<p>LS-Gaussian 10은 화면을 타일로 분할하고 각 타일의 가우시안 밀도에 따라 작업 부하(Workload)를 예측하여 GPU 스레드에 동적으로 할당한다. 이는 Jetson AGX Orin과 같은 모바일 GPU 아키텍처에서 스레드 간의 유휴 시간(Idle time)을 최소화하여 평균 5.41배의 속도 향상을 이끌어냈다.</p>
<ol start="3">
<li>대규모 환경을 위한 스트리밍 (Streaming Architecture):</li>
</ol>
<p>로봇이 탐사하는 환경이 커질수록 맵 데이터는 GPU 메모리를 초과하게 된다. DiskChunGS 11는 씬을 공간적으로 분할된 ’청크(Chunk)’로 관리하고, 현재 로봇의 카메라 시야(Frustum)에 들어오는 청크만을 디스크에서 VRAM으로 비동기 로딩하는 방식을 채택했다. 이를 통해 수 킬로미터에 달하는 대규모 환경(KITTI 데이터셋 등)을 제한된 메모리를 가진 Jetson Orin에서도 실시간으로 렌더링할 수 있는 확장성을 확보했다.</p>
<table><thead><tr><th><strong>기술 분류</strong></th><th><strong>대표 연구</strong></th><th><strong>핵심 메커니즘</strong></th><th><strong>로봇 적용 시 이점</strong></th></tr></thead><tbody>
<tr><td><strong>가지치기</strong></td><td>OMG 3, Reduced 3DGS 6</td><td>기여도/해상도 기반 비중요 가우시안 제거</td><td>연산량 감소, FPS 증가</td></tr>
<tr><td><strong>양자화</strong></td><td>Compact3D 8, CompGS 9</td><td>K-means 코드북, 인덱싱 저장</td><td>맵 데이터 전송 효율 증대 (45배 압축)</td></tr>
<tr><td><strong>구조적 압축</strong></td><td>Scaffold-GS 7</td><td>앵커 포인트 기반 속성 디코딩</td><td>저장 공간 절약, 뷰 적응형 렌더링</td></tr>
<tr><td><strong>하드웨어 가속</strong></td><td>HyperGS 5</td><td>FPGA 정렬/래스터화 유닛 병렬화</td><td>저전력 구동, 배터리 효율 극대화</td></tr>
<tr><td><strong>메모리 관리</strong></td><td>DiskChunGS 11</td><td>청크 기반 동적 VRAM 로딩</td><td>대규모 맵 확장성(Scalability) 확보</td></tr>
</tbody></table>
<h2>3.  3DGS 기반 SLAM: 구조, 알고리즘 및 성능 비교</h2>
<p>로봇 자율 주행의 근간이 되는 SLAM 시스템에 3DGS를 적용하려는 시도는, 기존의 포인트 클라우드나 복셀(Voxel), 메쉬(Mesh) 기반 맵이 가지는 시각적 품질의 한계와 NeRF 기반 SLAM이 가지는 느린 속도 문제를 동시에 해결하고자 한다. 3DGS 기반 SLAM은 크게 <strong>트래킹(Tracking)</strong>, <strong>매핑(Mapping)</strong>, **맵 관리(Map Management)**의 세 가지 모듈로 구성된다.</p>
<h3>3.1  3DGS SLAM의 핵심 아키텍처</h3>
<ol>
<li>트래킹 (Camera Tracking):</li>
</ol>
<p>현재 3DGS 맵을 렌더링한 이미지와 로봇 카메라의 입력 이미지 사이의 광도 오차(Photometric Error)를 최소화하는 방향으로 카메라의 6-DoF 포즈(Pose)를 최적화한다. 3DGS의 빠른 렌더링 속도 덕분에 수백 Hz의 주기로 포즈 업데이트가 가능하며, 이는 급격한 움직임이나 동적인 환경에서도 강건한 추적 성능을 보장한다.</p>
<ol start="2">
<li>매핑 및 밀도화 (Mapping and Densification):</li>
</ol>
<p>새로운 영역이 관측되거나 기존 영역의 디테일이 부족할 경우, 가우시안을 추가(Cloning/Splitting)하거나 속성을 업데이트한다. SLAM에서는 사전 학습된 데이터가 없기 때문에, 입력되는 비디오 스트림에 맞춰 점진적으로(Incremental) 가우시안을 생성하고 최적화하는 전략이 필수적이다.</p>
<ol start="3">
<li>키프레임 선정 및 관리 (Keyframe Selection):</li>
</ol>
<p>모든 프레임을 맵 업데이트에 사용하면 연산 부하가 과도해지므로, 씬의 변화가 크거나 새로운 정보가 많은 프레임을 키프레임으로 선정하여 최적화를 수행한다.12</p>
<h3>3.2  주요 3DGS SLAM 알고리즘 분석</h3>
<h4>3.2.1 ) SplaTAM: Splat, Track &amp; Map</h4>
<p><em>SplaTAM</em> 13은 RGB-D 센서를 활용하는 3DGS SLAM의 대표적인 연구로, 명시적인 볼륨 표현을 실시간 최적화에 적용한 선구적인 사례이다.</p>
<ul>
<li><strong>실루엣 마스크(Silhouette Mask) 활용</strong>: 3DGS는 빈 공간(Empty Space)을 명시적으로 ’비어있음’으로 표현하지 않고 가우시안이 없는 상태로 둔다. <em>SplaTAM</em>은 유효한 밀도가 존재하는 영역을 구분하는 실루엣 마스크를 생성하여, 트래킹 시 불필요한 영역의 노이즈가 포즈 추정에 악영향을 주는 것을 방지한다.</li>
<li><strong>성능</strong>: 기존의 암시적 표현(Implicit Representation) 기반 SLAM 대비 카메라 포즈 추정 정확도와 맵 재구성 품질에서 2배 이상의 성능을 기록했으며, 400 FPS 이상의 압도적인 렌더링 속도를 달성하여 실시간 로봇 애플리케이션에 적합함을 증명했다.</li>
</ul>
<h4>3.2.2 ) GS-SLAM: Dense Visual SLAM</h4>
<p><em>GS-SLAM</em> 12은 적응형 확장 전략과 정교한 트래킹 기법을 통해 맵의 완전성(Completeness)과 정확성을 높이는 데 주력한다.</p>
<ul>
<li><strong>적응형 3D 가우시안 확장</strong>: 기하학적 오차와 렌더링 오차를 동시에 고려하여, 새로운 기하학적 구조가 발견된 곳에 효율적으로 가우시안을 추가한다. 또한, 노이즈가 심하거나 최적화가 덜 된 가우시안을 제거하는 가지치기 전략을 병행하여 맵의 품질을 유지한다.</li>
<li><strong>Coarse-to-Fine 트래킹</strong>: 초기에는 저해상도에서 대략적인 포즈를 추정하고, 점차 고해상도로 정밀하게 포즈를 보정하는 방식을 사용하여 연산 시간을 단축하면서도 강건한 트래킹을 수행한다. Replica 데이터셋에서 평균 386 FPS의 렌더링 속도를 기록하였다.</li>
</ul>
<h4>3.2.3 ) MonoGS: Monocular Gaussian SLAM</h4>
<p>대부분의 로봇이 RGB-D 센서를 탑재하지만, 드론이나 저가형 로봇은 단안(Monocular) RGB 카메라만을 사용할 수 있다. <em>MonoGS</em> 18는 깊이 정보 없이 RGB 이미지만으로 3DGS SLAM을 수행한다.</p>
<ul>
<li><strong>기하학적 정규화</strong>: 깊이 정보의 부재로 인한 척도 모호성(Scale Ambiguity)과 깊이 추정의 불안정성을 해결하기 위해, 기하학적 코드북과 정규화 항을 도입하여 3차원 구조의 일관성을 강제한다.</li>
<li><strong>한계 및 극복</strong>: 단안 방식은 RGB-D 방식에 비해 트래킹 정확도가 떨어질 수밖에 없으나, 최근 연구에서는 사전 학습된 깊이 추정 네트워크(Depth Prior)를 결합하거나 관성 측정 장치(IMU)를 융합하여 성능을 개선하고 있다.21</li>
</ul>
<h3>3.3  성능 비교 평가</h3>
<p>다음 표는 주요 3DGS SLAM 알고리즘과 기존 방식들의 성능을 Replica 및 TUM-RGBD 데이터셋을 기준으로 비교한 것이다.18 수치는 평균 절대 궤적 오차(ATE, cm)와 렌더링 속도(FPS), 그리고 구조적 유사도(SSIM)를 포함한다.</p>
<table><thead><tr><th><strong>알고리즘</strong></th><th><strong>센서 타입</strong></th><th><strong>ATE (cm) ↓</strong></th><th><strong>Rendering FPS ↑</strong></th><th><strong>SSIM ↑</strong></th><th><strong>특징 및 비고</strong></th></tr></thead><tbody>
<tr><td><strong>SplaTAM</strong> 14</td><td>RGB-D</td><td><strong>0.36</strong></td><td>400+</td><td>0.86~0.95</td><td>고품질 매핑, 실루엣 마스크, 높은 연산 요구량</td></tr>
<tr><td><strong>GS-SLAM</strong> 12</td><td>RGB-D</td><td>0.50</td><td>386</td><td>0.92</td><td>적응형 확장, 빠른 트래킹, 균형 잡힌 성능</td></tr>
<tr><td><strong>MonoGS</strong> 19</td><td>RGB</td><td>0.58</td><td>&lt; 10 (Full System)</td><td>0.85</td><td>단안 카메라 지원, 하드웨어 제약 시 유리</td></tr>
<tr><td><strong>Point-SLAM</strong></td><td>RGB-D</td><td>0.52</td><td>&lt; 5</td><td>0.80~0.90</td><td>포인트 기반, 렌더링 속도 느림</td></tr>
<tr><td><strong>NICE-SLAM</strong></td><td>RGB-D</td><td>1.80+</td><td>&lt; 2</td><td>0.80</td><td>NeRF 기반, 매우 느린 속도, 엣지 구동 불가</td></tr>
</tbody></table>
<p><strong>분석 및 시사점</strong>:</p>
<ul>
<li><strong>속도 혁명</strong>: 3DGS 기반 SLAM(SplaTAM, GS-SLAM)은 기존 NeRF 기반 SLAM(NICE-SLAM)이나 포인트 기반 SLAM 대비 수십 배에서 수백 배 빠른 렌더링 속도를 보여준다. 이는 로봇이 고속으로 이동하거나 급격히 회전하는 상황에서도 트래킹을 잃지 않게(Tracking Loss 방지) 하는 결정적인 요인이다.</li>
<li><strong>정확도와 자원의 트레이드오프</strong>: <em>SplaTAM</em>은 가장 높은 정확도를 보이지만 메모리 사용량이 많을 수 있다. 반면, <em>GS-SLAM</em>은 속도와 정확도 사이의 균형을 유지한다. 엣지 디바이스에서는 <em>MonoGS</em>와 같이 센서 의존도를 낮추거나, 앞서 언급한 경량화 기법(Compact3D 등)을 SLAM 파이프라인에 통합하여 메모리 효율을 높이는 전략이 필요하다.</li>
<li><strong>동적 환경 대응</strong>: 최근 <em>DyGS-SLAM</em>과 같은 연구들은 동적 객체(사람, 이동하는 차량 등)가 존재하는 환경에서도 강건한 SLAM을 수행하기 위해 동적 가우시안과 정적 가우시안을 분리하여 관리하는 방법을 제안하고 있다.24</li>
</ul>
<h2>4.  로봇 내비게이션 및 물리적 조작을 위한 응용</h2>
<p>SLAM을 통해 맵이 작성되었다면, 로봇은 이를 바탕으로 목적지까지 이동(Navigation)하거나 물체를 조작(Manipulation)해야 한다. 3DGS는 시각적으로 우수하지만, 물리적 상호작용을 위한 충돌 모델이나 의미론적 정보가 부족하다는 한계가 있다. 이를 극복하기 위한 최신 연구 동향은 다음과 같다.</p>
<h3>4.1  안전한 자율 주행을 위한 Splat-Nav</h3>
<p><em>Splat-Nav</em> 25는 3DGS 맵을 로봇의 경로 계획(Path Planning)에 직접 활용하는 프레임워크다.</p>
<ul>
<li><strong>확률적 충돌 검사</strong>: 가우시안은 명확한 경계면(Surface)이 없는 확률 분포이다. <em>Splat-Nav</em>는 가우시안의 99% 신뢰 구간(Confidence Interval)을 점유 공간으로 간주하여 충돌 가능성을 평가한다.</li>
<li><strong>안전 통로 생성</strong>: 직접적인 충돌 검사는 비용이 많이 들고 미분 불가능하므로, <em>Splat-Nav</em>는 ’안전 이동 통로(Safe Corridor)’를 정의하는 폴리토프(Polytope)를 생성하고, 이 내부에서 베지어 곡선(Bézier Curve)을 이용하여 부드러운 경로를 생성한다.</li>
<li><strong>성능</strong>: 온보드 RGB 카메라만으로 25Hz 이상의 상태 추정(Splat-Loc)과 2Hz 이상의 경로 재계획(Splat-Plan)을 수행하며, 이는 기존 NeRF 기반 내비게이션 대비 한 차수(Order of magnitude) 빠른 처리 속도이다.</li>
</ul>
<h3>4.2  6-DoF 조작을 위한 GraspSplats 및 언어 기반 상호작용</h3>
<p>로봇 팔을 이용한 파지(Grasping) 및 조작 작업에서는 물체의 정확한 형상 인식과 의미론적 이해가 필수적이다.</p>
<ul>
<li><strong>GraspSplats</strong> 27: 3DGS에 언어-비전 모델(CLIP 등)의 임베딩을 통합하여, 사용자의 자연어 명령(예: “컵의 손잡이를 잡아라”)을 이해하고 해당 부위의 가우시안을 식별한다. <em>GraspSplats</em>는 가우시안의 기하학적 정보를 활용하여 6-DoF 파지 포즈를 밀리초(ms) 단위로 제안하며, 포인트 트래커를 통해 물체가 움직이거나 변형되어도 실시간으로 파지 지점을 추적한다. 이는 정적인 씬에 국한되었던 기존 방법론을 넘어 동적 조작의 가능성을 열었다.</li>
<li><strong>ManiGaussian</strong> 29: 로봇의 행동에 따른 환경의 변화를 예측하기 위해 3DGS 기반의 월드 모델(World Model)을 구축한다. 이는 강화학습 에이전트가 미래의 상태를 시각적으로 시뮬레이션하고 최적의 행동을 학습하는 데 활용된다.</li>
</ul>
<h3>4.3  물리 엔진과의 통합 및 디지털 트윈</h3>
<p><em>High-Fidelity Digital Twin</em> 30 연구 등은 3DGS 데이터를 물리 엔진(Unity, ROS2 MoveIt, PhysX)이 이해할 수 있는 형태로 변환하는 데 주력한다.</p>
<ul>
<li><strong>충돌 메쉬 생성</strong>: 3DGS의 가우시안 클라우드에서 등위면(Isosurface) 추출 알고리즘(Marching Cubes 등)을 적용하거나, 가시성 기반 필터링을 통해 노이즈(Floaters)를 제거하고 충돌 검사가 가능한 메쉬(Mesh)를 실시간으로 생성한다.</li>
<li><strong>물리 속성 부여</strong>: <em>PhysGaussian</em> 31과 같이 가우시안 자체에 질량, 탄성, 마찰 계수 등의 물리적 속성을 부여하여, 별도의 메쉬 변환 없이도 물리 시뮬레이션과 렌더링이 동시에 가능한 통합 표현법이 연구되고 있다.</li>
</ul>
<h2>5.  결론 및 향후 전망</h2>
<p>3D Gaussian Splatting은 로봇의 공간 인지 능력을 시각적 리얼리즘과 실시간성이라는 두 축에서 혁신적으로 발전시키고 있다. 수 기가바이트에 달하는 데이터 크기와 불규칙한 메모리 접근 패턴은 초기 로봇 적용의 걸림돌이었으나, <strong>가지치기(Pruning)</strong>, <strong>벡터 양자화(VQ)</strong>, <strong>FPGA/ASIC 기반 하드웨어 가속</strong> 기술의 발전으로 엣지 디바이스에서도 충분히 구동 가능한 수준에 도달하였다.</p>
<p>SLAM 분야에서는 <em>SplaTAM</em>, <em>GS-SLAM</em> 등의 연구를 통해 3DGS가 단순한 렌더링 도구를 넘어 정밀한 위치 추정과 맵 생성의 핵심 엔진으로 작동할 수 있음이 입증되었다. 특히 400 FPS에 육박하는 렌더링 속도는 고속 드론 비행이나 급격한 회피 기동 중에도 안정적인 트래킹을 가능하게 한다. 나아가 <em>GraspSplats</em>와 <em>Splat-Nav</em>는 3DGS 맵이 로봇의 물리적 상호작용과 경로 계획에 직접적으로 기여할 수 있는 길을 열었다.</p>
<p>향후 연구는 <strong>분산형 다중 로봇 SLAM (Distributed Multi-robot SLAM)</strong>, <strong>의미론적 3DGS (Semantic 3DGS)</strong>, 그리고 **물리-렌더링 통합 모델 (Physics-integrated Rendering)**로 확장될 것이다. 특히 로봇 운영체제(ROS)와의 표준화된 통합과 glTF와 같은 개방형 포맷으로의 3DGS 표준화가 가속화됨에 따라, 3DGS는 차세대 로봇 공간 지능(Spatial Intelligence)을 위한 범용 미들웨어로 자리 잡을 것으로 전망된다.</p>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>