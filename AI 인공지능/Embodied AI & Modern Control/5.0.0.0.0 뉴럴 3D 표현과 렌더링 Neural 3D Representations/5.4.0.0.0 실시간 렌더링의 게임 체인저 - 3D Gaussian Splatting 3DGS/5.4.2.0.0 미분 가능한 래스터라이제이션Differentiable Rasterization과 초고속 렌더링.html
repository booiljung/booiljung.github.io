<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.4.2 미분 가능한 래스터라이제이션(Differentiable Rasterization)과 초고속 렌더링</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.4.2 미분 가능한 래스터라이제이션(Differentiable Rasterization)과 초고속 렌더링</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 5. 뉴럴 3D 표현과 렌더링 (Neural 3D Representations)</a> / <a href="index.html">5.4 실시간 렌더링의 게임 체인저: 3D Gaussian Splatting (3DGS)</a> / <span>5.4.2 미분 가능한 래스터라이제이션(Differentiable Rasterization)과 초고속 렌더링</span></nav>
                </div>
            </header>
            <article>
                <h1>5.4.2 미분 가능한 래스터라이제이션(Differentiable Rasterization)과 초고속 렌더링</h1>
<h2>1.  서론: 렌더링 패러다임의 대전환과 명시적 표현의 부활</h2>
<p>현대 컴퓨터 그래픽스와 3D 비전 기술의 발전사에서 **미분 가능한 래스터라이제이션(Differentiable Rasterization)**의 등장은 단순한 성능 최적화를 넘어선 렌더링 철학의 근본적인 전환을 상징한다.1 지난 수년간 3D 장면 복원(Scene Reconstruction) 및 새로운 시점 합성(Novel View Synthesis) 분야를 지배해 온 것은 신경 방사형 필드(Neural Radiance Fields, NeRF)로 대표되는 암시적(Implicit) 표현 방식과 볼륨 레이 마칭(Volumetric Ray Marching) 기법이었다.4 NeRF는 연속적인 MLP(Multi-Layer Perceptron) 네트워크를 통해 장면의 기하학적 정보와 색상을 인코딩함으로써 고해상도의 포토리얼리스틱한 이미지를 생성하는 데 성공했으나, 본질적으로 광선 하나당 수백 번의 샘플링과 신경망 연산을 요구하는 막대한 계산 비용으로 인해 실시간 렌더링과 빠른 학습 속도를 달성하는 데에는 태생적인 한계를 지니고 있었다.6</p>
<p>이러한 맥락에서 등장한 **3D Gaussian Splatting(3DGS)**은 “렌더링은 빨라야 한다“는 그래픽스의 오랜 명제를 다시금 상기시키며, 명시적(Explicit) 기하 표현인 포인트 클라우드(Point Cloud) 기반의 접근 방식을 현대적인 미분 가능 렌더링 파이프라인과 결합시켰다.2 3DGS의 핵심 엔진인 미분 가능한 래스터라이저는 수백만 개의 3D 가우시안(Gaussian) 프리미티브를 2D 화면에 투영하고 합성하는 과정을 수학적으로 완벽하게 미분 가능하도록 설계함으로써, 2D 이미지의 픽셀 오차를 3D 공간의 기하학적 파라미터(위치, 회전, 크기, 불투명도, 색상)로 역전파(Backpropagation)할 수 있게 만들었다.2</p>
<p>본 5.4.2장에서는 3DGS가 어떻게 기존의 느린 볼륨 렌더링 방식을 타파하고 1080p 해상도에서 100 FPS 이상의 초고속 렌더링과 30분 이내의 빠른 학습 속도를 동시에 달성했는지, 그 기술적 심층부를 해부한다. 특히, EWA(Elliptical Weighted Average) 스플래팅 이론에 기반한 투영 기하학, GPU 병렬 처리를 극대화하는 타일 기반 정렬(Tile-based Sorting) 알고리즘, 그리고 메모리 사용량을 획기적으로 줄인 투과율 복원(Transmittance Recovery) 기반의 역전파 메커니즘을 상세히 기술한다. 이는 독자로 하여금 단순한 알고리즘의 이해를 넘어, 하드웨어 친화적인 딥러닝 렌더링 시스템을 설계하는 통찰력을 제공할 것이다.</p>
<h2>2.  수학적 기초: 3D 가우시안의 투영 기하학 (Mathematical Foundations)</h2>
<p>미분 가능한 래스터라이제이션의 첫 단계는 3차원 월드 공간(World Space)에 정의된 이방성(Anisotropic) 가우시안을 2차원 화면 공간(Screen Space)으로 투영하는 것이다. 이 과정은 단순한 점의 이동이 아니라, 3차원 타원체(Ellipsoid)의 형상 정보를 2차원 평면상의 타원(Ellipse)으로 변환하는 기하학적 사상(Mapping) 과정이다.1</p>
<h3>2.1 D 공분산 행렬의 파라미터화와 물리적 의미</h3>
<p>3DGS는 장면을 구성하는 기본 단위로 3D 가우시안 <span class="math math-inline">G(x)</span>를 사용한다. 각 가우시안은 평균(위치) <span class="math math-inline">\mu \in \mathbb{R}^3</span>와 공분산 행렬 <span class="math math-inline">\Sigma \in \mathbb{R}^{3 \times 3}</span>로 정의된다. 여기서 공분산 행렬 <span class="math math-inline">\Sigma</span>는 가우시안의 크기와 방향성을 결정하는 핵심 요소이다.9 하지만 <span class="math math-inline">\Sigma</span>를 직접 최적화할 경우, 행렬이 양의 준정부호(Positive Semi-definite) 조건을 만족하지 못하게 되어 물리적으로 불가능한 형상이 될 위험이 있다. 이를 방지하기 위해 3DGS는 스케일링 벡터 <span class="math math-inline">s \in \mathbb{R}^3</span>와 회전 쿼터니언 <span class="math math-inline">q \in \mathbb{R}^4</span>를 사용하여 공분산을 간접적으로 구성한다.1</p>
<p>회전 쿼터니언 <span class="math math-inline">q</span>로부터 유도된 회전 행렬을 <span class="math math-inline">R</span>, 스케일링 벡터 <span class="math math-inline">s</span>로 구성된 대각 행렬을 <span class="math math-inline">S</span>라고 할 때, 3D 공분산 행렬 <span class="math math-inline">\Sigma</span>는 다음과 같이 분해된다:<br />
<span class="math math-display">
\Sigma = R S S^T R^T
</span><br />
이 수식은 최적화 과정에서 <span class="math math-inline">s</span>와 <span class="math math-inline">q</span>에 대해 경사 하강법(Gradient Descent)을 적용하더라도 항상 유효한 타원체 형상을 유지하도록 보장한다. 미분 가능한 래스터라이저는 후방향 패스에서 <span class="math math-inline">\Sigma</span>에 대한 미분을 계산한 뒤, 연쇄 법칙(Chain Rule)을 통해 이를 <span class="math math-inline">s</span>와 <span class="math math-inline">q</span>에 대한 미분으로 분해하여 전달한다.9</p>
<h3>2.2 뷰 변환(Viewing Transformation)과 야코비안 선형화(Jacobian Linearization)</h3>
<p>월드 좌표계에 있는 가우시안을 카메라 시점으로 옮기기 위해 뷰 변환 행렬 <span class="math math-inline">W</span>가 적용된다. 카메라 좌표계에서의 공분산 <span class="math math-inline">\Sigma_{camera}</span>는 다음과 같다 9:<br />
<span class="math math-display">
\Sigma_{camera} = W \Sigma W^T
</span><br />
가장 핵심적인 단계는 3D 가우시안을 2D 이미지 평면으로 투영하는 것이다. 원근 투영(Perspective Projection)은 비선형 변환이기 때문에, 가우시안의 분포를 완벽하게 보존하면서 2D로 변환하는 것은 불가능하다. 이에 3DGS는 Zwicker et al.(2001)의 EWA Splatting 기법을 차용하여, 투영 함수 <span class="math math-inline">\phi</span>를 국소적으로 선형화하는 근사법을 사용한다.9 투영 변환의 야코비안(Jacobian) 행렬 <span class="math math-inline">J</span>를 이용하면, 2D 화면 공간에서의 공분산 <span class="math math-inline">\Sigma&#39;</span>는 다음과 같이 근사된다:<br />
<span class="math math-display">
\Sigma&#39; = J W \Sigma W^T J^T
</span><br />
여기서 야코비안 행렬 <span class="math math-inline">J \in \mathbb{R}^{2 \times 3}</span>는 카메라 좌표계의 점 <span class="math math-inline">t = (t_x, t_y, t_z)</span>를 이미지 평면으로 투영할 때의 미분 계수들로 구성된다. 카메라의 초점 거리(Focal Length)를 <span class="math math-inline">f_x, f_y</span>라고 할 때, <span class="math math-inline">J</span>는 다음과 같이 정의된다 10:<br />
<span class="math math-display">
J = \begin{bmatrix} f_x / t_z &amp; 0 &amp; -(f_x \cdot t_x) / t_z^2 \\ 0 &amp; f_y / t_z &amp; -(f_y \cdot t_y) / t_z^2 \end{bmatrix}
</span><br />
이 행렬 <span class="math math-inline">J</span>는 3D 가우시안이 카메라로부터 멀어질수록(<span class="math math-inline">t_z</span>가 커질수록) 화면상에 투영되는 크기가 작아지는 원근 효과를 수학적으로 모델링한다. 또한, 시선의 중심에서 벗어난 주변부(Periphery)로 갈수록 가우시안이 찌그러져 보이는 현상까지도 이 선형 근사 모델을 통해 자연스럽게 처리된다.</p>
<h3>2.3 D 공분산의 역행렬 연산과 수치적 안정성</h3>
<p>래스터라이제이션 단계에서 각 픽셀에 대한 가우시안의 기여도(불투명도 <span class="math math-inline">\alpha</span>)를 계산하기 위해서는 2D 가우시안 분포의 지수항을 계산해야 하며, 여기에는 2D 공분산 행렬의 역행렬 <span class="math math-inline">(\Sigma&#39;)^{-1}</span>이 포함된다.<br />
<span class="math math-display">
G(x) = \exp \left( -\frac{1}{2} (x - \mu&#39;)^T (\Sigma&#39;)^{-1} (x - \mu&#39;) \right)
</span><br />
이때 <span class="math math-inline">\Sigma&#39;</span>가 특이 행렬(Singular Matrix)이 되거나 행렬식(Determinant)이 0에 가까워지면 역행렬 계산이 불안정해져 렌더링에 치명적인 아티팩트(Artifact)를 유발할 수 있다. 이를 방지하기 위해 3DGS 래스터라이저는 계산된 2D 공분산의 대각 성분에 작은 엡실론 값(예: 0.3 I)을 더해주는 저역 통과 필터(Low-pass Filter) 처리를 수행한다.12 이는 가우시안의 크기가 픽셀 크기보다 작아질 때 발생할 수 있는 앨리어싱(Aliasing)을 방지하는 역할도 겸한다.</p>
<h2>3.  전방향 패스: 타일 기반 아키텍처와 병렬 처리 (Forward Pass Architecture)</h2>
<p>3DGS가 Mip-NeRF 360과 같은 기존 방법론 대비 수천 배 빠른 렌더링 속도를 달성할 수 있었던 비결은 GPU 하드웨어 아키텍처를 완벽하게 이해하고 설계된 <strong>타일 기반 래스터라이제이션(Tile-based Rasterization)</strong> 파이프라인에 있다.2 이 파이프라인은 전체 화면을 독립적인 타일들의 집합으로 분해함으로써, 대규모 병렬 처리와 캐시 일관성(Cache Coherency)을 극대화한다.</p>
<h3>3.1 화면 분할 및 가시성 컬링 (Screen Tiling &amp; Frustum Culling)</h3>
<p>렌더링 파이프라인의 첫 단계에서 화면은 16x16 픽셀 크기의 타일(Tile) 그리드로 분할된다.2 이는 GPU의 워프(Warp) 크기(일반적으로 32 쓰레드) 및 공유 메모리(Shared Memory) 블록 크기와 조화를 이루도록 설계된 수치이다.</p>
<p>수백만 개의 가우시안 중 화면 밖(Frustum)에 있거나 카메라 뒤쪽에 위치한 것들은 렌더링에 불필요하므로 즉시 제거(Culling)되어야 한다. 3DGS는 각 가우시안의 99% 신뢰 구간(Confidence Interval) 타원체가 뷰 프러스텀과 교차하는지 검사하는 ‘가드 밴드(Guard Band)’ 방식의 컬링을 수행한다.14 이 단계를 통과한 유효한 가우시안들만이 다음 단계인 인스턴싱으로 넘어간다.</p>
<h3>3.2 가우시안 인스턴싱과 정렬 키 생성 (Instancing &amp; Key Generation)</h3>
<p>단일 가우시안은 화면상에서 여러 개의 타일에 걸쳐 존재할 수 있다. 예를 들어, 카메라에 매우 가까이 있는 가우시안은 수십 개의 타일을 덮을 수 있다. 3DGS는 이러한 가우시안을 각 타일마다 별도의 처리 단위로 복제하는 인스턴싱(Instancing) 과정을 거친다.2</p>
<p>복제된 각 가우시안 인스턴스에는 64비트의 정렬 키(Sort Key)가 부여된다. 이 키의 비트 구성은 래스터라이저의 효율성을 결정짓는 중요한 설계 요소이다 16:</p>
<ul>
<li><strong>상위 32비트 (High 32-bit):</strong> 타일 ID (Tile ID)</li>
<li><strong>하위 32비트 (Low 32-bit):</strong> 뷰 공간 깊이 (View Space Depth, <span class="math math-inline">z</span>-depth)</li>
</ul>
<p>이러한 키 구조는 후속 정렬 단계에서 두 가지 효과를 동시에 달성한다. 첫째, 모든 가우시안을 타일별로 그룹화한다(상위 비트 기준). 둘째, 같은 타일 내에 속한 가우시안들은 카메라로부터 가까운 순서대로(Front-to-Back) 정렬한다(하위 비트 기준). 이는 알파 블렌딩 시 앞쪽 물체가 뒤쪽 물체를 가리는 가시성(Visibility) 처리를 자연스럽게 해결해준다.</p>
<h3>3.3 GPU Radix Sort를 통한 초고속 정렬</h3>
<p>생성된 키들을 정렬하기 위해 3DGS는 <strong>GPU Radix Sort</strong> 알고리즘을 사용한다.2 Radix Sort는 비교 기반 정렬(Comparison Sort)과 달리 <span class="math math-inline">O(N)</span>의 선형 시간 복잡도를 가지며, GPU의 병렬 아키텍처에서 매우 효율적으로 동작한다. 특히 NVIDIA의 CUB 라이브러리와 같은 고도로 최적화된 프리미티브를 활용하여 수백만 개의 키를 수 밀리초(ms) 내에 정렬할 수 있다.17 정렬이 완료되면, 각 타일은 자신에게 속한 가우시안들의 시작 인덱스와 끝 인덱스 범위(Range)를 식별할 수 있게 되며, 이후 각 타일은 완전히 독립적으로 병렬 렌더링을 수행한다.</p>
<h3>3.4 타일별 픽셀 셰이딩과 조기 종료 최적화 (Per-Tile Shading &amp; Early Stopping)</h3>
<p>각 타일은 하나의 GPU 쓰레드 블록(Thread Block)에 할당되어 처리된다. 블록 내의 쓰레드들은 협력하여 해당 타일에 속한 가우시안 데이터를 전역 메모리(Global Memory)에서 고속의 공유 메모리(Shared Memory)로 로드한다.18 이후 각 픽셀을 담당하는 쓰레드는 정렬된 가우시안 리스트를 순회하며 색상과 불투명도를 누적한다.</p>
<p>이때 조기 종료(Early Stopping) 기법이 적용되어 렌더링 속도를 획기적으로 높인다. 알파 블렌딩 공식에 따라 누적 투과율 <span class="math math-inline">T</span>가 0에 가까워지면(즉, 앞의 물체들에 의해 뒤쪽이 완전히 가려지면), 더 이상의 가우시안을 처리하는 것은 무의미하다.<br />
<span class="math math-display">
T_{final} &lt; \epsilon \quad (\text{예: } \epsilon = 0.0001)
</span><br />
이 조건이 만족되면 해당 픽셀의 처리는 즉시 중단된다. 더 나아가, 타일 내의 모든 픽셀이 포화(Saturated) 상태에 도달하면 해당 타일의 전체 연산이 조기에 종료된다.18 이는 깊이 복잡도(Depth Complexity)가 높은 장면에서 불필요한 연산을 제거하여 프레임 레이트를 방어하는 핵심 기제이다.</p>
<h2>4.  후방향 패스: 미분 가능성과 경사 역전파 (Backward Pass &amp; Transmittance Recovery)</h2>
<p>전방향 패스가 렌더링 속도를 책임진다면, 후방향 패스(Backward Pass)는 3DGS의 학습 효율과 메모리 사용량을 결정짓는 핵심 파트이다. 래스터라이제이션의 모든 과정은 미분 가능해야 하며, 이를 통해 2D 이미지와 Ground Truth 이미지 간의 차이(Loss)가 3D 가우시안의 파라미터 업데이트로 이어져야 한다.</p>
<h3>4.1 자동 미분(Auto-differentiation)의 한계와 분석적 미분의 필요성</h3>
<p>PyTorch와 같은 딥러닝 프레임워크의 자동 미분 기능을 래스터라이제이션 과정 전체에 적용하는 것은 사실상 불가능하다. 전방향 패스에서 수행되는 수백만 번의 블렌딩 연산과 중간값들을 계산 그래프(Computational Graph)에 모두 저장하려면 수백 기가바이트의 VRAM이 필요하기 때문이다. 이를 해결하기 위해 3DGS 저자들은 래스터라이제이션의 미분 공식을 수학적으로 직접 유도(Analytical Derivation)하고, 이를 최적화된 CUDA 커널로 직접 구현하는 방식을 택했다.2 이 방식은 자동 미분 대비 메모리 사용량을 수십 분의 일로 줄이면서도 정확한 경사(Gradient) 계산을 보장한다.</p>
<h3>4.2 투과율 복원(Transmittance Recovery) 기법: 메모리 혁신</h3>
<p>후방향 패스에서 가장 큰 난관은 각 가우시안이 픽셀에 기여했을 당시의 투과율 <span class="math math-inline">T_i</span> 값을 알아야 한다는 점이다. 전방향 패스에서는 <span class="math math-inline">T_i</span>가 계속 업데이트되면서 사라지기 때문에, 일반적인 방식으로는 모든 <span class="math math-inline">T_i</span>를 별도의 버퍼에 저장해야 한다 (<span class="math math-inline">O(N \times \text{Pixels})</span> 메모리).</p>
<p>3DGS는 **투과율 복원(Transmittance Recovery)**이라는 혁신적인 기법을 도입하여 이 문제를 해결했다. 전방향 패스가 끝난 시점의 최종 누적 불투명도 <span class="math math-inline">\alpha_{final}</span>만을 저장해두고, 후방향 패스에서 이를 역산하여 필요한 <span class="math math-inline">T_i</span>를 복원하는 것이다.2</p>
<p>알파 블렌딩의 점화식 <span class="math math-inline">T_{i+1} = T_i (1 - \alpha_i)</span>를 역으로 이용하면 다음과 같은 관계가 성립한다:<br />
<span class="math math-display">
T_i = \frac{T_{i+1}}{1 - \alpha_i}
</span><br />
이 수식을 통해, 래스터라이저는 중간 투과율 값들을 저장하지 않고도, 뒤에서 앞으로(또는 구현에 따라 앞에서 뒤로) 순회하며 필요한 시점의 투과율을 즉석에서 계산해낼 수 있다. 하지만 <span class="math math-inline">1 - \alpha_i</span>가 0에 가까울 경우 나눗셈 연산의 수치적 불안정성(Division by Zero)이 발생할 수 있으므로, 실제 구현에서는 전방향 패스와 동일하게 정순(Front-to-Back)으로 순회하며 <span class="math math-inline">T</span>를 다시 계산하는 방식이 주로 사용되기도 한다.18 어떠한 방식을 쓰든 핵심은 **“모든 중간 상태를 저장하지 않는다”**는 메모리 절약 철학이다.</p>
<h3>4.3 파라미터별 경사(Gradient) 계산의 세부 메커니즘</h3>
<p>후방향 패스 커널은 픽셀 색상 오차 <span class="math math-inline">\frac{\partial \mathcal{L}}{\partial C}</span>를 입력받아 각 가우시안 파라미터에 대한 미분을 계산한다. 주요 파라미터별 미분 흐름은 다음과 같다 20:</p>
<ul>
<li>
<p>색상(<span class="math math-inline">c_i</span>)에 대한 미분: 가우시안의 색상이 최종 픽셀에 얼마나 기여했는지는 그 당시의 투과율 <span class="math math-inline">T_i</span>와 자신의 불투명도 <span class="math math-inline">\alpha_i</span>에 비례한다.<br />
<span class="math math-display">
\frac{\partial \mathcal{L}}{\partial c_i} = \sum_{\text{pixels}} \frac{\partial \mathcal{L}}{\partial C} \cdot \alpha_i T_i
</span></p>
</li>
<li>
<p>불투명도(<span class="math math-inline">\alpha_i</span>)에 대한 미분: 불투명도의 변화는 해당 가우시안의 기여도뿐만 아니라, 그 뒤에 있는 모든 가우시안의 가시성(<span class="math math-inline">T_{k&gt;i}</span>)을 감소시키는 효과를 가진다. 따라서 미분식은 양의 항(자신의 기여 증가)과 음의 항(뒤쪽 가우시안 차폐)의 합으로 구성된다.<br />
<span class="math math-display">
\frac{\partial \mathcal{L}}{\partial \alpha_i} = \frac{\partial \mathcal{L}}{\partial C} \left( c_i T_i - \frac{1}{1-\alpha_i} \sum_{k &gt; i} c_k \alpha_k T_k \right)
</span></p>
</li>
<li>
<p><strong>2D 평균(<span class="math math-inline">\mu&#39;</span>) 및 공분산(<span class="math math-inline">\Sigma&#39;</span>)에 대한 미분:</strong> 불투명도 <span class="math math-inline">\alpha_i</span>는 가우시안의 위치와 형상에 종속적인 함수이므로, <span class="math math-inline">\alpha_i</span>에 대한 경사는 다시 가우시안의 2D 중심 좌표와 공분산 행렬에 대한 경사로 전파된다.</p>
</li>
<li>
<p><strong>3D 파라미터(<span class="math math-inline">\mu, s, q</span>)로의 역전파:</strong> 마지막으로, 앞서 유도한 뷰 변환 및 투영 변환의 야코비안 행렬 <span class="math math-inline">J</span>와 회전 행렬 <span class="math math-inline">W</span>의 전치(Transpose)를 곱하여, 화면 공간(Screen Space)에서의 경사를 월드 공간(World Space)의 파라미터 변화량으로 변환한다.13<br />
<span class="math math-display">
\frac{\partial \mathcal{L}}{\partial \mu_{3D}} = J^T \cdot \frac{\partial \mathcal{L}}{\partial \mu_{2D}}
</span></p>
</li>
</ul>
<p>이러한 정교한 미분 흐름 덕분에 3DGS는 2D 이미지만을 관측하고도 3D 공간상에서 가우시안들을 정확한 위치로 이동시키고, 적절한 크기와 방향으로 변형시킬 수 있게 된다.</p>
<h2>5.  적응형 밀도 제어와의 상호작용 (Interaction with Adaptive Density Control)</h2>
<p>미분 가능한 래스터라이제이션의 역할은 파라미터 값을 수정하는 것에 그치지 않는다. 3DGS 알고리즘의 가장 독창적인 특징 중 하나인 **적응형 밀도 제어(Adaptive Density Control)**는 래스터라이저가 출력하는 경사(Gradient) 정보를 나침반 삼아 가우시안의 개수와 분포를 동적으로 조절한다.1</p>
<h3>5.1 뷰 공간 위치 경사(View-space Position Gradient)의 활용</h3>
<p>래스터라이제이션 과정에서 계산된 ’뷰 공간 위치에 대한 경사 평균값(<span class="math math-inline">\nabla_{pos}</span>)’은 해당 가우시안이 기하학적으로 불안정하거나 표현력이 부족한 상태임을 나타내는 강력한 지표이다. 특정 가우시안의 위치 경사가 크다는 것은, 해당 가우시안을 이동시켜야만 렌더링 오차를 줄일 수 있다는 뜻이며, 이는 그 위치에 기하학적 정보가 충분하지 않다는 신호로 해석된다.</p>
<h3>5.2 복제(Clone)와 분할(Split) 전략</h3>
<p>3DGS는 100회 정도의 반복(Iteration)마다 가우시안들의 평균 위치 경사 값을 검사하여 다음과 같은 구조적 변경을 수행한다 1:</p>
<ul>
<li><strong>Under-reconstruction (과소 재구성) <span class="math math-inline">\rightarrow</span> 복제(Clone):</strong> 경사가 크지만 가우시안의 크기(Scale)가 작은 경우, 이는 해당 영역에 디테일이 더 필요하지만 가우시안 하나로는 부족함을 의미한다. 이 경우 가우시안을 동일한 위치에 복제하여 밀도를 높인다.</li>
<li><strong>Over-reconstruction (과대 재구성) <span class="math math-inline">\rightarrow</span> 분할(Split):</strong> 경사가 크고 가우시안의 크기도 큰 경우, 이는 하나의 거대한 가우시안이 복잡한 지형을 억지로 덮고 있음을 의미한다. 이 경우 큰 가우시안을 두 개의 작은 가우시안으로 분할(Split)하여 더 세밀한 표현이 가능하도록 만든다. 분할 시 크기는 1.6배 축소된다.</li>
</ul>
<h3>5.3 래스터라이저 기반의 제거(Prune)</h3>
<p>또한 래스터라이저는 렌더링에 거의 기여하지 않는 가우시안을 식별하는 역할도 한다. 학습 과정에서 불투명도(<span class="math math-inline">\alpha</span>)가 특정 임계값(예: 0.005) 이하로 떨어지거나, 화면 밖으로 멀리 벗어난 가우시안들은 주기적으로 제거(Prune)된다.9 이는 전체 가우시안의 수를 적정 수준으로 유지하여 메모리 폭증을 막고 렌더링 속도를 보존하는 중요한 최적화 과정이다.</p>
<p>결국 미분 가능한 래스터라이저는 단순한 이미지 생성기를 넘어, 3D 장면의 구조적 성장(Growth)과 가지치기(Pruning)를 지휘하는 **‘구조적 피드백 루프(Structural Feedback Loop)’**의 핵심 엔진으로 작동한다.</p>
<h2>6.  하드웨어 가속 및 최적화 구현 (Hardware Acceleration &amp; Optimization)</h2>
<p>3DGS 논문이 발표된 이후, 그 잠재력을 극대화하기 위한 다양한 하드웨어 가속 기법과 최적화 구현체들이 등장했다. 이는 3DGS가 단순한 알고리즘을 넘어 하나의 시스템으로서 진화하고 있음을 보여준다.</p>
<h3>6.1 gsplat 라이브러리와 메모리 최적화</h3>
<p>원저자의 구현체(Inria version) 이후 등장한 <strong>gsplat</strong> 라이브러리는 3DGS의 래스터라이제이션 커널을 더욱 극한으로 최적화했다.9 gsplat은 전방향 패스에서 타일별 데이터 로딩 시 공유 메모리(Shared Memory) 접근 패턴을 개선하여 뱅크 충돌(Bank Conflict)을 줄이고, 후방향 패스에서 불필요한 원자적 연산(Atomic Operation)을 최소화했다. 이를 통해 Mip-NeRF 360 데이터셋 기준 학습 속도를 15% 이상 단축하고 메모리 사용량을 최대 4배 절감하는 성과를 거두었다.9</p>
<h3>6.2 FlashGS와 LiteGS: 극한의 속도와 경량화</h3>
<p><strong>FlashGS</strong> 23와 <strong>LiteGS</strong> 24는 3DGS의 래스터라이저를 수정하여 더 높은 FPS와 더 적은 메모리를 목표로 한다.</p>
<ul>
<li><strong>FlashGS:</strong> 대규모 장면에서의 렌더링 속도 저하를 막기 위해, 가우시안의 밀집도에 따라 동적으로 타일 크기를 조절하거나 압축된 가우시안 표현형을 사용하여 데이터 전송 대역폭을 줄인다. 이는 1080p 해상도에서 100 FPS를 훌쩍 넘는 성능을 보여준다.</li>
<li><strong>LiteGS:</strong> 모바일 장치나 엣지 디바이스와 같이 자원이 제한된 환경을 타겟으로 한다. 연속적인 가우시안 속성을 양자화(Quantization)하거나, 중요도가 낮은 가우시안을 공격적으로 컬링하는 경량화된 래스터라이저를 탑재하여 메모리 부족 문제를 해결한다.</li>
</ul>
<h3>6.3 전용 하드웨어 가속기: GSCore</h3>
<p>소프트웨어적 최적화를 넘어, 3DGS 렌더링만을 위한 전용 하드웨어 아키텍처인 <strong>GSCore</strong>와 같은 연구도 등장했다.25 GSCore는 가우시안의 정렬과 투영, 블렌딩 연산에 특화된 파이프라인을 실리콘 레벨에서 구현하여, 범용 GPU 대비 전력 소모를 획기적으로 줄이면서도 모바일 환경에서 실시간 렌더링이 가능함을 입증했다. 이는 향후 AR 글래스나 VR 헤드셋에 3DGS 전용 칩셋이 탑재될 가능성을 시사한다.</p>
<h2>7.  비교 분석 및 성능 평가 (Comparative Analysis)</h2>
<p>3DGS의 미분 가능한 래스터라이제이션이 가져온 성능 혁신을 객관적으로 평가하기 위해, 기존의 대표적인 렌더링 기법들과의 정량적, 정성적 비교를 수행한다. 비교 대상은 고품질 렌더링의 대명사인 <strong>Mip-NeRF 360</strong>, 빠른 학습 속도를 자랑하는 <strong>Instant-NGP</strong>, 그리고 복셀 기반의 <strong>Plenoxels</strong>이다.</p>
<h3>7.1 [표 5.4.2.1] 렌더링 알고리즘별 성능 및 효율성 비교 (Mip-NeRF 360 데이터셋 기준)</h3>
<table><thead><tr><th><strong>항목 (Metric)</strong></th><th><strong>Mip-NeRF 360</strong></th><th><strong>Instant-NGP</strong></th><th><strong>Plenoxels</strong></th><th><strong>3D Gaussian Splatting</strong></th></tr></thead><tbody>
<tr><td><strong>기본 표현 방식</strong></td><td>Implicit (MLP)</td><td>Hybrid (Hash Grid+MLP)</td><td>Explicit (Sparse Voxel)</td><td><strong>Explicit (3D Gaussians)</strong></td></tr>
<tr><td><strong>렌더링 속도 (FPS)</strong></td><td>0.07 FPS</td><td>~10 FPS</td><td>~8 FPS</td><td><strong>&gt; 130 FPS</strong></td></tr>
<tr><td><strong>학습 시간</strong></td><td>~48 시간</td><td>~5 분</td><td>~20 분</td><td><strong>~40 분</strong></td></tr>
<tr><td><strong>화질 (PSNR)</strong></td><td>27.69 (최상)</td><td>25.50 (중)</td><td>23.08 (하)</td><td><strong>27.21 (최상급)</strong></td></tr>
<tr><td><strong>메모리 효율성</strong></td><td>낮음 (모델 작음, 렌더링 큼)</td><td>높음 (해시 충돌 가능성)</td><td>매우 낮음 (VRAM 과다)</td><td><strong>중간 (VRAM 4~10GB)</strong></td></tr>
<tr><td><strong>미분 가능성</strong></td><td>Auto-diff 의존</td><td>Auto-diff (CUDA 최적화)</td><td>Analytical</td><td><strong>Analytical Rasterizer</strong></td></tr>
</tbody></table>
<p>데이터 출처 종합: 1</p>
<h3>7.2 렌더링 속도 (FPS) 분석</h3>
<p>표에서 가장 두드러지는 차이는 단연 렌더링 속도이다. Mip-NeRF 360이 프레임당 수십 초가 걸리는 반면, 3DGS는 초당 100프레임 이상을 렌더링한다. 이는 NeRF가 광선 하나당 수백 번의 신경망 연산을 수행하는 ‘무거운(Heavy)’ 픽셀 처리 방식을 사용하는 반면, 3DGS는 정렬된 가우시안을 픽셀에 단순히 ‘덮어쓰는(Splatting)’ 가벼운 연산을 수행하기 때문이다. 특히 타일 기반 정렬과 조기 종료 최적화 덕분에 해상도가 높아져도 성능 저하가 적다는 점은 실시간 애플리케이션(VR/AR)에 결정적인 이점이다.</p>
<h3>7.3 학습 시간과 수렴 속도</h3>
<p>학습 속도 면에서 3DGS는 Instant-NGP보다는 다소 느리지만, Mip-NeRF 360에 비해서는 수십 배 빠르다. 40분 내외의 학습으로 Mip-NeRF 360에 필적하는 화질을 얻을 수 있다는 것은 생산성 측면에서 엄청난 격차이다.26 이는 래스터라이저가 제공하는 명확하고 강력한 기하학적 경사(Gradient) 덕분에 최적화가 헤매지 않고 빠르게 수렴하기 때문이다.</p>
<h3>7.4 화질과 아티팩트</h3>
<p>화질 면에서 3DGS는 Mip-NeRF 360과 거의 대등한 수준(PSNR 27점대)을 보여준다. NeRF 계열이 고주파 디테일(High-frequency Details)을 뭉개는 경향이 있는 반면, 3DGS는 이방성 가우시안을 통해 날카로운 엣지와 복잡한 텍스처를 선명하게 보존한다. 다만, 가우시안의 개수가 부족할 경우 ‘바늘 구멍(Pin-hole)’ 같은 아티팩트가 발생하거나, 반대로 가우시안이 너무 클 경우 ‘팝핑(Popping)’ 현상이 발생할 수 있으나, 이는 적응형 밀도 제어를 통해 대부분 완화된다.15</p>
<p>결론적으로 3DGS의 미분 가능한 래스터라이제이션은 **“NeRF의 품질과 래스터라이제이션의 속도”**라는 두 마리 토끼를 모두 잡은, 현재 3D 비전 분야의 게임 체인저(Game Changer)임이 분명하다.</p>
<hr />
<h2>8.  한계점 및 미래 연구 방향 (Limitations &amp; Future Directions)</h2>
<p>혁신적인 성능에도 불구하고, 현재의 미분 가능한 래스터라이제이션 기술은 몇 가지 한계점을 안고 있으며, 이는 향후 연구자들에게 중요한 과제를 제시한다.</p>
<h3>8.1 저장 공간 및 메모리 용량 문제</h3>
<p>3DGS는 장면을 수백만 개의 가우시안 파라미터로 명시적으로 저장하기 때문에, 모델 파일의 크기가 수백 MB에서 수 GB에 달할 수 있다.5 이는 수 MB 수준인 NeRF 모델에 비해 배포 및 스트리밍에 불리하다. 이를 해결하기 위해 가우시안 속성을 압축(Compression)하거나, 벡터 양자화(Vector Quantization)를 적용하여 용량을 줄이는 연구가 활발히 진행 중이다.</p>
<h3>8.2 앨리어싱(Aliasing)과 줌-인/아웃 아티팩트</h3>
<p>EWA Splatting 기반의 투영은 기본적으로 저역 통과 필터링을 포함하고 있지만, 카메라가 가우시안에 매우 근접하거나 멀어질 때 앨리어싱(계단 현상)이나 화면이 자글거리는 현상이 발생할 수 있다.14 최근 <strong>Mip-Splatting</strong>과 같은 연구는 3D 스케일 공간(Scale Space) 이론을 도입하여 이러한 앨리어싱 문제를 해결하고 다양한 해상도에서 일관된 렌더링 품질을 보장하려는 시도를 하고 있다.14</p>
<h3>8.3 동적 장면(Dynamic Scene) 및 반사 재질의 한계</h3>
<p>기본 3DGS 래스터라이저는 정적 장면(Static Scene)을 가정하고 있다. 움직이는 물체나 거울 반사와 같은 복잡한 광학 현상을 처리하기 위해서는 시간 차원(Time Dimension)을 추가한 4D Gaussian Splatting이나, 래스터라이저 내에 레이 트레이싱(Ray Tracing) 요소를 결합하려는 하이브리드 접근이 요구된다.8 이는 래스터라이제이션의 속도 이점을 유지하면서 물리 기반 렌더링(PBR)의 리얼리즘을 달성하기 위한 차세대 연구 주제이다.</p>
<h2>9.  결론 (Conclusion)</h2>
<p>본 절에서는 3D Gaussian Splatting의 기술적 중추인 **미분 가능한 래스터라이제이션(Differentiable Rasterization)**을 심도 있게 분석하였다. 이 기술은 전통적인 그래픽스 파이프라인의 효율성과 현대 딥러닝의 최적화 이론을 우아하게 결합한 사례이다.</p>
<ol>
<li><strong>수학적 정교함:</strong> 3D 공분산의 투영과 야코비안 선형화를 통해, 3D 기하 정보를 2D 화면에 미분 가능하게 연결하였다.</li>
<li><strong>구현의 효율성:</strong> 타일 기반 정렬과 투과율 복원 기법을 통해, GPU의 병렬 처리 능력을 극한까지 끌어올리고 메모리 병목을 해소하였다.</li>
<li><strong>구조적 유연성:</strong> 래스터라이제이션 과정에서 생성되는 경사 정보를 이용해 장면의 구조를 스스로 진화시키는 적응형 밀도 제어를 가능케 했다.</li>
</ol>
<p>이러한 혁신을 통해 3DGS는 실시간 렌더링, 고화질, 빠른 학습이라는 3D 비전의 난제(Trilemma)를 해결하였으며, 이는 향후 메타버스, 자율주행, 로보틱스 등 다양한 산업 분야에서 3D 데이터를 처리하는 표준 엔진으로 자리 잡을 가능성이 매우 높다. 독자들은 본 절의 내용을 바탕으로, 앞으로 더욱 진화할 미분 가능 렌더링 기술의 흐름을 이해하고 응용할 수 있는 견고한 토대를 마련했을 것이다.</p>
<h2>10. 참고 자료</h2>
<ol>
<li>3D Gaussian Splatting for Real-Time Radiance Field Rendering - Inria, https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/</li>
<li>3D Gaussian Splatting for Real-Time Radiance Field Rendering - Inria, https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/3d_gaussian_splatting_low.pdf</li>
<li>[2308.04079] 3D Gaussian Splatting for Real-Time Radiance Field Rendering - arXiv, https://arxiv.org/abs/2308.04079</li>
<li>TUM AI Lecture Series - The 3D Gaussian Splatting Adventure: Past, Present, Futur (George Drettakis) - YouTube, https://www.youtube.com/watch?v=DjOqkVIlEGY</li>
<li>The Battle For Realism in 3D Rendering: A Brief Overview of NeRFs vs. Gaussian Splatting | by Aahana | Antaeus AR | Medium, https://medium.com/antaeus-ar/the-battle-for-realism-in-3d-rendering-a-brief-overview-of-nerfs-vs-gaussian-splatting-580cff4d8801</li>
<li>3D Gaussian Splatting for Intelligence, Surveillance, and Reconnaissance - CS231n - Stanford University, https://cs231n.stanford.edu/2024/papers/3d-gaussian-splatting-for-intelligence-surveillance-and-reconnai.pdf</li>
<li>3D representation of Architectural Heritage: a comparative analysis of NeRF, Gaussian Splatting, and SfM-MVS reconstructions usi, https://isprs-archives.copernicus.org/articles/XLVIII-2-W8-2024/93/2024/isprs-archives-XLVIII-2-W8-2024-93-2024.pdf</li>
<li>3D Gaussian Splatting for Real-Time Radiance Field Rendering | Qiang Zhang, https://zhangtemplar.github.io/3d-gaussian-splatting/</li>
<li>3D Gaussian Splatting - Paper Explained, Training NeRFStudio - Learn OpenCV, https://learnopencv.com/3d-gaussian-splatting/</li>
<li>Rendering in 3D Gaussian Splatting - Scthe’s blog, https://www.sctheblog.com/blog/gaussian-splatting/</li>
<li>A Python Engineer’s Introduction to 3D Gaussian Splatting (Part 2) - Medium, https://medium.com/data-science/a-python-engineers-introduction-to-3d-gaussian-splatting-part-2-7e45b270c1df</li>
<li>Object Space EWA Surface Splatting: A Hardware Accelerated Approach to High Quality Point Rendering, https://www.merl.com/publications/docs/TR2002-31.pdf</li>
<li>gaussian_splatting/MATH.md at main - GitHub, https://github.com/joeyan/gaussian_splatting/blob/main/MATH.md</li>
<li>Rasterization - gsplat documentation, https://docs.gsplat.studio/main/apis/rasterization.html</li>
<li>Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives - arXiv, https://arxiv.org/html/2412.00578v3</li>
<li>Understanding and Exploring 3D Gaussian Splatting: A Comprehensive Overview - Medium, https://medium.com/@logessiva/understanding-and-exploring-3d-gaussian-splatting-a-comprehensive-overview-b4004f28ef1c</li>
<li>FlashGS: Efficient 3D Gaussian Splatting for Large-scale and High-resolution Rendering, https://arxiv.org/html/2408.07967v1</li>
<li>diff-gaussian-rasterization/cuda_rasterizer/forward.cu at main - GitHub, https://github.com/graphdeco-inria/diff-gaussian-rasterization/blob/main/cuda_rasterizer/forward.cu</li>
<li>kwea123/gaussian_splatting_notes: A detailed formulae explanation on gaussian splatting - GitHub, https://github.com/kwea123/gaussian_splatting_notes</li>
<li>Efficient Differentiable Hardware Rasterization for 3D Gaussian Splatting - arXiv, https://arxiv.org/html/2505.18764v1</li>
<li>Lightweight Gradient-Aware Upscaling of 3D Gaussian Splatting Images - arXiv, https://arxiv.org/html/2503.14171v2</li>
<li>3D Scene Reconstruction from the Inside: Explore the Mathematics Behind gsplat, https://rocm.blogs.amd.com/software-tools-optimization/point-2-gaussian/README.html</li>
<li>FlashGS: Efficient 3D Gaussian Splatting for Large-scale and High-resolution Rendering - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_FlashGS_Efficient_3D_Gaussian_Splatting_for_Large-scale_and_High-resolution_Rendering_CVPR_2025_paper.pdf</li>
<li>LiteGS: A High-performance Framework to Train 3DGS in Subminutes via System and Algorithm Codesign - arXiv, https://arxiv.org/html/2503.01199v3</li>
<li>GSCore: Efficient Radiance Field Rendering via Architectural Support for 3D Gaussian Splatting - Jaewoong Sim, https://jaewoong.org/pubs/asplos24-gscore.pdf</li>
<li>[Quick Review] 3D Gaussian Splatting for Real-Time Radiance Field Rendering - Liner, https://liner.com/review/3d-gaussian-splatting-for-realtime-radiance-field-rendering</li>
<li>3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes - Nicholas Sharp, https://nmwsharp.com/media/papers/gaussian-ray-tracing/GaussianRayTracing.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>