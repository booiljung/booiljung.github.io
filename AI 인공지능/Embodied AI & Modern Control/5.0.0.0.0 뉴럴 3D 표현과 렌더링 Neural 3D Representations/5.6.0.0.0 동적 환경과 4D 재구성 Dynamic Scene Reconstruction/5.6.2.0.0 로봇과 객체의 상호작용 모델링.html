<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.6.2 로봇과 객체의 상호작용 모델링</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.6.2 로봇과 객체의 상호작용 모델링</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 5. 뉴럴 3D 표현과 렌더링 (Neural 3D Representations)</a> / <a href="index.html">5.6 동적 환경과 4D 재구성 (Dynamic Scene Reconstruction)</a> / <span>5.6.2 로봇과 객체의 상호작용 모델링</span></nav>
                </div>
            </header>
            <article>
                <h1>5.6.2 로봇과 객체의 상호작용 모델링</h1>
<p>로봇 공학의 진보는 로봇이 환경을 단순히 관측하는 것을 넘어, 물리적 실체로서 환경과 상호작용하고 그 결과를 예측하며, 나아가 의도된 변화를 만들어내는 능력에 달려 있다. 본 절에서는 로봇과 객체 간의 상호작용을 모델링하는 최신 방법론을 심도 있게 다룬다. 특히, 최근 컴퓨터 비전과 그래픽스 분야에서 혁신을 일으키고 있는 뉴럴 렌더링(Neural Rendering) 기술—NeRF(Neural Radiance Fields)와 3D Gaussian Splatting(3DGS)—이 물리 시뮬레이션(Physics Simulation)과 결합하여 어떻게 “시각-물리 통합(Visuo-Physical Unity)“을 달성하고 있는지 분석한다. 전통적인 메쉬(Mesh) 기반 접근법의 한계를 극복하고, 미분 가능한 물리 엔진(Differentiable Physics Engine)을 통해 시스템 식별(System Identification)과 제어(Control) 문제를 해결하는 과정을 수학적 정식화와 함께 포괄적으로 기술한다.</p>
<h2>1.  서론: 시각적 관측과 물리적 실재의 간극 해소</h2>
<p>로봇이 미지의 객체와 상호작용하기 위해서는 객체의 기하학적 형상뿐만 아니라 질량, 마찰계수, 탄성률과 같은 물리적 속성을 파악해야 한다. 과거의 로봇 시스템은 시각적 인식(Perception)과 물리적 제어(Control)가 분리된 파이프라인으로 운영되었다. 즉, 카메라로 얻은 포인트 클라우드나 메쉬를 통해 형상을 복원한 후, 이를 별도의 강체 또는 연체 시뮬레이터에 입력하여 물리적 거동을 계산하는 방식이었다. 그러나 이러한 접근법은 시각적 복원 과정에서의 오차, 복잡한 위상(Topology) 변화 처리의 어려움, 그리고 무엇보다 시뮬레이션 결과와 실제 관측 간의 불일치 문제를 야기한다.</p>
<p>최근 등장한 물리 통합 뉴럴 필드(Physics-Integrated Neural Fields)는 이러한 문제를 근본적으로 해결하고자 한다. 이 접근법의 핵심 철학은 “보이는 대로 시뮬레이션한다(What You See Is What You Simulate)“는 것으로, 렌더링을 위한 표현(Representation)과 물리 시뮬레이션을 위한 표현을 일치시키는 것이다. 이는 미분 가능한 렌더링(Differentiable Rendering)과 미분 가능한 물리(Differentiable Physics)의 결합을 통해 가능해졌으며, 로봇은 이를 통해 비디오 관측만으로 객체의 물리적 특성을 역전파(Backpropagation)로 학습하고, 미래의 상호작용 결과를 예측할 수 있게 되었다.</p>
<h2>2.  연속체 역학 기반의 뉴럴 표현: PhysGaussian과 PAC-NeRF</h2>
<p>상호작용 모델링의 첫 단계는 대상을 적절히 표현하는 것이다. 강체뿐만 아니라 젤리나 옷감 같은 연체(Deformable Body), 물이나 연기 같은 유체(Fluid), 모래와 같은 입자성 물질(Granular Material)을 모두 아우를 수 있는 통합된 표현이 요구된다. 이를 위해 연속체 역학(Continuum Mechanics)을 뉴럴 필드에 도입한 연구들이 주목받고 있다.</p>
<h3>2.1  PhysGaussian: 3D 가우시안 커널을 이용한 라그랑주 역학</h3>
<p>3D Gaussian Splatting(3DGS)은 수만 개의 3D 가우시안 타원체(Ellipsoid)로 장면을 표현하여 실시간 렌더링을 가능하게 하는 기술이다. PhysGaussian은 이러한 가우시안 커널 하나하나를 물리적 질량을 가진 물질점(Material Point)으로 취급함으로써, 렌더링 프리미티브에 뉴턴 역학을 직접 주입한다.</p>
<h4>2.1.1  운동학적 진화와 변형 구배</h4>
<p>물체의 변형은 초기 상태 <span class="math math-inline">\mathbf{X}</span>에서 현재 상태 <span class="math math-inline">\mathbf{x}</span>로의 매핑 <span class="math math-inline">\mathbf{x} = \phi(\mathbf{X}, t)</span>로 정의된다. 이때 국소적인 변형을 나타내는 변형 구배 텐서(Deformation Gradient Tensor) <span class="math math-inline">\mathbf{F}</span>는 다음과 같이 정의된다.<br />
<span class="math math-display">
\mathbf{F}(\mathbf{X}, t) = \frac{\partial \mathbf{x}}{\partial \mathbf{X}}
</span><br />
PhysGaussian의 핵심 기여는 물리 시뮬레이션에서 계산된 변형 구배 <span class="math math-inline">\mathbf{F}</span>가 3D 가우시안의 기하학적 속성인 공분산 행렬(Covariance Matrix) <span class="math math-inline">\Sigma</span>를 어떻게 변화시키는지를 수학적으로 유도한 데 있다. 초기 공분산이 <span class="math math-inline">\Sigma_0</span>일 때, 변형된 가우시안의 공분산 <span class="math math-inline">\Sigma(t)</span>는 다음과 같이 닫힌 형태(Closed-form)로 업데이트된다.<br />
<span class="math math-display">
\Sigma(t) = \mathbf{F}(t) \Sigma_0 \mathbf{F}(t)^T
</span></p>
<p><span class="math math-display">
\mu(t) = \phi(\mathbf{X}, t)
</span></p>
<p>이 수식은 물리 엔진이 계산한 물체의 늘어남(Stretch)과 회전(Rotation)이 시각적 렌더링 요소인 가우시안 타원체에 즉각적으로 반영됨을 의미한다. 이를 통해 로봇이 물체를 눌렀을 때(Compression)나 비틀었을 때(Torsion), 물체의 텍스처와 형상이 물리 법칙에 따라 자연스럽게 일그러지는 현상을 별도의 리깅(Rigging) 없이 구현할 수 있다.</p>
<h4>2.1.2  MPM 기반 시뮬레이션과 이방성 정규화</h4>
<p>PhysGaussian은 입자(Lagrangian)와 그리드(Eulerian) 방식을 혼용한 물질점 방법(Material Point Method, MPM)을 채택하여 다양한 물성(탄성, 소성, 유체 등)을 시뮬레이션한다. MPM은 큰 변형이나 위상 변화(찢어짐, 합쳐짐)를 처리하는 데 탁월하지만, 가우시안 커널이 과도하게 길어지거나 납작해지는 경우 렌더링 품질이 저하될 수 있다. 이를 방지하기 위해 PhysGaussian은 가우시안의 스케일 <span class="math math-inline">S</span>에 대한 이방성 정규화(Anisotropy Regularizer) 손실을 도입한다.<br />
<span class="math math-display">
\mathcal{L}_{aniso} = \sum_{p \in P} \max \left( \frac{\max(S_p)}{\min(S_p)}, r \right) - r
</span><br />
여기서 <span class="math math-inline">r</span>은 허용 가능한 최대 비율이다. 이 손실 함수는 가우시안이 물리적으로 비현실적인 ‘바늘’ 모양으로 변형되는 것을 억제하여 시뮬레이션의 안정성과 렌더링 품질을 동시에 확보한다.</p>
<h3>2.2  PAC-NeRF: 오일러-라그랑주 하이브리드 접근법</h3>
<p>PhysGaussian이 입자 중심의 접근이라면, PAC-NeRF(Physics Augmented Continuum NeRF)는 NeRF의 오일러 그리드 표현과 MPM의 라그랑주 입자 표현을 결합한 하이브리드 프레임워크이다. 이는 특히 유체나 연기와 같이 형상이 정해지지 않은 객체의 상호작용 모델링에 강점을 가진다.</p>
<h4>2.2.1  보존 법칙의 내재화</h4>
<p>PAC-NeRF는 뉴럴 필드가 단순히 시각적 형상만을 학습하는 것이 아니라, 물리적 보존 법칙(Conservation Laws)을 만족하도록 강제한다. 질량 보존(Conservation of Mass)과 운동량 보존(Conservation of Momentum) 법칙은 손실 함수(Loss Function)의 형태로 네트워크 학습에 통합된다.<br />
<span class="math math-display">
\frac{D\sigma}{Dt} = 0 \quad (\text{질량 보존})
</span></p>
<p><span class="math math-display">
\rho \frac{D\mathbf{v}}{Dt} = \nabla \cdot \mathbf{T} + \rho \mathbf{g} \quad (\text{운동량 보존})
</span></p>
<p>여기서 <span class="math math-inline">\sigma</span>는 밀도, <span class="math math-inline">\mathbf{v}</span>는 속도장, <span class="math math-inline">\mathbf{T}</span>는 코시 응력 텐서(Cauchy Stress Tensor), <span class="math math-inline">\mathbf{g}</span>는 중력 가속도이다. 이러한 물리적 제약 조건은 비디오 관측 데이터가 희소하거나(Sparse Views) 노이즈가 심할 때, 모델이 물리적으로 타당하지 않은 해(예: 물체가 갑자기 사라지거나 생성되는 현상)로 수렴하는 것을 방지한다.</p>
<h4>2.2.2  기하학적 보정과 시스템 식별</h4>
<p>PAC-NeRF는 초기 형상 추정이 불완전하더라도 물리 시뮬레이션을 통해 이를 보정(Geometric Correction)하는 능력을 갖추고 있다. 예를 들어, 물체가 떨어지는 영상을 관측할 때, 중력 가속도와 물체의 변형 양상을 분석하여 초기 프레임에서 가려져 보이지 않았던 부분의 질량 분포까지 추론할 수 있다. 또한, 미분 가능한 MPM(DiffMPM)을 활용하여 관측된 비디오와 시뮬레이션 결과 간의 차이를 역전파함으로써, 대상 객체의 전단 계수(Shear Modulus), 점성(Viscosity) 등 물리 파라미터를 식별한다.</p>
<h2>3.  미분 가능한 접촉 역학 (Differentiable Contact Dynamics)</h2>
<p>로봇이 객체를 조작(Manipulation)하는 과정에서 가장 핵심적이고도 어려운 문제는 ’접촉(Contact)’이다. 접촉은 힘을 전달하는 주된 통로이지만, 수학적으로는 상호 관통 불가(Non-penetration) 조건과 같은 부등식 제약 조건으로 표현되며, 접촉이 발생하는 순간 힘이 불연속적으로 변화하기 때문에 미분 불가능한 특성을 가진다. 이는 그래디언트 기반 최적화(Gradient-based Optimization)를 방해하는 주요 요인이다. 최근 연구들은 이러한 접촉 현상을 미분 가능한 형태로 근사하거나 재정의하는 다양한 기법을 제안하고 있다.</p>
<h3>3.1  페널티 기반 및 장벽 함수 (Penalty &amp; Barrier Methods)</h3>
<p>가장 직관적인 방법은 접촉 제약 조건을 위반했을 때(즉, 물체가 겹쳤을 때) 큰 비용을 부과하는 페널티 방법이다. DiffSDFSim은 물체의 형상을 서명된 거리 함수(Signed Distance Function, SDF)로 표현하고, 침투 깊이(Penetration Depth)에 비례하는 반발력을 생성한다.<br />
<span class="math math-display">
\mathbf{f}_{contact} = -k_p \cdot \min(0, \Phi(\mathbf{x})) \cdot \nabla \Phi(\mathbf{x})
</span><br />
여기서 <span class="math math-inline">\Phi(\mathbf{x})</span>는 SDF 값이며, <span class="math math-inline">\nabla \Phi(\mathbf{x})</span>는 접촉 법선 벡터 역할을 한다. 이 방식은 침투 깊이에 대해 연속적으로 미분 가능하므로, 로봇 제어기는 충돌을 최소화하거나 의도적으로 접촉을 유지하는 궤적을 생성할 수 있다.</p>
<p>더 나아가, 로그 장벽 함수(Log-Barrier Function)를 사용하여 물체가 접촉면에 가까워질수록 비용이 무한대로 발산하게 함으로써, 엄격한 비관통 조건을 만족시키는 최적화 기법도 사용된다.<br />
<span class="math math-display">
B(\mathbf{x}) = -\frac{1}{t} \sum \log(-g_i(\mathbf{x}))
</span><br />
이러한 장벽 함수는 내부 점 방법(Interior Point Method)과 결합되어, 로봇의 경로 계획 시 안전 거리를 확보하는 데 유용하다.</p>
<h3>3.2  신경망 기반 충돌 필드 (Neural Collision Fields)</h3>
<p>최근에는 접촉 에너지를 공간에 대한 적분 형태로 정의하여 미분 가능성을 극대화하는 Neural Collision Fields가 제안되었다. 두 물체 <span class="math math-inline">A, B</span> 사이의 충돌 포텐셜 <span class="math math-inline">E_{col}</span>은 각 물체 표면의 점들 간 상호작용의 합으로 표현된다.<br />
<span class="math math-display">
E_{col} = \iint_{A, B} \exp(-k \|\mathbf{x}_A - \mathbf{x}_B\|^2) d\mathbf{x}_A d\mathbf{x}_B
</span><br />
이 수식은 가우시안 커널을 사용하여 근거리 상호작용을 부드럽게 모델링한다. 물체가 실제로 닿지 않았더라도 거리가 가까워지면 에너지가 증가하므로, 충돌 발생 전부터 회피를 위한 그래디언트 정보를 제공할 수 있다는 장점이 있다. 이는 좁은 공간에서 로봇 팔을 제어하거나 복잡한 형상의 물체를 조립하는 작업에서 국소 최저점(Local Minima)에 빠지지 않고 해를 찾을 수 있게 돕는다.</p>
<h3>3.3  미분 가능한 접촉 렌치 최적화 (Diff-LfD)</h3>
<p>로봇이 도구를 사용하거나 물체의 자세를 변경(Reorientation)할 때, 접촉점에서 가해야 하는 힘과 모멘트, 즉 렌치(Wrench)를 결정하는 것은 역동역학(Inverse Dynamics) 문제이다. Diff-LfD는 인간의 시연 비디오로부터 이러한 접촉 렌치를 학습하는 프레임워크를 제시한다.</p>
<p>목표 물체의 포즈 <span class="math math-inline">\mathbf{P}_{target}</span>에 도달하기 위해 필요한 최적의 렌치 <span class="math math-inline">\mathbf{W}^*</span>는 다음 손실 함수를 최소화하여 구한다.<br />
<span class="math math-display">
\mathbf{W}^* = \arg\min_{\mathbf{W}} \left( \lambda_{pose} \|\mathcal{F}(\mathbf{P}_0, \mathbf{W}) \ominus \mathbf{P}_{target}\|^2 + \lambda_{reg} \|\mathbf{W}\|^2 \right)
</span><br />
여기서 <span class="math math-inline">\mathcal{F}</span>는 미분 가능한 물리 시뮬레이터이며, <span class="math math-inline">\ominus</span>는 SE(3) 다양체(Manifold) 상에서의 거리 차이를 의미한다. 접촉의 불확실성을 다루기 위해, 렌치 공간에서 가우시안 노이즈를 샘플링하고 이에 대한 기댓값의 그래디언트를 계산하는 확률적 최적화(Stochastic Optimization) 기법이 사용되기도 한다.<br />
<span class="math math-display">
\nabla_{\mathbf{W}} \mathbb{E} [L] \approx \frac{1}{N} \sum_{i=1}^N \nabla L(\mathcal{F}(\mathbf{P}_0, \mathbf{W} + \epsilon_i))
</span><br />
이러한 접근법은 마찰 원뿔(Friction Cone) 제약 조건 내에서 미끄러짐 없이 물체를 조작할 수 있는 힘을 찾아내며, 이는 로봇의 임피던스 제어(Impedance Control)나 토크 제어(Torque Control)에 직접적인 입력으로 사용된다.</p>
<h3>3.4  마찰 모델의 미분 가능화 (SoftMAC)</h3>
<p>마찰은 스틱(Stick)과 슬립(Slip) 상태 간의 전환이 불연속적이기 때문에 미분이 어렵다. SoftMAC과 같은 연구는 이를 해결하기 위해 예측 기반(Forecast-based) 접촉 모델을 사용하거나, 마찰력을 부드러운 활성화 함수(Softplus, Tanh)로 근사한다.<br />
<span class="math math-display">
\mathbf{f}_{friction} = -\mu \|\mathbf{f}_{normal}\| \cdot \tanh(\frac{\mathbf{v}_{rel}}{\epsilon})
</span><br />
여기서 <span class="math math-inline">\mathbf{v}_{rel}</span>은 상대 속도이며, <span class="math math-inline">\epsilon</span>은 평활화 파라미터이다. 이 근사 모델은 속도가 0 근처일 때의 급격한 변화를 부드럽게 만들어 역전파가 가능하게 하며, 로봇이 물체를 파지할 때 필요한 최소한의 마찰력을 학습하는 데 기여한다.</p>
<h2>4.  시스템 식별 및 물리 속성 추정 (System Identification)</h2>
<p>로봇이 실제 환경에서 효과적으로 작동하려면 상호작용하는 객체의 물리적 파라미터를 정확히 알아야 한다. 이를 ’시스템 식별’이라 하며, 미분 가능한 물리 엔진과 뉴럴 렌더링의 결합은 시각적 정보만으로 이를 수행할 수 있는 강력한 도구를 제공한다.</p>
<h3>4.1  비디오 기반 파라미터 역추정 (Inverse Parameter Estimation)</h3>
<p>Physics3D와 gradSim은 관측된 비디오와 시뮬레이션 결과의 픽셀 단위 차이(Photometric Loss)를 최소화하는 방식으로 물리 파라미터 <span class="math math-inline">\theta</span> (질량, 마찰계수, 탄성률 등)를 추정한다.<br />
<span class="math math-display">
\theta^* = \arg\min_{\theta} \sum_{t=1}^T \| \mathcal{R}(\mathcal{S}(\mathbf{s}_0, \theta, t)) - \mathbf{I}_{obs}^{(t)} \|_2^2
</span><br />
여기서 <span class="math math-inline">\mathcal{R}</span>은 렌더링 함수, <span class="math math-inline">\mathcal{S}</span>는 물리 시뮬레이션 함수이다. 이 과정은 “Analysis-by-Synthesis” 접근법의 일종으로, 시뮬레이터가 생성한 영상이 실제 영상과 같아질 때까지 물리 파라미터를 반복적으로 수정한다. 특히 탄성체 시뮬레이션에서는 영율(Young’s Modulus, <span class="math math-inline">E</span>)과 푸아송 비(Poisson’s Ratio, <span class="math math-inline">\nu</span>)가 물체의 변형 거동을 결정하는 핵심 변수이며, 이를 정확히 추정하면 로봇이 물체의 강성(Stiffness)에 맞춰 파지력을 조절할 수 있다.</p>
<h3>4.2  대규모 언어 모델(MLLM)을 활용한 제로샷 추정 (PhysSplat)</h3>
<p>최근 PhysSplat 연구는 순수하게 시각적 최적화에만 의존하는 방식의 한계(느린 수렴 속도, 국소 최적해)를 극복하기 위해 멀티모달 대규모 언어 모델(MLLM)을 도입했다. GPT-4V와 같은 모델은 이미지 속 객체의 의미론적(Semantic) 정보를 파악하여, 해당 물체의 일반적인 물리적 속성(예: “금속 캔은 단단하고 가볍다”, “스펀지는 부드럽고 탄성이 있다”)을 사전 지식(Prior)으로 제공한다.<br />
<span class="math math-display">
\hat{\theta}_{init} = \text{MLLM}(\mathbf{I}_{obs}, \text{&quot;Estimate material properties&quot;})
</span><br />
이렇게 초기화된 파라미터는 미분 가능한 시뮬레이션 루프의 시작점으로 사용되어 수렴 속도를 비약적으로 높이며, 데이터가 부족한 상황에서도 강건한 추정을 가능하게 한다. PhysSplat은 이 파라미터를 가우시안 입자에 할당하고 MPM 시뮬레이션을 수행하여, 사실적인 동적 상호작용을 실시간에 가깝게 생성한다.</p>
<h2>5.  모델 예측 제어(MPC)와 뉴럴 표현의 통합</h2>
<p>시스템 식별을 통해 학습된 물리 모델은 로봇의 제어 전략, 특히 모델 예측 제어(Model Predictive Control, MPC)에 직접적으로 활용된다. MPC는 현재 상태에서 가능한 미래의 행동 시퀀스를 시뮬레이션하고, 비용 함수를 최소화하는 최적의 행동을 선택하는 기법이다.</p>
<h3>5.1  3DGS 기반 시각적 MPC (Visual MPC with 3DGS)</h3>
<p>기존의 MPC는 주로 로봇의 관절 각도나 물체의 6D 포즈와 같은 저차원 상태 공간에서 작동했다. 그러나 모래, 액체, 옷감과 같은 비정형 객체(Deformable/Granular Objects)는 명확한 상태 정의가 어렵다. 이에 대한 해결책으로 3DGS의 가우시안 파라미터 집합 자체를 상태 공간(State Space)으로 활용하는 연구가 등장했다.<br />
<span class="math math-display">
\mathbf{z}_t = \{(\mu_i, \Sigma_i, \mathbf{c}_i, \alpha_i)\}_{i=1}^N
</span><br />
로봇의 제어 입력 <span class="math math-inline">\mathbf{u}_t</span>에 따른 미래 상태 <span class="math math-inline">\mathbf{z}*{t+1}</span>은 학습된 동역학 모델(GNN 또는 Transformer 기반)이나 미분 가능한 물리 엔진을 통해 예측된다. 비용 함수는 목표 이미지 <span class="math math-inline">\mathbf{I}*{target}</span>과 예측된 상태의 렌더링 이미지 간의 차이로 정의된다.<br />
<span class="math math-display">
J(\mathbf{u}_{t:t+H}) = \sum_{k=1}^H \| \mathcal{R}(\mathbf{z}_{t+k}) - \mathbf{I}_{target} \|^2
</span><br />
이러한 접근법은 입자성 물질을 흩뜨리거나 모으는 작업(Granular Manipulation)에서 탁월한 성능을 보였다. 3DGS는 수천 개의 입자를 개별적으로 추적하고 렌더링할 수 있어, 기존의 2D 이미지 기반 MPC보다 훨씬 정교한 3D 공간 제어가 가능하다.</p>
<h3>5.2  그래디언트 기반 궤적 최적화 (Gradient-based Trajectory Optimization)</h3>
<p>미분 가능한 시뮬레이터와 렌더러를 사용하면, 제어 입력 <span class="math math-inline">\mathbf{u}</span>에 대한 비용 함수 <span class="math math-inline">J</span>의 그래디언트 <span class="math math-inline">\nabla_{\mathbf{u}} J</span>를 해석적으로(Analytically) 계산할 수 있다. 이는 샘플링 기반(Sampling-based) 최적화 방법(예: CEM, MPPI)보다 훨씬 적은 횟수의 반복으로 최적해에 수렴하게 한다.<br />
<span class="math math-display">
\mathbf{u} \leftarrow \mathbf{u} - \eta \nabla_{\mathbf{u}} J(\mathbf{u})
</span><br />
특히 복잡한 다자유도 로봇 팔의 궤적 생성이나 동적인 장애물 회피 문제에서, 미분 가능한 물리 모델은 로봇이 물리적 제약 조건(충돌, 관절 한계, 마찰)을 만족하면서도 목표를 달성하는 경로를 효율적으로 찾을 수 있게 해준다.</p>
<h2>6.  최신 연구 동향 및 향후 과제</h2>
<p>로봇-객체 상호작용 모델링 기술은 3DGS와 미분 가능한 물리의 결합을 통해 빠르게 발전하고 있다. GASP(Gaussian Splatting for Physics-based Simulations)는 3DGS의 가우시안을 삼각형 메쉬의 요소로 변환하지 않고 직접 시뮬레이션하는 ‘Flat Gaussian’ 방식을 제안하여 계산 효율성을 높였다. 또한 PIDG(Physics-Informed Deformable Gaussian)는 변형 필드(Deformation Field)를 학습하여 물리적 일관성을 유지하면서도 동적인 장면을 고품질로 복원하는 기술을 선보였다.</p>
<p>하지만 여전히 해결해야 할 과제들이 남아 있다.</p>
<ol>
<li><strong>실시간성(Real-time Performance):</strong> 수십만 개의 가우시안 입자와 복잡한 MPM 시뮬레이션을 동시에 처리하는 것은 높은 연산 능력을 요구한다. CUDA 최적화 및 계층적(Hierarchical) 표현을 통한 가속화가 필수적이다.</li>
<li><strong>다중 물리(Multi-physics) 결합:</strong> 강체, 연체, 유체가 혼재된 복합 환경에서의 상호작용(예: 로봇이 컵에 담긴 물을 쏟지 않고 옮기는 작업)을 안정적으로 미분 가능하게 시뮬레이션하는 것은 여전히 도전적이다.</li>
<li><strong>Sim-to-Real 간극:</strong> 시뮬레이션에서 학습된 물리 모델이 실제 세계의 복잡한 마찰이나 공기 저항 등을 완벽히 반영하지 못할 때 발생하는 성능 저하를 줄이기 위한 도메인 랜덤화(Domain Randomization) 및 온라인 적응(Online Adaptation) 연구가 지속되어야 한다.</li>
</ol>
<p>결론적으로, 로봇과 객체의 상호작용 모델링은 시각적 사실성과 물리적 정확성을 동시에 추구하는 방향으로 나아가고 있으며, 이는 로봇이 인간 수준의 조작 능력을 갖추는 데 핵심적인 역할을 할 것이다.</p>
<h3>6.1 표 5.6.2.1 주요 물리-시각 통합 상호작용 모델링 프레임워크 비교</h3>
<table><thead><tr><th><strong>모델명</strong></th><th><strong>표현 방식 (Rendering / Physics)</strong></th><th><strong>물리 엔진 및 특징</strong></th><th><strong>주요 응용 분야</strong></th><th><strong>참고문헌</strong></th></tr></thead><tbody>
<tr><td><strong>PhysGaussian</strong></td><td>3D Gaussian / Lagrangian Particles</td><td><strong>MLS-MPM</strong>. 가우시안 커널에 물리 속성(질량, 탄성) 직접 주입. 변형 구배에 따른 공분산 업데이트.</td><td>탄성체, 금속, 점소성 유체 생성 및 시뮬레이션</td><td></td></tr>
<tr><td><strong>PAC-NeRF</strong></td><td>NeRF (Grid) / MPM Particles</td><td><strong>DiffMPM</strong>. 오일러-라그랑주 하이브리드. 질량/운동량 보존 법칙을 손실 함수로 사용.</td><td>유체, 연체, 입자성 물질의 시스템 식별</td><td></td></tr>
<tr><td><strong>PhysSplat</strong></td><td>3D Gaussian / MPM Particles</td><td><strong>MPM</strong>. MLLM(GPT-4V)을 활용한 제로샷 물성 추정. 3DGS의 효율적 물리 시뮬레이션.</td><td>실시간 상호작용, 오픈 월드 시뮬레이션</td><td></td></tr>
<tr><td><strong>Diff-LfD</strong></td><td>SDF &amp; Mesh / Differentiable Physics</td><td><strong>Diff-Rigidbody</strong>. 비디오 시연으로부터 접촉 렌치(Wrench) 및 궤적 최적화.</td><td>로봇 매니퓰레이션, 도구 사용 학습</td><td></td></tr>
<tr><td><strong>GASP</strong></td><td>Flat Gaussian / Mesh Vertices</td><td><strong>MPM</strong>. 가우시안을 메쉬 요소로 변환하지 않고 직접 입자로 사용.</td><td>동적 씬 렌더링, 객체 간 상호작용</td><td></td></tr>
<tr><td><strong>Neural Collision Fields</strong></td><td>Implicit Surface / Integral Potential</td><td><strong>Neural Field</strong>. 충돌 에너지를 적분 형태로 정의하여 미분 가능성 확보.</td><td>충돌 회피, 경로 계획</td><td></td></tr>
<tr><td><strong>SoftMAC</strong></td><td>Mesh &amp; Particles / Soft Contact</td><td><strong>Forecast-based Contact</strong>. 유체-고체, 천-고체 간의 양방향 결합 및 마찰 모델링.</td><td>다중 물리 상호작용, 유연 물체 조작</td><td></td></tr>
</tbody></table>
<h2>7. 참고 자료</h2>
<ol>
<li>Physics-Integrated 3D Gaussians for Generative Dynamics - Tianyi Xie, https://xpandora.github.io/PhysGaussian/</li>
<li>pac-nerf: physics augmented continuum neural radiance fields, https://xuan-li.github.io/pdf/publications/li2023pacnerf.pdf</li>
<li>Physics-Integrated 3D Gaussians for Generative Dynamics, https://openaccess.thecvf.com/content/CVPR2024/papers/Xie_PhysGaussian_Physics-Integrated_3D_Gaussians_for_Generative_Dynamics_CVPR_2024_paper.pdf</li>
<li>Physics-Integrated 3D Gaussians for Generative Dynamics, https://ieeexplore.ieee.org/iel8/10654794/10654797/10658121.pdf</li>
<li>Improving Physics-Augmented Continuum Neural Radiance Field …, https://openaccess.thecvf.com/content/CVPR2024/papers/Kaneko_Improving_Physics-Augmented_Continuum_Neural_Radiance_Field-Based_Geometry-Agnostic_System_Identification_with_CVPR_2024_paper.pdf</li>
<li>DiffSDFSim: Differentiable Rigid-Body Dynamics With Implicit Shapes, https://arxiv.org/abs/2111.15318</li>
<li>DiffSDFSim: Differentiable Rigid-Body Dynamics With Implicit Shapes, https://www.researchgate.net/publication/357640233_DiffSDFSim_Differentiable_Rigid-Body_Dynamics_With_Implicit_Shapes</li>
<li>Global Optimization 7. Penalty and Barrier Methods, http://math.bme.hu/~takacsp/GlobalOptimization2021/GO_07.pdf</li>
<li>Lecture 17: October 22 17.1 Barrier Method Formulation, https://www.stat.cmu.edu/~ryantibs/convexopt-F13/scribes/lec17.pdf</li>
<li>Neural Collision Fields for Triangle Primitives - Research at NVIDIA, https://research.nvidia.com/labs/prl/zesch2023ncf/neuralcollision2023.pdf</li>
<li>Diff-LfD: Contact-aware Model-based Learning from Visual …, https://proceedings.mlr.press/v229/zhu23a/zhu23a.pdf</li>
<li>SoftMAC: Differentiable Soft Body Simulation with Forecast-based …, https://arxiv.org/html/2312.03297v4</li>
<li>Inverse Dynamics with Rigid Contact and Friction - Positronics Lab, https://positronicslab.github.io/assets/pdfs/inverse-dynamics.pdf</li>
<li>A Geometric Sufficient Condition for Contact Wrench Feasibility, https://www.researchgate.net/publication/365101693_A_Geometric_Sufficient_Condition_for_Contact_Wrench_Feasibility</li>
<li>Physics3D: Learning Physical Properties of 3D Gaussians via Video …, https://liuff19.github.io/Physics3D/static/pdf/Physics3D.pdf</li>
<li>gradSim: Differentiable simulation for system identification and …, https://gradsim.github.io/</li>
<li>Response estimation and system identification of dynamical systems …, https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/733233/s40323-025-00291-9.pdf?sequence=3</li>
<li>PhysSplat : Efficient Physics Simulation for 3D Scenes via MLLM …, https://openaccess.thecvf.com/content/ICCV2025/papers/Zhao_PhysSplat_Efficient_Physics_Simulation_for_3D_Scenes_via_MLLM-Guided_Gaussian_ICCV_2025_paper.pdf</li>
<li>Gaussian Splatting Visual MPC for Granular Media Manipulation, https://ieeexplore.ieee.org/iel8/11127273/11127223/11128002.pdf</li>
<li>Gaussian Splatting Visual MPC for Granular Media Manipulation, https://weichengtseng.github.io/gs-granular-mani/</li>
<li>Gradient-Based Trajectory Optimization With Learned Dynamics, https://crl.ethz.ch/papers/Gradient_Based_Trajectory_Optimization_With_Learned_Dynamics_final.pdf</li>
<li>Gradient-Based Framework for Bilevel Optimization of Black-Box …, https://pubs.acs.org/doi/10.1021/acs.iecr.4c03584</li>
<li>An Integrated Framework for Fast Joint-Space Model-Predictive …, https://proceedings.mlr.press/v164/bhardwaj22a/bhardwaj22a.pdf</li>
<li>GASP: Gaussian Splatting for Physic-Based Simulations - arXiv, https://arxiv.org/html/2409.05819v3</li>
<li>GASP: Gaussian Splatting for Physic-Based Simulations, https://www.researchgate.net/publication/383912256_GASP_Gaussian_Splatting_for_Physic-Based_Simulations</li>
<li>(PDF) Physics-Informed Deformable Gaussian Splatting, https://www.researchgate.net/publication/397480509_Physics-Informed_Deformable_Gaussian_Splatting_Towards_Unified_Constitutive_Laws_for_Time-Evolving_Material_Field</li>
<li>Physics-Informed Deformable Gaussian Splatting - Emergent Mind, https://www.emergentmind.com/topics/physics-informed-deformable-gaussian-splatting-pidg</li>
<li>PIN-WM: Learning Physics-INformed World Models for Non … - arXiv, https://arxiv.org/html/2504.16693v1</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>