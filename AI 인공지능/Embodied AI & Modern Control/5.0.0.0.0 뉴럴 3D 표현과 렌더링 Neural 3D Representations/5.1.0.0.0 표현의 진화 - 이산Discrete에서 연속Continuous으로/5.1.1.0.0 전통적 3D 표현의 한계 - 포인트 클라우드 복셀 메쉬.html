<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.1.1 전통적 3D 표현의 한계: 포인트 클라우드, 복셀, 메쉬</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.1.1 전통적 3D 표현의 한계: 포인트 클라우드, 복셀, 메쉬</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 5. 뉴럴 3D 표현과 렌더링 (Neural 3D Representations)</a> / <a href="index.html">5.1 표현의 진화: 이산(Discrete)에서 연속(Continuous)으로</a> / <span>5.1.1 전통적 3D 표현의 한계: 포인트 클라우드, 복셀, 메쉬</span></nav>
                </div>
            </header>
            <article>
                <h1>5.1.1 전통적 3D 표현의 한계: 포인트 클라우드, 복셀, 메쉬</h1>
<h2>1.  서론: 3차원 공간 지각과 데이터 표현의 본질적 딜레마</h2>
<p>인간의 시각 정보 처리 과정과 인공지능(AI)의 공간 지각 능력 사이에는 근본적인 차이가 존재한다. 인간은 2차원 망막 이미지를 통해 3차원 공간의 깊이, 구조, 물성을 직관적으로 추론하는 반면, 컴퓨터 비전 시스템은 입력 데이터를 처리 가능한 수학적 형태로 변환하는 과정을 거쳐야 한다. 지난 10년간 딥러닝(Deep Learning) 기술, 특히 합성곱 신경망(Convolutional Neural Networks, CNN)의 비약적인 발전은 2차원 이미지 처리 분야에서 인간 수준, 혹은 그 이상의 성능을 달성하게 했다. 이러한 성공의 이면에는 ’픽셀(Pixel)’이라는, 2차원 공간을 정규 격자(Regular Grid) 형태로 완벽하게 분할하고 구조화하는 ’표준 표현(Canonical Representation)’의 존재가 있었다. 픽셀은 데이터의 저장, 전송, 연산의 효율성을 극대화하며, CNN의 핵심 연산인 합성곱(Convolution)과 풀링(Pooling)이 수학적으로 우아하게 정의될 수 있는 토대를 제공했다.</p>
<p>그러나 3차원 공간으로 차원이 확장되는 순간, 이러한 표준화된 표현의 이점은 사라지고 ’차원의 저주(Curse of Dimensionality)’라는 난제와 마주하게 된다. 제미나이(Gemini)와 같은 현대의 거대 멀티모달 모델(LMM)이 텍스트와 2D 이미지를 넘어 3차원 물리 세계를 이해하고 상호작용하기 위해서는 3D 데이터를 효과적으로 표현하고 처리하는 방법론이 필수적이다. 하지만 불행하게도 3D 도메인에서는 픽셀과 같은 유일하고도 완벽한 표준 표현이 존재하지 않는다. 대신 연구자들과 엔지니어들은 각기 다른 목적과 하드웨어 제약에 따라 발전해 온 이산적(Discrete) 표현 방식들에 의존해 왔다.</p>
<p>현재 3D 딥러닝과 로보틱스 생태계를 지배하고 있는 세 가지 전통적 표현 방식은 <strong>복셀(Voxel)</strong>, <strong>포인트 클라우드(Point Cloud)</strong>, 그리고 **메쉬(Mesh)**이다. 이들은 각기 다른 방식으로 연속적인(Continuous) 3D 공간을 근사(Approximate)하며, 데이터 수집 장치(센서)의 특성이나 최종 애플리케이션(렌더링, 물리 시뮬레이션 등)의 요구사항에 따라 선택적으로 사용된다. 하지만 딥러닝 모델이 더 높은 해상도의 3D 객체를 생성하거나, 복잡한 위상(Topology)을 가진 환경을 이해하려 할 때, 이들 전통적 표현 방식은 심각한 구조적 한계와 계산적 병목(Bottleneck)을 드러낸다.1</p>
<p>본 장에서는 이 세 가지 표현 방식이 딥러닝 파이프라인 내에서 야기하는 문제점들을 심층적으로 분석한다. 우리는 각 표현 방식의 데이터 구조적 특성에서 기인하는 메모리 비효율성(Memory Inefficiency), 정보 손실(Information Loss), 위상학적 경직성(Topological Rigidity), 그리고 미분 불가능성(Non-differentiability)의 문제를 구체적인 이론적 배경과 최신 연구 사례를 통해 고찰할 것이다. 이러한 분석은 왜 최근의 3D 비전 연구가 이산적 표현을 넘어 암시적 함수(Implicit Function)나 뉴럴 필드(Neural Fields)와 같은 연속적 표현(Continuous Representation)으로 패러다임을 전환하고 있는지를 이해하는 데 필수적인 기반이 된다.</p>
<h2>2.  복셀(Voxel): 해상도와 메모리의 트레이드오프와 큐빅 복잡도</h2>
<h3>2.1  복셀의 정의와 3D CNN의 확장성</h3>
<p>복셀(Voxel)은 ’Volume’과 ’Pixel’의 합성어로, 2차원 픽셀을 3차원 공간으로 가장 직관적으로 확장한 개념이다. 복셀 표현은 3차원 유클리드 공간을 균일한 크기의 입방체(Cube) 격자(Grid)로 분할하고, 각 격자에 해당 공간의 속성값을 할당하는 방식이다.2 가장 단순한 형태로는 해당 공간이 객체로 채워져 있는지를 나타내는 이진 점유(Binary Occupancy) 값(0 또는 1)을 저장하며, 더 복잡한 형태로는 색상(RGB), 밀도(Density), 혹은 표면까지의 거리(Distance Field) 등을 저장할 수 있다.</p>
<p>복셀 그리드는 데이터가 메모리 상에 규칙적으로 배열되어 있다는 강력한 장점을 가진다. 이는 2D 이미지에서 사용되는 스트라이드(Stride) 기반의 메모리 접근 패턴과 합성곱 연산을 3차원으로 그대로 확장할 수 있음을 의미한다. 초기 3D 딥러닝 연구를 이끌었던 <strong>VoxNet</strong> 3과 같은 아키텍처는 이러한 특성을 이용하여 3D 형상 분류(Classification) 및 세분화(Segmentation) 작업에서 유의미한 성과를 거두었다. VoxNet은 3D 공간을 <span class="math math-inline">32 \times 32 \times 32</span> 크기의 복셀 그리드로 양자화하고, 3D 합성곱 필터를 적용하여 공간적 특징을 추출했다. 이는 데이터의 위상적 관계(Topological Relationship)가 격자 구조 내에 내재되어 있어, 이웃한 복셀 간의 지역적 상관관계를 학습하기에 매우 적합했기 때문이다.</p>
<h3>2.2  <span class="math math-inline">O(N^3)</span>의 저주: 세제곱 복잡도와 메모리 장벽</h3>
<p>그러나 복셀 표현은 해상도가 증가함에 따라 메모리 사용량과 연산량이 3제곱(<span class="math math-inline">O(N^3)</span>)으로 증가하는 ‘큐빅 복잡도(Cubic Complexity)’ 문제를 안고 있다. 이는 3D 딥러닝 모델의 확장성을 제한하는 가장 치명적인 요인이다.4</p>
<p>예를 들어, 2D 이미지에서 <span class="math math-inline">256 \times 256</span> 해상도는 매우 낮은 해상도로 간주되지만, 이를 3차원 복셀 그리드(<span class="math math-inline">256^3</span>)로 확장하면 약 1,670만 개의 복셀이 필요하다. 만약 각 복셀이 32비트 실수형(float32) 데이터를 저장한다면, 단 하나의 3D 객체를 표현하는 데 약 67MB의 메모리가 소요된다. 딥러닝 학습 시 배치 크기(Batch Size)를 32나 64로 설정하고, 네트워크 내부의 활성화 맵(Activation Map)까지 고려하면, 최신 GPU의 VRAM 용량으로도 감당하기 어려운 수준의 메모리 폭발이 발생한다.</p>
<p>이러한 제약으로 인해 초기 복셀 기반 연구들은 대부분 <span class="math math-inline">32^3</span> 혹은 기껏해야 <span class="math math-inline">64^3</span> 해상도에 머물러야 했다.4 <span class="math math-inline">32^3</span> 해상도는 객체의 대략적인 부피감(Volumetric Shape)은 표현할 수 있지만, 복잡한 물체의 표면 디테일, 얇은 구조물, 정교한 곡률 등을 표현하기에는 턱없이 부족하다. 결과적으로 복셀 기반 모델은 고해상도 3D 복원이나 생성 작업에서 흐릿하고 뭉툭한(Bloby) 결과물을 내놓을 수밖에 없다.5</p>
<h3>2.3  공간 희소성(Sparsity)과 메모리 낭비</h3>
<p>복셀 표현의 또 다른 비효율성은 3차원 데이터의 본질적인 ’희소성(Sparsity)’에서 기인한다. 3D 공간에 존재하는 대부분의 객체는 표면(Surface)으로 정의되며, 그 내부는 균일하거나 비어 있는 경우가 많다. 즉, 3차원 공간 전체 부피 중에서 실제 유의미한 정보가 존재하는 영역은 객체의 표면 근처인 2차원 다양체(Manifold)에 불과하다.</p>
<p>그러나 밀집 복셀 그리드(Dense Voxel Grid) 방식은 객체가 존재하지 않는 ’빈 공간(Free Space)’과 센서가 닿지 않은 ’미지 공간(Unknown Space)’까지도 모두 메모리를 할당하여 표현해야 한다.3 예를 들어, 넓은 방 안에 놓인 작은 의자 하나를 표현할 때, 방 전체 공간을 복셀로 채우면 90% 이상의 복셀은 ’0(비어있음)’이라는 정보를 저장하는 데 낭비된다. 이는 희소한 환경일수록 메모리 효율이 급격히 저하됨을 의미하며, 로보틱스나 자율 주행과 같이 광활한 공간을 다루는 분야에서 복셀 그리드를 메인 데이터 구조로 사용하기 어렵게 만든다.</p>
<h3>2.4  이산화 아티팩트와 정보 손실 (Aliasing &amp; Binning)</h3>
<p>연속적인 공간을 이산적인 복셀로 변환하는 복셀화(Voxelization) 과정은 필연적으로 정보 손실을 수반한다.</p>
<ul>
<li><strong>비닝(Binning) 문제:</strong> 서로 다른 위치에 있는 두 점이라도 하나의 복셀 격자 크기보다 가깝게 위치하면 동일한 복셀로 병합되어 구분이 불가능해진다.3 이는 미세한 텍스처나 얇은 판(Thin structures) 같은 형상이 소실되는 원인이 된다.</li>
<li><strong>계단 현상(Aliasing):</strong> 복셀로 표현된 표면은 매끄러운 곡선이 아닌, 레고 블록을 쌓은 듯한 계단 형태(Manhattan World)를 띠게 된다. 이는 표면 법선 벡터(Normal Vector)의 불연속성을 초래하여, 물리 시뮬레이션에서 접촉(Contact) 판정을 불안정하게 만들거나 렌더링 시 시각적 품질을 저하시킨다.6</li>
</ul>
<h3>2.5  적응형 자료구조의 시도와 한계: Octree와 Hash</h3>
<p>메모리 낭비 문제를 해결하기 위해 <strong>옥트리(Octree)</strong> 4나 <strong>해시 그리드(Hash Grid)</strong> 와 같은 적응형 자료구조가 제안되었다. 옥트리는 빈 공간은 큰 블록으로 묶어서 표현하고, 객체의 표면과 같이 상세 정보가 필요한 영역만 재귀적으로 분할하여 깊이를 늘리는 방식이다. OctNet이나 O-CNN과 같은 연구들은 이러한 자료구조를 딥러닝에 적용하여 해상도를 <span class="math math-inline">256^3</span>에서 최대 <span class="math math-inline">512^3</span>까지 확장하는 데 성공했다.4</p>
<p>하지만 이러한 접근 방식은 다음과 같은 새로운 한계를 야기한다.</p>
<ol>
<li><strong>구현 복잡도:</strong> 옥트리와 같은 트리 구조는 메모리 접근 패턴이 불규칙하여, GPU의 병렬 처리 아키텍처(SIMD)에 최적화하기 어렵다. 이는 학습 및 추론 속도의 저하로 이어진다.</li>
<li><strong>여전한 이산화 한계:</strong> 해상도를 높였음에도 불구하고, 근본적으로 공간을 축에 정렬된(Axis-aligned) 박스로 나누는 방식은 여전히 존재한다. 따라서 회전 불변성(Rotation Invariance)이 없으며, 물체가 약간만 회전해도 복셀 표현이 크게 달라지는 문제가 발생한다.</li>
</ol>
<table><thead><tr><th><strong>특성 비교</strong></th><th><strong>밀집 복셀 (Dense Voxel)</strong></th><th><strong>옥트리/희소 복셀 (Sparse Voxel)</strong></th></tr></thead><tbody>
<tr><td><strong>메모리 복잡도</strong></td><td><span class="math math-inline">O(N^3)</span> - 매우 높음</td><td><span class="math math-inline">O(N^2)</span> - 표면에 비례하여 감소</td></tr>
<tr><td><strong>구현 난이도</strong></td><td>낮음 (단순 텐서 연산)</td><td>높음 (해시 테이블, 트리 순회 필요)</td></tr>
<tr><td><strong>GPU 효율성</strong></td><td>높음 (규칙적 메모리 접근)</td><td>낮음 (랜덤 메모리 접근, 캐시 미스)</td></tr>
<tr><td><strong>최대 해상도</strong></td><td><span class="math math-inline">\sim 64^3</span></td><td><span class="math math-inline">\sim 512^3</span></td></tr>
<tr><td><strong>한계</strong></td><td>해상도 부족, 메모리 낭비</td><td>구현 복잡성, 여전한 이산화 아티팩트</td></tr>
</tbody></table>
<h2>3.  포인트 클라우드(Point Cloud): 연결성의 부재와 구조적 모호함</h2>
<h3>3.1  포인트 클라우드의 대중성과 직관성</h3>
<p>포인트 클라우드(Point Cloud)는 3차원 공간상의 좌표 <span class="math math-inline">(x, y, z)</span>를 가진 점들의 집합(Set)으로 3D 형상을 표현한다.7 필요에 따라 각 점은 색상(RGB), 반사 강도(Intensity), 법선(Normal) 등의 추가 속성을 가질 수 있다. 포인트 클라우드는 LiDAR(Light Detection and Ranging), RGB-D 카메라(Depth Camera), 사진측량(Photogrammetry) 등 현대의 3D 데이터 획득 장비들이 생성하는 가장 원초적이고 직접적인 데이터 형태(Raw Data)이다.8</p>
<p>복셀과 달리, 포인트 클라우드는 객체가 실제로 존재하는 표면의 위치 정보만을 저장하므로 공간 효율성이 매우 뛰어나다. 빈 공간을 표현하기 위해 메모리를 낭비하지 않으며, 원하는 만큼 점의 개수를 늘려 밀도를 조절할 수 있다. <strong>PointNet</strong> 7과 같은 선구적인 연구는 포인트 클라우드를 복셀이나 메쉬로 변환하지 않고 딥러닝 네트워크에 직접 입력하는 방법을 제안했다. PointNet은 점들의 순서가 바뀌어도 결과가 변하지 않는 **치환 불변성(Permutation Invariance)**을 만족하는 대칭 함수(Symmetric Function, 예: Max Pooling)를 사용하여, 포인트 클라우드 기반 딥러닝의 가능성을 증명했다.</p>
<h3>3.2  위상(Topology) 정보의 부재와 표면 정의의 모호성</h3>
<p>그러나 포인트 클라우드는 근본적으로 “점들의 집합“일 뿐, 그 점들이 어떻게 연결되어 표면(Surface)을 구성하는지에 대한 **위상 정보(Topology)**나 <strong>연결성(Connectivity)</strong> 정보를 전혀 포함하지 않는다.4</p>
<ul>
<li><strong>내부/외부의 불명확성:</strong> 포인트 클라우드 데이터만으로는 어디가 객체의 내부(Interior)이고 어디가 외부(Exterior)인지 명확히 정의할 수 없다. 이는 닫힌 표면(Closed Surface)을 보장하지 않으므로, 3D 프린팅이나 물리 시뮬레이션을 위한 부피(Volume) 계산이 불가능하다.</li>
<li><strong>후처리의 필요성:</strong> 포인트 클라우드를 시각적으로 렌더링하거나 물리 엔진에 적용하기 위해서는 점들을 연결하여 면(Mesh)을 생성하는 표면 재구성(Surface Reconstruction) 과정(예: Poisson Reconstruction, Ball Pivoting)이 반드시 필요하다. 이 과정은 계산 비용이 높을 뿐만 아니라, 노이즈가 많은 데이터에서는 실패할 확률이 높다.4</li>
</ul>
<h3>3.3  국소 구조 파악의 연산 비용: 이웃 탐색의 병목</h3>
<p>이미지나 복셀에서는 인덱싱(Indexing) <span class="math math-inline">(i, j, k)</span>을 통해 특정 픽셀의 이웃에 즉시 접근(<span class="math math-inline">O(1)</span>)할 수 있다. 반면, 포인트 클라우드는 정렬되지 않은(Unordered) 데이터이므로, 특정 점 주변의 국소적 특징(Local Geometry)을 학습하기 위해서는 이웃 점들을 찾아내는 탐색 과정이 필요하다.</p>
<p>PointNet++이나 DGCNN(Dynamic Graph CNN)과 같은 발전된 아키텍처들은 <strong>k-최근접 이웃(k-NN)</strong> 알고리즘이나 **볼 쿼리(Ball Query)**를 사용하여 국소 영역을 그룹화한다.7 하지만 이러한 탐색 알고리즘의 시간 복잡도는 점의 개수가 <span class="math math-inline">N</span>일 때 <span class="math math-inline">O(N \log N)</span> 또는 <span class="math math-inline">O(N^2)</span>에 달한다. 점의 개수가 수십만 개 이상으로 늘어나면 이웃 탐색에 소요되는 시간이 전체 신경망 연산 시간의 상당 부분을 차지하게 되며, 이는 실시간 처리(Real-time Processing)의 큰 병목이 된다.11</p>
<h3>3.4  밀도 불균형(Density Irregularity)과 센서 노이즈</h3>
<p>현실 세계에서 수집된 포인트 클라우드는 결코 이상적이지 않다. 센서의 물리적 특성으로 인해 발생하는 <strong>밀도 불균형</strong>과 <strong>노이즈</strong>는 딥러닝 모델의 학습을 어렵게 만든다.</p>
<ul>
<li><strong>거리 의존적 밀도:</strong> LiDAR 센서는 원점을 중심으로 방사형으로 레이저를 쏘기 때문에, 센서와 가까운 물체는 점들이 매우 조밀하게 찍히지만, 거리가 멀어질수록 점 사이의 간격이 넓어져 매우 희소해진다.8 이는 합성곱 필터와 같이 고정된 수용 영역(Receptive Field)을 가진 신경망이 거리 변화에 따라 일관된 특징을 추출하는 것을 방해한다. PointNet++은 이를 해결하기 위해 다중 스케일 그룹화(Multi-scale Grouping, MSG) 등을 제안했으나, 연산량 증가를 피할 수 없었다.</li>
<li><strong>가려짐(Occlusion)과 불완전성:</strong> 카메라나 레이저가 닿지 않는 물체의 뒷면이나 가려진 영역은 데이터가 전혀 없는 ’구멍(Hole)’으로 남는다. 딥러닝 모델은 이러한 불완전한 입력으로부터 전체 형상을 추론해야 하는 어려운 과제(Completion)를 떠안게 된다.6</li>
<li><strong>이상치(Outliers):</strong> 공기 중의 먼지, 유리의 반사, 센서 에러 등으로 인해 실제 표면과 동떨어진 위치에 점이 생성되는 이상치 문제는 전체 형상의 통계적 특성(Global Max Pooling 등)을 왜곡시킬 수 있다. 이를 제거하기 위해 Radius Outlier Removal(ROR)이나 Statistical Outlier Removal(SOR) 같은 필터링 알고리즘이 사용되지만, 이 역시 추가적인 연산 비용과 파라미터 튜닝을 요구한다.12</li>
</ul>
<h3>3.5  로보틱스 관점: 터널링 효과와 충돌 감지 오류</h3>
<p>로봇의 경로 계획(Path Planning)이나 충돌 방지(Collision Avoidance)에 포인트 클라우드를 사용할 때, 점과 점 사이의 ’빈 공간’은 치명적인 위험요소가 된다. 로봇 팔이나 주행 로봇이 희소한 포인트 클라우드 사이의 빈 공간을 “이동 가능한 안전한 공간“으로 오인하여 장애물을 통과하려고 시도하는 **터널링 효과(Tunneling Effect)**가 발생할 수 있다.13 이를 방지하기 위해 점들을 팽창(Inflation)시키거나 안전 마진을 크게 두어야 하는데, 이는 로봇이 좁은 공간을 통과하지 못하게 하는 보수적인 움직임을 유발한다.</p>
<h2>4.  메쉬(Mesh): 비정형 데이터 구조와 미분 불가능성의 장벽</h2>
<h3>4.1  메쉬의 정의와 그래픽스 표준으로서의 위상</h3>
<p>다각형 메쉬(Polygon Mesh), 특히 **삼각형 메쉬(Triangle Mesh)**는 정점(Vertex, <span class="math math-inline">V</span>), 간선(Edge, <span class="math math-inline">E</span>), 면(Face, <span class="math math-inline">F</span>)의 집합으로 구성된 그래프(Graph) 구조로 3D 형상을 표현한다.14 메쉬는 컴퓨터 그래픽스(CG), CAD, 가상현실(VR), 게임 엔진 등에서 렌더링을 위한 사실상의 표준(De Facto Standard)이다. 이는 GPU 하드웨어가 삼각형 래스터화(Rasterization) 파이프라인에 최적화되어 있어, 텍스처 매핑과 조명 효과를 실시간으로 처리하기에 가장 효율적이기 때문이다.</p>
<p>최근 딥러닝 연구(예: Pixel2Mesh, AtlasNet)는 이미지로부터 직접 3D 메쉬를 생성하거나 변형(Deformation)하는 시도를 하고 있다.15 그러나 메쉬를 딥러닝의 입력이나 출력으로 사용하는 것은 복셀이나 포인트 클라우드보다 훨씬 복잡하고 까다로운 문제를 야기한다.</p>
<h3>4.2  그래프 구조의 비정형성(Irregularity)</h3>
<p>메쉬는 정점들이 불규칙하게 연결된 그래프 구조를 가진다. 2D 이미지의 픽셀은 항상 4개(상하좌우) 또는 8개의 이웃을 가지는 반면, 메쉬의 각 정점은 연결된 이웃 정점의 개수(Valence)가 제각각이다. 또한, 간선의 길이도 일정하지 않다.</p>
<p>이러한 **비정형성(Irregularity)**은 표준 CNN 연산을 적용하는 것을 불가능하게 만든다. 이를 해결하기 위해 그래프 신경망(Graph Neural Networks, GNN)이나 메쉬 전용 합성곱(MeshCNN) 등이 제안되었다. 이들은 측지 거리(Geodesic Distance)나 스펙트럼(Spectral) 분석을 이용해 합성곱을 정의하지만, 다음과 같은 한계가 있다 10:</p>
<ul>
<li><strong>풀링의 어려움:</strong> 메쉬의 해상도를 줄이는 풀링(Pooling) 연산(예: Edge Collapse)은 메쉬의 위상을 변화시키며, 어떤 간선을 먼저 제거하느냐에 따라 형상이 크게 달라질 수 있다. 이는 학습의 안정성을 저해한다.</li>
<li><strong>고정된 텐서 크기:</strong> 일반적인 딥러닝 하드웨어는 고정된 크기의 텐서 연산에 최적화되어 있다. 정점과 면의 개수가 매번 다른 메쉬 데이터를 배치(Batch)로 묶어 처리하는 것은 효율성이 떨어진다.</li>
</ul>
<h3>4.3  위상학적 경직성(Topological Rigidity)</h3>
<p>메쉬 기반 생성 모델의 가장 큰 약점은 <strong>위상(Topology)을 변경하기 어렵다</strong>는 점이다. 대부분의 메쉬 생성 네트워크(예: Pixel2Mesh)는 구(Sphere)와 같은 초기 템플릿 메쉬를 변형(Deformation)하여 목표 형상을 만든다.</p>
<ul>
<li><strong>Genus-0 제약:</strong> 구 형태의 템플릿에서 출발한 메쉬는 아무리 변형시켜도 구멍이 없는(Genus-0) 위상을 유지해야 한다. 즉, 도넛(Genus-1)이나 컵의 손잡이처럼 구멍이 뚫린 복잡한 위상을 가진 객체를 표현하는 것은 위상학적으로 불가능하다.4 억지로 변형을 가하면 메쉬가 찢어지거나 자기 교차(Self-intersection)가 발생하는 등 심각한 기하학적 오류가 발생한다.</li>
<li><strong>다중 차트 접근법의 한계:</strong> 이를 극복하기 위해 AtlasNet과 같이 여러 개의 2D 패치(Chart)를 변형하여 이어 붙이는 방식이 제안되었으나, 패치들 사이가 완벽하게 연결되지 않아 닫힌 표면(Watertight Surface)을 형성하지 못하는 경우가 많다.6</li>
</ul>
<h3>4.4  미분 불가능한 렌더링(Non-differentiable Rendering)과 역전파의 단절</h3>
<p>3D 재구성 모델을 비지도 학습(Unsupervised Learning)이나 자기 지도 학습(Self-supervised Learning)으로 훈련시키기 위해서는, 생성된 3D 메쉬를 2D 이미지로 렌더링한 후 원본 이미지와 비교하여 손실(Loss)을 계산해야 한다.</p>
<p>그러나 전통적인 렌더링 파이프라인(Rasterization)은 이산적인 픽셀 선택 과정을 포함한다. 즉, 어떤 픽셀이 삼각형 내부에 있는지 없는지를 판단하는 과정은 계단 함수(Step Function)와 같아서 미분 불가능(Non-differentiable)하다. 미분값이 0이거나 정의되지 않으면, 2D 이미지의 픽셀 오차(Pixel Error)를 3D 메쉬 정점의 좌표 <span class="math math-inline">(x, y, z)</span>로 역전파(Backpropagate)하여 모델을 업데이트할 수 없다.16</p>
<p>이를 해결하기 위해 <strong>미분 가능한 렌더링(Differentiable Rendering)</strong> 기술(예: Soft Rasterizer, DIB-R, Nvdiffrast)이 활발히 연구되고 있다.18 이들은 래스터화 과정을 확률적(Probabilistic)으로 부드럽게 근사(Smoothing)하여 그래디언트(Gradient)가 흐를 수 있게 한다. 하지만 이러한 부드러운 근사는 흐릿한 렌더링 결과를 낳거나, 텍스처와 기하학적 정보가 모호하게 섞이는 아티팩트를 유발할 수 있으며, 기존 렌더러에 비해 계산 비용이 월등히 높다는 단점이 있다.</p>
<h3>4.5  메쉬 생성의 병목: 마칭 큐브(Marching Cubes)</h3>
<p>암시적 필드(Implicit Field)나 복셀 데이터로부터 메쉬를 추출하기 위해 널리 사용되는 <strong>마칭 큐브(Marching Cubes)</strong> 알고리즘 역시 딥러닝 파이프라인의 관점에서는 미분 불가능한 후처리(Post-processing) 단계이다. 따라서 메쉬 토폴로지 자체를 최적화하는 End-to-End 학습을 구현하는 데 큰 걸림돌이 된다. 최근에는 DMTet(Deep Marching Tetrahedra)과 같이 이를 미분 가능하게 만들려는 시도가 있으나, 여전히 위상 변화가 심한 복잡한 씬(Scene)에서는 불안정한 모습을 보인다.20</p>
<hr />
<h2>5.  비교 분석 및 로보틱스 응용에서의 함의</h2>
<h3>5.1  표현 방식 간의 구조적 비교</h3>
<p>앞서 논의한 세 가지 표현 방식은 각각 메모리, 연산 효율, 표현력 사이에서 트레이드오프 관계를 가진다. 아래 표는 이를 요약한 것이다.</p>
<table><thead><tr><th><strong>특성</strong></th><th><strong>복셀 (Voxel)</strong></th><th><strong>포인트 클라우드 (Point Cloud)</strong></th><th><strong>메쉬 (Mesh)</strong></th></tr></thead><tbody>
<tr><td><strong>데이터 구조</strong></td><td>정규 격자 (Structured Grid)</td><td>비정렬 집합 (Unordered Set)</td><td>그래프 (Graph/Simplicial Complex)</td></tr>
<tr><td><strong>메모리 효율</strong></td><td>낮음 (<span class="math math-inline">O(N^3)</span>, 희소성 낭비)</td><td>높음 (표면 점만 저장)</td><td>중간 (연결 정보 오버헤드 존재)</td></tr>
<tr><td><strong>위상(Topology)</strong></td><td>암시적 표현 가능</td><td>부재 (None)</td><td>명시적 (Explicit), 변경 어려움</td></tr>
<tr><td><strong>CNN 적용</strong></td><td>용이 (3D Conv)</td><td>불가 (PointNet 등 전용 구조 필요)</td><td>불가 (GNN, MeshCNN 필요)</td></tr>
<tr><td><strong>렌더링</strong></td><td>Ray Marching (느림)</td><td>Splatting (품질 낮음)</td><td>Rasterization (빠름, 표준)</td></tr>
<tr><td><strong>주요 한계</strong></td><td>해상도 제한, 메모리 폭발</td><td>연결성 부재, 이웃 탐색 비용</td><td>위상 고정, 미분 불가능성</td></tr>
</tbody></table>
<h3>5.2  로보틱스 매니퓰레이션(Manipulation)과 시뮬레이션의 괴리</h3>
<p>로보틱스 분야에서 3D 표현의 정확성은 로봇의 성공적인 물리적 상호작용과 직결된다. 특히 로봇이 물체를 조작(Grasping &amp; Manipulation)하거나 천과 같은 변형체(Deformable Object)를 다룰 때, 이산적 표현의 한계는 **Sim-to-Real Gap(시뮬레이션과 현실의 차이)**을 심화시키는 주된 원인이 된다.21</p>
<ol>
<li><strong>물리 속성 추론의 부재:</strong> 포인트 클라우드나 껍데기뿐인 메쉬(Shell Mesh)는 물체의 내부가 채워져 있는지, 질량 분포가 어떻게 되어 있는지에 대한 정보를 제공하지 않는다. 로봇 시뮬레이터는 이러한 껍데기 정보를 기반으로 충돌체(Collider)를 근사(Convex Hull Decomposition 등)하여 생성하는데, 이 과정에서 실제 물체의 형상과 미묘하게 달라져 파지(Grasping) 실패를 유발한다.22</li>
<li><strong>접촉 역학의 불안정성:</strong> 복셀이나 낮은 해상도의 메쉬로 표현된 물체는 표면이 거칠거나 계단 모양을 띤다. 물리 엔진에서 마찰력이나 접촉력을 계산할 때, 이러한 거친 표면은 비현실적인 튀는 현상이나 미끄러짐을 발생시킨다. 특히 정밀한 조립 작업에서 수 밀리미터(mm) 단위의 오차는 치명적이다.</li>
<li><strong>실시간성의 제약:</strong> 로봇 제어 루프는 보통 수백 Hz 이상의 고속으로 동작해야 한다. 그러나 고해상도 메쉬 생성이나 포인트 클라우드의 이웃 탐색은 수십 ms 이상의 지연(Latency)을 발생시켜, 동적인 환경에서의 실시간 피드백 제어를 어렵게 만든다.14</li>
</ol>
<h3>5.3  충돌 감지와 경로 계획의 딜레마</h3>
<p>자율 주행 로봇이나 드론이 경로를 계획할 때, 환경을 표현하는 방식은 안전과 직결된다.</p>
<ul>
<li><strong>포인트 클라우드:</strong> 센서 노이즈로 인해 허공에 생성된 ’고스트 포인트(Ghost Point)’를 장애물로 인식하여 급정지하거나, 반대로 얇은 전선이나 기둥을 감지하지 못하고 충돌하는 사례가 빈번하다.13</li>
<li><strong>복셀 맵:</strong> 안전을 위해 복셀 크기를 키우면(팽창), 로봇이 실제로 통과할 수 있는 좁은 통로를 막힌 길로 판단하여 최적 경로를 찾지 못하는 문제가 발생한다. 반대로 해상도를 높이면 맵 업데이트 속도가 느려져 고속 주행이 불가능해진다.24</li>
</ul>
<h2>6.  결론: 연속적 표현(Continuous Representation)으로의 패러다임 전환</h2>
<p>전통적인 이산적 3D 표현 방식인 복셀, 포인트 클라우드, 메쉬는 지난 수십 년간 3D 비전과 그래픽스 발전을 견인해 왔으나, 딥러닝 기반의 고해상도 생성 및 정밀한 로봇 상호작용이라는 현대적 요구사항 앞에서는 명확한 한계를 드러내고 있다.</p>
<ul>
<li><strong>메모리의 한계:</strong> 복셀의 <span class="math math-inline">O(N^3)</span> 복잡도는 고해상도 확장을 가로막는다.</li>
<li><strong>정보의 부재:</strong> 포인트 클라우드는 위상과 연결성이 없어 구조적 이해를 제한한다.</li>
<li><strong>유연성의 부족:</strong> 메쉬는 위상이 고정되어 있고 미분 불가능하여 딥러닝의 End-to-End 학습에 적합하지 않다.</li>
</ul>
<p>이러한 한계는 필연적으로 새로운 패러다임의 등장을 요구한다. Mescheder 1와 Park 6 등의 연구자들이 지적했듯이, 차세대 3D 표현은 <strong>“메모리 효율적이면서도 무한한 해상도로 형상을 표현할 수 있고(Infinite Resolution), 임의의 위상 변화를 유연하게 다룰 수 있는(Arbitrary Topology)”</strong> 특성을 갖추어야 한다. 이는 3D 공간을 이산적인 데이터 포인트의 집합이 아니라, 좌표 <span class="math math-inline">(x, y, z)</span>를 입력받아 점유 확률이나 거리 값을 출력하는 연속적인 <strong>함수(Function)</strong> 그 자체로 바라보는 관점의 전환을 의미한다.</p>
<p>이어지는 장에서는 이러한 배경하에 등장한 <strong>암시적 함수(Implicit Neural Representations)</strong>, 즉 **점유 네트워크(Occupancy Networks)**와 <strong>부호 거리 함수(Signed Distance Functions, SDF)</strong>, 그리고 **NeRF(Neural Radiance Fields)**가 어떻게 전통적 표현의 한계를 극복하고 3D AI의 새로운 지평을 열고 있는지에 대해 상세히 다룰 것이다. 제미나이와 같은 멀티모달 AI가 진정으로 3차원 물리 세계를 이해하기 위해서는, 픽셀과 복셀이라는 격자를 넘어 연속적인 함수 공간(Function Space)에서의 학습이 필수적이기 때문이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Occupancy Networks: Learning 3D Reconstruction in Function Space - CVF Open Access, https://openaccess.thecvf.com/content_CVPR_2019/papers/Mescheder_Occupancy_Networks_Learning_3D_Reconstruction_in_Function_Space_CVPR_2019_paper.pdf</li>
<li>A Beginner’s Guide to 3D Data: Understanding Point Clouds, Meshes, and Voxels - Medium, https://medium.com/@sanjivjha/a-beginners-guide-to-3d-data-understanding-point-clouds-meshes-and-voxels-385e02108141</li>
<li>Beyond the pixel plane: sensing and learning in 3D - The Gradient, https://thegradient.pub/beyond-the-pixel-plane-sensing-and-learning-in-3d/</li>
<li>[1812.03828] Occupancy Networks: Learning 3D Reconstruction in Function Space - ar5iv, https://ar5iv.labs.arxiv.org/html/1812.03828</li>
<li>Deep Learning for Unsupervised 3D Shape Representation with Superquadrics - MDPI, https://www.mdpi.com/2673-2688/6/12/317</li>
<li>DeepSDF: Learning Continuous Signed … - CVF Open Access, https://openaccess.thecvf.com/content_CVPR_2019/papers/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.pdf</li>
<li>3D Representation Methods: A Survey - arXiv, https://arxiv.org/html/2410.06475v1</li>
<li>How to represent 3D Data? - ORBi, <a href="https://orbi.uliege.be/bitstream/2268/248375/1/How%20to%20represent%203D%20data.pdf">https://orbi.uliege.be/bitstream/2268/248375/1/How%20to%20represent%203D%20data.pdf</a></li>
<li>Challenges of point cloud data. | Download Scientific Diagram - ResearchGate, https://www.researchgate.net/figure/Challenges-of-point-cloud-data_fig2_341709580</li>
<li>Convolutional Occupancy Networks - Andreas Geiger, https://www.cvlibs.net/publications/Peng2020ECCV.pdf</li>
<li>GenSDF: Two-Stage Learning of Generalizable Signed Distance Functions - NeurIPS, https://proceedings.neurips.cc/paper_files/paper/2022/file/9dfb5bc27e2d046199b38739e4ce64bd-Paper-Conference.pdf</li>
<li>Research on Robot Path Planning Based on Point Cloud Map in Orchard Environment - IEEE Xplore, https://ieeexplore.ieee.org/iel7/6287639/10380310/10496676.pdf</li>
<li>Dynamic 3D Point-Cloud-Driven Autonomous Hierarchical Path Planning for Quadruped Robots - PMC - NIH, https://pmc.ncbi.nlm.nih.gov/articles/PMC11117888/</li>
<li>Subsecond 3D Mesh Generation for Robot Manipulation - arXiv, https://arxiv.org/html/2512.24428v1</li>
<li>Contrastive Learning for 3D Point Clouds Classification and Shape Completion - PMC - NIH, https://pmc.ncbi.nlm.nih.gov/articles/PMC8587100/</li>
<li>A Brief Review on Differentiable Rendering: Recent Advances and Challenges - MDPI, https://www.mdpi.com/2079-9292/13/17/3546</li>
<li>A General Differentiable Mesh Renderer for Image-based 3D Reasoning, https://vgl.ict.usc.edu/Research/DMR/</li>
<li>Differentiable Rendering with Perturbed Optimizers - NeurIPS, https://proceedings.neurips.cc/paper/2021/file/ab233b682ec355648e7891e66c54191b-Paper.pdf</li>
<li>Differentiable Visual Computing: Challenges and Opportunities, https://cseweb.ucsd.edu/~tzli/Differentiable_Visual_Computing_Challenges_and_Opportunities.pdf</li>
<li>One-Shot Real-to-Sim via End-to-End Differentiable Simulation and Rendering - arXiv, https://arxiv.org/html/2412.00259v3</li>
<li>Cloth manipulation planning on basis of mesh representations with incomplete domain knowledge and voxel-to-mesh estimation - PMC - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC9849740/</li>
<li>Amodal 3D Reconstruction for Robotic Manipulation via Stability and Connectivity - University of Washington, https://homes.cs.washington.edu/~pedrod/papers/corl20.pdf</li>
<li>Unified 3D Perception and Generative Control for Generalist Robots, https://www.ri.cmu.edu/app/uploads/2025/08/ngkanats_phd_ri_2025.pdf</li>
<li>Obstacle Avoidance and Path Planning Methods for Autonomous Navigation of Mobile Robot - MDPI, https://www.mdpi.com/1424-8220/24/11/3573</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>