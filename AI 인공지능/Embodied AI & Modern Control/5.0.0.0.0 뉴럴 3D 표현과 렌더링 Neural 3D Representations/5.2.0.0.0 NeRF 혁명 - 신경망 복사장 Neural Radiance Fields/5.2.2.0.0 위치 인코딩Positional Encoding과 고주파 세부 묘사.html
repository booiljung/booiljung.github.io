<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.2.2 위치 인코딩(Positional Encoding)과 고주파 세부 묘사</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.2.2 위치 인코딩(Positional Encoding)과 고주파 세부 묘사</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 5. 뉴럴 3D 표현과 렌더링 (Neural 3D Representations)</a> / <a href="index.html">5.2 NeRF 혁명: 신경망 복사장 (Neural Radiance Fields)</a> / <span>5.2.2 위치 인코딩(Positional Encoding)과 고주파 세부 묘사</span></nav>
                </div>
            </header>
            <article>
                <h1>5.2.2 위치 인코딩(Positional Encoding)과 고주파 세부 묘사</h1>
<p>본 장에서는 뉴럴 래디언스 필드(NeRF)의 성능을 결정짓는 가장 핵심적이고도 이론적으로 심도 있는 메커니즘인 ’위치 인코딩(Positional Encoding)’에 대해 포괄적으로 다룬다. NeRF가 단순한 완전 연결 신경망(Fully Connected Network) 구조임에도 불구하고 사진과 같은 고해상도의 디테일과 날카로운 경계면을 표현할 수 있는 이유는 바로 입력 좌표를 고차원의 주파수 영역으로 매핑하는 이 과정에 있다. 본 절에서는 딥러닝 네트워크가 본질적으로 갖는 ’스펙트럼 편향(Spectral Bias)’의 이론적 배경을 뉴럴 탄젠트 커널(Neural Tangent Kernel, NTK) 관점에서 분석하고, NeRF 저자들이 채택한 위치 인코딩 수식의 수학적 함의와 하이퍼파라미터 <span class="math math-inline">L=10, L=4</span>의 설정 근거, 그리고 이것이 최종 렌더링 품질과 3D 장면의 기하학적 복원에 미치는 영향을 철저하게 파헤친다.</p>
<h2>1.  좌표 기반 신경망의 한계와 스펙트럼 편향(Spectral Bias)</h2>
<p>NeRF의 핵심 아이디어는 3차원 공간의 좌표 <span class="math math-inline">(x, y, z)</span>와 시점 방향 <span class="math math-inline">(\theta, \phi)</span>를 입력받아 해당 위치의 색상 <span class="math math-inline">\mathbf{c}=(r, g, b)</span>와 밀도 <span class="math math-inline">\sigma</span>를 출력하는 연속적인 함수 <span class="math math-inline">F_\Theta</span>를 신경망으로 근사하는 것이다. 이론적으로 다층 퍼셉트론(MLP)은 ’보편 근사 정리(Universal Approximation Theorem)’에 의해 충분한 수의 뉴런과 층이 주어지면 임의의 연속 함수를 근사할 수 있어야 한다. 그러나 초기 NeRF 연구진이 위치 인코딩 없이 순수한 <span class="math math-inline">xyz</span> 좌표값(Raw Coordinates)만을 정규화하여 MLP에 입력했을 때, 결과는 이론적 기대와는 전혀 달랐다.1</p>
<h3>1.1 고주파수 정보의 손실 현상</h3>
<p>실험 결과, 위치 인코딩이 없는 네트워크는 장면의 전체적인 색감(Low-frequency content)은 학습할 수 있었으나, 텍스처, 날카로운 모서리, 미세한 그림자와 같은 고주파(High-frequency) 성분을 전혀 표현하지 못했다. 결과물은 마치 초점이 맞지 않는 사진처럼 극도로 흐릿한(Blurry) 상태였으며, 학습을 아무리 오래 진행해도 디테일은 개선되지 않았다.1 이는 단순히 네트워크의 용량(Capacity) 부족 문제가 아니라, 좌표 기반 MLP가 갖는 구조적인 학습 편향 때문이었다.</p>
<h3>1.2 스펙트럼 편향(Spectral Bias)의 심층 분석</h3>
<p>이러한 현상은 딥러닝 이론에서 <strong>스펙트럼 편향(Spectral Bias)</strong> 또는 **F-Principle(Frequency Principle)**이라 불리는 개념으로 설명된다.2 Rahimi와 Recht의 연구, 그리고 이후 Tancik 등이 주도한 연구들은 ReLU 활성화 함수를 사용하는 심층 신경망이 주파수 도메인에서 어떻게 동작하는지를 수학적으로 규명했다.</p>
<ol>
<li><strong>저주파 우선 학습의 법칙:</strong> 경사 하강법(Gradient Descent)을 통해 최적화되는 신경망은 목표 함수(Target Function)의 오차를 줄여나갈 때, 저주파 성분부터 우선적으로 학습하는 경향이 있다. 즉, 이미지의 전체적인 밝기나 완만한 색상 변화는 초기 에폭(Epoch)에서 빠르게 수렴하지만, 급격한 변화를 나타내는 고주파 성분은 학습 속도가 기하급수적으로 느리거나, 학습 데이터의 노이즈로 간주되어 무시되는 경향이 있다.3</li>
<li><strong>뉴럴 탄젠트 커널(NTK)과 대역폭의 한계:</strong> NTK 이론은 무한한 너비를 가진 신경망의 학습 동역학을 커널 회귀(Kernel Regression)로 모델링한다. 이 이론에 따르면, 표준 좌표 기반 MLP는 입력 공간에서의 거리에 따라 급격하게 감쇠하는(rapid frequency falloff) 커널에 해당한다.3 신호 처리 관점에서 이는 네트워크가 본질적으로 강력한 **‘저역 통과 필터(Low-pass Filter)’**로 동작함을 의미한다. 따라서 네트워크가 표현할 수 있는 주파수 대역폭(Bandwidth)이 제한되어 있어, 자연 이미지나 복잡한 3D 장면과 같이 넓은 주파수 스펙트럼을 가진 함수를 근사하는 데 근본적인 병목(Bottleneck)이 발생한다.3</li>
</ol>
<p>결론적으로, <span class="math math-inline">(x, y, z)</span>와 같은 저차원 좌표를 직접 입력으로 사용하는 것은 네트워크가 고차원의 복잡한 신호를 학습하는 것을 방해한다. 이를 극복하기 위해서는 입력을 네트워크가 처리하기 쉬운 형태, 즉 고주파 성분이 명시적으로 포함된 고차원 공간으로 변환해주는 과정이 필수적이다.</p>
<h2>2.  위치 인코딩 함수 <span class="math math-inline">\gamma(\cdot)</span>의 수학적 정의와 메커니즘</h2>
<p>NeRF 연구진은 스펙트럼 편향 문제를 해결하기 위해, 입력 좌표를 네트워크에 주입하기 전에 고주파수 삼각함수들의 집합으로 매핑하는 <strong>위치 인코딩(Positional Encoding)</strong> 기법을 도입했다. 이는 트랜스포머(Transformer) 모델에서 시퀀스의 순서 정보를 주입하기 위해 사용된 방법과 수식적으로 유사하지만, 그 목적은 전혀 다르다. 트랜스포머가 이산적인 토큰의 위치(Discrete positions)를 구분하기 위해 인코딩을 사용했다면, NeRF는 연속적인 좌표 공간(Continuous coordinate space)을 고차원 매니폴드로 매핑하여 네트워크가 고주파 변동을 쉽게 보간(Interpolate)할 수 있도록 돕는 역할을 한다.6</p>
<h3>2.1 인코딩 수식의 상세 구조</h3>
<p>위치 인코딩 함수 <span class="math math-inline">\gamma : \mathbb{R} \rightarrow \mathbb{R}^{2L}</span>은 스칼라 입력값 <span class="math math-inline">p</span>를 <span class="math math-inline">2L</span>차원의 벡터로 변환한다. NeRF 논문에서 정의한 표준 수식은 다음과 같다 8:<br />
<span class="math math-display">
\gamma(p) = \left( \sin(2^0 \pi p), \cos(2^0 \pi p), \sin(2^1 \pi p), \cos(2^1 \pi p), \dots, \sin(2^{L-1} \pi p), \cos(2^{L-1} \pi p) \right)
</span><br />
이 수식의 설계에는 다음과 같은 공학적 고려사항들이 반영되어 있다.</p>
<ol>
<li><strong>입력 정규화 (Normalization):</strong> 함수 <span class="math math-inline">\gamma</span>를 적용하기 전, 모든 입력 좌표 <span class="math math-inline">p</span> (즉, <span class="math math-inline">x, y, z</span> 및 방향 벡터의 성분)는 <span class="math math-inline">[-1, 1]</span> 범위 내에 존재하도록 정규화된다.1 이는 삼각함수의 주기성과 결합하여, 전체 장면이 삼각함수의 정의 구역 내에 적절히 분포되도록 보장한다. 만약 입력값이 이 범위를 크게 벗어나면 동일한 인코딩 값을 갖는 위치들이 발생하는 앨리어싱(Aliasing) 문제가 생길 수 있다.</li>
<li><strong>로그 스케일 주파수 할당 (Log-linear Spacing):</strong> 주파수 계수는 <span class="math math-inline">2^0, 2^1, \dots, 2^{L-1}</span>과 같이 2의 거듭제곱 형태로 증가한다. 이는 음악의 옥타브(Octave) 개념이나 신호 처리의 웨이블릿(Wavelet) 변환과 유사하게, 네트워크가 거시적인 구조(저주파)부터 미세한 디테일(고주파)까지 계층적으로 정보에 접근할 수 있도록 한다.10 선형적으로 주파수를 증가시키는 것보다 로그 스케일로 증가시키는 것이 넓은 주파수 대역을 효율적으로 커버하는 데 유리하다.</li>
<li><strong>위상 보존과 직교성:</strong> 각 주파수에 대해 <span class="math math-inline">\sin</span>과 <span class="math math-inline">\cos</span> 항을 쌍으로 배치함으로써, 위상(Phase) 정보가 보존된다. 이는 오일러 공식 <span class="math math-inline">e^{ix} = \cos x + i\sin x</span>에 의해 복소 평면에서의 회전으로 해석될 수 있으며, 네트워크가 공간상에서의 이동(Shift) 불변성을 학습하는 데 도움을 준다. 또한, 서로 다른 주파수의 삼각함수들은 서로 직교(Orthogonal)에 가까운 성질을 가지므로, 입력 피처 간의 독립성을 높여 MLP의 학습 효율을 증대시킨다.</li>
<li><strong><span class="math math-inline">\pi</span>의 역할:</strong> 수식에 포함된 <span class="math math-inline">\pi</span> 항은 정규화된 입력 범위 <span class="math math-inline">[-1, 1]</span>을 삼각함수의 주기 <span class="math math-inline">2\pi</span>에 대응시키는 스케일링 팩터다. <span class="math math-inline">\sin(\pi p)</span>는 <span class="math math-inline">p</span>가 -1에서 1로 변할 때 정확히 한 주기를 완성한다. 이를 통해 입력 공간 전체에 걸쳐 고유한 피처 값을 생성할 수 있다.8</li>
</ol>
<p>3차원 공간 좌표 <span class="math math-inline">\mathbf{x} = (x, y, z)</span>의 경우, 이 함수는 각 성분에 대해 독립적으로 적용되며, 그 결과들은 연결(Concatenate)되어 최종적으로 <span class="math math-inline">3 \times 2L</span> 차원의 벡터를 형성한다. 마찬가지로 3차원 카르테시안 단위 벡터로 표현된 시점 방향 <span class="math math-inline">\mathbf{d}</span>도 동일한 방식으로 인코딩된다.</p>
<h2>3.  주파수 대역 파라미터 <span class="math math-inline">L</span>의 전략적 설정: <span class="math math-inline">L=10</span>과 <span class="math math-inline">L=4</span></h2>
<p>NeRF 모델의 렌더링 품질을 결정짓는 가장 중요한 하이퍼파라미터는 주파수 대역의 수 <span class="math math-inline">L</span>이다. 이 값은 네트워크가 얼마나 높은 주파수의 정보를 받아들일지 결정하는 ’대역폭 조절 나사’와 같다. NeRF 연구진은 실험적 검증을 통해 공간 위치 <span class="math math-inline">\mathbf{x}</span>와 시점 방향 <span class="math math-inline">\mathbf{d}</span>에 대해 서로 다른 <span class="math math-inline">L</span> 값을 설정하는 비대칭적 전략을 채택했다.8</p>
<p>아래 표는 각 입력 유형에 따른 파라미터 설정과 그에 따른 입력 벡터의 차원 변화를 요약한 것이다.</p>
<table><thead><tr><th><strong>입력 변수</strong></th><th><strong>기호</strong></th><th><strong>물리적 의미</strong></th><th><strong>성분 수 (Dimensions)</strong></th><th><strong>주파수 대역 수 (L)</strong></th><th><strong>최종 인코딩 차원</strong></th><th><strong>설정 근거 및 목적</strong></th></tr></thead><tbody>
<tr><td><strong>공간 위치</strong></td><td><span class="math math-inline">\mathbf{x}</span></td><td>3D 좌표 <span class="math math-inline">(x, y, z)</span></td><td>3</td><td><strong>10</strong></td><td><span class="math math-inline">3 \times 2 \times 10 = 60</span></td><td>기하학적 형상의 정밀함, 텍스처의 고주파 디테일 표현</td></tr>
<tr><td><strong>시점 방향</strong></td><td><span class="math math-inline">\mathbf{d}</span></td><td>관측 각도 <span class="math math-inline">(d_x, d_y, d_z)</span></td><td>3</td><td><strong>4</strong></td><td><span class="math math-inline">3 \times 2 \times 4 = 24</span></td><td>부드러운 조명 변화, 반사(Specular) 표현, 과적합 방지</td></tr>
</tbody></table>
<h3>3.1  공간 위치 <span class="math math-inline">\mathbf{x}</span>에 대한 <span class="math math-inline">L=10</span>: 고해상도 기하학의 복원</h3>
<p>공간 좌표 <span class="math math-inline">\mathbf{x}</span>에 대해 상대적으로 높은 값인 <span class="math math-inline">L=10</span>을 설정한 이유는 3D 장면의 기하학적 구조(Geometry)와 색상 텍스처가 매우 높은 주파수 성분을 포함하고 있기 때문이다.</p>
<ul>
<li><strong>불연속적인 밀도 장(Density Field):</strong> 3D 공간에서 물체와 빈 공간(Air)의 경계는 밀도 <span class="math math-inline">\sigma</span>가 0에서 양수 값으로 급격하게 변하는 지점이다. 신호 처리 관점에서 이러한 ’계단 함수(Step Function)’나 ’펄스(Pulse)’는 무한한 고주파 성분의 합으로 표현된다. 따라서 물체의 경계면을 흐릿하지 않고 날카롭게(Sharp) 표현하기 위해서는 충분히 높은 주파수 대역의 정보가 입력되어야 한다.</li>
<li><strong>복잡한 텍스처 표현:</strong> 레고 장난감의 미세한 그릴 구멍, 나뭇잎의 잎맥, 카펫의 질감 등은 픽셀 단위에서 급격한 색상 변화를 일으킨다. <span class="math math-inline">L=10</span>일 때, 최대 주파수는 <span class="math math-inline">2^9\pi = 512\pi</span>에 달하며, 이는 입력 좌표 공간에서 매우 미세한 위치 변화에도 인코딩 값이 크게 진동함을 의미한다. 이를 통해 네트워크는 아주 작은 공간적 차이도 구별할 수 있게 된다.1</li>
<li><strong>실험적 최적점:</strong> 연구진은 <span class="math math-inline">L</span> 값을 변화시키며 실험한 결과, <span class="math math-inline">L=10</span> 근처에서 지각적 품질(Perceptual Quality)과 노이즈 억제 사이의 균형이 가장 좋음을 확인했다. <span class="math math-inline">L</span>이 너무 낮으면 이미지가 흐려지고, <span class="math math-inline">L</span>이 지나치게 높으면 고주파 노이즈가 발생할 수 있다.</li>
</ul>
<h3>3.2  시점 방향 <span class="math math-inline">\mathbf{d}</span>에 대한 <span class="math math-inline">L=4</span>: 반사 특성과 과적합의 제어</h3>
<p>반면, 시점 방향 <span class="math math-inline">\mathbf{d}</span>에 대해서는 <span class="math math-inline">L=4</span>라는 낮은 값을 사용한다. 여기에는 렌더링 방정식의 물리적 특성과 학습 안정성에 대한 깊은 고려가 담겨 있다.</p>
<ul>
<li><strong>BRDF의 저주파 특성:</strong> 람베르트 반사(Lambertian Reflection)와 같은 난반사 성분은 시점에 따라 색상이 거의 변하지 않으며, 정반사(Specular Reflection)조차도 현실 세계의 물체에서는 어느 정도의 거칠기(Roughness)로 인해 빛이 퍼지는 현상을 보인다. 따라서 특정 지점의 색상이 시점에 따라 변하는 양상은 공간적 변화에 비해 훨씬 부드럽고 완만하다(Smooth function).13</li>
<li><strong>과적합(Overfitting) 방지:</strong> 만약 시점 방향에 대해 높은 <span class="math math-inline">L</span>값(예: 10)을 사용한다면, 네트워크는 훈련 이미지에 존재하는 고주파 노이즈나 특정 뷰에서만 관찰되는 일시적인 아티팩트까지 ’시점 의존적 효과’로 착각하여 학습할 수 있다. 이는 새로운 뷰에서 렌더링할 때, 공중에 떠 있는 불규칙한 유리 조각 같은 ‘플로터(Floater)’ 아티팩트를 만들거나, 물체의 표면이 보는 각도에 따라 비현실적으로 반짝거리는 문제를 야기한다.</li>
<li><strong>구조적 제약(Architectural Constraint):</strong> NeRF의 네트워크 구조는 밀도 <span class="math math-inline">\sigma</span>는 오직 위치 <span class="math math-inline">\mathbf{x}</span>에만 의존하고, 색상 <span class="math math-inline">\mathbf{c}</span>만이 <span class="math math-inline">\mathbf{x}</span>와 <span class="math math-inline">\mathbf{d}</span> 모두에 의존하도록 설계되어 있다. 시점 방향 인코딩의 차원을 24차원(<span class="math math-inline">L=4</span>)으로 제한함으로써, 네트워크의 용량이 형상(Geometry) 학습에 집중되도록 하고, 시점 정보는 오직 조명 효과를 조절하는 데에만 사용되도록 강제하는 효과가 있다.7</li>
</ul>
<h2>4.  푸리에 피처(Fourier Features)와 튜닝 가능한 대역폭</h2>
<p>Tancik 등이 발표한 “Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains” 2 논문은 NeRF의 위치 인코딩이 단순한 경험적 트릭이 아니라, <strong>NTK의 커널 대역폭을 제어하는 수학적으로 정당한 방법</strong>임을 입증했다. 이 연구는 NeRF의 성공 요인을 이론적으로 뒷받침하는 가장 중요한 문헌이다.</p>
<h3>4.1 고정 커널에서 튜닝 가능한 커널로의 전환</h3>
<p>표준 MLP의 NTK는 회전 불변(Rotation invariant) 성질을 가지며, 이는 고정된 대역폭을 가진 커널로 작용한다. 그러나 입력 데이터 <span class="math math-inline">\mathbf{v}</span>를 푸리에 피처 매핑 <span class="math math-inline">\gamma(\mathbf{v})</span>로 변환한 후 MLP에 통과시키면, 합성된 커널(Composed Kernel)은 **고정적(Stationary)**이면서도 **튜닝 가능한 대역폭(Tunable Bandwidth)**을 가진 커널로 변환된다.3</p>
<p>여기서 ’튜닝 가능하다’는 것은 인코딩 수식의 주파수 스케일(NeRF의 경우 <span class="math math-inline">2^k</span>)을 조절함으로써 NTK 커널의 폭(Width)을 조절할 수 있다는 뜻이다.</p>
<ul>
<li><strong>좁은 대역폭 (Low Scale):</strong> 커널이 넓게 퍼지며(Wide kernel), 네트워크는 데이터 포인트들을 부드럽게 보간한다. 이는 과소적합(Underfitting)을 유발하여 이미지를 흐릿하게 만든다.</li>
<li><strong>적절한 대역폭 (NeRF의 설정):</strong> 커널 폭이 적절히 좁아져 데이터의 세밀한 구조를 포착하면서도 인접한 영역의 일관성을 유지한다. 이것이 NeRF가 <span class="math math-inline">L=10</span>에서 달성한 지점이다.</li>
<li><strong>지나친 대역폭 (High Scale):</strong> 커널이 델타 함수(Delta function)에 가까워지며, 네트워크는 훈련 데이터 포인트들 사이를 전혀 연결하지 못하고 개별 픽셀 값만 암기해버린다. 이는 과적합(Overfitting)과 고주파 노이즈를 초래한다.5</li>
</ul>
<h3>4.2 가우시안 매핑(Gaussian Mapping)과의 비교</h3>
<p>Tancik 등의 연구에서는 NeRF와 같은 축 정렬(Axis-aligned) 인코딩 외에도, 랜덤한 방향의 주파수를 사용하는 가우시안 푸리에 피처 매핑(Random Fourier Features)을 제안했다.<br />
<span class="math math-display">
\gamma(\mathbf{v}) = [\cos(2\pi \mathbf{B}\mathbf{v}), \sin(2\pi \mathbf{B}\mathbf{v})]^T
</span><br />
여기서 <span class="math math-inline">\mathbf{B}</span>는 가우시안 분포 <span class="math math-inline">\mathcal{N}(0, \sigma^2)</span>에서 샘플링된 행렬이다. 이론적으로는 가우시안 매핑이 방향 편향(Directional Bias)이 없어 더 우수할 수 있으나, NeRF와 같은 3D 복원 작업에서는 x, y, z 축을 따라 정렬된 구조(건축물, 격자 등)가 많기 때문에 축 정렬 인코딩(<span class="math math-inline">2^k</span> 방식)이 경험적으로 더 나은 성능을 보이거나 대등한 결과를 낸다. NeRF가 채택한 방식은 이산적인 주파수 대역을 결정론적으로(Deterministically) 사용함으로써 구현의 단순함과 성능의 안정성을 모두 확보했다.3</p>
<h2>5.  비교 분석: 다른 인코딩 기법 및 모델</h2>
<p>NeRF의 위치 인코딩 방식을 이해하기 위해, 유사한 목적을 가진 다른 기법들과 비교해 보는 것이 유익하다.</p>
<table><thead><tr><th><strong>비교 대상</strong></th><th><strong>특징 및 차이점</strong></th><th><strong>NeRF와의 관계</strong></th></tr></thead><tbody>
<tr><td><strong>Transformer Positional Encoding</strong></td><td>시퀀스 내 토큰의 상대적/절대적 위치 인덱싱 목적. 순서 정보 주입이 주된 목표.</td><td>수식 형태는 매우 유사하나(사인/코사인 사용), NeRF는 ’연속 좌표의 매니폴드 매핑’을 위해 사용한다는 점에서 목적이 완전히 다르다.6</td></tr>
<tr><td><strong>SIREN (Sinusoidal Representation Networks)</strong></td><td>활성화 함수 자체를 ReLU 대신 사인 함수(<span class="math math-inline">\sin</span>)로 사용. 미분 가능성이 뛰어나고 고주파 정보를 잘 학습함.</td><td>NeRF는 입력단에서만 사인 함수를 사용하고 내부는 ReLU를 쓰지만, SIREN은 모든 층에서 주기 함수를 사용한다. SIREN이 더 복잡한 신호를 표현할 수 있으나 학습이 까다로울 수 있다. NeRF의 PE 방식이 더 일반적인 MLP 구조와 호환성이 좋다.5</td></tr>
<tr><td><strong>Instant-NGP (Hash Encoding)</strong></td><td>공간을 다해상도 해시 테이블(Hash Table)로 매핑하고, 학습 가능한 파라미터(Feature vector)를 저장.</td><td>NeRF의 함수형 인코딩과 달리, 메모리를 사용하여 피처를 직접 학습한다. NeRF 방식보다 학습 속도가 수천 배 빠르고 디테일 표현력이 뛰어나지만, 메모리 사용량이 크다. NeRF의 PE는 메모리 효율적인 대안이다.</td></tr>
<tr><td><strong>Grid-based Methods (Plenoxels, DVGO)</strong></td><td>3D 공간을 복셀 그리드에 직접 저장.</td><td>위치 인코딩이 필요 없거나 보간(Interpolation)에 의존한다. NeRF의 PE는 연속적인 함수 표현(Implicit Representation)을 가능하게 하여 무한한 해상도를 이론적으로 지원한다는 차별점이 있다.</td></tr>
</tbody></table>
<h2>6.  코드 구현과 실제 적용</h2>
<p>실제 연구 및 개발 환경에서 NeRF의 위치 인코딩은 <code>Embedder</code> 클래스로 모듈화되어 구현된다. PyTorch 프레임워크를 기준으로 한 구현의 핵심 논리는 다음과 같다.8</p>
<ol>
<li><strong>입력 차원 확인:</strong> <code>input_dims</code> 인자를 통해 위치(3)인지 방향(3)인지 확인한다. (논문에 따라 방향을 구면 좌표계 <span class="math math-inline">(\theta, \phi)</span>인 2차원으로 보기도 하지만, 구현의 편의성과 짐벌 락 방지를 위해 3차원 카르테시안 벡터를 주로 사용한다 8).</li>
<li><strong>주파수 밴드 생성:</strong> <code>torch.linspace</code>를 사용하여 <span class="math math-inline">0</span>부터 <span class="math math-inline">L-1</span>까지의 지수 스케일을 생성하고, 이를 <span class="math math-inline">2</span>의 거듭제곱으로 변환한다.</li>
<li><strong>함수 리스트 구성:</strong> 생성된 주파수 밴드 각각에 대해 <span class="math math-inline">\sin</span>과 <span class="math math-inline">\cos</span> 함수를 적용하는 람다(Lambda) 함수들을 리스트에 담는다. 이때 <span class="math math-inline">\pi</span>를 곱하는 연산이 포함된다.</li>
<li><strong>원본 입력 포함(Include Input):</strong> 많은 구현체에서 인코딩된 벡터뿐만 아니라 원본 입력 <span class="math math-inline">\mathbf{x}</span> 자체도 벡터의 초입에 연결(Concatenate)한다. 이는 ResNet의 스킵 연결(Skip Connection)과 유사하게, 네트워크가 고주파 정보뿐만 아니라 선형적인 위치 정보에도 직접 접근할 수 있게 하여 학습 초기 안정성을 돕는다.8</li>
</ol>
<pre><code class="language-Python"># NeRF 위치 인코딩의 개념적 구현 (PyTorch)
class Embedder:
    def __init__(self, **kwargs):
        self.kwargs = kwargs
        self.create_embedding_fn()

    def create_embedding_fn(self):
        embed_fns =
        d = self.kwargs['input_dims']
        out_dim = 0
        
        # 원본 입력 포함 여부 확인 (일반적으로 True)
        if self.kwargs['include_input']:
            embed_fns.append(lambda x : x)
            out_dim += d
            
        max_freq = self.kwargs['max_freq_log2'] # L-1
        N_freqs = self.kwargs['num_freqs']      # L
        
        # 주파수 밴드 생성: 2^0, 2^1,..., 2^(L-1)
        if self.kwargs['log_sampling']:
            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)
        else:
            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)
            
        for freq in freq_bands:
            for p_fn in [torch.sin, torch.cos]:
                # 핵심 수식 적용: sin(2^k * pi * x)
                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq * torch.pi)) 
                out_dim += 2 * d # sin, cos 성분 추가
        
        self.embed_fns = embed_fns
        self.out_dim = out_dim

    def embed(self, inputs):
        # 모든 인코딩 함수를 적용 후 채널 차원(마지막 차원)에서 연결
        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)
</code></pre>
<p>이 구현 코드는 NeRF 모델의 <code>forward</code> 패스 가장 앞단에서 호출되며, 입력 좌표를 고차원으로 팽창시켜 MLP의 첫 번째 레이어(Linear Layer)로 전달한다. 계산 비용 측면에서 위치 인코딩은 단순한 요소별(Element-wise) 연산이므로 전체 렌더링 파이프라인에서 차지하는 부하는 무시할 수 있을 만큼 작다.</p>
<h2>7.  결론 및 시사점</h2>
<p>5.2.2절에서는 NeRF가 딥러닝의 고질적인 한계인 스펙트럼 편향을 극복하고, 사진과 구별하기 힘든 고주파 세부 묘사를 달성할 수 있었던 핵심 동력인 위치 인코딩을 심층적으로 분석했다.</p>
<p><span class="math math-inline">\gamma(\cdot)</span> 함수를 통한 고차원 매핑은 단순한 좌표 변환이 아니라, NTK의 커널 대역폭을 튜닝하여 신경망의 학습 동역학을 근본적으로 변화시키는 과정이다. 특히, 기하학적 정밀도가 요구되는 공간 좌표에는 <span class="math math-inline">L=10</span>을, 부드러운 색상 변화가 주를 이루는 시점 방향에는 <span class="math math-inline">L=4</span>를 할당한 NeRF의 비대칭적 설계는 3D 장면의 물리적 특성과 신경망 학습 이론이 정교하게 결합된 결과다.</p>
<p>위치 인코딩이 없었다면 NeRF는 흐릿한 덩어리만을 생성하는 실패한 실험으로 끝났을 것이다. 그러나 이 간단하면서도 강력한 아이디어 덕분에 NeRF는 컴퓨터 비전과 그래픽스 분야의 패러다임을 바꾸는 혁신적인 모델로 자리 잡을 수 있었다. 이러한 위치 인코딩 전략은 이후 등장한 Mip-NeRF의 IPE(Integrated Positional Encoding), BARF의 번들 조정(Bundle Adjustment), 그리고 다양한 NeRF 변형 모델들의 이론적 토대가 되었으며, 좌표 기반 신경망(Coordinate-based Neural Networks)이 나아가야 할 방향을 제시했다.13</p>
<h2>8. 참고 자료</h2>
<ol>
<li>ankurhanda/nerf2D: Adding positional encoding to the input preserves sharp edges in the image - GitHub, https://github.com/ankurhanda/nerf2D</li>
<li>Fourier Features Let Networks Learn High Frequency … - Neural Fields, https://neuralfields.cs.brown.edu/paper_46.html</li>
<li>Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains - NeurIPS, https://papers.neurips.cc/paper_files/paper/2020/file/55053683268957697aa39fba6f231c68-Paper.pdf</li>
<li>Frequency principle/spectral bias - Wikipedia, https://en.wikipedia.org/wiki/Frequency_principle/spectral_bias</li>
<li>Fourier Feature Networks - Ben Mildenhall, https://bmild.github.io/fourfeat/</li>
<li>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis, https://cseweb.ucsd.edu/~ravir/pratul_eccv20.pdf</li>
<li>Neural Radiance Fields (NeRF): A Complete Tutorial | by Kavishka Abeywardana - Medium, https://medium.com/@kdwaMachineLearning/neural-radiance-fields-nerf-a-complete-tutorial-b813e3ed4461</li>
<li>The Annotated NeRF Training NeRF on Custom Dataset in Pytorch, https://learnopencv.com/annotated-nerf-pytorch/</li>
<li>Neural Radiance Field | Qiang Zhang, https://zhangtemplar.github.io/nerf/</li>
<li>NeRF View Synthesis - Emergent Mind, https://www.emergentmind.com/topics/neural-radiance-field-nerf-view-synthesis</li>
<li>Deep Dive into NeRF (Neural Radiance Fields) - Damian Bogunowicz - dtransposed, https://dtransposed.github.io/blog/2022/08/06/NeRF/</li>
<li>Semantically-aware Neural Radiance Fields for Visual Scene Understanding: A Comprehensive Review - arXiv, https://arxiv.org/html/2402.11141v1</li>
<li>NeRF: Neural Radiance Field in 3D Vision: A Comprehensive Review - arXiv, https://arxiv.org/html/2210.00379v6</li>
<li>[2006.10739] Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains - arXiv, https://arxiv.org/abs/2006.10739</li>
<li>Key Parts and Codes(NeRF) - Medium, https://medium.com/@335653717/key-parts-and-codes-nerf-47040d620f8b</li>
<li>Adaptive Positional Encoding for Bundle-Adjusting Neural Radiance Fields - CVF Open Access, https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Positional_Encoding_for_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2023_paper.pdf</li>
<li>BARF: Bundle-Adjusting Neural Radiance Fields - Chen-Hsuan Lin, https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>