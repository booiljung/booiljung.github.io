<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:5.2.1 볼륨 렌더링 방정식(Volumetric Rendering Equation)과 밀도(Density)</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>5.2.1 볼륨 렌더링 방정식(Volumetric Rendering Equation)과 밀도(Density)</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 5. 뉴럴 3D 표현과 렌더링 (Neural 3D Representations)</a> / <a href="index.html">5.2 NeRF 혁명: 신경망 복사장 (Neural Radiance Fields)</a> / <span>5.2.1 볼륨 렌더링 방정식(Volumetric Rendering Equation)과 밀도(Density)</span></nav>
                </div>
            </header>
            <article>
                <h1>5.2.1 볼륨 렌더링 방정식(Volumetric Rendering Equation)과 밀도(Density)</h1>
<h2>1.  서론: 기하학적 명시성에서 확률적 연속체로의 전환</h2>
<h3>1.1  새로운 패러다임의 도래</h3>
<p>컴퓨터 그래픽스와 비전의 역사는 장면(Scene)을 어떻게 효율적이고 정확하게 표현할 것인가에 대한 끊임없는 탐구의 과정이었다. 전통적으로 3차원 세계는 폴리곤 메쉬(Polygon Mesh)나 포인트 클라우드(Point Cloud)와 같은 ‘명시적(Explicit)’ 표면 표현법에 의해 지배되어 왔다. 이러한 방식은 물체와 빈 공간 사이의 경계가 확정적(Deterministic)이며, 표면은 불투명하고 단단한 껍질이라는 가정을 전제로 한다. 그러나 2020년, Neural Radiance Fields(NeRF)의 등장은 이러한 고전적 관점을 송두리째 뒤흔들었다.1 NeRF는 3차원 공간을 비어있는 공간과 물체가 있는 공간으로 이분법적으로 나누지 않는다. 대신, 공간 전체를 미세한 입자(Particle)들이 떠다니는, 밀도(Density)를 가진 연속적인 매질(Medium)로 간주한다.</p>
<p>이러한 접근 방식의 핵심에는 **볼륨 렌더링 방정식(Volumetric Rendering Equation)**이 자리 잡고 있다. 이것은 단순한 렌더링 알고리즘이 아니다. 이것은 2차원 이미지라는 관측된 결과물로부터 3차원 공간의 구조라는 원인을 추론해내기 위한 미분 가능한 확률적 엔진이다. 본 절에서는 이 방정식의 물리적 기원인 복사 전달 이론(Radiative Transfer Theory)에서 시작하여, 신경망이 학습 가능한 형태의 미분 방정식으로 유도되는 과정, 그리고 컴퓨터가 계산 가능한 이산적(Discrete) 형태로 변환되는 수치 해석적 기법들을 심도 있게 파헤칠 것이다.</p>
<h3>1.2  “구름“으로서의 세계</h3>
<p>NeRF의 세계관에서 모든 물체는 본질적으로 ’구름’과 같다. 단단한 책상도, 투명한 유리잔도, 복잡한 머리카락도 모두 공간상에 분포하는 밀도 함수 <span class="math math-inline">\sigma(\mathbf{x})</span>의 값 차이일 뿐이다.3 책상은 밀도가 매우 높은 입자들의 집합이며, 공기는 밀도가 0에 수렴하는 입자들의 집합이다. 이러한 관점은 위상(Topology)의 변화를 자연스럽게 처리할 수 있게 하며, 반투명한 물체나 연기, 불꽃과 같은 볼륨 효과(Volumetric Effects)를 별도의 예외 처리 없이 통합적으로 표현할 수 있게 한다.</p>
<p>우리는 이제부터 빛이 이 가상의 입자 구름을 통과하며 겪는 물리적 여정을 수식으로 추적할 것이다. 이 여정은 확률론과 미적분학, 그리고 신호 처리 이론이 교차하는 지점에서 설명된다.</p>
<h2>2.  물리적 기초: 복사 전달과 방출-흡수 모델</h2>
<h3>2.1  복사 전달 방정식(Radiative Transfer Equation)의 일반형</h3>
<p>볼륨 렌더링 방정식의 뿌리는 입자 물리학과 대기 과학에서 주로 다루는 복사 전달 방정식(RTE)에 있다. 일반적인 매질 내에서 빛의 휘도(Radiance) <span class="math math-inline">L</span>이 방향 <span class="math math-inline">\mathbf{\omega}</span>로 진행하며 거리 <span class="math math-inline">s</span>만큼 이동할 때 겪는 변화는 다음과 같이 기술된다.<br />
<span class="math math-display">
\frac{dL(\mathbf{x}, \mathbf{\omega})}{ds} = -\sigma_t(\mathbf{x}) L(\mathbf{x}, \mathbf{\omega}) + \sigma_a(\mathbf{x}) L_e(\mathbf{x}, \mathbf{\omega}) + \sigma_s(\mathbf{x}) \int_{\Omega} p(\mathbf{\omega}, \mathbf{\omega}&#39;) L(\mathbf{x}, \mathbf{\omega}&#39;) d\mathbf{\omega}&#39;
</span><br />
여기서 각 항은 다음을 의미한다:</p>
<ol>
<li><span class="math math-inline">-\sigma_t L</span>: 소멸(Extinction). 흡수와 산란에 의해 빛이 잃어버리는 양.</li>
<li><span class="math math-inline">+\sigma_a L_e</span>: 방출(Emission). 매질 자체가 스스로 빛을 내는 양 (예: 불, 형광).</li>
<li><span class="math math-inline">+\sigma_s \int...</span>: 산란(In-scattering). 다른 방향에서 오던 빛이 산란되어 현재 방향 <span class="math math-inline">\mathbf{\omega}</span>로 합류하는 양.</li>
</ol>
<p>이 방정식은 매우 복잡하며, 특히 산란 항(Integral term)은 재귀적인 계산을 요구하기 때문에 실시간 렌더링이나 역전파를 통한 학습에는 지나치게 무겁다.2</p>
<h3>2.2  NeRF의 선택: 방출-흡수 모델 (Emission-Absorption Model)</h3>
<p>NeRF는 연산의 효율성과 학습의 안정성을 위해 이 복잡한 물리 모델을 대폭 단순화한 **방출-흡수 모델(Emission-Absorption Model)**을 채택한다.6 이 모델에서는 입자에 의한 빛의 산란(Scattering)을 무시하거나, 혹은 산란 효과를 방출(Emission) 항에 포함하여 근사한다. 즉, 빛이 입자에 부딪히면 흡수되어 사라지거나(Absorption), 입자가 스스로 빛을 뿜어내는(Emission) 두 가지 상호작용만이 존재한다고 가정한다.</p>
<p>이러한 가정 하에, 광선 <span class="math math-inline">\mathbf{r}(t) = \mathbf{o} + t\mathbf{d}</span>를 따라 진행하는 빛의 변화율은 다음과 같은 1계 선형 미분 방정식으로 축약된다.<br />
<span class="math math-display">
\frac{dL(t)}{dt} = -\sigma(t) L(t) + \sigma(t) \mathbf{c}(t)
</span><br />
여기서:</p>
<ul>
<li><span class="math math-inline">\sigma(t)</span>: 위치 <span class="math math-inline">t</span>에서의 부피 밀도(Volume Density). 흡수 계수(Absorption Coefficient)와 소멸 계수(Extinction Coefficient)의 역할을 동시에 수행한다.</li>
<li><span class="math math-inline">\mathbf{c}(t)</span>: 위치 <span class="math math-inline">t</span>에서 방출되는 색상(Radiance).</li>
</ul>
<p>이 단순화는 NeRF가 복잡한 전역 조명(Global Illumination) 효과를 완벽히 시뮬레이션하지 못하게 하는 한계이기도 하지만, 동시에 미분 가능한 렌더링을 가능케 하여 딥러닝과의 결합을 성공시킨 핵심 전략이기도 하다.4</p>
<h2>3.  밀도(Density, <span class="math math-inline">\sigma</span>)와 투과율(Transmittance, <span class="math math-inline">T</span>)의 심층 해석</h2>
<h3>3.1  부피 밀도의 확률론적 정의</h3>
<p>NeRF에서 예측하는 값 <span class="math math-inline">\sigma(\mathbf{x})</span>는 단순한 불투명도가 아니다. 엄밀한 물리적, 확률적 정의는 **“광선이 무한소 구간 <span class="math math-inline">dt</span>를 지날 때 입자와 충돌할 미분 확률(Differential Probability)”**이다.10<br />
<span class="math math-display">
P(\text{hit in } [t, t+dt)) = \sigma(t) dt
</span><br />
이 정의에 따르면 <span class="math math-inline">\sigma</span>의 단위는 거리의 역수(<span class="math math-inline">1/m</span>)가 된다. 따라서 <span class="math math-inline">\sigma</span>는 0 이상의 값을 가지며(<span class="math math-inline">\sigma \ge 0</span>), 그 값의 크기는 해당 공간이 얼마나 빽빽한 입자들로 채워져 있는지를 나타낸다. 예를 들어, 콘크리트 벽 내부라면 <span class="math math-inline">\sigma \to \infty</span>일 것이고, 진공 상태라면 <span class="math math-inline">\sigma = 0</span>이다.12</p>
<h3>3.2  투과율(Transmittance)의 유도: 생존 분석</h3>
<p>투과율 <span class="math math-inline">T(t)</span>는 광선이 원점(<span class="math math-inline">t=0</span>)에서 출발하여 거리 <span class="math math-inline">t</span>까지 진행하는 동안 <strong>어떠한 입자와도 충돌하지 않고 살아남을 확률</strong>로 정의된다. 이를 생존 분석(Survival Analysis)의 관점에서 유도해보자.</p>
<p>광선이 거리 <span class="math math-inline">t</span>까지 생존할 확률을 <span class="math math-inline">T(t)</span>라고 하자. 광선이 <span class="math math-inline">t+dt</span>까지 생존하려면, 다음 두 조건이 독립적으로 만족되어야 한다.</p>
<ol>
<li>거리 <span class="math math-inline">t</span>까지 이미 생존해 있어야 한다 (<span class="math math-inline">T(t)</span>).</li>
<li>구간 <span class="math math-inline">[t, t+dt]</span> 사이에서 입자와 충돌하지 않아야 한다 (<span class="math math-inline">1 - \sigma(t)dt</span>).</li>
</ol>
<p>따라서,<br />
<span class="math math-display">
T(t+dt) = T(t) \cdot (1 - \sigma(t)dt)
</span></p>
<p><span class="math math-display">
\frac{T(t+dt) - T(t)}{dt} = -T(t)\sigma(t)
</span></p>
<p>극한 <span class="math math-inline">dt \to 0</span>을 취하면 다음과 같은 미분 방정식을 얻는다.<br />
<span class="math math-display">
T&#39;(t) = -\sigma(t)T(t)
</span><br />
이 미분 방정식의 해를 구하기 위해 양변을 <span class="math math-inline">T(t)</span>로 나누고 적분한다.<br />
<span class="math math-display">
\int_{0}^{t} \frac{T&#39;(s)}{T(s)} ds = \int_{0}^{t} -\sigma(s) ds
</span></p>
<p><span class="math math-display">
\ln T(t) - \ln T(0) = -\int_{0}^{t} \sigma(s) ds
</span></p>
<p>광선의 시작점에서는 충돌이 없었으므로 <span class="math math-inline">T(0) = 1</span> (즉, <span class="math math-inline">\ln T(0) = 0</span>)이다. 따라서 최종적으로 투과율 공식이 유도된다.<br />
<span class="math math-display">
T(t) = \exp \left( -\int_{t_n}^{t} \sigma(s) ds \right)
</span><br />
이 수식은 **비어-람베르트 법칙(Beer-Lambert Law)**과 정확히 일치한다.5 물리적으로 이 식은 매질을 통과하는 빛의 강도가 매질의 깊이(Optical Depth, <span class="math math-inline">\tau = \int \sigma ds</span>)에 따라 지수적으로 감쇠(Exponential Decay)함을 의미한다.</p>
<h3>3.3  투과율의 성질과 직관</h3>
<p>투과율 <span class="math math-inline">T(t)</span>는 다음과 같은 중요한 성질을 가진다.</p>
<ol>
<li><strong>단조 감소(Monotonically Decreasing):</strong> <span class="math math-inline">\sigma(t) \ge 0</span>이므로, 적분값은 <span class="math math-inline">t</span>가 증가함에 따라 계속 커지고, <span class="math math-inline">T(t)</span>는 1에서 시작하여 0으로 수렴한다. 즉, 광선은 멀리 갈수록 무언가에 가로막힐 확률이 높아진다.</li>
<li><strong>가시성(Visibility):</strong> <span class="math math-inline">T(t)</span>는 카메라에서 거리 <span class="math math-inline">t</span>에 있는 물체가 ’보일 확률’로 해석될 수 있다. 만약 <span class="math math-inline">t</span> 이전에 밀도가 높은 물체(예: 벽)가 있었다면 <span class="math math-inline">\int \sigma ds</span>가 매우 커져서 <span class="math math-inline">T(t) \approx 0</span>이 되고, <span class="math math-inline">t</span> 지점의 물체는 가려져 보이지 않게 된다(Occlusion).</li>
</ol>
<h2>4.  연속적 볼륨 렌더링 방정식 (Continuous Volumetric Rendering Equation)</h2>
<p>이제 미분 방정식의 해를 이용하여, 광선을 따라 들어오는 최종 색상 <span class="math math-inline">C(\mathbf{r})</span>를 적분 형태로 표현할 수 있다.</p>
<h3>4.1  적분 방정식의 구성</h3>
<p>광선이 거리 <span class="math math-inline">t</span>에 있는 미소 구간 <span class="math math-inline">dt</span>에서 얻게 되는 색상은, 그 지점에 입자가 존재해야 하고(충돌), 그 입자가 색을 방출해야 하며, 그 빛이 다시 카메라까지 돌아오는 동안 가려지지 않아야(투과) 한다.<br />
<span class="math math-display">
C(\mathbf{r}) = \int_{t_n}^{t_f} T(t) \sigma(\mathbf{r}(t)) \mathbf{c}(\mathbf{r}(t), \mathbf{d}) dt
</span><br />
이 식은 NeRF의 **성배(Holy Grail)**와 같은 공식이다. 각 항을 분석하면 다음과 같다1:</p>
<ul>
<li><span class="math math-inline">T(t)</span>: 카메라에서 <span class="math math-inline">t</span>까지의 경로가 비어있을 확률 (Visibility).</li>
<li><span class="math math-inline">\sigma(t)dt</span>: <span class="math math-inline">t</span> 지점에서 입자가 존재할 확률 (Opacity density).</li>
<li><span class="math math-inline">\mathbf{c}(t)</span>: 해당 입자가 방출하는 색상 (Radiance).</li>
</ul>
<h3>4.2  확률 밀도 함수(PDF)로서의 해석</h3>
<p>수학적으로 이 식은 기댓값(Expectation)의 형태를 띤다. 여기서 가중치 함수 <span class="math math-inline">w(t) = T(t)\sigma(t)</span>를 주목해야 한다.<br />
<span class="math math-display">
\text{PDF}(t) = T(t)\sigma(t)
</span><br />
이 함수는 **“광선이 정확히 거리 <span class="math math-inline">t</span>에서 처음으로 입자와 충돌하여 멈출 확률 밀도”**를 나타낸다.10</p>
<ul>
<li>
<p><span class="math math-inline">\int_{0}^{\infty} T(t)\sigma(t) dt = 1</span> (완전 불투명한 매질의 경우)</p>
</li>
<li>
<p>따라서 렌더링 된 색상 <span class="math math-inline">C(\mathbf{r})</span>는 광선을 따라 만나는 입자들의 색상 <span class="math math-inline">\mathbf{c}(t)</span>를 충돌 확률 밀도 <span class="math math-inline">T(t)\sigma(t)</span>로 가중 평균한 기댓값이다.<br />
<span class="math math-display">
C(\mathbf{r}) = \mathbb{E}_{t \sim T(t)\sigma(t)} [\mathbf{c}(t)]
</span></p>
</li>
</ul>
<p>이러한 통계적 해석은 NeRF 학습의 본질을 꿰뚫는다. NeRF는 2D 이미지를 보며, 광선상의 어느 지점 <span class="math math-inline">t</span>에서 확률 밀도(PDF)의 피크(Peak)를 세워야 하는지를 학습하는 과정이다. 학습이 잘 된 NeRF 모델에서 PDF는 물체의 표면 위치에서 델타 함수(Delta function)에 가까운 뾰족한 형태를 띠게 된다.</p>
<h3>4.3  불투명도(Opacity)와 누적 분포 함수(CDF)</h3>
<p><span class="math math-inline">1 - T(t)</span>는 광선이 거리 <span class="math math-inline">t</span> 이전에 이미 무언가와 충돌했을 누적 확률(CDF)이다.<br />
<span class="math math-display">
\text{Opacity}(t) = 1 - T(t) = \int_{t_n}^{t} T(s)\sigma(s) ds
</span><br />
이는 렌더링 방정식이 확률 분포의 정의와 완벽하게 부합함을 보여준다. 불투명도는 0(완전 투명)에서 시작하여 1(완전 불투명)로 증가하는 함수이며, 그 미분값이 바로 PDF인 <span class="math math-inline">T(t)\sigma(t)</span>가 되는 것이다.10</p>
<h2>5.  이산화(Discretization)와 수치 구적법(Numerical Quadrature)</h2>
<p>연속적인 적분식은 이론적으로 우아하지만, 디지털 컴퓨터에서 이를 직접 계산하는 것은 불가능하다. 신경망(MLP)은 공간상의 임의의 좌표에 대해 <span class="math math-inline">\sigma</span>와 <span class="math math-inline">\mathbf{c}</span>를 질의(Query)할 수 있지만, 적분 값을 해석적(Analytically)으로 구할 수는 없다. 따라서 우리는 이 적분을 유한한 합(Sum)으로 근사해야 한다. 이 과정을 **구적법(Quadrature)**이라고 한다.16</p>
<h3>5.1  구분적 상수 가정 (Piecewise Constant Assumption)</h3>
<p>NeRF는 광선을 <span class="math math-inline">N</span>개의 구간(Bin)으로 나누고, 각 구간 내에서는 밀도와 색상이 일정하다는 <strong>구분적 상수 가정</strong>을 적용한다. 구간을 <span class="math math-inline">[t_i, t_{i+1}]</span>라 하고, 구간의 길이를 <span class="math math-inline">\delta_i = t_{i+1} - t_i</span>라고 하자.</p>
<p>이 가정 하에서 구간 <span class="math math-inline">i</span> 내의 투과율 적분을 계산해보자.<br />
<span class="math math-display">
\int_{t_i}^{t_{i+1}} \sigma(s) ds \approx \sigma_i \cdot (t_{i+1} - t_i) = \sigma_i \delta_i
</span><br />
이 근사를 통해 연속 적분식은 다음과 같은 이산적 합으로 변환된다.<br />
<span class="math math-display">
\hat{C}(\mathbf{r}) = \sum_{i=1}^{N} \int_{t_i}^{t_{i+1}} T(t) \sigma_i \mathbf{c}_i dt
</span><br />
여기서 <span class="math math-inline">T(t)</span>는 구간 내에서도 계속 감소하므로, 이를 적분 밖으로 빼내지 않고 정확히 계산하면 다음과 같은 결과를 얻는다.<br />
<span class="math math-display">
\int_{t_i}^{t_{i+1}} T(t) \sigma_i dt = T_i \cdot (1 - \exp(-\sigma_i \delta_i))
</span><br />
여기서 <span class="math math-inline">T_i</span>는 <span class="math math-inline">i</span>번째 구간의 시작점까지 도달할 확률이다.</p>
<h3>5.2  알파 컴포지팅(Alpha Compositing) 공식의 유도</h3>
<p>위의 적분 결과에서 나온 <span class="math math-inline">(1 - \exp(-\sigma_i \delta_i))</span> 항은 컴퓨터 그래픽스에서 널리 쓰이는 알파(Alpha, <span class="math math-inline">\alpha</span>) 값과 동일하다.<br />
<span class="math math-display">
\alpha_i = 1 - \exp(-\sigma_i \delta_i)
</span><br />
이 수식은 매우 중요한 물리적 의미와 수치적 안정성을 내포하고 있다.</p>
<ol>
<li><strong>물리적 의미:</strong> <span class="math math-inline">\alpha_i</span>는 해당 구간 <span class="math math-inline">\delta_i</span>를 지나는 동안 빛이 흡수될 확률이다.</li>
<li><strong>값의 범위:</strong> <span class="math math-inline">\sigma_i \ge 0</span>이고 <span class="math math-inline">\delta_i &gt; 0</span>이므로, <span class="math math-inline">\alpha_i</span>는 항상 $ 만약 <span class="math math-inline">\delta_i</span> 항이 없다면, 샘플링 간격에 따라 물체의 투명도가 변하는 심각한 아티팩트가 발생할 것이다.</li>
</ol>
<h3>5.3  최종 이산 렌더링 방정식</h3>
<p>최종적으로 컴퓨터가 계산하는 식은 다음과 같다.<br />
<span class="math math-display">
\hat{C}(\mathbf{r}) = \sum_{i=1}^{N} w_i \mathbf{c}_i
</span><br />
여기서 가중치 <span class="math math-inline">w_i</span>는 다음과 같이 정의된다.<br />
<span class="math math-display">
w_i = T_i \alpha_i = \left( \prod_{j=1}^{i-1} (1 - \alpha_j) \right) \alpha_i
</span><br />
이 식은 “전통적인 알파 블렌딩(Alpha Blending)“을 뒤에서부터가 아니라 앞에서부터(Front-to-back) 누적하는 형태이다.</p>
<ul>
<li><strong><span class="math math-inline">T_i</span> (Transmittance):</strong> <span class="math math-inline">i</span>번째 샘플 앞의 모든 샘플들이 투명해야(<span class="math math-inline">1-\alpha_j \approx 1</span>) 값이 살아남는다.</li>
<li><strong><span class="math math-inline">\alpha_i</span> (Opacity):</strong> <span class="math math-inline">i</span>번째 샘플 자체가 불투명해야(<span class="math math-inline">\alpha_i \approx 1</span>) 값이 기여한다.</li>
</ul>
<p>이 구조는 앞쪽 물체가 뒤쪽 물체를 가리는 <strong>차폐(Occlusion)</strong> 현상을 수학적으로 완벽하게 구현한다. 앞쪽의 <span class="math math-inline">\alpha_1</span>이 1이면, <span class="math math-inline">T_2</span>부터는 모두 0이 되어 뒤쪽의 색상은 렌더링에 전혀 영향을 주지 못한다.</p>
<p><strong>표 5.2.1-A 연속 모델과 이산 모델의 비교</strong></p>
<table><thead><tr><th><strong>구분</strong></th><th><strong>연속 모델 (Theory)</strong></th><th><strong>이산 모델 (Implementation)</strong></th><th><strong>비고</strong></th></tr></thead><tbody>
<tr><td><strong>적분/합</strong></td><td><span class="math math-inline">\int_{t_n}^{t_f} (\dots) dt</span></td><td><span class="math math-inline">\sum_{i=1}^{N} (\dots)</span></td><td>리만 합 근사</td></tr>
<tr><td><strong>밀도</strong></td><td><span class="math math-inline">\sigma(t)</span> (연속 함수)</td><td><span class="math math-inline">\sigma_i</span> (구간 내 상수)</td><td>MLP의 출력값</td></tr>
<tr><td><strong>투과율</strong></td><td><span class="math math-inline">T(t) = \exp(-\int \sigma ds)</span></td><td><span class="math math-inline">T_i = \prod (1-\alpha_j)</span></td><td>누적 곱으로 계산</td></tr>
<tr><td><strong>기여도</strong></td><td><span class="math math-inline">T(t)\sigma(t)dt</span></td><td><span class="math math-inline">w_i = T_i \alpha_i</span></td><td>가중치</td></tr>
<tr><td><strong>역전파</strong></td><td>변분법(Calculus of Variations)</td><td>연쇄 법칙(Chain Rule)</td><td>자동 미분 가능</td></tr>
</tbody></table>
<h2>6.  샘플링 전략: 몬테카를로 적분과 계층적 구조</h2>
<p>볼륨 렌더링 방정식의 품질은 ’어디를 샘플링하느냐’에 전적으로 달려있다. 한정된 샘플 개수(<span class="math math-inline">N</span>)로 적분 오차를 최소화해야 하기 때문이다.</p>
<h3>6.1  균일 샘플링(Uniform Sampling)의 한계와 층화 추출법(Stratified Sampling)</h3>
<p>가장 단순한 방법은 광선을 <span class="math math-inline">N</span>등분하여 일정한 간격으로 샘플링하는 것이다. 그러나 이는 치명적인 문제를 야기한다. 규칙적인 샘플링 패턴은 주파수 영역에서 앨리어싱(Aliasing)을 일으키며, MLP가 샘플링 위치에만 과적합(Overfitting)되어, 샘플 사이의 공간을 제대로 학습하지 못하는 결과를 낳는다.18</p>
<p>이를 해결하기 위해 NeRF는 **층화 추출법(Stratified Sampling)**을 사용한다. 광선을 <span class="math math-inline">N</span>개의 구간(Bin)으로 나누되, 각 구간 내에서 샘플의 위치를 무작위로 흔들어준다(Jittering).<br />
<span class="math math-display">
t_i \sim \mathcal{U} \left[ t_n + \frac{i-1}{N}(t_f - t_n), \quad t_n + \frac{i}{N}(t_f - t_n) \right]
</span></p>
<ul>
<li><strong>학습 시(Training):</strong> 매번 샘플 위치가 달라지므로, 연속적인 공간 전체를 골고루 학습하는 효과(Data Augmentation)를 준다. 무작위성은 앨리어싱(규칙적 패턴)을 노이즈로 변환하며, 이는 딥러닝 모델이 훨씬 다루기 쉬운 형태이다.</li>
<li><strong>추론 시(Inference):</strong> 보통 무작위성을 제거하고 구간의 중점을 사용하여 일관된 이미지를 생성한다.</li>
</ul>
<h3>6.2  계층적 볼륨 샘플링 (Hierarchical Volume Sampling)</h3>
<p>대부분의 공간은 비어있다(Empty Space). 빈 공간을 샘플링하는 것은 계산 자원의 낭비이다. 반면, 물체의 표면 근처는 밀도가 급격히 변하므로 고해상도 샘플링이 필요하다. 이를 위해 NeRF는 <strong>Coarse-to-Fine</strong> 전략을 사용한다.19</p>
<ol>
<li>
<p><strong>Coarse 단계:</strong> 먼저 층화 추출법으로 <span class="math math-inline">N_c</span>개의 점을 드문드문 샘플링하고 ’Coarse 네트워크’를 통해 평가한다.</p>
</li>
<li>
<p>PDF 생성: 계산된 가중치 <span class="math math-inline">w_i</span>를 정규화하여, 광선 위의 확률 밀도 함수(PDF)를 근사한다.<br />
<span class="math math-display">
\hat{w}_i = \frac{w_i}{\sum w_j}
</span><br />
이 PDF는 물체가 있을 확률이 높은 곳에서 높은 값을 가진다.</p>
</li>
<li>
<p><strong>역변환 샘플링(Inverse Transform Sampling):</strong> 이 PDF의 누적 분포 함수(CDF)를 구한 뒤, 역함수법을 사용하여 <span class="math math-inline">N_f</span>개의 새로운 샘플을 추출한다. 이렇게 하면 물체 표면 근처에 샘플들이 집중적으로 배치된다.</p>
</li>
<li>
<p><strong>Fine 단계:</strong> <span class="math math-inline">N_c + N_f</span>개의 모든 샘플을 사용하여 ’Fine 네트워크’를 통해 최종 색상을 계산한다.</p>
</li>
</ol>
<p>이 과정은 일종의 <strong>중요도 샘플링(Importance Sampling)</strong> 기법이다. 몬테카를로 적분 이론에 따르면, 피적분 함수(여기서는 밀도 분포)에 비례하여 샘플을 배치할 때 분산(Variance, 즉 노이즈)이 최소화된다. 계층적 샘플링은 이를 통해 렌더링 품질을 비약적으로 향상시킨다.</p>
<h2>7.  미분 가능성과 최적화 역학 (Optimization Dynamics)</h2>
<p>NeRF의 가장 강력한 특징은 렌더링 과정 전체가 미분 가능하다는 점이다. 이는 우리가 명시적인 3D 데이터를 가지고 있지 않아도, 2D 이미지만으로 3D 모델을 학습할 수 있게 해준다.</p>
<h3>7.1  그래디언트의 흐름 (Gradient Flow)</h3>
<p>손실 함수 <span class="math math-inline">\mathcal{L} = \| \hat{C}(\mathbf{r}) - C_{gt}(\mathbf{r}) \|^2</span>에 대한 그래디언트는 연쇄 법칙(Chain Rule)을 통해 MLP의 파라미터 <span class="math math-inline">\theta</span>까지 역전파된다.11<br />
<span class="math math-display">
\frac{\partial \mathcal{L}}{\partial \theta} = \sum_{i} \frac{\partial \mathcal{L}}{\partial \hat{C}} \frac{\partial \hat{C}}{\partial w_i} \frac{\partial w_i}{\partial (\sigma_i, \mathbf{c}_i)} \frac{\partial (\sigma_i, \mathbf{c}_i)}{\partial \theta}
</span><br />
이 식의 의미를 직관적으로 해석하면 다음과 같다:</p>
<ul>
<li><strong>색상 오류 수정:</strong> 만약 렌더링 된 픽셀 색상이 정답과 다르다면, <span class="math math-inline">w_i</span>가 큰(즉, 표면으로 간주된) 샘플의 색상 <span class="math math-inline">\mathbf{c}_i</span>를 수정하는 방향으로 그래디언트가 강하게 흐른다.</li>
<li><strong>기하 구조 수정:</strong> 만약 빈 공간이어야 할 곳에 물체가 있다고 예측했다면(Ghost Geometry), <span class="math math-inline">\sigma_i</span>를 낮춰 <span class="math math-inline">\alpha_i</span>와 <span class="math math-inline">w_i</span>를 0으로 만드는 방향으로 학습된다. 반대의 경우 <span class="math math-inline">\sigma_i</span>를 높인다.</li>
<li><strong>Occlusion 처리:</strong> 앞쪽 샘플의 <span class="math math-inline">\sigma</span>가 커지면 <span class="math math-inline">T</span>가 감소하여 뒤쪽 샘플의 그래디언트가 차단된다. 이는 네트워크가 “앞에 있는 물체가 뒤를 가린다“는 사실을 학습하게 한다.</li>
</ul>
<h3>7.2  불확실성과 스케일 모호성 (Scale Ambiguity)</h3>
<p>렌더링 방정식의 이산화 과정에서 <span class="math math-inline">\delta_i</span> 항은 스케일 모호성을 해결하는 열쇠이다. 장면 전체를 <span class="math math-inline">k</span>배 확대하면 <span class="math math-inline">\delta_i</span>도 <span class="math math-inline">k</span>배 늘어난다. 물리적으로 동일한 불투명도를 유지하려면 밀도 <span class="math math-inline">\sigma</span>는 <span class="math math-inline">1/k</span>로 줄어들어야 한다(<span class="math math-inline">\sigma \propto 1/\text{distance}</span>). NeRF 모델은 학습 데이터의 스케일에 맞춰 이러한 <span class="math math-inline">\sigma</span>의 크기를 자동으로 조정하여 학습한다.13 만약 <span class="math math-inline">\delta_i</span>를 고려하지 않고 단순히 <span class="math math-inline">\sigma</span>의 합으로만 렌더링했다면, 카메라가 물체에 가까이 다가갈 때 물체가 투명해지거나 짙어지는 비현실적인 현상이 발생했을 것이다.</p>
<h3>7.3  불안정성과 규제 (Regularization)</h3>
<p>볼륨 렌더링은 본질적으로 모호성(Ambiguity)을 가진다. 동일한 이미지를 만들어내는 3D 형상은 무수히 많을 수 있다(예: 얇은 반투명 막들의 중첩 vs 하나의 단단한 표면). NeRF 학습 초기에는 공간 전체에 희미한 안개(Fog)가 낀 것 같은 현상이 발생하다가, 학습이 진행될수록 밀도가 표면으로 응집된다. 때로는 카메라 바로 앞에 시야를 가리는 ’부유물(Floaters)’이 생성되기도 하는데, 이를 억제하기 위해 밀도 <span class="math math-inline">\sigma</span>의 희소성(Sparsity)을 강제하는 정규화(Regularization) 항을 손실 함수에 추가하기도 한다.</p>
<h2>8.  결론: 방정식이 여는 미래</h2>
<p>5.2.1절에서 우리는 NeRF의 핵심 엔진인 <strong>볼륨 렌더링 방정식</strong>을 샅샅이 분해해보았다.</p>
<ul>
<li><strong>기원:</strong> 이 방정식은 빛의 물리적 거동을 기술하는 복사 전달 방정식의 간소화된 형태(<span class="math math-inline">T&#39; = -T\sigma</span>)에서 출발했다.</li>
<li><strong>의미:</strong> 수학적으로는 조건부 확률 밀도(PDF)에 기반한 기댓값 연산이며, 물리적으로는 매질 내 입자들의 가시성(Visibility)과 불투명도(Opacity)의 상호작용이다.</li>
<li><strong>구현:</strong> 연속 적분은 구분적 상수 가정과 구적법을 통해 이산적인 합(<span class="math math-inline">\sum w_i \mathbf{c}_i</span>)으로 변환되며, 이 과정에서 알파(<span class="math math-inline">\alpha = 1 - e^{-\sigma \delta}</span>)가 자연스럽게 유도된다.</li>
<li><strong>학습:</strong> 미분 가능한 구조 덕분에 2D 이미지의 오차를 역전파하여 3D 공간의 밀도와 색상을 스스로 최적화할 수 있다.</li>
</ul>
<p>이 방정식은 단순해 보이지만, 그 안에는 3차원 비전의 패러다임을 바꾼 통찰이 담겨 있다. 딱딱한 표면의 제약에서 벗어나, 세상을 연속적인 밀도 필드로 표현함으로써 우리는 머리카락, 연기, 투명체 등 기존에 표현하기 힘들었던 복잡한 장면들을 신경망 안에 담을 수 있게 되었다. 다음 절에서는 이 방정식을 더욱 효율적으로 계산하기 위한 자료 구조(Octree, Hash Grid)와, 렌더링 속도를 가속화하기 위한 최신 연구들에 대해 논의할 것이다.</p>
<p><strong>표 5.2.1-B 핵심 용어 요약</strong></p>
<table><thead><tr><th><strong>용어 (Terms)</strong></th><th><strong>기호</strong></th><th><strong>정의 및 역할</strong></th></tr></thead><tbody>
<tr><td><strong>부피 밀도 (Volume Density)</strong></td><td><span class="math math-inline">\sigma(t)</span></td><td>공간의 불투명도 정도. 입자와의 충돌 확률 밀도. (<span class="math math-inline">1/m</span>)</td></tr>
<tr><td><strong>투과율 (Transmittance)</strong></td><td><span class="math math-inline">T(t)</span></td><td>빛이 거리 <span class="math math-inline">t</span>까지 도달할 확률. 지수적 감쇠. (<span class="math math-inline">0 \sim 1</span>)</td></tr>
<tr><td><strong>알파 (Alpha)</strong></td><td><span class="math math-inline">\alpha_i</span></td><td>이산 구간 <span class="math math-inline">\delta_i</span> 내에서의 불투명도. (<span class="math math-inline">1 - e^{-\sigma \delta}</span>)</td></tr>
<tr><td><strong>구분적 상수 가정</strong></td><td>-</td><td>미소 구간 내에서 밀도와 색상이 일정하다고 가정하는 근사법.</td></tr>
<tr><td><strong>층화 추출법 (Stratified Sampling)</strong></td><td>-</td><td>구간 내에서 무작위 위치를 샘플링하여 앨리어싱을 방지하는 기법.</td></tr>
<tr><td><strong>계층적 샘플링 (Hierarchical)</strong></td><td>-</td><td>Coarse 네트워크로 PDF를 만들고 Fine 네트워크로 중요 지점을 재샘플링.</td></tr>
</tbody></table>
<h2>9. 참고 자료</h2>
<ol>
<li>Neural radiance field - Wikipedia, https://en.wikipedia.org/wiki/Neural_radiance_field</li>
<li>Neural Radiance Fields (NeRFs) - Cornell: Computer Science, https://www.cs.cornell.edu/courses/cs5670/2022sp/lectures/lec22_nerf_for_web.pdf</li>
<li>Lecture: Neural Fields Part 2 - UNC Computer Science, https://www.cs.unc.edu/~ronisen/teaching/fall_2022/pdf_lectures/lecture10_NF_2.pdf</li>
<li>Transferable Generative Models - UC Berkeley EECS, https://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-161.pdf</li>
<li>[2510.22161] I2-NeRF: Learning Neural Radiance Fields Under Physically-Grounded Media Interactions - arXiv, https://arxiv.org/abs/2510.22161</li>
<li>Neural Radiance Fields for the Real World: A Survey - arXiv, https://arxiv.org/html/2501.13104v1</li>
<li>Shyam-pi/Volume-Rendering-and-Neural-Radiance-Fields - GitHub, https://github.com/Shyam-pi/Volume-Rendering-and-Neural-Radiance-Fields</li>
<li>“I“²-NeRF: Learning Neural Radiance Fields Under Physically-Grounded Media Interactions, https://arxiv.org/html/2510.22161v1</li>
<li>NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis, https://cseweb.ucsd.edu/~viscomp/classes/cse274/fa21/papers/srinivasan-cvpr21.pdf</li>
<li>Volume Rendering Digest (for NeRF), https://www.cs.unc.edu/~ronisen/teaching/fall_2022/pdf_lectures/volume_rendering_nerf.pdf</li>
<li>Dynamic scene representation in the era of neural rendering: from NeRFs to 3DGSs - Hep Journals, https://journal.hep.com.cn/fcs/EN/10.1007/s11704-025-50389-x</li>
<li>A Beginner’s 12-Step Visual Guide to Understanding NeRF: Neural Radiance Fields for Scene Representation and View Synthesis | by Aqeel Anwar - Medium, https://medium.com/data-science/a-12-step-visual-guide-to-understanding-nerf-representing-scenes-as-neural-radiance-fields-24a36aef909a</li>
<li>Alpha Invariance: On Inverse Scaling Between Distance and Volume Density in Neural Radiance Fields - arXiv, https://arxiv.org/html/2404.02155v1</li>
<li>Data Augmentation for Deep-learning-based Eye-tracking using Neural Radiance Fields - Diva-portal.org, http://www.diva-portal.org/smash/get/diva2:1946053/FULLTEXT01.pdf</li>
<li>45 Radiance Fields - Foundations of Computer Vision - MIT, https://visionbook.mit.edu/nerf.html</li>
<li>NeRF Revisited: Fixing Quadrature Instability in Volume Rendering - NeurIPS, https://proceedings.neurips.cc/paper_files/paper/2023/file/5301c49207917c5c870131959971851c-Paper-Conference.pdf</li>
<li>NeRF: A Volume Rendering Perspective | Yue Yu, https://yconquesty.github.io/blog/ml/nerf/nerf_rendering.html</li>
<li>NeRF: Neural Radiance Field in 3D Vision: A Comprehensive Review - arXiv, https://arxiv.org/html/2210.00379v6</li>
<li>NeRF - Neural Radiance Fields (review) - Apoorve Singhal, https://www.apoorvesinghal.com/blog/nerf/</li>
<li>NeRF - nerfstudio, https://docs.nerf.studio/nerfology/methods/nerf.html</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>