<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:Chapter 2. 제어 이론의 역사와 소프트웨어 2.0</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>Chapter 2. 제어 이론의 역사와 소프트웨어 2.0</h1>
                    <nav class="breadcrumbs"><a href="../../../index.html">Home</a> / <a href="../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../index.html">제목: Embodied AI & Modern Control</a> / <a href="index.html">Chapter 2. 제어 이론의 역사와 소프트웨어 2.0</a> / <span>Chapter 2. 제어 이론의 역사와 소프트웨어 2.0</span></nav>
                </div>
            </header>
            <article>
                <h1>Chapter 2. 제어 이론의 역사와 소프트웨어 2.0</h1>
<h2>1.  서론: 결정론적 세계에서 확률론적 학습으로</h2>
<p>로봇 공학과 자동화 기술의 역사는 ’불확실성(Uncertainty)’과의 투쟁으로 정의될 수 있다. 인류는 기계가 의도한 대로 정확하게 움직이기를 갈망해 왔으며, 이를 위해 수세기 동안 정교한 수학적 모델과 물리 법칙을 동원하여 시스템을 통제하려 노력했다. 우리는 이것을 제어 이론(Control Theory)이라 부르며, 이 학문은 산업 혁명 이후 기계 문명을 지탱하는 중추적인 역할을 수행해 왔다. 고전적인 제어 이론은 시스템의 역학(Dynamics)을 완벽하게 기술할 수 있다는 전제 하에, 미분 방정식이라는 언어를 통해 입력과 출력의 관계를 규명하는 ‘결정론적(Deterministic)’ 세계관을 대변한다. 이것이 바로 우리가 ’소프트웨어 1.0(Software 1.0)’이라 부르는, 인간이 명시적인 규칙과 논리를 코드로 작성하여 기계에 주입하는 방식의 정점이다.1</p>
<p>그러나 21세기에 접어들어 컴퓨팅 파워의 비약적인 발전과 데이터의 폭발적인 증가는 새로운 패러다임을 요구하기 시작했다. 로봇이 공장이라는 통제된 환경을 벗어나 일상 공간과 같은 비정형 환경(Unstructured Environment)으로 진출함에 따라, 모든 물리적 상호작용을 수식으로 모델링하는 것이 불가능에 가까워졌기 때문이다.2 이때 등장한 딥러닝(Deep Learning)과 인공지능은 제어의 문제를 ’모델링’이 아닌 ’최적화(Optimization)’의 관점에서 재해석하는 계기를 마련했다. 안드레이 카패시(Andrej Karpathy)가 제창한 ’소프트웨어 2.0(Software 2.0)’은 인간이 코드를 작성하는 대신, 원하는 동작(목표)과 데이터(경험)를 제공하면 최적화 알고리즘이 스스로 코드를 찾아내는 새로운 프로그래밍 방식을 의미한다.1</p>
<p>본 장에서는 로봇 제어 기술의 진화 과정을 역사적 맥락에서 조망하고, 고전 제어 이론이 직면한 한계와 이를 극복하기 위한 데이터 기반 접근법의 등장을 심층적으로 분석한다. 특히, 소프트웨어 1.0에서 소프트웨어 2.0으로의 전환이 단순한 기술적 대체가 아니라, 로봇 시스템을 설계하고 구현하는 철학적 기반의 이동임을 논증하며, 딥러닝 기반의 시각-운동 제어(Visuomotor Control)와 미분 가능한 물리학(Differentiable Physics) 등 최신 연구 동향을 통해 로봇 공학의 미래를 가늠해 보고자 한다.</p>
<h2>2.  소프트웨어 1.0의 시대: 고전 제어 이론의 유산과 한계</h2>
<p>소프트웨어 1.0, 즉 고전적인 프로그래밍 패러다임에서 로봇 제어는 ‘모델 기반(Model-Based)’ 접근 방식을 따른다. 엔지니어는 로봇의 기구학적 구조, 링크의 질량, 관성 모멘트, 마찰 계수 등을 측정하여 운동 방정식을 수립하고, 이를 바탕으로 원하는 궤적을 추종하도록 모터의 토크를 계산하는 제어기를 설계한다. 이 과정은 물리학에 대한 깊은 이해와 엄밀한 수학적 분석을 요구하며, 시스템이 모델과 일치할 때 완벽한 성능을 보장한다.</p>
<h3>2.1  제어 이론의 태동과 고전 제어(Classical Control)의 정립</h3>
<p>제어 이론의 기원은 산업 혁명기의 증기 기관 조속기(Governor)로 거슬러 올라가지만, 체계적인 이론으로 정립된 것은 20세기 초반이다. 제임스 클러크 맥스웰(James Clerk Maxwell)과 에드워드 라우스(Edward Routh) 등은 미분 방정식을 통해 시스템의 안정성(Stability)을 해석하는 기틀을 마련했다.5 이후 1920년대 니콜라스 미노르스키(Nicolas Minorsky)에 의해 체계화된 PID(Proportional-Integral-Derivative) 제어는 피드백(Feedback) 제어의 효시가 되었다.5</p>
<p>PID 제어는 현재 오차(비례), 과거 오차의 누적(적분), 그리고 오차의 변화율(미분)을 결합하여 제어 입력을 생성한다.</p>
<ul>
<li><strong>비례항(P):</strong> 현재의 오차를 줄이는 방향으로 즉각적인 반응을 유도한다.</li>
<li><strong>적분항(I):</strong> 시스템의 잔류 편차(Steady-state Error)를 제거하여 정확도를 높인다.</li>
<li><strong>미분항(D):</strong> 오차의 변화 속도를 감지하여 오버슈트(Overshoot)를 억제하고 시스템의 안정성을 확보한다.</li>
</ul>
<p>이 시기의 제어 이론, 즉 ’고전 제어(Classical Control)’는 주로 주파수 영역(Frequency Domain)에서 시스템을 해석했다. 라플라스 변환(Laplace Transform)을 이용해 시간 영역의 미분 방정식을 주파수 영역의 대수 방정식으로 변환하고, 전달 함수(Transfer Function)를 통해 입력과 출력의 관계를 분석했다.7 보드 선도(Bode Plot)나 나이퀴스트 판별법(Nyquist Criterion)과 같은 도구들은 엔지니어가 시스템의 안정 여부를 직관적으로 판단하게 해주었다. 하지만 고전 제어는 주로 단일 입력-단일 출력(SISO) 선형 시불변 시스템(LTI)에 국한되어 있었으며, 로봇 팔과 같이 여러 관절이 서로 복잡하게 상호작용하는 다변수(MIMO) 비선형 시스템을 다루기에는 한계가 있었다.7</p>
<h3>2.2  현대 제어(Modern Control)와 상태 공간 해석</h3>
<p>1950년대 후반, 우주 개발 경쟁과 함께 더욱 정밀하고 복잡한 시스템 제어의 필요성이 대두되면서 ‘현대 제어(Modern Control)’ 이론이 등장했다. 현대 제어는 주파수 영역 대신 시간 영역(Time Domain)에서 시스템을 직접 해석하며, ‘상태 공간(State-Space)’ 모델을 핵심 도구로 사용한다.6</p>
<p>상태 공간 모델은 시스템의 동적 거동을 1차 미분 방정식의 집합으로 표현한다. 로봇 공학에서 이는 로봇의 관절 각도와 각속도 등을 상태 변수(State Variable)로 정의하고, 이들의 변화를 행렬 연산으로 기술하는 방식이다. 이를 통해 다입력-다출력(MIMO) 시스템을 체계적으로 다룰 수 있게 되었으며, 칼만 필터(Kalman Filter)와 같은 상태 추정 기법과 결합하여 센서 잡음이 있는 환경에서도 정확한 제어가 가능해졌다.9</p>
<p>특히 로봇 매니퓰레이터 제어에 널리 사용되는 **계산 토크 제어(Computed Torque Control)**는 현대 제어 이론의 정수를 보여준다. 이는 로봇의 비선형 동역학 모델(질량, 코리올리 힘, 중력 등)을 역으로 계산하여 상쇄시킴으로써, 복잡한 로봇 시스템을 마치 단순한 선형 시스템인 것처럼 거동하게 만드는 기법이다.3 이론적으로 모델이 완벽하다면 계산 토크 제어는 어떠한 궤적이라도 오차 없이 추종할 수 있다.</p>
<h3>2.3  강건 제어(Robust Control)와 적응 제어(Adaptive Control)의 고군분투</h3>
<p>그러나 “모든 모델은 틀렸다. 다만 일부가 유용할 뿐이다“라는 조지 박스(George Box)의 격언처럼, 실제 물리 세계를 완벽하게 기술하는 모델은 존재하지 않는다. 마찰, 마모, 센서 노이즈, 예측 불가능한 외란(Disturbance) 등은 언제나 ’모델링 오차(Modeling Error)’를 유발한다.10</p>
<p>이를 극복하기 위해 제어 이론은 더욱 정교해졌다.</p>
<ul>
<li><strong>강건 제어(Robust Control):</strong> 모델링 오차나 외란이 존재하더라도 시스템이 불안정해지지 않도록, 최악의 상황(Worst Case)을 가정하여 제어기를 설계한다. H-infinity 제어 등이 대표적이며, 불확실성의 범위를 수학적으로 규정하고 그 안에서 성능을 보장하려 한다.12</li>
<li><strong>적응 제어(Adaptive Control):</strong> 시스템의 파라미터가 변하거나(예: 로봇이 무거운 물체를 들어 질량이 변함) 알 수 없을 때, 실시간으로 파라미터를 추정하고 제어 법칙을 수정한다.12 이는 로봇이 미지의 물체를 조작해야 할 때 필수적인 기술로 여겨졌다.</li>
</ul>
<p>이러한 노력에도 불구하고, 소프트웨어 1.0 방식은 근본적인 장벽에 부딪혔다. 바로 ’비정형 환경’과 ’고차원 데이터’의 문제다.</p>
<h3>2.4  소프트웨어 1.0의 한계: 접촉이 풍부한(Contact-Rich) 환경과 차원의 저주</h3>
<p>고전 제어 이론이 가장 취약한 지점은 로봇이 환경과 물리적으로 복잡하게 접촉해야 하는 ‘접촉이 풍부한(Contact-Rich)’ 작업이다.3</p>
<ol>
<li><strong>모델링의 불가능성 (The Impossibility of Modeling):</strong> 허공에서 로봇 팔을 휘두르는 것은 비교적 정확하게 모델링할 수 있다. 하지만 로봇 손이 주머니 속의 열쇠를 더듬어 찾거나, 뻑뻑한 뚜껑을 돌려 따거나, 쌀이 가득 찬 유연한 봉지를 집어 드는 상황을 생각해 보자.15 이때 발생하는 마찰, 변형, 미끄러짐, 충돌 등은 고도의 비선형성과 불연속성을 가진다. 이를 미분 방정식으로 표현하려면 수천 개의 변수와 미지의 파라미터가 필요하며, 사실상 실시간 연산이 불가능한 수준의 복잡도를 가진다.17</li>
<li><strong>부드럽지 않은 역학(Non-smooth Dynamics):</strong> 접촉은 본질적으로 불연속적인 현상이다. 물체와 닿기 전에는 힘이 0이었다가, 닿는 순간 급격히 증가한다. 이러한 불연속성은 미분 가능성(Differentiability)을 전제로 하는 많은 최적 제어 알고리즘(Gradient-based Optimization)을 무력화시킨다. 국소적인 기울기(Gradient) 정보가 전역적인 해결책을 제시하지 못하거나, 최적화 과정이 국소 최솟값(Local Minima)에 빠지게 만든다.17</li>
<li><strong>인지와 제어의 분리 (Separation of Perception and Control):</strong> 전통적인 로봇 소프트웨어 스택은 ’인지(Perception) -&gt; 계획(Planning) -&gt; 제어(Control)’의 모듈식 파이프라인으로 구성된다.20 비전 시스템이 카메라 이미지를 처리하여 “컵의 위치: (x, y, z)“라는 상태(State)를 추출하면, 계획 모듈이 경로를 생성하고, 제어 모듈이 이를 실행한다. 이 방식의 문제는 인지 모듈의 사소한 오차가 제어 단계로 전파되어 증폭된다는 점이다. 비전 시스템이 컵의 위치를 1cm만 잘못 추정해도, 제어기는 엉뚱한 허공을 잡거나 컵을 쳐서 넘어뜨리게 된다. 소프트웨어 1.0에서는 인지 모듈이 제어의 결과로부터 피드백을 받아 스스로를 수정하는 메커니즘이 부재하다.2</li>
</ol>
<p>이러한 한계는 로봇 공학자들에게 “모델을 더 정교하게 만들 것인가, 아니면 모델링 자체를 포기할 것인가?“라는 근원적인 질문을 던졌다. 그리고 딥러닝의 등장은 후자, 즉 데이터와 학습을 통한 해결책에 힘을 실어주었다.</p>
<h2>3.  소프트웨어 2.0: 최적화를 통한 프로그래밍의 재정의</h2>
<p>2017년, 당시 테슬라의 AI 디렉터였던 안드레이 카패시는 “Software 2.0“이라는 도발적인 에세이를 통해 프로그래밍의 역사가 새로운 장으로 넘어갔음을 선언했다.1 그는 딥러닝을 단순한 알고리즘의 일종이 아니라, 인간이 컴퓨터에게 명령을 내리는 방식 자체가 변화한 것으로 해석했다.</p>
<h3>3.1  소프트웨어 2.0의 정의와 철학</h3>
<p>소프트웨어 2.0은 **“평가 기준(Evaluation Criterion)에 기반한 최적화(Optimization)를 통해 작성된 코드”**로 정의된다.4</p>
<ul>
<li><strong>소프트웨어 1.0:</strong> 프로그래머가 문제 해결을 위한 논리적 절차(알고리즘)를 C++, Python 등의 언어로 명시적으로 작성한다. 이는 프로그래머의 머릿속에 있는 지식을 코드로 옮기는 과정이다 (Explicit Programming).</li>
<li><strong>소프트웨어 2.0:</strong> 프로그래머는 ’목표(Goal)’와 ’데이터(Data)’를 정의한다. 그리고 신경망(Neural Network)이라는 유연한 구조 안에서, 최적화 알고리즘(예: 경사 하강법, Stochastic Gradient Descent)이 목표를 달성하는 데 필요한 세부적인 연산(가중치, Weights)을 스스로 찾아내도록 한다. 이는 데이터에 내재된 패턴을 통해 프로그램이 스스로 작성되는 과정이다 (Implicit Programming).1</li>
</ul>
<p>카패시는 이를 “프로그램 공간(Program Space)에서의 탐색“으로 비유했다. 소프트웨어 1.0은 인간이 가능한 모든 프로그램의 공간에서 ’좋은 프로그램’이라고 생각되는 하나의 점을 찾아 직접 찍는 행위라면, 소프트웨어 2.0은 경사 하강법이라는 강력한 탐색 도구를 이용해 프로그램 공간을 미끄러져 내려가며 최적의 지점을 자동으로 찾아가는 과정이다.22</p>
<h3>3.2  소프트웨어 2.0의 기술적 특성과 이점</h3>
<p>소프트웨어 2.0은 기존 소프트웨어와는 질적으로 다른 특성을 가진다. 이러한 특성은 특히 로봇 제어와 같은 실시간, 고성능 컴퓨팅 환경에서 중요한 시사점을 가진다.23</p>
<ol>
<li><strong>균일한 계산 구조 (Computationally Homogeneous):</strong> 소프트웨어 1.0 코드는 복잡한 분기문(if-else), 루프, 객체 호출 등으로 뒤엉켜 있어 하드웨어 최적화가 어렵다. 반면, 소프트웨어 2.0(신경망)은 근본적으로 ’행렬 곱셈(Matrix Multiplication)’과 ’활성 함수(ReLU 등)’라는 두 가지 연산의 무한 반복으로 구성된다. 이는 실리콘 칩 설계에 혁명을 가져왔다. 구글의 TPU나 테슬라의 도조(Dojo) 칩과 같은 AI 가속기(ASIC)는 오직 이 단순한 연산만을 극한으로 빠르게 처리하도록 설계되었으며, 이는 소프트웨어 1.0이 누릴 수 없는 하드웨어 효율성을 제공한다.24</li>
<li><strong>일정한 실행 시간 (Constant Running Time):</strong> 로봇 제어에서 실시간성(Real-time Constraints)은 생명과도 같다. 복잡한 C++ 코드는 입력 조건에 따라 실행 경로가 달라져 연산 시간이 들쭉날쭉할 수 있다. 그러나 신경망의 순전파(Forward Pass) 연산량은 입력 데이터의 값과 무관하게 항상 일정하다. 이는 제어 주기를 예측 가능하게 만들고 시스템 안정성을 높인다.24</li>
<li><strong>유연한 성능 트레이드오프 (Agile Performance Trade-off):</strong> 소프트웨어 1.0에서 프로그램의 실행 속도를 2배 높이려면 코드를 갈아엎는 수준의 최적화가 필요하다. 하지만 소프트웨어 2.0에서는 신경망의 채널 수를 줄이거나 층을 얕게 만든 뒤 재학습시키면, 정확도를 약간 희생하는 대신 속도를 즉시 높일 수 있다. 반대로 컴퓨팅 자원이 늘어나면 모델 크기를 키워 성능을 높일 수 있다. 이러한 확장성(Scalability)은 소프트웨어 2.0의 가장 강력한 무기 중 하나다.23</li>
</ol>
<h3>3.3  프로그래머의 역할 변화: 코딩에서 큐레이션으로</h3>
<p>소프트웨어 2.0 시대의 프로그래머는 더 이상 복잡한 알고리즘을 짜느라 밤을 새우지 않는다. 대신 그들은 **‘데이터 큐레이터(Data Curator)’**가 된다.1</p>
<ul>
<li><strong>데이터셋 관리:</strong> 좋은 데이터가 좋은 프로그램을 만든다. 프로그래머는 데이터를 수집하고, 라벨링하고, 노이즈를 제거하고, 데이터의 불균형을 해소하는 데 주력한다.</li>
<li><strong>아키텍처 설계:</strong> 어떤 신경망 구조가 문제 해결에 적합한지(CNN, Transformer, RNN 등)를 결정하고 실험한다.</li>
<li><strong>평가 지표 설정:</strong> 최적화 알고리즘이 나아갈 방향(Loss Function)을 정의한다.</li>
</ul>
<p>카패시는 이를 “소스 코드는 데이터이고, 컴파일러는 학습 알고리즘(Optimizer)인 시대“라고 표현했다. 깃허브(GitHub)에 코드를 올리는 대신, 대규모 데이터셋 저장소를 관리하고 모델 가중치(Weights)를 버전 관리하는 것이 새로운 개발 표준이 되고 있다.26</p>
<h2>4.  딥러닝 기반 제어의 진화: 픽셀에서 토크까지</h2>
<p>소프트웨어 2.0 철학이 로봇 제어 분야에 구체적으로 구현되기 시작한 것은 심층 강화학습(Deep Reinforcement Learning, DRL)과 시각-운동 정책(Visuomotor Policy) 연구가 본격화된 2010년대 중반부터이다. 이 시기의 연구들은 로봇이 세상을 ‘보고’ ’이해’하고 ’행동’하는 방식을 근본적으로 통합시켰다.</p>
<h3>4.1  심층 강화학습(Deep RL)과 연속 제어의 돌파구</h3>
<p>2015년, 딥마인드(DeepMind)가 발표한 DQN(Deep Q-Network)은 아타리 게임을 인간보다 잘 플레이하며 충격을 주었지만, 이산적인 행동(조이스틱의 상하좌우)만을 다룰 수 있어 로봇 제어(모터의 연속적인 힘 조절)에는 직접 적용하기 어려웠다.</p>
<p>이 장벽을 허문 것이 릴리크랩(Lillicrap) 등이 2015년 제안한 DDPG(Deep Deterministic Policy Gradient) 알고리즘이다.27 DDPG는 행위자-비평가(Actor-Critic) 구조를 도입하여, 연속적인 공간(Continuous Action Space)에서 최적의 행동을 출력하는 정책 신경망(Actor)과 그 행동의 가치를 평가하는 가치 신경망(Critic)을 동시에 학습시켰다. 이는 딥러닝이 로봇의 관절 토크나 속도와 같은 아날로그적인 물리량을 직접 제어할 수 있음을 증명한 기념비적인 연구였다.29</p>
<p>이후 DRL은 더욱 정교해졌다. TD3(Twin Delayed DDPG)는 학습의 불안정성을 개선했고, **SAC(Soft Actor-Critic)**는 엔트로피(Entropy) 최대화 개념을 도입하여 로봇이 불확실한 상황에서도 더 강건하고 다양한 시도를 통해 최적의 해를 찾도록 유도했다.30 이러한 알고리즘들은 모델에 대한 사전 지식 없이도(Model-free), 로봇이 시행착오를 통해 걷거나 물체를 조작하는 법을 스스로 깨우칠 수 있게 만들었다.</p>
<h3>4.2  End-to-End 시각-운동 제어 (Visuomotor Policies)</h3>
<p>강화학습이 ’제어’를 학습했다면, 이를 ’인지’와 결합하여 진정한 소프트웨어 2.0 파이프라인을 완성한 것은 세르게이 레빈(Sergey Levine) 등의 연구였다. 2016년 발표된 <strong>“End-to-End Training of Deep Visuomotor Policies”</strong> 논문은 로봇 공학의 성배와도 같았던 ’인지와 제어의 통합’을 실현했다.21</p>
<p>기존에는 카메라 영상에서 물체의 위치를 파악하는 비전 알고리즘과, 그 위치로 팔을 뻗는 제어 알고리즘이 별개로 존재했다. 레빈의 연구팀은 이를 하나의 거대한 신경망(CNN)으로 통합했다.</p>
<ul>
<li><strong>입력:</strong> 로봇 카메라의 원시 이미지(Raw Pixels)와 로봇 팔의 현재 상태(Joint Angles).</li>
<li><strong>출력:</strong> 로봇 모터에 가할 토크(Torques).</li>
<li><strong>학습 방법:</strong> 유도된 정책 탐색(Guided Policy Search, GPS).32 이는 궤적 최적화(Trajectory Optimization)를 통해 생성된 ‘교사’ 데이터를 지도 학습(Supervised Learning) 방식으로 신경망이 모방하게 하는 기법이다.</li>
</ul>
<p>이 연구에서 로봇은 병뚜껑 닫기, 블록 맞추기, 옷걸이 걸기와 같은 정교한 작업을 수행했다. 놀라운 점은, 연구자들이 로봇에게 “병뚜껑은 동그랗다“거나 “옷걸이는 세모다“라는 특징을 전혀 알려주지 않았다는 것이다. 신경망은 오직 성공적인 동작을 수행하기 위해 이미지상의 어떤 패턴이 중요한지를 스스로 학습했다. 이는 소프트웨어 1.0 방식이 놓치기 쉬운 미세한 시각적 단서까지 활용하여, 기존 방식보다 월등히 높은 성공률을 보여주었다.21</p>
<h3>4.3  공간 오토인코더(Spatial Autoencoders): 스스로 상태를 정의하다</h3>
<p>첼시 핀(Chelsea Finn) 등은 2016년 심층 공간 오토인코더(Deep Spatial Autoencoders) 연구를 통해, 로봇이 이미지로부터 ’상태(State)’를 정의하는 방법론을 제안했다.35</p>
<p>전통적인 제어에서는 엔지니어가 “컵의 중심 좌표 (x, y)“와 같이 상태를 정의해 주어야 했다. 하지만 비정형 물체(예: 구겨진 천, 액체)는 중심 좌표 하나로 상태를 정의할 수 없다. 공간 오토인코더는 로봇이 카메라 이미지를 압축하고 복원하는 과정에서, 물체의 변화를 가장 잘 설명하는 특징점(Feature Points)들을 스스로 찾아내도록 학습시킨다. 이렇게 학습된 특징점들은 사람이 정의한 좌표보다 훨씬 풍부한 정보를 담고 있어, 강화학습의 효율을 극대화했다. 이는 데이터로부터 문제의 구조를 발견하는 소프트웨어 2.0의 철학이 상태 추정(State Estimation) 단계까지 확장된 사례이다.</p>
<h2>5.  데이터 엔진과 시뮬레이션: 소프트웨어 2.0의 연료</h2>
<p>소프트웨어 2.0의 성능은 코드의 품질이 아닌 ’데이터의 양과 질’에 비례한다. 그러나 로봇 공학에서 데이터를 얻는 것은 매우 비싸다. 로봇을 실제로 움직여 데이터를 모으는 것은 시간이 오래 걸리고, 장비 파손의 위험이 있으며, 무엇보다 수집할 수 있는 데이터의 양에 물리적 한계가 있다. 이 문제를 해결하기 위해 시뮬레이션 기술, 특히 **‘미분 가능한 물리학(Differentiable Physics)’**이 핵심 기술로 부상했다.</p>
<h3>5.1  미분 가능한 물리학(Differentiable Physics) vs 강화학습(RL)</h3>
<p>기존의 물리 엔진(MuJoCo, Bullet 등)은 시뮬레이션의 결과(다음 상태)만을 출력하는 블랙박스였다. 따라서 이를 이용해 학습하려면 강화학습과 같이 수많은 무작위 시행착오(Sampling)를 거쳐야만 했다. 이는 데이터 효율(Sample Efficiency)이 매우 낮다는 단점이 있다.37</p>
<p>반면, 미분 가능한 물리 엔진은 시뮬레이션 과정 전체가 미분 가능하도록(Differentiable) 설계되었다. 즉, 시뮬레이션의 결과에 대한 입력 변수(제어 파라미터)의 기울기(Gradient)를 해석적으로 계산할 수 있다.</p>
<ul>
<li><strong>RL의 접근:</strong> “이쪽으로 움직여봤더니 점수가 좋더라” (수천 번 시도 필요).</li>
<li><strong>미분 가능한 물리학의 접근:</strong> “결과를 좋게 하려면 입력을 정확히 이 방향으로 수정해야 한다” (역전파를 통해 즉시 계산).</li>
</ul>
<p>이는 딥러닝의 역전파(Backpropagation) 알고리즘을 물리 엔진 내부까지 확장한 것이다. 로봇이 가상 환경에서 동작을 수행했을 때, 그 결과와 목표 사이의 오차(Loss)를 줄이기 위해 제어 입력을 어떻게 수정해야 하는지를 수학적으로 정확하게 계산할 수 있다.39 연구 결과에 따르면, 미분 가능한 시뮬레이터를 활용할 경우 기존 강화학습 대비 수십 배에서 수백 배 빠른 학습 속도를 보여주며, 훨씬 정교한 제어 정책을 수립할 수 있다.41 이는 로봇 제어 문제를 ’탐색(Search)’의 문제에서 ’최적화(Optimization)’의 문제로 변환시킴으로써 소프트웨어 2.0의 효율성을 극대화한다.</p>
<h3>5.2  현실 격차(Reality Gap)와 도메인 무작위화(Domain Randomization)</h3>
<p>시뮬레이션에서 완벽하게 학습된 로봇도 실제 환경에 투입되면 엉뚱한 행동을 하곤 한다. 이를 <strong>‘현실 격차(Reality Gap)’</strong> 문제라고 한다. 시뮬레이션은 현실의 마찰, 조명, 센서 노이즈 등을 완벽하게 모사할 수 없기 때문이다.42</p>
<p>소프트웨어 2.0은 이 문제를 **‘도메인 무작위화(Domain Randomization)’**라는 독특한 데이터 전략으로 극복한다. 시뮬레이션 환경의 물리 파라미터(마찰 계수, 질량, 중력 등)와 시각적 요소(조명, 텍스처, 카메라 위치)를 의도적으로 무작위로 변동시켜 학습시키는 것이다.43 이렇게 엄청나게 다양한 가상 환경을 경험한 로봇에게, 실제 현실은 단지 ’또 하나의 노이즈가 섞인 시뮬레이션 환경’일 뿐이다. 이 방식은 OpenAI의 로봇 손이 큐브를 조작하거나, 테슬라의 로봇이 걷는 법을 배우는 데 결정적인 역할을 했다.</p>
<h3>5.3  데이터 엔진(Data Engine): 코드를 대체하는 라벨링</h3>
<p>안드레이 카패시는 테슬라의 자율주행 개발 경험을 통해 **‘데이터 엔진(Data Engine)’**의 중요성을 역설했다. 개발자는 모델이 실패하는 엣지 케이스(Edge Case, 예: 터널 입구의 눈부심, 특이한 형태의 트럭)를 발견하면, 코드를 수정하는 대신 해당 상황과 유사한 데이터를 대량으로 수집하고 라벨링하여 데이터셋에 추가한다.26 모델을 재학습시키면 해당 오류는 자연스럽게 수정된다.</p>
<p>이러한 선순환 구조(Flywheel)가 구축되면, 로봇 시스템의 성능 향상은 엔지니어의 코딩 실력이 아니라, 데이터 파이프라인의 효율성에 의해 결정된다. 이는 로봇 개발 조직의 구조를 근본적으로 변화시키고 있다.</p>
<h2>6.  사례 연구: 테슬라 오토파일럿에서 옵티머스까지</h2>
<p>테슬라의 사례는 소프트웨어 2.0 철학이 실제 산업 현장, 특히 대규모 로봇 시스템에 어떻게 적용되는지를 보여주는 가장 극적인 예시이다. 테슬라는 자동차를 ’바퀴 달린 로봇’으로 정의하고, 자율주행(FSD)을 위해 개발된 소프트웨어 2.0 스택을 휴머노이드 로봇 ’옵티머스(Optimus)’에 그대로 이식하고 있다.25</p>
<h3>6.1  휴리스틱의 제거와 신경망의 전면화</h3>
<p>초기 자율주행 시스템은 차선 인식, 신호등 인식, 장애물 회피 등을 위해 수많은 C++ 코드(규칙 기반 로직)를 사용했다. “차선이 노란색이면…”, “신호등이 빨간색이면…“과 같은 규칙들은 복잡한 도심 환경에서 끊임없이 예외 상황에 부딪혔다.44</p>
<p>카패시와 테슬라 AI 팀은 이를 거대한 신경망으로 대체해 나갔다. ’HydraNet’이라 불리는 거대 모델은 8개의 카메라 영상을 동시에 입력받아 3차원 벡터 공간(Vector Space)을 재구성하고, 차량의 경로를 직접 계획한다.45 최근의 FSD v12 버전에서는 주행 판단과 제어까지도 신경망이 수행하는 ‘End-to-End’ 학습이 적용되었다. 이는 “규칙을 가르치는 것보다, 수십억 프레임의 인간 주행 영상을 보여주고 모방하게 하는 것이 낫다“는 소프트웨어 2.0의 승리를 의미한다.44</p>
<h3>6.2  옵티머스: 범용 로봇을 향한 소프트웨어 2.0의 확장</h3>
<p>테슬라 봇 ’옵티머스’는 이러한 FSD의 신경망 두뇌를 공유한다. 로봇의 시각 처리 시스템은 자동차와 동일하며, 경로 계획 및 제어 알고리즘 역시 동일한 아키텍처를 사용한다.25</p>
<p>소프트웨어 2.0 관점에서 휴머노이드 제어는 자율주행과 본질적으로 다르지 않다. 입력(카메라, 관절 센서)과 출력(관절 액추에이터 토크)의 차원만 다를 뿐, 목표는 동일하게 ’데이터에 기반한 최적화’이다.</p>
<ul>
<li><strong>모션 리타겟팅(Motion Retargeting):</strong> 인간이 웨어러블 장비를 착용하고 수행한 동작 데이터를 로봇에게 학습시킨다. 로봇은 역운동학(Inverse Kinematics) 수식을 푸는 대신, 인간의 동작을 모방하며 균형 잡기와 물체 조작을 동시에 배운다.46</li>
<li><strong>통합된 지능:</strong> 기존 로봇 공학이 ’보행 제어기’와 ’손 조작 제어기’를 따로 만들고 합치려 했다면, 소프트웨어 2.0은 하나의 신경망이 전신 제어(Whole-body Control)를 수행하도록 학습한다. 이는 로봇이 걷으면서 자연스럽게 팔을 흔들거나, 물건을 집기 위해 허리를 숙이는 협응 동작을 자연스럽게 발현시킨다.</li>
</ul>
<h2>7.  결론: 제어의 미래와 소프트웨어 3.0</h2>
<p>우리는 지금 로봇 제어의 역사가 ’수학적 증명’에서 ’데이터기반 학습’으로 넘어가는 변곡점에 서 있다. 고전 제어 이론(소프트웨어 1.0)이 인류에게 정밀한 기계 문명을 선물했다면, 소프트웨어 2.0은 로봇에게 비정형 세계를 이해하고 적응하는 유연함을 부여하고 있다.</p>
<p>PID 제어기가 100년이 지난 지금도 쓰이듯이, 고전 제어 이론이 완전히 사라지지는 않을 것이다. 안전이 절대적으로 중요한 영역(예: 수술 로봇의 안전 정지 메커니즘)에서는 여전히 명시적인 코드가 필요하다. 그러나 로봇 지능의 핵심 엔진은 되돌릴 수 없이 신경망으로 이동하고 있다.</p>
<p>일각에서는 벌써 **‘소프트웨어 3.0’**을 논의한다. 이는 대규모 언어 모델(LLM)과 같은 초거대 AI가 인간의 자연어 프롬프트를 이해하고, 스스로 코드를 작성하거나 로봇의 행동을 계획하는 단계를 의미한다.47 “빨간 사과를 집어줘“라는 인간의 말을 이해하고(Software 3.0), 이를 수행하기 위해 팔을 뻗는 최적의 궤적을 신경망이 생성하며(Software 2.0), 최종적으로 모터의 전류를 제어하는(Software 1.0) 하이브리드 아키텍처가 미래 로봇 제어의 표준이 될 가능성이 높다.</p>
<p>결국, 제어 이론의 역사는 인간이 기계에게 의도를 전달하는 언어가 기계어(Machine Code)에서 수식(Math)으로, 다시 데이터(Data)로, 그리고 마침내 자연어(Natural Language)로 진화해 온 과정이라 할 수 있다. 소프트웨어 2.0은 그 거대한 여정의 가장 역동적인 현재 진행형이다.</p>
<h3>7.1 표 2.1: 제어 패러다임의 비교 (소프트웨어 1.0 vs 2.0)</h3>
<table><thead><tr><th><strong>비교 항목</strong></th><th><strong>소프트웨어 1.0 (고전/현대 제어)</strong></th><th><strong>소프트웨어 2.0 (딥러닝/AI 로보틱스)</strong></th></tr></thead><tbody>
<tr><td><strong>핵심 철학</strong></td><td><strong>명시적 프로그래밍 (Explicit)</strong> 인간이 규칙과 논리를 설계</td><td><strong>암시적 프로그래밍 (Implicit)</strong> 목표와 데이터로 최적화</td></tr>
<tr><td><strong>기반 이론</strong></td><td>미분 방정식, 라플라스 변환, 선형대수</td><td>신경망(Neural Net), 확률 통계, 최적화 이론</td></tr>
<tr><td><strong>제어 대상</strong></td><td>선형화 가능한 시스템, 정형 환경</td><td>고도의 비선형 시스템, 비정형/접촉 환경</td></tr>
<tr><td><strong>개발 도구</strong></td><td>MATLAB, Simulink, C++, Python</td><td>PyTorch, TensorFlow, JAX, 대규모 GPU 클러스터</td></tr>
<tr><td><strong>하드웨어</strong></td><td>CPU (복잡한 분기 처리에 최적화)</td><td>GPU/TPU/NPU (단순 행렬 연산 병렬 처리에 최적화)</td></tr>
<tr><td><strong>상태 추정</strong></td><td>센서 퓨전 (Kalman Filter) -&gt; 수동 특징 추출</td><td>End-to-End 학습 (Raw Sensor Data -&gt; Action)</td></tr>
<tr><td><strong>개발자 역할</strong></td><td>알고리즘 설계자, 수학적 모델링 전문가</td><td>데이터 큐레이터, 신경망 아키텍트</td></tr>
<tr><td><strong>대표 사례</strong></td><td>산업용 로봇 팔(용접, 도색), 보스턴 다이내믹스(초기)</td><td>테슬라 FSD/옵티머스, 구글 RT-2, 딥마인드 로보틱스</td></tr>
<tr><td><strong>한계점</strong></td><td>모델링 오차에 취약, 고차원 인지 데이터 통합 난해</td><td>결과의 해석 불가능성(Black-box), 막대한 데이터 필요</td></tr>
</tbody></table>
<p>출처: Andrej Karpathy의 “Software 2.0” 1, Levine 등의 “End-to-End Visuomotor Policies” 21 및 제어 이론 역사 문헌 6 종합.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>Software 2.0: An Emerging Era of Automatic Code Generation - The Softtek Blog, https://blog.softtek.com/software-2.0-an-emerging-era-of-automatic-code-generation</li>
<li>Software 2.0; or, why did that AI think that muffin was a chihuahua? - AI &amp; Big Data Expo - Conference and Exhibition, https://www.ai-expo.net/software-2-0-or-why-did-that-ai-think-that-muffin-was-a-chihuahua/</li>
<li>Torque-Limited Manipulation Planning through Contact by Interleaving Graph Search and Trajectory Optimization, http://biorobotics.ri.cmu.edu/papers/paperUploads/85259-2703.pdf</li>
<li>1월 3, 2026에 액세스, <a href="https://karpathy.medium.com/software-2-0-a64152b37c35#:~:text=Software%202.0%20is%20code%20written,%20%5Bhttps://karpathy.medium.com/software-2-0-a64152b37c35#:~:text=Software%202.0%20is%20code%20written,this%20training%20data%20correctly%E2%80%9D">https://karpathy.medium.com/software-2-0-a64152b37c35#:~:text=Software%202.0%20is%20code%20written,this%20training%20data%20correctly%E2%80%9D).</a>.](https://karpathy.medium.com/software-2-0-a64152b37c35#:~:text=Software%202.0%20is%20code%20written,this%20training%20data%20correctly”).)</li>
<li>Control theory - Wikipedia, https://en.wikipedia.org/wiki/Control_theory</li>
<li>Control Theory and Robotics: A Comprehensive Overview | by Rajat Sharma | Medium, https://medium.com/@rajat01221/control-theory-and-robotics-a-comprehensive-overview-105cbd15da71</li>
<li>State space analysis - WordPress.com, https://cybertycoons.files.wordpress.com/2014/04/unit2-sr.pdf</li>
<li>What are the reasons or problems associated with the classical control theory, that led to the development of modern control theory? | ResearchGate, https://www.researchgate.net/post/What-are-the-reasons-or-problems-associated-with-the-classical-control-theory-that-led-to-the-development-of-modern-control-theory</li>
<li>Controlling Contact-Rich Manipulation Under Partial Observability - Robotics, https://www.roboticsproceedings.org/rss16/p023.pdf</li>
<li>Online Estimation of Manipulator Dynamics for Computed Torque Control of Robotic Systems - PMC - NIH, https://pmc.ncbi.nlm.nih.gov/articles/PMC12656155/</li>
<li>Robust Model-Based In-Hand Manipulation with Integrated Real-Time Motion-Contact Planning and Tracking - arXiv, https://arxiv.org/html/2505.04978v1</li>
<li>A Tutorial on Robust Control, Adaptive Control and Robust Adaptive Control—Application to Robotic Manipulators - MDPI, https://www.mdpi.com/2411-5134/4/3/49</li>
<li>A Journey Through the History of Control Theory - YouTube, https://www.youtube.com/watch?v=FD6Fz9cYy5I</li>
<li>Unlock low-level force control with Universal Robots Direct Torque Control, https://www.universal-robots.com/blog/unlock-low-level-force-control-with-universal-robots-direct-torque-control/</li>
<li>AI #114: Liars, Sycophants and Cheaters - LessWrong, https://www.lesswrong.com/posts/pazFKtkp7T8qaRzva/ai-114-liars-sycophants-and-cheaters</li>
<li>Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics - ResearchGate, https://www.researchgate.net/publication/330673140_Decoupling_feature_extraction_from_policy_learning_assessing_benefits_of_state_representation_learning_in_goal_based_robotics</li>
<li>Leveraging Structure for Efficient and Dexterous Contact-Rich Manipulation - DSpace@MIT, https://dspace.mit.edu/bitstream/handle/1721.1/158946/suh-hjsuh-phd-eecs-2025-thesis.pdf?sequence=1&amp;isAllowed=y</li>
<li>Recasting Classical Motion Planning for Contact-Rich Manipulation - arXiv, https://arxiv.org/html/2506.00351v2</li>
<li>Robust Contact-rich Manipulation through Implicit Motor Adaptation - Idiap Publications, https://publications.idiap.ch/attachments/papers/2025/Xue_IJRR_2025.pdf</li>
<li>Science and Engineering for Learning Robots - Eric Jang, https://blog.evjang.com/2021/03/learning-robots.html</li>
<li>End-to-End Training of Deep Visuomotor Policies - CCC - Computing Research Association, https://cra.org/ccc/great-innovative-idea-end-to-end-training-of-deep-visuomotor-policies/</li>
<li>Science and Engineering for Learned Robots | Eric Jang, https://evjang.com/2021/03/14/learning-robots.html</li>
<li>Software 2.0 - Andrej Karpathy – Medium, https://karpathy.medium.com/software-2-0-a64152b37c35</li>
<li>[N] Software 2.0 - Andrej Karpathy : r/MachineLearning - Reddit, https://www.reddit.com/r/MachineLearning/comments/7cdov2/n_software_20_andrej_karpathy/</li>
<li>how-to-invest-in-the-ai-revolution.pdf - Trading with Cody, https://www.tradingwithcody.com/content/files/wp-content/uploads/2024/06/how-to-invest-in-the-ai-revolution.pdf</li>
<li>Andrej Karpathy: Tesla AI, Self-Driving, Optimus, Aliens, and AGI | Lex Fridman Podcast #333 | by The Shortcut | Medium, https://medium.com/@theShortcut8/andrej-karpathy-tesla-ai-self-driving-optimus-aliens-and-agi-lex-fridman-podcast-333-87a07901e34b</li>
<li>(PDF) Continuous control with deep reinforcement learning - ResearchGate, https://www.researchgate.net/publication/281670459_Continuous_control_with_deep_reinforcement_learning</li>
<li>[PDF] Continuous control with deep reinforcement learning - Semantic Scholar, https://www.semanticscholar.org/paper/Continuous-control-with-deep-reinforcement-learning-Lillicrap-Hunt/024006d4c2a89f7acacc6e4438d156525b60a98f</li>
<li>A Comprehensive Review of Deep Learning Techniques in Mobile Robot Path Planning: Categorization and Analysis - MDPI, https://www.mdpi.com/2076-3417/15/4/2179</li>
<li>Deep Deterministic Policy Gradient Algorithm: A Systematic Review - ResearchGate, https://www.researchgate.net/publication/375414282_Deep_Deterministic_Policy_Gradient_Algorithm_A_Systematic_Review</li>
<li>End-to-End Training of Deep Visuomotor Policies - Journal of Machine Learning Research, https://www.jmlr.org/papers/volume17/15-522/15-522.pdf</li>
<li>[PDF] Guided Policy Search - Semantic Scholar, https://www.semanticscholar.org/paper/Guided-Policy-Search-Levine-Koltun/244539f454800697ed663326b7cfba337ca0c2ec</li>
<li>Guided Policy Search - Supplementary Materials - Stanford Computer Graphics Laboratory, https://graphics.stanford.edu/projects/gpspaper/index.htm</li>
<li>End-to-End Training of Deep Visuomotor Policies - UC Berkeley Robot Learning Lab, https://rll.berkeley.edu/RSS2015-BlueSky-Shakey/Levine-ShakeyWS-2015.pdf</li>
<li>[1509.06113] Deep Spatial Autoencoders for Visuomotor Learning - arXiv, https://arxiv.org/abs/1509.06113</li>
<li>Deep Spatial Autoencoders for Visuomotor Learning, https://rll.berkeley.edu/dsae/dsae.pdf</li>
<li>A Differentiable Physics Engine for Deep Learning in Robotics - Frontiers, https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2019.00006/full</li>
<li>Learning Robot Control: From Reinforcement Learning to Differentiable Simulation - OpenReview, https://openreview.net/pdf/cd19aa7c52cabe22e7ee2b4ade1d478bd960d08b.pdf</li>
<li>Fast and Feature-Complete Differentiable Physics for Articulated Rigid Bodies with Contact - Robotics, https://www.roboticsproceedings.org/rss17/p034.pdf</li>
<li>Differentiable Information Enhanced Model-Based Reinforcement Learning, https://ojs.aaai.org/index.php/AAAI/article/download/34419/36574</li>
<li>Differentiable Information Enhanced Model-Based Reinforcement Learning - arXiv, https://arxiv.org/html/2503.01178v1</li>
<li>[1908.05256] Continuous Control for High-Dimensional State Spaces: An Interactive Learning Approach - arXiv, https://arxiv.org/abs/1908.05256</li>
<li>A Deep Reinforcement Learning Framework for Control of Robotic Manipulators in Simulated Environments - IEEE Xplore, https://ieeexplore.ieee.org/iel8/6287639/10380310/10606462.pdf</li>
<li>Transcript for Walter Isaacson: Elon Musk, Steve Jobs, Einstein, Da Vinci &amp; Ben Franklin | Lex Fridman Podcast #395, https://lexfridman.com/walter-isaacson-transcript/</li>
<li>Horizon Robotics’ Liu Jingchu: God’s Perspective and Imagination, https://en.eeworld.com.cn/news/qcdz/eic567994.html</li>
<li>Lex Fridman Podcast - #333 – Andrej Karpathy: Tesla AI, Self-Driving, Optimus, Aliens, and AGI Transcript and Discussion - PodScripts, https://podscripts.co/podcasts/lex-fridman-podcast/333-andrej-karpathy-tesla-ai-self-driving-optimus-aliens-and-agi</li>
<li>Andrej Karpathy: Software in the era of AI [video] - Hacker News, https://news.ycombinator.com/item?id=44314423</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>