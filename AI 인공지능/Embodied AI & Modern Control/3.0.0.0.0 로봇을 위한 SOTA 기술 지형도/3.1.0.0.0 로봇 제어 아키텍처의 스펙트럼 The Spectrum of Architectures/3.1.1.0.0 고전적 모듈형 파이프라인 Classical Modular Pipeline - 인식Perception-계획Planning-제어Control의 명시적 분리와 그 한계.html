<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:3.1.1 고전적 모듈형 파이프라인 (Classical Modular Pipeline): 인식(Perception)-계획(Planning)-제어(Control)의 명시적 분리와 그 한계</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>3.1.1 고전적 모듈형 파이프라인 (Classical Modular Pipeline): 인식(Perception)-계획(Planning)-제어(Control)의 명시적 분리와 그 한계</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 3. 로봇을 위한 SOTA 기술 지형도</a> / <a href="index.html">3.1 로봇 제어 아키텍처의 스펙트럼 (The Spectrum of Architectures)</a> / <span>3.1.1 고전적 모듈형 파이프라인 (Classical Modular Pipeline): 인식(Perception)-계획(Planning)-제어(Control)의 명시적 분리와 그 한계</span></nav>
                </div>
            </header>
            <article>
                <h1>3.1.1 고전적 모듈형 파이프라인 (Classical Modular Pipeline): 인식(Perception)-계획(Planning)-제어(Control)의 명시적 분리와 그 한계</h1>
<p>로봇 공학이 태동하던 시기부터 현재의 산업 현장에 이르기까지, 로봇 제어 아키텍처를 지배해 온 가장 강력하고 보편적인 패러다임은 바로 **“감지-계획-행동(Sense-Plan-Act, SPA)”**으로 명명되는 고전적 모듈형 파이프라인이다. 이 아키텍처는 복잡하고 비정형적인 물리 세계의 상호작용 문제를 인간 공학자가 이해하고 다룰 수 있는 단위로 환원하여 해결하려는 시도에서 출발했다. 1960년대 후반 스탠포드 연구소(SRI)의 기념비적인 로봇 ’쉐이키(Shakey)’에서 정립된 이래 1, 이 접근법은 수십 년간 로봇 공학의 표준 참조 모델(Standard Reference Model)로 기능해 왔다. 본 절에서는 고전적 파이프라인의 철학적 배경과 이를 구성하는 각 모듈의 심층적인 기술적 원리, 그리고 현대의 비정형 환경(Unstructured Environment)에서 드러나는 구조적 한계와 그 필연적인 붕괴 과정을 면밀히 분석한다.</p>
<h2>1.  환원주의적 접근과 SPA 패러다임의 철학</h2>
<p>고전적 파이프라인의 핵심 철학은 **환원주의(Reductionism)**와 **모듈화(Modularity)**이다. ’자율성(Autonomy)’이라는 거대하고 난해한 문제를 단번에 해결하는 것은 불가능에 가깝다. 따라서 공학자들은 이를 기능적으로 명확히 정의된 하위 시스템(Subsystem)으로 분할(Decomposition)하고, 각 시스템을 직렬로 연결하여 전체 지능을 구현하고자 했다.1 이 구조는 정보의 흐름을 단방향의 순차적 과정으로 정의하며, 각 단계는 이전 단계의 산출물을 100% 신뢰할 수 있는 진실(Ground Truth)로 가정하고 처리한다.</p>
<h3>1.1  감지-계획-행동(SPA) 사이클의 정의</h3>
<p>SPA 패러다임에서 로봇의 제어 루프는 엄격하게 구분된 세 단계의 순환으로 구성된다.</p>
<ol>
<li><strong>감지(Sense):</strong> 로봇은 다양한 센서(LiDAR, 카메라, IMU 등)를 통해 외부 세계의 물리적 신호를 수집한다. 이 단계의 목적은 노이즈가 섞인 고차원 데이터로부터 로봇의 현재 상태(State)와 주변 환경에 대한 정량적 모델(World Model)을 재구성하는 것이다.3 출력값은 주로 지도(Map), 객체의 위치 좌표, 로봇의 포즈(Pose)와 같은 <strong>상징적(Symbolic) 혹은 기하학적(Geometric) 정보</strong>이다.</li>
<li><strong>계획(Plan):</strong> 감지 단계에서 갱신된 월드 모델과 로봇의 목표(Goal)를 입력받아, 현재 상태에서 목표 상태로 전이하기 위한 최적의 행동 시퀀스(Action Sequence)를 생성한다. 이는 대역적 경로 계획(Global Path Planning)과 지역적 궤적 생성(Trajectory Generation)을 포함하며, 출력값은 시간에 따른 **참조 궤적(Reference Trajectory)**이다.3</li>
<li><strong>행동(Act):</strong> 생성된 참조 궤적을 물리적으로 실현하기 위해 하위 제어기(Low-level Controller)가 작동한다. 이 단계에서는 로봇 동역학(Dynamics)을 고려하여 관절 모터에 인가할 토크(Torque)나 전압을 계산한다. 출력값은 실제 구동기에 전달되는 **제어 입력(Control Input)**이다.6</li>
</ol>
<p>이러한 접근 방식은 초기 인공지능 연구의 ’물리적 기호 시스템 가설(Physical Symbol System Hypothesis)’에 깊은 뿌리를 두고 있다. 즉, 지능이란 기호(Symbol)를 조작하는 과정이며, 로봇의 신체는 이러한 기호 연산의 결과를 물리 세계에 투영하는 수단에 불과하다는 이원론적 관점이 투영되어 있다.8</p>
<h3>1.2  모듈화의 공학적 효용성</h3>
<p>수십 년간 이 구조가 유지될 수 있었던 이유는 공학적 관점에서의 명확한 이점 때문이다.</p>
<ul>
<li><strong>해석 가능성(Interpretability)과 디버깅:</strong> 시스템이 오작동할 경우 원인을 규명하기 용이하다. 로봇이 장애물을 피하지 못했다면, “라이다가 장애물을 감지하지 못했는가?(Perception Failure)”, “경로 생성기가 충돌 경로를 생성했는가?(Planning Failure)”, 아니면 “모터가 명령을 따라가지 못했는가?(Control Failure)“를 명확히 구분하여 진단할 수 있다.10</li>
<li><strong>개발의 분업화:</strong> 각 모듈은 서로 다른 학문적 배경을 가진 전문가들에 의해 독립적으로 개발될 수 있다. 컴퓨터 비전 연구자는 인식 정확도 향상에만 집중하고, 제어 이론가는 궤적 추종 성능에만 집중하면 된다. 이들은 사전에 정의된 인터페이스(Interface)를 통해서만 소통하므로, 시스템 통합의 복잡도를 낮출 수 있다.12</li>
<li><strong>이론적 보증(Theoretical Guarantee):</strong> 각 모듈은 수학적으로 모델링되어 있어 성능에 대한 이론적 증명이 가능하다. 예를 들어, 제어 모듈의 안정성(Stability)은 리아프노프(Lyapunov) 함수를 통해, 경로 계획의 완전성(Completeness)은 알고리즘적으로 증명될 수 있다.13</li>
</ul>
<h2>2.  파이프라인의 심층 해부: 수학적 정식화와 구성 기술</h2>
<p>고전적 파이프라인의 각 단계는 단순한 기능 블록이 아니라, 고도의 수학적 이론과 알고리즘으로 무장한 독립적인 연구 분야이다. 현대 로봇 공학의 관점에서 각 단계가 어떻게 정식화(Formulation)되고 구현되는지 심층적으로 분석한다.</p>
<h3>2.1  인식(Perception): 상태 추정(State Estimation)과 불확실성의 관리</h3>
<p>인식 모듈의 핵심 임무는 센서로부터 들어오는 날것의 데이터(Raw Data) <span class="math math-inline">z_t</span>를 처리하여, 시스템의 상태 벡터(State Vector) <span class="math math-inline">x_t</span>를 추정하는 것이다.15 이는 수학적으로 <strong>상태 추정(State Estimation)</strong> 문제로 귀결된다.</p>
<h4>2.1.1  베이즈 필터와 칼만 필터의 지배</h4>
<p>고전적 로봇 공학에서 상태 <span class="math math-inline">x_t</span>는 직접 관측 불가능한(Hidden) 변수이며, 센서 데이터 <span class="math math-inline">z_t</span>는 노이즈 <span class="math math-inline">v_t</span>를 포함한 관측 방정식 <span class="math math-inline">z_t = h(x_t) + v_t</span>로 표현된다. 이를 해결하기 위해 확률적 접근법인 베이즈 필터(Bayes Filter)가 사용되며, 선형 가우스 시스템(Linear Gaussian System)을 가정한 **칼만 필터(Kalman Filter, KF)**와 비선형 시스템을 위한 **확장 칼만 필터(Extended Kalman Filter, EKF)**가 표준으로 자리 잡았다.10</p>
<p>EKF 알고리즘은 다음의 두 단계로 순환하며 상태를 갱신한다 18:</p>
<ol>
<li>
<p>예측(Prediction): 로봇의 운동 모델(Motion Model)을 사용하여 다음 상태를 예측한다.<br />
<span class="math math-display">
\hat{x}_{t\vert t-1} = f(\hat{x}_{t-1\vert t-1}, u_{t-1})
</span></p>
<p><span class="math math-display">
P_{t\vert t-1} = F_t P_{t-1\vert t-1} F_t^T + Q_t
</span></p>
</li>
</ol>
<p>여기서 <span class="math math-inline">P</span>는 오차 공분산 행렬, <span class="math math-inline">F_t</span>는 운동 모델의 야코비안(Jacobian), <span class="math math-inline">Q_t</span>는 프로세스 노이즈 공분산이다.</p>
<ol start="2">
<li>
<p>갱신(Update): 실제 센서 측정값 <span class="math math-inline">z_t</span>와 예측값의 차이(Innovation)를 반영하여 상태를 보정한다.<br />
<span class="math math-display">
K_t = P_{t\vert t-1} H_t^T (H_t P_{t\vert t-1} H_t^T + R_t)^{-1}
</span></p>
<p><span class="math math-display">
\hat{x}_{t\vert t} = \hat{x}_{t\vert t-1} + K_t (z_t - h(\hat{x}_{t\vert t-1}))
</span></p>
<p><span class="math math-display">
P_{t\vert t} = (I - K_t H_t) P_{t\vert t-1}
</span></p>
</li>
</ol>
<p>이 과정에서 칼만 이득(Kalman Gain) <span class="math math-inline">K_t</span>는 측정 신뢰도 <span class="math math-inline">R_t</span>와 예측 신뢰도 <span class="math math-inline">P_{t\vert t-1}</span> 사이의 가중치를 최적으로 조절한다.</p>
<h4>2.1.2  특징 공학(Feature Engineering)과 SLAM</h4>
<p>위치 추정을 넘어 주변 환경을 지도로 구성하기 위해 <strong>SLAM(Simultaneous Localization and Mapping)</strong> 기술이 필수적이다. 딥러닝 이전 시대에는 사람이 직접 설계한 특징(Hand-crafted Features)에 의존했다.</p>
<ul>
<li><strong>시각적 특징:</strong> 이미지에서는 <strong>Canny Edge Detector</strong>로 윤곽선을 추출하거나, <strong>SIFT(Scale-Invariant Feature Transform)</strong> 알고리즘을 사용하여 크기, 회전, 조명 변화에 강인한 특징점(Keypoint)을 검출하고 기술자(Descriptor)를 생성하여 매칭했다.20</li>
<li><strong>점유 격자 지도(Occupancy Grid Map):</strong> 라이다(LiDAR) 데이터는 공간을 격자로 나누고 각 격자가 장애물일 확률을 업데이트하는 방식으로 처리되었다. 이는 로봇이 주행 가능한 공간(Free Space)과 불가능한 공간(Occupied Space)을 이진법적으로 구분하는 기초가 된다.22</li>
</ul>
<p>하지만 이러한 고전적 인식은 ’의미(Semantic)’를 이해하지 못한다는 치명적인 한계가 있었다. SIFT는 특징점 간의 기하학적 매칭은 수행하지만, 그것이 ’책상’인지 ’의자’인지는 알지 못한다. 따라서 로봇은 장애물을 피할 수는 있어도, “의자를 옆으로 치우고 지나가라“는 고차원적인 판단을 내리기 위한 정보를 생산하지 못했다.22</p>
<h3>2.2  계획(Planning): 구성 공간(C-Space)의 탐색</h3>
<p>인식 모듈이 제공한 지도와 자신의 위치 <span class="math math-inline">\hat{x}_t</span>를 바탕으로, 계획 모듈은 목표 지점 <span class="math math-inline">x_{goal}</span>까지 도달하기 위한 경로를 생성한다. 로봇의 계획 문제는 작업 공간(Task Space)이 아닌, 로봇의 모든 관절 각도로 정의되는 **구성 공간(Configuration Space, C-Space)**에서 이루어진다.</p>
<h4>2.2.1  이산 탐색과 샘플링 기반 알고리즘</h4>
<p>C-Space 상에서 장애물 영역 <span class="math math-inline">C_{obs}</span>를 피해 자유 영역 <span class="math math-inline">C_{free}</span>를 연결하는 경로를 찾는 것은 계산 복잡도가 매우 높은 문제(PSPACE-hard)이다.24 이를 해결하기 위해 두 가지 주류 접근법이 사용된다.</p>
<ul>
<li><strong>격자 기반 탐색(Grid-based Search):</strong> 공간을 일정한 격자로 나누고 그래프로 모델링한 뒤, <strong>A* 알고리즘</strong>이나 <strong>Dijkstra 알고리즘</strong>을 적용한다. A*는 휴리스틱 함수 <span class="math math-inline">f(n) = g(n) + h(n)</span> (여기서 <span class="math math-inline">g(n)</span>은 시작점부터의 비용, <span class="math math-inline">h(n)</span>은 목표까지의 추정 비용)을 이용하여 탐색 효율을 높인다.10 그러나 자유도가 높은 로봇 팔(7-DoF 이상)에서는 상태 공간의 크기가 지수적으로 증가하는 ’차원의 저주(Curse of Dimensionality)’로 인해 적용이 불가능하다.</li>
<li><strong>샘플링 기반 탐색(Sampling-based Planning):</strong> 고차원 문제를 해결하기 위해 **RRT(Rapidly-exploring Random Tree)**나 **PRM(Probabilistic Roadmap)**이 도입되었다.26 RRT는 공간상에 무작위로 샘플 <span class="math math-inline">q_{rand}</span>를 생성하고, 트리에서 가장 가까운 노드 <span class="math math-inline">q_{nearest}</span>로부터 <span class="math math-inline">q_{rand}</span> 방향으로 일정 거리만큼 확장하여 새로운 노드 <span class="math math-inline">q_{new}</span>를 추가한다. 이 과정은 <span class="math math-inline">q_{new}</span>가 충돌이 없을 때만 수행되며, 이를 반복하여 시작점과 목표점을 연결하는 트리를 빠르게 성장시킨다.28</li>
<li><em>RRT의 확장:</em> RRT* (Optimal RRT)는 경로의 최적성(Optimality)을 점진적으로 보장하며, 비홀로노믹(Non-holonomic) 제약 조건을 가진 차량이나 로봇의 동역학적 계획에도 널리 쓰인다.25</li>
</ul>
<h4>2.2.2  기호적 계획(Symbolic Planning)과 STRIPS</h4>
<p>단순 이동이 아닌 “컵을 집어 주방으로 옮겨라“와 같은 복합 작업을 수행하기 위해서는 기호적 추론이 필요하다. 1970년대의 **STRIPS(Stanford Research Institute Problem Solver)**는 로봇의 상태와 행동을 논리적 명제로 기술하는 표준을 정립했다.2</p>
<ul>
<li><strong>상태(State):</strong> <code>On(Cup, Table)</code>, <code>HandEmpty</code>, <code>Clear(Cup)</code></li>
<li><strong>행동(Action):</strong> <code>PickUp(x)</code></li>
<li><em>Precondition:</em> <code>On(x, Table) \land HandEmpty \land Clear(x)</code></li>
<li><em>Effect:</em> <code>Holding(x) \land \neg On(x, Table) \land \neg HandEmpty</code></li>
</ul>
<p>이러한 기호적 계획은 **PDDL(Planning Domain Definition Language)**로 발전하여 현대의 <strong>TAMP(Task and Motion Planning)</strong> 시스템의 상위 레이어를 담당한다.29 그러나 연속적인 물리 세계를 이산적인 기호로 추상화하는 과정에서 필연적으로 발생하는 정보 손실은 후술할 ’기호 접지 문제’의 원인이 된다.</p>
<h3>2.3  제어(Control): 궤적 추종과 피드백 루프</h3>
<p>계획 모듈이 생성한 경로는 기하학적인 선(Line)일 뿐이며, 물리적인 힘을 포함하지 않는다. 제어 모듈의 역할은 로봇이 이 경로를 시간 <span class="math math-inline">t</span>에 맞춰 정확하게 따라가도록(Trajectory Tracking) 모터에 적절한 전압이나 토크를 인가하는 것이다.</p>
<h4>2.3.1  고전적 피드백 제어: PID와 계산 토크</h4>
<p>산업용 로봇에서 가장 널리 쓰이는 제어 기법은 <strong>PID(Proportional-Integral-Derivative)</strong> 제어이다.10<br />
<span class="math math-display">
u(t) = K_p e(t) + K_i \int_0^t e(\tau) d\tau + K_d \frac{d}{dt}e(t)
</span><br />
여기서 <span class="math math-inline">e(t) = x_{des}(t) - x(t)</span>는 목표값과 현재값의 오차이다. PID는 모델을 정확히 몰라도 튜닝을 통해 성능을 낼 수 있지만, 로봇 팔과 같이 관성 모멘트가 자세에 따라 변하는 비선형 시스템에서는 성능 한계가 명확하다.</p>
<p>이를 극복하기 위해 로봇의 동역학 모델 <span class="math math-inline">M(q)\ddot{q} + C(q, \dot{q})\dot{q} + g(q) = \tau</span>을 역으로 이용하는 **계산 토크 제어(Computed Torque Control)**가 사용된다.6 이는 비선형 항(중력, 코리올리 힘)을 토크 입력으로 미리 상쇄시켜 시스템을 선형화(Feedback Linearization)한 후, 선형 제어기를 적용하는 방식이다.<br />
<span class="math math-display">
\tau = M(q)(\ddot{q}_{des} + K_v \dot{e} + K_p e) + C(q, \dot{q})\dot{q} + g(q)
</span></p>
<h4>2.3.2  최적 제어(Optimal Control)와 MPC</h4>
<p>현대 제어의 정점에는 **모델 예측 제어(Model Predictive Control, MPC)**가 있다. MPC는 미래의 일정 구간(Horizon) 동안의 시스템 거동을 예측하고, 비용 함수(Cost Function)를 최소화하는 제어 입력을 실시간으로 최적화하여 계산한다.7<br />
<span class="math math-display">
\min_{u_{0:N-1}} \sum_{k=0}^{N-1} (x_k^T Q x_k + u_k^T R u_k) + x_N^T P x_N
</span></p>
<p><span class="math math-display">
\text{s.t. } x_{k+1} = f(x_k, u_k), \quad u_{\min} \le u_k \le u_{\max}, \quad x_k \in \mathcal{X}_{free}
</span></p>
<p>여기서 <span class="math math-inline">Q</span>와 <span class="math math-inline">R</span> 행렬은 상태 오차와 에너지 소모 간의 가중치를 조절하는 설계 파라미터이다. MPC는 관절의 속도 한계나 토크 한계와 같은 물리적 제약 조건을 명시적으로 고려할 수 있다는 강력한 장점이 있지만, 매 틱(tick)마다 최적화 문제를 풀어야 하므로 막대한 계산 비용을 요구한다.</p>
<h2>3.  고전적 파이프라인의 구조적 한계와 붕괴</h2>
<p>고전적 파이프라인은 통제된 공장 환경(Structured Environment)에서는 탁월한 성능을 발휘했다. 그러나 로봇이 연구실을 벗어나 예측 불가능한 현실 세계(Unstructured Environment)와 마주하면서, 모듈 간의 명시적 분리는 시스템의 유연성을 저해하고 치명적인 실패를 야기하는 근본 원인으로 지목되기 시작했다.</p>
<h3>3.1  정보 병목과 지연 시간(Latency): Motion-to-Photon Loop</h3>
<p>SPA 구조의 가장 직관적인 약점은 순차적 처리로 인한 지연 시간이다. 감지, 계획, 제어가 직렬로 연결되어 있어, 앞 단계가 완료되지 않으면 다음 단계가 시작될 수 없다.1</p>
<ul>
<li><strong>직렬 처리의 비효율성:</strong> 정밀한 SLAM이나 최적 경로 계획은 수십 밀리초(ms)에서 수 초(s)의 연산을 필요로 한다. 고속으로 이동하는 자율주행차나 드론의 경우, 인식 모듈의 처리가 끝난 시점에서 해당 데이터는 이미 과거의 정보가 되어버린다. 이를 <strong>“Motion-to-Photon”</strong> 지연이라 하며, 제어 시스템의 위상 지연(Phase Lag)을 유발하여 불안정성을 초래한다.33</li>
<li><strong>비동기 주기의 불일치:</strong> 카메라는 30Hz, 라이다는 10Hz, 제어기는 1kHz로 동작하는 등 각 모듈의 동작 주기가 다르다. 이를 통합하기 위해 ROS(Robot Operating System)와 같은 미들웨어를 사용하지만, 메시지 직렬화/역직렬화(Serialization/Deserialization) 및 통신 오버헤드(DDS Latency)로 인해 시스템 전체의 반응 속도가 저하된다.33 이는 급박한 상황에서의 회피 기동을 불가능하게 만든다.</li>
</ul>
<h3>3.2  오차의 누적과 전파(Compounding Errors): 전화기 게임 효과</h3>
<p>모듈화된 시스템의 가장 치명적인 결함은 <strong>오차의 누적(Compounding Errors)</strong> 현상이다.35 하위 모듈은 상위 모듈의 출력을 의심 없이 받아들여야 하므로, 작은 오차가 단계를 거치며 증폭된다.</p>
<ul>
<li><strong>인식 오차의 나비 효과:</strong> 인식 모듈이 장애물의 위치를 실제보다 5cm 옆으로 잘못 추정했다고 가정하자. 계획 모듈은 이 잘못된 정보를 바탕으로 경로를 생성하고, 제어 모듈은 이 잘못된 경로를 완벽하게 추종하려 노력한다. 결국 로봇은 정밀하게 제어된 상태로 장애물에 충돌하게 된다. 제어 모듈은 경로가 잘못되었다는 것을 알 방법이 없으며, 계획 모듈은 인식이 틀렸다는 것을 알 방법이 없다.</li>
<li><strong>불확실성 정보의 소실:</strong> 칼만 필터는 상태의 불확실성을 공분산 <span class="math math-inline">P</span>로 가지고 있지만, 대부분의 고전적 파이프라인에서 계획 모듈로 데이터를 넘길 때는 평균값(Mean, <span class="math math-inline">\hat{x}</span>)만 전달하고 공분산은 무시한다(Thresholding). 즉, “여기에 장애물이 있을 확률이 60%“라는 풍부한 정보는 “장애물 있음” 혹은 “없음“이라는 이진 정보로 강제 변환되며 뉘앙스가 소실된다.23</li>
</ul>
<h3>3.3  기호 접지 문제(The Symbol Grounding Problem)</h3>
<p>상위 레벨의 기호적 계획(Symbolic Planning)과 하위 레벨의 센서 데이터 간의 괴리는 **“기호 접지 문제(Symbol Grounding Problem)”**라는 심오한 난제를 야기한다.9</p>
<ul>
<li><strong>추상화의 손실:</strong> “컵(Cup)“이라는 기호는 컵의 모양, 재질, 마찰 계수, 무게 중심 등 수많은 물리적 속성을 포괄적으로 단순화한 것이다. 기호적 계획기(PDDL 등)는 이러한 세부 사항을 다루지 못한다. 로봇이 “컵을 집어라“라는 명령을 수행할 때, 그 컵이 얇은 종이컵인지 무거운 머그잔인지에 따라 파지력(Gripping Force)을 다르게 제어해야 하지만, 기호 시스템에서는 둘 다 동일한 <code>Cup</code>이라는 토큰일 뿐이다.40</li>
<li><strong>비정형 환경의 표현 불가:</strong> 비정형 환경의 모든 요소를 사전에 정의된 기호로 매핑하는 것은 불가능하다. 찌그러진 캔, 젖은 바닥, 찢어진 종이 등은 표준화된 기호로 표현하기 어려우며, 이를 억지로 분류하려다 보면 심각한 정보 왜곡이 발생한다. 이는 로봇이 낯선 환경에서 융통성 없이 행동하거나(Brittle), 멈춰 서게 만드는 주된 원인이다. Harnad가 제기한 이 문제는 고전적 AI가 실제 물리 세계(Embodied World)와 연결되지 못하고 겉도는 현상을 이론적으로 설명한다.41</li>
</ul>
<h3>3.4  현실과의 괴리(Reality Gap)와 모델링의 한계</h3>
<p>계획과 제어 모듈은 로봇과 환경에 대한 수학적 모델에 전적으로 의존한다. 그러나 모델은 언제나 현실의 근사(Approximation)일 뿐이다.</p>
<ul>
<li><strong>강체(Rigid Body) 가정의 붕괴:</strong> 대부분의 시뮬레이션과 계획 알고리즘은 물체를 변형되지 않는 강체로 가정한다. 그러나 천, 케이블, 액체, 흙과 같은 변형체(Deformable Object)를 다룰 때 이러한 가정은 무너진다.3 옷을 개거나 케이블을 꽂는 작업에서 고전적 제어기가 실패하는 이유는 대상의 변형을 모델링할 수 없기 때문이다.</li>
<li><strong>접촉과 마찰의 비선형성:</strong> 접촉(Contact)과 마찰(Friction)은 매우 비선형적이고 불연속적인 물리 현상이다. 이를 단순한 쿨롱 마찰 모델 등으로 선형화할 경우, 실제 상황에서의 미끄러짐이나 기계적 걸림(Jamming)을 예측하지 못한다.</li>
</ul>
<h3>3.5  학습의 차단: 그래디언트 블로킹(Gradient Blocking)</h3>
<p>현대 AI의 관점에서 볼 때, 고전적 파이프라인의 가장 큰 기술적 장벽은 **“미분 불가능성(Non-differentiability)”**으로 인한 학습의 차단이다.43</p>
<ul>
<li><strong>단절된 최적화:</strong> 딥러닝은 최종 목적 함수의 에러를 역전파(Backpropagation)하여 입력단까지의 모든 파라미터를 수정하는 종단간(End-to-End) 학습을 기반으로 한다. 그러나 고전적 파이프라인의 중간 단계인 A* 알고리즘(이산적 그래프 탐색), 기호적 계획기(논리 연산), 하드코딩된 제어 로직(If-else 분기)은 미분 불가능한 연산(argmax, discrete sampling)을 포함하고 있다.</li>
<li><strong>경험 기반 개선의 불가능:</strong> 따라서 시스템 전체를 데이터 기반으로 최적화할 수 없다. 인식 모듈은 이미지넷 데이터로만 학습하고, 제어 모듈은 수식으로만 튜닝된다. 로봇이 이동하다가 미끄러져 넘어졌을 때(최종 실패), 이 신호가 역전파되어 인식 모듈의 “바닥 재질 분류기“를 개선하거나 계획 모듈의 “보폭 설정 파라미터“를 수정하는 데 사용될 수 없다. 즉, 경험을 통해 시스템 전체가 유기적으로 똑똑해지는 학습 루프(Learning Loop)가 구조적으로 차단(Blocked)되어 있다.43</li>
</ul>
<h2>4.  사례 연구: DARPA Robotics Challenge (DRC)의 교훈</h2>
<p>고전적 파이프라인의 한계는 2015년 **DARPA Robotics Challenge (DRC)**에서 극적으로 증명되었다. 재난 현장 대응을 목표로 한 이 대회에서, 세계 최고의 팀들이 만든 휴머노이드 로봇들은 대부분 고전적 SPA 파이프라인에 의존했다.47</p>
<ul>
<li><strong>Stop-and-Think의 딜레마:</strong> 로봇들은 한 걸음을 떼거나 밸브를 돌리기 위해 수십 초에서 수 분간 멈춰 섰다. 센서로 스캔하고(Sense), 포인트 클라우드를 정합해 지도를 만들고(Map), 발 디딜 곳을 계획하고(Plan), 조심스럽게 움직이는(Act) 과정을 반복했다. 이는 재난 현장이 요구하는 속도와 반응성과는 거리가 멀었다.48</li>
<li><strong>모델링 오차로 인한 붕괴:</strong> 로봇들은 문을 열거나 드릴을 잡는 과정에서 수없이 넘어졌다. 이는 센서 노이즈로 인해 문손잡이의 위치를 1~2cm 잘못 인식했을 때, 혹은 지면의 경사를 미세하게 잘못 추정했을 때, 강체 기반의 경직된 제어기(Rigid Controller)가 이를 유연하게 받아들이지 못하고(Lack of Compliance) 발산했기 때문이다.50</li>
<li><strong>교훈:</strong> DRC는 정교하게 계산된 계획(Deliberation)보다, 불확실성을 안고 즉각적으로 반응할 수 있는 반사 신경(Reactivity)과 환경에 순응하는 유연성(Compliance)이 필수적이라는 교훈을 남겼다. 이는 이후 딥러닝 기반의 강화학습과 End-to-End 제어가 로봇 공학의 전면에 부상하는 결정적인 계기가 되었다.</li>
</ul>
<h3>4.1 표 3.1.1.1 고전적 파이프라인의 모듈별 특징 및 한계점 요약</h3>
<table><thead><tr><th><strong>단계 (Module)</strong></th><th><strong>입력 (Input) / 출력 (Output)</strong></th><th><strong>대표 알고리즘 (Algorithm Examples)</strong></th><th><strong>주요 수학적 도구 (Mathematical Tools)</strong></th><th><strong>구조적 한계 (Intrinsic Limitations)</strong></th></tr></thead><tbody>
<tr><td><strong>인식 (Perception)</strong></td><td><strong>In:</strong> Raw Sensor Data (<span class="math math-inline">z_t</span>) <strong>Out:</strong> State Estimate (<span class="math math-inline">\hat{x}_t</span>), Map</td><td>Kalman Filter (EKF), Particle Filter, Canny, SIFT, SLAM</td><td>Bayes Rule, Optimization, Linear Algebra</td><td>의미론적 이해 부재, 오차 증폭의 시작점, 연산 지연 (Latency)</td></tr>
<tr><td><strong>계획 (Planning)</strong></td><td><strong>In:</strong> State (<span class="math math-inline">\hat{x}_t</span>), Goal, Map <strong>Out:</strong> Reference Trajectory (<span class="math math-inline">x_{ref}</span>)</td><td>A*, Dijkstra, RRT, PRM, STRIPS, PDDL</td><td>Graph Theory, Topology, Discrete Math</td><td>차원의 저주, 기호 접지 문제, 모델링 오차에 취약</td></tr>
<tr><td><strong>제어 (Control)</strong></td><td><strong>In:</strong> Ref Trajectory, Current State <strong>Out:</strong> Torque (<span class="math math-inline">\tau</span>), Velocity (<span class="math math-inline">u</span>)</td><td>PID, Computed Torque, LQR, MPC</td><td>Calculus of Variations, Differential Eq.</td><td>강체 가정의 한계, 미분 불가능성(학습 차단), 비정형 환경 대응력 부족</td></tr>
</tbody></table>
<h3>4.2 수식 3.1.1.1: 파이프라인 오차 전파 모델 (Error Propagation Model)</h3>
<p>시스템 전체의 오차 <span class="math math-inline">E_{total}</span>은 각 모듈의 고유 오차와 시스템의 야코비안(민감도)에 의해 다음과 같이 비선형적으로 누적된다.<br />
<span class="math math-display">
E_{total} \approx \frac{\partial f_{ctrl}}{\partial x_{plan}} \left( \frac{\partial f_{plan}}{\partial x_{perc}} E_{perc} + E_{plan} \right) + E_{ctrl}
</span><br />
여기서 <span class="math math-inline">E_{perc}, E_{plan}, E_{ctrl}</span>은 각 모듈의 잔여 오차이며, 편미분 항들은 오차가 다음 단계로 전이될 때 증폭되는 게인(Gain)을 의미한다. 만약 계획 모듈이 인식 오차에 민감하다면(<span class="math math-inline">\frac{\partial f_{plan}}{\partial x_{perc}} \gg 1</span>), 아주 작은 센서 노이즈나 인식 실패도 제어 단계에서는 재앙적인 물리적 충돌로 이어질 수 있음을 수식적으로 보여준다. 이는 고전적 파이프라인이 왜 그토록 정밀한 센서와 캘리브레이션에 집착할 수밖에 없었는지를 설명한다.</p>
<h2>5. 참고 자료</h2>
<ol>
<li>Robot Control Architectures - Semantic Scholar, https://pdfs.semanticscholar.org/a621/723d1f3d27539c0e9094fcfa8d1e9bbda7b2.pdf</li>
<li>Robotic Paradigms and Control Architectures, https://cw.fel.cvut.cz/b221/_media/courses/crl-courses/redcp/crl36redcp-lec02-slides.pdf</li>
<li>Lessons for Robotics From the Control Architecture of the Octopus - Frontiers, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2022.862391/full</li>
<li>[Hello World!] Sense — Plan — Act | by StreetDrone - Medium, https://medium.com/streetdrone/hello-world-sense-plan-act-aa5772e93344</li>
<li>Structured control for autonomous robots - Robotics and Automation, IEEE Transactions on, http://www.cs.cmu.edu/afs/cs/user/reids/www/papers/structured.pdf</li>
<li>11.4. Motion Control with Torque or Force Inputs (Part 3 of 3) – Modern Robotics, https://modernrobotics.northwestern.edu/nu-gm-book-resource/11-4-motion-control-with-torque-or-force-inputs-part-3-of-3/</li>
<li>An integrative review of control strategies in robotics - Extrica, https://www.extrica.com/article/25014</li>
<li>Full text of “( Writing Science) Friedrich Kittler Gramophone, Film, Typewriter Stanford University Press ( 1999)” - Internet Archive, <a href="https://archive.org/stream/WritingScienceFriedrichKittlerGramophoneFilmTypewriterStanfordUniversityPress1999/(Writing%20Science)%20Friedrich%20Kittler-Gramophone%2C%20Film%2C%20Typewriter-Stanford%20University%20Press%20(1999)_djvu.txt">https://archive.org/stream/WritingScienceFriedrichKittlerGramophoneFilmTypewriterStanfordUniversityPress1999/%28Writing%20Science%29%20Friedrich%20Kittler-Gramophone%2C%20Film%2C%20Typewriter-Stanford%20University%20Press%20%281999%29_djvu.txt</a></li>
<li>The Difficulties in Symbol Grounding Problem and the Direction for Solving It - MDPI, https://www.mdpi.com/2409-9287/7/5/108</li>
<li>Relevance of Classical Algorithms in Modern Autonomous Driving Architectures - YouTube, https://www.youtube.com/watch?v=sWJ8t0Bphlk</li>
<li>A Crash Course of Planning for Perception Engineers in Autonomous Driving | by Patrick Langechuan Liu | The Thinking Car | Medium, https://medium.com/the-thinking-car/a-crash-course-of-planning-for-perception-engineers-in-autonomous-driving-ede324d78717</li>
<li>MODEL BASED ENERGY MANAGEMENT AND STATE ESTIMATION FOR THE ROBOTIC ELECTRIC VEHICLE ROBOMOBIL - mediaTUM, https://mediatum.ub.tum.de/doc/1415807/document.pdf</li>
<li>Online Estimation of Manipulator Dynamics for Computed Torque Control of Robotic Systems - MDPI, https://www.mdpi.com/1424-8220/25/22/6831</li>
<li>(PDF) Neuro-Symbolic Robotics: Capabilities, Limitations, and Challenges - ResearchGate, https://www.researchgate.net/publication/387868208_Neuro-Symbolic_Robotics_Capabilities_Limitations_and_Challenges</li>
<li>Data Driven Algorithms For Perception With Applications To Autonomous Driving, Energy And Mixed Reality - UC Berkeley EECS, https://www2.eecs.berkeley.edu/Pubs/TechRpts/2021/EECS-2021-28.pdf</li>
<li>STATE ESTIMATION FOR ROBOTICS - University of Toronto, http://asrl.utias.utoronto.ca/~tdb/bib/barfoot_ser17.pdf</li>
<li>Hardware, Algorithms, and Applications of the Neuromorphic Vision Sensor: A Review, https://pmc.ncbi.nlm.nih.gov/articles/PMC12526923/</li>
<li>Continuous-Time State Estimation Methods in Robotics: A Survey - arXiv, https://arxiv.org/pdf/2411.03951</li>
<li>Parameter Estimation of Manipulator Robot Dynamics - DSpace@MIT, https://dspace.mit.edu/bitstream/handle/1721.1/106380/967656473-MIT.pdf?sequence=1</li>
<li>An Overview on Visual SLAM: From Tradition to Semantic - MDPI, https://www.mdpi.com/2072-4292/14/13/3010</li>
<li>Combination of SIFT and Canny Edge Detection for Registration Between SAR and Optical Images - ResearchGate, https://www.researchgate.net/publication/347930751_Combination_of_SIFT_and_Canny_Edge_Detection_for_Registration_Between_SAR_and_Optical_Images</li>
<li>Constraint-based Approaches for Robotic Systems: from Computer Vision to Real-Time Robot Control - mediaTUM, https://mediatum.ub.tum.de/doc/1431736/1431736.pdf</li>
<li>Uncertainty-Aware Perception-Based Control for Autonomous Racing - arXiv, https://arxiv.org/html/2508.02494</li>
<li>Path Planning in Unstructured Environments - DiVA portal, http://www.diva-portal.org/smash/get/diva2:1057261/FULLTEXT01.pdf</li>
<li>A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches - arXiv, https://arxiv.org/html/2404.02817v3</li>
<li>PLANNING ALGORITHMS - Steven M. LaValle, https://lavalle.pl/planning/book.pdf</li>
<li>Ch. 6 - Motion Planning - Robotic Manipulation, https://manipulation.csail.mit.edu/trajectories.html</li>
<li>Robotic Motion Planning: RRT’s, https://www.cs.cmu.edu/~motionplanning/lecture/lec20.pdf</li>
<li>Combining Task and Motion Planning: Challenges and Guidelines - Frontiers, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.637888/full</li>
<li>MIT Open Access Articles Learning Symbolic Operators for Task and Motion Planning, https://dspace.mit.edu/bitstream/handle/1721.1/143745/2103.00589.pdf?sequence=2&amp;isAllowed=y</li>
<li>Predictive Control of a Two-Wheeled Balancing Robot: Lab Practice Control Systems, https://ethz.ch/content/dam/ethz/special-interest/mavt/dynamic-systems-n-control/idsc-dam/Lectures/Control-Lab/SigiStudent.pdf</li>
<li>Coupled Error Dynamic Formulation for Modal Control of a Two Link Manipulator having Two Revolute Joints, https://engineeringresearch.org/index.php/GJRE/article/download/101523/16069/32725</li>
<li>(PDF) Latency Overhead of ROS2 for Modular Time-Critical Systems - ResearchGate, https://www.researchgate.net/publication/348295821_Latency_Overhead_of_ROS2_for_Modular_Time-Critical_Systems</li>
<li>Understanding and Mitigating Network Latency Effect on Teleoperated-Robot with Extended Reality - arXiv, https://arxiv.org/html/2506.01135v2</li>
<li>iWalker: Imperative Visual Planning for Walking Humanoid Robot - arXiv, https://arxiv.org/html/2409.18361v4</li>
<li>Bridging the Gap Between Modular and End-to-end Autonomous Driving Systems - UC Berkeley EECS, https://www2.eecs.berkeley.edu/Pubs/TechRpts/2022/EECS-2022-79.pdf</li>
<li>Estimating Perceptual Uncertainty to Predict Robust Motion Plans, https://experts.illinois.edu/en/publications/estimating-perceptual-uncertainty-to-predict-robust-motion-plans/</li>
<li>A Short review of Symbol Grounding in Robotic and Intelligent Systems - DiVA portal, http://www.diva-portal.org/smash/get/diva2:620699/FULLTEXT01.pdf</li>
<li>Symbol grounding problem - Wikipedia, https://en.wikipedia.org/wiki/Symbol_grounding_problem</li>
<li>A Survey of Robotic Language Grounding: Tradeoffs between Symbols and Embeddings, https://arxiv.org/html/2405.13245v2</li>
<li>Grounding Action Words in the Sensorimotor Interaction with the World: Experiments with a Simulated iCub Humanoid Robot - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC2901088/</li>
<li>Bridging the Simulation to Reality Gap in Robotics - Essex Research Repository, https://repository.essex.ac.uk/40339/1/KVasios-PhD.pdf</li>
<li>KiVi: Kinesthetic-Visuospatial Integration for Dynamic and Safe Egocentric Legged Locomotion - arXiv, https://arxiv.org/html/2509.23650v1</li>
<li>A Review of YOLOv12: Attention-Based Enhancements vs. Previous Versions, https://www.researchgate.net/publication/390845812_A_Review_of_YOLOv12_Attention-Based_Enhancements_vs_Previous_Versions</li>
<li>(PDF) Putting An End to End-to-End: Gradient-Isolated Learning of Representations, https://www.researchgate.net/publication/344330404_Putting_An_End_to_End-to-End_Gradient-Isolated_Learning_of_Representations</li>
<li>arXiv:2504.11995v1 [cs.CV] 16 Apr 2025, <a href="https://arxiv.org/pdf/2504.11995">https://arxiv.org/pdf/2504.11995?</a></li>
<li>Fault Tolerant Planning for Critical Robots - LAAS-CNRS, https://homepages.laas.fr/felix/publis-pdf/dsn07.pdf</li>
<li>Odin: Team VictorTango’s Entry in the DARPA Urban Challenge | RoMeLa, <a href="https://www.romela.org/wp-content/uploads/2015/05/Odin-Team-VictorTango%E2%80%99s-Entry-in-the-DARPA-Urban-Challenge.pdf">https://www.romela.org/wp-content/uploads/2015/05/Odin-Team-VictorTango%E2%80%99s-Entry-in-the-DARPA-Urban-Challenge.pdf</a></li>
<li>Winning the DARPA Grand Challenge with an AI Robot. - ResearchGate, https://www.researchgate.net/publication/221605936_Winning_the_DARPA_Grand_Challenge_with_an_AI_Robot</li>
<li>Lessons from the Amazon Picking Challenge: Four Aspects of Building Robotic Systems, https://www.researchgate.net/publication/318830208_Lessons_from_the_Amazon_Picking_Challenge_Four_Aspects_of_Building_Robotic_Systems</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>