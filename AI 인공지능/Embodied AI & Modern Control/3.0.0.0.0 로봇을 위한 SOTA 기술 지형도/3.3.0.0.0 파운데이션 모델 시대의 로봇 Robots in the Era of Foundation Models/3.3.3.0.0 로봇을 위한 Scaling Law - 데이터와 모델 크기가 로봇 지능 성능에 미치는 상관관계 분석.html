<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:3.3.3 로봇을 위한 'Scaling Law': 데이터와 모델 크기가 로봇 지능 성능에 미치는 상관관계 분석</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>3.3.3 로봇을 위한 'Scaling Law': 데이터와 모델 크기가 로봇 지능 성능에 미치는 상관관계 분석</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">인공지능 (Artificial Intelligence, AI)</a> / <a href="../../index.html">제목: Embodied AI & Modern Control</a> / <a href="../index.html">Chapter 3. 로봇을 위한 SOTA 기술 지형도</a> / <a href="index.html">3.3 파운데이션 모델 시대의 로봇 (Robots in the Era of Foundation Models)</a> / <span>3.3.3 로봇을 위한 'Scaling Law': 데이터와 모델 크기가 로봇 지능 성능에 미치는 상관관계 분석</span></nav>
                </div>
            </header>
            <article>
                <h1>3.3.3 로봇을 위한 ‘Scaling Law’: 데이터와 모델 크기가 로봇 지능 성능에 미치는 상관관계 분석</h1>
<h2>1.  서론: 임바디드 AI 시대의 도래와 스케일링 법칙의 재발견</h2>
<p>인공지능(AI) 연구의 역사는 데이터와 연산 자원의 폭발적인 증가가 지능형 시스템의 성능을 어떻게 혁신적으로 변화시키는지를 증명해 온 과정이라 해도 과언이 아니다. 특히 자연어 처리(Natural Language Processing, NLP)와 컴퓨터 비전(Computer Vision, CV) 분야에서 관찰된 ’스케일링 법칙(Scaling Laws)’은 딥러닝 모델의 성능이 모델의 파라미터 수, 학습 데이터의 양, 그리고 투입된 컴퓨팅 자원에 비례하여 멱법칙(Power-law) 분포를 따르며 예측 가능하게 향상된다는 경험적, 이론적 토대를 제공하였다. OpenAI의 GPT 시리즈나 구글의 PaLM과 같은 거대 언어 모델(Large Language Models, LLM)의 성공은 이러한 스케일링 법칙이 단순한 가설이 아니라, 현대 AI 시스템 설계를 관통하는 핵심 공학 원리임을 입증했다.1</p>
<p>그러나 물리적 세계와 직접 상호작용해야 하는 로봇 공학, 즉 ‘임바디드 AI(Embodied AI)’ 분야에서 이러한 스케일링 법칙이 동일하게 적용되는지에 대한 논의는 상대적으로 늦게 시작되었다. 이는 로봇 공학이 직면한 고유의 난제, 즉 ’모라벡의 역설(Moravec’s Paradox)’로 대변되는 물리적 상호작용의 복잡성과 고품질의 로봇 행동 데이터를 수집하는 데 드는 막대한 비용 때문이었다. 텍스트나 이미지 데이터가 인터넷상에 무한히 존재하는 것과 달리, 로봇 데이터는 물리적 실행을 통해 수집되어야 하므로 데이터의 희소성이 스케일링의 주된 병목으로 작용해 왔다.1</p>
<p>하지만 최근 ’로봇 파운데이션 모델(Robot Foundation Models, RFM)’의 등장과 범용 로봇 데이터셋 구축을 위한 글로벌 협력은 이러한 상황을 급격히 변화시키고 있다. 본 장에서는 로봇 지능의 성능이 모델의 크기와 데이터의 규모에 따라 어떻게 변화하는지를 정량적, 정성적으로 분석한다. 특히, 단순히 데이터가 많아지면 성능이 좋아진다는 일차원적인 결론을 넘어, 로봇 도메인에서의 스케일링 계수가 언어 도메인과 어떻게 다르며, 특정 임계점을 넘었을 때 발생하는 ’창발적 능력(Emergent Capabilities)’이 로봇의 범용성(Generalization)과 추론(Reasoning) 능력에 어떤 혁신을 가져오는지 심층적으로 고찰한다.</p>
<p>우리는 먼저 스케일링 법칙의 이론적 배경과 수식적 정의를 로봇 공학의 관점에서 재해석하고, RT-1, RT-2, PaLM-E와 같은 최신 모델들의 사례를 통해 모델 크기(Model Size)가 물리적 추론 능력에 미치는 영향을 분석할 것이다. 이어 Open X-Embodiment 프로젝트로 대표되는 대규모 데이터 스케일링이 교차 형태(Cross-Embodiment) 전이 학습에 미치는 효과를 살펴보고, 마지막으로 이러한 스케일링이 로봇의 미래 지능에 시사하는 바를 논의한다.</p>
<h2>2.  임바디드 AI를 위한 신경 스케일링 법칙의 이론적 프레임워크</h2>
<h3>2.1 스케일링 법칙의 수학적 정의와 로봇 도메인으로의 확장</h3>
<p>신경 스케일링 법칙은 딥러닝 모델의 테스트 손실(Test Loss) <span class="math math-inline">L</span>이 모델의 크기 <span class="math math-inline">N</span>, 데이터셋의 크기 <span class="math math-inline">D</span>, 그리고 컴퓨팅 자원 <span class="math math-inline">C</span>와 멱법칙 관계를 형성한다는 원리이다. 이는 Kaplan et al. (2020)의 연구에서 처음 체계화되었으며, 다음과 같은 일반적인 수식으로 표현될 수 있다.1<br />
<span class="math math-display">
L(N, D) \approx \frac{A}{N^\alpha} + \frac{B}{D^\beta} + E
</span><br />
여기서 <span class="math math-inline">A, B, E</span>는 상수이며, <span class="math math-inline">\alpha</span>와 <span class="math math-inline">\beta</span>는 각각 모델 크기와 데이터 크기에 대한 스케일링 지수(Scaling Exponent)를 나타낸다. <span class="math math-inline">E</span>는 모델이 도달할 수 있는 최소한의 기약 오차(Irreducible Error)를 의미한다. 이 수식은 자원이 지수적으로(<span class="math math-inline">10^x</span>) 증가할 때 성능 오차는 선형적으로 감소함을 시사한다.</p>
<p>로봇 공학에서 이 법칙을 적용하기 위한 시도는 Sartor와 Thompson(2024)의 대규모 메타 분석 연구를 통해 구체화되었다. 그들은 327개 이상의 로봇 학습 관련 논문을 분석하여 로봇 파운데이션 모델(RFM) 역시 이러한 멱법칙 관계를 따름을 확인했다.3 그러나 로봇 도메인은 입력 데이터가 텍스트와 같은 이산적(Discrete) 심볼이 아니라, 연속적(Continuous)인 센서 데이터와 관절 제어 신호로 구성된다는 점에서 독특한 스케일링 특성을 보인다.</p>
<h3>2.2 로봇과 타 도메인(NLP, Vision)의 스케일링 계수 비교 분석</h3>
<p>로봇 공학에서의 스케일링 법칙은 NLP보다는 컴퓨터 비전(Computer Vision)의 특성과 더 유사한 패턴을 보인다. 이는 로봇의 행동 생성이 본질적으로 시각적 인식(Visual Perception)에 기반하기 때문이다. 그러나 더욱 흥미로운 점은 로봇 작업에서의 성능 개선 속도가 언어 작업보다 더 가파르다는 연구 결과이다.</p>
<p>아래 표는 각 도메인별 스케일링 특성을 비교 분석한 것이다.</p>
<table><thead><tr><th><strong>도메인</strong></th><th><strong>주요 입력 양식</strong></th><th><strong>스케일링 특성 (Scaling Behavior)</strong></th><th><strong>데이터 효율성 및 특징</strong></th></tr></thead><tbody>
<tr><td><strong>자연어 처리 (NLP)</strong></td><td>텍스트 (이산적 토큰)</td><td>완만한 멱법칙 (<span class="math math-inline">\alpha_{NLP} \approx 0.076</span>)</td><td>데이터가 풍부하여 데이터 스케일링이 용이함. 문맥 이해와 구문론적 패턴 학습에 집중됨. 4</td></tr>
<tr><td><strong>컴퓨터 비전 (CV)</strong></td><td>이미지 (연속적 픽셀)</td><td>중간 멱법칙</td><td>이미지 해상도와 데이터셋 다양성에 민감함. 로봇 시각 처리의 기반이 됨.</td></tr>
<tr><td><strong>로봇 공학 (Robotics)</strong></td><td>이미지 + 상태 + 행동</td><td><strong>가파른 멱법칙 (<span class="math math-inline">\alpha_{Robot} &gt; \alpha_{NLP}</span>)</strong></td><td>초기 성능은 낮으나 자원 투입 대비 성능 향상 폭이 큼. 물리적 상호작용의 복잡성으로 인해 모델 용량이 커질수록 ’이해’의 깊이가 급격히 깊어짐. 1</td></tr>
</tbody></table>
<p>Sartor와 Thompson의 연구에 따르면, 로봇 모델의 성능 향상 기울기가 언어 모델보다 가파르다는 것은 현재 로봇 AI의 성능이 다소 미흡하더라도, 향후 데이터와 연산 자원이 대규모로 투입될 경우 언어 모델이 보여준 것 이상의 비약적인 성능 향상을 기대할 수 있음을 시사한다.5 이는 로봇의 물리적 제어 공간이 언어의 의미론적 공간보다 훨씬 고차원적이고 복잡하기 때문에, 초기 학습에는 많은 자원이 필요하지만 일정 수준을 넘어서면 물리 법칙과 인과 관계를 모델이 내재화하면서 성능이 급격히 개선되는 것으로 해석된다.</p>
<h3>2.3 작업 복잡도(Task Complexity)와 스케일링 효율성</h3>
<p>로봇 스케일링 법칙에서 고려해야 할 또 다른 중요한 변수는 ’작업의 복잡도’이다. 단순한 ’집어 옮기기(Pick-and-Place)’와 같은 익숙한 작업(Familiar Tasks)은 비교적 작은 모델과 적은 데이터로도 빠르게 성능이 포화되는 경향을 보인다. 반면, 물체의 물성을 고려해야 하거나, 방해물(Distractor)이 많은 낯선 환경(Unseen Environment)에서의 작업과 같은 낯선 작업(Unfamiliar Tasks)은 스케일링의 효과가 훨씬 더 뚜렷하게 나타난다.4</p>
<p>즉, 복잡하고 낯선 작업을 수행하기 위해서는 단순히 알고리즘을 개선하는 것보다, 모델의 크기를 키우고 더 다양하고 방대한 데이터를 학습시키는 것이 훨씬 효과적인 전략이 된다. 이는 “The Bitter Lesson“에서 리치 서튼(Rich Sutton)이 주장한 바와 같이, 인간의 지식을 하드코딩하려는 시도보다 일반적인 학습 방법론에 대규모 연산을 투입하는 것이 장기적으로 승리한다는 원칙이 로봇 공학에서도 유효함을 강력하게 지지한다.1</p>
<h2>3.  모델 크기(Model Size)와 로봇 지능의 상관관계: 용량(Capacity)이 만드는 질적 차이</h2>
<p>모델의 파라미터 수, 즉 모델 크기(Model Size)는 로봇이 습득할 수 있는 지식의 총량과 추론의 깊이를 결정짓는 핵심 요소이다. 과거의 로봇 제어 모델들은 수백만 개 수준의 파라미터를 가진 경량 네트워크(예: ResNet-50)에 의존했으나, 최근에는 수백억, 수천억 개의 파라미터를 가진 거대 모델들이 도입되면서 로봇 지능의 패러다임이 바뀌고 있다.</p>
<h3>3.1 RT-1: 트랜스포머 아키텍처 도입과 초기 스케일링의 한계</h3>
<p>RT-1(Robotics Transformer 1)은 로봇 제어에 트랜스포머 아키텍처를 본격적으로 도입하여 스케일링의 가능성을 탐색한 초기 모델이다. RT-1은 약 3,500만 개의 파라미터를 가진 EfficientNet-B3를 비전 백본으로 사용하고, 이를 토큰화하여 트랜스포머에 입력하는 구조를 채택했다.6</p>
<p>구글 딥마인드 팀은 RT-1 개발 과정에서 모델 크기와 데이터 크기에 따른 일반화 성능을 실험했다. 연구 결과, 모델의 크기가 커질수록 실세계 작업(Real-world tasks)의 성공률이 향상되는 경향을 보였으나, 특정 수준 이상에서는 성능 향상이 둔화되는 현상이 관찰되었다. 이는 RT-1이 학습한 데이터가 로봇의 물리적 궤적 데이터에만 국한되어 있어, 모델의 용량을 키워도 학습할 수 있는 ’지식’의 범위가 제한적이었기 때문으로 분석된다.7 RT-1은 훈련 데이터에 포함되지 않은 새로운 물체나 추상적인 명령을 이해하는 데에는 명확한 한계를 보였다.</p>
<h3>3.2 RT-2와 PaLM-E: VLM 기반의 거대 모델과 창발성(Emergence)</h3>
<p>RT-1의 한계를 극복하기 위해 등장한 RT-2와 PaLM-E는 인터넷 규모의 텍스트와 이미지 데이터로 사전 학습된 거대 비전-언어 모델(Vision-Language Model, VLM)을 로봇 제어의 백본(Backbone)으로 활용한다. 이 접근법은 모델 크기를 획기적으로 키움으로써 로봇 지능의 질적 도약을 이끌어냈다.</p>
<h4>3.2.1  RT-2 (Vision-Language-Action): 행동을 언어처럼 토큰화하다</h4>
<p>RT-2는 로봇의 행동(Action)을 텍스트 토큰과 동일한 방식으로 처리하는 ‘비전-언어-행동(VLA)’ 모델이다. RT-2는 120억 파라미터(12B)의 PaLM-E와 550억 파라미터(55B)의 PaLI-X를 기반으로 구축되었으며, 이 두 모델의 크기 차이에 따른 성능 비교는 스케일링 법칙의 효과를 명확히 보여준다.8</p>
<ul>
<li><strong>일반화 성능의 비약적 향상:</strong> RT-2 PaLI-X 55B 모델은 50억 파라미터(5B) 모델 대비 일반화 성능이 약 2배 향상되었다. 특히 훈련 데이터에 없는 새로운 물체(Novel Objects)나 배경(Novel Backgrounds)에서의 작업 성공률에서 큰 격차를 보였다.10</li>
<li><strong>창발적 능력의 발현:</strong> 가장 주목할 만한 점은 모델 크기가 커짐에 따라 ’창발적 능력’이 발현된다는 것이다. 55B 모델은 “멸종된 동물을 집어라(Pick up the extinct animal)“라는 명령을 받았을 때, 로봇 데이터셋에는 없는 ’멸종 동물’이라는 개념과 시각적 인식(공룡 인형)을 연결하여 올바른 행동을 수행했다. 반면, 작은 모델들은 이러한 추론을 수행하지 못했다.11</li>
<li><strong>미묘한 언어적 뉘앙스 구분:</strong> RT-2-X 실험에서 55B 모델은 “사과를 천 <em>위에(on)</em> 놓아라“와 “사과를 천 <em>근처에(near)</em> 놓아라“와 같은 미세한 전치사의 차이를 구별하여 서로 다른 궤적을 생성할 수 있었다. 이는 작은 모델에서는 불가능했던 정교한 언어-행동 정렬(Alignment) 능력이다.12</li>
</ul>
<h4>3.2.2  PaLM-E (Embodied Multimodal Language Model): 규모가 가져오는 긍정적 전이</h4>
<p>PaLM-E는 최대 5,620억(562B) 파라미터까지 확장된 세계 최대 규모의 임바디드 모델이다. 이는 5,400억 파라미터의 PaLM 언어 모델에 220억 파라미터의 비전 트랜스포머(ViT)를 결합한 형태이다.13</p>
<ul>
<li><strong>파국적 망각(Catastrophic Forgetting)의 방지:</strong> 일반적으로 모델을 특정 도메인(로봇)에 대해 미세 조정(Fine-tuning)하면 기존의 일반 지식(언어 능력)을 잊어버리는 현상이 발생한다. 그러나 PaLM-E 연구 결과, 모델의 크기가 커질수록 이러한 망각 현상이 급격히 줄어들었다. 562B 모델은 로봇 조작 능력을 습득하면서도 시각적 질의응답(VQA)이나 일반 상식 추론 능력을 거의 완벽하게 유지했다.15</li>
<li><strong>다중 모달리티 간의 긍정적 전이(Positive Transfer):</strong> 거대 모델은 시각, 언어, 로봇 센서 데이터 등 서로 다른 모달리티의 정보를 하나의 임베딩 공간에서 통합하여 처리한다. 이 과정에서 인터넷 데이터에서 배운 ’상식’이 로봇의 ‘물리적 행동’ 학습을 돕는 긍정적 전이 현상이 발생한다. 예를 들어, 인터넷에서 ’스펀지는 가볍고 부드럽다’는 지식을 배운 거대 모델은 로봇이 스펀지를 집을 때 힘을 조절해야 한다는 것을 더 적은 데이터로도 학습할 수 있게 된다.16</li>
</ul>
<h3>3.3 모델 스케일링의 한계와 효율성 트레이드오프</h3>
<p>모델 크기를 키우는 것이 성능 향상의 만능열쇠처럼 보이지만, 로봇 공학에는 ’실시간성(Real-time Constraints)’이라는 결정적인 제약이 존재한다.</p>
<ul>
<li><strong>추론 속도(Inference Speed) 문제:</strong> RT-2-PaLI-X 55B 모델은 강력한 성능을 보이지만, 거대한 연산량으로 인해 추론 속도가 1~3Hz(초당 1~3회 제어) 수준으로 제한된다. 이는 고속으로 움직이는 물체를 잡거나 동적인 환경에 반응하기에는 부족한 속도이다.9 반면, 5B 모델은 5Hz 정도의 속도를 낼 수 있어 실시간 제어에 더 유리하다.</li>
<li><strong>토큰 압축 기술의 필요성:</strong> 이를 해결하기 위해 RT-1에서는 ’TokenLearner’와 같은 기술을 도입하여 이미지 정보를 적은 수의 핵심 토큰으로 압축, 추론 속도를 2.4배 이상 향상시켰다.6 향후 스케일링 법칙을 로봇에 적용하기 위해서는 모델 크기를 키우면서도 추론 효율성을 유지할 수 있는 희소 모델(Sparse Models), 양자화(Quantization), 증류(Distillation) 기술이 필수적으로 동반되어야 한다.</li>
</ul>
<h2>4.  데이터 크기(Data Size)와 다양성: Open X-Embodiment 패러다임</h2>
<p>Sartor와 Thompson의 메타 분석에 따르면, 로봇 지능 성능은 데이터셋의 크기와 다양성에 대해 멱법칙을 따르며 향상된다. 특히 로봇 공학에서는 데이터의 절대적인 양(Quantity)뿐만 아니라, 데이터가 포함하는 환경, 물체, 작업의 다양성(Diversity)이 스케일링 효과를 결정짓는 핵심 변수이다.</p>
<h3>4.1 데이터 희소성 문제와 Open X-Embodiment 프로젝트</h3>
<p>기존의 로봇 연구는 특정 실험실에서, 특정 로봇 하드웨어로, 제한된 작업만을 수행한 데이터를 사용하여 모델을 학습시켰다. 이러한 방식은 ‘데이터 사일로(Data Silo)’ 현상을 야기하여, 범용적인 로봇 모델 탄생을 가로막는 주된 원인이 되었다. 이를 해결하기 위해 구글 딥마인드와 전 세계 33개 연구소는 ‘Open X-Embodiment’ 프로젝트를 통해 로봇 데이터의 ’ImageNet 모멘트’를 실현하고자 했다.17</p>
<ul>
<li><strong>데이터 규모와 구성:</strong> 이 프로젝트는 22종의 서로 다른 로봇 형태(Single-arm, Dual-arm, Mobile Manipulator 등), 527개 이상의 기술(Skills), 그리고 100만 개 이상의 에피소드를 포함하는 단일 데이터셋을 구축했다.17</li>
<li><strong>데이터 다양성의 중요성:</strong> 데이터셋에는 16만 개 이상의 작업(Tasks)이 포함되어 있으며, 이는 단순한 반복 작업이 아니라 다양한 물체와 환경에서의 상호작용을 포괄한다. 연구 결과, 데이터의 다양성이 확보될 때 모델은 특정 환경에 과적합(Overfitting)되지 않고 일반화 능력을 획득하는 것으로 나타났다.</li>
</ul>
<h3>4.2 교차 형태(Cross-Embodiment) 학습과 긍정적 전이</h3>
<p>Open X-Embodiment 데이터셋을 활용한 RT-X 모델의 실험 결과는 데이터 스케일링이 가져오는 ’교차 형태 전이(Cross-Embodiment Transfer)’의 강력함을 입증한다.</p>
<ol>
<li><strong>RT-1-X의 성능 향상:</strong> 다양한 로봇의 데이터를 혼합하여 학습한 RT-1-X 모델은 특정 로봇의 데이터로만 학습된 원본 모델 대비 평균 50% 높은 성공률을 기록했다.11 이는 로봇 A의 데이터가 로봇 B의 학습에 도움을 줄 수 있음을 의미한다. 예를 들어, ‘물체를 잡는’ 기본적인 물리적 상호작용의 원리는 로봇 팔의 형태가 달라도 공유될 수 있기 때문이다.</li>
<li><strong>데이터 부족 로봇에 대한 혜택:</strong> 데이터가 충분한 로봇(Data-rich robots)보다는 데이터가 부족한 로봇(Data-scarce robots)이 대규모 데이터셋 학습의 혜택을 더 크게 입는 것으로 나타났다. 이는 거대 데이터셋이 일종의 ‘지식의 저수지’ 역할을 하여, 경험이 부족한 로봇에게 일반적인 조작 기술을 전수해주기 때문이다.</li>
<li><strong>구조적 이질성의 극복:</strong> 서로 다른 로봇은 관절(DoF)의 수나 동작 방식이 다르다. RT-X는 이러한 이질성을 극복하기 위해 행동 공간(Action Space)을 통일하거나, 각 로봇의 형태 정보를 임베딩(Embedding)하여 모델에 주입하는 방식을 사용한다.19 이를 통해 모델은 다양한 로봇의 신체적 특징을 구분하면서도 공통된 작업 수행 능력을 학습한다.</li>
</ol>
<h3>4.3 시뮬레이션 데이터와 현실 데이터의 통합</h3>
<p>현실 데이터만으로는 스케일링의 한계가 존재하기 때문에, 시뮬레이션 데이터를 활용한 스케일링 연구도 병행되고 있다.</p>
<ul>
<li><strong>Sim-to-Real 스케일링:</strong> 수백만 건의 시뮬레이션 에피소드를 학습한 모델이 현실 세계에서 높은 성공률을 보이는 사례들이 보고되고 있다. 시뮬레이션 데이터는 무한히 생성 가능하므로, 데이터 크기에 대한 스케일링 법칙을 검증하고 모델의 기본기를 다지는 데 유용하다.21</li>
<li><strong>Real-to-Sim-to-Real:</strong> 현실 데이터를 바탕으로 시뮬레이션 환경을 구축(Digital Twin)하고, 여기서 대규모 데이터를 생성하여 다시 현실 로봇을 학습시키는 순환적 파이프라인이 제안되고 있다. 이는 데이터의 양적 팽창을 가능하게 하여 스케일링 곡선을 지속적으로 우상향하게 만드는 동력이 된다.</li>
</ul>
<h3>4.4 데이터 스케일링의 멱법칙 특성 분석</h3>
<p>RT-2 논문의 분석에 따르면, 데이터 크기에 따른 성능 향상은 수확 체감(Diminishing Returns)의 법칙을 따르지만, 여전히 로그-선형(Log-linear) 관계를 유지한다.5</p>
<ul>
<li><strong>익숙한 작업 vs. 낯선 작업:</strong> 익숙한 환경에서의 작업 성능은 적은 데이터 추가로도 빠르게 90% 이상의 성공률에 도달하며 포화된다. 그러나 낯선 환경이나 새로운 물체에 대한 대응 능력은 데이터 양이 지수적으로 증가해야 선형적으로 향상된다. 즉, 범용성을 확보하기 위해서는 기하급수적으로 많은 데이터가 필요하다.</li>
<li><strong>공동 미세 조정(Co-fine-tuning)의 비율:</strong> VLA 모델 학습 시, 로봇 데이터와 웹 데이터(VQA 등)의 혼합 비율이 성능에 중요한 영향을 미친다. 웹 데이터는 ’상식’과 ’추론’을, 로봇 데이터는 ’물리적 행동’을 담당한다. 실험 결과, 로봇 데이터와 웹 데이터의 비율을 적절히 조절했을 때(예: RT-2에서는 로봇 데이터의 가중치를 높임) 로봇의 물리적 조작 능력과 의미론적 추론 능력이 동시에 극대화됨이 확인되었다.23</li>
</ul>
<h2>5.  창발적 능력(Emergent Capabilities)과 의미론적 추론</h2>
<p>스케일링 법칙의 가장 매력적인 결과는 모델과 데이터가 특정 임계점을 넘었을 때, 이전에는 관찰되지 않았던 새로운 능력들이 갑자기 나타나는 ’창발성(Emergence)’이다. 로봇 공학에서 이는 단순한 동작 수행을 넘어, 인간의 의도를 해석하고 상황을 추론하여 창의적으로 행동하는 능력으로 발현된다.</p>
<h3>5.1 사고의 사슬(Chain-of-Thought) 추론과 로봇 행동</h3>
<p>대규모 언어 모델에서 관찰되던 ‘사고의 사슬(Chain-of-Thought, CoT)’ 추론 능력이 VLA 모델을 통해 로봇 행동 생성에도 적용되고 있다.</p>
<ul>
<li><strong>실험적 증거:</strong> RT-2 연구에서 “내가 지금 피곤한데 어떤 음료를 마셔야 할까?“라는 질문을 로봇에게 던졌을 때, 로봇은 바로 물건을 집는 대신 “사람이 피곤하다 -&gt; 에너지가 필요하다 -&gt; 에너지 드링크가 적절하다“라는 중간 추론 과정을 거쳐 에너지 드링크를 선택했다.10</li>
<li><strong>성능 비교:</strong> 이러한 CoT 능력을 활용했을 때, 복잡한 다단계 추론이 필요한 작업의 성공률이 비약적으로 상승했다. PaLM-E 실험에서도 시각적 정보를 바탕으로 한 CoT(“Visual Chain-of-Thought”)가 로봇의 장기 계획(Long-horizon Planning) 능력을 향상시킴이 확인되었다.16</li>
</ul>
<h3>5.2 의미론적 지식과 물리적 행동의 연결</h3>
<p>창발적 능력은 웹 스케일 데이터에서 학습된 의미론적 지식(Semantic Knowledge)이 로봇의 물리적 행동(Physical Action)과 정렬될 때 극대화된다.</p>
<ul>
<li><strong>즉석 도구 사용(Improvised Tool Use):</strong> “못을 박아야 하는데 망치가 없다“는 상황에서, 로봇은 주변에 있는 ’돌’을 집어 망치 대용으로 사용하는 능력을 보여주었다. 이는 로봇 데이터셋에는 없는 내용이며, 웹 데이터에서 ‘돌은 단단하고 무겁다’, ’망치 대신 단단한 물체를 쓸 수 있다’는 지식을 전이받아 물리적 행동으로 구현한 사례이다.10</li>
<li><strong>추상적 상징 이해:</strong> “Taylor Swift를 틀어줘“라는 명령에 로봇이 ’음표 모양의 아이콘’이 그려진 물체를 선택하거나, “가장 작은 물체를 가장 큰 물체 위에 올려라“와 같은 상대적 개념을 이해하고 수행하는 능력 또한 모델 스케일링을 통해 획득된 창발적 능력이다.</li>
</ul>
<h3>5.3 창발성 발현을 위한 조건</h3>
<p>이러한 능력은 모든 모델에서 나타나는 것이 아니다. 연구 결과에 따르면, 모델의 파라미터가 적어도 수백억 개(예: PaLI-X 55B, PaLM-E 12B 이상) 이상이어야 하며, 학습 데이터 역시 충분한 다양성을 갖추어야 한다. 작은 모델들은 단순히 명령을 텍스트로 매칭하는 수준에 그치지만, 거대 모델은 명령의 ’의도’를 파악하고 시각적 정보와 결합하여 유연한 행동 전략을 수립한다.16 이는 로봇 지능의 발전이 선형적인 개선이 아니라, 어느 순간 계단식으로 도약(Phase Transition)할 것임을 암시한다.</p>
<h2>6.  결론 및 시사점: 범용 로봇 지능을 향한 길</h2>
<p>본 장의 분석을 통해 우리는 데이터와 모델 크기가 로봇 지능 성능에 미치는 영향이 단순한 상관관계를 넘어, 로봇의 지능적 한계를 돌파하는 핵심 동력임을 확인할 수 있었다.</p>
<p><strong>핵심 요약:</strong></p>
<ol>
<li><strong>가파른 스케일링 곡선:</strong> 로봇 공학에서의 스케일링 법칙은 언어 모델보다 더 가파른 성능 향상 기울기를 보인다. 이는 로봇 분야가 데이터와 연산 자원의 투입에 대해 매우 높은 잠재적 수익률(Return on Investment)을 가지고 있음을 의미한다.</li>
<li><strong>모델 크기와 지능의 깊이:</strong> 모델의 크기를 키우는 것은 단순히 기억 용량을 늘리는 것이 아니라, 복잡한 추론과 창발적 능력을 발현시키기 위한 필수 조건이다. RT-2와 PaLM-E의 사례는 거대 모델만이 물리적 세계의 복잡성을 이해하고 유연하게 대처할 수 있음을 증명했다.</li>
<li><strong>데이터 다양성의 승리:</strong> Open X-Embodiment 프로젝트는 단일 로봇의 대량 데이터보다, 다기종 로봇의 다양한 데이터가 범용 모델(Generalist Model) 구축에 훨씬 효과적임을 입증했다. ’교차 형태 전이’는 데이터 희소성 문제를 해결할 가장 강력한 열쇠이다.</li>
<li><strong>VLA 패러다임의 확립:</strong> 시각, 언어, 행동을 통합한 VLA 모델은 인터넷의 지식을 로봇의 행동으로 변환하는 가장 효율적인 아키텍처로 자리 잡았다.</li>
</ol>
<p>미래 전망:</p>
<p>향후 로봇 연구는 “더 큰 모델, 더 많은 데이터“라는 스케일링 법칙의 기본 원칙을 따르면서도, 현실적인 제약을 극복하기 위한 기술적 진보를 병행할 것이다. 실시간 추론을 위한 효율화 기술, 시뮬레이션과 현실을 오가는 하이브리드 데이터 파이프라인, 그리고 로봇의 행동 안전성을 보장하는 정렬(Alignment) 기술이 결합될 때, 우리는 실험실을 벗어나 일상생활에서 인간과 공존하며 복잡한 임무를 수행하는 진정한 의미의 ’범용 로봇(General Purpose Robot)’을 마주하게 될 것이다.</p>
<p>다음 표는 본 장에서 논의된 주요 로봇 파운데이션 모델들의 스케일링 특성과 성과를 요약한 것이다.</p>
<h3>6.1 표 3.3.3-1 주요 로봇 파운데이션 모델의 스케일링 특성 및 성과 요약</h3>
<table><thead><tr><th><strong>모델명</strong></th><th><strong>기반 모델 (Backbone)</strong></th><th><strong>파라미터 수</strong></th><th><strong>학습 데이터 특징</strong></th><th><strong>주요 스케일링 성과 및 특징</strong></th><th><strong>출처</strong></th></tr></thead><tbody>
<tr><td><strong>RT-1</strong></td><td>EfficientNet-B3 + Transformer</td><td>~35M</td><td>130k 에피소드 (로봇 전용)</td><td>데이터 다양성 증가 시 일반화 성능 향상, 그러나 지식 범위의 한계로 성능 포화 관찰됨.</td><td>6</td></tr>
<tr><td><strong>RT-2</strong></td><td>PaLM-E, PaLI-X</td><td>12B ~ 55B</td><td>로봇 데이터 + 웹 스케일 VQA 데이터</td><td>창발적 추론 능력 발현 (예: 추상적 명령 수행). 55B 모델이 5B 모델 대비 미본 작업(Unseen Task) 성능 2~3배 우수.</td><td>10</td></tr>
<tr><td><strong>PaLM-E</strong></td><td>PaLM + ViT</td><td>562B</td><td>인터넷 언어/비전 + 로봇 센서 데이터</td><td>언어 능력을 유지하며 로봇 작업 학습(Catastrophic Forgetting 방지). 멀티모달 긍정적 전이 효과 입증.</td><td>13</td></tr>
<tr><td><strong>RT-X</strong></td><td>RT-1, RT-2 기반</td><td>가변적</td><td>22종 로봇, 1M+ 에피소드 (Open X)</td><td>교차 형태(Cross-Embodiment) 일반화 달성. 단일 로봇 모델 대비 평균 50% 성능 향상.</td><td>11</td></tr>
</tbody></table>
<p>이 분석은 집필 중인 서적의 독자들에게 AI 로봇 공학의 최전선에서 벌어지고 있는 거대 모델 경쟁의 현황과 그 과학적 근거를 명확히 전달하며, 로봇 지능의 미래가 하드웨어의 개선뿐만 아니라 데이터와 모델이라는 소프트웨어적 자원의 거대한 확장에 달려 있음을 시사하는 중요한 이정표가 될 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Neural Scaling Laws in Robotics - arXiv, https://arxiv.org/html/2405.14005v2</li>
<li>Neural Scaling Laws for Embodied AI - arXiv, https://arxiv.org/html/2405.14005v1</li>
<li>[2405.14005] Neural Scaling Laws in Robotics - arXiv, https://arxiv.org/abs/2405.14005</li>
<li>Neural Scaling Laws for Embodied AI - ResearchGate, https://www.researchgate.net/publication/380821116_Neural_Scaling_Laws_for_Embodied_AI</li>
<li>Neural Scaling Laws in Robotics (2405.14005v2) - Emergent Mind, https://www.emergentmind.com/papers/2405.14005</li>
<li>RT-1: Robotics Transformer for real-world control at scale, https://research.google/blog/rt-1-robotics-transformer-for-real-world-control-at-scale/</li>
<li>RT-1: Robotics Transformer for Real-World Control at Scale - arXiv, https://arxiv.org/abs/2212.06817</li>
<li>Vision Language Action Models (VLA) &amp; Policies for Robots, https://learnopencv.com/vision-language-action-models-lerobot-policy/</li>
<li>RT-2: Vision-Language-Action Models Transfer Web Knowledge to …, https://www.cs.utexas.edu/~yukez/cs391r_fall2023/slides/pre_10-24_Ming.pdf</li>
<li>RT-2: Vision-Language-Action Models, https://robotics-transformer2.github.io/</li>
<li>Open X-Embodiment: Robotic Learning Datasets and RT-X Models, https://www.robot-learning.ml/2023/files/paper18.pdf</li>
<li>Open X-Embodiment: Towards a generic robot learning | AI-SCHOLAR, https://ai-scholar.tech/en/articles/robot%2Fopen-x-embodiment</li>
<li>PaLM-E: An Embodied Multimodal Language Model, https://palm-e.github.io/</li>
<li>PaLM-E: An Embodied Multimodal Language Model, https://proceedings.mlr.press/v202/driess23a/driess23a.pdf</li>
<li>[Quick Review] PaLM-E: An Embodied Multimodal Language Model, https://liner.com/review/palme-embodied-multimodal-language-model</li>
<li>PaLM-E: An embodied multimodal language model, https://research.google/blog/palm-e-an-embodied-multimodal-language-model/</li>
<li>Scaling up learning across many different robot types, https://deepmind.google/blog/scaling-up-learning-across-many-different-robot-types/</li>
<li>1월 4, 2026에 액세스, https://arxiv.org/html/2310.08864v4</li>
<li>Align-Then-stEer: Adapting the Vision-Language Action Models …, https://arxiv.org/html/2509.02055v1</li>
<li>X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment …, https://chatpaper.com/paper/198923</li>
<li>Data Scaling Laws in Imitation Learning for Robotic Manipulation, https://data-scaling-laws.github.io/</li>
<li>Krish Mehta, https://djkesu.com/</li>
<li>(PDF) RT-2: Vision-Language-Action Models Transfer Web …, https://www.researchgate.net/publication/372784419_RT-2_Vision-Language-Action_Models_Transfer_Web_Knowledge_to_Robotic_Control</li>
<li>GitHub - kyegomez/RT-2: Democratization of RT-2 “RT-2, https://github.com/kyegomez/RT-2</li>
<li>RT-2: New model translates vision and language into action, https://deepmind.google/blog/rt-2-new-model-translates-vision-and-language-into-action/</li>
<li>RT-2: Vision-Language-Action Models Transfer Web Knowledge to …, https://robotics-transformer2.github.io/assets/rt2.pdf</li>
<li>Emergent Abilities in LLMs, https://www.emergentmind.com/topics/emergent-abilities-of-large-language-models</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>