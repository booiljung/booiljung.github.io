# 3D 포인트 클라우드 특징점 알고리즘
[특징점 기술](./index.md)



3D 포인트 클라우드 데이터는 자율 주행, 로보틱스, 증강 현실, 디지털 트윈 등 현대 기술의 다양한 분야에서 핵심적인 역할을 수행한다. 이러한 방대한 3차원 데이터로부터 의미 있는 정보를 추출하는 과정에서 특징점(Keypoint)과 특징 기술자(Feature Descriptor)는 가장 근본적인 구성 요소로 작용한다. 특징점 기반 접근법의 핵심 철학은, 수백만 개에 달하는 전체 포인트 클라우드를 직접 처리하는 대신, 정보량이 풍부하고 반복적으로 탐지 가능한 소수의 '중요한' 지점들을 식별하고, 이 지점들 주변의 국소적인 기하학적 정보를 고유한 벡터로 기술하는 것이다.1 이 전략은 계산의 복잡성을 극적으로 감소시키면서도, 객체 인식, 3차원 모델 정합(registration), 장면 이해와 같은 고수준 컴퓨터 비전 작업에 필요한 핵심 정보를 보존한다.5 즉, 특징점은 데이터 처리의 효율성과 강건성을 동시에 확보하기 위한 필수적인 첫 단계이다.


최근 몇 년간 딥러닝 기술의 발전으로 데이터로부터 특징을 직접 학습하는 방법론이 큰 주목을 받고 있다.10 그러나 Harris, SIFT, ISS와 같은 전통적인, 즉 수작업으로 설계된(handcrafted) 알고리즘들은 여전히 학술 및 산업 현장에서 중요한 가치를 지닌다. 이 알고리즘들은 방대한 학습 데이터셋 없이도 작동하며, 그 동작 원리가 수학적으로 명확하여 결과의 해석 가능성이 높다는 장점을 가진다. 특정 응용 분야나 제약 조건 하에서는 최신 딥러닝 기술에 필적하거나 이를 능가하는 성능을 보이기도 한다. 더욱이, 이들은 새로운 학습 기반 방법론의 성능을 평가하고 비교 분석하기 위한 강력하고 신뢰성 있는 베이스라인(baseline)으로서 필수적인 역할을 수행한다.12


본 보고서는 3D 포인트 클라우드 처리 분야에서 근간을 이루는 6가지 핵심 전통적 알고리즘-NARF(Normal Aligned Radial Feature), SIFT(Scale-Invariant Feature Transform) Keypoint, HarrisKeypoint3D, ISSKeypoint3D(Intrinsic Shape Signatures), SUSANKeypoint, SHOT(Signatures of Histograms of OrienTations)-을 심층적으로 분석하고 비교하는 것을 목적으로 한다. 각 알고리즘의 이론적 배경과 수학적 원리를 탐구하고, 구현상의 주요 특징, 다양한 교란 요인에 대한 성능적 강건성, 그리고 계산 복잡도를 다각적으로 조명할 것이다.

이 분석을 통해, 단순히 알고리즘들을 나열하는 것을 넘어 이들의 근본적인 차이점을 명확히 하고자 한다. 3D 특징점 처리 파이프라인은 크게 두 가지 핵심 역할, 즉 "어디에 특징점이 있는가?"를 찾는 **탐지기(Detector)**와 "그 특징점 주변을 어떻게 표현할 것인가?"를 정의하는 **기술자(Descriptor)**로 나뉜다. 본 보고서에서 다루는 알고리즘들은 이 역할에 따라 명확히 구분된다. HarrisKeypoint3D, ISSKeypoint3D, SUSANKeypoint는 주로 탐지기 역할에 집중하며 14, SHOT은 순수한 기술자이다.11 반면, NARF와 SIFT는 탐지기와 기술자 기능을 모두 포함하는 통합 프레임워크의 성격을 띤다.18 이러한 역할 분담을 이해하는 것은 전체 시스템의 성능을 예측하고 최적의 알고리즘 조합을 찾는 데 매우 중요하다. 실제 응용에서는 'ISS 탐지기 + SHOT 기술자'와 같이 각 역할에 가장 적합한 알고리즘을 조합하여 사용하는 경우가 많기 때문이다.9

따라서 본 보고서는 먼저 각 탐지기와 기술자를 개별적으로 심층 분석한 후, 이들의 조합과 성능 트레이드오프를 종합적으로 비교하고, 최종적으로 특정 응용 분야에 가장 적합한 알고리즘을 선택하기 위한 실용적인 가이드라인을 제시하며 마무리할 것이다.


특징점 탐지기는 포인트 클라우드 내에서 안정적이고 반복적으로 검출될 수 있는, 즉 정보량이 풍부한 지점을 식별하는 역할을 한다. 이 장에서는 "어디에 특징점이 있는가?"라는 질문에 각기 다른 철학으로 답하는 5가지 주요 탐지 알고리즘의 핵심 원리와 수학적 기반을 상세히 분석한다.


SIFT는 원래 2D 이미지 특징점 추출을 위해 개발되었으나, 그 강력한 성능 덕분에 3D 포인트 클라우드 환경으로 확장되었다.20


SIFT의 핵심 아이디어는 **스케일 공간(Scale-Space)** 이론에 기반한다. 객체를 다양한 크기(스케일)에서 관찰하더라도 동일한 특징점을 안정적으로 찾기 위해, 원본 데이터에 여러 단계의 가우시안 블러링(Gaussian blurring)을 적용하여 다중 스케일 표현을 생성한다.21 이후 인접한 스케일의 이미지 간 차분(Difference-of-Gaussians, DoG)을 계산하여 스케일 변화에 강건한 특징점 후보를 찾는다.21


3D SIFT는 2D에서의 픽셀 강도(intensity) 개념을 3D 고유의 속성으로 대체한다. 대표적으로 점의 국소적 밀도(density) 4나 주 곡률(principal curvature) 20이 사용된다.

1. **스케일 공간 구축**: 3D 포인트 클라우드 데이터 $I(x,y,z)$를 다양한 표준편차 $\sigma$를 갖는 3D 가우시안 필터 $G(x,y,z,\sigma)$와 컨볼루션하여 여러 스케일의 평활화된(smoothed) 데이터 $L(x,y,z,\sigma)$을 생성한다.
   $$
   L(x,y,z,\sigma) = G(x,y,z,\sigma) * I(x,y,z)
   $$
   **DoG 계산**: 인접한 스케일 $k\sigma$와 $\sigma$에 대해 평활화된 데이터 간의 차이를 계산하여 DoG 데이터 $D(x,y,z,\sigma)$를 얻는다.
   $$
   D(x,y,z,\sigma) = L(x,y,z,k\sigma) - L(x,y,z,\sigma)
   $$
   **극값 탐지**: DoG 공간에서 한 점이 자신의 3차원 이웃 26개 점(동일 스케일의 8개, 상위 스케일의 9개, 하위 스케일의 9개)보다 값이 크거나(극대) 작으면(극소) 특징점 후보로 선정된다.3 이 과정은 스케일 정규화된 라플라시안 연산자의 근사로 볼 수 있으며, 블롭(blob)과 유사한 구조를 탐지하는 데 효과적이다.21


SIFT의 성능은 여러 파라미터에 의해 조절된다.

- `nOctaveLayers`: 각 스케일 옥타브 내의 레이어 수. 이 값을 높이면 더 촘촘한 스케일 간격을 탐색하여 정확도를 높일 수 있지만 계산 비용이 증가한다.22
- `contrastThreshold`: DoG 값이 이 임계값보다 낮은, 즉 대비가 약한 특징점 후보를 제거한다. 이는 노이즈나 불안정한 특징점을 걸러내는 데 중요한 역할을 한다.22
- `edgeThreshold`: 주 곡률의 비율을 분석하여 평평한 엣지(edge) 상에 위치한 불안정한 특징점을 제거한다. 코너와 같이 여러 방향으로 곡률이 뚜렷한 점만 남기기 위함이다.22

SIFT는 이름에서 알 수 있듯이 스케일 변화에 매우 강건하다. 하지만 30도 이상의 큰 시점 변화에 대해서는 매칭 성능이 급격히 저하되는 한계를 보인다.24 또한 다중 스케일 공간을 구축하고 모든 후보점에 대해 이웃 비교를 수행하는 과정에서 계산 복잡도가 매우 높아 실시간 응용에는 제약이 따른다.20


Harris 탐지기는 2D 이미지에서 코너(corner)를 찾는 데 널리 사용되는 알고리즘으로, 이를 3D 공간으로 확장한 것이다.5


2D Harris 코너 탐지기는 이미지의 특정 지점 주변에서 모든 방향으로 픽셀 강도 변화가 큰 지점을 코너로 정의한다. 3D HarrisKeypoint는 이 아이디어를 3D 포인트 클라우드에 적용하기 위해, 픽셀 강도의 그래디언트 대신 각 점에서의 **표면 법선(surface normal) 벡터**를 사용한다.14 즉, 3D 코너는 주변 법선 벡터들이 모든 방향으로 급격하게 변하는 지점으로 간주된다.


각 점 $p$와 그 주변 이웃 점들의 법선 벡터를 이용하여 3x3 공분산 행렬(Covariance Matrix) 또는 구조 텐서(Structure Tensor) $M$을 구축한다. 2D에서 이미지 그래디언트 $I_x, I_y$의 곱을 사용했다면, 3D에서는 법선 벡터 $n_x, n_y, n_z$의 편미분을 이용해 행렬을 구성한다.5
$$
M = \sum_{q \in N(p)} w(q) \begin{bmatrix} n_x^2 & n_x n_y & n_x n_z \\ n_y n_x & n_y^2 & n_y n_z \\ n_z n_x & n_z n_y & n_z^2 \end{bmatrix}
$$
여기서 $w(q)$는 가우시안 가중치이다. 이 행렬의 고유값 $\lambda_1, \lambda_2, \lambda_3$는 세 개의 직교하는 주축 방향으로의 법선 변화량의 크기를 나타낸다. 코너 응답 함수 $R$은 이 고유값들을 조합하여 계산되며, $R$ 값이 큰 지점이 코너로 탐지된다. Point Cloud Library(PCL)에서는 여러 종류의 응답 함수를 제공한다.26

- **HARRIS**: $R = \det(M) - k \cdot (\text{trace}(M))^2$. 여기서 $\det(M) = \lambda_1\lambda_2\lambda_3$이고 $\text{trace}(M) = \lambda_1+\lambda_2+\lambda_3$이다. $k$는 경험적으로 결정되는 상수(보통 0.04)이다.25
- **NOBLE**: $R = \det(M) / (\text{trace}(M) + \epsilon)$.28
- **TOMASI**: $R = \min(\lambda_1, \lambda_2, \lambda_3)$. 가장 작은 고유값이 크다는 것은 모든 방향으로의 변화가 크다는 의미이므로 코너를 잘 나타낸다.28
- **CURVATURE**: 표면 곡률 값 자체를 응답 값으로 사용한다.


HarrisKeypoint3D는 계산이 비교적 빠르고 9, 코너나 엣지와 같이 기하학적으로 뚜렷한 구조를 탐지하는 데 효과적이다. 그러나 법선 추정의 정확도에 성능이 크게 좌우되며, 노이즈가 심한 데이터에서는 부정확한 법선으로 인해 성능이 저하될 수 있다.20 또한, 고정된 이웃 크기를 사용하므로 SIFT와 달리 스케일 불변성을 내재적으로 보장하지 않는다.


ISS는 반복성(repeatability)이 높은 특징점을 탐지하는 데 중점을 둔 알고리즘이다.2


좋은 특징점은 그 주변의 기하학적 구조가 모든 주축 방향으로 풍부한 변화를 보이는 지점이어야 한다는 직관에 기반한다. 즉, 평면(변화가 두 방향으로만 큼)이나 선(변화가 한 방향으로만 큼)과 같은 퇴화된(degenerate) 구조를 가진 점들은 배제하고, 3차원적으로 복잡한 구조를 가진 점을 선택한다.15


ISS의 핵심은 각 점 $p$의 이웃 점들로 구성된 산점 행렬(scatter matrix) $\Sigma(p)$의 고유값 분해(Eigenvalue Decomposition)에 있다.30

1. **산점 행렬 계산**: 점 $p$의 이웃 영역 $N(p)$에 대해 산점 행렬을 다음과 같이 계산한다.
   $$
   \Sigma(p) = \frac{1}{|N(p)|} \sum_{q \in N(p)} (q - \mu_p)(q - \mu_p)^T
   $$
   여기서 $\mu_p$는 이웃 점들의 평균 위치(중심점)이다.

2. **고유값 분석**: 산점 행렬 $\Sigma(p)$를 고유값 분해하여 크기 순으로 정렬된 고유값 $\lambda_1 \ge \lambda_2 \ge \lambda_3$를 얻는다. 이 고유값들은 각 주축 방향으로 점들이 얼마나 퍼져 있는지를 나타낸다.

3. **특징점 조건**: ISS는 안정적이고 반복적인 특징점을 찾기 위해 고유값들 사이에 다음과 같은 제약 조건을 적용한다.15

   - $\lambda_2 / \lambda_1 < \gamma_{21}$

   - $\lambda_3 / \lambda_2 < \gamma_{32}$

     첫 번째 조건($\lambda_1$이 $\lambda_2$보다 훨씬 큼)은 점들의 분포가 선(line) 형태가 아님을 보장한다. 두 번째 조건($\lambda_2$가 $\lambda_3$보다 훨씬 큼)은 점들의 분포가 평면(plane) 형태가 아님을 보장한다. $\gamma_{21}$과 $\gamma_{32}$는 보통 1에 가까운 값(예: 0.975)으로 설정되어, 세 고유값이 비교적 균일하게 큰 값을 갖는 것을 방지한다.

4. **비최대 억제(Non-Maximum Suppression)**: 위의 조건을 만족하는 점들 중에서, 가장 작은 고유값 $\lambda_3$을 현저성(saliency) 점수로 사용한다. 이 점수가 이웃 내에서 최대인 점만이 최종 특징점으로 선택된다.30


ISS는 시점 변화에 대해 매우 높은 반복성을 보이는 것으로 알려져 있으며, 여러 비교 연구에서 가장 우수한 성능을 보이는 탐지기 중 하나로 꾸준히 언급된다.3 이러한 강건성 덕분에 로봇의 위치 추정 및 지도 작성을 동시에 수행하는 SLAM(Simultaneous Localization and Mapping)과 같이 안정성이 극히 중요한 응용 분야에서 널리 선호된다.31


SUSAN은 미분 연산을 사용하지 않는 독특한 접근 방식으로 특징점을 탐지한다.32


알고리즘의 이름이 그 원리를 잘 설명한다. 각 점(nucleus, 핵)을 중심으로 하는 원형 마스크(mask) 내에서, 핵과 유사한 값을 갖는 영역, 즉 **USAN(Univalue Segment Assimilating Nucleus)**을 찾는다.18 기하학적으로 평평한 영역의 중심에 핵이 위치하면 USAN의 면적은 최대가 된다. 반면, 핵이 엣지에 가까워지면 USAN의 면적은 절반 정도로 줄어들고, 코너에 위치하면 면적은 최소가 된다. SUSAN은 바로 이 **가장 작은(Smallest) USAN**을 가진 지점을 코너, 즉 특징점으로 탐지한다.32


원본 2D SUSAN은 픽셀의 밝기(brightness)를 비교하지만, PCL에 구현된 3D SUSANKeypoint는 3차원 데이터의 특성을 반영하기 위해 **강도(intensity) 정보와 표면 법선(normal) 정보**를 함께 활용한다.7

1. **USAN 결정**: 중심점 $p_i$의 이웃 점 $p_j$가 USAN에 포함되는지 여부는 다음 두 임계값을 기준으로 판단된다.

   - 강도 임계값 $t_i$: $\|I(p_i) - I(p_j)\| < t_i$
   - 법선 각도 임계값 $t_a$: $1 - |\mathbf{n}_i \cdot \mathbf{n}_j| < t_a$

2. **응답 계산**: USAN의 면적(즉, 위 조건을 만족하는 이웃 점의 수) $A$를 계산하고, 이를 이용해 응답 함수 $R$를 계산한다.
   $$
   R = g - A
   $$
   여기서 $g$는 기하학적 임계값(USAN 면적의 최대 가능값)이다. $R$ 값이 큰 지점, 즉 USAN 면적이 작은 지점이 특징점 후보가 된다.

3. **비최대 억제**: 후보점들 중에서 응답 값이 국소적으로 최대인 점들만 최종 특징점으로 선택한다.


SUSAN은 미분 연산을 사용하지 않으므로 이미지 그래디언트에 의존하는 Harris나 SIFT에 비해 노이즈에 더 강건하고 계산이 빠르다는 장점이 있다.32 하지만 성능이 마스크 반경, 강도 임계값, 법선 임계값 등 여러 파라미터에 민감하게 반응할 수 있어 튜닝이 필요하다.


NARF는 3D 포인트 클라우드를 직접 처리하는 대신, 이를 2.5D **거리 이미지(Range Image)**로 변환하여 처리하는 독특한 접근법을 취한다.1


NARF의 핵심 아이디어는 두 가지로 요약된다. 첫째, 센서의 시점에서 발생하는 객체의 **경계(object borders)** 정보를 명시적으로 활용한다. 둘째, 특징점 자체는 표면이 안정적인(stable) 곳에 위치시키되, 그 주변에는 기하학적 변화가 풍부한 곳을 선택한다.18 이는 특징점의 위치는 안정적으로 유지하면서도, 주변 정보는 풍부하게 만들어 후속 기술자(descriptor) 계산이 더 강건하고 변별력 있게 이루어지도록 하기 위함이다.


1. **경계 추출**: 거리 이미지에서 인접 픽셀 간의 깊이 값 차이가 큰 지점을 찾아 객체의 실루엣과 같은 경계점을 탐지한다.1
2. **표면 변화 점수 계산**: 각 픽셀 위치에서, 경계 정보와 국소적인 표면의 주 곡률을 결합하여 표면이 얼마나 변하는지를 나타내는 점수(score)와 그 변화의 주된 방향(dominant direction)을 계산한다.18
3. **특징점 선정**: 각 픽셀 주변 영역에서 계산된 주된 방향들이 얼마나 다양한지, 그리고 해당 픽셀 자체의 표면이 얼마나 안정적인지를 종합적으로 고려하여 최종 특징(interest) 값을 산출한다. 이 특징 값이 주변보다 높은 국소적 최대(local maxima) 지점을 최종 NARF 특징점으로 선정한다.18


NARF는 깊이 카메라나 라이다(LiDAR) 센서로부터 직접 얻을 수 있는 거리 이미지 데이터에 매우 효율적으로 적용될 수 있다. 특히 부분적인 뷰(partial view)에서 객체의 외곽선 정보를 효과적으로 활용하여 특징점을 찾는 데 강점이 있다. 그러나 비조직화된(unorganized) 포인트 클라우드에는 먼저 거리 이미지로 변환하는 전처리 과정이 필요하며, 생성된 거리 이미지는 센서의 시점(viewpoint)에 의존적이므로 시점 변화에 민감할 수 있다는 단점을 가진다.

이처럼 3D 특징점 탐지기는 각기 다른 철학을 바탕으로 '중요한 점'을 정의한다. SIFT와 Harris는 변화율(미분)에, ISS는 기하학적 구조의 안정성에, SUSAN은 영역 내 값의 균일성에, 그리고 NARF는 2.5D 투영과 경계 정보에 초점을 맞춘다. 이러한 근본적인 패러다임의 차이는 각 알고리즘이 특정 데이터 유형과 응용 시나리오에 대해 보이는 강점과 약점을 결정하며, 이는 알고리즘 선택의 중요한 기준이 된다.


특징 기술자는 탐지된 특징점 주변의 국소적인 기하학적 정보를 고유하고 압축된 형태의 벡터로 표현하는 역할을 한다. 좋은 기술자는 서로 다른 위치의 특징점을 구별할 수 있는 높은 **변별력(Distinctiveness)**과, 시점 변화나 노이즈에도 불구하고 동일한 위치의 특징점을 항상 같은 벡터로 표현하는 **불변성(Invariance)**을 동시에 갖추어야 한다.


SHOT은 현재 가장 널리 사용되고 성능이 입증된 3D 특징 기술자 중 하나로, 기하학적 속성 히스토그램 기반 기술자의 대표적인 예이다.11


SHOT의 핵심 아이디어는 특징점 주변의 기하학적 형상을 **표면 법선 벡터들의 방향성 분포**를 통해 요약하는 것이다. 즉, 주변 점들의 법선이 특징점의 법선에 대해 어떤 방향으로 분포하는지를 히스토그램으로 만들어 고유한 '서명(Signature)'으로 사용한다.


기술자의 회전 불변성을 보장하는 것은 매우 중요하다. 이를 위해 SHOT은 기술자 계산에 앞서 각 특징점에 대해 고유하고 반복적으로 결정될 수 있는 **LRF(Local Reference Frame)**를 구축한다.11 LRF는 일종의 지역 좌표계로, 특징점 

$p$와 그 이웃 점들의 좌표 및 법선 정보를 이용하여 주성분 분석(PCA)과 유사한 방식으로 계산된다. 이 과정은 모호성을 해결하기 위해 추가적인 규칙을 포함하며, 결과적으로 특징점마다 유일한 3개의 직교 축(x, y, z)을 정의한다. 이후의 모든 계산은 이 LRF를 기준으로 이루어지므로, 원본 포인트 클라우드가 임의로 회전하더라도 LRF 자체가 함께 회전하여 기술자 값은 변하지 않게 된다.40


1. **지원 영역 설정**: LRF가 구축된 특징점을 중심으로 특정 반경 $r$ 내의 모든 점들을 이웃으로 하는 구(sphere) 형태의 지원 영역(support region)을 정의한다.
2. **공간 분할**: 이 구형 영역을 LRF의 축을 기준으로 방위각(azimuth, 8개), 고도(elevation, 2개), 반경(radius, 2개) 방향으로 나누어 총 $8 \times 2 \times 2 = 32$개의 공간적 빈(bin)으로 분할한다.40
3. **국소 히스토그램 계산**: 32개의 각 빈에 대해, 그 안에 속하는 모든 이웃 점 $q$의 법선 $\mathbf{n}_q$와 중심 특징점의 법선 $\mathbf{n}_p$ 사이의 각도의 코사인 값($\cos(\angle(\mathbf{n}_p, \mathbf{n}_q))$)을 계산한다. 각 빈마다 이 코사인 값들의 분포를 나타내는 1차원 히스토그램(보통 11개의 빈으로 구성)을 생성한다.
4. **최종 기술자 벡터 생성**: 32개의 모든 국소 히스토그램을 순서대로 직렬 연결(concatenate)하여 최종적으로 $32 \times 11 = 352$차원의 SHOT 기술자 벡터를 생성한다.42 이 벡터가 해당 특징점의 고유한 기하학적 서명이 된다.


SHOT은 매우 높은 변별력을 가지며, 노이즈와 점 밀도 변화에도 비교적 강건한 성능을 보인다. 그러나 LRF 계산과 352차원의 히스토그램 생성 과정은 계산 비용이 높은 편이며, 기술자의 성능은 LRF가 얼마나 안정적으로 계산되는지에 크게 의존한다. 이러한 계산 및 메모리 부담을 줄이기 위해, 실수형 벡터를 이진(binary) 벡터로 변환하는 **B-SHOT** 42이나 

**CI-SHOT** 43과 같은 변형 알고리즘들이 제안되었다. 이들은 매칭 속도를 크게 향상시키고 메모리 사용량을 줄여 실시간 응용에 더 적합하다.


NARF 기술자는 NARF 탐지기와 마찬가지로 거리 이미지(Range Image)를 기반으로 작동하며, 법선 정보를 적극적으로 활용한다.


특징점의 법선 방향으로 정렬된 2D 이미지 패치(patch)를 생성하고, 그 위에 방사형 패턴을 적용하여 특징을 추출하는 방식이다. 이는 3D 공간 정보를 2D 이미지 처리 기술로 효율적으로 분석하려는 시도이다.18


1. **법선 정렬 패치 생성**: 특징점에서 계산된 표면 법선 벡터가 Z축 방향을 향하도록 주변 3D 영역을 가상으로 회전시킨다. 이 회전된 좌표계에서 점들을 2D 그리드에 투영하여 **법선 정렬 패치(normal aligned patch)**라는 작은 거리 이미지를 생성한다.
2. **방사형 패턴 적용**: 생성된 패치 위에 중심점에서 방사형으로 뻗어 나가는 여러 개의 빔(beam)으로 구성된 별 모양(star pattern)을 겹친다.18
3. **특징 추출**: 각 빔 아래에 놓인 픽셀들의 거리 값 변화를 분석하여 하나의 특징 값으로 요약한다. 이 과정은 해당 방향으로 공간이 채워져 있는지(occupied) 비어있는지(free space)에 대한 정보를 효과적으로 인코딩한다.
4. **기술자 벡터 구성**: 모든 빔에서 추출된 값들을 모아 하나의 벡터로 구성하면 NARF 기술자가 완성된다.


법선 정렬 패치를 통해 Z축 회전을 제외한 회전 불변성이 확보된다. 남은 Z축 주변의 회전(in-plane rotation)에 대한 불변성은 패치 내에서 계산된 **주된 방향(dominant orientation)**을 찾고, 이 방향을 기준으로 기술자 벡터의 요소들을 순환적으로 이동(shift)시켜 정규화함으로써 달성된다.18


3D SIFT 기술자는 2D SIFT의 핵심 아이디어를 3D 시공간(spatio-temporal)으로 확장한 개념이다.44 여기서 '시간'은 실제 시간이 아닌 스케일(scale) 차원을 의미한다.


특징점 주변의 3D 공간에서 그래디언트의 방향과 크기를 다차원 히스토그램으로 만들어 고유한 특징으로 표현한다.


1. **3D 그래디언트 계산**: 공간 좌표(x, y)와 스케일 좌표(t)에 대한 그래디언트 성분 $L_x, L_y, L_t$를 유한 차분을 이용해 근사적으로 계산한다.

2. **3D 방향 및 크기 계산**: 계산된 그래디언트 성분들을 사용하여 3D 그래디언트의 크기 $m_{3D}$와 두 개의 방향각, 즉 구면 좌표계의 방위각 $\theta$와 고도각 $\phi$를 계산한다.44
   $$
   m_{3D}(x, y, t) = \sqrt{L_x^2 + L_y^2 + L_t^2}
   $$

   $$
   \theta(x, y, t) = \tan^{-1}(L_y / L_x)
   $$

   $$
   \phi(x, y, t) = \tan^{-1}(L_t / \sqrt{L_x^2 + L_y^2})
   $$

   **다차원 히스토그램 생성**: 특징점 주변 영역을 2D SIFT와 유사하게 공간적으로 분할한다 (예: 4x4x4=64개의 3D 하위 볼륨). 각 하위 볼륨에 대해, 그 안에 속한 점들의 3D 그래디언트 방향($\theta, \phi$)에 대한 2D 히스토그램을 생성한다. 이때 각 점의 기여도는 그래디언트 크기 $m_{3D}$와 중심점으로부터의 거리에 따른 가우시안 가중치를 곱하여 가중된다.

3. **최종 기술자 벡터**: 모든 하위 볼륨의 히스토그램들을 직렬로 연결하여 최종적인 고차원 기술자 벡터를 생성한다. 2D SIFT가 128차원인 것에 비해, 3D SIFT는 훨씬 더 큰 차원의 벡터를 생성하게 된다.22


3D SIFT 기술자는 스케일과 회전에 불변하는 매우 풍부한 정보를 담고 있지만, 그만큼 계산 복잡도가 매우 높고 기술자 벡터의 차원이 커서 저장 및 매칭에 많은 비용이 소요된다는 명확한 단점이 있다.

결론적으로, 성공적인 3D 특징 기술자들은 복잡한 3D 국소 기하학을 이산적이고(discrete) 표준화된(canonical) 벡터로 변환하기 위한 공통된 전략을 채택한다. 첫째, **안정적인 LRF(Local Reference Frame) 구축**을 통해 회전 불변성 문제를 해결한다. LRF의 안정성은 기술자 전체의 성능을 좌우하는 핵심 요소이다.41 둘째, **히스토그램 기반 양자화(quantization)**를 통해 주변 정보를 요약하고 압축한다. 이는 미세한 노이즈나 점 밀도 변화에 대한 민감도를 줄이고, 다양한 국소 형상을 비교 가능한 형태로 만드는 효과적인 추상화 메커니즘이다. LRF가 '기준'을 설정하고 히스토그램이 '내용'을 요약하는 이 두 가지 전략은 3D 공간의 연속적이고 복잡한 정보를 다루기 위한 핵심적인 접근법이라 할 수 있다.


앞서 개별적으로 분석한 알고리즘들을 동일한 척도 위에서 비교하며, 각 알고리즘의 성능, 효율성, 그리고 이 둘의 조합이 만들어내는 시너지를 종합적으로 평가한다.


알고리즘의 성능은 주로 반복성, 변별력, 그리고 다양한 교란 요인에 대한 강건성으로 평가된다.


좋은 탐지기는 동일한 객체를 다른 시점에서 보거나 노이즈가 추가되어도 항상 같은 지점을 특징점으로 찾아내는 높은 **반복성**을 가져야 한다. 한편, 좋은 기술자는 서로 다른 특징점들을 명확히 구분할 수 있는 높은 **변별력**을 가져야 한다. 이 두 가지 특성은 때때로 상충 관계에 있다. 예를 들어, 넓고 평평한 벽면의 중심점은 매우 안정적으로 반복해서 찾을 수 있지만(높은 반복성), 그 지점은 아무런 기하학적 특징이 없어 변별력이 거의 없다.2 ISS와 같은 탐지기는 기하학적 안정성에 기반하여 반복성이 높은 지점을 찾는 데 중점을 두는 반면, SHOT과 같은 기술자는 풍부한 정보를 인코딩하여 변별력을 극대화하는 것을 목표로 한다.


- **스케일 변화(Scale Changes)**: SIFT는 설계 자체가 스케일 공간 이론에 기반하므로 스케일 변화에 가장 강건하다. 반면 Harris, ISS, SUSAN 등은 기본적으로 고정된 스케일(이웃 반경)에서 작동하므로 스케일 변화에 취약하다. 이러한 단점을 보완하기 위해 Harris-Laplace와 같이 멀티스케일 분석을 추가한 변형 알고리즘들이 제안되기도 한다.25
- **회전(Rotation)**: LRF(Local Reference Frame)를 명시적으로 계산하여 사용하는 SHOT, 또는 주 방향을 찾아 정규화하는 SIFT와 NARF 기술자는 이론적으로 회전 불변성을 가진다. 탐지기 중에서는 고유값 분석에 기반한 ISS가 회전에 대해 높은 강건성을 보이는 것으로 여러 실험에서 입증되었다.8
- **노이즈(Noise)**: 미분 연산을 사용하지 않는 SUSAN은 이론적으로 노이즈에 강한 특성을 보인다.32 SIFT의 초기 가우시안 블러링 단계나 ISS/Harris의 이웃 평균화 과정 역시 어느 정도 노이즈를 완화하는 효과가 있다. 그러나 Harris와 SHOT처럼 표면 법선에 크게 의존하는 알고리즘들은 노이즈로 인해 법선 추정이 부정확해질 경우 성능이 크게 저하될 수 있다.20
- **가려짐(Occlusion) 및 클러터(Clutter)**: 특징점 주변의 국소적인 정보만을 사용하는 모든 지역(local) 특징점 기반 방식은 객체 전체의 형상을 보는 전역(global) 방식보다 가려짐과 주변의 복잡한 배경(클러터)에 본질적으로 더 강건하다.46 하지만 기술자의 성능은 지원 영역(support radius)의 크기와 트레이드오프 관계에 있다. 지원 영역이 크면 더 풍부한 정보를 담아 변별력이 높아지지만, 가려짐이나 클러터에 의해 영향을 받을 확률도 함께 커진다.46
- **포인트 밀도 변화(Point Density Variation)**: 포인트 밀도의 변화는 이웃 점의 수와 분포를 직접적으로 바꾸기 때문에 모든 알고리즘의 성능에 영향을 미친다. 특히 고정된 반경으로 이웃을 탐색하는 방식은 밀도가 낮은 영역에서는 정보 부족을, 밀도가 높은 영역에서는 과도한 계산을 유발할 수 있어 민감하게 반응한다.47


| 알고리즘     | 역할          | 스케일 불변성      | 회전 불변성        | 노이즈 강건성        | 가려짐/클러터 강건성 | 밀도 변화 강건성        | 시점 변화 강건성 |
| ------------ | ------------- | ------------------ | ------------------ | -------------------- | -------------------- | ----------------------- | ---------------- |
| **NARF**     | 탐지기+기술자 | 약함               | 강함 (주 방향)     | 보통 (거리 이미지)   | 강함 (경계 활용)     | 약함 (거리 이미지 의존) | 약함 (시점 의존) |
| **SIFT**     | 탐지기+기술자 | 매우 강함 (DoG)    | 강함 (주 방향)     | 강함 (가우시안 필터) | 강함 (국소적)        | 보통                    | 보통 (<30°)      |
| **Harris3D** | 탐지기        | 약함 (고정 스케일) | 약함               | 약함 (법선 의존)     | 강함 (국소적)        | 약함 (법선 의존)        | 보통             |
| **ISS3D**    | 탐지기        | 약함 (고정 스케일) | 매우 강함 (고유값) | 보통 (평균화)        | 강함 (국소적)        | 보통                    | 매우 강함        |
| **SUSAN**    | 탐지기        | 약함 (고정 스케일) | 약함               | 강함 (미분 미사용)   | 강함 (국소적)        | 보통                    | 보통             |
| **SHOT**     | 기술자        | 약함 (고정 스케일) | 매우 강함 (LRF)    | 보통 (법선 의존)     | 강함 (국소적)        | 보통                    | 매우 강함 (LRF)  |


알고리즘의 실용성은 성능뿐만 아니라 계산에 필요한 시간과 자원에 의해 결정된다.


- **탐지기**: 대부분의 탐지기는 각 점에 대해 이웃을 탐색하는 과정이 계산량의 상당 부분을 차지한다. KD-Tree와 같은 자료구조를 사용하면, 전체 점의 개수를 $N$, 이웃 점의 개수를 $k$라 할 때 이웃 탐색은 대략 $O(N \log N)$ 또는 $O(N k)$의 시간 복잡도를 가진다.
  - **SIFT**는 여러 스케일과 옥타브에 걸쳐 이 과정을 반복하고 DoG 계산 및 극값 탐지를 수행하므로 전체적인 계산 복잡도가 매우 높다.20
  - **Harris**와 **SUSAN**은 단일 스케일에서 작동하므로 상대적으로 계산이 빠르다.9
- **기술자**: 기술자의 복잡도는 주로 이웃 점의 수 $k$에 의존한다.
  - 과거에 널리 쓰였던 **PFH** 기술자는 이웃 내의 모든 점 쌍($k(k-1)/2$)을 고려하므로 시간 복잡도가 $O(k^2)$에 달해 매우 느렸다.51
  - 이를 개선한 **FPFH**는 각 점과 그 이웃 간의 관계만을 계산하여 복잡도를 $O(k)$로 크게 낮췄다.11
  - **SHOT**은 LRF 계산과 32개의 히스토그램 생성이 필요하며, 전체적인 복잡도는 $O(k)$에 비례하지만 상수 인자가 커서 FPFH보다는 계산량이 많다.


계산 부담을 줄이기 위한 다양한 최적화 기법이 존재한다. SHOT의 경우, 352차원의 실수형 벡터를 352비트의 이진 벡터로 변환하는 **B-SHOT**이 제안되었다. B-SHOT은 매칭 시 유클리드 거리 대신 비트 연산으로 빠른 해밍 거리(Hamming distance)를 사용함으로써, 6배 빠른 매칭 속도와 32배 적은 메모리 사용량을 달성했다.42 또한, 많은 PCL 구현체들은 OpenMP를 이용한 병렬 처리를 지원하여 멀티코어 CPU 환경에서 성능을 향상시킨다.40


| 알고리즘     | 역할          | 시간 복잡도 (per point) | 공간 복잡도 (per point) | 주요 파라미터                                        | 필요 입력 데이터 |
| ------------ | ------------- | ----------------------- | ----------------------- | ---------------------------------------------------- | ---------------- |
| **NARF**     | 탐지기+기술자 | 빠름                    | 낮음                    | `support_size`                                       | 거리 이미지      |
| **SIFT**     | 탐지기+기술자 | 매우 높음               | 높음 (128+ dim)         | `nOctaveLayers`, `contrastThreshold`                 | 좌표, 강도/곡률  |
| **Harris3D** | 탐지기        | 빠름                    | 낮음 (응답값)           | `radius`, `threshold`, `method`                      | 좌표, 법선       |
| **ISS3D**    | 탐지기        | 보통                    | 낮음 (응답값)           | `salient_radius`, `gamma_21`, `gamma_32`             | 좌표             |
| **SUSAN**    | 탐지기        | 빠름                    | 낮음 (응답값)           | `radius`, `intensity_threshold`, `angular_threshold` | 좌표, 법선, 강도 |
| **SHOT**     | 기술자        | 높음                    | 높음 (352 dim)          | `radius`                                             | 좌표, 법선       |


실제 응용에서 최상의 성능은 개별 알고리즘의 성능이 아닌, 탐지기와 기술자의 현명한 조합에서 비롯된다.

- **최적의 조합**: 각 역할의 강점을 극대화하는 조합이 이상적이다. 예를 들어, 시점 변화에 매우 강건하고 반복성이 높은 **ISS 탐지기**로 안정적인 특징점을 찾고, 그 위치에서 변별력이 매우 뛰어난 **SHOT 기술자**로 주변 형상을 기술하는 조합은 3D 객체 인식 및 정합 분야에서 매우 강력한 성능을 보이는 것으로 널리 알려져 있다.9
- **부조화**: 반대로, 특성이 맞지 않는 조합은 성능 저하를 유발할 수 있다. 예를 들어, 스케일 불변성이 없는 Harris 탐지기로 찾은 특징점에 스케일 불변 기술자인 SIFT를 적용하는 것은 큰 의미가 없다. 탐지기와 기술자가 스케일 처리 방식, 노이즈 민감도 등에서 유사한 특성을 가질 때 시너지가 극대화된다.
- **학습 기반 접근의 시사점**: 최근 연구에서는 특정 기술자로 매칭했을 때 성공 확률이 높은 지점을 탐지하도록 탐지기를 학습시키는 방식 2이나, 탐지기와 기술자를 하나의 네트워크에서 동시에 학습하는 End-to-End 방식 10이 등장했다. 이는 전통적인 조합 방식의 한계를 보여주는 동시에, 탐지기와 기술자 두 요소가 얼마나 강하게 상호 의존적인지를 명확히 방증한다.


지금까지의 분석을 바탕으로, 실제 응용 시나리오별로 어떤 알고리즘 또는 조합이 가장 적합한지에 대한 실용적인 지침을 제공한다.



이 분야의 핵심 요구사항은 **실시간성**과 **강건성**이다. 로봇이 움직이면서 계속해서 새로운 데이터를 처리해야 하므로 계산 속도가 빨라야 하며, 시점 변화, 조명 변화, 동적 객체로 인한 노이즈 등 다양한 환경 변화에도 안정적으로 자신의 위치를 추정하고 지도를 작성해야 한다.


- **ISS3D (탐지기) + SHOT/FPFH (기술자)**: 이 조합은 강건성이 가장 중요한 SLAM 응용에서 표준처럼 여겨진다. ISS는 시점 변화에 대한 반복성이 매우 높아 안정적인 랜드마크(landmark)를 지속적으로 탐지하는 데 탁월하다.31 이렇게 탐지된 지점에서 변별력이 높은 SHOT이나 계산이 더 빠른 FPFH 기술자를 사용하여 루프 클로징(loop closure, 이전에 방문했던 장소를 재인식하는 것)의 정확도를 높일 수 있다. 여러 비교 연구에서 ISS는 SLAM 적용에 적합하다는 평가를 받았다.31
- **Harris3D / SUSAN (탐지기) + (간단한 기술자)**: 계산 부하를 최소화해야 하는 저사양 임베디드 시스템에서는 빠른 탐지 속도를 가진 Harris3D나 SUSAN이 대안이 될 수 있다. 특히 코너나 엣지와 같은 구조적 특징이 풍부한 실내 환경에서 효과적이다.9
- **NARF (통합)**: 센서가 거리 이미지를 직접 제공하는 경우(예: 특정 LiDAR, 깊이 카메라), NARF는 전처리 없이 매우 빠른 실시간 성능을 보일 수 있다. 이기종(heterogeneous) 로봇, 즉 서로 다른 종류의 센서를 사용하는 로봇들 간의 SLAM 시나리오에서 잠재력을 가진다.31



이 분야에서는 실시간성보다는 **높은 변별력**과 **부분적 가려짐(occlusion) 및 클러터(clutter)에 대한 강건성**이 더 중요하다. 데이터베이스에 저장된 수많은 객체 모델 중에서 주어진 장면에 있는 객체를 정확히 찾아내거나, 유사한 객체를 검색해내는 것이 목표이다.


- **(ISS/SIFT Detector) + SHOT/SIFT Descriptor**: SHOT과 SIFT 기술자는 매우 풍부하고 고유한 기하학적 정보를 담고 있어 객체의 정체성을 표현하는 데 매우 효과적이다. 이들의 높은 변별력은 데이터베이스에서 유사한 객체를 정확하게 검색하는 데 결정적인 역할을 한다.17 탐지기로는 안정적인 ISS나 스케일 변화에 강한 SIFT를 사용하는 것이 좋다.
- **NARF (통합)**: 특히 단일 시점에서 얻은 부분적인 스캔 데이터로부터 객체를 인식해야 하는 경우, NARF는 객체의 경계(실루엣) 정보를 명시적으로 활용하므로 인식률을 높이는 데 기여할 수 있다.18



이 분야에서는 **높은 정밀도**와 **안정성**이 가장 중요하다. 기계 부품의 마모 상태를 검사하거나, 문화재를 디지털로 복원하는 등의 작업에서는 특정 기하학적 결함(코너, 엣지, 균열 등)을 정확하게 탐지하고, 반복적인 측정에서도 일관된 결과를 얻는 것이 필수적이다.


- **HarrisKeypoint3D**: 코너 탐지에 특화된 Harris3D는 기계 부품의 모서리, 볼트 구멍의 중심, 혹은 특정 구조물의 꼭짓점과 같이 명확한 코너를 정밀하게 찾는 데 매우 유용하다.25
- **SUSANKeypoint**: 엣지 탐지 능력이 뛰어나고 노이즈에 강건하여, 부품의 표면 긁힘이나 균열과 같은 선형 결함을 검사하는 데 활용될 수 있다.


이러한 응용에서는 여러 각도에서 촬영한 포인트 클라우드 스캔들을 하나의 정밀한 3D 모델로 정합(registration)하는 과정이 필수적이다. Harris나 SUSAN으로 탐지된 정밀한 특징점들은 이 정합 과정의 기준점(correspondences)으로 사용되어, 최종 3D 재구성 모델의 정확도를 높이는 데 결정적인 기여를 한다.25



본 보고서는 6가지 전통적 3D 특징점 알고리즘인 NARF, SIFT, Harris3D, ISS3D, SUSAN, SHOT에 대한 심층 비교 분석을 수행했다. 분석 결과, 각 알고리즘은 고유한 수학적 철학을 바탕으로 설계되었으며, 성능, 효율성, 강건성 측면에서 명확한 트레이드오프 관계를 보임을 확인했다. 따라서 "모든 상황에 최적인 단 하나의 알고리즘"은 존재하지 않으며, 최적의 선택은 항상 응용 분야의 구체적인 요구사항과 처리해야 할 데이터의 특성에 따라 달라진다. 성공적인 알고리즘 선택을 위한 핵심 기준은 다음 네 가지로 요약할 수 있다.

1. **탐지기와 기술자의 시너지 조합**: 개별 알고리즘의 성능보다 조합의 시너지가 더 중요하다.
2. **입력 데이터 의존성**: 알고리즘이 요구하는 입력 데이터(예: 거리 이미지, 표면 법선, 강도)를 효율적으로 제공할 수 있는가.
3. **강건성 요구 수준**: 예상되는 주요 교란 요인(예: 스케일 변화, 노이즈, 가려짐)에 효과적으로 대응할 수 있는가.
4. **계산 자원 제약**: 실시간 처리 능력과 메모리 사용량이 시스템의 요구사항을 만족하는가.


본 보고서에서 다룬 전통적 알고리즘들은 3D 컴퓨터 비전 분야의 근간을 이루는 중요한 도구이다. 이들은 기하학적 원리에 기반하여 직관적이고 해석 가능한 결과를 제공하며, 오늘날에도 많은 시스템에서 핵심적인 역할을 수행하고 있다. 그러나 이들은 명확한 한계 또한 가지고 있다. 최적의 성능을 내기 위해 수많은 파라미터를 수동으로 조정해야 하는 어려움, 복잡하고 비정형적인 실제 환경에서의 강건성 한계, 그리고 객체의 색상, 질감, 또는 의미론적(semantic) 정보를 활용하지 못하는 점 등이 그것이다.


이러한 전통적 방법론의 한계를 극복하기 위해, 최근의 연구 동향은 특징점 탐지와 기술 과정을 데이터로부터 직접 학습하는 **학습 기반(Learning-based) 방법론**으로 빠르게 이동하고 있다.2 딥러닝 모델은 특정 데이터셋에 대해 더 높은 반복성과 변별력을 달성할 수 있으며, 탐지기와 기술자를 하나의 네트워크에서 동시에 최적화하는 End-to-End 학습을 통해 조합 문제를 근본적으로 해결할 잠재력을 보여준다.

향후 3D 특징점 연구는 전통적 알고리즘이 제공하는 명확한 기하학적 통찰과 딥러닝의 강력한 데이터 기반 표현 학습 능력을 결합하는 **하이브리드(hybrid) 방식**이나, 다양한 환경과 데이터에 대해 일반화 성능이 뛰어나고 더욱 강건한 **새로운 학습 기반 특징**을 개발하는 방향으로 나아갈 것이다. 전통적 알고리즘에 대한 깊은 이해는 이러한 미래 기술을 개발하고 평가하는 데 있어 여전히 필수적인 기초가 될 것이다.


1. NARF keypoint computation | Download Scientific Diagram - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/figure/NARF-keypoint-computation_fig3_267390917
2. Learning a Descriptor-Specific 3D Keypoint Detector - CVF Open Access, accessed July 24, 2025, https://openaccess.thecvf.com/content_iccv_2015/papers/Salti_Learning_a_Descriptor-Specific_ICCV_2015_paper.pdf
3. A Comparative Evaluation of 3D Keypoint Detectors in a RGB-D Object Dataset - UBI, accessed July 24, 2025, https://www.di.ubi.pt/~lfbaa/pubs/VISAPP2014.pdf
4. A Comparative Evaluation of 3D Keypoint Detectors in a RGB-D Object Dataset - SciTePress, accessed July 24, 2025, https://www.scitepress.org/papers/2014/46799/46799.pdf
5. a robust extension of the Harris operator for interest point detection on 3D meshes - Ivan Sipiran, accessed July 24, 2025, https://ivan-sipiran.com/papers/SB11b.pdf
6. 3D-SUSAN: A robust extension of 2D SUSAN operator for 3D interest points detection | Request PDF - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/publication/323672283_3D-SUSAN_A_robust_extension_of_2D_SUSAN_operator_for_3D_interest_points_detection
7. Module keypoints - Point Cloud Library (PCL), accessed July 24, 2025, http://pointclouds.org/documentation/group__keypoints.html
8. A Comparative Evaluation of 3D Keypoint Detectors - UBI, accessed July 24, 2025, http://www.di.ubi.pt/~lfbaa/pubs/conftele2013.pdf
9. A Comparative Evaluation of 3D Keypoint Detectors in a RGB-D ..., accessed July 24, 2025, https://www.researchgate.net/publication/259781229_A_Comparative_Evaluation_of_3D_Keypoint_Detectors_in_a_RGB-D_Object_Dataset
10. RSKDD-Net: Random Sample-based Keypoint Detector and Descriptor, accessed July 24, 2025, https://proceedings.neurips.cc/paper/2020/file/f40723ed94042ea9ea36bfb5ad4157b2-Paper.pdf
11. 3D Feature Detector-Descriptor Pair Evaluation on Point Clouds - EURASIP, accessed July 24, 2025, https://new.eurasip.org/Proceedings/Eusipco/Eusipco2020/pdfs/0000590.pdf
12. The quality of the voxel grid based on the point cloud resolution... | Download Scientific Diagram - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/figure/The-quality-of-the-voxel-grid-based-on-the-point-cloud-resolution-calculated-by-the-mean_fig1_277386160
13. SNAKE: Shape-aware Neural 3D Keypoint Field - OpenReview, accessed July 24, 2025, https://openreview.net/references/pdf?id=o348OKVUD
14. Example of Harris 3D keypoints algorithm using Point Cloud Library (PCL) - GitHub, accessed July 24, 2025, https://github.com/Edge330/Harris-3D-keypoints
15. Open3D (C++ API): open3d::geometry::keypoint Namespace ..., accessed July 24, 2025, https://www.open3d.org/docs/0.12.0/cpp_api/namespaceopen3d_1_1geometry_1_1keypoint.html
16. SUSAN 3D operator, principal saliency degrees and directions extraction and a brief study on the robustness to noise - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/publication/224115072_SUSAN_3D_operator_principal_saliency_degrees_and_directions_extraction_and_a_brief_study_on_the_robustness_to_noise
17. fedassa/SHOT: C++ implementation of the SHOT 3D ... - GitHub, accessed July 24, 2025, https://github.com/fedassa/SHOT
18. NARF: 3D Range Image Features for Object Recognition - CiteSeerX, accessed July 24, 2025, https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e0701662a370622a1cdbb7c6a83bbede3d0e6c23
19. What is SIFT(Scale Invariant Feature Transform) Algorithm? - Analytics Vidhya, accessed July 24, 2025, https://www.analyticsvidhya.com/blog/2019/10/detailed-guide-powerful-sift-technique-image-matching-python/
20. 3D-SIFT keypoint computation | Download Scientific Diagram - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/figure/D-SIFT-keypoint-computation_fig5_267390917
21. Scale-invariant feature transform - Wikipedia, accessed July 24, 2025, https://en.wikipedia.org/wiki/Scale-invariant_feature_transform
22. What is Scale-Invariant Feature Transform (SIFT)? - Roboflow Blog, accessed July 24, 2025, https://blog.roboflow.com/sift/
23. Describe the concept of scale-invariant feature transform (SIFT) - GeeksforGeeks, accessed July 24, 2025, https://www.geeksforgeeks.org/computer-vision/describe-the-concept-of-scale-invariant-feature-transform-sift/
24. SIFT Descriptor | SIFT Detector - YouTube, accessed July 24, 2025, https://www.youtube.com/watch?v=IBcsS8_gPzE
25. Harris corner detector - Wikipedia, accessed July 24, 2025, https://en.wikipedia.org/wiki/Harris_corner_detector
26. pcl::HarrisKeypoint3D< PointInT, PointOutT, NormalT > Class Template Reference - Point Cloud Library, accessed July 24, 2025, http://pointclouds.org/documentation/classpcl_1_1_harris_keypoint3_d.html
27. Ivan Sipiran's Personal Page - DCC UChile, accessed July 24, 2025, https://users.dcc.uchile.cl/~isipiran/harris3D.html
28. 6.2 Harris Corner Detector - Carnegie Mellon University, accessed July 24, 2025, https://www.cs.cmu.edu/~16385/s17/Slides/6.2_Harris_Corner_Detector.pdf
29. Corner Detection of the Computer VR Microscope Image Based on the 3D Reconstruction Algorithm - PMC - PubMed Central, accessed July 24, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC9329034/
30. Intrinsic Shape Signatures (ISS) - Open3D latest (664eff5 ..., accessed July 24, 2025, https://www.open3d.org/docs/latest/tutorial/Advanced/iss_keypoint_detector.html
31. 3D Keypoint Repeatability for Heterogeneous Multi-Robot SLAM, accessed July 24, 2025, http://act.cs.brown.edu/publications/Boroson_ICRA2019.pdf
32. The SUSAN Principle for Feature Detection, accessed July 24, 2025, https://users.fmrib.ox.ac.uk/~steve/susan/susan/node2.html
33. A Comparative Evaluation of 3D Keypoint Detectors - UBI, accessed July 24, 2025, https://www.di.ubi.pt/~lfbaa/pubs/conftele2013.pdf
34. Corner detection - Wikipedia, accessed July 24, 2025, https://en.wikipedia.org/wiki/Corner_detection
35. pcl::SUSANKeypoint< PointInT, PointOutT, NormalT, IntensityT > Class Template Reference, accessed July 24, 2025, http://docs.ros.org/hydro/api/pcl/html/classpcl_1_1SUSANKeypoint.html
36. pcl: susan.h File Reference - the official ROS docs, accessed July 24, 2025, https://docs.ros.org/en/hydro/api/pcl/html/susan_8h.html
37. pcl::SUSANKeypoint< PointInT, PointOutT, NormalT, IntensityT > Class Template Reference - Point Cloud Library, accessed July 24, 2025, https://pointclouds.org/documentation/classpcl_1_1_s_u_s_a_n_keypoint.html
38. NARF 3D Range Image Features For Object Recognitio | PDF - Scribd, accessed July 24, 2025, https://www.scribd.com/document/392344911/NARF-3D-Range-Image-Features-for-Object-Recognitio
39. Registration of 3D point clouds using a local descriptor based on grid point normal, accessed July 24, 2025, https://opg.optica.org/abstract.cfm?uri=ao-60-28-8818
40. PCL/OpenNI tutorial 4: 3D object recognition (descriptors) - robotica ..., accessed July 24, 2025, https://robotica.unileon.es/index.php?title=PCL/OpenNI_tutorial_4:_3D_object_recognition_(descriptors)
41. Learning to assign Local Reference Frame for 3D Point Cloud - Shun-Cheng Wu, accessed July 24, 2025, https://shunchengwu.github.io/tecniquereport/Learned-LRF/
42. B-SHOT : A Binary Feature Descriptor for Fast and Efficient Keypoint Matching on 3D Point Clouds - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/publication/280803085_B-SHOT_A_Binary_Feature_Descriptor_for_Fast_and_Efficient_Keypoint_Matching_on_3D_Point_Clouds
43. CI-SHOT: A Statistical Method for Binary Feature Descriptor on 3D Point Clouds, accessed July 24, 2025, https://openreview.net/forum?id=xQsZM2aCH7
44. A 3-Dimensional SIFT Descriptor and its Application to Action ..., accessed July 24, 2025, https://www.cs.cmu.edu/~saada/Publications/2007_ACMMM_3DSIFT.pdf
45. Scale-Invariant Feature Transform (SIFT) | Computer Vision and Image Processing Class Notes | Fiveable, accessed July 24, 2025, https://library.fiveable.me/computer-vision-and-image-processing/unit-3/scale-invariant-feature-transform-sift/study-guide/aGPD0BuZ2rC30OQp
46. Recognizing Objects in 3D Point Clouds with Multi-Scale Local Features - MDPI, accessed July 24, 2025, https://www.mdpi.com/1424-8220/14/12/24156
47. A more repeatable and robust local reference frame for 3D local, accessed July 24, 2025, https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11069/1106913/A-more-repeatable-and-robust-local-reference-frame-for-3D/10.1117/12.2524177.full?origin_id=x116999&webSyncID=a0cbad05-9329-ad88-3c9d-902bc9993ced&sessionGUID=268bead4-9a28-531a-b0d3-a6b03c97c009
48. PPTFH: Robust Local Descriptor Based on Point-Pair Transformation Features for 3D Surface Matching - PMC, accessed July 24, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC8124800/
49. Low Complexity Keypoint Extraction Based on SIFT Descriptor and Its Hardware Implementation for Full-HD 60fps Video | Request PDF - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/publication/274466807_Low_Complexity_Keypoint_Extraction_Based_on_SIFT_Descriptor_and_Its_Hardware_Implementation_for_Full-HD_60fps_Video
50. SIFT-Based Low Complexity Keypoint Extraction and Its Real-Time Hardware Implementation for Full-HD Video - APSIPA, accessed July 24, 2025, http://www.apsipa.org/proceedings_2012/papers/216.pdf
51. Point Feature Histograms (PFH) descriptors - Point Cloud Library 0.0 documentation, accessed July 24, 2025, https://pcl.readthedocs.io/projects/tutorials/en/master/pfh_estimation.html
52. Robustness of 3D keypoint detection by conventional ISS and Harris3D - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/figure/Robustness-of-3D-keypoint-detection-by-conventional-ISS-and-Harris3D-FADA-3K-with-ISS_fig4_346894410
53. ICP registration with SHOT descriptor for arresters point clouds - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/publication/382954894_ICP_registration_with_SHOT_descriptor_for_arresters_point_clouds
54. NARF: 3D Range Image Features for Object Recognition - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/publication/260320178_NARF_3D_Range_Image_Features_for_Object_Recognition
55. Harris corner detector – Knowledge and References - Taylor & Francis, accessed July 24, 2025, https://taylorandfrancis.com/knowledge/Engineering_and_technology/Artificial_intelligence/Harris_corner_detector/
56. Harris Operator Corner Detection using Sliding Window Method - ResearchGate, accessed July 24, 2025, https://www.researchgate.net/publication/241213390_Harris_Operator_Corner_Detection_using_Sliding_Window_Method
57. Key-Grid: Unsupervised 3D Keypoints Detection using Grid Heatmap Features, accessed July 24, 2025, https://jackhck.github.io/keygrid.github.io/
58. Back to 3D: Few-Shot 3D Keypoint Detection with Back-Projected 2D Features, accessed July 24, 2025, https://wimmerth.github.io/back-to-3d.html
59. Learning Deep Network for Detecting 3D Object Keypoints and 6D Poses - CVF Open Access, accessed July 24, 2025, https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhao_Learning_Deep_Network_for_Detecting_3D_Object_Keypoints_and_6D_CVPR_2020_paper.pdf
60. KeypointDETR: An End-to-End 3D Keypoint Detector - European Computer Vision Association, accessed July 24, 2025, https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09481.pdf

