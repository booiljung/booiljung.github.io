<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:아고스비전 광시야 3D 비전 센서</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>아고스비전 광시야 3D 비전 센서</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">센서 (Sensors)</a> / <a href="index.html">스테레오 카메라 (Stereo Camera)</a> / <span>아고스비전 광시야 3D 비전 센서</span></nav>
                </div>
            </header>
            <article>
                <h1>아고스비전 광시야 3D 비전 센서</h1>
<h2>1.  3D 비전 기술의 진화와 아고스비전의 등장</h2>
<h3>1.1 D 공간 인식 기술의 패러다임 전환</h3>
<p>현대 기술 시스템, 특히 지능형 로봇, 자율주행 모빌리티, 스마트 팩토리 분야에서 3차원 공간을 정밀하게 인식하는 능력은 더 이상 선택이 아닌 필수 요소로 자리 잡았다. 3D 센서는 로봇이 단순히 사물과의 거리를 측정하는 것을 넘어, 복잡하고 예측 불가능한 환경과 능동적으로 상호작용하고, 안전을 확보하며, 주어진 임무를 효율적으로 수행하기 위한 핵심적인 감각 기관 역할을 한다.1</p>
<p>기존의 3D 센서 기술, 예를 들어 라이다(LiDAR), ToF(Time-of-Flight), 그리고 협각(narrow-angle) 스테레오 카메라는 각자의 영역에서 기술적 발전을 이루었으나 명백한 한계점을 노출해왔다. 특히 자율주행 시스템의 주력 센서로 사용되는 라이다는 수평 방향으로 넓은 시야각을 제공하는 장점이 있지만, 수직 방향 시야각이 통상적으로 30도 내외에 불과하다는 치명적인 약점을 가진다.2 이러한 제한된 수직 시야는 로봇이나 차량 바로 앞의 노면 상태, 예를 들어 도로의 단차나 구멍, 그리고 낮은 장애물을 인식하지 못하는 심각한 ’인식 사각지대(blind spot)’를 발생시켜 안전한 자율주행을 저해하는 주요 원인으로 작용해왔다.3</p>
<h3>1.2 아고스비전(ArgosVision)의 출현과 ’광시야(Panoramic View)’의 가치</h3>
<p>이러한 기술적 공백을 해결하고 로봇 비전의 새로운 가능성을 제시하기 위해 ㈜아고스비전(이하 아고스비전)이 등장했다. 아고스비전의 핵심 제품인 ’아고스뷰(ArgosVue)’는 ’인간의 눈에 필적하는 넓은 시야’를 제공함으로써 기존 센서 기술의 한계를 극복하는 것을 목표로 한다.2 아고스뷰는 라이다의 수직 시야각 한계를 극복하고, 로봇이 주변 환경을 보다 포괄적으로 이해할 수 있도록 설계되었다.</p>
<p>아고스비전의 등장은 단순히 새로운 센서의 출시 이상의 의미를 가진다. 이는 로봇 비전 분야에서 요구되는 ’데이터의 질’에 대한 패러다임 전환을 시사한다. 기존 라이다가 상대적으로 희소한 3D 좌표 정보의 집합인 ’희소 포인트 클라우드(sparse point cloud)’를 제공했다면, 아고스뷰는 고해상도 컬러 이미지와 ’조밀한 포인트 클라우드(dense point cloud)’를 동시에 제공한다.6 이러한 변화는 최근 폭발적으로 발전하고 있는 인공지능(AI) 영상 인식 기술의 요구와 정확히 일치한다. 로봇이 단순히 장애물의 ‘존재’ 여부를 파악하는 수준을 넘어, 그 장애물이 ’무엇인지’를 식별하고 의미를 이해(scene understanding)하기 위해서는 풍부한 시각적 데이터가 필수적이기 때문이다. 아고스뷰는 스테레오 ‘카메라’ 기술에 기반하기에, 라이다가 제공하지 못하는 색상과 질감 정보를 포함한 고해상도 RGB-D(컬러+깊이) 영상을 제공할 수 있다.7 따라서 아고스비전은 라이다의 기술적 약점을 보완하는 것을 넘어, 차세대 AI 기반 지능형 로봇이 필요로 하는 ’풍부한 시각 데이터(rich visual data)’를 제공하는 핵심 솔루션으로 자리매김하려는 전략적 목표를 가지고 있다.</p>
<p>본 보고서는 아고스비전의 광시야 3D 비전 센서 기술의 본질을 심층적으로 분석하고, 제품 포트폴리오, 시장 경쟁력, 그리고 미래 잠재력을 종합적으로 평가하여 해당 기술과 기업에 대한 포괄적이고 통찰력 있는 이해를 제공하는 것을 목적으로 한다.</p>
<h2>2.  기업 분석: 아고스비전 (ArgosVision) - 기술 혁신의 구심점</h2>
<h3>2.1 설립 배경 및 정체성</h3>
<p>아고스비전은 2020년 1월 29일에 설립된 딥테크 스타트업으로, 그 뿌리는 정부 주도의 대형 연구개발 사업에 있다.9 회사는 과학기술정보통신부의 글로벌 프론티어 사업으로 출범한 ’다차원 스마트 IT 융합시스템 연구단(CISS)’의 핵심 연구원들이 연구 성과를 직접 사업화하기 위해 창업한 한국과학기술연구원(KIST)의 스핀오프(spin-off) 기업이다.1 창업자인 박기영 대표 역시 연구원 출신으로, 오랜 연구를 통해 축적된 기술을 실제 시장에 적용하고자 창업을 결심했다.2</p>
<p>사명인 ’아고스비전’은 그리스 신화에 등장하는 눈이 100개 달린 거인 ’아르고스 파놉테스(Argos Panoptes)’에서 영감을 얻었다. 이는 여러 대의 카메라를 융합하여 기존 단일 카메라의 한계를 뛰어넘는 혁신적인 비전 시스템을 만들겠다는 회사의 초기 비전을 상징한다.9 현재는 시스템의 가격 경쟁력과 효율성을 최적화하기 위해 2개의 카메라를 사용하는 스테레오 비전 방식으로 기술을 집약했다.9</p>
<p>이러한 ’KIST 스핀오프’라는 배경은 아고스비전의 핵심 경쟁력이자 비즈니스 전략의 근간을 이룬다. 딥테크 스타트업은 기술 개발부터 상용화까지 긴 시간과 막대한 자본이 소요되어 초기 생존 단계인 ’죽음의 계곡(Valley of Death)’을 넘어서기 매우 어렵다. 그러나 아고스비전은 CISS 연구단의 검증된 연구 성과를 기반으로 출발하여 기술적 불확실성을 상당 부분 해소한 상태에서 사업을 시작할 수 있었다. 또한, ’KIST’라는 공신력 있는 국가 연구기관의 후광은 초기 기술에 대한 시장의 신뢰를 확보하고, 정부 R&amp;D 과제 수주 및 정책 자금을 유치하는 데 결정적인 이점으로 작용했다. 이는 자본이 부족한 초기 스타트업이 안정적으로 성장 기반을 다지는 데 중요한 역할을 했다.</p>
<h3>2.2 성장 연혁 및 주요 성과</h3>
<p>아고스비전은 설립 이후 짧은 기간 동안 괄목할 만한 성과를 거두며 기술력과 시장성을 입증해왔다. 2021년 중소벤처기업부의 대표적인 기술창업 지원 프로그램인 팁스(TIPS)에 선정되었으며, 같은 해 ’K-Global 스타트업 공모전’에서 대상인 과학기술정보통신부 장관상을 수상했다.9</p>
<p>국제 무대에서도 기술의 혁신성을 인정받았다. 2023년 미국 라스베이거스에서 열린 세계 최대 가전·IT 전시회인 CES에서 ‘아고스뷰’ 제품으로 혁신상(Innovation Award)을 수상하며 글로벌 시장의 주목을 받았다.1 이후 2024년에는 정부의 유망 스타트업 육성 프로그램인 ‘초격차 스타트업 1000+’ 프로젝트에 선정되는 등 지속적인 성장을 위한 동력을 확보했다.10</p>
<p>이러한 성과는 투자 유치로도 이어졌다. 회사는 투자전문 액셀러레이터 씨엔티테크로부터 시드(Seed) 투자를 유치했으며 13, KDB산업은행의 ‘KDB NextONE’, 삼성전자의 ’C-Lab Outside’와 같은 유수의 액셀러레이팅 프로그램에 참여하며 사업 역량을 체계적으로 강화해왔다.10</p>
<h3>2.3 비전과 목표</h3>
<p>아고스비전의 핵심 비전은 ’지능형 로봇의 눈’을 개발하여 ’로봇에게 사람과 같은 수준의 공간 인식 능력을 제공’하는 것이다.8 이는 단순히 하드웨어 센서를 공급하는 것을 넘어, 로봇이 세상을 인식하고 인간과 상호작용하는 방식을 근본적으로 재정의하려는 야심 찬 목표를 내포하고 있다.10</p>
<p>궁극적으로 아고스비전은 광시야 3D 컴퓨터 비전 기술을 선도하는 ’컴퓨터 비전 솔루션 회사’로 성장하는 것을 지향한다.13 이는 센서 하드웨어 판매에 그치지 않고, 하드웨어와 긴밀하게 결합된 고도의 소프트웨어 및 AI 알고리즘을 통해 종합적인 인식 솔루션을 제공하는 기업으로 발전하겠다는 장기적인 로드맵을 보여준다.</p>
<h2>3.  핵심 기술 심층 분석: 아고스뷰(ArgosVue)의 작동 원리</h2>
<h3>3.1 하드웨어 아키텍처: 수직 배치 어안 렌즈 스테레오 카메라</h3>
<p>아고스뷰의 기술적 근간은 독특한 하드웨어 구성에서 비롯된다. 바로 ‘수직 방향으로 배치된 어안 렌즈(Fisheye Lens) 스테레오 카메라’ 시스템이다.8 일반적인 스테레오 카메라가 수평으로 배치되는 것과 달리, 수직 배치를 통해 수직 방향의 시야각을 극대화했다. 여기에 화각이 180도를 넘는 어안 렌즈 두 개를 사용하여 인간의 시야에 필적하거나 그 이상의 초광각 시야를 물리적으로 확보한다.7</p>
<p>사용되는 이미지 센서는 2메가픽셀(MP) 해상도의 컬러 CMOS 센서이며, ‘글로벌 셔터(Global Shutter)’ 방식을 채택했다.7 글로벌 셔터는 센서의 모든 픽셀이 동시에 빛을 받아들여 이미지를 생성하는 방식으로, 빠르게 움직이는 로봇이나 주변 객체를 촬영할 때 발생하는 이미지 왜곡(젤로 현상)을 원천적으로 방지한다. 이는 정확한 3D 깊이 정보를 계산하는 데 필수적인 요소다.</p>
<h3>3.2 소프트웨어 알고리즘: 구면 스테레오 매칭 (Spherical Stereo Matching)</h3>
<p>어안 렌즈는 넓은 시야를 제공하는 대신 이미지 중심에서 멀어질수록 극심한 방사상 왜곡을 발생시킨다. 이 왜곡된 이미지를 그대로 사용해서는 정확한 스테레오 정합(matching)이 불가능하다. 아고스비전은 이 문제를 해결하기 위해 ’구면 스테레오 매칭’이라는 고도의 알고리즘을 개발하여 적용했다.8</p>
<p>이 기술의 핵심은 획득한 2차원의 왜곡된 어안 이미지를 가상의 3차원 구(sphere) 표면에 투영하는 ‘구면 매핑(Spherical Mapping)’ 과정에 있다.8 이렇게 구면에 매핑된 두 개의 이미지는 왜곡이 보정된 상태이므로, 두 이미지 간의 대응점(corresponding points)을 찾아 시차(disparity)를 정밀하게 계산할 수 있다. 이 시차 정보는 삼각 측량 원리에 따라 각 픽셀의 깊이(depth) 정보로 변환된다. 이 복잡한 과정을 통해 최종적으로 고밀도의 ’깊이 맵(Depth Map)’과 ’3D 포인트 클라우드(Point Cloud)’가 실시간으로 생성되는 것이다.10</p>
<h3>3.3 데이터 처리 및 출력</h3>
<p>아고스뷰는 처리된 결과물을 다양한 형태로 출력하여 개발자의 활용성을 극대화한다. 고해상도 컬러 영상과 깊이 정보가 결합된 RGB-D 영상, 깊이 맵, 그리고 3D 포인트 클라우드 데이터를 실시간으로 제공한다.8 특히 데이터 출력 형태 중 하나로 라이다와 유사한 포인트 클라우드 형식을 지원하는데, 이는 기존에 라이다 센서를 기반으로 개발된 자율주행 알고리즘이나 시스템에 아고스뷰를 쉽게 통합할 수 있도록 하기 위한 전략적 고려이다.2</p>
<p>또한, 로봇 개발 생태계의 사실상 표준(de facto standard)인 ROS(Robot Operating System)를 완벽하게 지원한다.20 영상, 깊이 맵, 포인트 클라우드 등 모든 데이터를 ROS의 표준 메시지 형식인 ’토픽(Topic)’으로 발행(publish)하여, ROS 기반으로 개발하는 전 세계 로봇 개발자들이 별도의 드라이버 개발 없이 즉시 센서를 활용할 수 있도록 편의성을 제공한다.7</p>
<h3>3.4 내장형 AI 프로세서 (Edge AI)</h3>
<p>아고스뷰의 기술적 선택, 즉 어안 렌즈와 구면 스테레오 매칭의 조합은 ’최대 시야각 확보’라는 목표를 달성하기 위한 것이지만, 이는 필연적으로 ’계산 복잡도 증가’라는 대가를 수반한다. 이러한 막대한 연산량을 로봇의 주 제어 컴퓨터에 부담시키면 전체 시스템의 성능 저하를 초래할 수 있다.</p>
<p>아고스비전은 이 문제를 해결하기 위해 센서 내부에 NVIDIA Jetson 시리즈(TX2NX, Orin Nano 등)와 같은 고성능 AI 프로세서를 탑재하는 ‘엣지 컴퓨팅(Edge Computing)’ 방식을 채택했다.6 이를 통해 센서가 획득한 방대한 데이터를 외부로 전송하지 않고, 센서 자체적으로 실시간 3D 재구성, 객체 검출, 자세 추정 등 복잡한 컴퓨터 비전 알고리즘을 직접 실행할 수 있다.7 이는 시스템 전체의 부하를 줄이고 데이터 처리 지연 시간을 최소화하여 로봇의 반응 속도를 획기적으로 높인다.</p>
<p>결론적으로, 아고스뷰의 아키텍처는 ’광시야’라는 핵심 가치를 실현하기 위한 필연적인 기술적 선택들의 유기적인 조합이다. 이러한 설계는 제품의 단가를 높이는 요인이 될 수 있지만, 동시에 시스템 통합의 복잡성을 줄이고 실시간 성능을 보장하는 강력한 차별화 요소로 작용한다. 아고스뷰가 단순한 ’카메라’가 아닌, ’독립적인 지능형 인식 시스템(Intelligent Perception System)’이자 ’All-in-One 개발 환경’을 표방하는 이유가 바로 여기에 있다.10</p>
<h2>4.  제품 포트폴리오 분석</h2>
<p>아고스비전은 시장의 다양한 요구에 대응하기 위해 세분화된 제품 포트폴리오를 구축하고 있다. 이는 초기 기술 수용자를 위한 개발 플랫폼부터 상용 제품에 탑재되는 임베디드 모듈, 그리고 새로운 시장을 개척하기 위한 AIoT 디바이스까지 체계적으로 구성되어 있다. 이러한 포트폴리오는 ’기술 확산 모델’에 기반한 정교한 시장 침투 전략을 보여준다. 첫째, 개발자 키트로 초기 기술 수용자(innovators, early adopters)를 확보하여 기술 생태계를 구축하고, 둘째, DAR 모델로 로봇이라는 핵심 시장(early majority)을 본격적으로 공략하며, 셋째, AIoT 모델로 기술을 변용하여 지능형 관제라는 더 큰 규모의 인접 시장(late majority)으로 확장하는 단계적 접근을 취하고 있다.</p>
<h3>4.1  ArgosVue 개발자 키트 (Developer Kit / Lite)</h3>
<ul>
<li><strong>목표 고객:</strong> 이 제품은 로봇 공학, 컴퓨터 비전, AI 분야의 연구개발자 및 엔지니어를 주된 대상으로 한다.13 신속한 프로토타이핑과 새로운 애플리케이션 개발을 지원하는 것이 핵심 목적이다.</li>
<li><strong>핵심 특징:</strong> 가장 큰 특징은 ‘All-in-One’ 개발 환경을 제공한다는 점이다.10 제품 내에 Linux 기반 운영체제를 탑재하고 있어, 별도의 고성능 PC 없이 모니터, 키보드, 마우스만 직접 연결하면 독립된 개발 워크스테이션으로 사용할 수 있다. ROS 지원, 소프트웨어 개발 키트(SDK) 및 샘플 코드 제공을 통해 개발자들이 아고스뷰의 광시야 3D 데이터를 손쉽게 활용하여 알고리즘을 개발하고 테스트할 수 있도록 지원한다.8</li>
<li><strong>세부 모델:</strong> 성능과 가격에 따라 두 가지 모델로 나뉜다. 표준 ’개발자 키트’는 고성능 NVIDIA Jetson Orin Nano 8G 프로세서와 200° 어안 렌즈를 탑재하여 최대 수평 200°, 수직 160°의 시야각을 제공한다. 반면 ‘Lite’ 모델은 NVIDIA Jetson TX2NX 프로세서와 180° 어안 렌즈를 사용하여 수평 190°, 수직 130°의 시야각을 제공하며, 보다 경제적인 가격으로 핵심 기능을 경험할 수 있도록 구성되었다.10</li>
</ul>
<h3>4.2  ArgosVue DAR (Panoramic Pseudo-LiDAR)</h3>
<ul>
<li><strong>목표 시장:</strong> 자율주행 서비스 로봇, 마이크로 모빌리티 등 실제 상용 제품에 탑재되는 것을 목표로 하는 임베디드 센서 모듈이다.8</li>
<li><strong>핵심 특징:</strong> ’의사-라이다(Pseudo-LiDAR)’라는 개념을 전면에 내세운다. 이는 카메라 기반 센서임에도 불구하고, 라이다처럼 넓은 범위의 3D 포인트 클라우드를 생성하여 주변 환경을 3차원으로 인식하는 능력을 강조하는 용어다. 가장 큰 장점은 단일 모듈로 로봇의 전방, 좌우 측방, 그리고 바닥의 장애물과 노면의 단차까지 동시에 인식할 수 있다는 점이다.8 이를 통해 여러 개의 3D 센서를 사용해야 했던 기존 방식에 비해 시스템 비용과 데이터 처리의 복잡성을 획기적으로 줄일 수 있다.</li>
<li><strong>구조적 특징:</strong> 상용 로봇에 쉽게 장착할 수 있도록 설계되었다. 센서 헤드와 고성능 AI 컴퓨팅 모듈이 최대 1미터 길이의 유연한 케이블로 분리되는 구조를 채택하여, 좁은 공간에도 유연하게 설치할 수 있다.10 또한, 방수 및 방진 설계를 적용하여 실내는 물론 실외의 다양한 환경에서도 안정적인 성능을 제공하는 견고성을 확보했다.10</li>
</ul>
<h3>4.3  ArgosVue AIoT (AIoT Sensor)</h3>
<ul>
<li><strong>목표 시장:</strong> 로봇 시장을 넘어 지능형 관제, 산업 안전, 스마트 빌딩, 헬스케어 등 더 넓은 시장을 겨냥한 제품이다.8</li>
<li><strong>핵심 특징:</strong> 기존의 영상 감시 시스템(CCTV)이 가진 한계를 극복하는 데 초점을 맞춘다. 이 장치는 엣지 단의 내장 AI 프로세서가 실시간으로 영상을 분석하여 사람의 존재, 위치, 쓰러짐과 같은 특정 이벤트만을 감지한다. 그리고 전체 영상 스트림 대신, ’인식 결과’에 해당하는 메타데이터만을 중앙 서버로 전송한다.10</li>
<li><strong>기술적 차별점:</strong> 이러한 방식은 두 가지 핵심적인 가치를 제공한다. 첫째, 민감한 영상 정보를 외부로 전송하지 않아 ‘사생활 보호’ 문제를 근본적으로 해결한다.10 둘째, 전송 데이터의 크기를 기존 영상 대비 1/100 수준으로 대폭 줄여, 통신 비용을 절감하고 하나의 관제 시스템에 훨씬 더 많은 수의 센서를 연결할 수 있는 높은 ’확장성’을 제공한다.10 아고스뷰의 광시야 특성은 1미터 이내의 근거리에서도 사각지대 없이 사람을 인식할 수 있게 하여, 좁은 공간이나 위험 구역을 모니터링하는 데 최적화된 성능을 발휘한다.10</li>
</ul>
<h3>4.4 표 1: 아고스뷰 제품 라인별 상세 기술 사양 비교</h3>
<table><thead><tr><th>항목 (Item)</th><th>ArgosVue 개발자 키트 Lite</th><th>ArgosVue 개발자 키트</th><th>ArgosVue DAR</th><th>ArgosVue AIoT</th></tr></thead><tbody>
<tr><td><strong>목표 애플리케이션</strong></td><td>R&amp;D, 프로토타이핑</td><td>고성능 R&amp;D, 프로토타이핑</td><td>자율주행 로봇/모빌리티</td><td>지능형 관제, 산업 안전</td></tr>
<tr><td><strong>이미지 센서</strong></td><td>2MP 컬러 CMOS (글로벌 셔터)</td><td>2MP 컬러 CMOS (글로벌 셔터)</td><td>2MP 컬러 CMOS (글로벌 셔터)</td><td>광시야 카메라 (사양 미확인)</td></tr>
<tr><td><strong>렌즈</strong></td><td>180° 어안 렌즈</td><td>200° 어안 렌즈</td><td>200° 어안 렌즈</td><td>광시야 렌즈</td></tr>
<tr><td><strong>시야각 (FoV)</strong></td><td>190°(H) x 130°(V)</td><td>200°(H) x 160°(V)</td><td>200°(H) x 140°(V)</td><td>사각지대 없는 광시야</td></tr>
<tr><td><strong>유효 인식 거리</strong></td><td>0.2m ~ 8m</td><td>0.2m ~ 8m</td><td>0.5m ~ 8m</td><td>근거리 특화 (1m 이내)</td></tr>
<tr><td><strong>깊이맵 해상도</strong></td><td>1200 x 800</td><td>1200 x 800</td><td>1000 x 700</td><td>N/A (결과 데이터 전송)</td></tr>
<tr><td><strong>프레임 레이트</strong></td><td>20Hz</td><td>20Hz</td><td>20Hz</td><td>실시간 인식</td></tr>
<tr><td><strong>내장 프로세서</strong></td><td>NVIDIA Jetson TX2NX</td><td>NVIDIA Jetson Orin Nano 8G</td><td>고성능 AI 컴퓨팅 모듈</td><td>내장 AI 프로세서</td></tr>
<tr><td><strong>주요 특징</strong></td><td>All-in-One 개발 환경</td><td>최고 성능 개발 환경</td><td>분리형 모듈, 방수/방진</td><td>사생활 보호, 데이터 효율성</td></tr>
<tr><td><strong>데이터 소스</strong></td><td>7</td><td>7</td><td>8</td><td>8</td></tr>
</tbody></table>
<h2>5.  시장 적용 및 활용 사례 분석</h2>
<p>아고스뷰의 독보적인 광시야 3D 인식 기술은 다양한 시장에서 기존 기술이 해결하지 못했던 문제들을 해결하며 새로운 가치를 창출하고 있다. 특히 ’근접 공간(Proximal Space)’에서의 정밀한 3D 인식에 집중함으로써, 원거리 탐지에 강점을 가진 라이다와 명확히 차별화되는 시장을 공략하고 있다. 이는 라이다를 대체하는 것이 아닌, 상호 ’보완’하는 센서 퓨전 아키텍처 내에서 핵심적인 역할을 수행하는 전략적 포지셔닝으로 분석된다.</p>
<h3>5.1 주력 시장 1: 지능형 로봇 자율주행 (Autonomous Navigation)</h3>
<p>아고스뷰의 가장 핵심적인 적용 분야는 지능형 로봇의 자율주행이다. 기존 라이다 센서는 수직 시야각의 한계로 인해 로봇 바로 앞의 노면 상태를 파악하기 어려웠다. 아고스뷰는 넓은 수직 시야각을 통해 로봇 바로 앞의 낮은 장애물, 도로의 단차, 구멍 등을 정밀하게 인식하여, 실내외의 복잡하고 비정형적인 환경에서도 로봇이 안전하게 주행할 수 있도록 한다.5</p>
<p>또한, 하나의 센서로 전방은 물론 좌우 측면의 사각지대까지 동시에 감지할 수 있어, 여러 개의 센서를 조합해야 했던 기존 방식의 복잡성을 해결한다.1 이는 로봇 시스템의 하드웨어 비용 절감, 데이터 처리 부하 감소, 전력 소모 최적화로 이어져 로봇의 상용화를 앞당기는 데 기여한다.</p>
<h3>5.2 주력 시장 2: 인간-로봇 상호작용 (Human-Robot Interaction, HRI)</h3>
<p>미래의 서비스 로봇은 인간과 긴밀하게 협력하고 소통하는 능력이 필수적이다. 이를 위해서는 로봇이 가까운 거리에서 사람의 의도를 파악할 수 있어야 한다. 아고스뷰는 0.5미터에서 1미터 이내의 아주 가까운 거리에서도 사람의 전신을 프레임 안에 담아 자세, 제스처, 움직임을 놓치지 않고 인식할 수 있다.1</p>
<p>기존의 3D 센서들은 화각이 좁아 이렇게 가까운 거리에서는 사람의 일부(얼굴이나 상체)밖에 인식하지 못했다.1 아고스뷰는 이 문제를 해결함으로써, 로봇이 사용자의 바로 옆에서 함께 이동하거나 작업을 수행하는 등 보다 자연스럽고 직관적인 상호작용을 가능하게 하여 서비스 로봇의 지능을 한 단계 끌어올리는 데 핵심적인 역할을 한다.</p>
<h3>5.3 확장 시장: 산업 안전 및 지능형 시스템</h3>
<p>아고스뷰의 기술은 로봇을 넘어 다양한 지능형 시스템의 안전과 효율성을 높이는 데 활용될 수 있다.</p>
<ul>
<li><strong>지게차 및 중장비:</strong> 공장이나 건설 현장에서 지게차와 같은 중장비 주변은 작업자에게 매우 위험한 공간이다. 아고스뷰는 장비에 부착되어 사각지대 없이 근접한 작업자를 실시간으로 감지하고 경고를 보내 충돌 사고를 예방하는 안전 센서로 활용될 수 있다.10</li>
<li><strong>제한/금지 구역 감시:</strong> 기존 CCTV로는 모니터링이 어려운 좁은 공간이나 위험 구역에 작업자가 출입하거나, 쓰러짐과 같은 이상 상황이 발생했을 때 이를 즉시 감지하여 관리자에게 알리는 지능형 안전 모니터링 시스템을 구축할 수 있다.10</li>
<li><strong>전동 휠체어:</strong> 사용자의 안전을 위해 전동 휠체어에 탑재되어 주변 장애물과 보도의 턱과 같은 노면 상태를 미리 인식함으로써 충돌 및 전도 사고를 방지하는 보조 시스템으로 적용될 수 있다.11</li>
</ul>
<h3>5.4 협력 사례 및 시장 진출 전략</h3>
<p>아고스비전은 기술의 상용화를 위해 국내외 유수 기업들과의 협력을 적극적으로 추진하고 있다. 특히 현대자동차, 만도와 같은 국내 대기업들과 서비스 로봇에 아고스뷰를 적용하기 위한 협업을 진행하고 있다는 점은 기술의 신뢰성과 시장성을 입증하는 중요한 사례이다.23</p>
<p>또한, 회사는 초기 시장 진입 전략으로 해외 크라우드 펀딩 플랫폼을 통해 ’아고스뷰 개발자 키트’를 전 세계 로봇 및 컴퓨터 비전 개발자들에게 판매할 계획을 세운 바 있다.13 이는 제품을 판매하는 것 이상의 의미를 가진다. 글로벌 시장에 아고스비전의 기술력을 알리고 초기 사용자들의 피드백을 적극적으로 수렴하여 제품을 개선하며, 동시에 아고스뷰를 중심으로 한 글로벌 개발자 생태계를 구축하기 위한 전략적 행보로 평가된다.</p>
<h2>6.  경쟁 환경 분석 및 시장 포지셔닝</h2>
<p>아고스뷰는 3D 비전 센서 시장에서 독자적인 기술적 포지션을 구축하고 있으나, 동시에 다양한 기술 대안 및 직접적인 경쟁 제품들과 치열한 경쟁에 직면해 있다.</p>
<h3>6.1 기술 대안과의 비교 (vs. LiDAR)</h3>
<ul>
<li><strong>차별적 우위:</strong> 라이다와의 가장 큰 차별점은 압도적인 수직 시야각이다. 아고스뷰는 최대 160°의 수직 시야각을 제공하는 반면, 일반적인 라이다는 30° 내외에 그친다.2 이 차이는 로봇의 근접 공간 인식 능력에서 결정적인 우위를 제공한다. 또한, 고해상도 컬러 영상을 함께 제공하여 AI 기반의 정교한 객체 인식 및 분류에 훨씬 유리하며, 일반적으로 동일한 수준의 3D 커버리지를 구현하는 데 있어 라이다보다 비용 효율적이다.3</li>
<li><strong>상대적 약점:</strong> 아고스뷰는 카메라 기반 기술의 본질적인 한계를 가진다. 최대 인식 거리가 수십 미터에서 수백 미터에 달하는 라이다에 비해 8미터 내외로 짧다. 또한, 스테레오 매칭 알고리즘은 외부 광원의 영향을 받기 때문에 직사광선이 강한 실외 환경에서는 성능이 저하될 수 있다. 텍스처가 거의 없는 균일한 표면(예: 흰색 벽, 유리)에서는 대응점을 찾기 어려워 깊이 정보를 정확하게 추출하지 못하는 경우도 발생할 수 있다.</li>
</ul>
<h3>6.2 직접 경쟁 제품 심층 비교 (vs. Other Stereo Cameras)</h3>
<p>3D 스테레오 비전 카메라 시장에는 Intel RealSense, Orbbec, Stereolabs와 같은 강력한 글로벌 기업들이 포진해 있다. 이들 제품과 아고스뷰를 비교 분석하면 아고스뷰의 독보적인 경쟁력을 명확히 파악할 수 있다.</p>
<p>아래 표에서 볼 수 있듯이, Intel RealSense D455(87°x58°), Orbbec Gemini 2 XL(91°x66°), Stereolabs ZED 2i(110°x70°) 등 주요 경쟁 제품들의 시야각과 비교했을 때, 아고스뷰 개발자 키트의 시야각(200°x160°)은 수평, 수직 모든 면에서 현저하게 넓다.24 이는 아고스뷰가 ’광시야(Panoramic)’라는 명확하고 독보적인 시장 포지션을 구축했음을 의미한다.</p>
<p>그러나 아고스뷰의 진정한 경쟁 우위는 단순히 ’더 넓은 시야각’이라는 하드웨어 사양에만 머무르지 않는다. 핵심적인 가치 제안은 ’하나의 센서로 여러 문제를 동시에 해결하는 통합 솔루션’에 있다. 기존 로봇 시스템을 설계할 때, 개발자들은 전방 장애물 감지를 위한 3D 센서, 측면 사각지대 커버를 위한 추가 센서, 바닥 단차 인식을 위한 또 다른 센서를 각각 별도로 장착하고 이들을 통합해야 했다.26 이는 하드웨어 구매 비용뿐만 아니라, 여러 센서의 데이터를 동기화하고 융합하는 데 막대한 개발 시간과 비용을 발생시켰다. 아고스뷰는 “하나의 모듈로 전방과 측방 및 바닥의 장애물 인식이 가능“하다고 주장함으로써 8, 고객의 시스템 복잡성, 개발 비용, 통합 시간을 획기적으로 줄여주는 강력한 경제적 이점을 제공한다. 따라서 개별 센서로서의 가격이 경쟁 제품보다 다소 높더라도, 시스템 전체 구축 비용(Total Cost of Ownership, TCO) 관점에서는 오히려 더 경제적인 선택이 될 수 있다.</p>
<h3>6.3 표 2: 주요 3D 스테레오 비전 센서 경쟁 제품 비교 분석</h3>
<table><thead><tr><th>항목 (Item)</th><th><strong>아고스비전 ArgosVue (Dev Kit)</strong></th><th><strong>Intel RealSense D455</strong></th><th><strong>Orbbec Gemini 2 XL</strong></th><th><strong>Stereolabs ZED 2i (2.1mm)</strong></th></tr></thead><tbody>
<tr><td><strong>기술 방식</strong></td><td>Passive Stereo (Fisheye)</td><td>Active IR Stereo</td><td>Infrared Enhanced Stereo</td><td>Passive Stereo</td></tr>
<tr><td><strong>시야각 (H x V)</strong></td><td><strong>200° x 160°</strong></td><td>87° x 58°</td><td>91° x 66°</td><td>110° x 70°</td></tr>
<tr><td><strong>깊이 해상도 @ FPS</strong></td><td>1200x800 @ 20fps</td><td>1280x720 @ 90fps</td><td>1280x800 @ 10fps</td><td>1280x720 @ 60fps</td></tr>
<tr><td><strong>유효 인식 거리</strong></td><td>0.2m ~ 8m</td><td>0.6m ~ 6m+</td><td>0.4m ~ 20m</td><td>0.3m ~ 20m</td></tr>
<tr><td><strong>셔터 타입</strong></td><td>글로벌 셔터</td><td>글로벌 셔터</td><td>글로벌 셔터</td><td>롤링 셔터</td></tr>
<tr><td><strong>내장 프로세서</strong></td><td><strong>NVIDIA Jetson Orin Nano</strong></td><td>Intel RealSense Vision Processor D4</td><td>Orbbec OBox Module</td><td>N/A (Host PC 의존)</td></tr>
<tr><td><strong>IMU</strong></td><td>미언급 (확인 필요)</td><td>Yes</td><td>Yes</td><td>Yes</td></tr>
<tr><td><strong>주요 특징</strong></td><td><strong>초광각 FoV</strong>, All-in-One 개발 환경</td><td>높은 프레임레이트, 성숙한 SDK</td><td>장거리 인식, PoE 지원</td><td>신경망 깊이 엔진, IP66 등급</td></tr>
<tr><td><strong>데이터 소스</strong></td><td>7</td><td>24</td><td>28</td><td>30</td></tr>
</tbody></table>
<h3>6.4 SWOT 분석</h3>
<ul>
<li>
<p><strong>강점 (Strengths):</strong></p>
</li>
<li>
<p>경쟁사를 압도하는 독보적인 초광각 시야각(FoV).</p>
</li>
<li>
<p>KIST 스핀오프 기업으로서 보유한 강력한 R&amp;D 역량과 기술 신뢰성.</p>
</li>
<li>
<p>고성능 AI 프로세서를 내장하여 엣지 단에서 복잡한 비전 알고리즘 실행 가능.</p>
</li>
<li>
<p>ROS 지원 등 개발자 친화적인 생태계 구축 노력.</p>
</li>
<li>
<p><strong>약점 (Weaknesses):</strong></p>
</li>
<li>
<p>글로벌 경쟁사 대비 상대적으로 낮은 브랜드 인지도.</p>
</li>
<li>
<p>스타트업으로서 대량 생산 경험 및 품질 관리(QC) 역량에 대한 검증 필요.</p>
</li>
<li>
<p>고성능 프로세서 탑재로 인한 잠재적인 가격 경쟁력 문제.</p>
</li>
<li>
<p><strong>기회 (Opportunities):</strong></p>
</li>
<li>
<p>서비스 로봇, 자율주행 모빌리티, 스마트 팩토리 등 전방 시장의 폭발적인 성장.13</p>
</li>
<li>
<p>산업 현장의 안전 규제 강화에 따른 고성능 안전 센서 수요 증가.</p>
</li>
<li>
<p>AI 기술 발전으로 고품질 3D 비전 데이터의 가치 증대.</p>
</li>
<li>
<p><strong>위협 (Threats):</strong></p>
</li>
<li>
<p>Intel, Orbbec 등 자본력과 유통망을 갖춘 글로벌 대기업과의 경쟁 심화.</p>
</li>
<li>
<p>가격이 하락하고 성능이 개선된 차세대 라이다(Solid-State LiDAR 등) 기술의 위협.</p>
</li>
<li>
<p>반도체 등 핵심 부품의 글로벌 공급망 불안정 리스크.</p>
</li>
</ul>
<h2>7.  결론: 미래 전망 및 전략적 제언</h2>
<h3>7.1 성장 잠재력 및 시장 기회 요약</h3>
<p>아고스비전은 기존 3D 센서 시장에 존재했던 명확한 기술적 공백, 즉 ’수직 시야각의 한계’를 해결하는 독보적인 ‘광시야’ 기술을 통해 지능형 로봇 및 산업 안전 시장에서 막대한 성장 잠재력을 보유하고 있다. AI 기술의 고도화와 로봇 시장의 확장은 아고스뷰와 같이 풍부하고 질 높은 시각 데이터를 제공하는 센서에 대한 수요를 필연적으로 가속화할 것이다. 특히 근접 공간에서의 정밀한 3D 인식과 인간-로봇 상호작용 능력은 아고스뷰를 단순한 부품이 아닌, 차세대 지능형 시스템의 핵심 솔루션으로 자리매김하게 할 것이다.</p>
<h3>7.2 도전 과제 및 리스크 분석</h3>
<p>그러나 이러한 밝은 전망 이면에는 극복해야 할 도전 과제들이 존재한다.</p>
<ul>
<li><strong>기술적 과제:</strong> 강한 직사광선과 같은 까다로운 실외 환경에서의 인식 안정성을 지속적으로 개선해야 한다. 또한, 대량 생산 체제로 전환할 때 모든 제품에서 균일한 성능과 정밀한 캘리브레이션을 유지하는 것이 중요한 과제가 될 것이다. 고성능 프로세서로 인한 전력 소모를 최적화하는 것 역시 모바일 로봇 적용에 있어 중요한 고려사항이다.</li>
<li><strong>사업적 과제:</strong> 글로벌 시장에서 Intel과 같은 거대 기업들과 경쟁하기 위해서는 브랜드 인지도를 높이고 신뢰를 구축하는 것이 시급하다. 안정적인 부품 공급망을 확보하고, 규모의 경제를 통해 가격 경쟁력을 갖추는 것 또한 장기적인 생존에 필수적이다. 핵심 시장인 로봇 분야를 넘어 AIoT 등 새로운 시장으로 성공적으로 다각화하는 능력도 시험대에 오를 것이다.</li>
</ul>
<h3>7.3 지속 가능한 성장을 위한 전략적 제언</h3>
<p>아고스비전이 지속 가능한 성장을 이루고 글로벌 리더로 도약하기 위해 다음과 같은 전략적 방향을 제언한다.</p>
<ol>
<li><strong>전략적 파트너십 강화:</strong> 현재 진행 중인 현대차, 만도와의 협력을 넘어, 물류, 농업, 건설 등 특정 버티컬 시장을 선도하는 로봇 기업들과 깊이 있는 전략적 파트너십을 체결해야 한다. 성공적인 상용화 사례(use case)를 공동으로 개발하고 이를 시장에 적극적으로 알려, 기술의 효용성을 입증하고 시장 진입 장벽을 낮추는 전략이 필요하다.</li>
<li><strong>개발자 생태계 활성화:</strong> ROS 지원을 넘어, 아고스뷰의 성능을 극대화할 수 있는 다양한 AI 모델(예: 정밀 자세 추정, 객체 분할)과 통합 예제, 상세한 튜토리얼을 제공하여 개발자 커뮤니티를 적극적으로 육성해야 한다. 강력하고 활발한 개발자 생태계는 기술이 시장의 사실상 표준(de facto standard)으로 자리 잡는 데 결정적인 역할을 한다.</li>
<li><strong>솔루션 기반 비즈니스 모델로의 전환:</strong> 장기적인 성공은 하드웨어 판매를 넘어 ’광시야 데이터 플랫폼’을 구축하는 데 달려있다. 하드웨어 기술은 시간이 지남에 따라 경쟁사에 의해 모방될 수 있지만, 아고스뷰 센서를 통해 독점적으로 수집된 ’초광각 3D 데이터’는 강력한 자산이 된다. 이 독점 데이터를 활용하여 특정 환경(예: 복잡한 물류창고의 팔레트 인식, 공사 현장의 작업자 동선 분석)에 특화된 고성능 AI 인식 알고리즘을 개발할 수 있다. 이렇게 개발된 알고리즘을 ‘지게차 충돌 방지 AI 모듈’, ’HRI 제스처 인식 솔루션’과 같이 특정 애플리케이션에 최적화된 소프트웨어 솔루션 형태로 제공해야 한다. 이는 하드웨어 판매를 통한 일회성 수익을 넘어, 라이선스나 구독형 소프트웨어(SaaS) 모델을 통해 지속적인 고부가가치를 창출하는 길이다. 이는 아고스비전이 단순한 센서 제조업체를 넘어, 그들의 최종 목표인 ’컴퓨터 비전 솔루션 회사’로 진화하는 핵심 경로가 될 것이다.13</li>
</ol>
<h2>8. 참고 자료</h2>
<ol>
<li>아고스비전, 지능형 로봇의 눈으로 사용되는 광시야 3D 비전 센서 ‘아고스뷰’ 개발 - 전자신문, https://m.etnews.com/20230922000169?obj=Tzo4OiJzdGRDbGFzcyI6Mjp7czo3OiJyZWZlcmVyIjtOO3M6NzoiZm9yd2FyZCI7czoxMzoid2ViIHRvIG1vYmlsZSI7fQ%3D%3D</li>
<li>“로봇도 사람만큼 볼 수 있어야 더 쓸모 있어” - 지디넷코리아, https://zdnet.co.kr/view/?no=20220324145549</li>
<li>ArgosVision - Ultra-wide 3D Depth Camera with Human FOV - Seoulz, https://www.seoulz.com/argosvision-ultra-wide-3d-depth-camera-with-human-fov/</li>
<li>아고스비전, 인간과 같은 시야를 가진 카메라가 로봇에 사용된다면? - 더프론티어, https://thefrontier.co.kr/argosvision/</li>
<li>아고스비전 - 아고스뷰 개발자 키트 - 한국로봇산업협회, https://www.k-robot.co.kr/k-robot/view.php?idx=173038&amp;page=38</li>
<li>www.robotworld.or.kr, https://www.robotworld.or.kr/visitors/pop_list_of_exhibitors.php?idx=101</li>
<li>ArgosVue Developer Kit - tradeKorea.com, https://www.tradekorea.com/product/detail/P806325/ArgosVue-Developer-Kit.html</li>
<li>(주)아고스비전, https://www.ace4u.kr/sub0902/fcompanyfull/download/id/902/type/etc</li>
<li>(주)아고스비전(광시야 3D 비전 센서) 기업정보 - 넥스트유니콘, https://www.nextunicorn.kr/company/ba11641fb283a396</li>
<li>ARGOSVISION, https://argosvision.com/ko/</li>
<li>[기업 인터뷰] 아고스비전, “광시야 3D 카메라로 로봇에게 눈을” - 제이엔피글로벌, https://www.jnp-aventures.com/?kboard_content_redirect=95</li>
<li>[ICT창업멘토링, 스타트업 길을 열다]&lt;12&gt;아고스비전 “광시야 3D 카메라로 ‘로봇의 눈’ 되겠다”, https://www.etnews.com/20221129000202</li>
<li>엔티테크, 지능형 로봇용 광시야 3D 비전 센서 스타트업 ’아고스비전’에 투자 - 넥스트유니콘, https://www.nextunicorn.kr/content/4550bd465b19ea97</li>
<li>지능형 로봇 3D비전센서 기업 ‘아고스비전’, 시드 투자 유치 - 로봇신문, https://www.irobotnews.com/news/articleView.html?idxno=26572</li>
<li>아고스비전 - 2025 로보월드, https://www.robotworld.or.kr/visitors/pop_list_of_exhibitors.php?idx=883</li>
<li>광시야 3D 비전 센서 개발 ‘아고스비전’, 씨엔티테크에서 시드 투자유치 - 와우테일, https://wowtale.net/2021/10/12/29962/</li>
<li>ARGOSVISION, https://argosvision.com/</li>
<li>Spherical stereo: (a)Spherical stereo pair (topbottom); (b)Spherical stereo geometry - ResearchGate, https://www.researchgate.net/figure/Spherical-stereo-aSpherical-stereo-pair-topbottom-bSpherical-stereo-geometry_fig11_257672104</li>
<li>Real-Time Sphere Sweeping Stereo From Multiview Fisheye Images - CVF Open Access, https://openaccess.thecvf.com/content/CVPR2021/papers/Meuleman_Real-Time_Sphere_Sweeping_Stereo_From_Multiview_Fisheye_Images_CVPR_2021_paper.pdf</li>
<li>아고스비전 - 무인이동체산업엑스포, https://uwc.center/?kboard_content_redirect=154</li>
<li>ArgosVue DAR - HANNOVER MESSE, https://www.hannovermesse.de/apollo/hannover_messe_2025/obs/Binary/A1424360/1424360_05026022.pdf</li>
<li>강남구, ’스마트 라이프 위크 2025’서 스마트도시 비전 선보인다 | 강남구청 &gt; 강남소식 &gt; 보도자료 &gt; 보도자료, https://www.gangnam.go.kr/board/B_000031/1074704/view.do?mid=ID01_0313</li>
<li>[인터뷰] 아고스비전, “아고스뷰로 5배 이상 넓은 시야 확보”, https://www.startuptoday.kr/news/articleView.html?idxno=44417</li>
<li>RealSense™ Depth Camera D455 (camera only) - FRAMOS, https://framos.com/products/3d/3d-cameras/depth-camera-d455-bulk-24722/</li>
<li>STEREOLABS ZED 2i CAMERA - Intuitive Robots, https://www.intuitive-robots.com/spot-robot-payloads-and-accessories/stereolabs-zed-2i-camera/</li>
<li>아고스비전 제품 홍보영상 - Sexyzoo Inc., https://sexyzoo.com/portfolio/argosvision/</li>
<li>Intel® RealSense™ Depth Camera D455 - Product Specifications, https://www.intel.com/content/www/us/en/products/sku/205847/intel-realsense-depth-camera-d455/specifications.html</li>
<li>Orbbec Gemini 2 XL 3D Camera - B&amp;H, https://www.bhphotovideo.com/c/product/1826621-REG/orbbec_100100424_gemini_2_xl_depth.html</li>
<li>Gemini 2 XL | Datasheet v1.0 - Cloudfront.net, https://d1cd332k3pgc17.cloudfront.net/wp-content/uploads/2023/12/ORBBEC_Datasheet_Gemini-2-XL.pdf</li>
<li>ZED 2i Camera Overview &amp; Datasheet - Mouser Electronics, https://www.mouser.com/datasheet/2/1520/StereoLabs_ZED_2i_Datasheet-3401402.pdf</li>
<li>ZED 2i Camera Overview &amp; Datasheet - Mouser Electronics, https://www.mouser.com/datasheet/2/1520/ZED_2i_Datasheet_v1_2-3498613.pdf</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>