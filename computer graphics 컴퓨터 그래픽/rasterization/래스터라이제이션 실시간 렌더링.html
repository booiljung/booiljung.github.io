<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:래스터라이제이션 실시간 렌더링</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>래스터라이제이션 실시간 렌더링</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">컴퓨터 그래픽 (Computer Graphics)</a> / <a href="index.html">래스터라이제이션 (Rasterization)</a> / <span>래스터라이제이션 실시간 렌더링</span></nav>
                </div>
            </header>
            <article>
                <h1>래스터라이제이션 실시간 렌더링</h1>
<h2>1.  래스터라이제이션의 기초 원리</h2>
<h3>1.1 1: 기하학에서 픽셀까지: 래스터라이제이션의 핵심 개념</h3>
<p>컴퓨터 그래픽스에서 3차원 가상 세계를 2차원 화면에 표시하는 과정은 렌더링(Rendering)이라 불리며, 이 렌더링을 수행하는 가장 보편적이고 효율적인 기술 중 하나가 바로 래스터라이제이션(Rasterization)이다. 이 기술의 핵심을 이해하기 위해서는 먼저 ’래스터(Raster)’라는 개념을 명확히 해야 한다.</p>
<h4>1.1.1 래스터의 정의</h4>
<p>래스터란 현대의 모든 디지털 디스플레이를 구성하는 기본 캔버스로, 이미지를 표현하기 위해 화상 정보를 2차원 배열 형태의 픽셀(Pixel, Picture Element)로 구성한 것을 의미한다.1 즉, 래스터는 격자 형태로 배열된 연속된 픽셀들의 집합이다. 우리가 보는 모니터, 스마트폰 화면 등은 모두 이러한 픽셀 격자로 이루어져 있으며, 각 픽셀에 특정 색상 값을 할당함으로써 최종 이미지가 형성된다.</p>
<p>래스터라이제이션이라는 용어는 독일어 ‘Raster’(골격, 틀)에서 유래했으며, 이는 라틴어 ‘rāstrum’(갈퀴, 긁개)에 뿌리를 두고 있다.3 이 어원은 기술의 본질을 직관적으로 설명하는 강력한 비유를 제공한다. 래스터라이제이션은 마치 갈퀴로 흙을 긁어 모양을 만들듯, 3차원 공간에 정의된 기하학적 데이터를 2차원 픽셀 격자 위로 ‘긁어서’ 어떤 픽셀들이 해당 기하학적 형태에 의해 ’덮이는지’를 결정하는 과정이다.</p>
<h4>1.1.2 근본적인 과제: 벡터에서 래스터로의 변환</h4>
<p>래스터라이제이션의 근본적인 과제는 3차원 객체의 벡터(Vector) 기반 표현을 2차원 래스터 이미지로 변환하는 것이다.2 3D 모델은 수학적으로 정의된 점(Vertex), 선(Edge), 면(Polygon)의 집합, 즉 벡터 데이터로 구성된다. 래스터라이제이션은 이러한 추상적인 기하학 정보를 가져와 화면의 물리적인 픽셀 격자에 투영하고 채우는 구체적인 작업이다. 이 접근 방식은 ‘객체 순서(Object-Order)’ 처리 철학을 따르는데, 이는 씬(Scene)의 각 객체를 순서대로 가져와 화면에 그려나가는 방식을 의미한다.</p>
<h4>1.1.3 기본 단위로서의 프리미티브</h4>
<p>래스터라이제이션 과정의 입력 데이터는 점(Point), 선(Line), 그리고 가장 중요한 삼각형(Triangle)과 같은 기하학적 기본 단위, 즉 프리미티브(Primitive)다.5 복잡한 3D 모델은 렌더링 파이프라인에 들어가기 전에 거의 예외 없이 수많은 삼각형의 집합인 메시(Mesh)로 분해된다. 따라서 3D 래스터라이제이션이 풀어야 할 가장 중심적인 문제는 ’삼각형을 래스터화하는 방법’이다.3</p>
<p>삼각형이 보편적으로 사용되는 이유는 그것이 기하학적으로 가장 단순하고 안정적인 다각형이기 때문이다. 임의의 세 개의 정점은 항상 하나의 평면을 정의하므로, 표면 법선(Normal), 면적, 보간(Interpolation)과 같은 계산이 매우 단순하고 예측 가능해진다. 이러한 단순성은 대규모 병렬 처리를 수행하는 GPU(Graphics Processing Unit)의 하드웨어 구현에 있어 절대적으로 중요하다.</p>
<h4>1.1.4 결정성과 스캔 변환 규칙</h4>
<p>래스터라이제이션 과정은 반드시 결정적(Deterministic)이어야 한다. 즉, 동일한 입력에 대해 항상 동일한 출력을 보장해야 한다. 만약 인접한 두 삼각형이 공유하는 경계선 위의 픽셀을 처리하는 규칙이 명확하지 않다면, 렌더링 순서에 따라 픽셀이 누락되거나(틈 발생) 중복으로 그려져(겹침 발생) 시각적 결함(Artifact)을 유발할 수 있다.3</p>
<p>이 문제를 해결하기 위해 ’탑-레프트 규칙(Top-Left Rule)’과 같은 일관된 스캔 변환 규칙이 사용된다. 이 규칙은 Direct3D 및 다수의 OpenGL 구현에서 채택하고 있으며, 다음과 같이 정의된다 3:</p>
<ol>
<li>픽셀의 중심이 삼각형 내부에 완전히 포함될 경우 해당 픽셀을 채운다.</li>
<li>픽셀의 중심이 정확히 삼각형의 경계선(Edge) 위에 놓일 경우, 그 경계선이 ‘상단(Top)’ 경계선이거나 ‘왼쪽(Left)’ 경계선일 때만 픽셀을 채운다.</li>
</ol>
<ul>
<li>’상단 경계선’은 정확히 수평이며 다른 경계선들보다 위에 있는 선을 의미한다.</li>
<li>’왼쪽 경계선’은 수평이 아니면서 삼각형의 왼쪽에 위치하는 선을 의미한다.</li>
</ul>
<p>이러한 규칙은 두 인접 삼각형이 경계선을 공유할 때, 해당 경계선 위의 픽셀이 단 하나의 삼각형에 의해서만 렌더링되도록 보장한다. 이는 픽셀이 두 번 이상 래스터화되는 것을 방지하여 계산 낭비를 줄이고 3, GPU의 수많은 코어가 어떤 순서로 병렬 처리하더라도 항상 일관되고 틈이 없는(hole-free) 최종 이미지를 생성하는 기반이 된다. 따라서 이 규칙은 단순한 구현 세부사항이 아니라, 병렬 하드웨어 환경에서 시각적 일관성을 보장하는 소프트웨어 API와 하드웨어 간의 근본적인 약속이다.</p>
<h2>2.  현대 프로그래밍 가능 그래픽스 파이프라인 상세 분석</h2>
<h3>2.1 1: 아키텍처 개요</h3>
<p>현대의 실시간 3D 렌더링은 단일 칩의 독자적인 작업이 아니라, 중앙 처리 장치(CPU)와 그래픽 처리 장치(GPU) 간의 긴밀한 협력을 통해 이루어진다. 이 협력 관계와 렌더링 파이프라인의 구조적 진화를 이해하는 것은 래스터라이제이션의 작동 방식을 파악하는 데 필수적이다.</p>
<h4>2.1.1 CPU와 GPU의 파트너십</h4>
<p>렌더링 과정은 본질적으로 분업화된 파트너십이다. CPU는 애플리케이션의 상위 레벨 로직, 씬 관리, 물리 시뮬레이션, 그리고 렌더링할 객체를 선별하는 컬링(Culling) 연산 등을 담당한다.4 CPU는 이러한 준비 작업을 마친 후, 렌더링에 필요한 데이터(정점 정보, 텍스처, 재질 등)와 그리기 명령(Draw Call)을 GPU로 전송한다. 그러면 GPU는 고도로 병렬화된 자체 파이프라인을 통해 이 명령들을 실행하여 최종 이미지를 생성한다.4 이러한 역할 분담은 각 프로세서가 가장 잘하는 작업에 집중하게 함으로써 실시간 프레임 속도를 달성하는 데 결정적인 역할을 한다.</p>
<h4>2.1.2 고정 함수에서 프로그래밍 가능 파이프라인으로의 진화</h4>
<p>초기 3D 그래픽스 하드웨어는 ‘고정 함수 파이프라인(Fixed-Function Pipeline, FFP)’ 구조를 가졌다. 이 파이프라인은 하드웨어에 미리 정의된 제한된 수의 기능(예: 특정 조명 모델, 정해진 변환 방식)만을 제공했으며, 개발자는 단지 이 기능들을 설정하고 조합하는 것만 가능했다.7 이는 창의적인 시각 효과 구현에 큰 제약으로 작용했다.9</p>
<p>그래픽 기술의 혁명은 ’프로그래머블 셰이더(Programmable Shader)’의 등장과 함께 시작되었다. 셰이더는 GPU 상에서 직접 실행되는 작은 프로그램으로, 개발자가 파이프라인의 특정 단계를 직접 코드로 제어할 수 있게 해준다.11 DirectX 8.0과 OpenGL 2.0을 기점으로 도입된 버텍스 셰이더(Vertex Shader)와 픽셀 셰이더(Pixel Shader)는 개발자에게 정점(Vertex)과 픽셀(Pixel) 수준의 처리 과정을 완벽하게 제어할 수 있는 권한을 부여했다.10 이로 인해 고정된 기능의 한계를 넘어 무한에 가까운 시각적 효과를 창출할 수 있게 되었고, 이는 현대 컴퓨터 그래픽스의 폭발적인 발전을 이끌었다. 현재의 GPU는 오래된 고정 함수 API 호출을 내부적으로 셰이더를 이용해 에뮬레이션하여 호환성을 유지한다.14</p>
<h4>2.1.3 데이터 흐름 개요</h4>
<p>렌더링 파이프라인의 전체 데이터 흐름은 다음과 같이 요약할 수 있다. 먼저 애플리케이션(주로 CPU에서 실행)이 3D 모델의 정점 데이터를 정점 버퍼(Vertex Buffer)에 채워 넣는다. 이 데이터는 GPU로 전송되어 파이프라인의 첫 단계인 입력 조립기(Input Assembler)를 통해 처리된다. 이후 여러 지오메트리 처리 단계를 거치며 3D 공간의 좌표가 2D 화면 좌표로 변환된다. 래스터라이저(Rasterizer)는 변환된 기하학 정보를 픽셀 조각인 프래그먼트(Fragment)로 변환하고, 프래그먼트 셰이더가 각 프래그먼트의 최종 색상을 계산한다. 마지막으로 출력 병합기(Output Merger)에서 깊이 테스트와 블렌딩 등을 거쳐 최종 픽셀 색상이 프레임버퍼(Framebuffer)에 기록되고, 이 프레임버퍼의 내용이 화면에 표시된다.1</p>
<h4>2.1.4 표 1: 현대 그래픽스 렌더링 파이프라인 단계</h4>
<p>아래 표는 현대 프로그래밍 가능 그래픽스 파이프라인의 각 단계를 요약한 것이다. 이는 이어질 상세 설명의 로드맵 역할을 하며, 각 단계의 핵심 기능, 입출력 데이터, 그리고 프로그래밍 가능 여부를 명확히 보여준다.</p>
<table><thead><tr><th>단계 이름</th><th>핵심 기능</th><th>입력</th><th>출력</th><th>프로그래밍 가능 여부</th></tr></thead><tbody>
<tr><td><strong>입력 조립기 (Input Assembler)</strong></td><td>정점 데이터로부터 프리미티브(삼각형 등) 구성</td><td>정점/인덱스 버퍼</td><td>프리미티브</td><td>고정 함수</td></tr>
<tr><td><strong>버텍스 셰이더 (Vertex Shader)</strong></td><td>정점의 좌표 변환 및 기타 정점별 연산</td><td>개별 정점</td><td>변환된 정점</td><td><strong>프로그래밍 가능</strong></td></tr>
<tr><td><strong>헐 셰이더 (Hull Shader)</strong></td><td>테셀레이션 수준 및 제어점 정의</td><td>제어점 패치</td><td>변환된 제어점, 테셀레이션 계수</td><td><strong>프로그래밍 가능</strong></td></tr>
<tr><td><strong>테셀레이터 (Tessellator)</strong></td><td>정의된 수준에 따라 프리미티브 세분화</td><td>테셀레이션 계수</td><td>새로운 샘플링 포인트</td><td>고정 함수</td></tr>
<tr><td><strong>도메인 셰이더 (Domain Shader)</strong></td><td>세분화된 정점의 최종 위치 계산</td><td>샘플링 포인트, 제어점 패치</td><td>변환된 정점</td><td><strong>프로그래밍 가능</strong></td></tr>
<tr><td><strong>지오메트리 셰이더 (Geometry Shader)</strong></td><td>프리미티브 생성, 수정, 파괴</td><td>프리미티브</td><td>0개 이상의 프리미티브</td><td><strong>프로그래밍 가능</strong></td></tr>
<tr><td><strong>래스터라이저 (Rasterizer)</strong></td><td>프리미티브를 프래그먼트로 변환 (클리핑, 컬링 등 포함)</td><td>변환된 프리미티브</td><td>프래그먼트</td><td>고정 함수</td></tr>
<tr><td><strong>프래그먼트 셰이더 (Fragment Shader)</strong></td><td>프래그먼트(픽셀)의 최종 색상 계산 (텍스처링, 조명)</td><td>보간된 프래그먼트 데이터</td><td>프래그먼트 색상 및 깊이</td><td><strong>프로그래밍 가능</strong></td></tr>
<tr><td><strong>출력 병합기 (Output Merger)</strong></td><td>프래그먼트를 프레임버퍼와 병합 (깊이/스텐실 테스트, 블렌딩)</td><td>프래그먼트 색상 및 깊이</td><td>최종 픽셀 색상</td><td>고정 함수</td></tr>
</tbody></table>
<h3>2.2 2: 지오메트리 처리 단계 (“무엇을“과 “어디에“를 처리)</h3>
<p>파이프라인의 전반부는 주로 3D 모델의 기하학적 정보, 즉 ‘무엇을(What)’ ‘어디에(Where)’ 그릴 것인지를 결정하는 데 집중한다. 이 단계들은 정점(Vertex) 데이터를 입력받아 화면에 표시될 최종 형태로 가공하는 역할을 수행한다.</p>
<h4>2.2.1 입력 조립기 (Input Assembler, IA)</h4>
<p>입력 조립기는 파이프라인의 가장 첫 번째 고정 함수 단계이다. 이 단계의 역할은 CPU가 메모리에 준비해 둔 정점 데이터(위치, 색상, 법선, 텍스처 좌표 등)를 읽어오는 것이다.15 이 데이터는 보통 정점 버퍼(Vertex Buffer)와 인덱스 버퍼(Index Buffer)라는 두 가지 형태로 제공된다. 정점 버퍼는 각 정점의 속성 정보를 담고 있으며, 인덱스 버퍼는 이 정점들을 어떤 순서로 연결하여 프리미티브(예: 삼각형)를 만들지를 정의한다. IA는 이 정보들을 바탕으로 지정된 프리미티브들을 조립하여 다음 단계인 버텍스 셰이더로 전달한다.16</p>
<h4>2.2.2 버텍스 셰이더 (Vertex Shader, VS)</h4>
<p>버텍스 셰이더는 파이프라인에서 만나는 첫 번째 프로그래밍 가능 단계이며, 그 역할은 지대하다. 이 셰이더는 입력 조립기로부터 전달받은 각 정점에 대해 개별적으로 한 번씩 실행된다.11</p>
<p>버텍스 셰이더의 가장 핵심적이고 필수적인 임무는 **좌표 공간 변환(Coordinate Space Transformation)**이다.4 3D 모델의 정점들은 처음에는 모델 자체의 원점을 기준으로 하는 로컬 공간(Local Space)에 정의되어 있다. 버텍스 셰이더는 일련의 행렬 곱셈을 통해 이 좌표들을 변환한다.</p>
<ol>
<li><strong>모델 변환 (Model/World Transform):</strong> 로컬 공간의 정점을 게임 세계 전체가 공유하는 단일 좌표계인 월드 공간(World Space)으로 변환한다. 이를 통해 모델을 월드 내 특정 위치에 배치하고, 회전시키고, 크기를 조절할 수 있다.</li>
<li><strong>뷰 변환 (View Transform):</strong> 월드 공간의 정점들을 카메라의 시점을 기준으로 하는 뷰 공간(View Space) 또는 카메라 공간(Camera Space)으로 변환한다. 이는 세상을 카메라의 눈으로 바라보는 것과 같다.</li>
<li><strong>투영 변환 (Projection Transform):</strong> 3차원 뷰 공간의 정점들을 2차원 화면에 투영하기 위한 준비 단계로, 최종적으로 ’클립 공간(Clip Space)’이라는 4차원 동차 좌표계로 변환한다. 이 과정에서 원근감(Perspective)이 적용되어 가까운 물체는 크게, 먼 물체는 작게 보이게 된다.</li>
</ol>
<p>이 모든 변환은 보통 하나의 행렬, 즉 모델-뷰-투영(Model-View-Projection, MVP) 행렬을 정점 좌표에 곱함으로써 효율적으로 수행된다. 이 외에도 버텍스 셰이더는 정점 단위 조명 계산(예: 고러드 셰이딩), 캐릭터 애니메이션을 위한 스키닝(Skinning) 등 다양한 정점별 연산을 수행할 수 있다.</p>
<h4>2.2.3 테셀레이션 단계 (Tessellation Stages)</h4>
<p>테셀레이션은 DirectX 11과 OpenGL 4.0에서 도입된 선택적 단계로, GPU가 동적으로 지오메트리를 세분화할 수 있게 해주는 강력한 기능이다.19 이 단계는 세 부분으로 구성된다.</p>
<ol>
<li><strong>헐 셰이더 (Hull Shader):</strong> 프로그래밍 가능한 이 셰이더는 입력으로 받은 지오메트리 패치(Patch)를 얼마나 잘게 쪼갤지, 즉 테셀레이션 계수(Tessellation Factor)를 결정한다.11</li>
<li><strong>테셀레이터 (Tessellator):</strong> 고정 함수 유닛으로, 헐 셰이더가 결정한 계수에 따라 실제로 패치를 더 작은 삼각형이나 선, 점으로 분할한다.11</li>
<li><strong>도메인 셰이더 (Domain Shader):</strong> 프로그래밍 가능한 마지막 단계로, 테셀레이터가 생성한 새로운 정점들의 최종 위치를 계산한다. 예를 들어, 높이 맵(Height Map)을 참조하여 평평한 표면에 울퉁불퉁한 지형 디테일을 추가할 수 있다.11</li>
</ol>
<p>테셀레이션의 주된 용도는 동적 상세 수준(Level of Detail, LOD) 구현이다. 카메라에서 가까운 객체는 매우 정교하게 세분화하여 디테일을 높이고, 멀리 있는 객체는 단순한 형태로 유지함으로써 시각적 품질과 성능 사이의 균형을 맞출 수 있다.20</p>
<h4>2.2.4 지오메트리 셰이더 (Geometry Shader, GS)</h4>
<p>지오메트리 셰이더는 파이프라인 중간에서 프리미티브 단위를 통째로 생성하거나 제거할 수 있는 선택적 프로그래밍 단계이다.18 입력으로 하나의 프리미티브(예: 삼각형 하나)를 받아 0개, 1개, 또는 여러 개의 새로운 프리미티브를 출력할 수 있다. 예를 들어, 모든 삼각형의 법선 벡터를 시각적으로 표시하거나, 정점에서 머리카락이나 풀잎 같은 지오메트리를 생성(Extrude)하는 데 사용될 수 있다. 강력한 기능이지만, 출력되는 데이터 양의 변동성이 커서 GPU 파이프라인에 병목 현상을 일으킬 수 있으므로 다른 셰이더 단계에 비해 신중하게 사용된다.</p>
<h3>2.3 3: 래스터라이제이션 및 픽셀 처리 단계 (“어떻게“를 처리)</h3>
<p>지오메트리 처리 단계에서 ‘무엇을 어디에’ 그릴지가 결정되면, 파이프라인의 후반부는 ‘어떻게(How)’ 그릴지를 담당한다. 이 단계들은 3차원 기하학 정보를 최종적인 2차원 픽셀 색상으로 변환하는 핵심적인 역할을 수행한다.</p>
<h4>2.3.1 래스터라이저 (Rasterizer)</h4>
<p>래스터라이저는 프로그래밍이 불가능한 핵심적인 고정 함수 하드웨어 단계이다.15 이 단계는 지오메트리 단계에서 넘어온 클립 공간의 프리미티브(주로 삼각형)를 입력받아, 화면에 표시될 픽셀들의 집합인 프래그먼트(Fragment)로 변환하는 역할을 한다. 이 과정은 여러 개의 중요한 하위 작업으로 구성된다.</p>
<ul>
<li>
<p><strong>클리핑 (Clipping):</strong> 뷰 프러스텀(View Frustum), 즉 카메라의 시야각에 의해 정의되는 잘린 피라미드 형태의 3D 공간 외부에 완전히 벗어난 프리미티브는 버려진다. 프러스텀 경계에 걸쳐 있는 프리미티브는 경계면을 따라 잘리고, 내부에 있는 부분만 유지된다. 이 과정을 통해 화면에 보이지 않는 지오메트리를 조기에 제거한다.15</p>
</li>
<li>
<p><strong>원근 분할 (Perspective Division):</strong> 클립 공간의 4차원 동차 좌표 <span class="math math-inline">(x, y, z, w)</span>를 네 번째 성분인 w로 나누어 정규화된 장치 좌표(Normalized Device Coordinates, NDC)로 변환한다 (x/w,y/w,z/w).15 이 과정을 통해 원근 투영이 완료되어,</p>
</li>
</ul>
<p>w값이 클수록(카메라에서 멀수록) 객체가 작게 보이게 된다. NDC 공간에서 x,y,z 좌표는 보통 -1에서 1 또는 0에서 1 사이의 범위를 갖는다.</p>
<ul>
<li>
<p><strong>후면 컬링 (Back-Face Culling):</strong> 매우 중요한 최적화 기법이다. 닫힌 객체(예: 구, 상자)의 경우, 카메라를 등지고 있는 삼각형 면들은 어차피 보이지 않는다. 후면 컬링은 삼각형의 표면 법선 벡터(면이 향하는 방향)와 카메라의 시선 벡터를 비교하여, 시선 방향과 반대인 후면(Back-face)들을 렌더링 과정에서 완전히 제외시킨다.15 이로써 처리해야 할 폴리곤의 수를 절반 가까이 줄일 수 있다.</p>
</li>
<li>
<p><strong>뷰포트 변환 (Viewport Transformation):</strong> NDC 공간의 좌표(-1에서 1 범위)를 실제 화면의 픽셀 좌표(예: 가로 0~1920, 세로 0~1080)로 변환한다.15 이 변환을 통해 3차원 좌표가 최종적인 2차원 화면 좌표로 사상(Mapping)된다. 이 과정에서</p>
</li>
</ul>
<p>z값은 깊이 정보로 유지되어 이후 깊이 테스트에 사용된다.</p>
<ul>
<li><strong>스캔 변환 (Scan Conversion):</strong> 뷰포트 변환을 거친 2차원 삼각형이 어떤 픽셀 중심점을 덮고 있는지 판별하는 과정이다. 래스터라이저는 삼각형 내부에 포함되는 모든 픽셀에 대해 ’프래그먼트’를 생성한다.15 프래그먼트는 최종 픽셀이 되기 전의 잠재적 픽셀 데이터로, 위치 정보와 함께 정점에서 보간된 속성 값(색상, 텍스처 좌표 등)을 포함한다.</li>
</ul>
<h4>2.3.2 프래그먼트 셰이더 (Fragment Shader) 또는 픽셀 셰이더 (Pixel Shader)</h4>
<p>프래그먼트 셰이더는 파이프라인의 두 번째 주요 프로그래밍 가능 단계로, GPU 성능에 가장 큰 영향을 미치는 부분 중 하나이다.1 이 셰이더는 래스터라이저가 생성한 모든 프래그먼트에 대해 한 번씩 실행되며, 해당 프래그먼트의 최종 색상을 결정하는 역할을 한다.11 DirectX에서는 ’픽셀 셰이더’라고 부르지만, OpenGL에서는 ’프래그먼트 셰이더’라는 용어를 사용한다.</p>
<p>프래그먼트 셰이더에서 수행되는 주요 작업은 다음과 같다.</p>
<ul>
<li><strong>텍스처링 (Texturing):</strong> 보간된 텍스처 좌표(UV)를 사용하여 텍스처 맵(Texture Map)에서 색상 값을 샘플링하고, 이를 프래그먼트의 기본 색상으로 사용한다.</li>
<li><strong>조명 (Lighting):</strong> 보간된 법선 벡터, 광원의 정보, 재질 속성 등을 이용해 퐁 셰이딩(Phong Shading)이나 물리 기반 렌더링(Physically Based Rendering, PBR)과 같은 정교한 픽셀 단위 조명 모델을 계산한다.22 이를 통해 사실적인 음영과 하이라이트를 표현한다.</li>
<li><strong>특수 효과 (Special Effects):</strong> 안개(Fog), 투명도(Transparency), 노멀 매핑(Normal Mapping) 등 다양한 시각 효과를 적용하여 최종 색상을 완성한다.</li>
</ul>
<p>프래그먼트 셰이더는 최종적으로 계산된 색상(RGBA) 값과 깊이(z) 값을 다음 단계인 출력 병합기로 전달한다.</p>
<h4>2.3.3 출력 병합기 (Output Merger, OM)</h4>
<p>출력 병합기는 파이프라인의 마지막 고정 함수 단계로, 프래그먼트 셰이더에서 넘어온 결과물을 프레임버퍼(Framebuffer)에 기록하는 역할을 한다.15 프레임버퍼는 화면에 표시될 최종 이미지의 색상 정보를 담는 컬러 버퍼(Color Buffer)와 각 픽셀의 깊이 정보를 담는 깊이 버퍼(Depth Buffer) 등으로 구성된다.</p>
<ul>
<li><strong>깊이 테스트 (Depth Test / Z-Test):</strong> 현재 프래그먼트의 깊이 값(z)을 깊이 버퍼에 이미 저장된 값과 비교한다. 만약 새로운 프래그먼트가 기존 픽셀보다 카메라에 더 가깝다면(깊이 값이 작다면), 컬러 버퍼와 깊이 버퍼를 새로운 값으로 갱신한다. 그렇지 않다면(더 멀리 있다면), 해당 프래그먼트는 가려진 것으로 판단하고 버린다. 이 테스트를 통해 객체 간의 올바른 가림(Occlusion) 관계가 결정된다.4</li>
<li><strong>스텐실 테스트 (Stencil Test):</strong> 깊이 테스트와 유사하지만, 스텐실 버퍼(Stencil Buffer)라는 별도의 버퍼를 사용하여 특정 영역에만 렌더링을 제한하는 등 복잡한 효과(예: 그림자, 마스킹)를 구현하는 데 사용된다.</li>
<li><strong>블렌딩 (Blending):</strong> 반투명 객체를 처리할 때 사용된다. 프래그먼트의 알파(Alpha) 값을 기반으로 새로운 프래그먼트의 색상과 컬러 버퍼에 이미 있는 색상을 혼합하여 최종 색상을 결정한다.15</li>
</ul>
<p>이 모든 테스트와 블렌딩 과정을 통과한 최종 픽셀 색상만이 컬러 버퍼에 기록되고, 렌더링이 완료된 프레임버퍼는 화면 표시 장치로 전송되어 우리가 보는 최종 이미지가 된다.1</p>
<h2>3.  필수 기술 및 알고리즘</h2>
<p>현대 래스터라이제이션 파이프라인은 그 자체만으로는 사실적인 이미지를 효율적으로 생성할 수 없다. 파이프라인의 각 단계를 지원하고 그 성능과 품질을 극대화하는 여러 핵심 알고리즘들이 존재한다. 이 장에서는 그중 가장 필수적인 기술인 깊이 버퍼링, 셰이딩 모델, 그리고 앤티에일리어싱에 대해 심도 있게 다룬다.</p>
<h3>3.1 1: 깊이 버퍼링을 이용한 가시성 문제 해결</h3>
<p>3D 씬을 2D 화면에 렌더링할 때 가장 근본적인 문제 중 하나는 ’무엇이 보이고 무엇이 가려지는가’를 결정하는 ‘숨은 면 제거(Hidden Surface Removal)’ 문제이다. 이 문제를 효율적으로 해결하기 위해 현대 그래픽스에서는 거의 보편적으로 깊이 버퍼링(Depth Buffering) 기법을 사용한다.</p>
<h4>3.1.1 Z-버퍼(Z-Buffer)</h4>
<p>Z-버퍼는 깊이 버퍼(Depth Buffer)라고도 불리며, 화면의 각 픽셀에 대한 깊이 정보, 즉 카메라로부터의 거리 값을 저장하는 2차원 메모리 배열이다.4 Z-버퍼의 크기는 컬러 버퍼와 동일하며, 각 픽셀 위치에 해당하는 Z-버퍼의 요소는 해당 픽셀에 마지막으로 그려진 객체의 정규화된 깊이 값(보통 0.0에서 1.0 사이)을 저장한다.</p>
<p>Z-버퍼링의 작동 원리는 매우 간단하면서도 강력하다.24</p>
<ol>
<li>렌더링을 시작하기 전에 Z-버퍼의 모든 값을 가장 먼 거리(예: 1.0)로 초기화한다.</li>
<li>파이프라인이 특정 픽셀 위치에 프래그먼트를 그리려고 할 때, 먼저 해당 프래그먼트의 깊이 값(znew)을 Z-버퍼의 같은 위치에 저장된 깊이 값(zbuffer)과 비교한다.</li>
<li>만약 znew&lt;zbuffer 이면, 새로운 프래그먼트가 기존의 것보다 카메라에 더 가깝다는 의미이므로, 해당 픽셀의 색상을 컬러 버퍼에 그리고 Z-버퍼의 값을 <span class="math math-inline">z_{new}</span>로 갱신한다.</li>
<li>만약 znew≥zbuffer 이면, 새로운 프래그먼트가 기존의 것 뒤에 가려져 있다는 의미이므로, 해당 프래그먼트를 버리고 아무 작업도 하지 않는다.</li>
</ol>
<p>이 방식은 렌더링 순서에 의존하지 않고 픽셀 단위로 가시성을 판별할 수 있게 해준다. 이는 화가가 먼 배경부터 그리고 가까운 물체를 덧칠하는 방식인 ’화가 알고리즘(Painter’s Algorithm)’과 같은 구식 기법들이 가진 순환 종속성 문제를 해결한 혁신적인 방법이었다.27</p>
<h4>3.1.2 Z-파이팅과 정밀도</h4>
<p>Z-버퍼는 유한한 비트 수(예: 16, 24, 32비트)로 깊이 값을 표현하기 때문에 정밀도에 한계가 있다. 이로 인해 ’Z-파이팅(Z-Fighting)’이라는 시각적 결함이 발생할 수 있다.23 Z-파이팅은 거의 동일한 깊이를 가진 두 개 이상의 평면이 겹쳐 있을 때, Z-버퍼의 정밀도 한계로 인해 어떤 면이 앞에 있는지 일관되게 결정하지 못하여 픽셀들이 깜빡이거나 줄무늬 패턴(스티칭)이 나타나는 현상이다.</p>
<p>이 문제는 Z-버퍼의 깊이 값이 비선형적으로 분포하기 때문에 더욱 심화된다. 투영 변환의 수학적 특성상, Z-버퍼의 정밀도는 카메라에 가까운 근접 클리핑 평면(Near Clipping Plane) 근처에서 가장 높고, 멀리 있는 원거리 클리핑 평면(Far Clipping Plane)으로 갈수록 급격히 낮아진다.24 따라서 근접 평면과 원거리 평면 사이의 거리 비율(</p>
<p>far/near)이 클수록 원거리에서의 정밀도 손실이 커져 Z-파이팅이 발생할 확률이 높아진다.28</p>
<p>Z-파이팅을 완화하는 주된 방법은 다음과 같다.</p>
<ul>
<li><strong>고정밀도 Z-버퍼 사용:</strong> 16비트 Z-버퍼보다 24비트나 32비트 Z-버퍼를 사용하면 정밀도가 높아져 문제를 크게 개선할 수 있다.24</li>
<li><strong>클리핑 평면 최적화:</strong> 근접 평면을 가능한 한 멀리, 원거리 평면을 가능한 한 가깝게 설정하여 far/near 비율을 최소화한다.24</li>
</ul>
<h4>3.1.3 성능 최적화 (Early-Z/Hi-Z)</h4>
<p>Z-테스트는 중요한 성능 최적화 기회도 제공한다. 전통적으로 깊이 테스트는 프래그먼트 셰이더가 실행된 후 출력 병합기 단계에서 수행되었다. 하지만 만약 어떤 프래그먼트가 다른 객체에 의해 완전히 가려질 것이 확실하다면, 비싼 연산이 포함된 프래그먼트 셰이더를 실행하는 것은 자원 낭비이다.</p>
<p>‘Early-Z’ (또는 Early Depth Test)는 이러한 낭비를 막기 위해 깊이 테스트를 프래그먼트 셰이더 <em>이전에</em> 수행하는 최적화 기법이다.1 만약 프래그먼트가 깊이 테스트에 실패하면, GPU는 즉시 해당 프래그먼트를 버리고 셰이더 실행을 건너뛴다. 이는 특히 화면에 겹쳐진 객체가 많은 복잡한 씬에서 엄청난 성능 향상을 가져온다. 더 나아가 현대 GPU는 ’계층적 Z-버퍼(Hierarchical Z-Buffer, Hi-Z)’를 사용하여, 픽셀 블록 단위로 가시성을 빠르게 판별하고 가려진 영역 전체를 한 번에 컬링함으로써 성능을 더욱 극대화한다.</p>
<h3>3.2 2: 표면 외관을 위한 셰이딩 모델</h3>
<p>셰이딩(Shading)은 빛과 표면의 상호작용을 계산하여 객체의 색상과 명암을 결정하는 과정이다. 래스터라이제이션은 셰이딩 모델을 통해 평평한 삼각형에 입체감과 사실감을 부여한다.</p>
<h4>3.2.1 퐁(Phong) 및 블린-퐁(Blinn-Phong) 모델</h4>
<p>퐁 셰이딩 모델은 1970년대에 부이 뜨엉 퐁(Bui Tuong Phong)에 의해 개발된 고전적이면서도 영향력 있는 조명 모델이다.29 이 모델은 조명을 세 가지 구성 요소로 분해하여 계산의 복잡성과 시각적 사실성 사이의 균형을 맞춘다.30</p>
<ul>
<li><strong>주변광 (Ambient):</strong> 씬 전체에 균일하게 존재하는 빛을 모사한다. 이는 광원으로부터 직접 빛을 받지 않는 그림자 영역이 완전한 검은색이 되는 것을 방지하고, 간접적으로 반사된 빛(Global Illumination)을 매우 단순하게 근사하는 역할을 한다.30 주변광은 보통 재질의 주변광 색상과 빛의 주변광 강도를 곱하여 간단히 계산된다.</li>
<li><strong>난반사광 (Diffuse):</strong> 무광택 또는 거친 표면에서 빛이 모든 방향으로 균일하게 흩어지는 현상을 모델링한다. 난반사의 밝기는 표면이 빛을 얼마나 정면으로 마주하고 있는지에 따라 결정된다. 이는 표면의 법선 벡터(Normal Vector)와 광원으로 향하는 벡터 사이의 각도에 대한 코사인 값, 즉 램버트의 코사인 법칙(Lambert’s Cosine Law)을 통해 계산된다.30</li>
<li><strong>정반사광 (Specular):</strong> 거울이나 광택 있는 금속처럼 매끄러운 표면에서 빛이 특정 방향으로 강하게 반사되는 하이라이트(Highlight)를 표현한다. 퐁 모델에서는 빛의 입사각과 동일한 각도로 반사되는 반사 벡터(Reflection Vector)와 관찰자(카메라)를 향하는 뷰 벡터(View Vector)가 얼마나 가까운지를 계산하여 정반사광의 강도를 결정한다.31</li>
</ul>
<p>블린-퐁(Blinn-Phong) 모델은 퐁 모델의 정반사광 계산을 최적화한 버전이다. 반사 벡터를 계산하는 대신, 광원 벡터와 뷰 벡터의 중간 지점에 있는 ’하프웨이 벡터(Halfway Vector)’를 사용한다.31 하프웨이 벡터와 표면 법선 벡터를 비교하는 것이 계산적으로 더 저렴하기 때문에, 블린-퐁 모델은 퐁 모델과 거의 유사한 결과를 더 빠른 속도로 제공하여 널리 사용되었다.</p>
<h4>3.2.2 정점 단위에서 픽셀 단위로의 발전</h4>
<p>초기 3D 그래픽스에서는 ’고러드 셰이딩(Gouraud Shading)’이 주로 사용되었다. 이 방식은 각 삼각형의 정점(Vertex)에서만 조명을 계산하고, 그 결과로 나온 색상 값을 삼각형 내부로 선형 보간(Linearly Interpolate)하여 채웠다.32 이 방식은 계산이 빠르다는 장점이 있었지만, 정반사 하이라이트처럼 삼각형 중간에 나타나야 하는 세밀한 조명 효과를 표현할 수 없었고, 하이라이트가 정점 근처에 있을 때만 부정확하게 나타나는 문제가 있었다.</p>
<p>프로그래머블 셰이더의 등장으로 ‘퐁 셰이딩(Phong Shading)’ 기법이 가능해졌다. 여기서 퐁 셰이딩은 조명 모델(Phong reflection model)과 다른, 보간 기법을 의미한다. 이 방식은 정점에서 색상이 아닌 법선 벡터를 보간하고, 래스터화된 모든 픽셀(프래그먼트)에 대해 프래그먼트 셰이더 내에서 조명을 다시 계산한다.22 이 ‘픽셀 단위(Per-pixel)’ 조명 계산은 삼각형의 크기에 상관없이 매끄럽고 정확한 정반사 하이라이트를 생성할 수 있게 해주었으며, 이는 실시간 그래픽 품질의 비약적인 발전을 가져온 중요한 전환점이었다.</p>
<h3>3.3 3: “계단 현상“과의 싸움: 앤티에일리어싱(AA) 기술</h3>
<p>래스터라이제이션은 본질적으로 연속적인 기하학적 형태(선, 삼각형의 경계)를 불연속적인 픽셀 격자로 표현하는 과정이다. 이 과정에서 ‘에일리어싱(Aliasing)’, 흔히 “계단 현상(Jaggies)“이라 불리는 시각적 결함이 발생한다.35 이는 부드러운 대각선이나 곡선이 픽셀 격자 위에서 톱니 모양으로 거칠게 표현되는 현상이다. 앤티에일리어싱(Anti-Aliasing, AA)은 이러한 계단 현상을 완화하여 이미지를 더 부드럽고 자연스럽게 만드는 기술들의 총칭이다.</p>
<h4>3.3.1 앤티에일리어싱 기술의 분류</h4>
<p>다양한 AA 기술들은 그 작동 원리와 성능/품질 트레이드오프에 따라 크게 세 가지 범주로 나눌 수 있다.</p>
<ul>
<li><strong>슈퍼샘플링 (Brute Force):</strong> 가장 원초적이고 효과가 확실한 접근 방식이다.</li>
<li><strong>SSAA (Super-Sampling Anti-Aliasing):</strong> 화면 전체를 목표 해상도보다 몇 배 더 높은 해상도로 렌더링한 다음, 최종적으로 목표 해상도로 축소(Downscale)하는 방식이다. 예를 들어 4x SSAA는 4배 많은 픽셀을 렌더링하므로 가장 높은 품질을 제공하지만, 그만큼 엄청난 성능 저하를 유발한다.37</li>
<li><strong>MSAA (Multi-Sample Anti-Aliasing):</strong> SSAA의 무식한 성능 비용을 최적화한 기법이다. MSAA는 삼각형의 경계선에서만 여러 번의 샘플링(Coverage Sampling)을 수행하여 기하학적 에일리어싱을 처리하고, 삼각형 내부의 픽셀 셰이딩은 픽셀당 한 번만 계산한다. 이로써 SSAA보다 훨씬 적은 비용으로 우수한 품질을 제공하여 오랫동안 AA 기술의 표준으로 자리 잡았다.35</li>
<li><strong>후처리 (Approximation):</strong> 렌더링이 완료된 최종 이미지에 추가적인 처리(Post-Processing)를 가해 에일리어싱을 감지하고 완화하는 방식이다.</li>
<li><strong>FXAA (Fast Approximate Anti-Aliasing):</strong> 최종 이미지에서 밝기 차이를 기반으로 경계선을 감지한 후, 해당 경계선을 부드럽게 흐리는(Blur) 셰이더 기반 기법이다. 성능 저하가 매우 적어 모바일이나 저사양 환경에서 널리 사용되지만, 텍스처 디테일까지 흐릿하게 만드는 단점이 있다.36</li>
<li><strong>SMAA (Subpixel Morphological Anti-Aliasing):</strong> FXAA와 유사한 후처리 방식이지만, 단순한 블러링 대신 패턴 인식을 통해 원래의 기하학적 형태를 재구성하려 시도한다. FXAA보다 선명한 결과를 제공하지만 연산 비용은 약간 더 높다.35</li>
<li><strong>시간적 기법 (Temporal):</strong> 이전 프레임의 정보를 활용하여 현재 프레임의 품질을 개선하는 방식이다.</li>
<li><strong>TAA (Temporal Anti-Aliasing):</strong> 현재 프레임과 이전 프레임의 이미지를 혼합하여 에일리어싱을 완화한다. 특히 움직이는 화면에서 발생하는 미세한 픽셀의 반짝임(Shimmering)을 효과적으로 제거하는 데 탁월하다. 하지만 빠르게 움직이는 객체 주변에 잔상(Ghosting)이나 블러 현상을 유발할 수 있는 단점이 있다.35</li>
</ul>
<h4>3.3.2 표 2: 주요 앤티에일리어싱 기술 비교</h4>
<table><thead><tr><th>기술</th><th>작동 방식 (Method)</th><th>성능 비용</th><th>시각적 품질 (장점)</th><th>시각적 결함 (단점)</th></tr></thead><tbody>
<tr><td><strong>SSAA</strong></td><td>전체 화면을 고해상도로 렌더링 후 다운샘플링</td><td>매우 높음</td><td>가장 완벽한 AA 품질. 텍스처 에일리어싱까지 제거.</td><td>극심한 성능 저하. 실시간 적용 거의 불가능.</td></tr>
<tr><td><strong>MSAA</strong></td><td>폴리곤 경계선에서만 다중 샘플링 수행</td><td>중간 ~ 높음</td><td>우수한 기하학적 에일리어싱 제거. 선명한 텍스처 유지.</td><td>텍스처 내부 에일리어싱, 투명 텍스처 에일리어싱은 처리 못 함.</td></tr>
<tr><td><strong>FXAA</strong></td><td>후처리 방식으로 이미지의 경계선을 감지하여 블러링</td><td>매우 낮음</td><td>성능 저하가 거의 없음. 모든 종류의 에일리어싱에 적용 가능.</td><td>이미지 전체가 다소 흐릿해짐. 특히 텍스처 디테일 손상.</td></tr>
<tr><td><strong>TAA</strong></td><td>이전 프레임 정보를 활용하여 현재 프레임 보정</td><td>낮음</td><td>움직임 중 발생하는 반짝임(Shimmering) 제거에 매우 효과적.</td><td>빠른 움직임에서 잔상(Ghosting) 및 블러 현상 발생 가능.</td></tr>
</tbody></table>
<h2>4.  경쟁 구도: 래스터라이제이션 대 레이 트레이싱</h2>
<p>수십 년간 실시간 렌더링의 왕좌를 지켜온 래스터라이제이션에게 최근 강력한 경쟁자가 등장했다. 바로 레이 트레이싱(Ray Tracing, 광선 추적)이다. 두 기술은 단순히 방법론만 다른 것이 아니라, 이미지를 생성하는 근본적인 철학에서부터 차이를 보인다. 이 장에서는 두 기술의 차이점을 분석하고, 실시간 그래픽스의 미래를 조망한다.</p>
<h3>4.1 1: 두 가지 렌더링 철학</h3>
<p>래스터라이제이션과 레이 트레이싱의 가장 근본적인 차이는 처리 순서에 있다.</p>
<ul>
<li>
<p><strong>객체 순서(Object-Order) vs. 이미지 순서(Image-Order):</strong></p>
</li>
<li>
<p><strong>래스터라이제이션</strong>은 ‘객체 순서’ 또는 ‘순방향(Forward)’ 렌더링 방식이다. 3D 공간에 존재하는 객체(삼각형)를 하나씩 가져와서 2D 화면 공간에 투영하는, 즉 “이 삼각형은 화면의 어떤 픽셀들을 덮는가?“를 묻는 방식이다.41</p>
</li>
<li>
<p><strong>레이 트레이싱</strong>은 ‘이미지 순서’ 또는 ‘역방향(Backward)’ 렌더링 방식이다. 화면의 각 픽셀에서부터 시작하여 가상의 광선(Ray)을 카메라를 통해 3D 씬으로 쏘아 보낸다. 그리고 그 광선이 어떤 객체와 부딪히는지, 부딪힌 지점의 색상은 무엇인지를 결정하기 위해 광원의 위치까지 경로를 역추적한다.42 이는 “이 픽셀에서는 무엇이 보이는가?“를 묻는 방식이다.</p>
</li>
<li>
<p>속도를 위한 근사 vs. 정확성을 위한 시뮬레이션:</p>
</li>
</ul>
<p>이러한 철학적 차이는 두 기술의 핵심적인 트레이드오프로 이어진다.</p>
<ul>
<li><strong>래스터라이제이션</strong>은 물리적으로 완벽하지 않더라도 최대한 빠르게 그럴듯한 이미지를 만들어내는 ‘근사(Approximation)’ 기법에 가깝다. 복잡한 빛의 상호작용을 직접 계산하는 대신, 셰이더와 다양한 ’트릭’을 사용하여 흉내 낸다. 이 속도 덕분에 수십 년간 비디오 게임과 같은 실시간 애플리케이션에서 지배적인 기술로 자리 잡을 수 있었다.44</li>
<li><strong>레이 트레이싱</strong>은 빛의 물리적 거동을 최대한 정확하게 모방하려는 ’시뮬레이션(Simulation)’에 가깝다. 광선이 표면에서 반사, 굴절, 산란하는 과정을 추적함으로써 매우 사실적인 이미지를 생성할 수 있다. 하지만 이 과정은 엄청난 양의 계산을 요구하기 때문에, 최근까지도 실시간 렌더링에는 부적합하다고 여겨졌다.41</li>
</ul>
<h3>4.2 2: 효과별 비교 분석</h3>
<p>두 기술의 차이는 반사, 그림자, 전역 조명과 같이 빛의 복잡한 상호작용을 표현할 때 극명하게 드러난다.</p>
<ul>
<li><strong>반사 (Reflections):</strong></li>
<li><strong>래스터라이제이션:</strong> 반사를 구현하기 위해 ’트릭’을 사용한다. 대표적으로 큐브맵(Cubemap)이나 리플렉션 프로브(Reflection Probe)를 사용하여 주변 환경을 텍스처에 미리 구워놓고 반사면에 입히거나, 스크린 공간 반사(Screen-Space Reflection, SSR)를 사용하여 현재 화면에 보이는 픽셀 정보만을 바탕으로 반사를 계산한다.47 이 방식들은 빠르지만, 화면 밖의 객체를 반사하지 못하거나, 다른 객체에 가려진 부분의 반사 정보가 누락되는 등의 한계를 가진다.48</li>
<li><strong>레이 트레이싱:</strong> 반사 현상을 자연스럽게 시뮬레이션한다. 픽셀에서 쏜 광선이 반사면에 부딪히면, 물리 법칙에 따라 반사 방향으로 새로운 광선을 쏘아 그 광선이 닿는 객체의 색상을 가져온다. 이 과정은 여러 번 반복될 수 있어(Multi-bounce), 반사된 물체 안에 또 다른 반사가 보이는 ’상호 반사(Inter-reflection)’나 화면 밖 객체의 반사까지 정확하게 표현할 수 있다.48</li>
<li><strong>그림자 (Shadows):</strong></li>
<li><strong>래스터라이제이션:</strong> 가장 일반적인 기법은 섀도 매핑(Shadow Mapping)이다. 광원의 시점에서 씬을 렌더링하여 깊이 맵(그림자 맵)을 생성하고, 본 렌더링 시 각 픽셀의 깊이와 그림자 맵의 깊이를 비교하여 그림자 여부를 판단한다. 이 방식은 그림자 경계가 거칠게 표현되는 ‘에일리어싱’ 문제나 해상도에 따른 품질 저하 문제를 겪기 쉽고, 물리적으로 정확한 부드러운 그림자(Soft Shadow)를 표현하기 어렵다.50</li>
<li><strong>레이 트레이싱:</strong> 그림자 또한 시뮬레이션을 통해 생성한다. 특정 지점에서 광원으로 향하는 ’그림자 광선(Shadow Ray)’을 쏘아, 광원까지 도달하는 경로상에 다른 객체가 있는지 확인한다. 객체가 있으면 그림자, 없으면 빛을 받는 것으로 판단한다. 광원의 크기를 고려하여 여러 개의 그림자 광선을 쏘면, 현실과 같이 물체에 가까울수록 선명하고 멀어질수록 부드럽게 퍼지는 그림자를 자연스럽게 만들어낼 수 있다.48</li>
<li><strong>전역 조명 (Global Illumination, GI):</strong></li>
<li><strong>래스터라이제이션:</strong> GI는 빛이 한 표면에서 반사되어 다른 표면을 비추는 간접광을 의미한다. 래스터라이제이션에서 동적인 GI를 실시간으로 처리하는 것은 매우 어렵다. 따라서 대부분의 게임에서는 정적인 장면에 대해 조명을 미리 계산하여 라이트맵(Lightmap)이라는 텍스처에 ‘굽는(Bake)’ 방식을 사용한다.48 동적인 근사 기법으로는 스크린 공간 앰비언트 오클루전(Screen-Space Ambient Occlusion, SSAO) 등이 있지만, 이는 구석진 곳에 음영을 더하는 제한적인 효과에 그친다.51</li>
<li><strong>레이 트레이싱:</strong> 광선이 여러 번 튕기는 것을 추적함으로써(Path Tracing), 동적인 GI를 물리적으로 정확하게 시뮬레이션할 수 있다.32 붉은 벽 옆에 있는 흰색 객체가 붉은빛을 띠는 ‘색 번짐(Color Bleeding)’ 현상 등, 래스터라이제이션으로는 흉내 내기 어려운 미묘하고 사실적인 조명 효과를 구현할 수 있다.50</li>
</ul>
<h4>4.2.1 표 3: 래스터라이제이션 vs. 레이 트레이싱 기능 비교</h4>
<table><thead><tr><th>기능</th><th>래스터라이제이션 접근법</th><th>레이 트레이싱 접근법</th><th>핵심 차이점 (성능 vs. 충실도)</th></tr></thead><tbody>
<tr><td><strong>반사</strong></td><td>큐브맵, SSR 등 ‘트릭’ 사용. 화면 내 정보만으로 근사.</td><td>반사 광선을 물리적으로 추적.</td><td><strong>성능:</strong> 래스터라이제이션이 훨씬 빠름. <strong>충실도:</strong> 레이 트레이싱은 화면 밖 객체, 상호 반사 등 물리적으로 정확한 결과를 제공.</td></tr>
<tr><td><strong>그림자</strong></td><td>섀도 매핑. 깊이 맵을 이용한 근사.</td><td>그림자 광선을 쏘아 가려짐 여부 판별.</td><td><strong>성능:</strong> 섀도 매핑이 빠름. <strong>충실도:</strong> 레이 트레이싱은 에일리어싱이 없고, 물리적으로 정확한 부드러운 그림자(Soft Shadow)를 자연스럽게 생성.</td></tr>
<tr><td><strong>전역 조명</strong></td><td>주로 라이트맵에 미리 ‘베이킹’. 실시간 근사는 SSAO 등으로 제한.</td><td>광선이 여러 번 튕기는 것을 시뮬레이션 (패스 트레이싱).</td><td><strong>성능:</strong> 베이킹은 실시간 비용이 없으나 동적이지 않음. <strong>충실도:</strong> 레이 트레이싱은 동적인 간접광과 색 번짐 현상을 사실적으로 표현.</td></tr>
</tbody></table>
<h3>4.3 3: 하이브리드 미래</h3>
<p>레이 트레이싱의 압도적인 시각적 품질에도 불구하고, 래스터라이제이션이 가까운 미래에 완전히 사라질 가능성은 낮다. 대신, 실시간 그래픽스의 미래는 두 기술의 장점을 결합한 <strong>하이브리드 렌더링(Hybrid Rendering)</strong> 모델로 나아가고 있다.52</p>
<p>하이브리드 모델에서 래스터라이제이션은 그 자체의 압도적인 속도를 활용하여 씬의 기본적인 가시성(Visibility)과 지오메트리를 처리하는 기반 역할을 한다.52 즉, 화면의 대부분을 빠르게 렌더링하는 주력 엔진으로 사용된다. 그 위에, 래스터라이제이션만으로는 표현하기 어려운 특정 효과들, 예를 들어 거울의 정확한 반사, 투명한 유리의 굴절, 부드러운 그림자, 사실적인 간접 조명 등을 레이 트레이싱을 통해 선택적으로 추가하는 방식이다.52</p>
<p>이러한 하이브리드 접근법을 현실로 만든 핵심 동력은 <strong>AI 기반 업스케일링 기술</strong>이다. NVIDIA의 DLSS(Deep Learning Super Sampling)나 AMD의 FSR(FidelityFX Super Resolution)과 같은 기술들은 레이 트레이싱으로 인해 무거워진 렌더링 작업을 더 낮은 해상도에서 수행한 뒤, AI 알고리즘을 통해 목표 해상도로 지능적으로 업스케일링한다.50 이를 통해 레이 트레이싱의 막대한 성능 비용을 상쇄하면서도 고품질의 최종 이미지를 실시간 프레임 속도로 얻을 수 있게 되었다. 결국, 미래의 실시간 렌더링은 래스터라이제이션의 효율성과 레이 트레이싱의 사실성을 모두 취하는, 가장 실용적인 방향으로 진화하고 있다.</p>
<h2>5.  래스터라이제이션의 진화와 미래</h2>
<p>래스터라이제이션은 정적인 기술이 아니다. 지난 수십 년간 하드웨어의 발전과 소프트웨어의 혁신 속에서 끊임없이 진화해왔으며, 현재도 새로운 도전과 기회에 직면하며 변화를 거듭하고 있다. 이 장에서는 래스터라이제이션의 역사적 발자취를 돌아보고, 현재와 미래의 기술 동향을 탐구한다.</p>
<h3>5.1 1: 역사적 관점</h3>
<h4>5.1.1 제약의 시대 (1990년대)</h4>
<p>1990년대 초중반의 3D 그래픽스는 극심한 하드웨어 제약 속에서 태동했다. 당시의 PC는 처리할 수 있는 폴리곤(삼각형)의 수가 매우 적었고, 텍스처를 저장할 메모리도 부족했다. 하지만 가장 큰 병목은 **필레이트(Fill Rate)**와 **메모리 대역폭(Memory Bandwidth)**이었다.54 필레이트는 GPU가 1초에 화면에 그릴 수 있는 픽셀의 총량을, 메모리 대역폭은 GPU가 메모리로부터 데이터를 얼마나 빨리 가져오고 쓸 수 있는지를 나타낸다. 이 두 가지 성능 지표의 한계는 복잡한 셰이딩이나 높은 해상도의 렌더링을 불가능하게 만들었다.</p>
<h4>5.1.2 압박 속의 혁신: 퀘이크(Quake) 사례</h4>
<p>이러한 제약 속에서 개발자들은 하드웨어의 한계를 극복하기 위한 창의적인 소프트웨어 기법을 고안해야 했다. 그 대표적인 사례가 1996년에 출시된 id Software의 퀘이크(Quake) 엔진이다.57 당시 하드웨어로는 동적인 실시간 조명을 모든 픽셀에 대해 계산하는 것이 불가능했다. 존 카맥(John Carmack)과 그의 팀은 이 문제를 해결하기 위해 **라이트맵(Lightmap)**이라는 혁신적인 기법을 도입했다.59</p>
<p>라이트맵은 씬의 정적인(움직이지 않는) 객체들에 대한 복잡한 조명과 그림자 정보를 미리 계산하여, 그 결과를 텍스처 이미지의 형태로 저장하는 방식이다. 게임이 실행될 때는 이 라이트맵을 객체의 기본 텍스처 위에 겹쳐 그리기만 하면 되었다. 이로써 실시간 성능 비용을 거의 들이지 않고도 매우 사실적이고 분위기 있는 정적 조명 효과를 구현할 수 있었다.62 라이트맵은 하드웨어의 한계를 소프트웨어적 창의성으로 극복한 대표적인 예시이며, 이후 수많은 게임 엔진에서 표준적인 기법으로 자리 잡았다.</p>
<h4>5.1.3 GPU와 프로그래머블 셰이더 혁명</h4>
<p>1990년대 후반, 3D 그래픽 가속기, 즉 GPU(Graphics Processing Unit)가 등장하면서 실시간 그래픽스 환경은 근본적으로 변화하기 시작했다.63 초기 GPU는 고정 함수 파이프라인을 통해 렌더링 과정을 하드웨어적으로 가속했다.</p>
<p>진정한 혁명은 2000년대 초, DirectX 8/9와 OpenGL 2.0이 <strong>프로그래머블 셰이더</strong>를 도입하면서 시작되었다.9 이는 그래픽스 파이프라인의 핵심 단계(정점 및 픽셀 처리)를 개발자가 직접 프로그래밍할 수 있게 만든 패러다임의 전환이었다. 고정된 하드웨어 기능에 얽매이지 않고, 개발자가 원하는 독창적인 시각 효과를 무한히 구현할 수 있는 시대가 열린 것이다. 언리얼 엔진(Unreal Engine)과 크라이엔진(CryEngine) 같은 게임 엔진들은 이 새로운 기술을 적극적으로 활용하여, 이전과는 비교할 수 없는 수준의 시각적 복잡성과 사실성을 선보이며 그래픽 기술의 발전을 이끌었다.51</p>
<h3>5.2 2: 현대 및 미래의 래스터라이제이션 기술</h3>
<p>래스터라이제이션 기술은 정체되어 있지 않다. 데스크톱과 모바일이라는 서로 다른 하드웨어 생태계의 요구에 맞춰 각기 다른 방향으로 진화하고 있으며, 인공지능과 같은 새로운 분야와 융합하며 그 응용 범위를 넓혀가고 있다. 이는 단순히 그림을 더 빨리 그리는 것을 넘어, 렌더링 과정 자체를 더 지능적이고 다재다능하게 만드는 방향으로 나아가고 있음을 시사한다.</p>
<h4>5.2.1 타일 기반 렌더링 (Tile-Based Rendering, TBR): 모바일 혁명</h4>
<p>데스크톱 GPU가 ‘즉시 모드(Immediate Mode)’ 렌더링, 즉 삼각형을 받는 즉시 처리하여 프레임버퍼 전체에 그리는 방식을 사용하는 것과 달리, 대부분의 모바일 GPU는 **타일 기반 렌더링(TBR)**이라는 근본적으로 다른 아키텍처를 채택하고 있다. ARM의 Mali 69와 Qualcomm의 Adreno 72가 대표적이다.</p>
<p>TBR 아키텍처는 화면을 작은 사각형 ‘타일(Tile)’(예: 16x16 픽셀)로 분할한다.69 렌더링은 두 단계로 진행된다. 첫 번째 ‘비닝(Binning)’ 단계에서는 씬의 모든 지오메트리를 처리하여 각 타일에 어떤 삼각형들이 영향을 미치는지 목록을 작성한다. 두 번째 ‘렌더링’ 단계에서는 각 타일을 하나씩, GPU 내의 매우 빠른 온칩(On-chip) 메모리에 로드하여 해당 타일에 속한 삼각형들만 렌더링한다.74 타일 하나의 렌더링이 완료되면 그 결과만 외부의 느린 주 메모리(DRAM)로 내보낸다.</p>
<p>이 방식은 렌더링 과정에서 발생하는 막대한 양의 깊이 및 색상 데이터 읽기/쓰기를 온칩 메모리 내에서 해결함으로써, 전력 소모가 크고 성능 병목이 되기 쉬운 외부 메모리 접근을 극적으로 줄여준다.69 이러한 구조적 차이 때문에 모바일 환경에서의 그래픽 최적화 전략은 데스크톱과 크게 다르며, 메모리 대역폭을 절약하는 것이 핵심 과제가 된다.76</p>
<h4>5.2.2 가변 비율 셰이딩 (Variable Rate Shading, VRS): 셰이딩과 가시성의 분리</h4>
<p>VRS는 비교적 최신 GPU에 도입된 기능으로, 렌더링 효율을 높이는 지능적인 최적화 기술이다. 전통적인 렌더링에서는 화면의 모든 픽셀을 개별적으로 셰이딩(색상 계산)했다. 하지만 VRS는 GPU가 픽셀 그룹(예: 2x2 또는 4x4 블록)을 단 한 번의 프래그먼트 셰이더 실행으로 처리하고, 그 결과를 블록 내의 모든 픽셀에 적용할 수 있게 해준다.80</p>
<p>핵심은 <strong>셰이딩 비율(Shading Rate)과 가시성 비율(Visibility Rate)을 분리</strong>한 것이다. 즉, 지오메트리의 경계는 원래 해상도로 정밀하게 계산하여 선명함을 유지하면서, 픽셀의 색상을 계산하는 셰이딩 작업의 빈도는 동적으로 조절할 수 있다. 개발자는 모션 블러가 적용된 영역, VR 헤드셋의 주변부, 어두운 영역 등 시각적으로 중요도가 낮은 부분의 셰이딩 비율을 낮춤으로써, 인지되는 품질 저하를 최소화하면서 상당한 성능 향상을 얻을 수 있다.82</p>
<h4>5.2.3 미분 가능 렌더링 (Differentiable Rendering): 새로운 지평</h4>
<p>미분 가능 렌더링은 래스터라이제이션을 그래픽스 영역을 넘어 인공지능(AI) 및 머신러닝(ML) 분야로 확장하는 최첨단 연구 분야이다.84 전통적인 렌더러는 입력(3D 모델, 카메라 위치 등)을 받아 출력(2D 이미지)을 생성하는, 미분이 불가능한 ’블랙박스’와 같았다.</p>
<p>미분 가능 렌더러는 이 과정을 수학적으로 미분 가능하게 만듦으로써, 최종 이미지의 픽셀 값 변화에 대한 입력 파라미터(예: 정점 위치, 카메라 각도)의 변화율, 즉 그래디언트(Gradient)를 계산할 수 있게 한다.87 이는 렌더러를 경사 하강법(Gradient Descent)과 같은 최적화 루프의 일부로 사용할 수 있음을 의미한다.</p>
<p>이 기술은 다음과 같은 새로운 응용을 가능하게 한다:</p>
<ul>
<li><strong>3D 모델 재구성:</strong> 단 한 장의 2D 이미지만으로 3D 모델의 형태와 텍스처를 추정하고 생성할 수 있다.87 렌더러가 생성한 이미지와 목표 이미지를 비교하고, 그 차이를 줄이는 방향으로 3D 모델 파라미터를 반복적으로 업데이트하는 방식이다.</li>
<li><strong>벡터 그래픽스 생성:</strong> AI가 특정 스타일의 이미지를 학습한 후, 이를 모방하는 새로운 벡터 그래픽(SVG 등)을 자동으로 생성할 수 있다.86</li>
</ul>
<p>미분 가능 렌더링은 렌더러의 역할을 순수한 시각화 도구에서, 물리 세계와 디지털 세계를 잇는 분석적이고 창의적인 도구로 재정의하며 래스터라이제이션 기술의 미래에 새로운 가능성을 열어주고 있다.</p>
<h2>6. 참고 자료</h2>
<ol>
<li>렌더링 파이프라인 - 게임 클라 개발 - 티스토리, accessed July 5, 2025, https://tsyang.tistory.com/77</li>
<li>그래픽스 파이프라인 - 위키백과, 우리 모두의 백과사전, accessed July 5, 2025, <a href="https://ko.wikipedia.org/wiki/%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4_%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8">https://ko.wikipedia.org/wiki/%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4_%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8</a></li>
<li>래스터화 - 위키백과, 우리 모두의 백과사전, accessed July 5, 2025, <a href="https://ko.wikipedia.org/wiki/%EB%9E%98%EC%8A%A4%ED%84%B0%ED%99%94">https://ko.wikipedia.org/wiki/%EB%9E%98%EC%8A%A4%ED%84%B0%ED%99%94</a></li>
<li>렌더링 파이프라인 간단 정리 - Blemish - 티스토리, accessed July 5, 2025, https://jeonhw.tistory.com/27</li>
<li>3D 그래픽 프로세서 검증을 위한 래스터라이저 설계 - Korea Science, accessed July 5, 2025, https://koreascience.kr/article/CFKO200932963977168.pdf</li>
<li>[그래픽스] 그래픽스 파이프라인 개념과 GPU에서의 쉐이더를 통한 가속화 - Today, I will, accessed July 5, 2025, <a href="https://flyduckdev.tistory.com/entry/%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4-%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8">https://flyduckdev.tistory.com/entry/%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4-%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8</a></li>
<li>fixed function vs shader based - graphics - Stack Overflow, accessed July 5, 2025, https://stackoverflow.com/questions/18950395/fixed-function-vs-shader-based</li>
<li>Fixed-function – Knowledge and References - Taylor &amp; Francis, accessed July 5, 2025, https://taylorandfrancis.com/knowledge/Engineering_and_technology/Computer_science/Fixed-function/</li>
<li>[Computer Graphics] 3D 그래픽의 역사 - Newtron의 프로그래밍 블로그, accessed July 5, 2025, https://newtron-vania.tistory.com/75</li>
<li>Fixed-function (computer graphics) - Wikipedia, accessed July 5, 2025, https://en.wikipedia.org/wiki/Fixed-function</li>
<li>그래픽 파이프라인 - UWP applications | Microsoft Learn, accessed July 5, 2025, https://learn.microsoft.com/ko-kr/windows/uwp/graphics-concepts/graphics-pipeline</li>
<li>OpenGL 정리 - 3. 프로그래머블 셰이더(Programmable Shader) - surkim 님의 블로그, accessed July 5, 2025, https://surkim.tistory.com/17</li>
<li>04-1. 그래픽스 파이프라인, Shader, GLSL - inhibitor.log, accessed July 5, 2025, https://inhibitor1217.github.io/2019/04/21/webgl-shader</li>
<li>Fixed Function Pipeline - OpenGL Wiki, accessed July 5, 2025, https://www.khronos.org/opengl/wiki/Fixed_Function_Pipeline</li>
<li>렌더링 파이프라인 ( Rendering Pipeline ) - 무면허 개발자 블로그, accessed July 5, 2025, https://shj9866.tistory.com/34</li>
<li>[OpenGL ES] 렌더링 파이프라인 훑어보기 - velog, accessed July 5, 2025, <a href="https://velog.io/@parksj3205/%EB%A0%8C%EB%8D%94%EB%A7%81-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0">https://velog.io/@parksj3205/%EB%A0%8C%EB%8D%94%EB%A7%81-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0</a></li>
<li>[DirectX 11] 스터디 3일 버퍼/셰이더 - 미녹 - 티스토리, accessed July 5, 2025, https://minok-portfolio.tistory.com/4</li>
<li>[Game Graphics] Graphics Pipeline - velog, accessed July 5, 2025, https://velog.io/@hkun_ho/Game-Graphics-DirectX-12</li>
<li>OpenGL 정리 - 3. 프로그래머블 셰이더(Programmable Shader), accessed July 5, 2025, https://surkim.tistory.com/m/17</li>
<li>[Computer Graphics] 렌더링 파이프라인 요약 - velog, accessed July 5, 2025, <a href="https://velog.io/@cedongne/Graphics-%EB%A0%8C%EB%8D%94%EB%A7%81-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%9A%94%EC%95%BD">https://velog.io/@cedongne/Graphics-%EB%A0%8C%EB%8D%94%EB%A7%81-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%9A%94%EC%95%BD</a></li>
<li>Direct3D 11 렌더링 파이프라인 - 개발 공부 연습 노트 - 티스토리, accessed July 5, 2025, https://myoung-min.tistory.com/9</li>
<li>퐁 셰이딩 - 위키백과, 우리 모두의 백과사전, accessed July 5, 2025, <a href="https://ko.wikipedia.org/wiki/%ED%90%81_%EC%85%B0%EC%9D%B4%EB%94%A9">https://ko.wikipedia.org/wiki/%ED%90%81_%EC%85%B0%EC%9D%B4%EB%94%A9</a></li>
<li>www.lenovo.com, accessed July 5, 2025, <a href="https://www.lenovo.com/kr/ko/glossary/z-buffering/#:~:text=%EB%91%90%20%EA%B0%9C%20%EC%9D%B4%EC%83%81%EC%9D%98%20%ED%91%9C%EB%A9%B4%EC%9D%98,%EC%9D%B4%20%EB%AC%B8%EC%A0%9C%EB%A5%BC%20%EC%99%84%ED%99%94%ED%95%A9%EB%8B%88%EB%8B%A4.">https://www.lenovo.com/kr/ko/glossary/z-buffering/#:~:text=%EB%91%90%20%EA%B0%9C%20%EC%9D%B4%EC%83%81%EC%9D%98%20%ED%91%9C%EB%A9%B4%EC%9D%98,%EC%9D%B4%20%EB%AC%B8%EC%A0%9C%EB%A5%BC%20%EC%99%84%ED%99%94%ED%95%A9%EB%8B%88%EB%8B%A4.</a></li>
<li>Z 버퍼링 - 위키백과, 우리 모두의 백과사전, accessed July 5, 2025, <a href="https://ko.wikipedia.org/wiki/Z_%EB%B2%84%ED%8D%BC%EB%A7%81">https://ko.wikipedia.org/wiki/Z_%EB%B2%84%ED%8D%BC%EB%A7%81</a></li>
<li>Z-버퍼링 이해하기: 알아야 할 모든 것 | 레노버 코리아 - Lenovo, accessed July 5, 2025, https://www.lenovo.com/kr/ko/glossary/z-buffering/</li>
<li>[DepthMap] zbuffer - 얍 - 티스토리, accessed July 5, 2025, https://hyelimkungkung.tistory.com/68</li>
<li>[three.js] Depth Buffering(Z-buffering) 개념 - velog, accessed July 5, 2025, <a href="https://velog.io/@cjkangme/three.js-Depth-BufferingZ-buffering-%EA%B0%9C%EB%85%90">https://velog.io/@cjkangme/three.js-Depth-BufferingZ-buffering-%EA%B0%9C%EB%85%90</a></li>
<li>[Unity] Z-buffer, Shader Lab - 일단 뭔가 해보는 곳 - 티스토리, accessed July 5, 2025, https://sunsimu1018.tistory.com/20</li>
<li>Phong Shading - soo:bak - 개념 - Ambient Reflection, 주변 반사, accessed July 5, 2025, https://soo-bak.github.io/dev/graphics/PhongShadingModel/</li>
<li>6장 3D Graphics - ④ 조명(퐁 셰이딩 - Phong Shading) - 달리는 개발자 - 티스토리, accessed July 5, 2025, https://dev-sbee.tistory.com/35</li>
<li>[Unity] URP 셰이더 퐁(Phong), 블린 퐁(Blinn Phong), 프레넬(Fresnel …, accessed July 5, 2025, https://lightbakery.tistory.com/36</li>
<li>렌더링 - 나무위키, accessed July 5, 2025, <a href="https://namu.wiki/w/%EB%A0%8C%EB%8D%94%EB%A7%81">https://namu.wiki/w/%EB%A0%8C%EB%8D%94%EB%A7%81</a></li>
<li>퐁 쉐이딩 (Pong Shading) - 용어사전 - CGlink, accessed July 5, 2025, https://cglink.com/terms/1085</li>
<li>Shading - 혼자하는 코딩 - 티스토리, accessed July 5, 2025, https://gofo-coding.tistory.com/entry/Shading</li>
<li>고해상도 렌더 파이프라인의 안티앨리어싱 | High Definition RP | 10.5.0, accessed July 5, 2025, https://docs.unity3d.com/kr/Packages/com.unity.render-pipelines.high-definition@10.5/manual/Anti-Aliasing.html</li>
<li>Anti aliasing | PPT - SlideShare, accessed July 5, 2025, https://www.slideshare.net/slideshow/anti-aliasing/12262298</li>
<li>안티에일리어싱 - 나무위키, accessed July 5, 2025, <a href="https://namu.wiki/w/%EC%95%88%ED%8B%B0%EC%97%90%EC%9D%BC%EB%A6%AC%EC%96%B4%EC%8B%B1">https://namu.wiki/w/%EC%95%88%ED%8B%B0%EC%97%90%EC%9D%BC%EB%A6%AC%EC%96%B4%EC%8B%B1</a></li>
<li>혹시 이거 뭐하는 건지 아는 사람? FXAA MSAA TXAA : r/GrandTheftAutoV_PC - Reddit, accessed July 5, 2025, https://www.reddit.com/r/GrandTheftAutoV_PC/comments/34as5u/can_someone_please_tell_me_what_these_do_fxaa/?tl=ko</li>
<li>안티에일리어싱 (r262 판) - 나무위키, accessed July 5, 2025, <a href="https://namu.wiki/w/%EC%95%88%ED%8B%B0%EC%97%90%EC%9D%BC%EB%A6%AC%EC%96%B4%EC%8B%B1?uuid=6b378a5b-0177-446d-9c0b-a79c28f45f46">https://namu.wiki/w/%EC%95%88%ED%8B%B0%EC%97%90%EC%9D%BC%EB%A6%AC%EC%96%B4%EC%8B%B1?uuid=6b378a5b-0177-446d-9c0b-a79c28f45f46</a></li>
<li>유니티를 사용하며 Anti-Aliasing 사용 경험? #개념 완벽 정리 #HDRP - 빵훈 - 티스토리, accessed July 5, 2025, <a href="https://0-hoon.tistory.com/entry/%EC%9C%A0%EB%8B%88%ED%8B%B0%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%A9%B0-Anti-Aliasing-%EC%82%AC%EC%9A%A9-%EA%B2%BD%ED%97%98-%EA%B7%B8%EB%9E%98%ED%94%BD-%EB%B3%B4%EC%99%84-%EA%B2%BD%ED%97%98">https://0-hoon.tistory.com/entry/%EC%9C%A0%EB%8B%88%ED%8B%B0%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%A9%B0-Anti-Aliasing-%EC%82%AC%EC%9A%A9-%EA%B2%BD%ED%97%98-%EA%B7%B8%EB%9E%98%ED%94%BD-%EB%B3%B4%EC%99%84-%EA%B2%BD%ED%97%98</a></li>
<li>광선 추적(ray tracing) 및 불칸(Vulkan) API를 활용한 고성능 센서 모델 - Applied Intuition, accessed July 5, 2025, https://www.appliedintuition.com/kr/blog/raytracing</li>
<li>레이 트레이싱이 인상적인 3D 렌더링을 발전시킨 과정 소개 - GarageFarm, accessed July 5, 2025, https://garagefarm.net/ko-blog/how-ray-tracing-has-elevated-the-already-impressive-effects-of-3d-rendering</li>
<li>What is real-time ray tracing? - Unreal Engine, accessed July 5, 2025, https://www.unrealengine.com/en-US/explainers/ray-tracing/what-is-real-time-ray-tracing</li>
<li>컴퓨터 그래픽스와 가상현실 구현 기술: 디지털 세계를 창조하는 마법 같은 기술들 - 재능넷, accessed July 5, 2025, https://www.jaenung.net/tree/19393</li>
<li>3D to 2D 변환: 입체 영상 평면화의 세계 🖼️ - 재능넷, accessed July 5, 2025, https://www.jaenung.net/tree/3070</li>
<li>패스 트레이싱이란? - NVIDIA Technical Blog - NVIDIA Developer, accessed July 5, 2025, <a href="https://developer.nvidia.com/ko-kr/blog/%ED%8C%A8%EC%8A%A4-%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%8B%B1%EC%9D%B4%EB%9E%80/">https://developer.nvidia.com/ko-kr/blog/%ED%8C%A8%EC%8A%A4-%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%8B%B1%EC%9D%B4%EB%9E%80/</a></li>
<li>[케이스 스터디] 건축 시각화에 쓰이는 언리얼 엔진의 리얼타임 레이 트레이싱 - 캐드앤그래픽스, accessed July 5, 2025, https://cadgraphics.co.kr/newsview.php?pages=news&amp;sub=news01&amp;catecode=2&amp;num=66474</li>
<li>리얼타임 레이 트레이싱이 무엇인가요? - Unreal Engine, accessed July 5, 2025, https://www.unrealengine.com/ko/explainers/ray-tracing/what-is-real-time-ray-tracing</li>
<li>레이트레이싱, 패스 트레이싱, 디노이징 - Hybrid3D, accessed July 5, 2025, https://blog.hybrid3d.dev/2019-11-15-raytracing-pathtracing-denoising</li>
<li>게임에서 레이 트레이싱이란 무엇입니까? - Corsair, accessed July 5, 2025, https://www.corsair.com/kr/ko/explorer/gamer/gaming-pcs/what-is-ray-tracing-in-games/</li>
<li>Crysis 2 and CryEngine 3 Key Rendering Features PDF - Pierre Yves Donzallaz, accessed July 5, 2025, https://pydonzallaz.wordpress.com/wp-content/uploads/2011/03/crysis-2-and-cryengine-3-key-rendering-features.pdf</li>
<li>레이트레이싱 VS 레스터라이제이션, 승자는?! - 재능넷, accessed July 5, 2025, https://www.jaenung.net/tree/24462</li>
<li>비교: 패스 트레이싱 vs 레이 트레이싱 (미친) : r/cyberpunkgame - Reddit, accessed July 5, 2025, https://www.reddit.com/r/cyberpunkgame/comments/12mwcvd/comparison_path_tracing_vs_ray_tracing_psycho/?tl=ko</li>
<li>Games on the N64 are often limited by memory bandwidth, which is taken up by r… | Hacker News, accessed July 5, 2025, https://news.ycombinator.com/item?id=36501079</li>
<li>GPU Memory Bandwidth and Its Impact on Performance - DigitalOcean, accessed July 5, 2025, https://www.digitalocean.com/community/tutorials/gpu-memory-bandwidth</li>
<li>Did 80s/90s computers have 2D graphics hardware effects? Like SNES MODE7, multiple background layers, line scrolling, sprite limits, background rotation, sprite scaling, etc.? - Reddit, accessed July 5, 2025, https://www.reddit.com/r/hardware/comments/qu9ly3/did_80s90s_computers_have_2d_graphics_hardware/</li>
<li>John Carmack talk at Upper Bound 2025 | Hacker News, accessed July 5, 2025, https://news.ycombinator.com/item?id=44070042</li>
<li>The Legendary Fast Inverse Square Root | by Shaw | Hard Mode - Medium, accessed July 5, 2025, https://medium.com/hard-mode/the-legendary-fast-inverse-square-root-e51fee3b49d9</li>
<li>Quake Engine code review : Rendition (4/4) - Fabien Sanglard, accessed July 5, 2025, https://fabiensanglard.net/quakeSource/quakeSourceRendition.php</li>
<li>Quake Lightmaps | project log, accessed July 5, 2025, https://jbush001.github.io/2015/06/11/quake-lightmaps.html</li>
<li>Lightmap - Wikipedia, accessed July 5, 2025, https://en.wikipedia.org/wiki/Lightmap</li>
<li>Lightmap - Sceneri, accessed July 5, 2025, https://www.sceneri.com/sceneri-docs-glossar/lightmap/</li>
<li>GPU란?- 그래픽 처리 장치 설명 - AWS, accessed July 5, 2025, https://aws.amazon.com/ko/what-is/gpu/</li>
<li>DirectX/버전 정보 - 나무위키, accessed July 5, 2025, <a href="https://namu.wiki/w/DirectX/%EB%B2%84%EC%A0%84%20%EC%A0%95%EB%B3%B4">https://namu.wiki/w/DirectX/%EB%B2%84%EC%A0%84%20%EC%A0%95%EB%B3%B4</a></li>
<li>Real-time ray tracing in Unreal Engine - Part 1: the evolution, accessed July 5, 2025, https://www.unrealengine.com/fr/blog/real-time-ray-tracing-in-unreal-engine-part-1—the-evolution</li>
<li>Introduction to Rendering in Unreal Engine for Unity Developers, accessed July 5, 2025, https://dev.epicgames.com/documentation/en-us/unreal-engine/introduction-to-rendering-in-unreal-engine-for-unity-developers</li>
<li>Rendering Technologies from Crysis 3 (GDC 2013) | PPT - SlideShare, accessed July 5, 2025, https://www.slideshare.net/slideshow/rendering-technologies-from-crysis-3-gdc-2013/25052434</li>
<li>Chapter 16. Vegetation Procedural Animation and Shading in Crysis | NVIDIA Developer, accessed July 5, 2025, https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-16-vegetation-procedural-animation-and-shading-crysis</li>
<li>Tile-based GPUs - Arm Developer, accessed July 5, 2025, https://developer.arm.com/documentation/102662/latest/Tile-based-GPUs</li>
<li>Tile-Based Rendering on the Arm Mali-G78AE - WP557, accessed July 5, 2025, https://docs.amd.com/r/en-US/wp557-versal-gen-2-gpu/Tile-Based-Rendering-on-the-Arm-Mali-G78AE</li>
<li>Tiled rendering - Wikipedia, accessed July 5, 2025, https://en.wikipedia.org/wiki/Tiled_rendering</li>
<li>Adreno - Wikipedia, accessed July 5, 2025, https://en.wikipedia.org/wiki/Adreno</li>
<li>Qualcomm ® Adreno™ GPU, accessed July 5, 2025, https://docs.qualcomm.com/bundle/publicresource/topics/80-78185-2/gpu.html?product=1601111740035277</li>
<li>Overview - Game Developer Guides documentation - Qualcomm, accessed July 5, 2025, https://docs.qualcomm.com/bundle/publicresource/topics/80-78185-2/overview.html</li>
<li>GPU Framebuffer Memory: Understanding Tiling - Samsung Developer, accessed July 5, 2025, https://developer.samsung.com/galaxy-gamedev/resources/articles/gpu-framebuffer.html</li>
<li>What are the key performance optimization techniques for VR? - Milvus, accessed July 5, 2025, https://milvus.io/ai-quick-reference/what-are-the-key-performance-optimization-techniques-for-vr</li>
<li>Optimization advice for graphics content on mobile devices - Arm, accessed July 5, 2025, <a href="https://documentation-service.arm.com/static/65952df1159ca73387227425?token">https://documentation-service.arm.com/static/65952df1159ca73387227425?token=</a></li>
<li>Optimize your mobile game performance: Expert tips on graphics and assets - Unity, accessed July 5, 2025, https://unity.com/blog/games/optimize-your-mobile-game-performance-expert-tips-on-graphics-and-assets</li>
<li>Rendering Optimization for Mobile - Epic Games Developers, accessed July 5, 2025, https://dev.epicgames.com/documentation/en-us/unreal-engine/optimization-and-development-best-practices-for-mobile-projects-in-unreal-engine</li>
<li>Variable-rate shading (VRS) - Win32 apps - Learn Microsoft, accessed July 5, 2025, https://learn.microsoft.com/en-us/windows/win32/direct3d12/vrs</li>
<li>Variable Rate Shading (VRS) - VRWorks - NVIDIA Developer, accessed July 5, 2025, https://developer.nvidia.com/vrworks/graphics/variablerateshading</li>
<li>Can someone explain Variable Rate Shading to me? How does it differ from traditional LOD? : r/nvidia - Reddit, accessed July 5, 2025, https://www.reddit.com/r/nvidia/comments/awonhu/can_someone_explain_variable_rate_shading_to_me/</li>
<li>Variable rate shading - Godot Engine (stable) documentation in English, accessed July 5, 2025, https://docs.godotengine.org/en/stable/tutorials/3d/variable_rate_shading.html</li>
<li>Adventures with Differentiable Mesh Rendering - Andrew Chan, accessed July 5, 2025, https://andrewkchan.dev/posts/diff-render.html</li>
<li>Differentiable Vector Graphics Rasterization for Editing and Learning - People | MIT CSAIL, accessed July 5, 2025, https://people.csail.mit.edu/tzumao/diffvg/</li>
<li>Differentiable Vector Graphics Rasterization for Editing and Learning - People, accessed July 5, 2025, https://people.csail.mit.edu/tzumao/diffvg/diffvg.pdf</li>
<li>Differentiable Rendering: A Survey - arXiv, accessed July 5, 2025, http://arxiv.org/pdf/2006.12057</li>
<li>Differentiable Rasterization, accessed July 5, 2025, https://srush.github.io/DiffRast/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>