<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:레이트레이싱 기술</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>레이트레이싱 기술</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">컴퓨터 그래픽 (Computer Graphics)</a> / <a href="index.html">Raytracing</a> / <span>레이트레이싱 기술</span></nav>
                </div>
            </header>
            <article>
                <h1>레이트레이싱 기술</h1>
<h2>1. 서론</h2>
<h3>1.1 레이 트레이싱: 컴퓨터 그래픽스의 성배</h3>
<p>레이 트레이싱(Ray Tracing)은 컴퓨터 그래픽스 분야에서 오랫동안 ’성배(Holy Grail)’로 여겨져 온 렌더링 기술이다.1 이는 단순히 사실적인 이미지를 생성하는 여러 기법 중 하나를 넘어, 현실 세계의 빛이 물리적으로 어떻게 행동하는지를 근본적으로 시뮬레이션하려는 시도에 기반을 두고 있기 때문이다. 물체의 색상, 그림자, 반사, 굴절과 같은 모든 시각적 현상은 광원에서 출발한 빛이 공간을 이동하며 물체와 상호작용하고, 최종적으로 관찰자의 눈에 도달하는 복잡한 과정의 결과물이다.2 레이 트레이싱은 바로 이 빛의 경로를 추적함으로써, 기존의 어떤 기법보다도 높은 수준의 물리적 정확성과 시각적 충실도를 달성하고자 한다.</p>
<p>이 기술의 잠재력은 픽사(Pixar)와 같은 스튜디오의 장편 애니메이션에서 수십 년간 증명되어 왔다. 극사실적인 조명과 재질 표현을 위해 프레임당 수 시간에 달하는 렌더링 시간을 감수하며 사용되어 온 오프라인 렌더링의 핵심 기술이 바로 레이 트레이싱이었다. 그러나 최근 몇 년 사이, 그래픽 하드웨어의 폭발적인 발전과 관련 소프트웨어 생태계의 성숙은 이 ’성배’를 실시간 애플리케이션, 특히 비디오 게임의 영역으로 가져왔다.1 이는 그래픽스 역사상 가장 중요한 패러다임 전환 중 하나로 평가받으며, 개발자와 사용자 모두에게 전례 없는 수준의 몰입감과 사실성을 제공하고 있다.3</p>
<h3>1.2 안내서의 구성 및 목표</h3>
<p>본 안내서는 레이 트레이싱 기술에 대한 심층적이고 포괄적인 기술적 고찰을 제공하는 것을 목표로 한다. 이를 위해 기술의 가장 근본적인 물리적, 수학적 원리에서부터 시작하여, 현대 실시간 그래픽스의 표준이었던 래스터라이제이션(Rasterization)과의 비교 분석을 통해 그 차별점과 의의를 명확히 한다.</p>
<p>이후 안내서는 레이 트레이싱을 구성하는 핵심 알고리즘과 렌더링 파이프라인의 각 단계를 심도 있게 파고든다. 특히, 방대한 계산량을 효율적으로 처리하기 위한 가속 구조(Acceleration Structure)와, 반사와 굴절 같은 복잡한 광학 현상을 구현하는 재귀적(Recursive) 추적 방식, 그리고 전역 조명(Global Illumination)을 위한 고급 기법인 패스 트레이싱(Path Tracing)을 상세히 다룬다.</p>
<p>기술의 실시간 구현을 가능하게 한 하드웨어 아키텍처와 소프트웨어 API 생태계에 대한 분석 또한 본 안내서의 중요한 부분을 차지한다. NVIDIA의 RT 코어와 AMD의 Ray Accelerator와 같은 전용 하드웨어의 작동 방식과 구조적 차이를 비교하고, Microsoft의 DirectX Raytracing(DXR) 및 Khronos 그룹의 Vulkan Ray Tracing API가 개발자에게 어떤 도구와 추상화 계층을 제공하는지 살펴본다.</p>
<p>실시간 구현에서 필연적으로 발생하는 노이즈 문제를 해결하기 위한 최적화 기법, 특히 다양한 디노이징(Denoising) 기술에 대한 분석은 실용적인 관점에서 매우 중요하다. 본 안내서는 시공간적 필터링부터 최신 AI 기반 기법에 이르기까지 주요 디노이징 기술의 원리와 장단점, 그리고 이들이 야기할 수 있는 시각적 아티팩트(Artifact)를 고찰한다.</p>
<p>마지막으로, 이러한 기술들이 실제 산업 현장에서 어떻게 적용되고 있는지를 영화, 게임, 건축 및 디자인 분야의 구체적인 사례 연구를 통해 분석한다. 더 나아가, 신경망 렌더링(Neural Rendering)과 같은 최신 연구 동향과의 융합을 통해 레이 트레이싱 기술이 앞으로 나아갈 방향과 미래를 조망하며 안내서를 마무리한다.</p>
<h2>2.  빛 수송 시뮬레이션의 근본 원리</h2>
<h3>2.1  물리적 현실과 렌더링 방정식</h3>
<p>컴퓨터 그래픽스의 궁극적인 목표는 가상의 3차원 세계를 2차원 이미지로 표현하는 것이며, 그 과정의 핵심은 현실 세계의 빛이 어떻게 물체와 상호작용하는지를 모사하는 데 있다. 우리가 어떤 물체를 보고 그 색과 형태, 질감을 인지하는 것은 광원(예: 태양, 전구)에서 방출된 빛 입자, 즉 광자(photon)가 물체 표면에 도달하여 반사(reflection), 굴절(refraction), 흡수(absorption), 산란(scattering) 등의 복잡한 상호작용을 거친 후, 그 결과로 우리 눈의 망막에 도달하기 때문이다.2</p>
<p>이러한 빛의 물리적 현상을 수학적으로 정밀하게 기술하기 위해 1986년 제임스 카지야(James Kajiya)에 의해 정립된 것이 바로 ’렌더링 방정식(The Rendering Equation)’이다.4 이 방정식은 컴퓨터 그래픽스에서 물리 기반 렌더링(Physically Based Rendering, PBR)의 이론적 토대를 이루며, 전역 조명(Global Illumination) 문제를 해결하기 위한 일반적인 공식으로 간주된다.4</p>
<p>렌더링 방정식은 특정 지점 <span class="math math-inline">x</span>에서 특정 방향 <span class="math math-inline">\omega_o</span>로 나가는 빛의 양, 즉 복사량(Radiance, <span class="math math-inline">L_o</span>)은 그 지점에서 자체적으로 방출하는 빛(<span class="math math-inline">L_e</span>)과, 그 지점을 둘러싼 반구(hemisphere, <span class="math math-inline">\Omega</span>) 내의 모든 방향 <span class="math math-inline">\omega_i</span>에서 들어오는 빛(<span class="math math-inline">L_i</span>)이 표면의 특성에 따라 반사된 양의 총합으로 정의된다. 이를 수식으로 표현하면 다음과 같다.<br />
<span class="math math-display">
L_o(x, \omega_o) = L_e(x, \omega_o) + \int_{\Omega} f_r(x, \omega_i, \omega_o) L_i(x, \omega_i) (\mathbf{n} \cdot \omega_i) d\omega_i
</span><br />
여기서 각 항의 의미는 다음과 같다.</p>
<ul>
<li><span class="math math-inline">L_o(x, \omega_o)</span>: 지점 <span class="math math-inline">x</span>에서 방향 <span class="math math-inline">\omega_o</span>로 나가는 복사량 (우리가 구하고자 하는 값).</li>
<li><span class="math math-inline">L_e(x, \omega_o)</span>: 지점 <span class="math math-inline">x</span>가 광원일 경우 방향 <span class="math math-inline">\omega_o</span>로 자체적으로 방출하는 복사량.</li>
<li><span class="math math-inline">\int_{\Omega} \dots d\omega_i</span>: 지점 <span class="math math-inline">x</span>를 중심으로 하는 반구 전체에 대한 적분.</li>
<li><span class="math math-inline">f_r(x, \omega_i, \omega_o)</span>: 양방향 반사 분포 함수(Bidirectional Reflectance Distribution Function, BRDF)로, 들어오는 빛 <span class="math math-inline">\omega_i</span>가 나가는 빛 <span class="math math-inline">\omega_o</span>로 얼마나 반사되는지를 결정하는 표면의 재질 특성.</li>
<li><span class="math math-inline">L_i(x, \omega_i)</span>: 지점 <span class="math math-inline">x</span>로 방향 <span class="math math-inline">\omega_i</span>에서 들어오는 복사량.</li>
<li><span class="math math-inline">(\mathbf{n} \cdot \omega_i)</span>: 입사각에 따른 빛의 감쇠를 나타내는 코사인 항 (램버트의 코사인 법칙).</li>
</ul>
<p>이 방정식의 핵심적인 특징은 재귀적(recursive)이라는 점이다. 어떤 지점으로 들어오는 빛(<span class="math math-inline">L_i</span>)은 사실 다른 지점에서 나간 빛(<span class="math math-inline">L_o</span>)이다. 즉, 장면의 모든 지점의 빛은 서로에게 영향을 미치며, 이 때문에 방정식은 해석적으로 풀기가 매우 어려운 적분 방정식의 형태를 띤다.5 레이 트레이싱, 특히 패스 트레이싱은 바로 이 복잡한 렌더링 방정식을 수치적으로 풀기 위한 강력한 방법론이다.</p>
<h3>2.2  광선 추적의 역발상: 카메라에서 광원으로</h3>
<p>물리적 현실에서 빛은 광원에서 출발하여 객체와 상호작용을 거쳐 관찰자의 눈으로 들어온다. 이 과정을 컴퓨터로 그대로 시뮬레이션하는 것을 ‘순방향 추적(Forward Tracing)’ 또는 ’라이트 트레이싱(Light Tracing)’이라고 할 수 있다. 하지만 이 방식은 렌더링에 있어 극도로 비효율적이다. 그 이유는 광원에서 방출되는 수십억, 수조 개의 광선 중 극히 일부만이 최종적으로 카메라 렌즈를 통과하여 이미지 센서에 상을 맺기 때문이다.2 대부분의 광선은 카메라와 전혀 상관없는 방향으로 흩어지거나, 다른 물체에 흡수되어 버린다. 따라서 이 모든 광선을 추적하는 것은 엄청난 계산 낭비로 이어진다.</p>
<p>이러한 계산적 비효율성을 해결하기 위해 레이 트레이싱은 물리적 과정과는 정반대의 접근법을 취한다. 바로 ’역방향 추적(Backward Tracing)’이다.2 이 방식은 광원이 아닌, 최종 결과물이 맺히는 카메라(또는 눈)에서부터 빛의 경로를 거꾸로 추적한다. 구체적인 과정은 다음과 같다.</p>
<ol>
<li><strong>시작점:</strong> 최종적으로 생성될 2D 이미지의 각 픽셀을 시작점으로 삼는다.</li>
<li><strong>광선 투사:</strong> 카메라의 원점(시점)에서 각 픽셀의 중심을 통과하는 가상의 ’시야 광선(Viewing Ray)’을 3D 공간으로 쏘아 보낸다.</li>
<li><strong>경로 역추적:</strong> 이 광선이 장면 내의 물체와 부딪히면, 그 지점에서 빛이 어디로부터 왔을지를 다시 추적한다. 예를 들어, 부딪힌 지점에서 광원을 향해 또 다른 광선(그림자 광선)을 쏘아보거나, 반사/굴절 법칙에 따라 새로운 광선을 생성하여 추적을 계속한다.</li>
<li><strong>색상 결정:</strong> 이 역추적 과정을 통해 광원에 도달하거나, 더 이상 추적이 불필요한 지점에 이르면, 그 경로를 따라 수집된 빛 정보를 종합하여 최초의 픽셀 색상을 결정한다.</li>
</ol>
<p>이러한 역방향 추적 방식의 근본적인 장점은 계산을 오직 최종 이미지에 기여하는 광선에만 한정시킨다는 점이다. 이미지의 해상도가 정해져 있다면, 추적해야 할 초기 광선의 수는 픽셀 수에 의해 제한된다. 이는 물리적으로 무한한 광선을 다루는 문제를, 계산적으로 유한하고 다룰 수 있는 문제로 변환시키는 핵심적인 발상의 전환이다. 이 역추적 개념은 단순한 구현상의 디테일이 아니라, 레이 트레이싱을 계산적으로 실현 가능하게 만든 가장 근본적인 알고리즘적 기반이라고 할 수 있다.</p>
<h3>2.3  기본 렌더링 파이프라인: 3단계 프로세스</h3>
<p>레이 트레이싱의 개념을 실제 알고리즘으로 구현한 가장 기본적인 렌더링 파이프라인은 크게 세 가지 핵심 단계로 구성된다.2 이 과정은 이미지의 모든 픽셀에 대해 독립적으로 반복된다.</p>
<ol>
<li>광선 생성 (Ray Generation):</li>
</ol>
<p>이 단계의 목표는 2D 픽셀 좌표를 3D 공간상의 광선으로 변환하는 것이다. 광선은 수학적으로 원점(origin) <span class="math math-inline">\mathbf{s}</span>와 단위 방향 벡터(direction vector) <span class="math math-inline">\mathbf{r}</span>로 정의된다. 광선 위의 모든 점 <span class="math math-inline">\mathbf{p}</span>는 파라미터 <span class="math math-inline">t</span>를 이용해 <span class="math math-inline">\mathbf{p}(t) = \mathbf{s} + t\mathbf{r}</span> (<span class="math math-inline">t \ge 0</span>)로 표현할 수 있다.7</p>
<p>광선을 생성하기 위해서는 카메라의 기하학적 정보가 필요하다. 주로 사용되는 투영 모델은 원근 투영(Perspective Projection)이다.6 원근 투영은 사람의 눈이나 카메라 렌즈가 세상을 보는 방식과 유사하게, 멀리 있는 물체는 작게 보이도록 하여 사실감과 깊이감을 부여한다. 카메라의 위치, 바라보는 방향, 시야각(Field of View, FOV), 그리고 이미지 평면의 종횡비 등을 이용해 각 픽셀 <span class="math math-inline">(x_p, y_p)</span>를 통과하는 고유한 광선의 방향 벡터를 계산한다.4</p>
<ol start="2">
<li>광선 교차 (Ray Intersection):</li>
</ol>
<p>생성된 광선이 3D 장면을 관통하면서 어떤 물체와 충돌하는지 찾아내는 단계이다. 장면은 수많은 기하학적 기본 단위(primitive), 주로 삼각형(triangle)으로 구성되어 있다. 알고리즘은 광선과 장면 내 모든 프리미티브와의 교차 여부를 테스트해야 한다.</p>
<p>만약 광선이 여러 물체와 교차한다면, 그 중 카메라 원점에서 가장 가까운 교차점만이 해당 픽셀에서 ‘보이는’ 지점이 된다.2 따라서 가장 작은 <span class="math math-inline">t</span> 값을 갖는 교차점을 찾아야 한다. 만약 광선이 어떤 물체와도 교차하지 않는다면, 해당 픽셀은 배경(background)으로 처리되며, 미리 지정된 배경색이나 환경 맵(environment map)의 색상을 갖게 된다. 이 교차 테스트는 레이 트레이싱에서 가장 많은 계산량을 요구하는 부분 중 하나이며, 이를 가속화하기 위해 가속 구조(Acceleration Structure)가 필수적으로 사용된다 (제3장 참조).</p>
<ol start="3">
<li>셰이딩 (Shading):</li>
</ol>
<p>가장 가까운 교차점이 결정되면, 해당 지점의 표면 색상을 계산하는 셰이딩 단계가 시작된다.6 셰이딩은 다양한 요소를 종합적으로 고려하여 최종 픽셀 색상을 결정한다.</p>
<ul>
<li><strong>재질(Material):</strong> 교차점의 물체가 가진 고유한 표면 특성(알베도 색상, 거칠기, 금속성 등)을 고려한다.</li>
<li><strong>직접 조명(Direct Illumination):</strong> 교차점에서 광원까지의 방향을 계산하고, 그 사이에 다른 물체가 가로막고 있는지 확인하기 위해 ’그림자 광선(Shadow Ray)’을 쏘아본다. 그림자 광선이 광원에 도달하기 전에 다른 물체와 부딪히면 해당 지점은 그림자 속에 있는 것이므로, 그 광원으로부터의 빛 기여는 무시된다.</li>
<li><strong>간접 조명(Indirect Illumination):</strong> 더 나아가, 교차점에서 새로운 광선을 생성하여 주변 환경으로부터 반사되거나 굴절되어 들어오는 빛을 계산한다. 이는 반사(reflection), 굴절(refraction), 전역 조명(global illumination)과 같은 고급 효과를 구현하는 핵심 과정이며, 재귀적(recursive)으로 <code>ray_trace</code> 함수를 호출함으로써 이루어진다.</li>
</ul>
<p>이 세 가지 단계(광선 생성, 교차, 셰이딩)를 모든 픽셀에 대해 수행하면, 마침내 하나의 완전한 2D 이미지가 렌더링된다. 다음은 이 과정을 나타내는 기본적인 의사 코드(pseudo-code) 구조이다.</p>
<pre><code>function render_image():
  for each pixel (x, y) in image:
    ray = generate_camera_ray(x, y)
    pixel_color[x, y] = trace_ray(ray)

function trace_ray(ray):
  intersection = find_closest_intersection(ray, scene)
  if intersection is found:
    color = shade(intersection)
    return color
  else:
    return background_color
</code></pre>
<h2>3.  현대 렌더링의 이분법: 레이 트레이싱 대 래스터라이제이션</h2>
<p>현대 컴퓨터 그래픽스, 특히 실시간 렌더링 분야는 두 가지 핵심 패러다임, 즉 레이 트레이싱과 래스터라이제이션의 경쟁과 융합의 역사라고 할 수 있다. 수십 년간 실시간 그래픽스의 왕좌를 지켜온 래스터라이제이션과, 궁극의 사실성을 무기로 새롭게 부상한 레이 트레이싱의 기술적 차이를 이해하는 것은 현대 렌더링 기술을 고찰하는 데 있어 필수적이다.</p>
<h3>3.1  래스터라이제이션의 작동 방식</h3>
<p>래스터라이제이션은 3차원 공간의 기하학적 모델(geometry)을 2차원 화면의 픽셀 그리드로 변환하는 매우 효율적이고 시간 검증된(time-tested) 기법이다. 그 이름에서 알 수 있듯이, 이 과정의 핵심은 ‘래스터화(rasterize)’, 즉 벡터 형태의 기하학 정보를 픽셀 단위의 래스터 이미지로 바꾸는 데 있다.</p>
<p>래스터라이제이션 파이프라인은 일반적으로 다음과 같은 단계로 진행된다 :</p>
<ol>
<li><strong>기하학 처리 (Geometry Processing / Vertex Shading):</strong> 3D 모델을 구성하는 각 정점(vertex)의 좌표를 모델 공간(model space)에서 월드 공간(world space), 뷰 공간(view space)을 거쳐 최종적으로 2D 화면에 투영될 클립 공간(clip space)으로 변환한다. 이 과정은 주로 행렬 곱셈을 통해 이루어진다.</li>
<li><strong>프리미티브 조립 (Primitive Assembly):</strong> 변환된 정점들을 연결하여 삼각형과 같은 기본 도형(primitive)을 구성한다.</li>
<li><strong>래스터화 (Rasterization):</strong> 2D로 투영된 각 삼각형이 화면의 어떤 픽셀들을 덮는지 결정한다. 이 과정을 거치면 삼각형은 픽셀의 후보군인 ’프래그먼트(fragment)’의 집합으로 변환된다.</li>
<li><strong>프래그먼트 처리 (Fragment Shading / Pixel Shading):</strong> 각 프래그먼트에 대해 최종 색상을 계산한다. 이 단계에서 텍스처 매핑, 조명 계산, 셰이딩 모델(예: Phong, Blinn-Phong) 적용 등이 이루어진다. 여러 프래그먼트가 동일한 픽셀을 덮을 경우, 깊이 테스트(depth test)를 통해 가장 앞에 있는 프래그먼트만 남기고 나머지는 폐기한다.</li>
</ol>
<p>이 방식은 객체(삼각형)를 중심으로 처리하며, GPU의 수많은 병렬 처리 코어에 매우 효율적으로 분배될 수 있도록 설계되었다. 이러한 구조적 특성 덕분에 래스터라이제이션은 수십 년간 비디오 게임과 같은 실시간 애플리케이션에서 압도적인 성능 우위를 점하며 표준 기술로 자리매김했다.</p>
<h3>3.2  기술적 장단점 비교 분석</h3>
<p>레이 트레이싱과 래스터라이제이션은 근본적으로 다른 철학을 바탕으로 하기에, 사실성, 성능, 개발 복잡성 측면에서 명확한 장단점을 보인다.</p>
<ul>
<li><strong>사실성 (Realism):</strong></li>
<li><strong>레이 트레이싱:</strong> 이 기술의 가장 큰 장점은 타의 추종을 불허하는 사실성이다. 빛의 물리적 경로를 직접 시뮬레이션하기 때문에, 반사, 굴절, 부드러운 그림자, 전역 조명(GI), 코스틱스(caustics)와 같은 복잡한 광학 효과를 별도의 ‘꼼수’ 없이 자연스럽고 정확하게 생성할 수 있다.8 특히 중요한 점은 화면 밖에 있는(off-screen) 객체도 반사되거나 그림자를 드리우는 등, 씬의 전역적인 정보를 일관되게 반영한다는 것이다.9</li>
<li><strong>래스터라이제이션:</strong> 반면, 래스터라이제이션은 본질적으로 이러한 광학 효과들을 직접 시뮬레이션할 수 없다. 대신, 이를 흉내 내기 위한 다양한 근사 기법에 의존한다. 예를 들어, 반사는 스크린 스페이스 반사(Screen-Space Reflections, SSR)로, 그림자는 섀도우 맵(Shadow Maps)으로, 간접 조명은 라이트맵(Lightmaps)이나 스크린 스페이스 앰비언트 오클루전(SSAO)으로 구현한다.3 이러한 기법들은 빠르지만, 화면에 보이는 정보에만 의존하기 때문에 시야를 벗어나면 반사가 사라지거나, 그림자 경계가 부자연스럽게 보이는 등 여러 시각적 오류(artifact)와 한계를 내포한다.10</li>
<li><strong>성능 (Performance):</strong></li>
<li><strong>래스터라이제이션:</strong> 성능은 래스터라이제이션의 절대적인 강점이다. 계산 과정이 비교적 단순하고, 수십 년에 걸쳐 하드웨어에 고도로 최적화되었기 때문에 매우 빠른 속도를 자랑한다. 실시간 애플리케이션에서 높은 프레임률(FPS)을 유지하는 데 극도로 유리하다.</li>
<li><strong>레이 트레이싱:</strong> 사실성을 얻는 대가로 엄청난 계산 비용을 치른다. 이미지의 모든 픽셀에 대해 하나 이상의 광선을 쏘고, 복잡한 가속 구조를 순회하며 수많은 교차 테스트를 수행해야 한다. 이로 인해 동일한 하드웨어에서도 래스터라이제이션에 비해 프레임률이 현저하게 감소한다. 예를 들어, 60 FPS가 나오던 게임이 레이 트레이싱을 켜면 15~30 FPS로 떨어질 수 있다.1</li>
<li><strong>개발 복잡성 (Development Complexity):</strong></li>
<li><strong>레이 트레이싱:</strong> 물리 법칙이라는 일관된 프레임워크 위에서 작동하기 때문에, 일단 파이프라인이 구축되면 사실적인 효과를 구현하는 것이 오히려 더 직관적일 수 있다. 개발자는 복잡하고 상황에 따라 달라지는 ’꼼수’를 고안하는 대신, 물리 모델 자체에 집중할 수 있다. 한 개발자는 “레이 트레이싱이 삶을 훨씬 편하게 해준다“고 언급하기도 했다.10</li>
<li><strong>래스터라이제이션:</strong> 사실적인 모습을 구현하기 위해 개발자들은 수십 년간 수많은 ’영리한 트릭(clever tricks)’과 근사치를 발명하고 개선해왔다.3 SSR, 섀도우 맵, SSAO, 라이트 프로브 등은 모두 개발자의 창의성과 노력의 산물이다. 그러나 이러한 기법들은 각각의 한계가 명확하고, 서로 충돌하거나 특정 상황에서 부자연스러운 결과를 낳는 경우가 많아, 이를 관리하고 조합하는 것은 상당한 노하우와 복잡성을 요구한다.</li>
</ul>
<p>이러한 장단점의 차이는 두 기술의 근본적인 접근 방식에서 기인한다. 래스터라이제이션은 “객체를 어떻게 화면에 효율적으로 그릴 것인가?“라는 문제에서 출발하여 픽셀을 채우는 방식이다. 반면, 레이 트레이싱은 “이 픽셀은 어떤 빛을 보아야 하는가?“라는 질문에서 시작하여 빛의 경로를 역추적하는 방식이다.</p>
<p>오랜 기간 래스터라이제이션이 그래픽스 시장을 지배할 수 있었던 이유는 단지 속도 때문만은 아니었다. 개발자들이 현실을 ‘모방하는’ 데 있어 놀라울 정도로 능숙해졌기 때문이다. 섀도우 매핑, SSR과 같은 기법들을 수십 년간 개선하여, 많은 사용자들에게 ‘충분히 좋은(good enough)’ 수준의 사실감을 제공하는 데 성공했다. 이로 인해 레이 트레이싱은 단순히 성능뿐만 아니라, 일반 사용자가 체감할 수 있는 시각적 향상 측면에서도 매우 높은 기준을 넘어야 하는 도전에 직면했다.10 하지만 이러한 관점은 개발자의 부담을 간과한다. 가짜 효과를 만드는 것은 복잡하고, 깨지기 쉬우며, 새로운 시나리오마다 재발명이 필요한 경우가 많다. 결국, 현대 렌더링의 패러다임 전환은 ’모방의 부담(개발자의 창의성)’을 ’시뮬레이션의 부담(계산 능력과 알고리즘 효율성)’으로 옮기는 과정이라고 볼 수 있다.</p>
<h3>3.3  하이브리드 렌더링: 두 패러다임의 융합</h3>
<p>오늘날 게임과 같은 실시간 애플리케이션에서 사용되는 ’레이 트레이싱’은 대부분 순수한 레이 트레이싱이 아니다. 대신, 래스터라이제이션의 속도와 레이 트레이싱의 품질을 결합한 ‘하이브리드 렌더링(Hybrid Rendering)’ 방식을 채택하고 있다.11</p>
<p>하이브리드 렌더링의 핵심 아이디어는 각 기술이 가장 잘하는 부분에 선택적으로 사용하는 것이다. 예를 들어, 씬의 기본적인 지오메트리를 렌더링하고 깊이 정보나 노멀, 알베도 같은 데이터를 담은 G-버퍼(G-buffer)를 생성하는 과정은 매우 빠른 래스터라이제이션으로 처리한다. 그 후, 래스터라이제이션만으로는 구현하기 어렵거나 품질이 떨어지는 특정 효과, 즉 사실적인 반사, 부드러운 그림자, 전역 조명 등에 대해서만 제한적으로 레이 트레이싱을 적용한다.</p>
<p>이러한 접근법은 성능과 시각적 충실도 사이에서 실용적인 균형점을 찾게 해준다. 전체 프레임을 레이 트레이싱하는 것에 비해 계산 부담을 크게 줄이면서도, 사용자가 가장 크게 체감하는 시각적 요소들의 품질을 극적으로 향상시킬 수 있다. 현재 거의 모든 실시간 레이 트레이싱 지원 게임은 이러한 하이브리드 파이프라인을 기반으로 하고 있으며, 이는 두 패러다임이 서로를 대체하는 것이 아니라, 당분간 상호 보완하며 공존할 것임을 시사한다.</p>
<table><thead><tr><th>특징 (Feature)</th><th>래스터라이제이션 (Rasterization)</th><th>레이 트레이싱 (Ray Tracing)</th><th>주요 출처</th></tr></thead><tbody>
<tr><td><strong>핵심 원리</strong></td><td>3D 객체를 2D 픽셀 그리드로 투영 및 변환 (객체 중심)</td><td>카메라에서 광선을 역추적하여 빛의 경로 시뮬레이션 (픽셀/광선 중심)</td><td></td></tr>
<tr><td><strong>주요 강점</strong></td><td>압도적인 속도, 높은 프레임률(FPS), 하드웨어 최적화</td><td>물리적 정확성, 극사실적인 광학 효과(반사, 굴절, 그림자)</td><td></td></tr>
<tr><td><strong>주요 약점</strong></td><td>부정확한 광학 효과(주로 ’꼼수’에 의존), 화면 공간 아티팩트</td><td>막대한 계산 비용, 낮은 프레임률(FPS)</td><td>3</td></tr>
<tr><td><strong>반사 처리</strong></td><td>스크린 스페이스 반사(SSR): 화면 내 정보만 사용, 시야 밖 반사 불가</td><td>물리 기반 반사: 화면 밖 객체 포함, 다중 반사 가능</td><td>3</td></tr>
<tr><td><strong>그림자 처리</strong></td><td>섀도우 맵: 해상도 제약, 부자연스러운 경계(aliasing) 발생 가능</td><td>물리 기반 그림자: 거리에 따라 부드러워지는 사실적인 그림자(soft shadows)</td><td></td></tr>
<tr><td><strong>전역 조명 처리</strong></td><td>주로 사전 계산된 라이트맵(정적) 또는 SSAO(동적, 제한적) 사용</td><td>동적인 간접 조명, 색 번짐(color bleeding) 자연스럽게 시뮬레이션</td><td>3</td></tr>
<tr><td><strong>개발 패러다임</strong></td><td>사실성을 위한 ’영리한 트릭’과 근사치 개발에 집중</td><td>물리 법칙 시뮬레이션에 집중, 개발자의 삶을 편하게 할 수 있음</td><td>10</td></tr>
</tbody></table>
<h2>4.  알고리즘의 핵심: 레이 트레이싱 파이프라인 심층 분석</h2>
<p>레이 트레이싱의 기본 원리는 단순하지만, 이를 실용적인 성능으로 구현하기 위해서는 정교한 알고리즘과 자료구조가 뒷받침되어야 한다. 이 장에서는 레이 트레이싱 파이프라인의 핵심을 이루는 가속 구조, 재귀적 광선 추적, 그리고 패스 트레이싱 알고리즘에 대해 심층적으로 분석한다.</p>
<h3>4.1  가속 구조: BVH (Bounding Volume Hierarchy)의 원리</h3>
<p>레이 트레이싱의 성능을 좌우하는 가장 큰 병목은 광선-객체 교차 테스트(ray-object intersection test)이다. 수백만 개의 삼각형으로 이루어진 복잡한 장면에서, 모든 픽셀에서 출발한 광선이 모든 삼각형과 일일이 교차 테스트를 수행한다면 그 계산량은 천문학적으로 증가한다. 이러한 ‘무차별 대입(brute-force)’ 방식의 시간 복잡도는 광선의 수와 프리미티브(삼각형)의 수에 비례하여 <span class="math math-inline">O(\text{num\_rays} \times \text{num\_primitives})</span>가 되므로, 실시간 렌더링은 불가능하다.</p>
<p>이 문제를 해결하기 위해 도입된 것이 바로 ’가속 구조(Acceleration Structure)’이며, 그 중 가장 널리 사용되는 것이 <strong>BVH(Bounding Volume Hierarchy)</strong> 이다.</p>
<ul>
<li>BVH의 작동 원리:</li>
</ul>
<p>BVH의 핵심 아이디어는 ‘분할과 정복(divide and conquer)’ 전략을 공간 분할에 적용하는 것이다. 장면의 기하학적 객체들을 직접 다루는 대신, 이들을 감싸는 더 단순한 형태의 경계 볼륨(Bounding Volume)을 계층적으로 구성하여 불필요한 교차 테스트를 대폭 줄인다.12</p>
<ol>
<li><strong>계층 구조 생성:</strong> 인접한 객체들을 하나의 그룹으로 묶고, 이 그룹 전체를 감싸는 단순한 경계 볼륨(주로 축 정렬 경계 상자, Axis-Aligned Bounding Box, AABB)을 생성한다.</li>
<li><strong>재귀적 그룹화:</strong> 이렇게 생성된 경계 볼륨들을 다시 더 큰 그룹으로 묶어 더 큰 경계 볼륨으로 감싸는 과정을 재귀적으로 반복한다. 이 과정은 최종적으로 장면의 모든 객체를 포함하는 단 하나의 최상위(root) 경계 볼륨을 갖는 트리(tree) 구조를 형성한다.12</li>
<li><strong>가지치기 (Pruning):</strong> 광선이 특정 노드(경계 볼륨)와 교차하지 않으면, 그 노드가 포함하는 모든 자식 노드 및 객체들은 더 이상 테스트할 필요가 없다. 광선이 그 영역을 지나가지 않는 것이 확실하기 때문이다. 이 ‘가지치기’ 과정을 통해 교차 테스트의 대상이 되는 객체의 수를 기하급수적으로 줄일 수 있다. 잘 구성된 BVH는 교차 테스트의 시간 복잡도를 평균적으로 <span class="math math-inline">O(\log N)</span> (여기서 <span class="math math-inline">N</span>은 객체의 수)까지 낮출 수 있다.</li>
</ol>
<ul>
<li>BVH 구축 (Construction):</li>
</ul>
<p>효율적인 BVH를 만드는 것은 렌더링 성능에 지대한 영향을 미친다. BVH 구축은 주로 ‘하향식(Top-down)’ 방식으로 이루어진다. 전체 장면을 포함하는 루트 노드에서 시작하여, 특정 기준에 따라 객체들을 두 개의 하위 그룹으로 나누고, 각 하위 그룹에 대해 이 과정을 재귀적으로 반복한다.12</p>
<p>이때 어떤 기준으로 객체들을 나눌 것인가 하는 ’분할 전략(Partitioning Strategy)’이 매우 중요하다. 가장 널리 쓰이고 효과적인 전략은 SAH(Surface Area Heuristic) 이다.12 SAH는 단순히 객체를 절반으로 나누는 것이 아니라, 특정 분할로 인해 발생할 예상 렌더링 비용을 모델링하여 비용이 최소화되는 분할 지점을 찾는다. 예상 비용은 ’자식 노드를 순회할 비용’과 ’자식 노드 내의 프리미티브와 교차 테스트를 수행할 비용’의 합으로 계산되며, 이는 각 노드의 표면적에 비례한다고 가정한다.12 이 외에도 객체들의 중심점의 중앙값을 기준으로 나누는 ’중앙점 분할(Middle Point Split)’이나 객체의 수를 동일하게 나누는 ‘균등 분할(Equal Counts Split)’ 같은 더 간단한 전략도 있다.12</p>
<ul>
<li>BVH 순회 (Traversal):</li>
</ul>
<p>광선이 주어지면, BVH 트리의 루트 노드부터 순회를 시작한다. 현재 노드의 경계 볼륨과 광선의 교차를 테스트한다.</p>
<ul>
<li>
<p><strong>교차 시:</strong> 현재 노드가 내부 노드(interior node)이면, 두 자식 노드에 대해 순회를 계속한다. 이때, 광선이 먼저 도달하는 자식 노드를 먼저 방문하는 것이 효율적이다. 현재 노드가 리프 노드(leaf node)이면, 해당 노드에 포함된 실제 프리미티브(삼각형)들과의 교차 테스트를 수행한다.12</p>
</li>
<li>
<p>비교차 시: 광선이 현재 노드의 경계 볼륨과 교차하지 않으면, 해당 서브트리 전체를 무시하고 다음 탐색으로 넘어간다.</p>
</li>
</ul>
<p>이러한 순회 과정은 일반적으로 재귀 호출 대신 스택(stack)을 사용하는 반복적 방식으로 구현하여 효율성을 높인다.12</p>
<h3>4.2  재귀적 광선 추적: 반사와 굴절의 물리</h3>
<p>기본적인 레이 트레이싱은 카메라에서 출발한 1차 광선(Primary Ray)이 가장 먼저 부딪히는 표면을 찾는 데 그친다. 하지만 현실 세계의 풍부한 시각적 효과를 재현하기 위해서는 빛이 표면에서 반사되거나 다른 매질을 통과하며 굴절되는 현상을 모델링해야 한다. 이는 2차 광선(Secondary Rays)을 생성하고, 이를 다시 추적하는 재귀적(recursive) 과정을 통해 이루어진다.</p>
<ul>
<li>반사 (Reflection):</li>
</ul>
<p>광선이 거울이나 광택이 있는 금속과 같은 반사율이 높은 표면에 부딪혔을 때, 빛은 반사의 법칙(Law of Reflection)에 따라 튕겨 나간다. 즉, 입사각과 반사각은 표면 법선(surface normal)에 대해 동일하다.15</p>
<p>수학적으로 반사 광선의 방향 벡터 <span class="math math-inline">\mathbf{r}_{\text{out}}</span>는 입사 광선의 방향 벡터 <span class="math math-inline">\mathbf{r}_{\text{in}}</span>과 표면의 단위 법선 벡터 <span class="math math-inline">\mathbf{n}</span>을 이용하여 다음과 같이 계산할 수 있다 15:<br />
<span class="math math-display">
  \mathbf{r}_{\text{out}} = \mathbf{r}_{\text{in}} - 2(\mathbf{r}_{\text{in}} \cdot \mathbf{n})\mathbf{n}
</span><br />
여기서 <span class="math math-inline">(\mathbf{r}_{\text{in}} \cdot \mathbf{n})</span>은 두 벡터의 내적(dot product)이다. 새로운 반사 광선은 교차점에서부터 <span class="math math-inline">\mathbf{r}_{\text{out}}</span> 방향으로 생성되며, 이 광선을 다시 <code>trace_ray</code> 함수에 입력으로 넣어 재귀적으로 추적한다. 이렇게 반환된 색상 정보는 원래 표면의 색상과 혼합되어 최종 픽셀 색상에 기여한다.15</p>
<ul>
<li>굴절 (Refraction):</li>
</ul>
<p>빛이 공기 중에서 물이나 유리로 들어가는 것처럼, 서로 다른 광학적 밀도를 가진 매질의 경계를 통과할 때 그 진행 방향이 꺾이는 현상을 굴절이라고 한다.15 이 현상은 각 매질의 굴절률(index of refraction, IOR)과 스넬의 법칙(Snell’s Law)에 의해 지배된다 15:<br />
<span class="math math-display">
  \eta_1 \sin\theta_1 = \eta_2 \sin\theta_2
</span><br />
여기서 <span class="math math-inline">\eta_1</span>과 <span class="math math-inline">\eta_2</span>는 각각 입사 매질과 투과 매질의 굴절률이며, <span class="math math-inline">\theta_1</span>과 <span class="math math-inline">\theta_2</span>는 법선과 광선이 이루는 각도이다. 반사와 마찬가지로, 벡터 연산을 통해 굴절 광선의 방향 벡터를 계산할 수 있으며, 이 새로운 광선을 재귀적으로 추적하여 투과된 물체 너머의 색상 정보를 얻어온다.</p>
<ul>
<li>재귀 깊이 (Recursion Depth):</li>
</ul>
<p>이러한 재귀적 추적은 이론적으로 무한히 계속될 수 있다. 예를 들어, 서로 마주보는 두 개의 거울 사이에서는 빛이 끝없이 반사된다.15 실제 렌더링에서 이런 무한 루프를 방지하기 위해, 반드시 ’최대 재귀 깊이(max recursion depth)’를 설정해야 한다.15 광선이 튕길 때마다 깊이 카운트를 1씩 증가시키고, 이 카운트가 미리 정해진 한계(예: 5 또는 10)에 도달하면 더 이상의 2차 광선 생성을 중단하고 재귀를 종료한다.15</p>
<h3>4.3  패스 트레이싱: 렌더링 방정식의 몬테카를로 해법</h3>
<p>재귀적 레이 트레이싱은 거울 같은 완벽한 반사(specular reflection)나 투명한 굴절은 잘 처리하지만, 대부분의 실제 물체 표면에서 일어나는 난반사(diffuse reflection)를 제대로 모델링하지 못한다. 난반사는 빛이 표면에 부딪혀 모든 방향으로 흩어지는 현상으로, 간접 조명(indirect lighting)과 전역 조명(Global Illumination, GI)의 핵심 요소이다. ’패스 트레이싱(Path Tracing)’은 이러한 복잡한 전역 조명을 포함한 렌더링 방정식을 풀기 위한 강력하고 우아한 알고리즘이다.17</p>
<p>기본적인 레이 트레이싱이 결정론적(deterministic) 렌더링이라면, 패스 트레이싱은 확률론적(probabilistic) 렌더링으로의 전환을 의미한다. 이는 ’2차 광선의 저주(curse of the secondary ray)’라 불릴 만한 근본적인 문제, 즉 고려해야 할 빛의 경로가 기하급수적으로 폭발하는 현상을 해결하기 위한 필연적인 선택이다. 난반사 표면의 한 점에서 빛은 반구 위의 모든 방향으로 흩어질 수 있으므로, 가능한 모든 경로를 추적하는 것은 불가능하다.</p>
<ul>
<li>몬테카를로 통합 (Monte Carlo Integration):</li>
</ul>
<p>패스 트레이싱은 이 문제를 몬테카를로 방법(Monte Carlo method)을 이용해 통계적으로 접근한다.5 렌더링 방정식의 해(특정 지점의 색상)를 구하기 위해, 그 해의 기댓값을 추정하는 것이다.</p>
<ol>
<li>광선이 난반사 표면에 부딪히면, 반사될 방향을 하나만 ‘무작위로’ 선택하여 2차 광선을 쏜다.</li>
<li>이 2차 광선이 또 다른 표면에 부딪히면, 다시 무작위 방향으로 3차 광선을 쏜다. 이 과정을 최대 재귀 깊이에 도달할 때까지 반복하여 하나의 완전한 ’경로(path)’를 생성한다.</li>
<li>이 경로를 따라 빛이 어떻게 전달되었는지를 계산하여 이 경로가 픽셀 색상에 기여하는 정도를 구한다.</li>
<li>동일한 픽셀에 대해 이 전체 과정을 수십, 수백 번 반복하여 여러 개의 독립적인 경로 샘플을 만들고, 그 결과들을 평균낸다.</li>
</ol>
<ul>
<li>편향과 분산 (Bias and Variance):</li>
</ul>
<p>대수의 법칙(Law of Large Numbers)에 따라, 샘플의 수(<span class="math math-inline">N</span>)를 무한대로 늘리면 이 평균값은 렌더링 방정식의 실제 해(참값)로 수렴한다. 이러한 특성 때문에 패스 트레이싱은 ‘편향되지 않은(unbiased)’ 렌더링 알고리즘이라고 불린다.18</p>
<p>하지만 실용적인 렌더링 시간 내에는 유한한 수의 샘플만을 사용할 수밖에 없다. 이로 인해 통계적 오차, 즉 ’분산(variance)’이 발생하며, 이것이 최종 이미지에 거칠고 점점이 박힌 듯한 ’노이즈(noise)’로 나타난다. 이 노이즈를 줄이는 가장 간단한 방법은 샘플 수를 늘리는 것이지만, 렌더링 시간은 샘플 수에 정비례하여 증가한다. 노이즈를 절반으로 줄이려면 샘플 수를 네 배로 늘려야 하는 등 수렴 속도가 느리다는 것이 패스 트레이싱의 가장 큰 단점이다.</p>
<ul>
<li>중요도 샘플링 (Importance Sampling):</li>
</ul>
<p>느린 수렴 속도를 개선하기 위해, 단순히 무작위로 방향을 샘플링하는 대신 ‘중요도 샘플링’ 기법이 사용된다. 이는 최종 결과에 더 큰 기여를 할 것으로 예상되는 ‘중요한’ 방향(예: 밝은 광원이 있는 방향, BRDF 값이 높은 방향)으로 샘플을 집중시키는 전략이다.5 각 샘플의 기여도는 그 샘플이 선택될 확률(Probability Density Function, PDF)로 나누어 보정함으로써 편향되지 않은 결과를 유지한다.</p>
<p>결론적으로, 패스 트레이싱의 등장은 렌더링의 패러다임을 ’교차점을 찾는 것’에서 ’중요한 교차점을 효율적으로 찾고 그 결과로 발생하는 통계적 노이즈를 처리하는 것’으로 전환시켰다. 이것이 바로 순수 패스 트레이싱이 오랫동안 오프라인 렌더링의 영역에 머물렀던 이유이며, 실시간 패스 트레이싱이 고성능 하드웨어 가속과 공격적인 디노이징 기술(제6장 참조)과 필연적으로 결합되는 이유이다.</p>
<h2>5.  실시간 구현의 동력: 하드웨어 가속 아키텍처</h2>
<p>레이 트레이싱의 엄청난 계산 요구량을 실시간으로 처리하기 위해서는 범용 컴퓨팅 유닛만으로는 한계가 명확했다. 이 기술의 대중화를 이끈 결정적인 돌파구는 바로 레이 트레이싱의 특정 연산을 전담하여 가속하는 전용 하드웨어의 등장이었다. NVIDIA와 AMD는 각기 다른 철학을 바탕으로 한 하드웨어 가속 아키텍처를 선보이며 실시간 레이 트레이싱 시대를 열었다.</p>
<h3>5.1  NVIDIA RT 코어: 전용 하드웨어의 혁신</h3>
<p>NVIDIA는 2018년 튜링(Turing) GPU 아키텍처를 발표하며 세계 최초로 실시간 레이 트레이싱을 위한 전용 하드웨어 유닛인 **RT 코어(Ray Tracing Core)**를 선보였다. 이는 레이 트레이싱이 더 이상 소프트웨어 에뮬레이션에 의존하지 않고 하드웨어 수준에서 직접 가속될 수 있음을 의미하는 혁신적인 사건이었다.</p>
<ul>
<li>핵심 기능:</li>
</ul>
<p>RT 코어의 설계 목표는 명확하다: 레이 트레이싱 파이프라인에서 가장 계산 비용이 높은 두 가지 핵심 작업을 전담하여 처리하는 것이다.19</p>
<ol>
<li><strong>BVH 순회 (BVH Traversal):</strong> 광선이 BVH(Bounding Volume Hierarchy) 트리의 노드들과 충돌하는지 계층적으로 테스트하는 연산.</li>
<li><strong>광선-삼각형 교차 테스트 (Ray-Triangle Intersection Test):</strong> BVH 순회를 통해 좁혀진 후보군 내의 실제 삼각형과 광선이 교차하는지 최종적으로 판정하는 연산.</li>
</ol>
<ul>
<li>SM과의 관계 및 작동 방식:</li>
</ul>
<p>RT 코어가 없는 이전 세대 GPU에서는 이 두 가지 작업이 모두 스트리밍 멀티프로세서(Streaming Multiprocessor, SM) 내의 범용 CUDA 코어에서 수천 개의 명령어를 실행하며 소프트웨어적으로 처리되어야 했다.19 이는 SM에 엄청난 부담을 주어 다른 셰이딩 작업을 병행할 수 없게 만들었다.</p>
<p>RT 코어는 이 부담을 SM으로부터 완전히 ’오프로드(offload)’한다. SM은 단지 레이 트레이싱이 필요할 때 레이 정보를 담아 RT 코어에 작업을 요청(probe)하기만 하면 된다. 그러면 RT 코어는 독립적으로 BVH 순회와 교차 테스트를 수행하고, 최종적으로 가장 가까운 교차점 정보(hit) 또는 교차점이 없음(miss)이라는 결과를 SM에 반환한다. 작업이 진행되는 동안 SM은 다른 픽셀이나 정점 셰이딩, 또는 범용 컴퓨팅(GPGPU) 작업을 자유롭게 수행할 수 있다. 이러한 비동기적 병렬 처리는 GPU 전체의 효율성과 처리량을 극적으로 향상시킨다.</p>
<p>튜링 아키텍처의 RT 코어는 파스칼 아키텍처의 소프트웨어 기반 레이 트레이싱 대비 10배에 달하는 성능 향상을 보이며, 초당 수십억 개(Giga Rays/Sec)의 광선을 처리할 수 있는 능력을 입증했다.19</p>
<h3>5.2  AMD Ray Accelerator: CU 통합형 하이브리드 접근법</h3>
<p>AMD는 2020년 RDNA 2 아키텍처를 통해 하드웨어 가속 레이 트레이싱을 도입했다. 이들의 접근 방식은 NVIDIA와는 다른 철학을 보여주는데, 바로 **Ray Accelerator(RA)**라는 이름의 가속기를 사용하는 것이다.</p>
<ul>
<li>CU와의 통합:</li>
</ul>
<p>RA는 RT 코어처럼 완전히 독립된 별개의 실리콘 블록이 아니라, 각 컴퓨트 유닛(Compute Unit, CU) 내에 통합된 고정 기능(fixed-function) 하드웨어 유닛이다. CU는 AMD GPU의 기본적인 연산 단위로, 셰이더 코드를 실행하는 스트림 프로세서들을 포함한다. RA는 이 CU 내에서 텍스처 유닛(Texture Mapping Unit, TMU)과 같은 다른 유닛들과 리소스를 공유하며 공존한다.20</p>
<ul>
<li>작동 방식:</li>
</ul>
<p>RA는 셰이더 프로그램의 직접적인 제어를 받으며 작동한다. 셰이더가 레이 트레이싱 명령을 실행하면, RA는 하드웨어적으로 BVH 순회를 위한 광선-상자(Ray-Box) 교차 테스트와 최종적인 광선-삼각형(Ray-Triangle) 교차 테스트를 가속한다. NVIDIA의 RT 코어가 SM으로부터 작업을 완전히 위임받아 자율적으로 처리하는 ’블랙박스’에 가깝다면, AMD의 RA는 셰이더 실행 흐름에 더 긴밀하게 통합되어 각 교차 테스트 단계를 셰이더가 더 세밀하게 제어할 수 있는 구조를 가진다. 이는 더 높은 유연성을 제공할 수 있지만, 반대로 셰이더 스케줄링이 최적화되지 않으면 성능 저하를 유발할 수도 있다.</p>
<h3>5.3  아키텍처 비교 분석</h3>
<p>NVIDIA와 AMD의 서로 다른 아키텍처 접근법은 성능, 유연성, 다이 면적 효율성 등에서 각기 다른 장단점과 트레이드오프를 가진다. 이 두 거대 GPU 기업이 동일한 문제(실시간 레이 트레이싱)를 해결하기 위해 근본적으로 다른 하드웨어 철학을 채택했다는 점은 매우 흥미롭다. 이 차이를 이해하는 것은 특정 워크로드에서 왜 한 아키텍처가 다른 아키텍처보다 더 나은 성능을 보이는지를 설명하는 열쇠가 된다.</p>
<p>NVIDIA의 ‘전용 유닛’ 접근법은 레이 트레이싱 작업 자체에 대해서는 최고의 성능을 발휘하도록 설계되었다. SM에서 작업을 완전히 분리함으로써, SM과 RT 코어는 각자의 작업에만 집중하여 최대의 병렬성을 이끌어낼 수 있다. 이는 복잡한 레이 트레이싱 부하가 걸렸을 때 강력한 성능을 보장한다. 반면, AMD의 ‘통합 가속기’ 접근법은 기존의 CU 구조를 최대한 활용하여 다이 면적을 효율적으로 사용하고, 셰이더 프로그래머에게 더 많은 제어 권한을 부여하려는 시도로 볼 수 있다. RDNA 2 아키텍처에서는 RA가 TMU와 리소스를 공유하는 구조 때문에, 텍스처 샘플링과 레이 트레이싱이 동시에 많이 발생하는 특정 시나리오에서 잠재적인 병목 현상이 지적되기도 했다.20 또한, 초기 세대에서는 순수한 광선-삼각형 교차 처리량(throughput)에서 NVIDIA의 전용 코어가 우위를 보였다.20</p>
<p>결론적으로, 이들의 차이는 ’레이 트레이싱을 위한 별도의 프로세서를 만드는 것’과 ‘기존 프로세서에 레이 트레이싱 가속 명령어를 추가하는 것’ 사이의 철학적 차이로 요약될 수 있다. 전자는 순수 레이 트레이싱 성능에, 후자는 유연성과 효율성에 무게를 둔다. 이러한 경쟁적인 아키텍처 발전은 전체 실시간 레이 트레이싱 생태계의 기술적 진보를 이끄는 중요한 원동력이 되고 있다.</p>
<table><thead><tr><th>특징 (Feature)</th><th>NVIDIA RT 코어 (Turing/Ampere)</th><th>AMD Ray Accelerator (RDNA 2)</th><th>주요 출처</th></tr></thead><tbody>
<tr><td><strong>아키텍처 접근법</strong></td><td>전용(Dedicated) 하드웨어 유닛</td><td>CU에 통합된(Integrated) 고정 기능 가속기</td><td></td></tr>
<tr><td><strong>위치</strong></td><td>SM 외부에 독립적으로 존재</td><td>각 CU(Compute Unit) 내부에 존재</td><td></td></tr>
<tr><td><strong>주요 가속 기능</strong></td><td>BVH 순회, 광선-삼각형 교차 테스트</td><td>광선-상자 교차 테스트, 광선-삼각형 교차 테스트</td><td></td></tr>
<tr><td><strong>셰이더 코어와의 관계</strong></td><td>SM으로부터 작업을 완전히 오프로드하여 비동기적으로 병렬 실행</td><td>CU 내 셰이더 실행과 긴밀하게 연동되어 셰이더의 제어를 받음</td><td>19</td></tr>
<tr><td><strong>상대적 처리량</strong></td><td>광선-삼각형 교차 처리량에 강점 (Ampere에서 2배 향상)</td><td>광선-상자 교차 처리량에 강점, 광선-삼각형 처리량은 상대적으로 낮았음</td><td>20</td></tr>
<tr><td><strong>잠재적 병목</strong></td><td>레이 트레이싱 외 작업에는 활용도 제한</td><td>텍스처 유닛(TMU)과 리소스 공유로 인한 스케줄링 병목 가능성</td><td>20</td></tr>
</tbody></table>
<h3>5.4  모바일 및 통합 GPU의 부상</h3>
<p>하드웨어 가속 레이 트레이싱은 더 이상 고가의 외장 데스크톱 GPU만의 영역이 아니다. 기술의 발전은 이 강력한 렌더링 기법을 스마트폰과 같은 모바일 기기 및 노트북의 통합 GPU로 빠르게 확산시키고 있다.</p>
<p>삼성은 Exynos 2200 AP(Application Processor)에 AMD의 RDNA 2 GPU 아키텍처를 기반으로 한 하드웨어 가속 레이 트레이싱 기능을 탑재하여 모바일 기기에서 실시간 레이 트레이싱의 가능성을 열었다. 또한, 모바일 칩셋 설계의 강자인 Arm은 Immortalis-G715 GPU에서, Imagination Technologies는 IMG CXT GPU에서 각각 하드웨어 레이 트레이싱 지원을 발표했다. Intel 역시 Arc Alchemist 아키텍처를 통해 자사의 통합 및 외장 GPU에 레이 트레이싱 가속 코어를 탑재했다.</p>
<p>이러한 흐름은 매우 중요한 의미를 갖는다. 이는 레이 트레이싱이 하이엔드 게이머나 전문가뿐만 아니라, 수십억 명의 모바일 기기 사용자에게도 제공될 수 있는 보편적인 기술로 나아가고 있음을 보여준다. 비록 모바일 환경의 전력 및 발열 제약으로 인해 데스크톱 수준의 복잡한 효과를 구현하는 데는 한계가 있겠지만, 모바일 게임과 증강현실(AR) 애플리케이션에서 더욱 사실적인 그림자, 반사, 조명 효과를 구현하여 사용자 경험을 한 차원 높일 수 있는 잠재력은 무궁무진하다.</p>
<h2>6.  소프트웨어 생태계: 레이 트레이싱 그래픽스 API</h2>
<p>강력한 하드웨어 가속기가 존재하더라도, 게임 엔진이나 렌더링 애플리케이션과 같은 소프트웨어가 이를 활용할 수 있는 표준화된 방법이 없다면 무용지물이다. 그래픽스 API(Application Programming Interface)는 바로 이 소프트웨어와 하드웨어 사이의 다리 역할을 하며, 개발자가 복잡한 하드웨어의 내부 구조를 직접 다루지 않고도 일관된 방식으로 GPU의 기능을 제어할 수 있게 해준다. 실시간 레이 트레이싱의 등장은 기존 API에 대대적인 확장을 요구했으며, Microsoft의 DirectX와 Khronos 그룹의 Vulkan이 이 변화를 주도하고 있다.</p>
<h3>6.1  Microsoft DirectX Raytracing (DXR)</h3>
<p>DXR은 Microsoft가 Windows 운영체제와 Xbox 콘솔을 위해 개발한 DirectX 12 API의 공식 레이 트레이싱 확장 기능이다. 2018년 Windows 10 업데이트와 함께 출시된 DXR은 PC 게임에서 실시간 레이 트레이싱을 구현하는 사실상의 표준으로 빠르게 자리 잡았다. DXR은 레이 트레이싱을 위한 완전히 새로운 그래픽스 파이프라인을 정의하며, 다음과 같은 핵심 구성 요소들을 도입했다.</p>
<ol>
<li><strong>가속 구조 (Acceleration Structure):</strong> GPU 메모리에 생성되는 BVH 데이터 구조로, 레이 트레이싱 연산을 위해 3D 장면의 지오메트리를 효율적인 형태로 표현한다. DXR은 최상위 가속 구조(Top-Level Acceleration Structure, TLAS)와 하위 가속 구조(Bottom-Level Acceleration Structure, BLAS)의 2단계 계층 구조를 사용한다. BLAS는 개별 메시(mesh)의 삼각형 정보를 담고, TLAS는 이러한 BLAS들의 인스턴스 정보(위치, 변환 등)를 담아 전체 장면을 구성한다.</li>
<li><strong>DispatchRays:</strong> 래스터라이제이션 파이프라인의 <code>Draw</code> 또는 <code>DrawIndexed</code> 호출과 유사한 역할을 하는 커맨드 리스트 함수이다. 이 함수가 호출되면 GPU는 지정된 차원(예: 렌더링할 이미지의 너비와 높이)만큼의 레이 생성 셰이더 스레드를 실행하여 레이 트레이싱 프로세스를 시작한다.</li>
<li><strong>새로운 HLSL 셰이더 타입:</strong> DXR은 레이 트레이싱 파이프라인의 각 단계를 처리하기 위한 새로운 유형의 셰이더들을 도입했다. 이 셰이더들은 <code>TraceRay()</code>라는 내장 함수를 통해 서로 상호작용하며 빛의 경로를 추적한다.</li>
</ol>
<ul>
<li><strong>Ray Generation Shader (레이 생성 셰이더):</strong> 파이프라인의 시작점. 카메라 위치에서 픽셀을 향해 1차 광선을 생성하고 <code>TraceRay()</code>를 호출한다.</li>
<li><strong>Intersection Shader (교차 셰이더):</strong> 삼각형이 아닌 절차적(procedural) 지오메트리나 커스텀 프리미티브와의 교차 테스트 로직을 정의한다.</li>
<li><strong>Any-Hit Shader (애니 히트 셰이더):</strong> 광선이 교차점을 찾을 때마다 호출된다. 주로 알파 테스팅(alpha testing)과 같이, 특정 조건에서 교차를 무시하고 광선이 계속 진행하도록 하는 데 사용된다.</li>
<li><strong>Closest-Hit Shader (최근접 히트 셰이더):</strong> 광선의 경로에서 가장 가까운 교차점이 확정되었을 때 단 한 번 호출된다. 재질의 셰이딩, 그림자 광선 생성, 반사/굴절 광선 생성 등 핵심적인 조명 계산을 수행한다.</li>
<li><strong>Miss Shader (미스 셰이더):</strong> 광선이 어떤 객체와도 교차하지 않았을 때 호출된다. 주로 배경색이나 스카이박스/환경 맵을 샘플링하는 데 사용된다.</li>
</ul>
<ol start="4">
<li><strong>레이 트레이싱 파이프라인 상태 객체 (PSO - Pipeline State Object):</strong> DXR은 새로운 유형의 PSO를 도입했다. 기존의 그래픽스 또는 컴퓨트 PSO와 달리, 레이 트레이싱 PSO는 위에서 언급된 모든 셰이더 코드(DXIL 라이브러리 형태), 각 셰이더와 연관된 루트 시그니처, 그리고 전역 파이프라인 설정(최대 재귀 깊이, 페이로드 크기 등)을 하나의 거대한 상태 객체로 묶는다. 이는 레이 트레이싱 중에는 어떤 셰이더든 호출될 수 있으므로, 모든 셰이더가 항상 GPU에 로드되어 있어야 한다는 특성을 반영한다.</li>
<li><strong>셰이더 테이블 (SBT - Shader Binding Table):</strong> SBT는 DXR 파이프라인에서 매우 중요한 역할을 하는 데이터 구조이다. 이는 GPU 메모리에 상주하며, 가속 구조 내의 특정 지오메트리와 그 지오메트리가 사용해야 할 셰이더(특히 히트 그룹: Intersection, Any-Hit, Closest-Hit 셰이더의 조합)를 연결하는 매핑 테이블 역할을 한다. <code>DispatchRays</code> 호출 시, GPU는 광선이 부딪힌 지오메트리의 ID를 이용해 SBT에서 해당 셰이더의 주소를 찾아 실행한다. 이를 통해 하나의 씬 안에서 객체마다 다른 재질과 셰이더를 효율적으로 적용할 수 있다.</li>
</ol>
<h3>6.2  Khronos Vulkan Ray Tracing</h3>
<p>Vulkan은 OpenGL의 후속으로 개발된 개방형 크로스플랫폼 그래픽스 API이며, 확장 기능(extensions)을 통해 레이 트레이싱을 지원한다. 주요 확장 기능은 <code>VK_KHR_ray_tracing_pipeline</code>, <code>VK_KHR_acceleration_structure</code>, <code>VK_KHR_deferred_host_operations</code> 등이며, 이들은 DXR과 매우 유사한 개념과 구조를 공유한다.</p>
<ul>
<li>DXR과의 유사성 및 기능적 동등성:</li>
</ul>
<p>Vulkan Ray Tracing은 DXR의 핵심 개념 대부분을 그대로 채용했다. 가속 구조(Acceleration Structure), 레이 트레이싱 파이프라인, 그리고 레이 생성, 최근접 히트, 미스 셰이더 등 동일한 종류의 셰이더 스테이지를 정의하고 사용한다.21 레이 트레이싱 작업을 시작하는 커맨드 역시</p>
<p>vkCmdTraceRaysKHR로 DXR의 DispatchRays와 유사한 역할을 한다.</p>
<p>이러한 높은 수준의 유사성은 우연이 아니다. 이는 업계가 하드웨어 가속 레이 트레이싱을 위한 공통된 추상화 모델에 수렴했음을 보여준다. 즉, “하드웨어에 레이 트레이싱을 지시하는 방법“에 대한 일종의 표준적인 ’언어’가 형성된 것이다. 이 덕분에 DXR과 Vulkan Ray Tracing은 기능적으로 거의 동등한 수준(feature parity)에 이르렀고, 이는 Valve의 Proton과 같은 호환성 레이어가 Vulkan을 기반으로 DXR로 만들어진 게임을 Linux와 같은 다른 플랫폼에서 실행할 수 있게 하는 기술적 기반이 된다.</p>
<ul>
<li>드라이버 수준 유효성 검사 (Driver-Level Validation):</li>
</ul>
<p>레이 트레이싱 애플리케이션의 디버깅은 매우 복잡할 수 있다. 이를 돕기 위해 NVIDIA와 같은 하드웨어 벤더는 DXR과 Vulkan 모두를 위한 드라이버 수준의 유효성 검사(validation) 기능을 제공한다. 이는 일반적인 API 디버그 레이어가 잡아내기 힘든 문제들, 예를 들어 비효율적으로 빌드된 가속 구조, NaN(Not a Number) 값을 포함한 잘못된 정점 데이터, 메모리 손상을 유발할 수 있는 특정 API 오용 등을 감지하여 개발자에게 경고를 보낸다. 이러한 도구는 애플리케이션의 안정성과 성능을 향상시키는 데 큰 도움이 된다.</p>
<h3>6.3  API 수준에서의 최적화</h3>
<p>하드웨어와 API가 발전함에 따라, 레이 트레이싱 성능을 더욱 향상시키기 위한 새로운 기능들이 API 수준에서 표준화되고 있다. DXR 1.2와 같은 최신 API 사양에 포함된 대표적인 최적화 기술은 다음과 같다.</p>
<ul>
<li>Opacity Micromaps (OMM):</li>
</ul>
<p>나뭇잎, 머리카락, 철조망과 같이 복잡한 투명/불투명 패턴을 가진 지오메트리는 레이 트레이싱에 큰 부담을 준다. 광선이 바운딩 박스에 부딪히더라도, 실제로는 투명한 부분을 통과하는 경우가 많아 불필요한 Any-Hit 셰이더 호출이 빈번하게 발생하기 때문이다. OMM은 이러한 객체의 불투명도 정보를 2-state(불투명, 투명) 또는 4-state(불투명, 투명, 불확실)의 저해상도 텍스처(마이크로맵)으로 미리 인코딩하는 기술이다.22 BVH 순회 중 하드웨어는 이 마이크로맵을 참조하여 광선이 명백히 투명한 영역을 통과하는 경우, 비용이 많이 드는 셰이더 호출을 완전히 건너뛸 수 있다. 이를 통해 알파 테스트가 많은 장면의 성능을 크게 향상시킬 수 있다.22</p>
<ul>
<li>Shader Execution Reordering (SER):</li>
</ul>
<p>레이 트레이싱 워크로드는 본질적으로 매우 발산적(divergent)이다. 인접한 픽셀에서 출발한 광선이라도 서로 다른 객체에 부딪히거나, 다른 재질의 셰이더를 실행하거나, 다른 경로로 튕겨 나갈 수 있다. GPU는 SIMD(Single Instruction, Multiple Data) 방식으로 작동하기 때문에, 동일한 워프(warp) 또는 웨이브프론트(wavefront) 내의 스레드들이 서로 다른 코드를 실행하면 유휴 상태(idle)의 코어가 발생하여 효율성이 크게 떨어진다.</p>
<p>SER은 이러한 비일관적인(incoherent) 워크로드를 해결하기 위한 기술이다.22 이는 실행 중에 유사한 작업을 수행해야 하는 셰이더 호출들을 동적으로 재정렬하고 그룹화하여, GPU 코어들이 더 일관된 작업을 함께 처리하도록 만든다. 이를 통해 실행 효율성과 메모리 접근의 일관성(coherence)을 높여 전체적인 레이 트레이싱 성능을 향상시킨다.22</p>
<p>이러한 API 수준의 최적화 기능들은 하드웨어, 드라이버, 게임 엔진의 긴밀한 협력을 통해 구현되며, 실시간 레이 트레이싱의 성능 한계를 지속적으로 밀어 올리는 데 중요한 역할을 한다.</p>
<p>제6장: 실시간의 숙명: 디노이징 기술 개론</p>
<h3>6.4 왜 디노이징이 필수적인가?</h3>
<p>실시간 레이 트레이싱, 특히 전역 조명을 위한 패스 트레이싱은 이론적으로 무한한 수의 광선 경로를 샘플링해야 정확한 결과를 얻을 수 있다. 그러나 실시간 애플리케이션은 한 프레임을 수십 분의 일 초(예: 16.6ms for 60 FPS) 안에 렌더링해야 한다는 엄격한 시간 제약을 받는다. 이 때문에 픽셀당 사용할 수 있는 광선의 수(samples-per-pixel, SPP)는 극히 제한적이며, 종종 1 SPP에도 미치지 못하는 경우가 많다.24</p>
<p>이렇게 적은 수의 샘플로 몬테카를로 통합을 수행하면, 그 결과는 필연적으로 높은 분산(variance)을 갖게 된다. 이 통계적 분산이 이미지 상에서는 마치 오래된 필름 사진처럼 자글자글한 ’노이즈(noise)’로 나타난다. 이 노이즈를 그대로 방치하면 이미지는 미학적으로 보기 흉할 뿐만 아니라, 장면의 디테일을 알아보기 어려울 정도로 품질이 저하되어 상업적으로 사용할 수 없는 수준이 된다.</p>
<p>따라서, 고품질의 실시간 레이 트레이싱을 구현하는 것은 효과적인 <strong>디노이징(Denoising)</strong> 기술의 개발과 불가분의 관계에 있다. 디노이징은 제한된 샘플로 생성된 노이즈 가득한 이미지를 입력받아, 노이즈는 제거하면서도 원본 장면의 중요한 기하학적, 재질적 디테일은 최대한 보존하여 깨끗하고 안정적인 최종 이미지를 재구성하는 후처리(post-processing) 기술이다. 이 장에서는 실시간 레이 트레이싱을 위해 개발된 주요 디노이징 기법들을 살펴본다.</p>
<h3>6.5  시공간적 필터링 기법</h3>
<p>초기의 실시간 디노이저들은 주로 이미지 공간(screen-space)에서 작동하는 필터링 기법에 의존했다. 이들의 핵심 아이디어는 현재 프레임의 공간적 정보(이웃 픽셀)와 이전 프레임의 시간적 정보(역사 버퍼)를 함께 활용하여 유효 샘플 수를 인위적으로 늘리는 것이다.</p>
<ul>
<li>SVGF (Spatiotemporal Variance-Guided Filtering):</li>
</ul>
<p>SVGF는 NVIDIA에서 개발하여 Quake 2 RTX와 같은 초기 실시간 패스 트레이싱 데모에 사용된 대표적인 시공간 필터링 기법이다.</p>
<ul>
<li><strong>작동 원리:</strong> SVGF는 여러 단계의 필터링 파이프라인으로 구성된다.</li>
</ul>
<ol>
<li><strong>시간적 누적 (Temporal Accumulation):</strong> 현재 프레임의 픽셀을 이전 프레임의 화면으로 재투영(reproject)한다. 이는 현재 프레임의 깊이(depth)와 모션 벡터(motion vector) 정보를 사용하여, 현재 픽셀이 이전 프레임의 어느 위치에 있었는지를 계산하는 과정이다. 재투영이 성공하면(예: 동일한 표면으로 판단되면), 이전 프레임의 필터링된 색상과 현재 프레임의 노이즈 섞인 색상을 혼합(blend)하여 시간적으로 누적된 결과를 만든다. 이를 통해 유효 SPP를 효과적으로 높인다.</li>
<li><strong>분산 추정 (Variance Estimation):</strong> 시간적 누적 과정에서 색상의 분산을 함께 계산한다. 분산은 해당 픽셀의 조명 정보가 얼마나 안정적인지를 나타내는 척도가 된다.</li>
<li><strong>가이드 필터링 (Guided Filtering):</strong> 분산 맵을 가이드로 사용하여 적응형 공간 필터(일반적으로 여러 번 반복되는 À-Trous 웨이블릿 필터)를 적용한다. 분산이 높은, 즉 노이즈가 심하고 정보가 불안정한 영역은 더 넓은 반경으로 강하게 필터링(블러링)하고, 분산이 낮은, 즉 디테일이 많고 안정적인 영역은 필터링을 약하게 하거나 건너뛰어 디테일 손실을 최소화한다. 이 가이드 필터링에는 노멀(normal)이나 깊이(depth) 정보도 함께 사용되어, 서로 다른 객체의 경계를 넘어 색상이 번지는(bleeding) 현상을 방지한다.</li>
</ol>
<ul>
<li><strong>장단점:</strong> SVGF는 비교적 간단한 원리로 상당한 노이즈 감소 효과를 볼 수 있다. 하지만 시간적 누적에 크게 의존하기 때문에, 움직이는 객체 주변이나 카메라가 빠르게 움직일 때 재투영이 실패하면서 고스팅(ghosting)이나 잔상(trailing)과 같은 아티팩트를 유발하기 쉽다.25 또한 공간 필터링 과정에서 미세한 텍스처 디테일이 뭉개지는 블러링(blurring) 현상이 발생할 수 있다.</li>
</ul>
<h3>6.6  AI 기반 기법</h3>
<p>전통적인 필터링 기법의 한계를 극복하기 위해, 최근 디노이징 기술의 주류는 딥러닝(Deep Learning)을 활용하는 AI 기반 방식으로 빠르게 전환되고 있다. AI 디노이저는 수많은 ’노이즈 이미지’와 ‘정답 이미지(Ground Truth, 수천 SPP로 렌더링된 깨끗한 이미지)’ 쌍을 학습한 신경망을 사용하여, 인간이 설계한 휴리스틱 필터보다 훨씬 더 정교하게 노이즈와 실제 디테일을 구분하고 재구성한다.26</p>
<ul>
<li>NVIDIA Real-time Denoisers (NRD):</li>
</ul>
<p>NVIDIA가 제공하는 API에 구애받지 않는(API-agnostic) 고성능 시공간 디노이저 라이브러리이다.29 개발자들은 이를 자신의 렌더링 파이프라인에 쉽게 통합할 수 있다. NRD는 확산(diffuse) 조명, 반사(specular) 조명, 그림자 등 각기 다른 특성을 가진 신호에 최적화된 여러 종류의 디노이저(예: REBLUR, RELAX, SIGMA)를 포함하고 있다. SVGF와 마찬가지로 G-버퍼와 히스토리 버퍼를 입력으로 사용하며, 특히 낮은 SPP 환경에서 안정적인 결과를 내도록 설계되었다.29</p>
<ul>
<li>Intel Open Image Denoise (OIDN):</li>
</ul>
<p>Intel이 개발한 고품질 오픈 소스 디노이징 라이브러리로, CPU와 GPU(Intel, NVIDIA, AMD 등)를 모두 지원하는 뛰어난 크로스 플랫폼 호환성을 자랑한다.30 OIDN의 핵심은 사전 훈련된 딥러닝 필터로, 노이즈 섞인 컬러 버퍼뿐만 아니라 알베도(albedo)와 노멀(normal) 같은 보조 특징 버퍼(auxiliary feature buffers)를 함께 입력받아 디테일 보존 능력을 극대화한다.30 처음에는 오프라인 렌더링의 베이킹 시간을 단축하는 용도로 주목받았으나, 하드웨어 가속(Intel XMX, NVIDIA Tensor Cores)을 통해 실시간 성능을 확보하면서 그 적용 범위가 넓어지고 있다.</p>
<ul>
<li>NVIDIA OptiX Denoiser:</li>
</ul>
<p>주로 오프라인 및 프로덕션 렌더링을 위해 설계된 AI 디노이저의 선구자 격이다. 재귀적 디노이징 오토인코더(Recurrent Denoising Autoencoder)라는 신경망 구조를 기반으로 하며, 수만 장의 방대한 데이터셋으로 훈련되어 매우 높은 품질의 결과를 제공한다.31 Autodesk Arnold, Blender Cycles 등 많은 상용 렌더러에 통합되어 아티스트의 작업 효율성을 크게 향상시켰다.</p>
<h3>6.7  업스케일링과의 융합</h3>
<p>디노이징 기술의 최신 진화 방향은 AI 기반 업스케일링 기술과의 깊은 융합이다. 디노이징이 ’누락된 샘플 정보’를 복원하는 문제라면, 업스케일링은 ’누락된 픽셀 정보’를 생성하는 문제로, 두 가지 모두 불완전한 정보로부터 완전한 이미지를 재구성한다는 공통점을 가진다.</p>
<ul>
<li>NVIDIA DLSS 3.5 (Ray Reconstruction):</li>
</ul>
<p>DLSS(Deep Learning Super Sampling) 3.5에 도입된 레이 재구성(Ray Reconstruction) 기술은 이러한 융합의 대표적인 사례이다. 이는 기존에 게임 엔진마다 각기 다른 여러 개의 수작업으로 튜닝된 디노이저들을, 더 많은 데이터를 학습한 단일 AI 네트워크로 대체한다.</p>
<p>이 통합 네트워크는 단순히 노이즈 섞인 픽셀뿐만 아니라, 게임 엔진으로부터 직접 받은 모션 벡터, 깊이, 표면 노멀 등 훨씬 더 풍부한 컨텍스트 정보를 활용한다. 이를 통해 AI는 노이즈 패턴과 기하학적 디테일을 더 정확하게 인식하고, 업스케일링 과정에서 저해상도 이미지를 고해상도로 변환하면서 동시에 노이즈를 제거하고 손실된 디테일을 지능적으로 ’재구성’한다. 그 결과, 전통적인 디노이저 + 업스케일러 조합보다 더 선명하고 아티팩트가 적은 고품질 이미지를 생성할 수 있다.32 이러한 흐름은 디노이저가 파이프라인의 끝에 있는 단순한 후처리 필터에서, 렌더링 파이프라인 전체와 상호작용하는 지능적인 ’재구성’의 핵심으로 진화하고 있음을 보여준다.</p>
<h3>6.8  주요 시각적 아티팩트 분석</h3>
<p>디노이징 기술은 필연적으로 완벽하지 않으며, 특정 상황에서 다양한 시각적 오류, 즉 아티팩트(artifact)를 발생시킬 수 있다. 이러한 아티팩트의 종류와 원인을 이해하는 것은 디노이저의 품질을 평가하고 개선하는 데 중요하다.</p>
<ul>
<li><strong>고스팅/잔상 (Ghosting/Trailing):</strong> 주로 시공간적 재사용 기법에서 발생하는 가장 흔한 아티팩트다. 빠르게 움직이는 객체나 카메라의 움직임으로 인해 이전 프레임의 정보가 현재 프레임에 유령처럼 남아 잔상을 만드는 현상이다. 이는 부정확한 모션 벡터나 재투영 실패로 인해 발생한다.</li>
<li><strong>블러링 (Blurring):</strong> 공간 필터링이 과도하게 적용될 때 발생한다. 디노이저가 고주파의 미세한 텍스처 디테일과 노이즈를 구분하지 못하고 함께 뭉개버려 이미지가 흐릿해지는 현상이다.26</li>
<li><strong>얼룩/반점 (Splotches/Blotches):</strong> 샘플 수가 매우 적은 영역, 특히 간접 조명이 복잡한 구석이나 그림자 영역에서 발생한다. 부족한 조명 정보를 보충하기 위해 주변 픽셀의 정보를 과도하게 가져오면서 물감이 번진 듯한 얼룩덜룩한 패턴이 생긴다.33</li>
<li><strong>디테일 소실 (Loss of Detail):</strong> 디노이저가 얇은 선, 작은 하이라이트, 미세한 그림자 등 작지만 중요한 시각적 요소를 노이즈로 오인하여 제거할 때 발생한다.</li>
<li><strong>불안정성/깜빡임 (Instability/Flickering):</strong> 프레임 간 디노이징 결과가 일관되지 않아, 정적인 장면임에도 불구하고 표면의 밝기나 색상이 미세하게 떨리거나 깜빡이는 현상이다. 시간적 안정성(temporal stability)은 디노이저의 핵심 품질 척도 중 하나이다.26</li>
</ul>
<table><thead><tr><th>기술 (Technique)</th><th>핵심 원리</th><th>주요 입력</th><th>강점</th><th>약점</th><th>주요 아티팩트</th><th>주요 출처</th></tr></thead><tbody>
<tr><td><strong>SVGF</strong></td><td>시공간적 분산 가이드 필터링</td><td>노이즈 이미지, G-Buffer(깊이, 노멀, 모션 벡터), 히스토리 버퍼</td><td>비교적 저렴한 비용으로 효과적인 노이즈 제거, 구현 용이</td><td>움직임에 취약, 디테일 보존력 한계</td><td>고스팅, 블러링</td><td></td></tr>
<tr><td><strong>NRD</strong></td><td>AI 기반 시공간적 필터링 (라이브러리)</td><td>노이즈 이미지, G-Buffer, 히스토리 버퍼</td><td>높은 성능, 다양한 신호(확산/반사)에 최적화된 디노이저 제공</td><td>NVIDIA 하드웨어에 최적화, 폐쇄 소스</td><td>고스팅, 블러링 (SVGF보다 개선됨)</td><td>29</td></tr>
<tr><td><strong>Intel OIDN</strong></td><td>AI 기반 딥러닝 필터 (오픈 소스)</td><td>노이즈 이미지, 보조 버퍼(알베도, 노멀)</td><td>뛰어난 디테일 보존력, 크로스 플랫폼(CPU/GPU) 지원</td><td>NRD/DLSS 대비 실시간 성능이 낮을 수 있음, 시간적 정보 미활용(구버전)</td><td>블러링, 반점</td><td>30</td></tr>
<tr><td><strong>DLSS Ray Reconstruction</strong></td><td>AI 기반 업스케일링 및 디노이징 통합</td><td>저해상도 노이즈 이미지, G-Buffer, 엔진 데이터 등 방대한 정보</td><td>뛰어난 디테일 재구성 및 아티팩트 억제, 성능 향상 효과 극대화</td><td>NVIDIA RTX GPU 및 DLSS 지원 게임에서만 사용 가능</td><td>고스팅(Frame Generation과 결합 시)</td><td></td></tr>
</tbody></table>
<h2>7.  실제 산업 적용 사례 분석</h2>
<p>레이 트레이싱 기술은 더 이상 이론이나 연구실의 영역에 머물러 있지 않다. 영화, 게임, 건축, 디자인 등 다양한 산업 분야에서 시각적 결과물의 품질을 혁신하고 작업 워크플로우를 변화시키는 핵심 동력으로 자리 잡았다. 각 산업은 고유의 요구사항과 제약 조건(실시간성, 최종 품질, 비용 등)을 가지고 있으며, 이에 따라 레이 트레이싱 기술을 각기 다른 방식으로 활용하고 있다. 이러한 사례들을 분석하는 것은 기술의 현재 위치와 실용적 가치를 이해하는 데 매우 중요하다.</p>
<h3>7.1  영화 산업: Weta Digital의 Manuka와 <em>아바타: 물의 길</em></h3>
<p>영화 및 시각 효과(VFX) 산업은 컴퓨터 그래픽스의 사실성을 극한까지 끌어올려야 하는 분야로, 수십 년 전부터 레이 트레이싱과 패스 트레이싱을 프로덕션 파이프라인의 핵심으로 사용해왔다.9 그러나 프레임 하나를 렌더링하는 데 수 시간에서 수 일이 소요되는 막대한 계산 비용은 제작 기간과 비용을 증가시키는 주된 요인이었다.34 이 분야의 선두주자인 Weta Digital(현 Weta FX)은 이러한 도전을 극복하고 예술적 비전을 실현하기 위해 자체적인 렌더링 기술을 개발해왔다.</p>
<ul>
<li>Weta Digital의 Manuka 렌더러:</li>
</ul>
<p>Manuka는 Weta가 자체 개발한 고성능 물리 기반 프로덕션 렌더러로, 몬테카를로 패스 트레이싱 알고리즘에 깊이 뿌리를 두고 있다.35 Manuka는 단순히 빛의 경로를 추적하는 것을 넘어, 빛의 물리적 특성을 더욱 근본적으로 시뮬레이션하기 위한 혁신적인 기술들을 탑재했다.</p>
<ul>
<li>
<p><strong>양방향 패스 트레이싱(Bidirectional Path Tracing):</strong> 카메라에서 출발하는 경로와 광원에서 출발하는 경로를 모두 추적하고 연결하여, 코스틱스(caustics)나 간접 조명이 복잡한 장면에서 노이즈를 훨씬 효율적으로 줄인다.35</p>
</li>
<li>
<p><strong>스펙트럴 렌더링(Spectral Rendering) &amp; Hero Spectral Sampling:</strong> Manuka의 가장 큰 기술적 특징 중 하나는 빛을 단순히 R, G, B 세 채널로 계산하는 것이 아니라, 가시광선 전체의 파장 분포, 즉 스펙트럼(spectrum)으로 처리한다는 것이다.36 이는 특히 피부와 같이 빛의 파장에 따라 흡수 및 산란 특성이 크게 달라지는 복잡한 재질을 매우 정확하게 렌더링하는 데 결정적이다. ’Hero Spectral Sampling’은 이 스펙트럼 계산을 다중 중요도 샘플링(MIS)과 결합하여 효율적으로 수행하는 Weta의 독자적인 기술이다.36</p>
</li>
<li>
<p>아바타: 물의 길 (Avatar: The Way of Water):</p>
</li>
</ul>
<p>제임스 카메론 감독의 이 영화는 Weta FX 역사상 가장 거대한 규모의 VFX 프로젝트였다. 영화의 3,289개 최종 샷 중 3,240개를 Weta가 담당했으며, 그중 2,225개가 물과 관련된 장면이었다. 이 영화의 경이로운 시각 효과는 Manuka 렌더러의 기술력이 집약된 결과물이다.</p>
<ul>
<li><strong>물과 빛의 상호작용:</strong> 영화의 제목처럼, 물은 가장 중요한 시각 요소였다. Weta는 새로운 물 시뮬레이션 툴셋을 개발하여, 물 표면의 얇은 막, 물보라, 물방울, 그리고 거대한 물의 볼륨이 캐릭터의 피부, 머리카락, 의상과 상호작용하는 복잡한 현상을 사실적으로 구현했다. Manuka의 패스 트레이싱 엔진은 이렇게 시뮬레이션된 물을 통과하고 굴절하며 산란하는 빛을 물리적으로 정확하게 계산하여, 실제보다 더 실제 같은 수중 장면을 만들어냈다.</li>
<li><strong>감성적 캐릭터 표현:</strong> 새로운 얼굴 성능 캡처 시스템은 배우의 얼굴 근육 움직임과 피부의 미세한 떨림을 분리하여 캡처하고, 이를 통해 Na’vi 캐릭터들의 감정을 더욱 섬세하고 사실적으로 표현할 수 있었다. Manuka의 스펙트럴 렌더링은 이러한 디지털 캐릭터의 피부 질감을 극도로 사실적으로 렌더링하여, 관객들이 CG 캐릭터에 깊이 몰입할 수 있도록 하는 데 핵심적인 역할을 했다.</li>
</ul>
<p>이처럼 영화 산업에서 레이 트레이싱은 단순히 ’사실적인 그림’을 넘어, ’감정을 전달하는 사실적인 캐릭터’와 ’스토리를 뒷받침하는 사실적인 환경’을 창조하는 핵심 기술로 활용되고 있다.</p>
<h3>7.2  게임 산업 (1): <em>사이버펑크 2077</em>의 다각적 RT 효과와 패스 트레이싱</h3>
<p><em>사이버펑크 2077</em>은 실시간 레이 트레이싱 기술이 게임 환경을 얼마나 극적으로 변화시킬 수 있는지를 보여준 대표적인 사례다. 이 게임은 단일 기술이 아닌, 여러 레이 트레이싱 효과를 조합한 하이브리드 렌더링의 집약체로, 플레이어의 하드웨어 사양에 따라 다양한 수준의 사실성을 제공한다.</p>
<ul>
<li>
<p><strong>구현된 하이브리드 RT 효과:</strong></p>
</li>
<li>
<p><strong>RT 확산 조명 및 전역 조명:</strong> 나이트 시티의 상징인 수많은 네온사인과 광고판이 발광체(emissive source) 역할을 하여 주변 건물과 도로에 사실적인 색 번짐(color bleeding) 효과를 만들어낸다. 하늘 역시 거대한 영역 광원으로 취급되어, 그림자 속 영역에 부드러운 간접 조명을 제공한다. 최상위 ‘Psycho’ 설정에서는 여러 번 튕기는 다중 바운스(multi-bounce) 전역 조명을 시뮬레이션하여 깊이감을 더한다.37</p>
</li>
<li>
<p><strong>RT 반사:</strong> 물웅덩이, 젖은 도로, 유리창 등에 주변 환경이 물리적으로 정확하게 반사된다. 이는 화면에 보이는 정보만 사용하는 스크린 스페이스 반사(SSR)의 한계를 극복하고, 시야 밖의 건물이나 움직이는 차량까지도 사실적으로 비춘다. 다만, 기술적 한계 또는 최적화 문제로 플레이어 캐릭터 ’V’는 반사되지 않는다는 단점이 있다.</p>
</li>
<li>
<p><strong>RT 그림자:</strong> 태양과 달빛에 의해 생성되는 그림자를 레이 트레이싱으로 처리하여, 그림자를 드리우는 물체(caster)와의 거리에 따라 그림자 경계가 자연스럽게 부드러워지는(softening) 효과를 구현한다.37</p>
</li>
<li>
<p><strong>RT 앰비언트 오클루전:</strong> 물체가 서로 맞닿거나 구석진 곳에 생기는 미세한 접촉 그림자를 정확하게 계산하여, 물체들이 장면에 더 잘 녹아들고 입체감이 살도록 한다. 예를 들어, 차량 아래의 어두운 영역이 훨씬 더 사실적으로 표현된다.37</p>
</li>
<li>
<p>RT 오버드라이브 모드 (Path Tracing):</p>
</li>
</ul>
<p>CD Projekt Red는 여기서 한 걸음 더 나아가, ’RT: 오버드라이브 모드’라는 이름으로 완전한 실시간 패스 트레이싱을 게임에 도입했다. 이는 기존의 하이브리드 방식처럼 특정 효과만 레이 트레이싱으로 처리하는 것이 아니라, 장면의 모든 조명을 패스 트레이싱으로 계산하는 것이다.</p>
<ul>
<li>이 모드에서는 빛의 다중 바운스가 기본적으로 시뮬레이션되므로, 여러 조명 효과들이 서로 유기적으로 상호작용하며 훨씬 더 물리적으로 일관되고 통합된 이미지를 만들어낸다.</li>
<li>이러한 막대한 계산량은 NVIDIA RTX 40 시리즈와 같은 최신 GPU의 강력한 레이 트레이싱 성능과, DLSS 3의 프레임 생성(Frame Generation) 및 Shader Execution Reordering(SER)과 같은 AI 기반 최적화 기술이 결합되었기에 비로소 실시간으로 구현 가능해졌다. <em>사이버펑크 2077</em>의 사례는 게임 그래픽스가 점차 오프라인 렌더링의 품질에 근접하고 있음을 보여주는 중요한 이정표다.</li>
</ul>
<h3>7.3  게임 산업 (2): Unreal Engine 5 Lumen의 하이브리드 트레이싱</h3>
<p>에픽게임즈의 언리얼 엔진 5(UE5)에 탑재된 <strong>Lumen</strong>은 차세대 게임을 위한 동적 전역 조명 및 반사 시스템으로, 레이 트레이싱 기술을 게임 엔진의 핵심 기능으로 통합한 대표적인 사례다. Lumen의 가장 큰 특징은 단일한 방식에 의존하지 않고, 다양한 하드웨어와 씬의 특성에 맞춰 여러 트레이싱 기법을 지능적으로 조합하는 정교한 하이브리드 파이프라인을 갖추고 있다는 점이다.</p>
<ul>
<li><strong>Lumen의 다단계 트레이싱 접근법:</strong></li>
</ul>
<ol>
<li><strong>스크린 트레이스 (Screen Traces):</strong> 가장 먼저, 가장 저렴한 비용으로 화면 내의 깊이 버퍼를 상대로 레이를 추적한다. 이는 화면에 이미 렌더링된 정보를 최대한 활용하여 빠르고 정확한 단거리 간접 조명과 반사를 구현한다.38</li>
<li><strong>소프트웨어 레이 트레이싱 (Software Ray Tracing):</strong> 스크린 트레이스에 실패한 경우(예: 화면 밖으로 나가는 레이), Lumen은 **메시 디스턴스 필드(Mesh Distance Fields)**를 사용하여 소프트웨어 방식으로 레이를 추적한다. 메시 디스턴스 필드는 각 메시의 표면으로부터의 거리를 저장한 볼류메트릭 텍스처로, 실제 삼각형 메시 대신 이 간략화된 표현에 대해 레이를 추적하여 속도를 높인다. 이 방식 덕분에 전용 RT 하드웨어가 없는 구형 GPU에서도 Lumen을 사용할 수 있다.</li>
<li><strong>하드웨어 레이 트레이싱 (Hardware Ray Tracing):</strong> RTX나 Radeon RX 6000 시리즈 이상과 같이 지원되는 하드웨어가 있는 경우, Lumen은 하드웨어 가속을 활용하여 실제 삼각형 메시에 대해 직접 레이를 추적한다. 이는 가장 정확하고 높은 품질의 결과를 제공하며, 특히 날카로운 반사나 복잡한 지오메트리에서 강점을 보인다.38</li>
</ol>
<ul>
<li>서피스 캐시 (Surface Cache):</li>
</ul>
<p>Lumen의 또 다른 핵심 최적화 기법은 ’서피스 캐시’이다. 레이가 어떤 표면에 부딪혔을 때, 매번 복잡한 재질 셰이더를 실행하는 것은 매우 비용이 크다. 대신 Lumen은 씬 표면의 재질과 조명 정보를 ’카드(card)’라고 불리는 저해상도의 파라미터화된 표현으로 미리 캡처하여 캐시에 저장해 둔다.38 레이가 부딪히면 이 캐시를 빠르게 조회하여 조명 값을 가져온다. 이는 씬의 단순화된 버전이지만, 실시간 동적 GI를 가능하게 하는 핵심적인 최적화이다. 다만, 이 캐시의 해상도 한계 때문에 거울처럼 선명한 반사에는 품질 저하가 발생할 수 있으며, 이 경우 하드웨어 레이 트레이싱의 ‘Hit Lighting’ 모드를 사용하여 보완한다.</p>
<p>Lumen은 이처럼 다양한 기술을 유기적으로 결합하여, 넓은 범위의 하드웨어에서 확장 가능한(scalable) 고품질 동적 전역 조명을 제공함으로써 차세대 게임 개발의 기준을 제시하고 있다.</p>
<h3>7.4  건축 및 디자인: V-Ray, Corona, Enscape 비교</h3>
<p>건축, 제품 디자인, 인테리어 시각화(Archviz) 분야에서 레이 트레이싱은 최종 결과물의 품질을 결정하는 핵심 기술이다. 이 분야에서는 크게 두 가지 상반된 요구가 공존한다: 디자인 과정에서의 빠른 피드백을 위한 <strong>실시간 시각화</strong>와, 클라이언트에게 최종 결과물을 제시하기 위한 <strong>극사실적(photorealistic) 렌더링</strong>. 이러한 요구에 맞춰 시장은 각기 다른 강점을 가진 렌더링 솔루션들로 분화되었다.</p>
<ul>
<li>Enscape:</li>
</ul>
<p>실시간 상호작용에 특화된 렌더러. Enscape의 가장 큰 특징은 Revit, SketchUp, Rhino와 같은 주요 CAD/BIM 소프트웨어에 플러그인 형태로 직접 통합되어, 디자이너가 작업하는 동안 실시간으로 레이 트레이싱된 뷰를 제공한다는 점이다. 디자인을 변경하면 렌더링 뷰에 즉시 반영되므로, 디자인 검토, 재질 선택, 조명 테스트 등의 과정을 매우 직관적이고 빠르게 진행할 수 있다. 사용법이 매우 쉬워 초보자도 쉽게 접근할 수 있으며, 디자인 초기 단계의 의사소통과 프레젠테이션에 매우 강력하다. 그러나 속도와 상호작용을 우선시하기 때문에, 최종 결과물의 사실성은 V-Ray나 Corona와 같은 전문 렌더러에는 미치지 못한다.</p>
<ul>
<li>V-Ray:</li>
</ul>
<p>품질과 제어의 업계 표준. V-Ray는 수십 년간 영화 VFX부터 건축 시각화에 이르기까지 폭넓게 사용되어 온 강력한 오프라인 렌더러이다. 레이 트레이싱과 전역 조명 기술을 기반으로 최고의 포토리얼리즘을 구현하며, 사용자가 조명, 재질, 카메라 등 렌더링의 거의 모든 요소를 세밀하게 제어할 수 있는 방대한 옵션을 제공한다. 최신 버전은 NVIDIA RTX GPU 가속을 지원하여 렌더링 속도를 크게 향상시켰다. 최고의 품질과 유연성을 제공하지만, 그만큼 배우기 어렵고 복잡하며, 한 장의 이미지를 렌더링하는 데 긴 시간이 소요될 수 있다는 단점이 있다.</p>
<ul>
<li>Corona:</li>
</ul>
<p>사용자 친화적인 포토리얼리즘. Corona는 V-Ray와 마찬가지로 고품질의 사실적인 이미지를 목표로 하지만, ’사용 편의성’에 훨씬 더 중점을 둔 렌더러이다. 복잡한 설정 없이도 빠르고 직관적으로 훌륭한 결과를 얻을 수 있어, 특히 건축 시각화 아티스트들 사이에서 큰 인기를 얻고 있다. 렌더링이 끝난 후에도 각 광원의 밝기와 색상을 실시간으로 조절할 수 있는 ‘LightMix’ 기능은 Corona의 상징적인 장점이다. 현재는 CPU 기반 렌더링만 지원하며, V-Ray만큼 다양한 기능이나 소프트웨어 통합을 제공하지는 않지만, 특정 워크플로우에서는 훨씬 더 효율적일 수 있다.</p>
<p>이 세 가지 솔루션의 존재는 건축/디자인 분야의 워크플로우가 어떻게 분화되었는지를 명확히 보여준다. 많은 스튜디오에서는 디자인 초기 및 중간 단계에서는 Enscape를 사용하여 빠르게 아이디어를 탐색하고 고객과 소통하고, 최종 디자인이 확정되면 V-Ray나 Corona로 전환하여 마케팅과 최종 납품을 위한 최고 품질의 이미지를 제작하는 하이브리드 워크플로우를 채택하고 있다. 이는 ’레이 트레이싱’이라는 단일 기술이 사용자의 목적과 작업 단계에 따라 ’실시간 미리보기’부터 ’최종 예술 작품’에 이르기까지 넓은 스펙트럼에 걸쳐 다양하게 활용되고 있음을 보여준다.</p>
<h2>8.  새로운 지평: 신경망 렌더링과 그래픽스의 미래</h2>
<p>레이 트레이싱이 실시간 그래픽스의 현재를 정의하고 있다면, 그 미래는 인공지능(AI), 특히 신경망(Neural Network)과의 융합을 통해 그려지고 있다. 신경망 렌더링(Neural Rendering)은 기존의 그래픽스 파이프라인을 보완하거나 심지어 대체할 잠재력을 가진 혁신적인 분야로, 렌더링의 패러다임을 ’계산(computation)’에서 ’학습(learning)’과 ’생성(generation)’으로 전환시키고 있다.</p>
<h3>8.1  NeRF (Neural Radiance Fields): 씬의 암시적 표현</h3>
<p>NeRF는 신경망 렌더링 분야에서 가장 주목받는 기술 중 하나로, 3D 장면을 표현하는 방식을 근본적으로 바꾼다.</p>
<ul>
<li>핵심 원리:</li>
</ul>
<p>전통적인 그래픽스는 삼각형 메시(mesh), 텍스처, 복셀(voxel) 등 명시적인(explicit) 데이터로 장면을 표현한다. 반면, NeRF는 단순한 다층 퍼셉트론(MLP)이라는 신경망의 학습된 가중치(weights)를 사용하여 3D 장면 전체를 ’암시적(implicit)’으로 표현한다.39</p>
<p>이 MLP는 5차원 좌표, 즉 3D 공간상의 위치 <span class="math math-inline">(x, y, z)</span>와 2D 시야 방향 <span class="math math-inline">(\theta, \phi)</span>을 입력으로 받는다. 그러면 네트워크는 해당 위치에서 해당 방향으로 바라봤을 때의 미분 가능한 볼륨 밀도(volume density, <span class="math math-inline">\sigma</span>)와 색상(color, <span class="math math-inline">c</span>)을 출력한다.40 즉, 신경망 자체가 장면의 모든 지점에서의 빛과 물질의 상호작용을 나타내는 연속적인 함수가 되는 것이다.</p>
<ul>
<li>뷰 합성 (View Synthesis):</li>
</ul>
<p>NeRF는 여러 각도에서 촬영된 2D 이미지 세트와 해당 이미지들의 카메라 위치/방향 정보만으로 훈련된다. 훈련 과정에서 네트워크는 렌더링된 이미지와 실제 이미지 간의 차이를 최소화하도록 가중치를 조정한다. 훈련이 완료되면, **볼류메트릭 렌더링(Volumetric Rendering)**이라는 기법을 사용하여 이전에 본 적 없는 새로운 시점에서도 매우 사실적인 이미지를 생성(합성)할 수 있다.40 이는 마치 수십 장의 사진만으로 그 공간을 자유롭게 돌아다니며 볼 수 있는 3D 모델을 만드는 것과 같다.</p>
<ul>
<li>잠재력과 한계:</li>
</ul>
<p>NeRF는 복잡한 기하학적 구조와 뷰에 따라 달라지는 반사 효과를 놀라울 정도로 잘 포착하여, 가상현실(VR), 증강현실(AR), 3D 모델 생성, 시뮬레이션 등 다양한 분야에서 혁신을 일으킬 잠재력을 가지고 있다. 하지만 초기 NeRF는 훈련과 렌더링 속도가 매우 느리고, 정적인 장면에만 적용 가능하다는 한계가 있었다. 현재는 Instant-NGP, Zip-NeRF 등 훈련 및 렌더링 속도를 실시간에 가깝게 끌어올리고 동적인 장면까지 다루려는 연구가 활발히 진행 중이다.39</p>
<h3>8.2  ReSTIR (Reservoir-based Spatiotemporal Importance Resampling)</h3>
<p>ReSTIR는 수백만 개의 동적인 광원이 존재하는 극도로 복잡한 조명 환경을 실시간으로 렌더링하기 위해 NVIDIA에서 개발한 혁신적인 샘플링 알고리즘이다. 이는 직접 조명(Direct Illumination) 렌더링의 품질과 성능을 극적으로 향상시킨다.</p>
<ul>
<li>핵심 아이디어:</li>
</ul>
<p>수많은 광원 중 실제로 특정 픽셀에 큰 영향을 미치는 ‘중요한’ 광원은 소수에 불과하다는 관찰에서 시작한다. ReSTIR의 목표는 이 중요한 광원들을 매우 효율적으로 찾아내는 것이다. 이를 위해 각 픽셀마다 **‘저수지(Reservoir)’**라는 작은 데이터 구조를 유지한다. 이 저수지에는 단 하나의 ‘최고의’ 광원 샘플 후보와 그 샘플의 중요도에 대한 통계 정보가 저장된다.</p>
<ul>
<li>작동 방식:</li>
</ul>
<p>ReSTIR는 두 가지 핵심 샘플링 기법을 연쇄적으로 결합한다.42</p>
<ol>
<li>
<p><strong>초기 후보 생성:</strong> 먼저, 각 픽셀에 대해 소수의 광원 샘플(예: 1~16개)을 무작위로 생성하고, 이들 중 가장 좋은 하나를 저수지에 저장한다.</p>
</li>
<li>
<p>시공간적 재샘플링 (Spatiotemporal Resampling): 그 다음, 이전 프레임의 동일한 위치 픽셀(시간적 이웃)과 현재 프레임의 주변 픽셀(공간적 이웃)들의 저수지를 가져온다. 현재 픽셀의 저수지와 이웃들의 저수지를 놓고, 이들 중에서 다시 한번 최고의 샘플을 확률적으로 ’재샘플링(resample)’하여 현재 픽셀의 저수지를 업데이트한다.</p>
</li>
</ol>
<p>이 과정을 통해, 단 몇 개의 초기 샘플만으로 시작했음에도 불구하고, 주변 시공간의 수많은 샘플 정보를 효과적으로 활용하여 마치 수천 개의 샘플을 테스트한 것과 유사한 고품질의 결과를 얻을 수 있다. 이 알고리즘은 Resampled Importance Sampling (RIS)과 Weighted Reservoir Sampling (WRS)이라는 통계적 기법에 기반하며, NVIDIA의 RTXDI(RTX Direct Illumination) 및 RTXGI(RTX Global Illumination) 기술의 핵심적인 기반이 된다.29</p>
<h3>8.3  NVIDIA RTX Kit: 신경망 렌더링 파이프라인의 청사진</h3>
<p>NVIDIA는 자사의 레이 트레이싱 및 AI 기술들을 **‘RTX Kit’**라는 이름의 소프트웨어 개발 키트(SDK) 모음으로 통합하여, 개발자들이 차세대 신경망 렌더링 파이프라인을 구축할 수 있도록 지원하고 있다.22 이는 그래픽스 파이프라인의 다양한 단계에 AI가 어떻게 깊숙이 통합될 수 있는지를 보여주는 청사진과 같다.</p>
<ul>
<li><strong>신경망 셰이더 (Neural Shaders):</strong> 기존의 HLSL/GLSL 셰이더 코드 내에서 직접 작은 신경망을 추론(inference)할 수 있게 하는 기술이다. 이를 통해 영화 품질의 복잡한 재질을 실시간으로 근사하거나, 셰이더 코드를 압축하는 등 이전에는 불가능했던 작업들을 수행할 수 있다.22 Microsoft는 DirectX에 Cooperative Vectors라는 이름으로 Tensor Core를 직접 활용할 수 있는 기능을 추가하여 이를 지원할 예정이다.43</li>
<li><strong>신경망 텍스처 압축 (Neural Texture Compression):</strong> AI를 사용하여 텍스처 데이터를 신경망 표현으로 압축한다. 이는 기존의 블록 압축(BC) 방식보다 훨씬 높은 압축률과 품질을 제공하여, VRAM 사용량을 획기적으로 줄일 수 있다.22</li>
<li><strong>RTX Mega Geometry &amp; Character Rendering:</strong> BVH 빌드 과정을 지능적으로 가속하여 수억 개의 삼각형으로 이루어진 방대한 지오메트리를 실시간으로 레이 트레이싱할 수 있게 하고(Mega Geometry), 사실적인 피부(Subsurface Scattering)와 경로 추적 기반의 머리카락(Strand-based path tracing) 렌더링을 위한 특화된 알고리즘을 제공한다.22</li>
</ul>
<h3>8.4  완전한 신경망 렌더링을 향하여</h3>
<p>레이 트레이싱이 오랫동안 그래픽스의 ’최종 목표’로 여겨졌지만, 이제는 그 자체가 더 큰 패러다임 전환을 위한 중요한 ’디딤돌’일 수 있다는 관점이 부상하고 있다. 그 최종 목표는 바로 **‘완전한 신경망 렌더링(Full Neural Rendering)’**이다.</p>
<p>이 개념의 핵심은 기존의 래스터라이제이션이나 레이 트레이싱과 같은 명시적인 계산 파이프라인을 AI가 생성하는 이미지로 대체하는 것이다. NVIDIA의 한 연구 부사장은 “먼 미래의 DLSS 10은 완전히 신경망으로 이루어진 렌더링 시스템이 될 것“이라고 예측했다. 이러한 시스템에서 AI는 단순히 노이즈를 제거하거나 해상도를 높이는 보조적인 역할을 넘어, 장면의 기하학적, 재질적 정보 등 최소한의 입력을 받아 빛의 물리 법칙을 내재적으로 이해하고 최종 이미지를 직접 ’생성’하게 된다.</p>
<p>이러한 비전이 실현되기 위해서는 AI 모델을 훈련시킬 방대한 양의 고품질 데이터가 필요하다. 여기서 레이 트레이싱, 특히 물리적으로 정확한 오프라인 패스 트레이싱이 결정적인 역할을 한다. 패스 트레이싱으로 생성된 ‘정답’ 이미지는 AI에게 빛이 현실 세계에서 어떻게 작동하는지를 가르치는 최고의 교과서가 된다.5 DLSS의 레이 재구성 기술이 슈퍼컴퓨터로 렌더링된 패스 트레이싱 이미지로 훈련되는 것이 그 대표적인 예다.32</p>
<p>결론적으로, 현재 업계가 실시간 레이 트레이싱 기술에 막대한 투자를 하는 이유는 단지 당장의 게임 그래픽을 향상시키기 위함만은 아니다. 이는 차세대 생성형 그래픽스 모델을 훈련시키기 위한, 물리 기반의 고품질 데이터를 대량으로 생산하는 과정이기도 하다. 레이 트레이싱은 AI에게 시각적 세계를 이해하고 창조하는 법을 가르치고 있으며, 언젠가 AI가 그 임무를 스스로 수행하게 될 때, 현재의 렌더링 파이프라인 개념 자체를 구시대의 유물로 만들 수도 있다. 이처럼 레이 트레이싱은 그래픽스의 종착역이 아니라, 완전히 새로운 시대로 나아가는 가장 중요한 관문이라 할 수 있다.</p>
<h2>9. 결론</h2>
<h3>9.1 레이 트레이싱 기술의 현주소 요약</h3>
<p>본 안내서에서 심층적으로 고찰한 바와 같이, 레이 트레이싱 기술은 지난 몇 년간 괄목할 만한 발전을 이루며 컴퓨터 그래픽스 분야의 지형을 근본적으로 바꾸어 놓았다. 한때 영화 및 VFX 산업의 오프라인 렌더링에서만 제한적으로 사용되던 이 기술은, 전용 하드웨어 가속기의 등장, DirectX Raytracing 및 Vulkan Ray Tracing과 같은 표준화된 API의 성숙, 그리고 AI 기반 최적화 기술의 비약적인 발전에 힘입어 이제 비디오 게임을 포함한 실시간 애플리케이션의 핵심 기술로 당당히 자리매김했다.</p>
<p>이는 단순히 그래픽 품질의 점진적 향상을 넘어, 렌더링의 근본 패러다임이 래스터라이제이션의 ’영리한 속임수(clever tricks)’에서 물리 기반 ’시뮬레이션(simulation)’으로 전환되고 있음을 의미하는 중대한 변화이다. 빛의 경로를 직접 추적함으로써, 개발자들은 더 이상 복잡하고 파편화된 근사 기법에 의존하지 않고도 일관되고 예측 가능한 방식으로 극사실적인 조명, 반사, 그림자 효과를 구현할 수 있게 되었다.</p>
<h3>9.2 지속적인 균형 탐색</h3>
<p>그러나 실시간 레이 트레이싱의 시대가 열렸음에도 불구하고, 기술의 현주소는 여전히 ’균형’을 향한 끊임없는 탐색 과정에 있다. 시각적 사실성, 실시간 성능, 그리고 개발의 편의성이라는 세 가지 핵심 요소 사이에는 여전히 명백한 트레이드오프가 존재한다.</p>
<p>현재 시장을 지배하는 하이브리드 렌더링 파이프라인, 특정 효과에만 레이 트레이싱을 선택적으로 적용하는 기법, 낮은 샘플 수로 인한 노이즈를 제거하기 위한 필수불가결한 디노이징 기술, 그리고 성능 저하를 만회하기 위한 DLSS나 FSR과 같은 AI 업스케일링 기술은 모두 이 까다로운 균형점을 맞추기 위한 치열한 노력의 산물이다. 순수한 패스 트레이싱이 제공하는 궁극의 사실성과 실시간 상호작용이 요구하는 엄격한 성능 제약 사이의 간극을 메우는 것이 현재 기술 발전의 핵심 과제이다.</p>
<h3>9.3 AI와의 융합과 미래 전망</h3>
<p>레이 트레이싱의 미래는 인공지능(AI)과의 융합에 깊이 연관되어 있다. 현재 AI는 주로 디노이징과 업스케일링이라는 후처리 단계에서 성능을 보조하는 역할을 하고 있지만, 이는 시작에 불과하다. 신경망 셰이더, NeRF와 같은 암시적 표현, ReSTIR와 같은 지능형 샘플링 알고리즘의 등장은 AI가 렌더링 파이프라인의 더욱 근본적인 영역으로 침투하고 있음을 보여준다.</p>
<p>궁극적으로, 업계는 래스터라이제이션이나 레이 트레이싱과 같은 기존의 명시적인 계산 파이프라인을 넘어, AI가 장면을 이해하고 물리 법칙을 모방하여 이미지를 직접 ’생성’하는 ‘완전한 신경망 렌더링’ 시대를 향해 나아가고 있다. 이러한 관점에서 볼 때, 현재의 레이 트레이싱은 그 자체가 최종 목표라기보다는, 기계가 시각적 세계를 물리적으로 정확하게 이해하고 생성하도록 훈련시키는 가장 중요한 ’데이터 생성 도구’이자 ’교과서’로서의 역할을 수행하고 있다. 따라서 레이 트레이싱 기술에 대한 지속적인 연구와 투자는 단순히 오늘날의 그래픽을 향상시키는 것을 넘어, 우리가 상상하는 것 이상의 몰입감과 사실성을 제공할 차세대 그래픽스 혁명의 발판을 마련하는 과정이라 할 수 있을 것이다.</p>
<h2>10. 참고 자료</h2>
<ol>
<li>M3 하드웨어 레이 트레이싱의 장점은 뭐임? : r/macgaming - Reddit, accessed July 17, 2025, https://www.reddit.com/r/macgaming/comments/17u9jd0/what_are_the_benefits_m3_hardware_raytracing/?tl=ko</li>
<li>레이 트레이싱 (1), accessed July 17, 2025, https://jebae.github.io/ray-tracing-principle/</li>
<li>게임에서 레이 트레이싱이란 무엇입니까? - Corsair, accessed July 17, 2025, https://www.corsair.com/kr/ko/explorer/gamer/gaming-pcs/what-is-ray-tracing-in-games/</li>
<li>Ray Tracing Graphics Pipeline Review Alternative Approaches Ray Casting Outline - Research, accessed July 17, 2025, https://groups.csail.mit.edu/graphics/classes/6.837/F01/Lecture17/lecture17.pdf</li>
<li>AmanSachan1/Monte-Carlo-Path-Tracer - GitHub, accessed July 17, 2025, https://github.com/AmanSachan1/Monte-Carlo-Path-Tracer</li>
<li>Overview of the Ray-Tracing Rendering Technique - Scratchapixel, accessed July 17, 2025, https://www.scratchapixel.com/lessons/3d-basic-rendering/ray-tracing-overview/ray-tracing-rendering-technique-overview.html</li>
<li>[그래픽스] 4. 레이트레이싱, accessed July 17, 2025, <a href="https://velog.io/@tjswodud/%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4-4.-%EB%A0%88%EC%9D%B4%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%8B%B1">https://velog.io/@tjswodud/%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4-4.-%EB%A0%88%EC%9D%B4%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%8B%B1</a></li>
<li>Vulkan Ray Tracing Pipeline - Image Synthesis - Part 2 - Chapter 1, accessed July 17, 2025, https://www.mathematik.uni-marburg.de/~thormae/lectures/graphics2/graphics_2_1_eng_web.html</li>
<li>Ray Tracing vs Rasterization: Unpacking Computer Graphics Rendering - Cable Matters, accessed July 17, 2025, https://www.cablematters.com/Blog/Computer-Accessories/ray-tracing-vs-rasterization</li>
<li>레이 트레이싱 (7) - jebae’s dev blog, accessed July 17, 2025, https://jebae.github.io/ray-tracing-reflection-refraction/</li>
<li>Understanding the Rendering Pipeline: Essentials for Traditional and Real-Time Rendering, accessed July 17, 2025, https://garagefarm.net/blog/understanding-the-rendering-pipeline-essentials-for-traditional-and-real-time-rendering</li>
<li>Why is ray tracing generally considered slower than rasterization? : r/computergraphics, accessed July 17, 2025, https://www.reddit.com/r/computergraphics/comments/uuzwlz/why_is_ray_tracing_generally_considered_slower/</li>
<li>실시간 레이트레이싱을 위한 부분 렌더링 기술 개발 - Korea Science, accessed July 17, 2025, https://www.koreascience.kr/article/CFKO201335553771065.pdf</li>
<li>언리얼 엔진의 레이 트레이싱 기술 완전 정복: 현실적인 그래픽의 비밀 - 재능넷, accessed July 17, 2025, https://www.jaenung.net/tree/23466</li>
<li>나만 레이 트레이싱 별로라고 생각하는 건가? : r/pcgaming - Reddit, accessed July 17, 2025, https://www.reddit.com/r/pcgaming/comments/1260agx/just_me_or_is_ray_tracing_overrated/?tl=ko</li>
<li>irendering.net, accessed July 17, 2025, <a href="https://irendering.net/rasterization-vs-ray-tracing-vs-path-tracing-what-is-the-difference/#:~:text=Taking%20all%20these%20points%20into,many%20points%20in%20any%20direction.">https://irendering.net/rasterization-vs-ray-tracing-vs-path-tracing-what-is-the-difference/#:~:text=Taking%20all%20these%20points%20into,many%20points%20in%20any%20direction.</a></li>
<li>NVIDIA Turing Architecture In-Depth | NVIDIA Technical Blog, accessed July 17, 2025, https://developer.nvidia.com/blog/nvidia-turing-architecture-in-depth/</li>
<li>Bounding volume hierarchy - Wikipedia, accessed July 17, 2025, https://en.wikipedia.org/wiki/Bounding_volume_hierarchy</li>
<li>Bounding Volume Hierarchies - Physically Based Rendering, accessed July 17, 2025, https://pbr-book.org/3ed-2018/Primitives_and_Intersection_Acceleration/Bounding_Volume_Hierarchies</li>
<li>Chapter 6 Bounding Volume Hierarchies (실시간 충돌탐지) - chan blog, accessed July 17, 2025, http://chanhaeng.blogspot.com/2018/11/chapter-6-bounding-volume-hierarchies.html</li>
<li>Path tracing - Wikipedia, accessed July 17, 2025, https://en.wikipedia.org/wiki/Path_tracing</li>
<li>Global Illumination and Path Tracing - Scratchapixel, accessed July 17, 2025, https://www.scratchapixel.com/lessons/3d-basic-rendering/global-illumination-path-tracing/global-illumination-path-tracing-practical-implementation.html</li>
<li>Monte Carlo Path Tracing, accessed July 17, 2025, https://cseweb.ucsd.edu/~viscomp/classes/cse168/sp21/lectures/168-lecture7.pdf</li>
<li>Ray-tracing hardware - Wikipedia, accessed July 17, 2025, https://en.wikipedia.org/wiki/Ray-tracing_hardware</li>
<li>How do RT cores work? - Raytracing - NVIDIA Developer Forums, accessed July 17, 2025, https://forums.developer.nvidia.com/t/how-do-rt-cores-work/314960</li>
<li>RT cores vs Ray Accelerators : r/Amd - Reddit, accessed July 17, 2025, https://www.reddit.com/r/Amd/comments/jn4wti/rt_cores_vs_ray_accelerators/</li>
<li>Nvidia Ampere vs. AMD RDNA 2: Battle of the Architectures : r/Amd, accessed July 17, 2025, https://www.reddit.com/r/Amd/comments/k88sp5/nvidia_ampere_vs_amd_rdna_2_battle_of_the/</li>
<li>DirectX Raytracing - Wikipedia, accessed July 17, 2025, https://en.wikipedia.org/wiki/DirectX_Raytracing</li>
<li>DX12 Raytracing tutorial - Helpers - NVIDIA Developer, accessed July 17, 2025, https://developer.nvidia.com/rtx/raytracing/dxr/dx12-raytracing-tutorial/dxr_tutorial_helpers</li>
<li>DX12 Raytracing tutorial - Part 2 | NVIDIA Developer, accessed July 17, 2025, https://developer.nvidia.com/rtx/raytracing/dxr/dx12-raytracing-tutorial-part-2</li>
<li>NVIDIA Vulkan Ray Tracing Tutorial, accessed July 17, 2025, https://developer.nvidia.com/rtx/raytracing/vkray</li>
<li>Ray Tracing :: Vulkan Documentation Project, accessed July 17, 2025, https://docs.vulkan.org/guide/latest/extensions/ray_tracing.html</li>
<li>Vulkan VS DX12 Raytracing : r/linux_gaming - Reddit, accessed July 17, 2025, https://www.reddit.com/r/linux_gaming/comments/1gfl4s4/vulkan_vs_dx12_raytracing/</li>
<li>Ray Tracing Validation for DirectX 12 and Vulkan | NVIDIA Technical Blog, accessed July 17, 2025, https://developer.nvidia.com/blog/ray-tracing-validation-at-the-driver-level/</li>
<li>Microsoft says DirectX Raytracing 1.2 will deliver up to 2.3x performance uplift, accessed July 17, 2025, https://www.tomshardware.com/pc-components/gpus/microsoft-says-directx-raytracing-1-2-will-deliver-up-to-2-3x-performance-uplift</li>
<li>Get Started with Neural Rendering Using NVIDIA RTX Kit, accessed July 17, 2025, https://developer.nvidia.com/blog/get-started-with-neural-rendering-using-nvidia-rtx-kit/</li>
<li>Real-Time Rendering of Glossy Reflections Using Ray Tracing and Two-Level Radiance Caching - AMD GPUOpen, accessed July 17, 2025, https://gpuopen.com/download/SA2023_RealTimeReflection.pdf</li>
<li>Spatiotemporal Variance-Guided Filtering (SVGF) - Wisp Wiki, accessed July 17, 2025, https://teamwisp.github.io/research/svfg.html</li>
<li>Spatiotemporal variance-guided filtering: real-time reconstruction for path-traced global illumination | Request PDF - ResearchGate, accessed July 17, 2025, https://www.researchgate.net/publication/318730200_Spatiotemporal_variance-guided_filtering_real-time_reconstruction_for_path-traced_global_illumination</li>
<li>Ray Tracing Denoising - Alain Galvan, accessed July 17, 2025, https://alain.xyz/blog/ray-tracing-denoising</li>
<li>Real-Time Volume-Rendering Image Denoising Based on Spatiotemporal Weighted Kernel Prediction - PMC, accessed July 17, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC12028196/</li>
<li>Intel® Open Image Denoise Library Saves Time, Boosts Quality, accessed July 17, 2025, https://www.intel.com/content/dam/develop/external/us/en/documents/intelopenimagedenoiselibrarysavestimeboostsquality.pdf</li>
<li>NVIDIA-RTX/NRD: NVIDIA Real-time Denoising (NRD) library - GitHub, accessed July 17, 2025, https://github.com/NVIDIA-RTX/NRD</li>
<li>Intel® Open Image Denoise, accessed July 17, 2025, https://www.openimagedenoise.org/</li>
<li>NVIDIA OptiX™ AI-Accelerated Denoiser, accessed July 17, 2025, https://developer.nvidia.com/optix-denoiser</li>
<li>Nvidia Hints at DLSS 10 Delivering Full Neural Rendering, Potentially Replacing Rasterization and Ray Tracing | Tom’s Hardware, accessed July 17, 2025, https://www.tomshardware.com/news/nvidia-hints-at-dlss-10-delivering-full-neural-rendering-potentially-replacing-rasterization-and-ray-tracing</li>
<li>What Has AI Done for Graphics? - ACM SIGGRAPH Blog, accessed July 17, 2025, https://blog.siggraph.org/2024/04/what-has-ai-done-for-graphics.html/</li>
<li>Spectral Rendering in Manuka, accessed July 17, 2025, https://jo.dreggn.org/path-tracing-in-production/2017/talk-jo/</li>
<li>언리얼 엔진 ‘리얼타임 레이 트레이싱’ – 진화 - 테크월드뉴스, accessed July 17, 2025, https://www.epnc.co.kr/news/articleView.html?idxno=94845</li>
<li>언리얼 엔진 리얼타임 레이 트레이싱 – 자동차 디자인과 시각화 - 테크월드뉴스, accessed July 17, 2025, https://www.epnc.co.kr/news/articleView.html?idxno=95665</li>
<li>Manuka: Weta Digital’s new renderer - fxguide, accessed July 17, 2025, https://www.fxguide.com/fxfeatured/manuka-weta-digitals-new-renderer/</li>
<li>Our Work on Avatar: The Way of Water | Wētā FX - Weta FX, accessed July 17, 2025, https://www.wetafx.co.nz/articles/our-work-on-avatar-the-way-of-water</li>
<li>Cyberpunk 2077 PC tech analysis: a closer look at the ultra high …, accessed July 17, 2025, https://www.eurogamer.net/digitalfoundry-2020-cyberpunk-2077-high-end-pc-tech-analysis</li>
<li>Cyberpunk 2077 ray tracing: what does it look like and how does it run?, accessed July 17, 2025, https://www.rockpapershotgun.com/cyberpunk-2077-ray-tracing-performance</li>
<li>Cyberpunk 2077 - Full Ray Tracing Deep Dive Trailer - YouTube, accessed July 17, 2025, https://www.youtube.com/watch?v=4K7Ugr-8stE</li>
<li>Lumen vs Ray Tracing: Photorealistic Results in 3D Rendering - Lunas, accessed July 17, 2025, https://www.lunas.pro/news/lumen-ray-tracing.html</li>
<li>What is real-time ray tracing? - Unreal Engine, accessed July 17, 2025, https://www.unrealengine.com/en-US/explainers/ray-tracing/what-is-real-time-ray-tracing</li>
<li>Lumen Technical Details in Unreal Engine | Unreal Engine 5.6 …, accessed July 17, 2025, https://dev.epicgames.com/documentation/en-us/unreal-engine/lumen-technical-details-in-unreal-engine</li>
<li>Enscape vs. V-Ray: Which Rendering Engine is Best for Your Workflow? - Vagon, accessed July 17, 2025, https://vagon.io/blog/enscape-vs-v-ray-which-rendering-engine-is-best-for-your-workflow</li>
<li>V-ray and Corona: Which renderer should you choose? | iRender Farm, accessed July 17, 2025, https://irendering.net/v-ray-and-corona-which-renderer-should-you-choose/</li>
<li>What is NeRF? - Neural Radiance Fields Explained - AWS, accessed July 17, 2025, https://aws.amazon.com/what-is/neural-radiance-fields/</li>
<li>Neural Radiance Fields (NeRFs): A Technical Exploration - Viso Suite, accessed July 17, 2025, https://viso.ai/deep-learning/neural-radiance-fields/</li>
<li>Neural Radiance Fields (NeRFs) - Hugging Face Community Computer Vision Course, accessed July 17, 2025, https://huggingface.co/learn/computer-vision-course/unit8/nerf</li>
<li>NeRF: 3D Scene Rendering with Neural Radiance Fields | by Dong-Keon Kim | Medium, accessed July 17, 2025, https://medium.com/@kdk199604/nerf-3d-scene-rendering-with-neural-radiance-fields-9bfae5a6fc1c</li>
<li>Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting - Research at NVIDIA, accessed July 17, 2025, https://research.nvidia.com/sites/default/files/pubs/2020-07_Spatiotemporal-reservoir-resampling/ReSTIR.pdf</li>
<li>Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting, accessed July 17, 2025, https://cs.dartmouth.edu/~wjarosz/publications/bitterli20spatiotemporal.html</li>
<li>tatran5/Reservoir-Spatio-Temporal-Importance-Resampling-ReSTIR - GitHub, accessed July 17, 2025, https://github.com/tatran5/Reservoir-Spatio-Temporal-Importance-Resampling-ReSTIR</li>
<li>Spatiotemporal Reservoir Resampling (ReSTIR) - Theory and Basic …, accessed July 17, 2025, https://gamehacker1999.github.io/posts/restir/</li>
<li>NVIDIA RTX Neural Rendering Introduces Next Era of AI-Powered Graphics Innovation, accessed July 17, 2025, https://developer.nvidia.com/blog/nvidia-rtx-neural-rendering-introduces-next-era-of-ai-powered-graphics-innovation/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>