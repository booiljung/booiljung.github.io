<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:실시간 레이트레이싱 렌더링</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>실시간 레이트레이싱 렌더링</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">컴퓨터 그래픽 (Computer Graphics)</a> / <a href="index.html">Raytracing</a> / <span>실시간 레이트레이싱 렌더링</span></nav>
                </div>
            </header>
            <article>
                <h1>실시간 레이트레이싱 렌더링</h1>
<h2>1.  3D 렌더링의 기본 원칙</h2>
<p>컴퓨터 그래픽스 분야에서 3D 장면을 2D 이미지로 변환하는 ‘렌더링’ 과정은 시각적 결과물의 사실성과 상호작용성을 결정하는 핵심 기술이다. 이 과정은 수십 년간 발전을 거듭해왔으며, 크게 두 가지 패러다임, 즉 ’래스터라이제이션(Rasterization)’과 ’레이트레이싱(Ray Tracing)’으로 나뉜다. 실시간 레이트레이싱의 혁신을 이해하기 위해서는 먼저 이 두 가지 근본적인 접근법의 철학과 기술적 특성을 명확히 구분해야 한다.</p>
<h3>1.1  렌더링 패러다임: 3D 장면에서 2D 이미지로</h3>
<h4>1.1.1  그래픽스 파이프라인: 개요</h4>
<p>렌더링이란 컴퓨터가 입력받은 3D 모델, 텍스처, 조명 등의 데이터를 기반으로 최종적인 2D 이미지를 생성하는 모든 과정을 의미한다.1 이 복잡한 과정은 ’렌더링 파이프라인’이라는 일련의 단계적 작업으로 구성된다. 파이프라인은 3차원 공간에 정의된 기하학적 정보를 우리가 보는 2차원 화면의 픽셀 색상 값으로 변환하는 역할을 수행하며, 각 단계는 특정 연산을 전문적으로 처리하도록 설계되어 있다.1</p>
<h4>1.1.2  래스터라이제이션 방식: 심층 분석</h4>
<p>래스터라이제이션은 수십 년간 실시간 그래픽스 분야를 지배해 온 전통적인 렌더링 방식이다. 이 방식의 핵심은 속도와 효율성에 있으며, 3D 객체를 2D 화면에 ’투영’하는 기하학적 접근법을 취한다.</p>
<h5>1.1.2.1  지오메트리 및 정점 처리</h5>
<p>래스터라이제이션 파이프라인의 첫 단계는 3D 모델을 처리하는 것이다. 컴퓨터 그래픽에서 3D 객체는 ’메시(mesh)’라고 불리는 다각형(polygon)의 집합으로 표현되며, 이 다각형은 대부분 삼각형으로 구성된다.3 각 삼각형의 꼭짓점, 즉 ’정점(vertex)’은 3D 공간 내 위치 정보뿐만 아니라 색상, 텍스처 좌표(UV), 노멀(normal, 표면의 방향을 나타내는 벡터) 등 다양한 속성 데이터를 포함한다.6</p>
<p>지오메트리 단계에서 GPU는 이 정점들을 순차적으로 처리한다. 먼저, 모델의 고유 좌표계(로컬 공간)에 있는 정점들을 장면 전체의 공통 좌표계(월드 공간)로 변환하는 ’월드 변환’을 수행한다. 그다음, 가상 카메라의 위치와 방향을 기준으로 이 정점들을 다시 변환하는 ’뷰 변환’을 거친다. 마지막으로, 3차원 공간의 정점들을 2차원 화면에 투영하는 ’투영 변환’을 통해 최종적으로 화면에 표시될 위치를 결정한다.1 이 전체 과정은 ‘객체 중심(object-centric)’ 접근법으로, 3D 객체에서 시작하여 2D 이미지로 나아가는 흐름을 가진다.7</p>
<h5>1.1.2.2  래스터라이저 단계와 픽셀 셰이딩</h5>
<p>지오메트리 단계에서 2D 화면에 투영된 삼각형들은 ’래스터라이저’라는 하드웨어 유닛으로 전달된다. 래스터라이저는 이 2D 삼각형이 화면의 어떤 픽셀들을 덮고 있는지를 결정하는 역할을 한다.1 이 과정에서 ’top-left rule’과 같은 규칙을 사용하여 삼각형의 경계에 걸친 픽셀을 일관되게 처리함으로써, 동일한 픽셀이 여러 번 렌더링되는 비효율을 방지한다.8</p>
<p>삼각형이 덮는 픽셀들이 결정되면, 각 픽셀에 대한 최종 색상을 계산하기 위해 ‘픽셀 셰이더(Pixel Shader)’ 또는 ’프래그먼트 셰이더(Fragment Shader)’가 실행된다.1 픽셀 셰이더는 정점들로부터 보간된 텍스처 좌표, 노멀 벡터 등의 데이터를 사용하여 텍스처를 입히고(텍스처 매핑), 장면 내 광원 정보를 바탕으로 조명과 음영을 계산한다.1 이 계산 결과가 바로 해당 픽셀의 최종 색상이 되어 컬러 버퍼에 저장된다.</p>
<h5>1.1.2.3  내재적 한계: 빛과 그림자의 근사</h5>
<p>래스터라이제이션의 가장 큰 특징은 그것이 빛의 물리적 현상을 직접 시뮬레이션하는 것이 아니라, 기하학적 투영을 기반으로 조명 효과를 ’근사(approximation)’한다는 점이다. 이러한 접근법은 매우 빠르다는 장점을 제공하지만, 물리적으로 정확한 광학 효과를 표현하는 데에는 명백한 한계를 가진다.</p>
<p>예를 들어, 반사 효과는 주로 ’스크린 스페이스 리플렉션(Screen Space Reflection, SSR)’이라는 기법으로 구현된다. SSR은 현재 화면에 렌더링된 정보(뎁스 버퍼와 컬러 버퍼)만을 사용하여 반사 이미지를 생성하기 때문에, 화면 밖에 있는 객체나 다른 객체에 가려진 부분은 반사되지 못하는 근본적인 한계를 지닌다.10 거울 속의 거울처럼 다중 반사가 일어나는 현상(inter-reflection)은 거의 불가능하다.</p>
<p>그림자 역시 ’섀도우 매핑(Shadow Mapping)’이라는 기법을 통해 근사적으로 구현된다. 이 방식은 광원의 시점에서 장면을 렌더링하여 깊이 정보(섀도우 맵)를 텍스처에 저장한 뒤, 본래 시점에서 렌더링할 때 이 맵을 참조하여 그림자 여부를 판단한다. 이 기법은 섀도우 맵의 해상도에 따라 그림자 경계가 각져 보이는 ‘앨리어싱(aliasing)’ 현상이나, 그림자가 물체에서 살짝 떠 보이는 ’피터 패닝(Peter-Panning)’과 같은 시각적 오류를 유발하기 쉽다.9</p>
<p>이처럼 래스터라이제이션은 속도를 위해 물리적 정확성을 희생하는, 고도로 최적화된 기하학적 투영 기법에 가깝다. 이는 빛을 시뮬레이션하는 것이 아니라, 투영된 지오메트리에 조명 정보를 ’덧칠’하는 방식이다. 반면, 레이트레이싱은 빛 자체의 경로를 추적하여 물리 현상을 시뮬레이션하는 근본적으로 다른 철학에서 출발한다. 이 패러다임의 차이가 두 기술의 모든 장단점을 결정짓는 근원이며, 실시간 그래픽스 기술 발전의 핵심적인 동력이 되어왔다.</p>
<h3>1.2  레이트레이싱 방식: 빛의 물리학 시뮬레이션</h3>
<p>레이트레이싱은 래스터라이제이션과는 정반대의 접근법을 취한다. 3D 객체를 2D 화면에 투영하는 대신, 가상의 카메라(또는 눈)에서부터 빛이 이동하는 경로를 역으로 추적하여 각 픽셀의 색상을 결정한다. 이는 실제 세계에서 우리가 사물을 인지하는 방식을 모방한 물리 기반 시뮬레이션 기법이다.4</p>
<h4>1.2.1  핵심 알고리즘: 광선의 여정</h4>
<p>레이트레이싱의 기본 원리는 ‘이미지 중심(image-centric)’ 접근법에 있다.7 렌더링할 최종 이미지의 각 픽셀에서 시작하여, 가상 카메라의 초점을 지나 3D 장면 속으로 가상의 ’광선(ray)’을 발사한다.6 이 광선이 장면 내의 어떤 객체와 가장 먼저 교차하는지를 계산한다. 교차점이 발견되면, 해당 지점의 재질(material) 속성(색상, 거칠기, 반사율 등)과 장면 내 광원의 위치 및 특성을 종합하여 픽셀의 색상을 결정하는 것이 알고리즘의 핵심이다.</p>
<h4>1.2.2  역방향 추적 vs. 순방향 추적: 효율성의 문제</h4>
<p>현실 세계에서 빛은 광원에서 출발하여 여러 객체에 반사된 후 우리 눈에 도달한다. 이를 그대로 시뮬레이션하는 ‘순방향 추적(forward tracing)’ 방식은 물리적으로 가장 정확하지만, 광원에서 방출되는 무수히 많은 광선 중 극소수만이 카메라에 도달하기 때문에 엄청난 양의 연산 낭비를 초래한다.17</p>
<p>이러한 비효율을 해결하기 위해 현대 컴퓨터 그래픽스의 레이트레이싱은 ‘역방향 추적(backward/reverse tracing)’ 방식을 채택한다.14 즉, 최종적으로 이미지에 기여하는 광선만을 고려하기 위해 카메라에서부터 광선을 발사하여 그 경로를 거슬러 올라가는 것이다. 이는 연산 효율성을 수십, 수백만 배 향상시키는 결정적인 최적화 기법이다.</p>
<h4>1.2.3  재귀적 레이트레이싱: 반사, 굴절, 그림자의 시뮬레이션</h4>
<p>레이트레이싱의 진정한 힘은 재귀적인(recursive) 특성에서 나온다. 카메라에서 발사된 주 광선(primary ray)이 어떤 표면에 부딪혔을 때, 알고리즘은 거기서 멈추지 않는다. 해당 지점에서 물리 법칙에 따라 새로운 이차 광선(secondary rays)들을 생성하여 추적을 계속한다.9</p>
<ul>
<li><strong>반사 광선 (Reflection Rays):</strong> 표면이 거울처럼 반사율이 높은 재질일 경우, 입사각과 동일한 반사각으로 반사 광선을 발사한다. 이 반사 광선이 또 다른 객체에 부딪히면, 그 객체의 색상 정보가 원래 픽셀의 색상에 기여하게 된다. 이 과정이 반복되면 거울 속 거울과 같은 다중 반사 효과를 자연스럽게 구현할 수 있다.21</li>
<li><strong>굴절 광선 (Refraction Rays):</strong> 표면이 유리나 물처럼 투명하거나 반투명한 재질일 경우, 재질의 굴절률에 따라 빛이 꺾이는 현상을 시뮬레이션하기 위해 굴절 광선을 발사한다. 이 광선은 객체 내부를 통과하여 반대편으로 나아가며, 이를 통해 사실적인 투명 및 굴절 효과를 얻을 수 있다.</li>
<li><strong>그림자 광선 (Shadow Rays):</strong> 주 광선이 객체와 교차한 지점에서, 장면 내의 모든 광원을 향해 그림자 광선을 발사한다. 만약 이 그림자 광선이 광원에 도달하기 전에 다른 불투명한 객체에 의해 가로막히면, 해당 지점은 그 광원에 대해 그림자 속에 있는 것으로 판단된다. 이 방식은 래스터라이제이션의 섀도우 맵과 달리 기하학적으로 완벽한 그림자를 생성한다.</li>
</ul>
<h4>1.2.4  패스 트레이싱: 사실주의와 전역 조명의 추구</h4>
<p>재귀적 레이트레이싱이 반사, 굴절, 직접적인 그림자와 같은 광학 현상을 잘 처리하는 반면, 빛이 표면에서 모든 방향으로 흩어지는 ’난반사(diffuse reflection)’와 이로 인해 발생하는 간접광 효과를 완벽하게 시뮬레이션하지는 못한다. 이 문제를 해결하고 궁극의 사실주의를 추구하는 기법이 바로 ’패스 트레이싱(Path Tracing)’이다.</p>
<p>패스 트레이싱은 ’렌더링 방정식(Rendering Equation)’이라는 물리 기반의 빛 전파 모델을 풀기 위한 알고리즘이다.3 이는 한 지점에 도달하는 빛이 광원에서 직접 오는 빛뿐만 아니라, 주변의 모든 다른 표면에서 반사되어 오는 간접광의 총합으로 이루어진다는 원리를 기반으로 한다. 패스 트레이싱은 광선이 표면에 부딪혔을 때, 몇 개의 정해진 이차 광선을 쏘는 대신, 몬테카를로(Monte Carlo) 방법을 사용하여 수많은 광선을 무작위 방향으로 발사하고 그 경로(path)를 추적한다.23</p>
<p>이 무작위적인 광선 경로들을 수없이 많이 샘플링하고 평균을 내어 렌더링 방정식을 근사적으로 해결한다. 이 과정을 통해 빛이 벽에 부딪혀 색이 번지는 ‘컬러 블리딩(color bleeding)’, 광원의 크기에 따라 그림자 경계가 부드러워지는 ‘소프트 섀도우(soft shadow)’, 그리고 장면 전체에 은은하게 퍼지는 간접광을 포함하는 ’전역 조명(Global Illumination, GI)’을 매우 사실적으로 구현할 수 있다.2 패스 트레이싱은 현재 오프라인 렌더링에서 사진과 같은 결과물을 얻기 위한 표준 기법으로 사용되며, 실시간 그래픽스 분야의 궁극적인 목표로 여겨진다.3</p>
<p>여기서 “레이트레이싱“과 “패스 트레이싱“의 관계를 명확히 할 필요가 있다. 종종 혼용되지만, 엄밀히 말해 레이트레이싱은 두 지점 간의 가시성을 확인하기 위해 광선을 쏘는 근본적인 ‘도구’ 또는 ’기술’이다.27 반면, 패스 트레이싱은 이 레이트레이싱이라는 도구를 사용하여 전역 조명을 포함한 렌더링 방정식을 푸는 구체적인 ’알고리즘’이다. 따라서 현대의 “RTX” 게임들은 순수한 재귀적 레이트레이싱과 완전한 패스 트레이싱 사이의 스펙트럼에 위치한다. 예를 들어, 단일 반사 효과는 간단한 레이트레이싱으로, 여러 번의 빛 반사가 필요한 전역 조명은 제한된 형태의 패스 트레이싱으로 구현하는 하이브리드 방식을 채택하는 경우가 많다. 이 기술적 계층(레이 캐스팅 –&gt;&gt; 재귀적 레이트레이싱 –&gt;&gt; 패스 트레이싱)을 이해하는 것은 각 게임이 제공하는 시각적 품질과 성능 요구 사항의 차이를 분석하는 데 매우 중요하다.</p>
<h4>1.2.5 표 2.1: 래스터라이제이션과 레이트레이싱 비교 분석</h4>
<table><thead><tr><th>기능</th><th>래스터라이제이션</th><th>레이트레이싱 / 패스 트레이싱</th></tr></thead><tbody>
<tr><td><strong>핵심 원리</strong></td><td>3D 삼각형을 2D 픽셀로 투영하는 객체 중심 접근법</td><td>카메라에서 광선을 추적하는 이미지 중심의 빛 물리 시뮬레이션</td></tr>
<tr><td><strong>주요 강점</strong></td><td>속도, 하드웨어 최적화, 실시간 성능</td><td>물리적 정확성, 사진과 같은 사실성</td></tr>
<tr><td><strong>주요 약점</strong></td><td>복잡한 빛 효과를 근사치와 ’꼼수’에 의존</td><td>극도로 높은 연산 비용</td></tr>
<tr><td><strong>반사 처리</strong></td><td>근사적(예: SSR), 화면 내 정보에만 국한됨</td><td>물리적으로 정확, 화면 밖 객체 반사, 상호 반사 지원</td></tr>
<tr><td><strong>그림자 처리</strong></td><td>근사적(예: 섀도우 맵), ‘피터 패닝’, 앨리어싱 등 아티팩트 발생 가능</td><td>물리적으로 정확, 광원 크기에 따라 자연스러운 소프트 섀도우 생성</td></tr>
<tr><td><strong>전역 조명(GI)</strong></td><td>주로 사전 계산된 ‘베이크(baked)’ 조명이나 스크린 공간 근사(SSGI)로 구현</td><td>패스 트레이싱을 통해 자연스럽게 시뮬레이션, 동적 컬러 블리딩 및 간접광 구현</td></tr>
</tbody></table>
<h2>2.  실시간 레이트레이싱의 도래</h2>
<p>수십 년간 레이트레이싱은 영화 VFX나 건축 시각화처럼 렌더링 시간에 구애받지 않는 오프라인 분야의 전유물이었다. 프레임당 수 분에서 수 시간이 걸리는 막대한 연산량 때문에, 초당 수십 프레임을 처리해야 하는 실시간 인터랙티브 환경에서는 사용이 불가능했다. 그러나 2018년을 기점으로 하드웨어와 소프트웨어 양쪽에서 혁신적인 기술 발전이 이루어지면서, ’실시간 레이트레이싱’이라는 새로운 시대가 열리게 되었다.</p>
<h3>2.1  하드웨어 혁명: 전용 가속기</h3>
<p>실시간 레이트레이싱을 가로막았던 가장 큰 장벽은 압도적인 연산량이었다. Full HD(1920x1080) 해상도에서 초당 60프레임을 렌더링하려면, 매초 1억 2천만 개 이상의 픽셀에 대해 광선을 추적해야 한다. 여기에 반사, 그림자 등을 위한 이차 광선까지 고려하면 연산량은 기하급수적으로 증가하여 초당 수십억 회의 광선-도형 교차 판정이 필요하다.29 특히 장면의 복잡도가 높아질수록 메모리 접근 비용이 급증하여 성능 저하의 주된 원인이 된다.30 기존의 범용 셰이더 코어만으로는 이 연산을 실시간으로 처리하는 것이 불가능했다.</p>
<p>이 문제를 해결한 것은 ’전용 하드웨어 가속’이라는 패러다임의 전환이었다. 범용 연산 유닛이 아닌, 레이트레이싱의 특정 작업을 전담하는 특수 목적 반도체(ASIC)를 GPU에 탑재하는 방식이다.</p>
<h4>2.1.1  NVIDIA의 접근: RT 코어의 아키텍처와 기능</h4>
<p>실시간 레이트레이싱 대중화의 포문을 연 것은 2018년 NVIDIA가 발표한 ‘튜링(Turing)’ 아키텍처였다.32 튜링 아키텍처의 핵심은 ’RT 코어(Ray Tracing Core)’라는 새로운 하드웨어 유닛의 도입이다.33 RT 코어는 GPU의 스트리밍 멀티프로세서(SM) 내부에 탑재된 전용 회로로, 레이트레이싱 연산 중 가장 부하가 큰 두 가지 작업을 전담하여 가속한다.34</p>
<ol>
<li><strong>BVH 순회 (Bounding Volume Hierarchy Traversal):</strong> 광선이 장면 내의 어떤 객체 그룹과 충돌할 가능성이 있는지 계층적 공간 자료 구조(BVH)를 빠르게 탐색하는 작업.</li>
<li><strong>광선-삼각형 교차 판정 (Ray-Triangle Intersection Test):</strong> BVH 순회를 통해 좁혀진 후보군 내에서 광선이 실제로 개별 삼각형과 교차하는지 판정하는 작업.</li>
</ol>
<p>이 두 작업은 기존 셰이더 코어로 처리할 경우 수천 개의 명령어가 필요한 매우 무거운 연산이다.35 RT 코어는 이 작업을 하드웨어적으로 처리하여 SM의 부담을 획기적으로 줄여준다. 그 결과, SM은 본연의 임무인 셰이딩(shading) 연산에 집중할 수 있게 되어 전체적인 렌더링 성능이 극적으로 향상되었다. NVIDIA에 따르면 튜링 아키텍처의 RT 코어는 이전 세대인 파스칼(Pascal) 아키텍처 대비 최대 25배 빠른 실시간 레이트레이싱 성능을 제공한다.36 이처럼 특정 작업을 위한 전용 하드웨어의 탑재는 실시간 레이트레이싱을 가능하게 한 가장 결정적인 기술적 도약이었다.</p>
<h4>2.1.2  AMD의 접근: 레이 액셀러레이터의 아키텍처와 기능</h4>
<p>AMD는 ‘RDNA 2’ 아키텍처를 통해 하드웨어 가속 레이트레이싱을 도입하며 경쟁에 합류했다. RDNA 2는 Microsoft의 DirectX 12 Ultimate 표준을 충족하는 최초의 AMD 아키텍처로, PlayStation 5와 Xbox Series X/S 콘솔에도 탑재되었다.38</p>
<p>AMD의 접근 방식은 ’레이 액셀러레이터(Ray Accelerator, RA)’라는 고정 기능 하드웨어 유닛을 각 컴퓨트 유닛(CU) 내에 통합하는 것이다.39 RA 역시 NVIDIA의 RT 코어와 마찬가지로 광선-삼각형 및 광선-바운딩 박스 교차 판정 연산을 가속하는 역할을 한다. 하지만 NVIDIA가 RT 코어를 비교적 독립적인 유닛으로 설계한 것과 달리, AMD의 RA는 CU와 더 긴밀하게 통합되어 있으며, 레이트레이싱 작업 흐름의 상당 부분을 여전히 셰이더 엔진에 의존하는 하이브리드적인 구조를 가진다.39 이는 두 회사의 GPU 아키텍처 철학의 차이를 보여주는 부분이기도 하다. 이후 RDNA 3 아키텍처에서는 RA의 성능이 개선되었고, 차세대 RDNA 4에서는 셰이더 엔진의 부담을 더욱 줄이기 위해 레이트레이싱 하드웨어를 근본적으로 재설계할 것으로 알려져 있다.38</p>
<h4>2.1.3  모바일의 개척: SoC 내 하드웨어 가속 레이트레이싱</h4>
<p>데스크톱 GPU에서 시작된 하드웨어 가속 레이트레이싱 기술은 빠르게 모바일 플랫폼으로 확장되고 있다. 그 대표적인 사례가 삼성전자의 ‘엑시노스 2200’ 시스템 온 칩(SoC)에 탑재된 ‘Xclipse 920’ GPU이다.41 Xclipse GPU는 AMD의 RDNA 2 아키텍처를 기반으로 설계되어, 모바일 기기로는 세계 최초로 하드웨어 가속 레이트레이싱을 지원한다.42</p>
<p>이는 스마트폰과 같은 저전력 기기에서도 가변 레이트 셰이딩(VRS)이나 레이트레이싱 기반의 사실적인 조명, 그림자, 반사 효과를 구현할 수 있게 되었음을 의미한다. 초기 벤치마크 결과에 따르면, Xclipse 920은 레이트레이싱 성능 면에서 일부 최신 경쟁 칩셋을 능가하는 모습을 보여주며, 모바일 그래픽스 기술의 새로운 가능성을 제시했다.44 이처럼 레이트레이싱 기술이 고성능 데스크톱에서 메인스트림 모바일 기기로 확산되는 추세는 이 기술이 미래 그래픽스의 표준이 될 것임을 시사한다.</p>
<h3>2.2  소프트웨어 프레임워크: 표준화된 API</h3>
<p>전용 하드웨어의 등장은 실시간 레이트레이싱을 위한 필요조건이었지만, 그것만으로는 충분하지 않았다. 개발자들이 이 하드웨어를 쉽고 일관된 방식으로 활용할 수 있도록 해주는 표준화된 소프트웨어 인터페이스, 즉 API(Application Programming Interface)의 등장이 필수적이었다. 표준 API는 하드웨어 제조사(NVIDIA, AMD, Intel)와 소프트웨어 개발사(게임 엔진, 3D 애플리케이션) 모두에게 안정적이고 통일된 개발 목표를 제공함으로써 기술 채택을 가속화하는 촉매제 역할을 했다.</p>
<h4>2.2.1  Microsoft DirectX Raytracing (DXR): 아키텍처와 구성 요소</h4>
<p>Microsoft는 DirectX 12의 확장 기능으로 ’DirectX Raytracing(DXR)’을 발표하며 PC 플랫폼에서 레이트레이싱 API의 표준을 제시했다.45 DXR은 레이트레이싱을 기존의 래스터라이제이션 및 컴퓨트 파이프라인과 원활하게 통합하는 것을 목표로 설계되었다.46 DXR의 핵심 구성 요소는 다음과 같다 45:</p>
<ul>
<li><strong>가속 구조 (Acceleration Structures, AS):</strong> 장면의 지오메트리를 GPU가 효율적으로 순회할 수 있도록 최적화된 자료 구조로, 일반적으로 BVH(Bounding Volume Hierarchy)를 의미한다. DXR은 개별 객체의 지오메트리를 담는 하위 수준 AS(BLAS)와, 이 BLAS들의 인스턴스 및 변환 정보를 담는 상위 수준 AS(TLAS)의 2단계 계층 구조를 사용한다.48</li>
<li><strong>DispatchRays 명령어:</strong> 래스터라이제이션의 <code>Draw</code> 명령어처럼, 레이트레이싱 작업을 시작하라는 명령을 GPU에 내린다.</li>
<li><strong>새로운 셰이더 타입:</strong> 레이트레이싱 파이프라인의 각 단계를 프로그래밍할 수 있도록 새로운 셰이더들이 도입되었다.</li>
<li><code>Ray Generation Shader</code>: 광선을 생성하고 추적을 시작하는 진입점.</li>
<li><code>Intersection Shader</code>: 절차적으로 생성된 지오메트리 등 기본 삼각형이 아닌 도형과의 교차 판정 로직을 정의.</li>
<li><code>Any-Hit Shader</code>: 광선이 어떤 객체와 교차할 때마다 호출되며, 주로 투명도 테스트(알파 테스팅) 등에 사용.</li>
<li><code>Closest-Hit Shader</code>: 광선 경로상 가장 가까운 객체와 교차했을 때 호출되며, 표면의 재질과 조명을 계산하는 핵심 셰이딩 로직을 담당.</li>
<li><code>Miss Shader</code>: 광선이 아무 객체와도 교차하지 않았을 때 호출되며, 주로 배경이나 스카이박스 색상을 처리.</li>
<li><strong>레이트레이싱 파이프라인 상태 객체 (RTPSO):</strong> 레이트레이싱 작업에 사용될 모든 셰이더와 상태를 하나로 묶어 컴파일한 객체.</li>
</ul>
<p>이러한 구조를 통해 개발자들은 어떤 하드웨어를 사용하는지에 관계없이 일관된 방식으로 레이트레이싱 코드를 작성할 수 있게 되었다. 이는 과거의 독점적인 API(예: NVIDIA OptiX)에 의존해야 했던 상황과 비교할 때 개발의 문턱을 크게 낮추는 중요한 변화였다.49</p>
<h4>2.2.2  Khronos Group의 Vulkan Ray Tracing: 아키텍처와 확장 기능</h4>
<p>크로스 플랫폼 그래픽스 API인 Vulkan 역시 일련의 확장 기능(KHR extensions)을 통해 레이트레이싱을 지원한다. <code>VK_KHR_acceleration_structure</code>, <code>VK_KHR_ray_tracing_pipeline</code> 등의 확장 기능들은 DXR과 유사한 개념적 토대 위에 구축되었다.50</p>
<p>Vulkan Ray Tracing 또한 가속 구조(AS), 새로운 셰이더 스테이지(Ray Generation, Closest Hit 등), 그리고 새로운 디스패치 명령어(<code>vkCmdTraceRaysKHR</code>)를 핵심 구성 요소로 가진다.50 Vulkan의 가장 큰 장점은 Windows를 넘어 Linux, Android 등 다양한 운영체제에서 레이트레이싱을 구현할 수 있는 길을 열었다는 점이다.</p>
<h4>2.2.3  실시간 성능의 핵심, 가속 구조(BVH)</h4>
<p>DXR과 Vulkan RT 모두의 핵심에는 ‘가속 구조’, 즉 BVH가 있다. BVH는 장면의 모든 삼각형들을 계층적인 경계 상자(bounding box)의 트리 구조로 정리한 것이다.48 광선을 추적할 때, 장면 내 모든 삼각형과 일일이 교차 판정을 하는 것은 O(n)의 복잡도를 가져 비효율적이다. 대신, GPU는 BVH 트리를 따라 내려가면서 광선이 통과하지 않는 큰 경계 상자들을 통째로 기각(cull)할 수 있다. 이 과정을 통해 실제 교차 판정이 필요한 삼각형의 수를 극적으로 줄여, 연산 복잡도를 O(log n) 수준으로 낮출 수 있다.9</p>
<p>이 BVH를 구축하고, 광선이 이 트리를 효율적으로 순회하는 과정이야말로 RT 코어나 레이 액셀러레이터가 전담하여 가속하는 가장 중요한 작업 중 하나이다.29 결국, 표준 API는 개발자에게 BVH를 구축하고 활용할 수 있는 일관된 방법을 제공하고, 하드웨어는 그 연산을 가속함으로써 실시간 레이트레이싱 생태계가 완성되는 것이다.</p>
<h2>3.  현대의 하이브리드 렌더링 파이프라인</h2>
<p>하드웨어 가속과 표준 API의 등장은 실시간 레이트레이싱을 ‘가능하게’ 만들었지만, 그것을 ‘실용적으로’ 만드는 데에는 또 다른 단계가 필요했다. 아무리 하드웨어 가속을 하더라도, 장면 전체를 순수 레이트레이싱으로 렌더링하는 것은 여전히 막대한 비용이 든다. 이 문제를 해결하기 위해 현대 실시간 그래픽스는 ’하이브리드 렌더링(Hybrid Rendering)’이라는 매우 실용적인 접근법을 채택했다. 이는 래스터라이제이션의 속도와 레이트레이싱의 품질을 지능적으로 결합하고, AI 기술을 통해 성능 저하를 보완하는 정교한 파이프라인이다.</p>
<h3>3.1  하이브리드 렌더링: 두 세계의 장점 결합</h3>
<h4>3.1.1  래스터라이제이션과 레이트레이싱의 시너지</h4>
<p>하이브리드 렌더링의 핵심 철학은 각 기술이 가장 잘하는 일에 집중하도록 하는 것이다. 래스터라이제이션은 3D 지오메트리를 2D 픽셀로 변환하는, 즉 ‘주 가시성(primary visibility)’ 문제를 해결하는 데 매우 빠르고 효율적이다. 반면, 레이트레이싱은 물리적으로 정확한 빛의 상호작용, 즉 반사, 그림자, 전역 조명 등을 시뮬레이션하는 데 탁월하다.6</p>
<p>하이브리드 파이프라인은 이 두 가지를 결합한다. 먼저 래스터라이제이션을 사용해 장면의 기본 뷰를 빠르게 렌더링하여 ’G-Buffer(Geometry Buffer)’를 생성한다. G-Buffer는 화면의 각 픽셀에 대한 깊이, 표면 노멀, 재질 ID, 색상 등의 정보를 담고 있는 텍스처 집합이다.46 그 후, 이 G-Buffer 정보를 활용하여 레이트레이싱이 꼭 필요한 부분에만 선택적으로 광선을 발사한다. 예를 들어, G-Buffer에서 반사율이 높은 재질로 식별된 픽셀에서만 반사 광선을 쏘거나, 모든 픽셀에서 광원을 향해 그림자 광선을 쏘아 정확한 그림자를 계산하는 식이다. 이 방식은 레이트레이싱의 연산량을 필요한 곳에만 집중시켜 전체적인 성능을 유지하면서도 시각적 품질을 극대화한다.</p>
<p>이러한 하이브리드 모델은 일시적인 과도기적 해결책이 아니라, 두 렌더링 패러다임의 고유한 강점을 지능적으로 활용하는 장기적이고 실용적인 엔지니어링 솔루션으로 자리 잡았다. 래스터라이제이션은 가시성 문제 해결에, 레이트레이싱은 조명 문제 해결에 특화되어 있으며, 이 ’최적의 도구를 최적의 작업에 사용한다’는 원칙이 하이브리드 렌더링의 효율성을 보장한다.7 미래의 그래픽스는 순수 패스 트레이서가 래스터라이제이션을 완전히 대체하기보다는, 두 기술의 경계가 더욱 모호해지는 고도로 통합된 하이브리드 파이프라인의 형태가 될 가능성이 높다.59</p>
<h4>3.1.2  현대 하이브리드 파이프라인 해부</h4>
<p>일반적인 하이브리드 렌더링 프레임은 다음과 같은 단계로 처리된다.</p>
<ol>
<li><strong>래스터라이제이션 패스 (G-Buffer 생성):</strong> 전통적인 래스터라이저를 사용하여 장면의 주 가시성을 결정하고, 각 픽셀의 지오메트리 및 재질 정보를 담은 G-Buffer를 생성한다. 이 단계는 매우 빠르다.</li>
<li><strong>레이트레이싱 패스 (효과 계산):</strong> G-Buffer의 데이터를 입력으로 받아, 특정 효과를 계산하기 위한 광선을 발사한다. 예를 들어, 레이트레이스드 앰비언트 오클루전(RTAO)을 위한 광선, 반사를 위한 광선, 그림자를 위한 광선 등이 각각 또는 통합된 패스로 처리된다. 이 단계에서는 성능을 위해 픽셀당 소수의 광선(예: 1 spp, samples per pixel)만 사용하므로 결과물은 노이즈가 많다.</li>
<li><strong>디노이징 (Denoising):</strong> 레이트레이싱 패스에서 생성된 노이즈가 많은 결과물을 시각적으로 깨끗하게 만들기 위해 정교한 필터링 알고리즘을 적용한다. 이 단계는 최종 이미지 품질에 결정적인 역할을 한다.55</li>
<li><strong>컴포지팅 및 톤 매핑 (Composition &amp; Tone Mapping):</strong> 래스터라이제이션으로 생성된 기본 이미지와, 레이트레이싱 및 디노이징을 거친 조명/반사 정보를 최종적으로 결합한다. 이후 톤 매핑 과정을 거쳐 화면에 표시할 최종 색상을 결정한다.</li>
</ol>
<h4>3.1.3  사례 연구: 언리얼 엔진 5의 루멘(Lumen) 하이브리드 시스템</h4>
<p>언리얼 엔진 5에 도입된 ’루멘(Lumen)’은 현대 하이브리드 렌더링 시스템의 정수를 보여주는 대표적인 사례다.61 루멘은 완전한 동적 전역 조명 및 반사 시스템으로, 여러 수준의 레이트레이싱 기술을 유연하게 결합한다.</p>
<ul>
<li><strong>스크린 트레이스 (Screen Traces):</strong> 루멘은 가장 먼저 화면 공간 내에서 광선을 추적하는 ’스크린 트레이스’를 시도한다. 이는 화면의 뎁스 버퍼를 상대로 광선을 추적하는 방식으로, SSR과 유사하지만 훨씬 더 발전된 형태다. 화면 내에서 해결 가능한 대부분의 간접광과 반사는 이 단계에서 매우 빠르게 처리된다.62</li>
<li><strong>소프트웨어 레이트레이싱 (Software Ray Tracing):</strong> 스크린 트레이스가 실패하면(예: 광선이 화면 밖으로 나가는 경우), 루멘은 ’루멘 씬(Lumen Scene)’이라는 장면의 단순화된 표현을 상대로 광선을 추적한다. 루멘 씬은 메시 디스턴스 필드(Mesh Distance Fields)라는 기술을 사용하여 생성되며, 하드웨어 레이트레이싱 지원 없이도 작동하는 소프트웨어 기반 레이트레이싱이다.62</li>
<li><strong>하드웨어 레이트레이싱 (Hardware Ray Tracing):</strong> 사용자의 GPU가 하드웨어 레이트레이싱을 지원하는 경우, 루멘은 이를 활용하여 훨씬 더 높고 정확한 품질의 결과물을 생성할 수 있다. 특히 반사, 반투명, 스키닝된 메시(캐릭터 등) 렌더링에서 소프트웨어 방식보다 월등한 품질을 보여준다.62</li>
</ul>
<p>이처럼 루멘은 성능과 품질 사이의 균형을 맞추기 위해 가장 저렴한 방법(스크린 트레이스)부터 가장 비싼 방법(하드웨어 레이트레이싱)까지 여러 계층의 기술을 동적으로 선택하고 조합하는 정교한 하이브리드 전략을 사용한다.</p>
<h3>3.2  성능 격차 극복: 렌더링 속의 인공지능</h3>
<p>실시간 레이트레이싱은 필연적으로 막대한 성능 부하를 동반한다. 이를 극복하고 사용자에게 높은 프레임률과 고해상도 경험을 제공하기 위해, 현대 그래픽스 파이프라인은 인공지능(AI) 기술을 핵심 요소로 통합했다. AI 기반 업스케일링과 디노이징 기술은 실시간 레이트레이싱의 실용성을 확보하는 데 결정적인 역할을 했다.</p>
<h4>3.2.1  디노이징과 업스케일링의 필요성</h4>
<p>실시간 레이트레이싱이 직면한 근본적인 딜레마는 ’품질 대 성능’이다. 물리적으로 정확한 이미지를 얻으려면 픽셀당 수백, 수천 개의 광선을 추적해야 하지만, 실시간 프레임률(예: 16.6ms 이내)을 유지하려면 픽셀당 단 한두 개의 광선만 사용할 수 있다.55 이처럼 적은 샘플 수로 렌더링된 이미지는 필연적으로 점박이 형태의 심한 ’노이즈(noise)’를 포함하게 된다.65</p>
<p>또한, 4K와 같은 고해상도에서 레이트레이싱을 활성화하면 최고 사양의 GPU조차도 원활한 프레임률을 유지하기 어렵다.31 따라서 두 가지 보완적인 해결책이 필수적이다.</p>
<ol>
<li><strong>디노이징(Denoising):</strong> 적은 샘플 수로 인해 발생한 노이즈를 제거하여 깨끗한 이미지를 만드는 기술.</li>
<li><strong>업스케일링(Upscaling):</strong> 낮은 해상도에서 게임을 렌더링하여 성능을 확보한 뒤, 이를 고해상도 이미지로 재구성하는 기술.</li>
</ol>
<p>이 두 가지 기술은 이제 AI를 통해 혁신적으로 발전하고 있다.</p>
<h4>3.2.2  NVIDIA DLSS: 슈퍼 레졸루션에서 프레임 생성까지</h4>
<p>NVIDIA의 DLSS(Deep Learning Super Sampling)는 AI 기반 업스케일링 기술의 선두 주자다.</p>
<ul>
<li><strong>DLSS 2 (슈퍼 레졸루션):</strong> DLSS 2는 ‘시간적(temporal)’ 업스케일링 기법이다. 슈퍼컴퓨터로 사전 훈련된 신경망을 사용하여, 현재 프레임의 저해상도 입력과 모션 벡터, 그리고 이전 프레임들의 데이터를 종합적으로 분석하여 고해상도 이미지를 재구성한다.68 DLSS 2는 종종 전통적인 TAA(Temporal Anti-Aliasing)를 적용한 네이티브 해상도 렌더링보다 더 선명하고 안정적인 이미지를 생성하기도 한다.69</li>
<li><strong>DLSS 3 (프레임 생성):</strong> RTX 40 시리즈 GPU부터 도입된 혁신적인 기술로, 단순히 해상도를 높이는 것을 넘어 완전히 새로운 프레임을 AI가 ’생성’하여 삽입한다. GPU 내의 광학 흐름 가속기(Optical Flow Accelerator)를 활용하여 렌더링된 두 프레임 사이의 중간 프레임을 예측하고 생성함으로써, 표시되는 프레임률을 극적으로 향상시킨다.68 이 기술은 CPU 병목 현상이 발생하는 상황에서도 성능을 높일 수 있지만, 약간의 입력 지연(latency)을 추가하기 때문에 이를 완화하기 위해 NVIDIA Reflex 기술과 함께 사용된다.68</li>
</ul>
<h4>3.2.3  DLSS 3.5 레이 재구성: AI 기반 디노이징 패러다임</h4>
<p>DLSS 3.5는 ’레이 재구성(Ray Reconstruction, RR)’이라는 새로운 구성 요소를 도입했다. 이는 업스케일링이 아닌, AI 기반 디노이징 기술에 초점을 맞춘다.68</p>
<p>기존의 레이트레이싱 파이프라인은 반사, 전역 조명 등 각기 다른 효과를 위해 수작업으로 조정된 여러 개의 디노이저를 사용했다. 레이 재구성은 이들을 하나의 통일된 AI 모델로 대체한다.71 이 AI 모델은 DLSS 3보다 5배 더 많은 데이터로 훈련되었으며, 다양한 레이트레이싱 효과의 패턴을 인식하고 이해한다. 이를 통해 시간적/공간적 데이터를 더 지능적으로 활용하여, 기존 디노이저에서 발생하던 고스팅(ghosting)이나 번짐(smearing) 같은 아티팩트를 줄이고 훨씬 더 선명하고 정확한 반사 및 조명 효과를 만들어낸다.72 또한, 여러 디노이저를 하나로 통합함으로써 VRAM 사용량을 줄이고 성능을 소폭 향상시키는 효과도 있다.72</p>
<h4>3.2.4  AMD FSR 및 Intel XeSS: 개방형 및 교차 호환 대안</h4>
<p>NVIDIA DLSS가 독점적인 하드웨어(텐서 코어)를 요구하는 반면, AMD와 Intel은 더 넓은 하드웨어 호환성을 목표로 하는 기술을 제공한다.</p>
<ul>
<li><strong>AMD FSR (FidelityFX Super Resolution):</strong> 오픈 소스 기반의 교차 호환 업스케일링 기술이다. 초기 버전(FSR 1)은 공간적 업스케일러였으나, FSR 2부터는 DLSS 2와 유사한 시간적(temporal) 방식을 채택했다.74 FSR 3는 ’AMD Fluid Motion Frames’라는 프레임 생성 기술을 추가하여 DLSS 3에 대응한다.74 FSR은 AMD GPU뿐만 아니라 NVIDIA, Intel GPU에서도 사용할 수 있어, 레이트레이싱을 폭넓은 하드웨어에서 즐길 수 있게 하는 중요한 역할을 한다.76</li>
<li><strong>Intel XeSS (Xe Super Sampling):</strong> Intel 역시 AI 기반의 교차 호환 업스케일링 솔루션인 XeSS를 제공한다. XeSS는 두 가지 모드로 작동하는데, Intel Arc GPU의 전용 XMX 코어를 활용하여 최상의 품질을 내는 모드와, NVIDIA 및 AMD GPU에서도 작동하는 범용 DP4a 명령어를 사용하는 호환 모드가 있다.77 이미지 품질 면에서 DLSS와 매우 경쟁력 있는 모습을 보여준다.</li>
</ul>
<p>이러한 AI 기반 업스케일링 및 디노이징 기술의 발전은 실시간 레이트레이싱과 떼려야 뗄 수 없는 공생 관계를 형성했다. 레이트레이싱이 만들어낸 ’성능 저하’라는 문제를 AI 기술이 해결하고, 역으로 플레이 가능한 레이트레이싱에 대한 수요가 AI 업스케일링 기술의 혁신을 폭발적으로 견인하고 있다. DLSS 2의 슈퍼 레졸루션에서 DLSS 3의 프레임 생성, 그리고 DLSS 3.5의 레이 재구성으로 이어지는 발전 과정은, AI 기술 혁신의 초점이 이제 실시간 레이트레이싱이 야기하는 특정 문제들을 해결하는 방향으로 명확히 맞춰져 있음을 보여준다.</p>
<h4>3.2.5 표 6.1: 업스케일링 기술 기능 및 호환성 비교 (DLSS, FSR, XeSS)</h4>
<table><thead><tr><th>기능</th><th>NVIDIA DLSS</th><th>AMD FSR</th><th>Intel XeSS</th></tr></thead><tbody>
<tr><td><strong>기반 기술</strong></td><td>AI/신경망 (컨볼루션/트랜스포머)</td><td>고급 시간적 알고리즘 (FSR 1은 공간적)</td><td>AI/신경망</td></tr>
<tr><td><strong>하드웨어 요구사항</strong></td><td>NVIDIA GeForce RTX GPU (텐서 코어). 프레임 생성은 RTX 40 시리즈 이상 필요.</td><td>교차 호환 (AMD, NVIDIA, Intel). 프레임 생성은 더 넓은 호환성 제공.</td><td>교차 호환 (DP4a 모드), 단 Intel Arc GPU (XMX 코어)에 최적화됨.</td></tr>
<tr><td><strong>핵심 차별점</strong></td><td>프레임 생성 (DLSS 3), 레이 재구성 (DLSS 3.5), 다중 프레임 생성 (DLSS 4).</td><td>오픈 소스, 폭넓은 하드웨어 지원.</td><td>AI 기반이면서도 교차 호환성을 유지.</td></tr>
<tr><td><strong>일반적 평가</strong></td><td>이미지 품질 및 재구성 능력에서 선두 주자로 평가받는 경우가 많음.</td><td>뛰어난 호환성. 이미지 품질은 경쟁력 있으나 때때로 DLSS보다 아티팩트가 더 보일 수 있음.</td><td>이미지 품질이 DLSS와 매우 경쟁력 있음, 특히 Arc 하드웨어에서.</td></tr>
</tbody></table>
<h2>4.  응용, 분석 및 미래 전망</h2>
<p>이론과 기술적 기반을 넘어, 실시간 레이트레이싱은 이미 다양한 산업 분야에서 실질적인 변화를 이끌어내고 있다. 인터랙티브 엔터테인먼트부터 영화 제작, 건축, 자동차 산업에 이르기까지, 이 기술은 단순히 시각적 품질을 향상시키는 것을 넘어 창작과 설계의 워크플로우 자체를 혁신하고 있다.</p>
<h3>4.1  레이트레이싱 효과 심층 분석</h3>
<p>실시간 레이트레이싱이 가져온 가장 극적인 변화는 기존 래스터라이제이션 기술이 ’근사’에 의존했던 광학 효과들을 물리적으로 정확하게 시뮬레이션할 수 있게 되었다는 점이다.</p>
<h4>4.1.1  반사: 레이트레이싱 vs. 스크린 스페이스 리플렉션 (SSR)</h4>
<p>전통적인 SSR은 화면에 보이는 픽셀 정보만을 사용하기 때문에, 카메라 시야 밖에 있는 객체나 다른 물체에 가려진 부분은 반사 이미지에 나타나지 않는 명백한 한계가 있었다.10 이는 종종 반사면의 가장자리가 부자연스럽게 잘리거나, 카메라가 움직일 때 반사 이미지가 갑자기 나타나거나 사라지는 시각적 결함으로 이어졌다.</p>
<p>반면, 레이트레이스드 리플렉션(RTR)은 광선을 3D 공간 전체로 추적하기 때문에 이러한 제약에서 자유롭다. 화면 밖에 있는 객체도 정확하게 반사하며, 거울이나 광택 있는 금속 표면이 서로를 비추는 ‘상호 반사(inter-reflection)’ 현상까지 자연스럽게 구현한다.80 이는 유리, 물, 광택 있는 바닥 등 반사 표면이 많은 환경에서 장면의 깊이와 사실감을 극적으로 향상시킨다.82</p>
<h4>4.1.2  그림자: 레이트레이싱 vs. 섀도우 매핑</h4>
<p>래스터라이제이션의 섀도우 매핑은 그림자를 미리 그려놓은 텍스처(섀도우 맵)에 의존하기 때문에 여러 아티팩트를 유발한다. 섀도우 맵의 해상도가 낮으면 그림자 경계가 톱니처럼 각져 보이고(‘앨리어싱’), 바이어스(bias) 값 설정이 잘못되면 그림자가 물체에서 떠 보이는 ‘피터 패닝’ 현상이 발생한다.11</p>
<p>레이트레이스드 섀도우는 이러한 문제를 근본적으로 해결한다. 광선이 물체 표면에서 광원까지의 경로를 직접 확인하므로, 그림자는 항상 지오메트리에 완벽하게 접촉한다.11 더 중요한 것은, 점 광원이 아닌 면적을 가진 광원(area light)을 시뮬레이션하여 물리적으로 정확한 ’소프트 섀도우’를 자연스럽게 생성한다는 점이다. 그림자 가장자리가 물체와의 거리에 따라 부드럽게 퍼지는 ‘반영(penumbra)’ 효과는 섀도우 매핑으로는 구현하기 매우 까다롭지만, 레이트레이싱에서는 광원의 크기에 따라 자연스럽게 나타나는 결과물이다.11</p>
<h4>4.1.3  전역 조명 및 앰비언트 오클루전: 레이트레이싱 vs. 베이크드 라이팅 및 SSAO</h4>
<p>전역 조명(GI)은 빛이 여러 표면에 반사되며 장면 전체를 비추는 현상으로, 사실감의 핵심 요소다. 전통적으로 실시간 GI는 불가능했기 때문에, 정적인 장면에 대해서는 조명 정보를 미리 계산하여 텍스처에 구워 넣는 ‘베이크드 라이팅(Baked Lighting)’ 기법이 사용되었다.84 이 방식은 고품질의 정적 조명을 제공하지만, 조명이나 물체가 움직이는 동적인 환경에서는 전혀 대응할 수 없는 치명적인 단점이 있다.85</p>
<p>레이트레이스드 글로벌 일루미네이션(RTGI)은 매 프레임 빛의 반사를 실시간으로 계산하여 완전한 동적 GI를 구현한다.87 문이 열리거나, 조명이 켜지거나, 물체가 파괴될 때 주변의 간접광이 즉각적으로 반응하여 장면의 생동감과 상호작용성을 극대화한다.22</p>
<p>앰비언트 오클루전(AO)은 구석이나 틈새처럼 주변광이 닿기 어려운 부분이 어두워지는 현상을 표현하는 기법이다. 스크린 스페이스 앰비언트 오클루전(SSAO)은 SSR과 마찬가지로 화면의 깊이 정보만을 사용하기 때문에 부정확하고 아티팩트가 발생하기 쉽다.88 반면, 레이트레이스드 앰비언트 오클루전(RTAO)은 광선을 쏴서 실제 지오메트리에 의한 차폐를 계산하므로 훨씬 더 정확하고 안정적인 접촉 그림자를 생성하여 물체를 환경에 자연스럽게 녹아들게 한다.89</p>
<p>이러한 물리 기반 시뮬레이션은 개발자의 작업 방식을 단순화하는 의외의 이점을 가져온다. 래스터라이제이션 환경에서 반쯤 사실적인 그림자를 구현하기 위해 개발자들은 ’계단식 섀도우 맵(Cascaded Shadow Maps)’과 같은 복잡하고 다단계적인 기법을 사용해야 했다.11 반사, 그림자, GI 각각에 대해 별도의 복잡한 시스템과 아티팩트를 회피하기 위한 ’꼼수’들이 필요했다. 하지만 레이트레이싱 환경에서는 개발자가 물리적으로 올바른 광원과 재질을 설정하기만 하면, 이러한 복잡한 효과들이 하나의 통일된 원리, 즉 빛의 시뮬레이션을 통해 자연스럽게 파생된다. 이는 예술적 ’꼼수’나 효과별 파이프라인의 필요성을 줄여, 개발 시간을 단축하고 아티스트가 창작에 더 집중할 수 있게 해준다.91</p>
<h3>4.2  인터랙티브 엔터테인먼트 사례 연구</h3>
<p>실시간 레이트레이싱 기술은 지난 몇 년간 AAA 게임들을 통해 그 가능성과 한계를 명확히 보여주며 빠르게 발전해왔다. 주요 타이틀들의 구현 방식을 연대순으로 분석하면 기술의 뚜렷한 진화 궤적을 확인할 수 있다.</p>
<h4>4.2.1  <em>Control</em> (2019): 다중 RT 효과의 선구적 구현</h4>
<p>Remedy Entertainment의 <em>Control</em>은 실시간 레이트레이싱의 잠재력을 대중에게 각인시킨 최초의 게임 중 하나다. 이 게임은 DXR API를 활용하여 레이트레이스드 반사, 투명 반사, 간접 난반사 조명, 접촉 그림자 등 포괄적인 RT 효과 모음을 구현했다.66</p>
<p><em>Control</em>은 광택 있는 바닥과 유리창이 많은 실내 환경을 배경으로, RT 반사가 어떻게 장면의 사실감을 극적으로 향상시키는지를 명확히 보여주었다. 하지만 동시에, 이러한 여러 효과를 중첩했을 때 발생하는 막대한 성능 저하를 통해 실시간 레이트레이싱의 높은 비용과 DLSS와 같은 업스케일링 기술의 필요성을 명확히 드러낸 사례이기도 하다.66</p>
<p><em>Control</em>은 하이브리드 렌더링의 가능성을 입증한 ’개념 증명’과 같은 타이틀이었다.</p>
<h4>4.2.2  <em>Cyberpunk 2077</em> (2020/2023): “오버드라이브 모드“를 통한 완전한 패스 트레이싱으로의 도약</h4>
<p>CD Projekt Red의 <em>Cyberpunk 2077</em>은 출시 초기부터 반사, 그림자, 조명 등 강력한 하이브리드 RT 기능을 선보였다.94 하지만 진정한 기술적 도약은 2023년 “레이트레이싱: 오버드라이브 모드” 업데이트를 통해 이루어졌다. 이 모드는 게임 그래픽 역사상 최초로 AAA급 오픈 월드 게임에 ’완전한 패스 트레이싱(Full Path Tracing)’을 ‘기술 프리뷰’ 형태로 도입한 것이다.26</p>
<p>오버드라이브 모드에서는 기존 하이브리드 방식처럼 반사, 그림자, GI를 별개의 효과로 계산하는 대신, 이 모든 것을 하나의 통일된 물리 기반 빛 시뮬레이션으로 처리한다. 그 결과, 네온사인이 가득한 나이트 시티의 조명은 훨씬 더 자연스럽고 통합된 모습으로 표현된다. 하지만 이는 현존하는 가장 극심한 성능 부하를 유발하는 렌더링 모드이기도 하다. 최고 사양의 GPU인 RTX 4090조차도 이 모드를 원활하게 구동하기 위해서는 DLSS 3 프레임 생성과 DLSS 3.5 레이 재구성과 같은 AI 기술에 전적으로 의존해야 한다.26</p>
<p><em>Cyberpunk 2077</em>의 오버드라이브 모드는 실시간 패스 트레이싱이 도달할 수 있는 시각적 충실도의 새로운 기준을 제시했다.</p>
<h4>4.2.3  <em>Alan Wake 2</em> (2023): 분위기적 스토리텔링을 위한 패스 트레이싱</h4>
<p><em>Control</em>의 개발사 Remedy는 <em>Alan Wake 2</em>를 통해 패스 트레이싱을 기술적 과시가 아닌, 특정한 예술적, 분위기적 목표를 달성하기 위한 도구로 활용하는 성숙한 모습을 보여주었다.101 이 게임은 어둡고 음산한 숲과 기괴한 도시 풍경 속에서 빛과 그림자를 활용하여 공포와 서스펜스를 극대화한다.</p>
<p><em>Alan Wake 2</em>의 패스 트레이싱은 조명과 반사를 완전하게 시뮬레이션하지만, <em>Cyberpunk 2077</em>과 달리 엔진의 기존 GI 시스템과 병행하여 작동하는 하이브리드 방식으로 구현되었다. 이로 인해 어떤 장면에서는 패스 트레이싱의 효과가 더 미묘하게 나타나기도 하지만, 미시적인 수준에서의 빛의 상호작용은 훨씬 더 정교하게 표현된다.101 또한 이 게임은 메시 셰이더(Mesh Shaders)와 같은 최신 GPU 아키텍처 기능을 적극적으로 활용하며, 패스 트레이싱과 결합하여 현존하는 가장 높은 사양을 요구하는 게임 중 하나가 되었다. 이는 업스케일링과 레이 재구성 기술이 이제 선택이 아닌 필수임을 보여주는 사례다.103</p>
<h4>4.2.4  <em>Minecraft with RTX</em> (2020): 양식화된 세계를 변혁하는 패스 트레이싱</h4>
<p><em>Minecraft with RTX</em>는 패스 트레이싱이 사실적인 그래픽 스타일에만 국한되지 않음을 보여주는 독특하고 중요한 사례다.107 블록으로 이루어진 단순하고 양식화된 세계에 완전한 패스 트레이싱을 적용하자, 게임의 미학 전체가 근본적으로 변모했다.</p>
<p>단순한 텍스처의 블록들이 사실적인 빛과 상호작용하면서 이전에는 상상할 수 없었던 시각적 깊이를 갖게 되었다. 물은 실제처럼 주변 환경을 반사하고 빛을 굴절시키며, 용암 블록은 주변에 강렬한 붉은빛을 발산하고, 나뭇잎 사이로 햇빛이 스며들어 부드러운 그림자를 드리운다.107 이는 패스 트레이싱이 단순히 그래픽을 ’개선’하는 것이 아니라, 게임의 분위기와 경험 자체를 ’재창조’할 수 있는 강력한 도구임을 입증했다.</p>
<p>이러한 사례들은 명확한 기술적 진화 과정을 보여준다. 2019년 <em>Control</em>이 다중 효과 하이브리드 시스템의 가능성을 열었고, 2020년 <em>Minecraft RTX</em>가 완전한 패스 트레이싱의 변혁적 힘을 보여주었으며, 2023년 <em>Cyberpunk 2077</em>과 <em>Alan Wake 2</em>는 가장 복잡한 AAA 게임 환경에 패스 트레이싱을 적용하며 기술의 최전선을 밀어 올렸다. 이 빠른 성숙 과정은 하드웨어, API, 그리고 DLSS와 같은 AI 기술의 발전이 함께 이루어낸 결과다.</p>
<h4>4.2.5 표 8.1: 주요 게임 타이틀의 레이트레이싱 구현 비교</h4>
<table><thead><tr><th>게임 타이틀</th><th>주요 RT/PT 구현 효과</th><th>일반적인 성능 영향</th><th>핵심 시각적 기여 / 의의</th></tr></thead><tbody>
<tr><td>*<strong>Control*</strong></td><td>반사, 투명 반사, 간접 난반사 조명, 접촉 그림자</td><td>높음; 다중 효과의 누적 비용으로 DLSS의 필요성 입증</td><td>주요 타이틀에서 포괄적인 DXR 기능 세트를 선구적으로 사용</td></tr>
<tr><td>*<strong>Cyberpunk 2077 (Overdrive)*</strong></td><td>완전한 패스 트레이싱 (그림자, 반사, GI 통합), RTX 다이렉트 일루미네이션 (RTXDI)</td><td>극심함; 최고 사양 하드웨어를 제외하고는 DLSS 3/3.5가 필수적임</td><td>주요 오픈 월드 게임 최초로 완전한 패스 트레이싱 모드를 구현하여 시각적 충실도의 새로운 기준 제시</td></tr>
<tr><td>*<strong>Alan Wake 2*</strong></td><td>완전한 패스 트레이싱 (High 프리셋), 다중 반사 간접 조명 및 반사 포함</td><td>극심함; 메시 셰이더 지원이 필요하며 현재까지 가장 사양이 높은 게임 중 하나</td><td>분위기 및 공포 효과를 위해 패스 트레이싱을 사용한 걸작으로, 기존 GI 시스템과 혼합</td></tr>
<tr><td>*<strong>Minecraft with RTX*</strong></td><td>모든 조명, 그림자, 반사에 대한 완전한 패스 트레이싱</td><td>매우 높음, 그러나 게임의 전체적인 미학을 변형시킴</td><td>비사실적이고 양식화된 세계에 패스 트레이싱이 미치는 변혁적인 힘을 입증</td></tr>
</tbody></table>
<h3>4.3  게이밍을 넘어서는 레이트레이싱의 응용</h3>
<p>실시간 레이트레이싱의 영향력은 게임 산업에만 머무르지 않는다. 물리적으로 정확한 빛 시뮬레이션을 실시간으로 구현하는 능력은 전통적으로 막대한 렌더링 시간을 감수해야 했던 여러 전문 산업 분야의 워크플로우를 근본적으로 바꾸고 있다.</p>
<h4>4.3.1  영화 및 애니메이션: 실시간과 오프라인 렌더링의 경계 붕괴</h4>
<p>전통적인 영화 및 애니메이션 제작 파이프라인에서 시각 효과(VFX)나 CG 장면의 최종 결과물을 확인하기까지는 프레임당 수 시간에서 수일에 달하는 ‘오프라인 렌더링’ 시간을 기다려야 했다. 이는 창의적인 수정과 반복 작업을 매우 느리고 비용이 많이 드는 과정으로 만들었다.</p>
<p>언리얼 엔진(Unreal Engine)과 같은 게임 엔진에 실시간 레이트레이싱이 통합되면서, 이러한 패러다임이 바뀌고 있다.22 ’가상 프로덕션(Virtual Production)’과 ‘사전 시각화(Pre-visualization)’ 단계에서 감독과 아티스트들은 촬영 현장에서 거의 최종 품질에 가까운 렌더링 결과물을 즉시 확인할 수 있다.22 예를 들어, LED 월을 배경으로 배우가 연기할 때, 배경 CG 환경의 조명과 반사가 실시간으로 배우에게 정확하게 반영된다. 이를 통해 조명, 카메라 앵글, 재질 등을 즉각적으로 수정하고 창의적인 결정을 신속하게 내릴 수 있게 되어, 제작 기간을 단축하고 결과물의 완성도를 높일 수 있다.</p>
<h4>4.3.2  건축 및 제품 시각화: 실시간 반복 작업과 사실성</h4>
<p>건축가와 제품 디자이너들은 고객에게 자신들의 비전을 설득력 있게 전달하기 위해 사실적인 시각화 자료에 크게 의존한다. 과거에는 몇 장의 정적인 렌더링 이미지나 미리 제작된 애니메이션에 의존해야 했다.</p>
<p>실시간 레이트레이싱은 이러한 과정을 상호작용이 가능한 경험으로 바꾸었다.114 건축가는 고객과 함께 가상 건물 내부를 걸어 다니며, 실시간으로 시간대를 바꿔 햇빛이 내부 공간에 미치는 영향을 정확하게 시뮬레이션하거나(sun studies), 벽의 재질이나 가구 배치를 즉석에서 변경하고 그 결과를 사실적인 조명 아래에서 바로 확인할 수 있다.113 이는 고객의 이해도를 높이고 피드백을 즉각적으로 반영하여 설계 과정을 효율화하며, 비용이 많이 드는 물리적 목업(mock-up) 제작의 필요성을 줄여준다.</p>
<h4>4.3.3  자동차 및 ADAS 시뮬레이션: 물리적으로 정확한 센서 모델링</h4>
<p>실시간 레이트레이싱의 가장 과학적인 응용 분야 중 하나는 자율 주행 시스템 개발이다. 첨단 운전자 보조 시스템(ADAS)과 자율 주행 차량에 탑재된 카메라, 라이다(LiDAR), 레이더와 같은 센서들은 인간의 눈과는 다른 방식으로 세상을 인식한다.</p>
<p>레이트레이싱 기술은 이러한 센서들이 방출하는 신호(빛, 전파 등)가 차량, 보행자, 도로 시설물 등과 어떻게 상호작용하는지를 물리적으로 정확하게 시뮬레이션하는 데 사용된다.119 예를 들어, 저조도 환경이나 여러 광원이 복잡하게 얽힌 터널 출구 등 실제 도로에서 마주칠 수 있는 까다로운 시나리오를 가상 환경에서 완벽하게 재현할 수 있다.120 이를 통해 실제 차량 테스트의 위험과 비용 없이, 수백만 킬로미터에 달하는 주행 데이터를 생성하여 ADAS 및 자율 주행 알고리즘을 훈련하고 검증할 수 있다. 이는 기술 개발을 가속화하고 안전성을 확보하는 데 결정적인 역할을 한다.</p>
<p>이처럼 다양한 산업 분야에서 실시간 레이트레이싱이 가져온 가장 심오한 변화는 최종 결과물의 시각적 품질 향상을 넘어선다. 진정한 혁신은 창의적이고 산업적인 ‘워크플로우’ 자체의 변화에 있다. 전통적인 파이프라인에 존재했던 ’창의적 결정’과 ‘결과물 확인’ 사이의 길고 비용이 많이 들었던 지연 시간을 붕괴시킨 것이 핵심이다.110 이 ’즉각적인 피드백 루프’는 창의성을 가속화하고, 비용을 절감하며, 산업 전반의 협업 방식을 바꾸는 패러다임 전환을 이끌고 있다. 최종 픽셀은 그 결과물일 뿐, 과정의 변화가 진정한 혁명이다.</p>
<h3>4.4  결론 및 미래 전망</h3>
<h4>4.4.1  현 상태 종합 및 주요 과제</h4>
<p>현재 실시간 레이트레이싱은 ’하이브리드 렌더링’이 지배적인 패러다임으로 자리 잡았다. 이는 전용 하드웨어 가속기에 의해 가능해졌으며, AI 기반 업스케일링 및 디노이징 기술에 크게 의존하고 있다. 이 기술 생태계는 불과 몇 년 만에 놀라운 시각적 도약을 이루었지만, 여전히 해결해야 할 과제들이 남아있다.</p>
<p>가장 큰 과제는 여전히 ’성능 비용’이다.121 최고 사양의 하드웨어를 제외한 대부분의 시스템에서는 고품질 레이트레이싱을 위해 해상도나 다른 그래픽 설정을 타협해야 한다. 다양한 성능의 하드웨어에 걸쳐 일관된 경험을 제공하도록 확장하는 것(scalability)은 개발자들에게 큰 숙제다.92 또한, 물리적으로 정확한 조명은 때때로 아티스트가 의도한 예술적 방향과 다를 수 있어, 기술적 정확성과 예술적 제어를 조화시키는 새로운 창작 방식에 대한 고민도 필요하다.123</p>
<h4>4.4.2  앞으로의 길: SIGGRAPH와 산업 동향에서 본 통찰</h4>
<p>SIGGRAPH와 같은 세계 최고 수준의 컴퓨터 그래픽스 학회는 실시간 렌더링의 미래를 엿볼 수 있는 중요한 지표다.124 SIGGRAPH 2024와 같은 최근 동향을 살펴보면, 업계의 관심사는 단순히 레이트레이싱의 성능을 높이는 것을 넘어, 이 기술을 AI, 몰입형 기술(AR/VR), 인터랙티브 시뮬레이션과 어떻게 융합할 것인지에 맞춰져 있다.125 특히 매년 개최되는 ‘Advances in Real-Time Rendering in Games’ 강좌는 업계 최전선에서 상용화되고 있는 기술들을 공유하는 장으로, GPU 기반 렌더링 파이프라인의 효율화, 머신러닝을 활용한 조명 개선, 모바일 렌더링 최적화 등이 주요 주제로 다뤄지고 있다.126 이는 미래의 실시간 그래픽스가 더욱 지능적이고 접근성이 높아지는 방향으로 나아가고 있음을 시사한다.</p>
<h4>4.4.3  최종 목표: 완전한 패스 트레이싱은 래스터라이제이션을 대체할 것인가?</h4>
<p>궁극적으로 모든 픽셀이 완전한 패스 트레이싱으로 렌더링되는 시대가 올 것인가? 현재까지의 증거들을 종합해 볼 때, 그럴 가능성은 낮아 보인다. 패스 트레이싱이 조명 시뮬레이션의 미래임은 분명하지만, 래스터라이제이션은 주 가시성을 결정하는 데 있어 압도적인 속도와 효율성을 가지고 있다.57</p>
<p>따라서 미래는 하나의 기술이 다른 기술을 완전히 대체하는 것이 아니라, 더욱 깊고 유기적으로 통합된 ’통합 파이프라인(Unified Pipeline)’의 형태가 될 것이다. 하드웨어는 통합된 셰이더 아키텍처로 발전하고 59, API는 래스터, 컴퓨트, 레이트레이싱을 동등한 파트너로 취급하며 46, AI 기술은 이들 사이의 성능 격차를 메우는 접착제 역할을 할 것이다. 언리얼 엔진 5의 루멘 시스템이 보여주듯, 미래의 엔진은 개발자에게 특정 기술의 선택을 강요하는 대신, 원하는 품질 수준을 요청받아 가장 효율적인 래스터라이제이션, 레이트레이싱, AI 재구성의 조합을 지능적으로 선택하여 결과물을 만들어낼 것이다.62 이것이 바로 실시간 렌더링 기술이 나아갈 진정한 ’최종 목표’일 것이다.</p>
<h2>5. 참고 자료</h2>
<ol>
<li>렌더링 파이프라인 간단 정리 - Blemish - 티스토리, accessed July 4, 2025, https://jeonhw.tistory.com/27</li>
<li>렌더링 - 나무위키, accessed July 4, 2025, <a href="https://namu.wiki/w/%EB%A0%8C%EB%8D%94%EB%A7%81">https://namu.wiki/w/%EB%A0%8C%EB%8D%94%EB%A7%81</a></li>
<li>3D 기술은 사라지지 않았다! - allscience - 티스토리, accessed July 4, 2025, https://allsicence.tistory.com/87</li>
<li>레이트레이싱 VS 레스터라이제이션, 승자는?! - 재능넷, accessed July 4, 2025, https://www.jaenung.net/tree/24462</li>
<li>UI/UX 디자이너를 위한 가이드 - 래스터화(Rasterization), accessed July 4, 2025, https://mesign.tistory.com/8</li>
<li>What’s the Difference Between Ray Tracing, Rasterization? - NVIDIA Blog, accessed July 4, 2025, https://blogs.nvidia.com/blog/whats-difference-between-ray-tracing-rasterization/</li>
<li>An Overview of the Rasterization Algorithm - Scratchapixel, accessed July 4, 2025, https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/overview-rasterization-algorithm.html</li>
<li>래스터화 - 위키백과, 우리 모두의 백과사전, accessed July 4, 2025, <a href="https://ko.wikipedia.org/wiki/%EB%9E%98%EC%8A%A4%ED%84%B0%ED%99%94">https://ko.wikipedia.org/wiki/%EB%9E%98%EC%8A%A4%ED%84%B0%ED%99%94</a></li>
<li>Ray Tracing vs Rasterization: Unpacking Computer Graphics Rendering - Cable Matters, accessed July 4, 2025, https://www.cablematters.com/Blog/Computer-Accessories/ray-tracing-vs-rasterization</li>
<li>Screen Space Reflection Techniques - oURspace - University of Regina, accessed July 4, 2025, https://ourspace.uregina.ca/items/3072d67d-205a-49b6-aa81-c3409726674d</li>
<li>Implementing fast, ray traced soft shadows in a game engine - Imagination Blog, accessed July 4, 2025, https://blog.imaginationtech.com/implementing-fast-ray-traced-soft-shadows-in-a-game-engine/</li>
<li>Shadow Mapping vs Ray Tracing: Revolutionizing Visual Rendering for Developers, accessed July 4, 2025, https://www.byteplus.com/en/topic/109804</li>
<li>Ray-tracing soft shadows in real-time | by Alexander Wester | Medium, accessed July 4, 2025, https://medium.com/@alexander.wester/ray-tracing-soft-shadows-in-real-time-a53b836d123b</li>
<li>sogi3d.tistory.com, accessed July 4, 2025, <a href="https://sogi3d.tistory.com/entry/RayTracing%EC%9D%98-%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8-%EA%B0%9C%EB%85%90%EA%B3%BC-%EB%8B%A8%EA%B3%84#:~:text=RayTracing%EC%9D%98%20%EC%9B%90%EB%A6%AC&amp;text=Ray%EB%A5%BC%20%EB%94%B0%EB%9D%BC%20%EB%AC%BC%EC%B2%B4%EC%99%80,%ED%98%84%EC%8B%A4%EC%A0%81%EC%9D%B8%20%EC%9D%B4%EB%AF%B8%EC%A7%80%EB%A5%BC%20%EB%A7%8C%EB%93%A4%EC%96%B4%EB%83%85%EB%8B%88%EB%8B%A4.&amp;text=%EA%B0%80%EC%83%81%20%ED%99%98%EA%B2%BD%20%EB%82%B4%EC%97%90%EC%84%9C%20%EB%B9%9B,Ray%EC%9D%98%20%EC%97%AD%EC%B6%94%EC%A0%81%EC%9E%85%EB%8B%88%EB%8B%A4.">https://sogi3d.tistory.com/entry/RayTracing%EC%9D%98-%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8-%EA%B0%9C%EB%85%90%EA%B3%BC-%EB%8B%A8%EA%B3%84#:~:text=RayTracing%EC%9D%98%20%EC%9B%90%EB%A6%AC&amp;text=Ray%EB%A5%BC%20%EB%94%B0%EB%9D%BC%20%EB%AC%BC%EC%B2%B4%EC%99%80,%ED%98%84%EC%8B%A4%EC%A0%81%EC%9D%B8%20%EC%9D%B4%EB%AF%B8%EC%A7%80%EB%A5%BC%20%EB%A7%8C%EB%93%A4%EC%96%B4%EB%83%85%EB%8B%88%EB%8B%A4.&amp;text=%EA%B0%80%EC%83%81%20%ED%99%98%EA%B2%BD%20%EB%82%B4%EC%97%90%EC%84%9C%20%EB%B9%9B,Ray%EC%9D%98%20%EC%97%AD%EC%B6%94%EC%A0%81%EC%9E%85%EB%8B%88%EB%8B%A4.</a></li>
<li>그래픽 신세계! 레이 트레이싱 한번에 이해하기! - YouTube, accessed July 4, 2025, https://www.youtube.com/watch?v=ykVGLdHJaoE</li>
<li>RayTracing의 기본적인 개념과 단계 :: Dev Loves Art,소기쓰리디, accessed July 4, 2025, <a href="https://sogi3d.tistory.com/entry/RayTracing%EC%9D%98-%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8-%EA%B0%9C%EB%85%90%EA%B3%BC-%EB%8B%A8%EA%B3%84">https://sogi3d.tistory.com/entry/RayTracing%EC%9D%98-%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8-%EA%B0%9C%EB%85%90%EA%B3%BC-%EB%8B%A8%EA%B3%84</a></li>
<li>Ray tracing (graphics) - Wikipedia, accessed July 4, 2025, https://en.wikipedia.org/wiki/Ray_tracing_(graphics)</li>
<li>레이 트레이싱 구현기 2-2. Pinhole Camera의 구조, 원리 그리고 구현 - velog, accessed July 4, 2025, <a href="https://velog.io/@hochul/%EB%A0%88%EC%9D%B4-%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%8B%B1-%EA%B5%AC%ED%98%84%EA%B8%B0-1-2.-Pinhole-Camera%EC%9D%98-%EA%B5%AC%EC%A1%B0-%EC%9B%90%EB%A6%AC-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EB%A0%88%EC%9D%B4%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%8B%B1%EC%9D%98-%EC%A2%85%EB%A5%98">https://velog.io/@hochul/%EB%A0%88%EC%9D%B4-%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%8B%B1-%EA%B5%AC%ED%98%84%EA%B8%B0-1-2.-Pinhole-Camera%EC%9D%98-%EA%B5%AC%EC%A1%B0-%EC%9B%90%EB%A6%AC-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EB%A0%88%EC%9D%B4%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%8B%B1%EC%9D%98-%EC%A2%85%EB%A5%98</a></li>
<li>레이 트레이싱 (1), accessed July 4, 2025, https://jebae.github.io/ray-tracing-principle/</li>
<li>레이 트레이싱이 인상적인 3D 렌더링을 발전시킨 과정 소개 - GarageFarm, accessed July 4, 2025, https://garagefarm.net/ko-blog/how-ray-tracing-has-elevated-the-already-impressive-effects-of-3d-rendering</li>
<li>레이트레이싱, 패스 트레이싱, 디노이징 - Hybrid3D, accessed July 4, 2025, https://blog.hybrid3d.dev/2019-11-15-raytracing-pathtracing-denoising</li>
<li>What is real-time ray tracing? - Unreal Engine, accessed July 4, 2025, https://www.unrealengine.com/en-US/explainers/ray-tracing/what-is-real-time-ray-tracing</li>
<li>Rasterization, Ray Tracing, Path Tracing &amp; Lumen – Explained for Beginners - YouTube, accessed July 4, 2025, https://www.youtube.com/watch?v=BFYC9usSTsI</li>
<li>Path Tracing vs Ray Tracing EXPLAINED in 2 Minutes! - YouTube, accessed July 4, 2025, https://www.youtube.com/watch?v=NbBUZ2yCf3Y</li>
<li>Difference between Real Time vs Path Traced - NVIDIA Developer Forums, accessed July 4, 2025, https://forums.developer.nvidia.com/t/difference-between-real-time-vs-path-traced/213210</li>
<li>Cyberpunk 2077 RT Overdrive Path Tracing: Full Path Tracing, Fully Unnecessary, accessed July 4, 2025, https://www.tomshardware.com/features/cyberpunk-2077-rt-overdrive-path-tracing-full-path-tracing-fully-unnecessary</li>
<li>What’s the difference between path tracing, ray tracing and photon, accessed July 4, 2025, https://news.ycombinator.com/item?id=9994935</li>
<li>news.ycombinator.com, accessed July 4, 2025, <a href="https://news.ycombinator.com/item?id=9994935#:~:text=Ray%20tracing%20simply%20is%20a,solve%20the%20light%20transport%20integral.">https://news.ycombinator.com/item?id=9994935#:~:text=Ray%20tracing%20simply%20is%20a,solve%20the%20light%20transport%20integral.</a></li>
<li>RTX란 무엇인가 3편 - GeForce RTX 튜링 아키텍처, accessed July 4, 2025, https://sausagetaste.github.io/2021/03/01/what_is_rtx_3.html</li>
<li>(PDF) A detailed study of ray tracing performance: render time and energy cost, accessed July 4, 2025, https://www.researchgate.net/publication/324840216_A_detailed_study_of_ray_tracing_performance_render_time_and_energy_cost</li>
<li>Remedy Shows The Preliminary Cost of NVIDIA RTX Ray Tracing Effects in Performance, accessed July 4, 2025, https://www.techpowerup.com/248649/remedy-shows-the-preliminary-cost-of-nvidia-rtx-ray-tracing-effects-in-performance</li>
<li>What Is NVIDIA Turing Architecture | HP® Tech Takes, accessed July 4, 2025, https://www.hp.com/us-en/shop/tech-takes/nvidia-turing-architecture-graphics-card</li>
<li>NVIDIA TURING GPU ARCHITECTURE, accessed July 4, 2025, https://images.nvidia.com/aem-dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf</li>
<li>Former NVIDIA GPU Architect: What is RT Core in Turing architecture? - Reddit, accessed July 4, 2025, https://www.reddit.com/r/nvidia/comments/97qogl/former_nvidia_gpu_architect_what_is_rt_core_in/</li>
<li>How do RT cores work? - Raytracing - NVIDIA Developer Forums, accessed July 4, 2025, https://forums.developer.nvidia.com/t/how-do-rt-cores-work/314960</li>
<li>실시간 레이 트레이싱을 지원하는 획기적인 GPU 아키텍처 ‘튜링(Turing)’ 발표 - NVIDIA 블로그, accessed July 4, 2025, https://blogs.nvidia.co.kr/blog/turing/</li>
<li>Real-Time Ray Tracing Realized: RTX Brings the Future of Graphics to Millions, accessed July 4, 2025, https://blogs.nvidia.com/blog/rtx-real-time-ray-tracing/</li>
<li>RDNA (microarchitecture) - Wikipedia, accessed July 4, 2025, https://en.wikipedia.org/wiki/RDNA_(microarchitecture)</li>
<li>AMD to Redesign Ray Tracing Hardware on RDNA 4 | TechPowerUp, accessed July 4, 2025, https://www.techpowerup.com/322081/amd-to-redesign-ray-tracing-hardware-on-rdna-4?cp=5</li>
<li>RDNA 3 dedicated hardware RT cores : r/Amd - Reddit, accessed July 4, 2025, https://www.reddit.com/r/Amd/comments/10ahfsl/rdna_3_dedicated_hardware_rt_cores/</li>
<li>Exynos 2200 | Mobile Processor | Samsung Semiconductor Global, accessed July 4, 2025, https://semiconductor.samsung.com/processor/mobile-processor/exynos-2200/</li>
<li>Samsung Announces Game Changing Exynos 2200, accessed July 4, 2025, https://semiconductor.samsung.com/news-events/news/samsung-announces-game-changing-exynos-2200/</li>
<li>Samsung Introduces Game Changing Exynos 2200 Processor With Xclipse GPU Powered by AMD RDNA 2 Architecture, accessed July 4, 2025, https://news.samsung.com/global/samsung-introduces-game-changing-exynos-2200-processor-with-xclipse-gpu-powered-by-amd-rdna-2-architecture</li>
<li>Just In: Old Exynos chip beats newest Snapdragon in raytracing performance! - SamMobile, accessed July 4, 2025, https://www.sammobile.com/news/exynos-2200-beats-snapdragon-8-gen-2-raytracing-performance/</li>
<li>DirectX Raytracing - Wikipedia, accessed July 4, 2025, https://en.wikipedia.org/wiki/DirectX_Raytracing</li>
<li>Introduction to NVIDIA RTX and DirectX Ray Tracing, accessed July 4, 2025, https://developer.nvidia.com/blog/introduction-nvidia-rtx-directx-ray-tracing/</li>
<li>DirectX Raytracing (DXR) Functional Spec - Microsoft Open Source, accessed July 4, 2025, https://microsoft.github.io/DirectX-Specs/d3d/Raytracing.html</li>
<li>DX12 Raytracing tutorial - Part 1 - NVIDIA Developer, accessed July 4, 2025, https://developer.nvidia.com/rtx/raytracing/dxr/dx12-raytracing-tutorial-part-1</li>
<li>A Gentle Introduction To DirectX Raytracing, accessed July 4, 2025, http://cwyman.org/code/dxrTutors/dxr_tutors.md.html</li>
<li>Ray Tracing - Vulkan Documentation, accessed July 4, 2025, https://docs.vulkan.org/guide/latest/extensions/ray_tracing.html</li>
<li>NVIDIA Vulkan Ray Tracing Tutorial, accessed July 4, 2025, https://nvpro-samples.github.io/vk_raytracing_tutorial_KHR/</li>
<li>Vulkan Ray Tracing Best Practices for Hybrid Rendering - Khronos Blog, accessed July 4, 2025, https://www.khronos.org/blog/vulkan-ray-tracing-best-practices-for-hybrid-rendering</li>
<li>Why is ray tracing generally considered slower than rasterization? : r/computergraphics, accessed July 4, 2025, https://www.reddit.com/r/computergraphics/comments/uuzwlz/why_is_ray_tracing_generally_considered_slower/</li>
<li>What is the role of RT Cores in real-time ray tracing and graphics rendering?, accessed July 4, 2025, <a href="https://massedcompute.com/faq-answers/?question=What+is+the+role+of+RT+Cores+in+real-time+ray+tracing+and+graphics+rendering?">https://massedcompute.com/faq-answers/?question=What%20is%20the%20role%20of%20RT%20Cores%20in%20real-time%20ray%20tracing%20and%20graphics%20rendering?</a></li>
<li>Adventures in Hybrid Rendering - Dihara Wijetunga, accessed July 4, 2025, https://diharaw.github.io/post/adventures_in_hybrid_rendering/</li>
<li>Hybrid Rendering for Real-Time Ray Tracing: High-Quality and Real-Time Rendering with DXR and Other APIs - ResearchGate, accessed July 4, 2025, https://www.researchgate.net/publication/331338528_Hybrid_Rendering_for_Real-Time_Ray_Tracing_High-Quality_and_Real-Time_Rendering_with_DXR_and_Other_APIs</li>
<li>Hybrid rendering for real-time lighting: ray tracing vs rasterization - Imagination Blog, accessed July 4, 2025, https://blog.imaginationtech.com/hybrid-rendering-for-real-time-lighting/</li>
<li>GDC - ZigguratVertigo’s Hideout, accessed July 4, 2025, https://colinbarrebrisebois.com/category/gdc/</li>
<li>Ray Tracing vs. Rasterization: Which One Wins in 2025? | by ServerWala InfraNet FZ-LLC, accessed July 4, 2025, https://medium.com/@serverwalainfra/ray-tracing-vs-rasterization-which-one-wins-in-2025-bfa9fda3d9a1</li>
<li>Hybrid-Rendering Techniques in GPU - arXiv, accessed July 4, 2025, https://arxiv.org/pdf/2312.06827</li>
<li>Real-Time Ray Tracing | Unreal Engine 4.27 Documentation | Epic Developer Community, accessed July 4, 2025, https://dev.epicgames.com/documentation/en-us/unreal-engine/real-time-ray-tracing?application_version=4.27</li>
<li>Lumen Global Illumination and Reflections in Unreal Engine - Epic Games Developers, accessed July 4, 2025, https://dev.epicgames.com/documentation/en-us/unreal-engine/lumen-global-illumination-and-reflections-in-unreal-engine</li>
<li>Lumen vs Ray Tracing: Photorealistic Results in 3D Rendering - Lunas, accessed July 4, 2025, https://www.lunas.pro/news/lumen-ray-tracing.html</li>
<li>Hardware Ray Tracing in Unreal Engine - Epic Games Developers, accessed July 4, 2025, https://dev.epicgames.com/documentation/en-us/unreal-engine/hardware-ray-tracing-in-unreal-engine</li>
<li>Thoughts and info on DLSS Ray Reconstruction : r/nvidia - Reddit, accessed July 4, 2025, https://www.reddit.com/r/nvidia/comments/16p3z0g/thoughts_and_info_on_dlss_ray_reconstruction/</li>
<li>Control PC Performance Analysis - DSOGaming, accessed July 4, 2025, https://www.dsogaming.com/pc-performance-analyses/control-pc-performance-analysis/</li>
<li>Ray tracing is amazing but the performance cost isn’t worth it - PC - GameFAQs, accessed July 4, 2025, https://gamefaqs.gamespot.com/boards/916373-pc/80267382?page=1</li>
<li>Nvidia DLSS guide – upscaling, ray reconstruction, and frame gen explained - PCGamesN, accessed July 4, 2025, https://www.pcgamesn.com/nvidia/dlss-graphics</li>
<li>Deep Learning Super Sampling - Wikipedia, accessed July 4, 2025, https://en.wikipedia.org/wiki/Deep_Learning_Super_Sampling</li>
<li>Upscaling Technologies Explained: DLSS vs FSR vs XeSS - ProSettings.net, accessed July 4, 2025, https://prosettings.net/blog/upscaling-technologies-explained/</li>
<li>NVIDIA DLSS 3.5 And Ray Reconstruction: A Quick Breakdown - Lowyat.NET, accessed July 4, 2025, https://www.lowyat.net/2023/309115/nvidia-dlss-3-5-ray-reconstruction-2/</li>
<li>NVIDIA DLSS 3.5 Ray Reconstruction Review - Better Than Native - Conclusion, accessed July 4, 2025, https://www.techpowerup.com/review/nvidia-dlss-35-ray-reconstruction/5.html</li>
<li>Decoding AI-Powered DLSS 3.5 Ray Reconstruction - NVIDIA Blog, accessed July 4, 2025, https://blogs.nvidia.com/blog/ai-decoded-ray-reconstruction/</li>
<li>What is AMD FSR? The upscaling technology explained - TechRadar, accessed July 4, 2025, https://www.techradar.com/computing/gpu/what-is-amd-fsr</li>
<li>What is AMD Radeon FidelityFX Super Resolution (FSR)? - CyberPowerPC, accessed July 4, 2025, https://www.cyberpowerpc.com/blog/what-is-amd-radeon-fidelityfx-super-resolution-fsr/</li>
<li>Maximum Ray Tracing Performance with AMD FSR 2 and AMD Radeon™ RX 7900 Series Graphics - AMD Community, accessed July 4, 2025, https://community.amd.com/t5/gaming/maximum-ray-tracing-performance-with-amd-fsr-2-and-amd-radeon-rx/ba-p/604780</li>
<li>What is Intel XeSS | CORSAIR, accessed July 4, 2025, https://www.corsair.com/us/en/explorer/gamer/gaming-pcs/what-is-intel-xess/</li>
<li>Intel® XeSS on Arc™ Graphics Explained, accessed July 4, 2025, https://game.intel.com/es/stories/intel-arc-graphics-xess/</li>
<li>Intel Details Inner Workings of XeSS - Tom’s Hardware, accessed July 4, 2025, https://www.tomshardware.com/news/intel-xess-technology-demo-and-overview</li>
<li>Screen Space Reflections + Ray-traced Reflections? : r/SpiderManPC - Reddit, accessed July 4, 2025, https://www.reddit.com/r/SpiderManPC/comments/100g9lx/screen_space_reflections_raytraced_reflections/</li>
<li>Unity and real-time ray tracing: a Q&amp;A - befores &amp; afters, accessed July 4, 2025, https://beforesandafters.com/2019/04/12/unity-and-real-time-ray-tracing-a-qa/</li>
<li>12: Screen-space reflections (left) vs ray-traced reflections (right)…. | Download Scientific Diagram - ResearchGate, accessed July 4, 2025, https://www.researchgate.net/figure/Screen-space-reflections-left-vs-ray-traced-reflections-right-Screen-space_fig30_369557201</li>
<li>Control is the best, most complex implementation of ray tracing in a game so far | PC Gamer, accessed July 4, 2025, https://www.pcgamer.com/control-is-the-best-most-complex-implementation-of-ray-tracing-in-a-game-so-far/</li>
<li>Baked Lighting in 3D: A Basic Guide for Artists and Designers - GarageFarm, accessed July 4, 2025, https://garagefarm.net/blog/baked-lighting-in-3d-a-basic-guide-for-artists-and-designers</li>
<li>Raytracing &amp; Light Baking? - Rendering - Epic Developer Community Forums, accessed July 4, 2025, https://forums.unrealengine.com/t/raytracing-light-baking/126955</li>
<li>why don’t developers use older lighter methods to have global illumination or other effects?, accessed July 4, 2025, https://www.reddit.com/r/pcmasterrace/comments/1akcvci/why_dont_developers_use_older_lighter_methods_to/</li>
<li>Baking Lights Comes Again With RTX in Unreal Engine 5 | by Metehan Yengil - Medium, accessed July 4, 2025, https://medium.com/design-bootcamp/baking-lights-comes-again-with-rtx-in-unreal-engine-5-d95655ef39eb</li>
<li>Ray-Traced Ambient Occlusion | Unreal-Development-Guides-and-Tips - GitHub Pages, accessed July 4, 2025, https://jaredp94.github.io/Unreal-Development-Guides-and-Tips/Content/RTRT/AmbientOcclusion.html</li>
<li>How do ambient occlusion and ray tracing work? - Quora, accessed July 4, 2025, https://www.quora.com/How-do-ambient-occlusion-and-ray-tracing-work</li>
<li>The Dark Side Of Ray-Traced Ambient Occlusion (RTAO) - The Gamedev Guru, accessed July 4, 2025, https://thegamedev.guru/unity-ray-tracing/ambient-occlusion-rtao/</li>
<li>나만 레이 트레이싱 별로라고 생각하는 건가? : r/pcgaming - Reddit, accessed July 4, 2025, https://www.reddit.com/r/pcgaming/comments/1260agx/just_me_or_is_ray_tracing_overrated/?tl=ko</li>
<li>HUB - Ray Tracing: Is The Performance Hit Worth It? : r/hardware - Reddit, accessed July 4, 2025, https://www.reddit.com/r/hardware/comments/1gfj7zf/hub_ray_tracing_is_the_performance_hit_worth_it/</li>
<li>Will ray tracing ever not cost frames? - Quora, accessed July 4, 2025, https://www.quora.com/Will-ray-tracing-ever-not-cost-frames</li>
<li>Cyberpunk 2077 ray tracing: what does it look like and how does it run?, accessed July 4, 2025, https://www.rockpapershotgun.com/cyberpunk-2077-ray-tracing-performance</li>
<li>Cyberpunk 2077 - Ray Tracing ON vs OFF Comparison (pre-1.62) - YouTube, accessed July 4, 2025, https://www.youtube.com/watch?v=Xf2QCdScU6o</li>
<li>Cyberpunk 2077 | Ray Tracing: Overdrive Mode - 4K Technology Preview Reveal - YouTube, accessed July 4, 2025, https://www.youtube.com/watch?v=Tk7Zbzd-6fs</li>
<li>Cyberpunk 2077: Path Ray Tracing Overdrive Performance Review (Update 1.62), accessed July 4, 2025, https://www.youtube.com/watch?v=C2lsZBTUtSM</li>
<li>How your 4090 run on cyberpunk 2077 setting benchmarks? : r/nvidia - Reddit, accessed July 4, 2025, https://www.reddit.com/r/nvidia/comments/11ub6rz/how_your_4090_run_on_cyberpunk_2077_setting/</li>
<li>Playing Cyberpunk Path Tracing on a friend’s 4090 was incredible. Over 100fps (w… | Hacker News, accessed July 4, 2025, https://news.ycombinator.com/item?id=35856912</li>
<li>Cyberpunk 2077: Phantom Liberty Benchmark Performance Review - 25+ GPUs Tested - Conclusion | TechPowerUp, accessed July 4, 2025, https://www.techpowerup.com/review/cyberpunk-2077-phantom-liberty-benchmark-test-performance-analysis/7.html</li>
<li>Alan Wake 2: a deep dive into Remedy’s high-end ray tracing | Eurogamer.net, accessed July 4, 2025, https://www.eurogamer.net/digitalfoundry-2023-alan-wake-2-rt-deep-dive</li>
<li>[Digital Foundry] Alan Wake 2 PC Path Tracing: The Next Level In Visual Fidelity? - Reddit, accessed July 4, 2025, https://www.reddit.com/r/hardware/comments/17nnw7c/digital_foundry_alan_wake_2_pc_path_tracing_the/</li>
<li>Alan Wake 2 - DLSS 3.5, Ray Tracing &amp; Path Tracing Benchmarks - DSOGaming, accessed July 4, 2025, https://www.dsogaming.com/pc-performance-analyses/alan-wake-2-dlss-3-5-ray-tracing-path-tracing-benchmarks/</li>
<li>Testing Alan Wake 2: Full Path Tracing and Ray Reconstruction Will Punish Your GPU, accessed July 4, 2025, https://www.tomshardware.com/features/alan-wake-2-will-punish-your-gpu</li>
<li>Erik Jansson - GPU driven Rendering with Mesh Shaders in Alan Wake 2 - YouTube, accessed July 4, 2025, https://www.youtube.com/watch?v=EtX7WnFhxtQ</li>
<li>Alan Wake 2 Performance Benchmark Review - 30 GPUs Tested - Conclusion, accessed July 4, 2025, https://www.techpowerup.com/review/alan-wake-2-performance-benchmark/9.html</li>
<li>Minecraft with RTX | Official GeForce RTX Ray Tracing Reveal Trailer - YouTube, accessed July 4, 2025, https://www.youtube.com/watch?v=91kxRGeg9wQ</li>
<li>Minecraft RTX is stunning. - YouTube, accessed July 4, 2025, https://www.youtube.com/watch?v=uiljJjkSaVc</li>
<li>The state of Minecraft RTX? : r/minecraftRTX - Reddit, accessed July 4, 2025, https://www.reddit.com/r/minecraftRTX/comments/16497ul/the_state_of_minecraft_rtx/</li>
<li>The Impact of Real-Time Rendering in 3D Animation - Prolific Studio, accessed July 4, 2025, https://prolificstudio.co/blog/real-time-rendering-in-3d-animation/</li>
<li>How Real-Time Rendering is Changing the Future of CGI and Filmmaking - Motion Marvels, accessed July 4, 2025, https://www.motionmarvels.com/blog/the-future-of-cgi-and-filmmaking</li>
<li>Ray Tracing - Unreal Engine, accessed July 4, 2025, https://www.unrealengine.com/en-US/explainers/ray-tracing</li>
<li>The Holy Grail: GPU realtime raytracing - Autodesk Blogs, accessed July 4, 2025, https://blogs.autodesk.com/design-studio/2020/07/21/the-holy-grail-real-time-gpu-ray-tracing/</li>
<li>Architectural Visualization and Real-Time Ray Tracing - Easy Render, accessed July 4, 2025, https://www.easyrender.com/a/architectural-visualization-and-real-time-ray-tracing</li>
<li>Architectural Visualization And Real Time Ray Tracing, accessed July 4, 2025, https://archovavisuals.com/architectural-visualization-ray-tracing/</li>
<li>What is Real-time Rendering and Why is it Important? - ArchXStudio, accessed July 4, 2025, https://www.archxstudio.com/what-is-real-time-rendering-and-why-is-it-important/</li>
<li>What is Ray Tracing and Its Uses in Architectural Visualization - McLine Studios, accessed July 4, 2025, https://mclinestudios.com/ray-tracing-in-architecture/</li>
<li>Why Real-Time Rendering Technology Matters for Architectural Visualization?, accessed July 4, 2025, https://mapsystemsindia.com/blog/real-time-rendering-for-architectural-visualization.html</li>
<li>Ray Tracing Design Kit | Keysight, accessed July 4, 2025, https://www.keysight.com/us/en/assets/3119-1115/technical-overviews/Ray-Tracing-Design-Kit.pdf</li>
<li>Ray tracing rendering engine – seeing the world through the eye of a sensor - rFpro, accessed July 4, 2025, https://rfpro.com/applications-autonomous-vehicle-development/adas-autonomous-vehicles/ray-tracing/</li>
<li>Impact of Real-Time Ray Tracing Technology in the VR Industry, accessed July 4, 2025, https://www.ikarusvr.com/blog/impact-of-real-time-ray-tracing-technology-in-the-vr-industry</li>
<li>What Is Ray Tracing? The Future of Graphics Rendering - Bluebird International, accessed July 4, 2025, https://bluebirdinternational.com/what-is-ray-tracing/</li>
<li>Cyberpunk RT Overdrive Benchmarks, Image Quality, Path Tracing, &amp; DLSS - Reddit, accessed July 4, 2025, https://www.reddit.com/r/nvidia/comments/12ij9c1/cyberpunk_rt_overdrive_benchmarks_image_quality/</li>
<li>Home Page | SIGGRAPH 2024, accessed July 4, 2025, https://s2024.siggraph.org/</li>
<li>Real-Time Live! | SIGGRAPH 2024, accessed July 4, 2025, https://s2024.siggraph.org/program/real-time-live/</li>
<li>SIGGRAPH 2024 shapes the future of computer graphics with immersive tech and cutting-edge demos, accessed July 4, 2025, https://www.cgw.com/Press-Center/Siggraph/2024/SIGGRAPH-2024-shapes-the-future-of-computer-grap.aspx</li>
<li>SIGGRAPH 2024 Shapes the Future of Computer Graphics and Interactive Techniques With Games, Immersive Technologies, and Cutting-Edge Technology Demos, accessed July 4, 2025, https://s2024.siggraph.org/siggraph-2024-shapes-the-future-of-computer-graphics-and-interactive-techniques-with-games-immersive-technologies-and-cutting-edge-technology-demos/</li>
<li>SIGGRAPH 2024 Shapes the Future of Computer Graphics and Interactive Techniques With Games, Immersive Technologies, and Cutting-Edge Technology Demos - PR Newswire, accessed July 4, 2025, https://www.prnewswire.com/news-releases/siggraph-2024-shapes-the-future-of-computer-graphics-and-interactive-techniques-with-games-immersive-technologies-and-cutting-edge-technology-demos-302194115.html</li>
<li>Advances in Real-Time Rendering in Games course SIGGRAPH 2024, accessed July 4, 2025, https://advances.realtimerendering.com/s2024/index.html</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>