<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:실시간 레이트레이싱</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>실시간 레이트레이싱</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">컴퓨터 그래픽 (Computer Graphics)</a> / <a href="index.html">Raytracing</a> / <span>실시간 레이트레이싱</span></nav>
                </div>
            </header>
            <article>
                <h1>실시간 레이트레이싱</h1>
<h2>1. D 그래픽스의 패러다임 전환 - 래스터라이제이션에서 레이트레이싱으로</h2>
<p>컴퓨터 그래픽스 분야는 지난 수십 년간 현실과 가상의 경계를 허물기 위한 끊임없는 기술적 진보를 거듭해왔다. 이 여정의 중심에는 이미지를 생성하는 핵심 기술, 즉 렌더링(Rendering)이 있으며, 렌더링 패러다임은 크게 래스터라이제이션(Rasterization)과 레이트레이싱(Ray Tracing)이라는 두 가지 방식으로 양분되어 발전해왔다. 오랫동안 실시간 그래픽스 영역은 래스터라이제이션이 절대적인 지위를 차지해왔으나, 최근 하드웨어와 소프트웨어 기술의 비약적인 발전은 과거 영화 및 VFX(Visual Effects) 분야의 전유물로 여겨졌던 레이트레이싱을 실시간 영역으로 끌어들이며 근본적인 패러다임의 전환을 이끌고 있다.</p>
<p>본 안내서는 실시간 레이트레이싱 기술에 대한 심층적이고 분석적인 고찰을 목적으로 한다. 이를 위해 먼저 래스터라이제이션과 레이트레이싱의 근본적인 원리와 기술적 장단점을 비교 분석하여 패러다임 전환의 필연성을 조명한다. 다음으로, 실시간 레이트레이싱을 현실로 만든 하드웨어 아키텍처의 혁신, 즉 NVIDIA의 RTX와 AMD의 RDNA 아키텍처를 기술적으로 해부하고, 이를 뒷받침하는 DirectX Raytracing(DXR) 및 Vulkan Ray Tracing과 같은 표준 API의 구조를 상세히 분석한다. 나아가, 실시간 구현의 핵심 난제인 성능과 품질 문제를 해결하기 위한 AI 기반 생태계, 특히 디노이징(Denoising)과 슈퍼 샘플링(Super Sampling) 기술의 원리와 발전을 심도 있게 다룬다. 실제 적용 사례로서 최신 비디오 게임들의 하이브리드 렌더링 및 패스 트레이싱(Path Tracing) 구현 방식을 비교 분석하고, 마지막으로 엔터테인먼트를 넘어 건축, 자동차, 산업용 디지털 트윈 등 다양한 산업 분야로 확장되는 실시간 레이트레이싱의 현재와 미래 전망을 종합적으로 제시하고자 한다.</p>
<h3>1.1  전통적 접근법: 래스터라이제이션 파이프라인의 기술적 분석</h3>
<p>래스터라이제이션은 3차원 공간에 정의된 기하학적 모델(삼각형 또는 폴리곤의 집합)을 2차원 화면(스크린)에 투영하여 픽셀 이미지로 변환하는 렌더링 기법이다.1 이 방식은 ‘객체 순서(object-order)’ 접근법을 따르는데, 이는 각 기하학적 프리미티브(primitive)를 순차적으로 처리하여 화면의 어떤 픽셀을 덮는지 결정하는 과정을 의미한다.3</p>
<p>래스터라이제이션의 처리 과정은 일반적으로 렌더링 파이프라인(Rendering Pipeline)이라 불리는 일련의 고정된 단계로 구성된다.3 이 파이프라인은 크게 세 단계로 나눌 수 있다. 첫째, **애플리케이션 단계(Application Stage)**에서는 CPU가 렌더링할 객체들을 선별(culling)하고 GPU에 렌더링 명령을 전달한다. 둘째, **지오메트리 단계(Geometry Stage)**에서는 GPU가 객체를 구성하는 정점(vertex) 데이터를 처리한다. 이 단계에서 정점 셰이더(Vertex Shader)는 모델의 로컬 좌표를 월드, 뷰, 프로젝션 공간으로 변환하는 행렬 연산을 수행하여 3D 공간의 객체를 2D 화면에 매핑할 준비를 한다.3 셋째, **래스터라이저 단계(Rasterizer Stage)**에서는 변환된 삼각형이 화면의 어떤 픽셀들을 덮는지 결정하고, 각 픽셀에 해당하는 프래그먼트(fragment)를 생성한다. 이후 프래그먼트 셰이더(Fragment Shader, 또는 픽셀 셰이더)가 각 프래그먼트의 최종 색상을 계산한다. 이 과정에서 Z-버퍼(Z-buffer) 또는 뎁스 버퍼(Depth Buffer)가 핵심적인 역할을 하는데, 카메라로부터의 깊이 값을 저장하여 어떤 픽셀이 다른 픽셀에 의해 가려지는지를 판단하고, 가려진 픽셀의 렌더링을 생략함으로써 은면 제거(hidden surface removal)를 효율적으로 수행한다.3</p>
<p>래스터라이제이션이 수십 년간 실시간 그래픽스의 표준으로 자리 잡은 이유는 명확하다. 그 계산 모델은 본질적으로 독립적인 정점과 픽셀을 대량으로 처리하는 방식이므로, 수천 개의 코어를 가진 GPU의 병렬 처리 아키텍처에 매우 이상적으로 부합한다.4 이러한 구조적 적합성 덕분에 하드웨어 제조사들은 수십 년간 래스터라이제이션 파이프라인에 최적화된 하드웨어를 개발할 수 있었고, 이는 압도적인 처리 속도로 이어졌다.2</p>
<p>하지만 이러한 속도는 근본적인 한계와 타협의 결과물이다. 래스터라이제이션은 본질적으로 물리적으로 정확한 빛의 시뮬레이션이 아닌, 그럴듯한 결과를 만들어내기 위한 ’영리한 속임수(clever tricks)’와 근사치의 집합이다.6 파이프라인의 각 단계는 독립적으로 작동하며, 특정 픽셀을 셰이딩할 때 씬 전체의 정보에 접근할 수 없다. 이러한 ‘지역적(local)’ 정보의 한계는 반사, 굴절, 전역 조명(Global Illumination), 부드러운 그림자 같은 ‘전역적(global)’ 광학 효과를 물리적으로 정확하게 구현하는 것을 불가능하게 만든다. 예를 들어, 스크린 공간 반사(Screen Space Reflections, SSR)는 화면에 보이는 정보만을 사용하여 반사를 계산하므로, 화면 밖에 있는 객체는 반사되지 않거나 화면 가장자리에서 반사가 깨지는 시각적 결함(artifact)이 필연적으로 발생한다.7 이처럼 래스터라이제이션의 한계는 더 높은 수준의 사실감을 추구하는 과정에서 점차 명확해졌고, 이는 새로운 패러다임의 필요성을 대두시켰다.</p>
<h3>1.2  물리적 접근법: 레이트레이싱 알고리즘의 핵심 원리</h3>
<p>레이트레이싱은 래스터라이제이션의 근사적 접근법과 달리, 빛의 물리적 경로를 추적하여 이미지를 생성하는 렌더링 기법이다.10 이 방식은 ‘이미지 순서(image-order)’ 접근법을 따르며, 가상의 카메라(또는 눈)에서 시작하여 화면의 각 픽셀을 통과하는 광선(ray)을 3D 공간으로 발사하고, 이 광선이 씬의 객체들과 상호작용하는 과정을 시뮬레이션하여 최종 픽셀 색상을 결정한다.12 실제 세계에서 광원에서 나온 빛이 우리 눈으로 들어오는 과정을 역으로 추적하는 것과 같기 때문에 ’광선 역추적(backward ray tracing)’이라고도 불린다.12</p>
<p>레이트레이싱의 핵심은 재귀적인(recursive) 광선 추적 과정에 있다.12</p>
<ol>
<li><strong>주 광선 (Primary Rays)</strong>: 먼저, 카메라 위치에서 화면의 각 픽셀을 향해 주 광선을 발사한다. 이 광선이 씬의 객체와 처음으로 교차하는 지점을 찾는다.14 만약 교차하는 객체가 없다면, 해당 픽셀은 배경색으로 처리된다.</li>
<li><strong>보조 광선 (Secondary Rays)</strong>: 주 광선이 객체 표면에 도달하면, 해당 지점에서 다양한 물리 현상을 시뮬레이션하기 위해 여러 종류의 보조 광선이 생성된다.</li>
</ol>
<ul>
<li><strong>그림자 광선 (Shadow Rays)</strong>: 교차점에서 모든 광원을 향해 광선을 발사한다. 만약 이 광선이 광원에 도달하기 전에 다른 불투명한 객체와 교차하면, 해당 지점은 그 광원에 의해 그림자가 진 것으로 판단한다.10</li>
<li><strong>반사 광선 (Reflection Rays)</strong>: 표면의 재질이 거울처럼 반사 속성을 가질 경우, 빛의 입사각과 반사각이 같다는 물리 법칙에 따라 반사 방향으로 새로운 광선을 발사한다. 이 반사 광선이 또 다른 객체와 교차하면, 그 객체의 색상이 원래 표면에 반사된 색상에 기여하게 된다.16</li>
<li><strong>굴절 광선 (Refraction Rays)</strong>: 표면이 유리나 물처럼 투명하거나 반투명할 경우, 빛이 다른 매질을 통과할 때 굴절하는 현상을 시뮬레이션하기 위해 굴절 광선을 발사한다. 이 광선의 방향은 스넬의 법칙(Snell’s Law)과 물질의 굴절률(index of refraction)에 따라 결정된다.16</li>
</ul>
<ol start="3">
<li><strong>재귀적 계산 (Recursive Calculation)</strong>: 이렇게 생성된 보조 광선들 역시 씬의 다른 객체와 교차하여 또 다른 보조 광선을 생성할 수 있다. 이 재귀적 과정은 미리 설정된 최대 깊이(recursion depth)에 도달하거나, 광선이 광원에 직접 닿거나, 씬 밖으로 벗어날 때까지 반복된다.12 최종적으로 각 픽셀의 색상은 이 모든 광선 경로를 따라 수집된 빛과 색상 정보를 종합하여 결정된다.10</li>
</ol>
<h3>1.3  비교 분석: 사실성, 성능, 그리고 알고리즘 복잡성</h3>
<p>래스터라이제이션과 레이트레이싱의 가장 큰 차이는 결과물의 사실성(fidelity)에서 비롯된다. 래스터라이제이션이 근사치에 의존하여 시각적 효과를 ‘흉내’ 내는 반면, 레이트레이싱은 빛의 물리적 상호작용을 직접 시뮬레이션함으로써 본질적으로 사실적인 결과를 생성한다. 물리적으로 정확한 반사, 부드러운 그림자(soft shadows), 간접광까지 고려하는 전역 조명, 그리고 빛이 렌즈를 통과하며 발생하는 코스틱(caustics) 효과 등은 레이트레이싱 알고리즘의 자연스러운 결과물이다.5</p>
<p>그러나 이러한 높은 사실성은 막대한 계산 비용을 수반한다. 화면의 모든 픽셀에 대해, 그리고 재귀적으로 생성되는 수많은 보조 광선에 대해 씬의 모든 객체와의 교차 검사를 수행해야 하므로, 레이트레이싱의 계산량은 기하급수적으로 증가한다.10 이 때문에 과거 레이트레이싱은 한 프레임을 렌더링하는 데 수 시간에서 수일이 걸리는 영화나 건축 시각화 같은 오프라인 렌더링 분야에서만 사용될 수 있었다.5 반면, 래스터라이제이션은 계산적으로 훨씬 단순하여 실시간 프레임률(초당 30 또는 60 프레임 이상)을 달성할 수 있었고, 이는 비디오 게임과 같은 인터랙티브 애플리케이션의 유일한 선택지가 되게 했다.</p>
<p>두 패러다임의 근본적인 차이는 ‘지역적’ 지식과 ‘전역적’ 지식의 차이로 요약할 수 있다. 래스터라이제이션은 “이 삼각형이 어떤 픽셀들을 덮는가?“라는 지역적인 질문에 답한다.1 이 과정에서 다른 객체에 대한 정보는 고려되지 않으므로, 개발자들은 전역적인 효과를 만들어내기 위해 스크린 공간 기법과 같은 ’속임수’를 사용해야만 했다. 반면, 레이트레이싱은 “이 픽셀은 씬의 무엇을 보는가?“라는 전역적인 질문에 답한다.12 픽셀에서 출발한 광선이 씬 전체를 탐험하며 정보를 수집하기 때문에, 반사나 전역 조명과 같은 효과는 특별한 기법이 아닌 알고리즘의 자연스러운 산물이 된다. 실시간 그래픽스의 역사는 이 간극을 메우려는 투쟁의 역사였다. 처음에는 래스터라이제이션에 더 정교한 ’속임수’를 추가하는 방향으로 발전했지만, 이제는 레이트레이싱이라는 물리적으로 ‘올바른’ 시뮬레이션을 가속화하는 방향으로 전환되고 있다.</p>
<p>이러한 패러다임 전환은 단일 기술의 돌파구만으로 이루어진 것이 아니다. 이는 더 높은 수준의 사실감에 대한 시장의 끊임없는 요구, 래스터라이제이션 기법의 명백한 한계, 그리고 결정적으로 이 막대한 계산 부하를 감당할 수 있는 전용 하드웨어와 AI 기술의 등장이 맞물리면서 가능해진 필연적인 결과이다.</p>
<h2>2.  하드웨어 혁명: 실시간 레이 가속을 위한 아키텍처</h2>
<p>실시간 레이트레이싱이 공상 과학의 영역에서 현실로 넘어오는 데 가장 결정적인 역할을 한 것은 전용 하드웨어의 등장이었다. 전통적인 GPU의 범용 셰이더 코어만으로는 레이트레이싱의 막대한 계산량을 실시간으로 처리하는 것이 불가능했다. 이 장에서는 실시간 레이트레이싱 시대를 연 두 거대 기업, NVIDIA와 AMD의 하드웨어 아키텍처 혁신을 심층적으로 분석한다.</p>
<h3>2.1  NVIDIA의 RTX 아키텍처: RT 코어와 텐서 코어 심층 분석</h3>
<p>NVIDIA는 2018년, 튜링(Turing) 아키텍처 기반의 GeForce RTX 20 시리즈를 발표하며 실시간 레이트레이싱의 포문을 열었다.21 이는 기존의 GTX 라인업과 구별되는 RTX라는 새로운 브랜드를 탄생시킨 기념비적인 사건으로, 튜링 아키텍처는 소비자용 GPU에 최초로 레이트레이싱과 인공지능을 위한 전용 하드웨어 코어를 탑재했다.</p>
<p>RT 코어(Ray Tracing Core)의 기능</p>
<p>RT 코어는 레이트레이싱 연산 중 가장 계산 집약적이고 반복적인 두 가지 특정 작업을 가속하기 위해 설계된 전용 하드웨어 유닛이다.4</p>
<ol>
<li><strong>경계 볼륨 계층(Bounding Volume Hierarchy, BVH) 순회</strong>: 레이트레이싱의 효율성은 광선이 씬의 모든 삼각형과 일일이 교차 검사를 하는 것을 피하는 데에 달려있다. 이를 위해 객체들을 감싸는 단순한 박스(경계 볼륨)들을 계층적인 트리 구조(BVH)로 구성한다. 광선이 어떤 박스와 교차하지 않으면, 그 박스 안의 모든 삼각형은 검사할 필요가 없게 된다. RT 코어는 이 BVH 트리를 매우 빠른 속도로 순회하여 광선과 충돌할 가능성이 있는 삼각형 그룹을 신속하게 찾아내는 역할을 한다.4</li>
<li><strong>광선-삼각형 교차 검사</strong>: BVH 순회를 통해 후보군이 좁혀지면, 최종적으로 광선이 특정 삼각형과 실제로 교차하는지 판별하는 수학적 계산을 수행한다. RT 코어는 이 교차 검사 연산 또한 하드웨어적으로 가속한다.4</li>
</ol>
<p>이러한 특정 작업을 범용 FP32 셰이더 코어에서 전용 RT 코어로 오프로드함으로써, 셰이더 코어는 재질의 색상과 속성을 계산하는 본연의 ‘셰이딩’ 작업에 집중할 수 있게 되었다. 이는 셰이딩, 레이트레이싱, AI 연산이 동시에 병렬적으로 처리될 수 있는 하이브리드 렌더링 파이프라인의 하드웨어적 기반을 마련했다.4</p>
<p>텐서 코어(Tensor Core)의 기능</p>
<p>텐서 코어는 딥러닝의 핵심 연산인 행렬 곱셈 및 누적 연산(4×4 행렬 연산 등)에 최적화된 하드웨어 유닛이다.4 텐서 코어는 직접적으로 레이트레이싱 연산을 수행하지는 않지만, 실시간 레이트레이싱을 실용적으로 만드는 데 필수적인</p>
<p><strong>공생 관계</strong>를 형성한다. 그 핵심 역할은 <strong>DLSS(Deep Learning Super Sampling)</strong> 기술을 가속하는 것이다. DLSS는 저해상도로 렌더링된 이미지를 AI를 통해 고해상도 이미지로 재구성(업스케일링)하는 기술로, 렌더링해야 할 픽셀 수를 극적으로 줄여 성능을 비약적으로 향상시킨다.4 즉, RT 코어가 레이트레이싱을 가능하게 만들고, 텐서 코어는 DLSS를 통해 그 성능 비용을 감당할 수 있는 수준으로 낮춰주는 역할을 한다. 이 두 전용 코어의 시너지가 바로 RTX 기술의 핵심이다. 이후 암페어(Ampere), 에이다 러브레이스(Ada Lovelace), 블랙웰(Blackwell) 아키텍처를 거치며 RT 코어와 텐서 코어의 성능과 효율은 지속적으로 향상되었다.24</p>
<h3>2.2  AMD의 RDNA 아키텍처: 레이 가속기의 진화와 혁신</h3>
<p>AMD는 RDNA 2 아키텍처를 통해 하드웨어 가속 레이트레이싱을 도입했으며, 이는 PlayStation 5와 Xbox Series X/S 콘솔에도 탑재되어 레이트레이싱 기술의 대중화를 이끌었다.25</p>
<p>레이 가속기(Ray Accelerator, RA)의 기능</p>
<p>AMD의 접근 방식은 각 컴퓨팅 유닛(Compute Unit, CU) 내에 **레이 가속기(RA)**라는 고정 함수 유닛을 통합하는 것이었다.26 RA 역시 NVIDIA의 RT 코어와 마찬가지로, BVH 순회 및 광선-삼각형 교차 검사와 같은 집약적인 연산을 셰이더 ALU(Arithmetic Logic Unit) 대신 전담하여 처리함으로써 전체적인 렌더링 효율을 높인다.</p>
<p>아키텍처의 진화 (RDNA 3 &amp; RDNA 4)</p>
<p>AMD는 세대를 거듭하며 레이트레이싱 및 AI 관련 하드웨어 역량을 꾸준히 강화해왔다.</p>
<ul>
<li>RDNA 3 아키텍처는 2세대 RA와 함께 1세대 AI 가속기를 도입하여, 보다 전문화된 하드웨어로 나아가는 방향성을 보여주었다.27</li>
<li>RDNA 4 아키텍처는 비약적인 발전을 이루었다. 3세대 RA는 이전 세대 대비 두 배의 처리량을 제공하며, 특히 **방향성 경계 상자(Oriented Bounding Boxes, OBB)**라는 혁신적인 기능을 지원한다. 또한 AI 가속기 성능 역시 대폭 향상되었다.27</li>
</ul>
<p>방향성 경계 상자(OBB) 심층 분석</p>
<p>OBB는 RDNA 4 아키텍처의 핵심 혁신 중 하나이다. 기존의 표준적인 축 정렬 경계 상자(Axis-Aligned Bounding Boxes, AABB)는 길고 가느다란 객체나 대각선으로 배치된 객체를 감쌀 때 비효율적이다. 상자 내부에 많은 빈 공간이 포함되어, 광선이 이 빈 공간을 지나가더라도 불필요한 교차 검사를 유발하기 때문이다. OBB는 객체의 형태에 맞춰 회전할 수 있어 기하학적 구조를 훨씬 더 밀착하여 감쌀 수 있다. 이는 불필요한 ‘거짓 양성(false positive)’ 광선 테스트의 수를 크게 줄여 BVH 순회 효율을 근본적으로 개선하는 효과를 가져온다.29 이는 단순히 처리 속도를 높이는 것을 넘어, 처리해야 할 작업 자체를 줄이는 보다 정교한 최적화 전략이다.</p>
<p>인피니티 캐시(Infinity Cache)</p>
<p>AMD는 RDNA 아키텍처에 인피니티 캐시라는 대용량 L3 캐시를 도입했다. 이는 GPU 메모리 대역폭을 효과적으로 증폭시키고 지연 시간을 줄여, 레이트레이싱과 같이 메모리 접근이 빈번한 애플리케이션의 성능을 향상시키는 데 중요한 역할을 한다.27</p>
<h3>2.3  아키텍처 비교 및 성능 영향</h3>
<p>NVIDIA와 AMD의 초기 접근 방식에는 철학적 차이가 있었다. NVIDIA는 처음부터 레이트레이싱(RT 코어)과 AI(텐서 코어)를 위한 별도의 전용 코어를 탑재하는 ‘올인(all-in)’ 전략을 취했다. 반면 AMD는 기존의 CU 내에 RA를 통합하는, 보다 점진적이고 통합적인 접근 방식을 선택했다. 이러한 차이는 각자의 소프트웨어 전략에도 영향을 미쳤다. NVIDIA는 강력한 하드웨어와 결합된 RTX 및 DLSS라는 독자적인 생태계 구축에 주력했고, AMD는 DirectX 12 Ultimate과 같은 개방형 표준을 중심으로 기술을 발전시켰다.</p>
<p>그러나 시간이 흐르면서 두 아키텍처는 점차 수렴하는 경향을 보인다. AMD는 RDNA 4에서 AI 가속기 성능을 대폭 강화하며 전용 AI 하드웨어의 중요성을 인정하고 있으며 28, NVIDIA 역시 이종(heterogeneous) 코어들 간의 병렬성과 통합을 지속적으로 개선하고 있다.4 이는 현대 그래픽스 렌더링이 범용 셰이딩, 레이트레이싱, AI라는 세 가지 다른 종류의 연산을 효율적으로 처리할 수 있는 이종 컴퓨팅 아키텍처를 필요로 한다는 업계 전반의 공감대가 형성되었음을 시사한다.</p>
<p>결론적으로, 실시간 레이트레이싱의 실현은 전용 하드웨어의 등장이 없었다면 불가능했을 것이다. RT 코어와 RA는 레이트레이싱 연산 자체를 가속했을 뿐만 아니라, 셰이딩 및 AI 연산과의 병렬 처리를 가능하게 함으로써 렌더링 파이프라인의 구조를 근본적으로 바꾸었다. 또한, 텐서 코어와 AI 가속기와 같은 AI 전용 하드웨어는 선택적인 부가 기능이 아니라, 성능 문제를 다른 각도에서 해결하는 필수적인 구성 요소였다. 이들은 업스케일링을 통해 애초에 추적해야 할 광선의 수를 줄이고, AI 디노이징을 통해 저품질의 노이즈 낀 이미지를 복원함으로써, 레이트레이싱이라는 기술 전체를 실용적인 영역으로 끌어올렸다. 이 하드웨어와 AI의 공생 관계야말로 현대 실시간 레이트레이싱의 초석이라 할 수 있다.</p>
<table><thead><tr><th>특징</th><th>NVIDIA (튜링 –&gt;&gt; 블랙웰)</th><th>AMD (RDNA 2 –&gt;&gt; RDNA 4)</th><th>아키텍처적 의의</th></tr></thead><tbody>
<tr><td><strong>레이트레이싱 유닛</strong></td><td>RT 코어 (Ray Tracing Core)</td><td>레이 가속기 (Ray Accelerator)</td><td>BVH 순회 및 광선-삼각형 교차 검사를 위한 전용 하드웨어</td></tr>
<tr><td><strong>AI/ML 유닛</strong></td><td>텐서 코어 (Tensor Core)</td><td>AI 가속기 (AI Accelerator)</td><td>DLSS/FSR 및 AI 디노이징과 같은 머신러닝 워크로드 가속</td></tr>
<tr><td><strong>아키텍처 통합</strong></td><td>별도의 독립된 코어</td><td>컴퓨팅 유닛(CU) 내에 통합</td><td>초기에는 접근 방식의 차이를 보였으나, 점차 이종 코어의 효율적 병렬 처리라는 공통 목표로 수렴</td></tr>
<tr><td><strong>핵심 혁신</strong></td><td>DLSS, Ray Reconstruction</td><td>방향성 경계 상자(OBB), 인피니티 캐시</td><td>NVIDIA는 AI 기반 이미지 재구성에서, AMD는 개방형 기술과 BVH 효율 개선에서 강점을 보임</td></tr>
<tr><td><strong>소프트웨어 생태계</strong></td><td>RTX/DLSS (독점적 생태계)</td><td>개방형 표준(DXR, Vulkan)/FSR</td><td>NVIDIA는 강력한 자체 생태계를, AMD는 넓은 호환성을 가진 개방형 기술을 중심으로 전략을 전개</td></tr>
</tbody></table>
<h2>3.  소프트웨어 기반: 현대 API와 하이브리드 렌더링 파이프라인</h2>
<p>새로운 하드웨어의 잠재력을 최대한 활용하기 위해서는 애플리케이션과 하드웨어를 연결하는 견고한 소프트웨어 기반이 필수적이다. 이 장에서는 개발자들이 하드웨어 가속 레이트레이싱 기능에 접근할 수 있도록 표준화된 인터페이스를 제공하는 그래픽 API와, 성능과 품질 사이의 균형을 맞추기 위해 등장한 지배적인 구현 전략인 하이브리드 렌더링 모델을 심층적으로 분석한다.</p>
<h3>3.1  Microsoft DirectX Raytracing (DXR)</h3>
<p>DXR은 Microsoft가 Windows 플랫폼을 위해 개발한 업계 표준 API로, DirectX 12의 확장 기능 형태로 제공된다.34 DXR은 개발자들이 특정 GPU 제조사에 종속되지 않고 일관된 방식으로 하드웨어 가속 레이트레이싱 기능을 사용할 수 있는 길을 열었다.</p>
<p>DXR은 기존의 그래픽스 및 컴퓨트 파이프라인과 구별되는 새로운 개념들을 도입했다.</p>
<ul>
<li><strong>레이트레이싱 파이프라인 상태 객체 (RTPSO)</strong>: 전통적인 그래픽스 파이프라인 상태 객체(PSO)와 달리, RTPSO는 레이트레이싱에 사용되는 모든 새로운 셰이더들을 하나의 객체로 묶어 관리한다.36</li>
<li><strong>가속 구조 (Acceleration Structures, AS)</strong>: DXR은 BVH를 ’가속 구조’라는 이름으로 API에 노출한다. 이는 두 단계의 계층 구조를 가진다.</li>
<li><strong>하위 수준 가속 구조 (Bottom-Level AS, BLAS)</strong>: 개별 객체의 기하학적 정보(정점 및 인덱스 버퍼)를 담고 있는 구조체이다. 각 메시에 대해 하나의 BLAS가 생성된다.37</li>
<li><strong>상위 수준 가속 구조 (Top-Level AS, TLAS)</strong>: 전체 씬을 구성하는 구조체로, 여러 BLAS에 대한 참조(인스턴스)와 각 인스턴스의 변환 행렬(위치, 회전, 크기), 재질 정보 등을 담고 있다. 실제 광선 추적은 TLAS에서 시작된다.37</li>
<li><strong>셰이더 바인딩 테이블 (Shader Binding Table, SBT)</strong>: SBT는 가속 구조 내의 특정 지오메트리와 실행되어야 할 셰이더(히트 그룹, 미스 셰이더 등)를 연결하는 중요한 메커니즘이다. 광선이 객체와 교차했을 때, GPU는 SBT를 참조하여 어떤 셰이더 코드를 실행할지 결정한다.38</li>
</ul>
<p>DXR은 레이트레이싱 과정을 제어하기 위해 다음과 같은 새로운 셰이더 단계를 도입했다 37:</p>
<ul>
<li><strong>광선 생성 셰이더 (Ray Generation Shader)</strong>: 레이트레이싱 과정의 시작점이다. <code>DispatchRays()</code> API 호출에 의해 그리드 형태로 실행되며, 각 스레드는 보통 화면의 한 픽셀을 담당한다. 이 셰이더 내에서 카메라 위치와 방향을 기반으로 주 광선을 생성하고, <code>TraceRay()</code> 함수를 호출하여 광선 추적을 시작한다.40</li>
<li><strong>교차 셰이더 (Intersection Shader)</strong>: 절차적으로 생성된 지오메트리(procedural geometry)나 사용자 정의 프리미티브와의 교차 판정 로직을 구현하는 데 사용된다. 일반적인 삼각형의 경우, 매우 최적화된 내장 교차 셰이더가 사용되므로 개발자가 직접 작성할 필요는 거의 없다.41</li>
<li><strong>애니 히트 셰이더 (Any-Hit Shader)</strong>: 광선이 잠재적인 교차점을 찾을 때마다 호출된다. 주로 알파 테스팅(alpha-testing)과 같은 효과에 유용하다. 예를 들어, 나뭇잎 텍스처의 투명한 부분을 광선이 통과하도록 하여 그 뒤에 있는 객체를 찾도록 <code>IgnoreHit()</code>를 호출할 수 있다.40</li>
<li><strong>클로지스트 히트 셰이더 (Closest-Hit Shader)</strong>: 광선 경로를 따라 발견된 모든 교차점 중 카메라에 가장 가까운, 확정된 교차점에 대해서만 단 한 번 호출된다. 표면의 재질을 평가하고, 최종 색상을 계산하며, 반사나 그림자를 위한 보조 광선을 생성하는 등 핵심적인 셰이딩 작업이 이 셰이더에서 이루어진다.40</li>
<li><strong>미스 셰이더 (Miss Shader)</strong>: 광선이 씬의 어떤 지오메트리와도 교차하지 않았을 때 호출된다. 주로 하늘이나 배경, 환경 맵 등을 렌더링하는 데 사용된다.39</li>
</ul>
<p>이처럼 DXR의 API 설계는 개발자가 ’광선 예산’을 효율적으로 관리할 수 있도록 매우 유연한 프레임워크를 제공한다. 다양한 셰이더 타입을 분리하고, 히트 그룹과 SBT를 통해 복잡한 상호작용을 제어할 수 있게 한 것은, 계산 비용이 비싼 레이트레이싱 효과를 시각적 효과가 가장 큰 곳에 외과수술처럼 정밀하게 적용해야 하는 하이브리드 렌더링의 현실을 직접적으로 반영한 결과이다.</p>
<h3>3.2  Khronos Vulkan Ray Tracing</h3>
<p>Vulkan은 Khronos Group이 개발한 크로스 플랫폼, 저수준(low-level) 그래픽 API로, DirectX의 강력한 대안으로 자리매김하고 있다.46 Vulkan의 레이트레이싱 지원은 핵심 사양에 포함된 것이 아니라, 일련의 확장 기능(extensions)을 통해 제공된다.</p>
<p>주요 확장 기능은 다음과 같다 48:</p>
<ul>
<li><code>VK_KHR_acceleration_structure</code>: DXR과 유사하게 BLAS와 TLAS를 생성하고 관리하는 공통 기반 기능을 제공한다.</li>
<li><code>VK_KHR_ray_tracing_pipeline</code>: DXR의 개념과 거의 동일한 레이트레이싱 파이프라인, 셰이더 단계, SBT를 정의한다.</li>
<li><code>VK_KHR_ray_query</code>: **인라인 레이트레이싱(inline ray tracing)**을 가능하게 하는 핵심 확장이다. 이 확장을 사용하면 전용 레이트레이싱 셰이더뿐만 아니라, 기존의 그래픽스 셰이더(정점, 프래그먼트)나 컴퓨트 셰이더 내에서도 직접 광선 쿼리를 수행할 수 있다.</li>
</ul>
<p>Vulkan은 셰이더의 중간 표현(Intermediate Representation)으로 SPIR-V를 사용하기 때문에, 개발자들은 GLSL뿐만 아니라 Microsoft의 DXC 컴파일러를 통해 HLSL로 작성된 셰이더도 사용할 수 있어 높은 유연성을 제공한다.47</p>
<p>특히 <code>VK_KHR_ray_query</code>의 등장은 두 렌더링 패러다임의 더 깊은 통합을 시사한다. DXR의 <code>DispatchRays()</code>가 별개의 레이트레이싱 패스를 시작하는 개념이라면, Vulkan의 광선 쿼리는 래스터라이제이션 패스 도중 픽셀 셰이더가 특정 픽셀에 대한 더 정확한 그림자나 반사 정보를 얻기 위해 필요에 따라 소수의 광선을 발사하는 것을 가능하게 한다. 이는 레이트레이싱을 별도의 후처리(post-process) 단계가 아닌, 텍스처 샘플링처럼 셰이더에서 사용할 수 있는 기본적인 프리미티브로 취급하는 진일보한 접근 방식이며, 두 파이프라인의 경계를 허무는 미래를 예고한다.</p>
<h3>3.3  지배적 패러다임: 하이브리드 렌더링 모델의 해부</h3>
<p>실시간 레이트레이싱 기술이 처음 도입되었을 때, 전체 화면을 순수한 레이트레이싱만으로 렌더링하는 것은 성능적으로 불가능에 가까웠다.20 이러한 현실적인 제약 속에서 탄생한 것이 바로 <strong>하이브리드 렌더링(Hybrid Rendering)</strong> 모델이다. 이 모델은 래스터라이제이션의 속도와 레이트레이싱의 품질이라는 두 마리 토끼를 모두 잡기 위한 실용적인 타협안이다.</p>
<p>하이브리드 모델에서의 역할 분담은 명확하다.20</p>
<ul>
<li><strong>래스터라이제이션의 역할</strong>: 씬의 기본 뷰(base pass)를 렌더링하는 역할을 담당한다. 즉, 카메라에 보이는 대부분의 객체를 전통적인 방식으로 매우 빠르게 그려내고, 이 과정에서 후속 레이트레이싱 단계에 필요한 핵심 정보가 담긴 **G-버퍼(Geometry Buffer)**를 생성한다. G-버퍼에는 각 픽셀의 깊이(depth), 표면 법선(normal), 재질 속성(albedo, roughness, metallic) 등의 데이터가 저장된다.</li>
<li><strong>레이트레이싱의 역할</strong>: 래스터라이제이션이 생성한 G-버퍼를 입력으로 받아, 래스터라이제이션만으로는 구현하기 어렵거나 품질이 낮은 효과들을 물리적으로 정확하게 ’개선’하는 역할을 한다. 예를 들어, G-버퍼의 픽셀 위치와 법선 정보를 이용해 반사 광선을 발사하여 정확한 반사를 계산하거나, 광원을 향해 그림자 광선을 발사하여 부드러운 그림자를 생성한다. 이렇게 계산된 레이트레이싱 효과는 최종적으로 래스터라이즈된 기본 이미지와 합성(composite)되어 최종 프레임을 완성한다.</li>
</ul>
<p>이러한 하이브리드 접근법은 레이트레이싱을 씬 전체가 아닌, 반사, 그림자, 전역 조명 등 시각적 효과가 극대화되는 특정 부분에만 선택적으로 적용함으로써 계산 부하를 현실적인 수준으로 제어한다. 현재 대부분의 실시간 레이트레이싱 지원 게임은 이 하이브리드 모델을 기반으로 하고 있으며, 이는 기술의 현주소를 가장 잘 보여주는 지배적인 패러다임이라 할 수 있다.</p>
<h2>4.  AI 기반 생태계: 성능과 품질의 장벽 극복</h2>
<p>실시간 레이트레이싱의 실용화를 가로막는 가장 큰 장벽은 성능과 품질의 상충 관계였다. 실시간 프레임률을 유지하기 위해 픽셀당 광선 수를 극도로 줄이면(예: 픽셀당 1개, 1 RPP) 이미지는 알아볼 수 없을 정도의 노이즈로 뒤덮인다.49 이 문제를 해결하고, 고품질의 레이트레이싱 그래픽을 높은 성능으로 구현하기 위해 등장한 것이 바로 AI 기술에 기반한 디노이징과 슈퍼 샘플링이다. 이 기술들은 선택적인 부가 기능이 아니라, 현대 실시간 레이트레이싱 생태계를 지탱하는 필수적인 기둥이다.</p>
<h3>4.1  디노이징의 필요성: 공간 필터에서 시공간 및 AI 기반 솔루션으로</h3>
<p>실시간 레이트레이싱은 제한된 시간 내에 렌더링을 완료해야 하므로, 오프라인 렌더링처럼 수천 개의 광선을 사용할 수 없다. 극소수의 샘플(광선)만을 사용한 결과물은 몬테카를로 노이즈(Monte Carlo noise)라 불리는 거친 점박이 형태의 노이즈를 필연적으로 포함하게 된다.49 **디노이징(Denoising)**은 이렇게 노이즈가 낀 입력 이미지를 필터링하여 깨끗하고 안정적인 최종 이미지로 재구성하는 후처리 과정이다.51</p>
<p>디노이징 기술은 다음과 같이 발전해왔다.</p>
<ul>
<li><strong>공간 필터링 (Spatial Filtering)</strong>: 단일 프레임 내에서 주변 픽셀들의 정보를 활용하여 노이즈를 제거하는 방식이다. 구현이 간단하지만, 노이즈와 이미지의 미세한 디테일을 구분하기 어려워 이미지를 뭉개는(blurring) 경향이 있다.51</li>
<li><strong>시간 필터링 (Temporal Filtering)</strong>: 이전 프레임의 결과물을 현재 프레임에 재투영(reprojection)하여 정보를 누적시키는 방식이다. 여러 프레임에 걸쳐 샘플 수를 효과적으로 늘릴 수 있어 공간 필터링보다 훨씬 높은 품질을 제공하지만, 카메라나 객체가 빠르게 움직일 때 이전 프레임의 정보가 잘못된 위치에 남아 ’고스팅(ghosting)’이나 ‘잔상(smearing)’ 현상을 유발할 수 있다.51</li>
<li><strong>시공간 분산 유도 필터링 (Spatiotemporal Variance-Guided Filtering, SVGF)</strong>: NVIDIA가 2017년에 발표한 선구적인 기술로, 공간 필터링과 시간 필터링을 지능적으로 결합한다.50 SVGF는 G-버퍼의 데이터(깊이, 법선, 모션 벡터)를 활용하여 시간적 누적을 수행하고, 픽셀의 분산(variance)을 추정하여 노이즈가 심한 영역에만 선택적으로 필터를 강하게 적용함으로써 디테일 손실을 최소화한다.53 이는 이후 등장한 많은 실시간 디노이저의 기반이 되었다.</li>
<li><strong>NVIDIA 실시간 디노이저 (NVIDIA Real-Time Denoisers, NRD)</strong>: SVGF의 후속 기술로, 고도로 최적화된 디노이저들의 라이브러리다.50 NRD는 SVGF 대비 약 50% 향상된 성능과 더 높은 이미지 품질, 그리고 현저히 줄어든 고스팅을 제공한다.50 NRD의 핵심적인 개선점 중 하나는 빛의 신호를 확산(diffuse)과 반사(specular)로 분리하여 각각에 최적화된 디노이징 알고리즘(예: REBLUR, RELAX)을 적용하는 것이다. 확산광은 시점에 덜 민감하고 넓은 영역에 걸쳐 부드럽게 변하는 반면, 반사광은 시점에 매우 민감하고 날카로운 디테일을 가지는 등 노이즈의 특성이 다르기 때문에, 이를 분리하여 처리하는 것이 훨씬 효과적인 결과를 낳는다.50</li>
</ul>
<h3>4.2  성능 증폭기로서의 AI 슈퍼 샘플링: NVIDIA DLSS와 AMD FSR 비교 분석</h3>
<p>디노이징이 품질 문제를 해결한다면, 슈퍼 샘플링은 성능 문제를 정면으로 돌파하는 기술이다. <strong>슈퍼 샘플링(Super Sampling)</strong> 또는 **업스케일링(Upscaling)**은 게임을 모니터의 네이티브 해상도보다 낮은 해상도로 렌더링한 후, 지능적인 알고리즘을 통해 목표 해상도로 확대하는 기술이다.23 예를 들어, 4K(3840x2160) 모니터에서 게임을 QHD(2560x1440)로 렌더링하면 처리해야 할 픽셀 수가 44% 수준으로 줄어든다. 이는 렌더링해야 할 주 광선의 수를 극적으로 감소시켜 레이트레이싱의 성능 부담을 크게 덜어준다.</p>
<h4>4.2.1  딥러닝 슈퍼 샘플링 (Deep Learning Super Sampling, DLSS)</h4>
<p>DLSS는 NVIDIA가 개발한 AI 기반 업스케일링 기술로, RTX GPU에 탑재된 전용 텐서 코어(Tensor Core)를 사용하여 가속된다.23 DLSS의 AI 모델은 NVIDIA의 슈퍼컴퓨터에서 수많은 고품질 오프라인 렌더링 이미지와 게임 엔진의 저해상도 입력, 모션 벡터 등을 학습하여, 낮은 해상도의 정보로부터 고품질의 최종 이미지를 ’재구성’하는 방법을 터득한다.23</p>
<p>DLSS는 버전을 거듭하며 획기적인 기능들을 추가해왔다.</p>
<ul>
<li><strong>DLSS 2.0 (슈퍼 해상도, Super Resolution)</strong>: 범용 AI 모델을 도입하여 다양한 게임에 쉽게 적용할 수 있게 되었으며, 시간적 데이터를 활용하여 네이티브 해상도와 동등하거나 때로는 더 나은 이미지 품질을 제공하며 업계 표준으로 자리 잡았다.24</li>
<li><strong>DLSS 3.0 (프레임 생성, Frame Generation)</strong>: RTX 40 시리즈의 광학 흐름 가속기(Optical Flow Accelerator, OFA)를 활용하는 혁신적인 기술이다. AI가 연속된 두 프레임을 분석하여 그 사이를 채울 완전히 새로운 중간 프레임을 ’생성’해낸다. 이를 통해 표시되는 프레임률을 최대 2배까지 끌어올릴 수 있다. 다만, 프레임 생성은 필연적으로 입력 지연(latency)을 증가시키므로, 이를 완화하기 위해 NVIDIA Reflex 기술이 함께 사용된다.24</li>
<li><strong>DLSS 3.5 (광선 재구성, Ray Reconstruction)</strong>: 기존에 여러 단계로 나뉘어 있던 수작업으로 튜닝된 디노이저들을, 5배 더 많은 데이터로 학습된 단일 AI 모델로 대체했다. 이 모델은 업스케일링과 디노이징을 동시에 수행하며, 특히 레이트레이싱된 반사 및 전역 조명의 품질을 획기적으로 개선하고 노이즈와 고스팅을 크게 줄여준다.24</li>
</ul>
<h4>4.2.2  피델리티FX 슈퍼 해상도 (FidelityFX Super Resolution, FSR)</h4>
<p>FSR은 AMD가 개발한 오픈 소스 업스케일링 기술로, 특정 하드웨어를 요구하지 않아 AMD, NVIDIA, Intel 등 다양한 GPU에서 사용할 수 있다는 강력한 장점을 가진다.60</p>
<p>FSR 역시 빠르게 발전해왔다.</p>
<ul>
<li><strong>FSR 1.0 (공간 업스케일링)</strong>: 단일 프레임만을 사용하는 공간적 업스케일링 기술이다. 진보된 엣지 감지 알고리즘(EASU)과 샤프닝 필터(RCAS)를 사용하며, 광범위한 하드웨어 호환성을 무기로 빠르게 시장에 보급되었다.60</li>
<li><strong>FSR 2.0 (시간 업스케일링)</strong>: 모션 벡터와 같은 시간적 데이터를 활용하기 시작하면서 이미지 품질을 비약적으로 향상시켰다. 이를 통해 DLSS 2.0과 직접적으로 경쟁할 수 있는 기술로 발돋움했다.62</li>
<li><strong>FSR 3.0 (프레임 생성)</strong>: ’플루이드 모션 프레임(Fluid Motion Frames, FMF)’이라는 프레임 보간 기술을 도입하여 DLSS 3에 대응한다. FSR 3 역시 오픈 소스이며, 다양한 GPU에서 프레임 생성 기술을 사용할 수 있도록 지원한다.62</li>
<li><strong>FSR 4.0</strong>: 최신 버전에서는 머신러닝(ML) 기반 업스케일링을 도입하여, DLSS의 AI 우선 접근 방식과 기술적으로 수렴하는 모습을 보인다. 이 기술은 RDNA 4 아키텍처의 새로운 AI 가속기에 최적화되어 있다.28</li>
</ul>
<p>이처럼 디노이징과 AI 슈퍼 샘플링은 서로 분리된 기술이 아니라, ’낮은 샘플 수의 레이트레이싱을 실용적으로 만든다’는 동일한 목표를 가진 동전의 양면과 같다. 이들은 성능과 품질의 선순환 고리를 형성한다. 슈퍼 샘플링이 렌더링 해상도를 낮춰 추적해야 할 광선의 수와 처리해야 할 노이즈의 양을 줄여주면, 디노이저는 더 적은 부담으로 더 높은 품질의 결과를 만들어낼 수 있다. DLSS 3.5의 광선 재구성은 이 두 과정을 하나의 강력한 AI 모델로 통합함으로써, 이러한 공생 관계가 기술적으로 얼마나 긴밀하게 연결되어 있는지를 명확히 보여준다.</p>
<table><thead><tr><th>특징</th><th>NVIDIA DLSS (4.0까지)</th><th>AMD FSR (4.0까지)</th><th>핵심 차별점</th></tr></thead><tbody>
<tr><td><strong>기반 기술</strong></td><td>AI/딥러닝</td><td>공간/시간 알고리즘 –&gt;&gt; AI</td><td>DLSS는 초기부터 AI 기반, FSR은 점진적으로 AI 도입</td></tr>
<tr><td><strong>하드웨어 요구사항</strong></td><td>NVIDIA RTX GPU (텐서 코어)</td><td>다양한 GPU (AMD, NVIDIA, Intel)</td><td>DLSS는 전용 하드웨어 필요, FSR은 개방성/호환성 중시</td></tr>
<tr><td><strong>주요 입력 데이터</strong></td><td>모션 벡터, 히스토리 버퍼, 광학 흐름</td><td>모션 벡터, 히스토리 버퍼</td><td>DLSS 3는 프레임 생성을 위해 광학 흐름 하드웨어 활용</td></tr>
<tr><td><strong>프레임 생성</strong></td><td>DLSS FG (Frame Generation)</td><td>FMF (Fluid Motion Frames)</td><td>개념은 유사하나, 하드웨어 의존성과 개방성에서 차이</td></tr>
<tr><td><strong>고급 기능</strong></td><td>광선 재구성(RR), DLAA</td><td>네이티브 AA</td><td>DLSS는 AI를 활용한 품질 개선에, FSR은 유연성에 강점</td></tr>
<tr><td><strong>개방성</strong></td><td>독점적 SDK (플러그인 형태 제공)</td><td>오픈 소스</td><td>FSR의 개방성은 빠른 채택을 유도하는 핵심 전략</td></tr>
</tbody></table>
<h2>5.  최신 기술 동향: 실시간 패스 트레이싱의 실제 구현</h2>
<p>하드웨어와 AI 생태계의 성숙은 실시간 그래픽스를 하이브리드 레이트레이싱을 넘어, 렌더링의 궁극적인 목표인 **패스 트레이싱(Path Tracing)**으로 나아가게 하고 있다. 이 장에서는 선구적인 게임들을 사례로 들어, 하이브리드 모델에서 완전한 패스 트레이싱으로의 기술적 진화를 추적하고 그 의미를 분석한다.</p>
<h3>5.1  기초 구현: <em>Control</em>의 하이브리드 레이트레이싱 효과 사례 연구</h3>
<p>2019년에 출시된 Remedy Entertainment의 <em>Control</em>은 DXR API를 활용한 하이브리드 렌더링 모델의 잠재력을 대중에게 각인시킨 최초의 종합적인 쇼케이스였다.64</p>
<p><em>Control</em>은 래스터라이제이션으로 기본 씬을 렌더링한 후, 여러 가지 개별적인 레이트레이싱 효과를 선택적으로 적용하여 시각적 사실성을 극대화했다.64</p>
<ul>
<li><strong>레이트레이싱 반사 (Ray-Traced Reflections)</strong>: 게임의 주 무대인 ’올디스트 하우스’의 광택 나는 바닥, 유리, 금속 표면에 물리적으로 정확한 반사를 구현했다. 이는 화면 밖의 객체나 다른 레이트레이싱 효과까지 반사하여, SSR의 한계를 명확히 뛰어넘는 깊이감과 현실감을 제공했다.</li>
<li><strong>레이트레이싱 간접 확산 조명 (Ray-Traced Indirect Diffuse Lighting)</strong>: 광선이 표면에서 반사될 때 색상이 주변으로 퍼져나가는 ‘컬러 블리딩(color bleeding)’ 현상을 시뮬레이션했다. 예를 들어, 붉은색 카펫 위에 서 있으면 주변의 흰 벽이 미묘하게 붉은빛을 띠게 되어, 객체들이 환경에 자연스럽게 녹아드는 효과를 창출했다.</li>
<li><strong>레이트레이싱 접촉 그림자 (Ray-Traced Contact Shadows)</strong>: 전통적인 섀도우 맵이 놓치기 쉬운 미세한 부분에 정확한 그림자를 추가했다. 책상 위의 작은 물체나 캐릭터의 발 주변에 생기는 선명한 접촉 그림자는 객체의 존재감을 뚜렷하게 하고 씬의 깊이를 더했다.</li>
</ul>
<p><em>Control</em>은 이처럼 개별적인 레이트레이싱 효과들을 조합하는 것만으로도 게임의 분위기와 몰입감을 얼마나 극적으로 변화시킬 수 있는지를 증명했다. 이는 당시 하드웨어 성능의 제약 속에서 레이트레이싱을 효과적으로 활용하는 가장 현실적인 방법이었으며, 이후 많은 게임들이 따르는 하이브리드 렌더링의 교본이 되었다.67</p>
<h3>5.2  패스 트레이싱으로의 도약: <em>Cyberpunk 2077</em>과 <em>Alan Wake 2</em>의 구현 분석</h3>
<p><strong>패스 트레이싱</strong>은 레이트레이싱의 가장 진보된 형태로, 씬의 모든 조명을 통합된 단일 알고리즘으로 시뮬레이션하는 것을 목표로 한다.5 하이브리드 모델처럼 반사, 그림자, GI를 별개의 효과로 계산하는 대신, 카메라에서 출발한 광선이 씬 안에서 여러 번 튕기며(multi-bounce) 광원에 도달하기까지의 전체 경로를 추적하여 빛의 물리적 전달을 가장 정확하게 모사한다.49 이는 ’렌더링 방정식(rendering equation)’을 수치적으로 푸는 과정과 유사하며, 실시간 그래픽스의 ’성배(holy grail)’로 여겨진다.</p>
<p>Cyberpunk 2077: RT 오버드라이브 모드</p>
<p>CD PROJEKT RED는 Cyberpunk 2077에 ’RT 오버드라이브’라는 이름의 완전한 패스 트레이싱 모드를 업데이트로 추가했다.70</p>
<ul>
<li><strong>구현 방식</strong>: 이 모드는 기존의 래스터라이제이션 기반 조명 시스템과 하이브리드 RT 효과 대부분을 비활성화하고, 이를 통합된 패스 트레이싱 솔루션으로 대체한다. 태양, 네온사인, 차량 헤드라이트 등 씬의 모든 광원으로부터 나오는 빛이 여러 번 반사되며 만들어내는 간접 조명과 부드러운 그림자를 물리적으로 정확하게 시뮬레이션한다.</li>
<li><strong>시각적 영향</strong>: 결과는 혁신적이다. 나이트 시티의 복잡한 환경이 이전에는 불가능했던 수준의 사실적인 조명으로 채워진다. 모든 빛이 자연스럽게 상호작용하며, 그림자는 광원의 크기와 거리에 따라 사실적으로 부드러워진다. 이는 기존 렌더링 모드의 다소 인위적이고 ‘게임 같은’ 느낌을 없애고, 씬 전체에 통일되고 현실적인 분위기를 부여한다.71</li>
<li><strong>성능의 원동력</strong>: 이 모드는 오직 최신 RTX 40 시리즈 GPU와 DLSS 3.5 기술의 결합을 통해서만 실용적인 프레임률로 구동될 수 있다. 특히, 패스 트레이싱으로 인해 발생하는 극심한 노이즈를 효과적으로 제거하고 이미지를 재구성하는 <strong>광선 재구성(Ray Reconstruction)</strong> 기술이 없었다면 실시간 구현은 불가능했을 것이다.73</li>
</ul>
<p>Alan Wake 2: 융합된 패스 트레이싱 접근법</p>
<p>Remedy Entertainment의 Alan Wake 2는 패스 트레이싱에 대해 다른 접근법을 취한다.9</p>
<ul>
<li><strong>구현 방식</strong>: <em>Alan Wake 2</em>는 <em>Cyberpunk 2077</em>처럼 기존 시스템을 완전히 대체하는 대신, 패스 트레이싱을 자신들의 고품질 래스터라이제이션 기반 GI 솔루션과 **융합(fuse)**하는 방식을 선택했다.9 즉, 반사와 같은 직접적인 광선 효과는 완전한 패스 트레이싱으로 처리하되, 간접 조명은 기존 GI 시스템의 결과물과 패스 트레이싱 결과를 혼합하여 최종 이미지를 생성한다.</li>
<li><strong>시각적 영향과 장단점</strong>: 이 융합 방식은 패스 트레이싱으로 인해 발생할 수 있는 노이즈나 고스팅 같은 시각적 결함을 줄여 더 안정적인 이미지를 만들어낸다. 하지만 <em>Cyberpunk 2077</em>의 순수한 패스 트레이싱만큼 시각적으로 혁신적인 변화를 가져오지는 않으며, 때로는 기저에 있는 래스터라이제이션 GI 시스템의 부정확함(예: 특정 부분의 그림자 누락)을 그대로 물려받는 단점도 있다.9</li>
<li><strong>기술적 의의</strong>: <em>Alan Wake 2</em>의 구현은 실시간 패스 트레이싱으로 가는 길이 하나만 있는 것이 아님을 보여준다. 이는 순수한 물리적 정확성보다는 이미지 안정성과 기존 엔진과의 통합 용이성을 우선시한, 매우 실용적인 공학적 절충안이다.</li>
</ul>
<p><em>Control</em>에서 <em>Cyberpunk 2077</em>과 <em>Alan Wake 2</em>로의 진화는 실시간 레이트레이싱이 개별 ‘효과’ 기반의 하이브리드 모델에서 통합된 ‘시뮬레이션’ 기반의 패스 트레이싱 모델로 발전하고 있음을 명확히 보여준다. 이는 하드웨어와 AI 생태계의 성숙이 가져온 직접적인 결과이며, 각 게임은 해당 시점의 기술적 가능성을 보여주는 중요한 이정표 역할을 한다.</p>
<h3>5.3  미래를 향한 여정: 완전한 실시간 패스 트레이싱의 과제와 전망</h3>
<p>완전한 실시간 패스 트레이싱이 보편화되기까지는 여전히 해결해야 할 과제들이 남아있다. 막대한 성능 부하, 업스케일링 및 프레임 생성 기술에 대한 높은 의존도(이는 입력 지연이나 시각적 결함을 유발할 수 있음), 그리고 복잡한 다중 반사광 경로를 효과적으로 디노이징하는 문제 등이 그것이다.70</p>
<p>이러한 과제를 해결하고 미래로 나아가기 위한 길은 세 가지 기술 기둥의 동시적인 발전에 달려 있다.</p>
<ol>
<li><strong>더 스마트한 하드웨어</strong>: OBB와 같이 알고리즘적으로 효율적인 가속 구조를 갖춘 더 강력한 레이 가속기와 AI 코어의 발전.</li>
<li><strong>더 스마트한 알고리즘</strong>: ReSTIR(Reservoir-based Spatiotemporal Importance Resampling)과 같이, 무차별적으로 광선을 쏘는 대신 중요한 빛의 경로에 계산 자원을 집중시키는 지능적인 샘플링 기법의 보편화.29</li>
<li><strong>더 스마트한 AI</strong>: 단순히 노이즈를 제거하는 것을 넘어, 빛의 물리적 전달 과정을 이해하고 이미지를 재구성하는 더욱 진보된 AI 모델(DLSS 3.5 이상)의 개발.</li>
</ol>
<p>이 세 가지 요소의 시너지는 결국 실시간 그래픽스를 현실과 구분할 수 없는 수준의 완전한 동적 패스 트레이싱으로 이끌 것이다.</p>
<h2>6.  엔터테인먼트를 넘어서: 산업의 혁신</h2>
<p>실시간 레이트레이싱의 영향력은 비디오 게임과 엔터테인먼트 산업에만 국한되지 않는다. 물리적 정확성이 무엇보다 중요한 전문 및 산업 분야에서, 이 기술은 시각화를 넘어 시뮬레이션과 예측의 도구로 자리매김하며 혁신을 주도하고 있다. 이러한 분야에서 실시간 레이트레이싱의 가치는 ’시각적 아름다움’에서 ’예측적 정확성’으로 전환된다.</p>
<h3>6.1  설계 및 시각화: 건축 및 자동차 산업</h3>
<p>건축 시각화 (Architectural Visualization)</p>
<p>건축 분야에서 실시간 레이트레이싱은 건축가와 고객이 건물이 실제로 지어지기 전에 사실적인 가상 공간을 상호작용적으로 체험할 수 있게 해준다.79</p>
<ul>
<li><strong>핵심 이점</strong>: 태양의 위치에 따른 그림자 변화(일조량 연구), 유리, 금속, 석재 등 다양한 건축 자재의 질감과 반사, 그리고 실내 공간의 자연광 유입 등을 물리적으로 정확하게 시뮬레이션할 수 있다. 이는 설계 과정에서 즉각적인 피드백을 제공하여 반복 수정 작업을 가속화하고, 고객과의 소통을 원활하게 하며, 비용이 많이 드는 물리적 축소 모형 제작의 필요성을 줄여준다.80 또한, 실제 인간의 눈처럼 환경의 밝기 변화에 적응하는 효과(Eye Adaptation) 등을 시뮬레이션하여 몰입감을 극대화할 수도 있다.82</li>
</ul>
<p>자동차 설계 (Automotive Design)</p>
<p>자동차 디자인에서 차체의 곡선과 표면 위로 빛이 어떻게 흐르고 반사되는지는 차량의 미학을 결정하는 매우 중요한 요소다.83</p>
<ul>
<li><strong>핵심 이점</strong>: 실시간 레이트레이싱을 통해 디자이너들은 자신들이 만든 차체의 곡면 위에서 빛이 실시간으로, 그리고 물리적으로 정확하게 어떻게 반응하는지 즉시 확인할 수 있다.83 이는 과거 수 시간이 걸리던 오프라인 렌더링이나 값비싼 클레이 모델 제작 과정을 대체하거나 보완하여, 설계 주기를 단축하고 더 나은 미적 결정을 내릴 수 있도록 돕는다. 이는 외장 디자인뿐만 아니라, 가죽, 플라스틱, 우드 등 다양한 재질로 구성된 내장 디자인을 검증하는 데에도 동일하게 적용되며, 최종적으로는 고품질의 마케팅 이미지나 가상 쇼룸을 제작하는 데에도 활용된다.83</li>
</ul>
<h3>6.2  시뮬레이션과 에뮬레이션: NVIDIA Omniverse를 통한 산업용 디지털 트윈의 부상</h3>
<p><strong>NVIDIA Omniverse</strong>는 현실 세계의 물리적 자산, 프로세스, 환경을 가상 공간에 그대로 복제하는 **디지털 트윈(Digital Twin)**을 구축하고 운영하기 위한 협업 플랫폼이다.85 Omniverse는 Pixar의 개방형 3D 씬 기술인 OpenUSD(Universal Scene Description)를 기반으로 하며, 그 핵심 렌더링 엔진은 RTX 실시간 레이트레이싱 기술로 구동된다. 이는 디지털 트윈이 물리적 원본과 시각적으로나 물리적으로 거의 동일한, 높은 충실도(high-fidelity)를 갖도록 보장한다.85</p>
<ul>
<li><strong>공장 및 물류창고 시뮬레이션</strong>: 실제 공장의 디지털 트윈을 생성하여 생산 라인의 레이아웃을 최적화하고, 로봇의 작업 흐름을 시뮬레이션하며, 실제 환경에 배치하기 전에 안전한 가상 환경에서 AI 로봇을 훈련시키는 데 사용된다.86</li>
<li><strong>자율주행차 시뮬레이션</strong>: 물리적으로 정확하게 레이트레이싱된 가상 세계에서 카메라, LiDAR, 레이더와 같은 자율주행 센서 데이터를 시뮬레이션하여 ADAS(첨단 운전자 보조 시스템) 및 자율주행 시스템을 훈련하고 검증한다. 이는 실제 도로에서 데이터를 수집하는 것보다 훨씬 안전하고, 비용 효율적이며, 다양한 시나리오를 무한히 테스트할 수 있다는 장점이 있다.88</li>
<li><strong>과학적 시각화</strong>: 연구자들이 방대한 양의 시뮬레이션 데이터를 고품질의 그래픽으로 실시간 상호작용하며 분석할 수 있도록 돕는다.86</li>
</ul>
<p>디지털 트윈은 실시간 레이트레이싱, 물리 시뮬레이션, 그리고 AI가 궁극적으로 융합된 개념이다. 물리적 시스템의 3D 모델을 레이트레이싱으로 사실적으로 구현하고, IoT 센서를 통해 실제 데이터를 실시간으로 동기화하며, 이 고충실도 가상 환경 내에서 AI 모델을 훈련하고 테스트한다. 그리고 시뮬레이션에서 얻은 통찰력을 다시 물리적 시스템을 최적화하는 데 사용하는 이 피드백 루프야말로 디지털 트윈의 진정한 힘이며, 그 중심에는 물리적 정확성을 보장하는 실시간 레이트레이싱이 있다.85</p>
<h3>6.3  무선 통신 및 센서 모델링</h3>
<p>실시간 레이트레이싱의 적용 분야는 빛의 시뮬레이션을 넘어 전파(Radio Frequency, RF) 시뮬레이션이라는 새로운 영역으로 확장되고 있다. 5G 및 6G 무선 네트워크 설계에서, 전파를 빛의 광선처럼 취급하여 복잡한 도심 환경에서의 신호 경로를 추적할 수 있다.90</p>
<p>**NVIDIA Aerial Omniverse Digital Twin (AODT)**은 이러한 개념을 구체화한 플랫폼이다. AODT는 실제 도시의 3D 모델 위에서 레이트레이싱을 통해 전파 채널을 시뮬레이션하고, 이를 NVIDIA의 소프트웨어 정의 RAN(Radio Access Network) 플랫폼과 결합한다. 이를 통해 통신 사업자들은 실제 기지국을 설치하기 전에 네트워크 커버리지, 간섭 현상, 신호 품질을 매우 정확하게 예측하고, 차세대 무선 통신 시스템 및 AI 기반 네트워크 관리 알고리즘을 개발하고 테스트할 수 있다.90 이는 물리적 법칙에 기반한 시뮬레이션이 어떻게 막대한 경제적 가치를 창출할 수 있는지를 보여주는 대표적인 사례이다.</p>
<h2>7.  결론: 종합 및 미래 전망</h2>
<p>실시간 레이트레이싱은 단일 기술의 발명품이 아니라, 세 가지 핵심 기술 기둥의 **공생적 동반 진화(symbiotic co-evolution)**를 통해 비로소 현실이 된 패러다임 전환이다.</p>
<ol>
<li><strong>하드웨어 가속</strong>: RT 코어와 레이 가속기와 같은 전용 실리콘이 레이트레이싱의 핵심적인 계산 부담을 덜어주었다.</li>
<li><strong>표준화된 소프트웨어</strong>: DXR 및 Vulkan과 같은 API가 안정적인 개발 환경을 제공하고 하이브리드 렌더링을 위한 프레임워크를 마련했다.</li>
<li><strong>AI 기반 성능 확보</strong>: 디노이징과 슈퍼 샘플링이라는 필수적인 기술이 극복 불가능해 보였던 성능과 품질 문제를 해결하여 기술의 실용성을 확보했다.</li>
</ol>
<p>이러한 발전은 영화 VFX를 위한 오프라인 렌더링과 게임을 위한 실시간 렌더링 사이의 경계를 빠르게 허물고 있다. 과거에는 상상할 수 없었던 수준의 시각적 품질과 기술이 이제 인터랙티브 애플리케이션에서 구현되고 있으며, 그 종착점은 완전한 실시간 패스 트레이싱을 향하고 있다.</p>
<p>미래를 전망할 때, 기술의 발전은 계속해서 세 가지 축을 중심으로 이루어질 것이다. 하드웨어는 더욱 강력하고 효율적인 전용 코어들의 심층적인 통합으로 발전할 것이고, 소프트웨어와 알고리즘은 ReSTIR과 같은 지능형 샘플링 기법과 인라인 레이트레이싱의 보편화를 통해 더욱 유연하고 효율적으로 진화할 것이다. 그리고 AI는 업스케일링과 디노이징을 넘어, 재질 생성, 광 경로 예측, 심지어 애니메이션에 이르기까지 렌더링 파이프라인의 모든 영역에 더욱 깊숙이 통합될 것이다.</p>
<p>궁극적인 목표는 명확하다. 소비자 수준의 하드웨어에서, 현실과 구분이 불가능한 수준의 완전한 동적 실시간 패스 트레이싱을 높은 해상도와 프레임률로 구현하는 것이다. 아직 해결해야 할 과제는 남아있지만, 지난 10년간 구축된 기술적 토대와 발전의 궤적은 이 목표가 더 이상 ’가능한가’의 문제가 아니라 ’언제’의 문제임을 명확히 보여주고 있다. 실시간 레이트레이싱은 3D 그래픽스의 새로운 시대를 열었으며, 그 혁신은 이제 막 시작되었을 뿐이다.</p>
<h2>8. 참고 자료</h2>
<ol>
<li>래스터화 - 위키백과, 우리 모두의 백과사전, accessed July 5, 2025, <a href="https://ko.wikipedia.org/wiki/%EB%9E%98%EC%8A%A4%ED%84%B0%ED%99%94">https://ko.wikipedia.org/wiki/%EB%9E%98%EC%8A%A4%ED%84%B0%ED%99%94</a></li>
<li>Ray Tracing vs. Path Tracing vs. 래스터화 설명, accessed July 5, 2025, <a href="https://pcoptimizedsettings.com/ko/ray-tracing-vs-path-tracing-vs-%EB%9E%98%EC%8A%A4%ED%84%B0%ED%99%94-%EC%84%A4%EB%AA%85/">https://pcoptimizedsettings.com/ko/ray-tracing-vs-path-tracing-vs-%EB%9E%98%EC%8A%A4%ED%84%B0%ED%99%94-%EC%84%A4%EB%AA%85/</a></li>
<li>렌더링 파이프라인 간단 정리 - Blemish - 티스토리, accessed July 5, 2025, https://jeonhw.tistory.com/27</li>
<li>RTX란 무엇인가 3편 - GeForce RTX 튜링 아키텍처 | Where Sungmin …, accessed July 5, 2025, https://sausagetaste.github.io/2021/03/01/what_is_rtx_3.html</li>
<li>3D 기술은 사라지지 않았다! - allscience - 티스토리, accessed July 5, 2025, https://allsicence.tistory.com/87</li>
<li>게임에서 레이 트레이싱이란 무엇입니까? - Corsair, accessed July 5, 2025, https://www.corsair.com/kr/ko/explorer/gamer/gaming-pcs/what-is-ray-tracing-in-games/</li>
<li>레이트레이싱, 패스 트레이싱, 디노이징 - Hybrid3D, accessed July 5, 2025, https://blog.hybrid3d.dev/2019-11-15-raytracing-pathtracing-denoising</li>
<li>광선 추적(ray tracing) 및 불칸(Vulkan) API를 활용한 고성능 센서 모델 - Applied Intuition, accessed July 5, 2025, https://www.appliedintuition.com/kr/blog/raytracing</li>
<li>Alan Wake 2: a deep dive into Remedy’s high-end ray tracing …, accessed July 5, 2025, https://www.eurogamer.net/digitalfoundry-2023-alan-wake-2-rt-deep-dive</li>
<li>레이트레싱 (Ray Tracing) - 용어사전 - CGlink, accessed July 5, 2025, https://cglink.com/terms/1166</li>
<li>모바일 레이 트레이싱 | 기술 | 삼성반도체 - Samsung Semiconductor, accessed July 5, 2025, https://semiconductor.samsung.com/kr/technologies/processor/mobile-ray-tracing/</li>
<li>RayTracing의 기본적인 개념과 단계 - Dev Loves Art,소기쓰리디, accessed July 5, 2025, <a href="https://sogi3d.tistory.com/entry/RayTracing%EC%9D%98-%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8-%EA%B0%9C%EB%85%90%EA%B3%BC-%EB%8B%A8%EA%B3%84">https://sogi3d.tistory.com/entry/RayTracing%EC%9D%98-%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9D%B8-%EA%B0%9C%EB%85%90%EA%B3%BC-%EB%8B%A8%EA%B3%84</a></li>
<li>레이트레이싱 VS 레스터라이제이션, 승자는?! - 재능넷, accessed July 5, 2025, https://www.jaenung.net/tree/24462</li>
<li>레이 트레이싱 (1), accessed July 5, 2025, https://jebae.github.io/ray-tracing-principle/</li>
<li>레이 트레이싱의 기초, accessed July 5, 2025, https://www.kocca.kr/knowledge/research/__icsFiles/afieldfile/2010/05/01/hhVybtiKrkdq.pdf</li>
<li>레이 트레이싱 (7), accessed July 5, 2025, https://jebae.github.io/ray-tracing-reflection-refraction/</li>
<li>게임 그래픽의 혁명! 레이트레이싱이란?? - 제대로 알고싶다 - YouTube, accessed July 5, 2025, https://m.youtube.com/watch?v=g72BOJGG56Y&amp;t=257s</li>
<li>What’s the difference between ray tracing in modern games? - YouTube, accessed July 5, 2025, https://www.youtube.com/watch?v=dcStpDs1Pew</li>
<li>라디오시티로 전역 조명 모델링 - 3ds Max 2016 도움말 - Autodesk Help, accessed July 5, 2025, https://help.autodesk.com/cloudhelp/2016/KOR/3DSMax-Archive/files/GUID-C5A3C77B-794B-4444-9783-7F2EA11C16BD.htm</li>
<li>RTX란 무엇인가 2편 - 레이트레이싱 이전의 기술 | Where Sungmin …, accessed July 5, 2025, https://sausagetaste.github.io/2020/11/16/what_is_rtx_2.html</li>
<li>GPU 용어 알아보기(CUDA, VRAM, Tensor Core, RT Core 등) - 배우고 싶은 것들을 모아, accessed July 5, 2025, <a href="https://whomini.tistory.com/entry/GPU-%EC%9A%A9%EC%96%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0CUDA-VRAM-Tensor-Core-RT-Core-%EB%93%B1">https://whomini.tistory.com/entry/GPU-%EC%9A%A9%EC%96%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0CUDA-VRAM-Tensor-Core-RT-Core-%EB%93%B1</a></li>
<li>요즘 금 대신 사용한다는 엔비디아 GPU 신제품 RTX 라인업의 작동 원리 - 바이라인네트워크, accessed July 5, 2025, https://byline.network/2018/08/22-18/</li>
<li>NVIDIA® DLSS란 무엇이며 어떻게 작동하나요? | 레노버 코리아 - Lenovo, accessed July 5, 2025, https://www.lenovo.com/kr/ko/glossary/what-is-nvidia-dlss/</li>
<li>딥 러닝 슈퍼 샘플링 - 위키백과, 우리 모두의 백과사전, accessed July 5, 2025, <a href="https://ko.wikipedia.org/wiki/%EB%94%A5_%EB%9F%AC%EB%8B%9D_%EC%8A%88%ED%8D%BC_%EC%83%98%ED%94%8C%EB%A7%81">https://ko.wikipedia.org/wiki/%EB%94%A5_%EB%9F%AC%EB%8B%9D_%EC%8A%88%ED%8D%BC_%EC%83%98%ED%94%8C%EB%A7%81</a></li>
<li>RDNA - 나무위키, accessed July 5, 2025, https://namu.wiki/w/RDNA</li>
<li>라데온 RX 6800/6800 XT 완전 리뷰 | AMD, 고성능 GPU 시장으로, accessed July 5, 2025, <a href="https://www.techlibrary.co.kr/t/73240/%EA%B2%8C%EC%9E%84/172774">https://www.techlibrary.co.kr/t/73240/%EA%B2%8C%EC%9E%84/172774</a></li>
<li>‘메인스트림 그래픽카드의 마스터피스’ 애즈락 AMD 라데온 RX 9060 XT 스틸레전드 16GB [써보니] - 위클리포스트(weeklypost), accessed July 5, 2025, https://www.weeklypost.kr/news/articleView.html?idxno=8833</li>
<li>AMD, 차세대 아키텍처 기반 ‘라데온 RX 9000 시리즈’ 발표 - 헬로티, accessed July 5, 2025, https://www.hellot.net/news/article.html?no=98443</li>
<li>AMD Radeon RX 9070 Series Technical Deep Dive - Architecture …, accessed July 5, 2025, https://www.techpowerup.com/review/amd-radeon-rx-9070-series-technical-deep-dive/3.html</li>
<li>AMD RDNA 4 Deep Dive: Exploring The Tech That Powers Radeon RX 9070 | HotHardware, accessed July 5, 2025, https://hothardware.com/reviews/amd-rdna-4-architecture-deep-dive</li>
<li>AMD RDNA 4 architecture deep dive: A 64-CU monolithic design with all-round improvements to compute, media encode-decode, ray tracing, and AI - Notebookcheck, accessed July 5, 2025, https://www.notebookcheck.net/AMD-RDNA-4-architecture-deep-dive-A-64-CU-monolithic-design-with-all-round-improvements-to-compute-media-encode-decode-ray-tracing-and-AI.969593.0.html</li>
<li>(HWCooling) Better, more capable than expected: RDNA 4 architecture deep dive - Reddit, accessed July 5, 2025, https://www.reddit.com/r/hardware/comments/1j195jy/hwcooling_better_more_capable_than_expected_rdna/</li>
<li>AMD RDNA 4 Architecture Deep-Dive: New Compute Units - BytePlus, accessed July 5, 2025, https://www.byteplus.com/en/topic/420142</li>
<li>엔비디아, Windows 10 업데이트와 함께 마이크로소프트 DXR 지원하는 신규 게임 레, accessed July 5, 2025, https://www.seminet.co.kr/channel_micro.html?menu=content_sub&amp;com_no=827&amp;category=product&amp;no=3828</li>
<li>MS, GDC서 더 리얼한 게임위한 DXR 기술 발표, accessed July 5, 2025, https://m.gamevu.co.kr/news/articleView.html?idxno=7497</li>
<li>Introduction to DirectX Raytracing - Chris Wyman, accessed July 5, 2025, http://cwyman.org/papers/rtg2019_Ch3_IntroductionToDirectXRaytracing.pdf</li>
<li>DirectX Raytracing (DXR) 프로그래밍 소개 - YouTube, accessed July 5, 2025, https://www.youtube.com/watch?v=ALcVb5b68Zw</li>
<li>DX12 Raytracing tutorial - Part 1 - NVIDIA Developer, accessed July 5, 2025, https://developer.nvidia.com/rtx/raytracing/dxr/dx12-raytracing-tutorial-part-1</li>
<li>DX12 Raytracing Tutorial - Extras - Another Ray Type - NVIDIA Developer, accessed July 5, 2025, https://developer.nvidia.com/rtx/raytracing/dxr/dx12-raytracing-tutorial/extra/dxr_tutorial_extra_another_ray_type</li>
<li>DirectX Raytracing, Tutorial 4, accessed July 5, 2025, http://cwyman.org/code/dxrTutors/tutors/Tutor4/tutorial04.md.html</li>
<li>Introduction to DirectX Raytracing (DXR) - SIGGRAPH 2018 | Beyond3D Forum, accessed July 5, 2025, https://forum.beyond3d.com/threads/introduction-to-directx-raytracing-dxr-siggraph-2018.60940/</li>
<li>DirectX Raytracing (DXR) Functional Spec - Microsoft Open Source, accessed July 5, 2025, https://microsoft.github.io/DirectX-Specs/d3d/Raytracing.html</li>
<li>DX12 Raytracing tutorial - Part 2 | NVIDIA Developer, accessed July 5, 2025, https://developer.nvidia.com/rtx/raytracing/dxr/dx12-raytracing-tutorial-part-2</li>
<li>Direct3D 12 raytracing samples - Learn Microsoft, accessed July 5, 2025, https://learn.microsoft.com/en-us/samples/microsoft/directx-graphics-samples/d3d12-raytracing-samples-win32/</li>
<li>Closest Hit Shader - Win32 apps - Learn Microsoft, accessed July 5, 2025, https://learn.microsoft.com/en-us/windows/win32/direct3d12/closest-hit-shader</li>
<li>Vulkan API - KO, accessed July 5, 2025, https://vkguide.dev/docs/ko/introduction/vulkan_overview/</li>
<li>Vulkan(API) - 나무위키, accessed July 5, 2025, https://namu.wiki/w/Vulkan(API)</li>
<li>Ray Tracing In Vulkan - Khronos Blog - The Khronos Group Inc, accessed July 5, 2025, https://www.khronos.org/blog/ray-tracing-in-vulkan</li>
<li>[그래픽스] Ray Tracing VS Path Tracing - velog, accessed July 5, 2025, <a href="https://velog.io/@15ywt/%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4-Ray-Tracing-VS-Path-Tracing">https://velog.io/@15ywt/%EA%B7%B8%EB%9E%98%ED%94%BD%EC%8A%A4-Ray-Tracing-VS-Path-Tracing</a></li>
<li>NVIDIA Real-Time Denoiser Delivers Best-in-Class Denoising in Ubisoft’s Watch Dogs Legion | NVIDIA Technical Blog, accessed July 5, 2025, https://developer.nvidia.com/blog/nvidia-real-time-denoiser-delivers-best-in-class-denoising-in-watch-dogs-legion/</li>
<li>언리얼 엔진의 레이 트레이싱 기술 완전 정복: 현실적인 그래픽의 비밀 - 재능넷, accessed July 5, 2025, https://www.jaenung.net/tree/23466</li>
<li>Spatiotemporal Variance-Guided Filtering: Real-time Reconstruction for Path Traced Global Illumination - Research at NVIDIA, accessed July 5, 2025, https://research.nvidia.com/labs/rtr/publication/schied2017spatiotemporal/</li>
<li>Spatiotemporal Variance-Guided Filtering (SVGF) - Wisp Wiki, accessed July 5, 2025, https://teamwisp.github.io/research/svfg.html</li>
<li>Spatiotemporal Variance-Guided Filtering: Real-Time Reconstruction for Path-Traced Global Illumination, accessed July 5, 2025, https://cg.ivd.kit.edu/publications/2017/svgf/svgf_preprint.pdf</li>
<li>Ray Tracing Denoising - Alain Galvan, accessed July 5, 2025, https://alain.xyz/blog/ray-tracing-denoising</li>
<li>NVIDIA-RTX/NRD: NVIDIA Real-time Denoising (NRD) library - GitHub, accessed July 5, 2025, https://github.com/NVIDIA-RTX/NRD</li>
<li>DLSS - 나무위키, accessed July 5, 2025, https://namu.wiki/w/DLSS</li>
<li>NVIDIA DLSS란 무엇인가요? - Corsair, accessed July 5, 2025, https://www.corsair.com/kr/ko/explorer/gamer/gaming-pcs/what-is-nvidia-dlss/</li>
<li>A quick comparison between Raw Path Tracing, Standard Denoising, and Ray Reconstruction : r/nvidia - Reddit, accessed July 5, 2025, https://www.reddit.com/r/nvidia/comments/16pyvvn/a_quick_comparison_between_raw_path_tracing/</li>
<li>What is AMD FSR? Upscaling, frame generation, and FSR 4 explained - PCGamesN, accessed July 5, 2025, https://www.pcgamesn.com/amd/fsr-fidelity-fx-super-resolution</li>
<li>그래픽 카드 성능을 높이는 세 가지 기술: DLSS, FSR, AFMF 이해하기 - 알고사자, accessed July 5, 2025, https://www.rgosaja.co.kr/buypcinkitinfo/?q=YToxOntzOjEyOiJrZXl3b3JkX3R5cGUiO3M6MzoiYWxsIjt9&amp;bmode=view&amp;idx=164565138&amp;t=board</li>
<li>AMD FidelityFX 슈퍼 해상도에 대한 간단한 설명 | CORSAIR, accessed July 5, 2025, https://www.corsair.com/kr/ko/explorer/gamer/gaming-pcs/amd-fsr-3/</li>
<li>AMD FSR 4 vs NVIDIA DLSS 4 - Corsair, accessed July 5, 2025, https://www.corsair.com/kr/ko/explorer/gamer/gaming-pcs/fsr-4-vs-dlss-4/</li>
<li>Control: Multiple Stunning Ray-Traced Effects Raise The Bar For …, accessed July 5, 2025, https://www.nvidia.com/en-us/geforce/news/gfecnt/control-rtx-ray-tracing-dlss/</li>
<li>‘Control’ Looks Absolutely Stunning On PC And Shows The Real Power Of Ray-Tracing, accessed July 5, 2025, https://www.mensxp.com/technology/games/56176-control-looks-absolutely-stunning-on-pc-and-shows-the-real-power-of-ray-tracing.html</li>
<li>Ray tracing (graphics) - Wikipedia, accessed July 5, 2025, https://en.wikipedia.org/wiki/Ray_tracing_(graphics)</li>
<li>How Control’s Locations &amp; Visuals Enhance the Narrative - YouTube, accessed July 5, 2025, https://www.youtube.com/watch?time_continue=3&amp;v=nagVzDHH8qE</li>
<li>NVIDIA’s Advanced Ray Tracing Effects in Control - YouTube, accessed July 5, 2025, https://www.youtube.com/watch?v=gJ7gdBGXODI</li>
<li>HDRP 레이트레이싱 / NVIDIA X UNITY 웨비나 - 스튜디오 오버그래픽스 - 티스토리, accessed July 5, 2025, https://mgtul.tistory.com/132</li>
<li>Best graphics of the year: Digital Foundry ranks its top games of 2023 - Cyberpunk 2077 with RT Overdrive, Avatar: Frontiers of Pandora and Alan Wake | IconEra, accessed July 5, 2025, https://icon-era.com/threads/best-graphics-of-the-year-digital-foundry-ranks-its-top-games-of-2023-cyberpunk-2077-with-rt-overdrive-avatar-frontiers-of-pandora-and-alan-wake.8293/</li>
<li>Digital Foundry’s ray tracking analysis in Cyberpunk 2077 (Non echo chamber ver) - PC, accessed July 5, 2025, https://gamefaqs.gamespot.com/boards/916373-pc/79186828</li>
<li>Digital Foundry’s deep dive analysis with ray tracing in Cyberpunk 2077 - PC - GameFAQs, accessed July 5, 2025, https://gamefaqs.gamespot.com/boards/916373-pc/79186571</li>
<li>Cyberpunk 2077 PC: What Does Ray Tracing Deliver… And Is It Worth It? - YouTube, accessed July 5, 2025, https://www.youtube.com/watch?v=6bqA8F6B6NQ</li>
<li>Cyberpunk 2077 Ray Tracing: Overdrive Technology Preview on RTX 4090 - YouTube, accessed July 5, 2025, https://www.youtube.com/watch?v=I-ORt8313Og</li>
<li>Alan Wake 2 PC Path Tracing: The Next Level In Visual Fidelity? : r/nvidia - Reddit, accessed July 5, 2025, https://www.reddit.com/r/nvidia/comments/17nnhke/alan_wake_2_pc_path_tracing_the_next_level_in/</li>
<li>Alan Wake 2 - DLSS 3.5, Ray Tracing &amp; Path Tracing Benchmarks - DSOGaming, accessed July 5, 2025, https://www.dsogaming.com/pc-performance-analyses/alan-wake-2-dlss-3-5-ray-tracing-path-tracing-benchmarks/</li>
<li>AMD Ray Reconstruction - History of and Paper Review - YouTube, accessed July 5, 2025, https://www.youtube.com/watch?v=Xu0OPsTY8oA</li>
<li>NVIDIA RTX Kit - NVIDIA Developer, accessed July 5, 2025, https://developer.nvidia.com/rtx-kit</li>
<li>Architectural Visualization and Real-Time Ray Tracing - Easy Render, accessed July 5, 2025, https://www.easyrender.com/a/architectural-visualization-and-real-time-ray-tracing</li>
<li>Why Real-Time Rendering Technology Matters for Architectural Visualization?, accessed July 5, 2025, https://mapsystemsindia.com/blog/real-time-rendering-for-architectural-visualization.html</li>
<li>What is Ray Tracing and Its Uses in Architectural Visualization - McLine Studios, accessed July 5, 2025, https://mclinestudios.com/ray-tracing-in-architecture/</li>
<li>Improving Presence in Real-time Architectural Visualization - Taylor &amp; Francis Online, accessed July 5, 2025, https://www.tandfonline.com/doi/full/10.1080/23311983.2020.1767346</li>
<li>Real-time ray tracing in Unreal Engine - Part 3: automotive design and visualization, accessed July 5, 2025, https://www.unrealengine.com/en-US/blog/real-time-ray-tracing-in-unreal-engine—part-3-automotive-design-and-visualization</li>
<li>The Holy Grail: GPU realtime raytracing - Autodesk Blogs, accessed July 5, 2025, https://blogs.autodesk.com/design-studio/2020/07/21/the-holy-grail-real-time-gpu-ray-tracing/</li>
<li>Utilizing NVIDIA Omniverse™ for Digital Twin Projects at the NTT DATA Innovation Center, accessed July 5, 2025, https://www.nttdata.com/global/en/insights/focus/2023/utilizing-nvidia-omniverse-for-digital-twin-projects-at-the-ntt-data-innovation-center</li>
<li>Omniverse Platform for OpenUSD - NVIDIA, accessed July 5, 2025, https://www.nvidia.com/en-us/omniverse/</li>
<li>NVIDIA Omniverse, could someone explain its use and what it does in Layman’s term : r/VisionPro - Reddit, accessed July 5, 2025, https://www.reddit.com/r/VisionPro/comments/1biiu52/nvidia_omniverse_could_someone_explain_its_use/</li>
<li>Ray tracing rendering engine – seeing the world through the eye of a sensor - rFpro, accessed July 5, 2025, https://rfpro.com/applications-autonomous-vehicle-development/adas-autonomous-vehicles/ray-tracing/</li>
<li>Blog: Industry-leading ray tracing technology for sensor modelling - rFpro, accessed July 5, 2025, https://rfpro.com/blog-industry-leading-ray-tracing-technology-for-sensor-modelling/</li>
<li>NVIDIA Aerial Omniverse Digital Twin, accessed July 5, 2025, https://developer.nvidia.com/aerial-omniverse-digital-twin</li>
<li>Ray Tracing for 5G &amp; 6G: Real-Time RF Simulation &amp; Optimization | VIAVI Solutions Inc., accessed July 5, 2025, https://www.viavisolutions.com/en-us/what-ray-tracing</li>
<li>NVIDIA Aerial Omniverse Digital Twin Boosts Development of AI-Native Wireless and Deployment Flexibility, accessed July 5, 2025, https://developer.nvidia.com/blog/nvidia-aerial-omniverse-digital-twin-boosts-development-of-ai-native-wireless-and-deployment-flexibility/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>