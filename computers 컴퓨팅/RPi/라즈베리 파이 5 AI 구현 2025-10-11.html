<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:라즈베리 파이 5 AI 구현</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>라즈베리 파이 5 AI 구현</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">컴퓨터 (Computers)</a> / <a href="index.html">라스베리 파이</a> / <span>라즈베리 파이 5 AI 구현</span></nav>
                </div>
            </header>
            <article>
                <h1>라즈베리 파이 5 AI 구현</h1>
<p>2025-10-11, G25DR</p>
<h3>0.1 초록:</h3>
<p>본 보고서는 라즈베리 파이 5 플랫폼에서의 인공지능(AI) 구현에 대한 철저한 기술적 분석을 제공한다. 하드웨어 아키텍처를 해부하고, 내장 프로세싱 성능을 평가하며, 전용 신경망 처리 장치(NPU) 가속기를 벤치마킹하고, 외부 GPU(eGPU) 통합이라는 실험적 영역을 탐구하며, 소프트웨어 생태계를 조사한다. 경험적 데이터와 아키텍처 분석의 종합을 통해, 성능, 전력, 비용, 복잡성 제약에 기반한 최적의 AI 구현 전략 선택을 위한 의사결정 프레임워크를 수립한다. 본 문서는 라즈베리 파이 5를 사용하여 엣지에서 강력하고 효율적인 AI 솔루션을 배포하고자 하는 엔지니어, 연구자, 고급 실무자들을 위한 결정적인 가이드 역할을 한다.</p>
<h2>1.  엣지 AI의 기반으로서의 라즈베리 파이 5</h2>
<h3>1.1  아키텍처의 진화: 엣지 컴퓨트를 위한 패러다임 전환</h3>
<p>라즈베리 파이 5는 단순한 점진적 업그레이드가 아니라, 엣지 AI 환경에서의 역할을 재정의하는 중요한 아키텍처 재설계의 산물이다.1 라즈베리 파이 4의 Cortex-A72에서 라즈베리 파이 5의 Cortex-A76으로의 전환은 클럭당 명령어 처리 성능(IPC)과 효율성의 비약적인 발전을 의미하며, 이는 복잡한 AI 모델 실행에 필수적이다.3</p>
<p>특히, 라즈베리 파이가 자체 설계한 RP1 “사우스브리지” I/O 컨트롤러의 도입은 핵심적인 변화이다. 이는 주변장치 I/O를 메인 SoC로부터 분리하여 “주변장치 성능과 기능성의 단계적 변화“를 가져왔다.5 이 아키텍처적 결정은 고성능 AI 가속기를 효과적으로 활용할 수 있는 토대를 마련했으며, 이전 모델들이 겪었던 I/O 병목 현상을 근본적으로 해결한다.</p>
<p>이러한 세대 간의 도약은 아래 표 1에서 명확하게 확인할 수 있다. CPU 아키텍처, 캐시 구조, 메모리 기술, 그리고 결정적으로 PCIe 인터페이스의 유무는 라즈베리 파이 5가 이전 세대와는 근본적으로 다른 수준의 컴퓨팅 플랫폼임을 보여준다.</p>
<p><strong>표 1: 라즈베리 파이 5 대 라즈베리 파이 4 주요 아키텍처 비교</strong></p>
<table><thead><tr><th>사양</th><th>라즈베리 파이 4 모델 B</th><th>라즈베리 파이 5</th></tr></thead><tbody>
<tr><td><strong>SoC</strong></td><td>Broadcom BCM2711</td><td>Broadcom BCM2712</td></tr>
<tr><td><strong>CPU 아키텍처</strong></td><td>4 × Cortex-A72 (ARMv8-A)</td><td>4 × Cortex-A76 (ARMv8-A)</td></tr>
<tr><td><strong>CPU 클럭 속도</strong></td><td>1.5 GHz (이후 1.8 GHz)</td><td>2.4 GHz</td></tr>
<tr><td><strong>캐시</strong></td><td>1MB L2 (공유)</td><td>512KB L2 (코어당), 2MB L3 (공유)</td></tr>
<tr><td><strong>GPU 아키텍처</strong></td><td>VideoCore VI</td><td>VideoCore VII</td></tr>
<tr><td><strong>GPU 클럭 속도</strong></td><td>500 MHz</td><td>800 MHz</td></tr>
<tr><td><strong>RAM 유형</strong></td><td>LPDDR4-3200 SDRAM</td><td>LPDDR4X-4267 SDRAM</td></tr>
<tr><td><strong>최대 RAM 용량</strong></td><td>8 GB</td><td>16 GB</td></tr>
<tr><td><strong>I/O 컨트롤러</strong></td><td>SoC에 통합</td><td>RP1 “사우스브리지”</td></tr>
<tr><td><strong>PCIe 인터페이스</strong></td><td>없음</td><td>PCIe 2.0 x1</td></tr>
</tbody></table>
<p>데이터 출처: 4</p>
<h3>1.2  BCM2712 시스템 온 칩(SoC): AI 성능의 심장</h3>
<h4>1.2.1  CPU: 쿼드 코어 64비트 Arm Cortex-A76 @ 2.4GHz</h4>
<p>BCM2712 SoC의 핵심은 라즈베리 파이 4 대비 2~3배의 CPU 성능 향상을 제공하는 쿼드 코어 Cortex-A76 프로세서이다.3 이 성능 향상은 단순히 클럭 속도 증가에 기인한 것이 아니라, AI 워크로드에 직접적인 영향을 미치는 마이크로아키텍처 개선에 기반한다.</p>
<ul>
<li>
<p><strong>캐시 계층 구조:</strong> 라즈베리 파이 5는 코어당 512KB의 L2 캐시와 2MB의 공유 L3 캐시를 탑재했다.3 이는 라즈베리 파이 4의 공유 1MB L2 캐시 구조에서 크게 발전한 것으로, 모델 추론 중 메모리 지연 시간을 줄여 데이터에 더 빠르게 접근할 수 있게 한다. 이는 AI 모델의 가중치와 활성화 값을 처리할 때 성능에 결정적인 영향을 미친다.</p>
</li>
<li>
<p><strong>ARMv8.2-A ISA 및 암호화 확장:</strong> 최신 명령어 집합 아키텍처(ISA)를 채택하고 하드웨어 암호화 확장을 포함함으로써 전반적인 시스템 성능과 보안이 강화되었다. 특히 암호화 작업에서는 라즈베리 파이 4보다 45배 빠른 속도를 보여주며, 이는 SoC의 현대화 수준을 단적으로 보여주는 예이다.14</p>
</li>
</ul>
<h4>1.2.2  GPU: VideoCore VII @ 800MHz</h4>
<p>업그레이드된 VideoCore VII GPU는 그래픽 성능뿐만 아니라 범용 컴퓨팅(GPGPU) 능력에서도 상당한 발전을 이루었다.</p>
<ul>
<li>
<p><strong>컴퓨팅 역량:</strong> OpenGL ES 3.1과 Vulkan 1.2/1.3과 같은 현대적인 그래픽 API를 지원한다.3 특히 Vulkan 지원은 GPU를 AI 모델 가속과 같은 컴퓨팅 작업에 활용할 수 있는 핵심적인 기술적 기반이 된다.</p>
</li>
<li>
<p><strong>성능 향상:</strong> 이 GPU는 라즈베리 파이 4의 VideoCore VI보다 2~2.5배 빠르다고 알려져 있고 1, 실제 벤치마크에서도 그래픽 및 컴퓨팅 성능에서 상당한 향상을 보였다.15</p>
</li>
</ul>
<h4>1.2.3  메모리 하위 시스템: LPDDR4X-4267 SDRAM</h4>
<p>AI 모델은 대량의 데이터를 신속하게 처리해야 하므로 메모리 대역폭이 매우 중요하다. 라즈베리 파이 5는 이 점에서 큰 이점을 가진다.</p>
<ul>
<li>
<p>2GB, 4GB, 8GB, 그리고 새롭게 추가된 16GB의 RAM 옵션을 제공하여 다양한 규모의 프로젝트에 대응할 수 있다.3</p>
</li>
<li>
<p>라즈베리 파이 4의 LPDDR4-3200보다 빠른 LPDDR4X-4267 메모리를 사용하여 최대 17GB/s의 메모리 대역폭을 제공한다.4 이 넓은 대역폭은 CPU와 연결된 가속기에 데이터를 원활하게 공급하는 데 필수적이다. 특히 16GB 모델은 거대 언어 모델(LLM)과 같은 메모리 집약적인 애플리케이션을 위해 특별히 포지셔닝되었다.19</p>
</li>
</ul>
<p>이러한 CPU, GPU, 메모리의 유기적인 개선은 라즈베리 파이 5를 이전 모델들과 차별화하는 핵심 요소이다. 이전에는 CPU 성능, 메모리 대역폭, I/O 중 하나가 항상 병목 지점이 되었지만, 라즈베리 파이 5는 이 세 가지 요소를 균형 있게 발전시켜 고성능 AI 파이프라인을 지속할 수 있는 최초의 라즈베리 파이로 설계되었다.</p>
<h3>1.3  PCIe 2.0 x1 인터페이스: 고속 가속으로의 관문</h3>
<p>고급 AI 구현을 위한 가장 중요한 단일 기능은 FFC(Flexible Flat Cable) 커넥터를 통해 제공되는 단일 레인 PCI Express 2.0 인터페이스이다.3 이 인터페이스는 NVMe SSD와 같은 고속 저장 장치뿐만 아니라, 결정적으로 NPU 가속기와 같은 고대역폭 주변장치를 연결할 수 있는 통로를 열어준다.1</p>
<p>이 인터페이스를 활용하기 위해서는 별도의 M.2 HAT이나 다른 어댑터가 필요하며, 이는 시스템 설계 시 고려해야 할 사항이다.3 또한, 시스템 설정 파일(<code>config.txt</code>)에서 <code>dtparam=pciex1_gen=3</code> 옵션을 통해 PCIe Gen 3.0 속도를 강제할 수 있는데, 이는 이후 섹션에서 논의될 바와 같이 NPU 가속기의 성능을 극대화하는 데 매우 중요한 역할을 한다.23</p>
<h2>2.  온디바이스 AI 추론: 내장 CPU 및 GPU 역량 활용</h2>
<h3>2.1  CPU 중심 추론: 새로운 기준선</h3>
<p>라즈베리 파이 5의 CPU 성능은 온디바이스 AI의 기준선을 크게 높여, 이전에는 가속기가 필요했던 작업을 CPU만으로도 충분히 수행할 수 있게 만들었다.</p>
<h4>2.1.1  벤치마크 분석</h4>
<p>다양한 벤치마크 결과가 이러한 주장을 뒷받침한다.</p>
<ul>
<li>
<p><strong>일반 성능:</strong> Geekbench 6 점수는 라즈베리 파이 4 대비 단일 코어에서 약 2.4배, 다중 코어에서 약 2.2배의 성능 향상을 보여준다.14 다른 벤치마크들 역시 유사하거나 더 큰 폭의 성능 향상을 보고하고 있다.22</p>
</li>
<li>
<p><strong>AI 특화 성능 (TensorFlow Lite):</strong> 가장 주목할 만한 결과는 TensorFlow Lite를 사용했을 때의 성능이다. 라즈베리 파이 5에서 전체 TensorFlow 모델은 라즈베리 파이 4보다 거의 5배 빠르게 실행되며, TensorFlow Lite 성능은 이제 구글 Coral TPU와 동등한 수준에 도달했다.28 이는 저가형 가속기의 가치 제안을 재구성하는 매우 중요한 데이터 포인트이다.</p>
</li>
<li>
<p><strong>AI 특화 성능 (ncnn):</strong> ncnn 프레임워크를 사용한 벤치마크에서는 MobileNetV2나 FastestDet과 같은 모델에서 4개의 스레드를 사용했을 때 추론 시간이 약 4배 향상되는 것을 보여준다.2 이 결과는 CPU만 사용한 테스트임에도 불구하고 인상적인 성능을 보여준다.2</p>
</li>
</ul>
<p>이러한 결과들은 엣지 AI 시장의 구도를 바꾸는 중요한 의미를 가진다. 과거 라즈베리 파이 3나 4와 같은 보드에서 Coral 같은 가속기가 필수적이었던 이유는 호스트 CPU의 성능 부족 때문이었다.28 하지만 이제 라즈베리 파이 5의 CPU는 실시간 비디오 추론(예: ncnn으로 YOLOv8n에서 약 12 FPS)을 충분히 소화할 수 있고 2, TensorFlow Lite에서는 Coral TPU와 비견될 만한 성능을 낸다.28 이는 기본적인 객체 탐지나 분류와 같은 수많은 애플리케이션에서 별도 가속기의 추가 비용, 복잡성, 전력 소모가 더 이상 정당화되지 않을 수 있음을 시사한다. 라즈베리 파이 5는 엣지 AI의 성능 하한선을 끌어올렸으며, 개발자들은 이제 CPU 기반 추론을 기본으로 삼고, 매우 까다로운 다중 스트림이나 저지연 애플리케이션에 한해서만 전용 NPU를 고려하는 방식으로 접근할 수 있게 되었다.</p>
<p><strong>표 2: CPU 기반 AI 추론 벤치마크 결과</strong></p>
<table><thead><tr><th>모델</th><th>프레임워크</th><th>RPi 4 (ms) - 4 스레드</th><th>RPi 5 (ms) - 4 스레드</th><th>성능 향상 배율</th></tr></thead><tbody>
<tr><td><strong>mobilenet_v2</strong></td><td>ncnn</td><td>61.88</td><td>13.63</td><td>4.5x</td></tr>
<tr><td><strong>mobilenet_v3</strong></td><td>ncnn</td><td>47.53</td><td>9.48</td><td>5.0x</td></tr>
<tr><td><strong>resnet50</strong></td><td>ncnn</td><td>262.83</td><td>56.29</td><td>4.7x</td></tr>
<tr><td><strong>FastestDet</strong></td><td>ncnn</td><td>38.69</td><td>6.59</td><td>5.9x</td></tr>
<tr><td><strong>MobileNet v1 SSD</strong></td><td>TensorFlow Lite</td><td>~140</td><td>~27</td><td>~5.2x</td></tr>
<tr><td><strong>MobileNet v2 SSD</strong></td><td>TensorFlow Lite</td><td>~155</td><td>~30</td><td>~5.2x</td></tr>
</tbody></table>
<p>데이터 출처:.2 TensorFlow Lite 값은 그래프에서 추정됨.</p>
<h4>2.1.2  소프트웨어 프레임워크 및 설치</h4>
<p>CPU 추론을 위한 주요 프레임워크 설정은 다음과 같다.</p>
<ul>
<li>
<p><strong>TensorFlow Lite:</strong> 경량 배포를 위해 <code>tflite-runtime</code> 패키지를 설치하는 것이 권장된다.30</p>
</li>
<li>
<p><strong>PyTorch:</strong> ARM64에서의 설치는 다소 까다로울 수 있으며, 공식 지원이 일관되지 않아 커뮤니티에서 제공하는 휠(wheel) 파일이나 가상 환경을 사용하는 것이 일반적이다.32</p>
</li>
<li>
<p><strong>ONNX Runtime:</strong> ONNX를 범용 모델 형식으로 활용하고 라즈베리 파이 5에 배포할 수 있다.36</p>
</li>
<li>
<p><strong>ncnn:</strong> ARM CPU에 고도로 최적화되어 있으며 벤치마크에서 강력한 성능을 보여주는 탁월한 선택지이다.2</p>
</li>
</ul>
<h3>2.2  VideoCore VII GPU를 컴퓨팅에 활용하기</h3>
<p>라즈베리 파이 5의 GPU 가속은 아직 초기 단계이지만 매우 유망한 분야이다.</p>
<ul>
<li>
<p><strong>Vulkan의 역할:</strong> VideoCore VII의 Vulkan 1.2/1.3 지원이 핵심 기술이다.8 Vulkan은 GPGPU 작업을 가능하게 하는 현대적인 저수준 API로, 라즈베리 파이 5는 라즈베리 파이 4에 비해 Vulkan 컴퓨팅 성능에서 몇 배 더 빠른 현저한 향상을 보여준다.15</p>
</li>
<li>
<p><strong>프레임워크 지원:</strong></p>
</li>
<li>
<p><strong>ncnn:</strong> 이 프레임워크는 Vulkan 백엔드를 통한 GPU 가속을 명시적으로 지원하며, 이를 활용하면 CPU 전용 성능을 능가한다고 알려져 있다.2</p>
</li>
<li>
<p><strong>llama.cpp:</strong> <code>llama.cpp</code>에 Vulkan 지원이 통합되면서 라즈베리 파이 5의 내장 GPU에서 직접 LLM 추론을 가속하는 것이 가능해졌으며, 이는 매우 중요한 발전이다.37</p>
</li>
<li>
<p><strong>TensorFlow Lite:</strong> TFLite에 GPU 델리게이트가 존재하지만, 라즈베리 파이 5의 VideoCore VII에서의 적용 및 성능은 아직 잘 문서화되어 있지 않아 추가적인 탐구가 필요한 영역이다.38</p>
</li>
</ul>
<p>GPU 가속의 잠재력은 크지만, 현재로서는 이를 쉽게 활용할 수 있는 소프트웨어 생태계가 미성숙한 상태이다. TensorFlow나 PyTorch와 같은 주류 프레임워크는 라즈베리 파이 5에서 ‘그냥 작동하는’ 공식 Vulkan 델리게이트를 제공하지 않는다.38 ncnn이나 <code>llama.cpp</code>처럼 Vulkan을 지원하는 프레임워크들은 더 전문적이며 소스 코드로부터 직접 빌드하는 등의 깊은 기술적 지식을 요구하는 경우가 많다.2 따라서 라즈베리 파이 5의 내장 GPU를 AI에 활용하는 것은 현재로서는 커스텀 빌드와 저수준 API에 익숙한 전문가급 개발자들의 영역이다. 성능 잠재력은 높지만 사용성의 격차가 크며, 이는 라즈베리 파이 생태계의 향후 소프트웨어 개발에서 핵심적인 영역이 될 것이다.</p>
<h3>2.3  내장 성능을 위한 최적화 전략</h3>
<ul>
<li>
<p><strong>모델 양자화(Quantization):</strong> 모델을 32비트 부동소수점(FP32)에서 8비트 정수(INT8)로 변환하는 과정이다. 이는 모델 크기를 줄이고 CPU의 정수 연산 기능을 활용하여 추론 속도를 높이는 핵심 기술로, TensorFlow Lite가 높은 성능을 보이는 주된 이유 중 하나이다.39</p>
</li>
<li>
<p><strong>올바른 프레임워크 선택:</strong> 프레임워크 선택이 성능에 큰 영향을 미친다. 예를 들어, ncnn은 ARM CPU에 고도로 최적화되어 있고 Vulkan 백엔드를 제공하여 강력한 선택지가 될 수 있는 반면 10, 전체 TensorFlow를 설치하는 것은 불필요하게 무겁다.28</p>
</li>
</ul>
<h2>3.  신경망 처리 장치(NPU)를 이용한 하드웨어 가속</h2>
<h3>3.1  공식 라즈베리 파이 AI 키트: 아키텍처 및 통합</h3>
<p>라즈베리 파이 재단은 공식 AI 가속 솔루션으로 라즈베리 파이 M.2 HAT+와 Hailo AI 모듈을 결합한 AI 키트를 출시했다.24</p>
<ul>
<li>
<p><strong>Hailo-8L NPU:</strong> 이 키트의 핵심은 13 TOPS(초당 테라 연산) 성능을 제공하는 Hailo-8L 신경망 추론 가속기이다.24 더 강력한 26 TOPS 성능의 Hailo-8을 탑재한 AI HAT+도 별도로 구매할 수 있다.44</p>
</li>
<li>
<p><strong>물리적 통합:</strong> 이 모듈은 M.2 2242 폼팩터를 사용하며, M.2 HAT+를 통해 라즈베리 파이 5의 PCIe 2.0 인터페이스에 연결된다. 열 방출을 위한 서멀 패드의 중요성도 강조된다.24</p>
</li>
</ul>
<p>이 공식 키트의 등장은 라즈베리 파이 생태계가 성숙하고 있음을 보여주는 중요한 신호이다. 이전에는 구글 Coral이나 인텔 NCS와 같은 서드파티 하드웨어에 의존해야 했고, 이들의 지원 수준이나 지속성은 불확실했다.30 실제로 구글의 Coral 지원은 약화된 것으로 평가받고 있다.28 반면, 라즈베리 파이 재단은 rpicam-apps, Picamera2 등 자체 소프트웨어 스택과 긴밀하게 통합된 솔루션을 직접 제공한다.24 이는 개발자들에게 안정적이고 장기적인 지원이 보장되는 플랫폼을 제공하며, 이는 단순한 취미 프로젝트를 넘어 상업적이고 장기적인 AI 프로젝트 개발의 위험을 줄여준다.</p>
<h3>3.2  최적의 NPU 성능을 위한 시스템 구성</h3>
<p>NPU의 잠재력을 최대한 활용하기 위해서는 정밀한 시스템 설정이 필수적이다.</p>
<ul>
<li>
<p><strong>OS 및 펌웨어:</strong> 최신 라즈베리 파이 OS(현재 Bookworm, Trixie는 미지원)와 2023년 12월 이후의 펌웨어가 필요하다.41</p>
</li>
<li>
<p><strong>드라이버 설치:</strong> <code>hailo-all</code> 패키지를 설치하여 필요한 드라이버와 런타임 도구를 확보해야 한다.25</p>
</li>
<li>
<p><strong>핵심적인 <code>config.txt</code> 수정:</strong> <code>/boot/firmware/config.txt</code> 파일에 <code>dtparam=pciex1</code>과 <code>dtparam=pciex1_gen=3</code> 라인을 추가하는 것이 매우 중요하다. 이 설정은 눈에 잘 띄지 않지만, 최대 성능을 이끌어내는 데 결정적인 역할을 한다.25</p>
</li>
</ul>
<h3>3.3  경험적 성능 분석: PCIe와 배치 처리의 영향</h3>
<p>벤치마크 결과는 NPU 성능을 좌우하는 요인들에 대한 깊은 이해를 제공한다.</p>
<ul>
<li>
<p><strong>PCIe Gen3의 절대적 중요성:</strong> YOLOv8s 모델을 사용한 벤치마크에서, 라즈베리 파이 5의 프레임률(FPS)은 PCIe Gen2 환경에 비해 PCIe Gen3 환경에서 <strong>두 배 더 높게</strong> 나타났다.48 이는 <code>config.txt</code> 설정 변경 하나만으로 100%의 성능 향상을 가져올 수 있음을 의미한다.</p>
</li>
<li>
<p><strong>배치 크기 최적화:</strong> 성능은 배치 크기에 따라 달라진다. FPS는 배치 크기 2에서 80, 4에서 100으로 증가하다가 <strong>배치 크기 8에서 120 FPS로 최고점</strong>을 기록한 후, 배치 크기 16에서는 다시 100 FPS로 감소했다.48</p>
</li>
<li>
<p><strong>PCIe 대역폭 포화 가설:</strong> 이러한 결과는 배치 크기 8에서 PCIe Gen3 x1 버스의 대역폭이 완전히 포화 상태에 이른다는 가설을 뒷받침한다. 이보다 큰 배치 크기는 I/O 병목 현상을 유발하여 NPU의 연산 능력을 상쇄시키고, 결과적으로 효율성 감소로 이어진다고 분석할 수 있다.48</p>
</li>
</ul>
<p>이는 AI 키트의 성능이 단순히 Hailo-8L 칩의 13 TOPS 사양만으로 결정되지 않는다는 것을 명확히 보여준다. 성능은 데이터 파이프라인, 특히 PCIe 버스에 의해 근본적으로 좌우된다. 따라서 AI 키트를 효과적으로 사용하기 위해서는 애플리케이션을 ’버스 인식적(bus-aware)’으로 설계해야 한다. 이는 단순히 AI 코드를 작성하는 것을 넘어, PCIe Gen3 활성화, 버스 용량에 맞는 배치 크기 조정, 데이터 전송 최소화 등 데이터 흐름을 공학적으로 설계하는 것을 포함한다. 시스템의 ‘실제’ 성능은 파이프라인의 가장 약한 연결 고리, 즉 PCIe x1 인터페이스에 의해 결정된다.</p>
<h3>3.4  가속기 성능 비교</h3>
<p><strong>표 3: AI 가속기 성능 비교 (YOLOv8s 모델 기준)</strong></p>
<table><thead><tr><th>구성</th><th>추론 속도 (FPS)</th><th>주요 병목 지점</th></tr></thead><tbody>
<tr><td><strong>RPi 5 CPU (ncnn)</strong></td><td>~12</td><td>CPU 연산 속도</td></tr>
<tr><td><strong>RPi 5 + Google Coral</strong></td><td>1-2 (보고됨)</td><td>드라이버/구성 문제 추정</td></tr>
<tr><td><strong>RPi 5 + AI Kit (PCIe Gen2)</strong></td><td>~60</td><td>PCIe 대역폭</td></tr>
<tr><td><strong>RPi 5 + AI Kit (PCIe Gen3, 최적 배치)</strong></td><td><strong>120</strong></td><td>PCIe 대역폭 포화</td></tr>
</tbody></table>
<p>데이터 출처: 2</p>
<p>위 표는 AI 키트의 압도적인 성능을 명확하게 보여준다. CPU 단독 실행 대비 약 10배의 성능 향상을 보이며, 구글 Coral은 현재 라즈베리 파이 5와의 호환성 문제로 인해 유의미한 성능을 내지 못하고 있다.48 서류상의 사양(Hailo-8L 13 TOPS vs. Coral 4 TOPS)과 아키텍처의 현대성을 고려할 때도 AI 키트가 우위에 있다.43 이 데이터는 고성능 작업을 위해 AI 키트를 선택하고 올바르게 구성하는 것이 왜 중요한지를 명확하게 입증한다.</p>
<h2>4.  고급 구현: 고성능 AI를 위한 외부 GPU(eGPU)</h2>
<h3>4.1  실현 가능성 및 시스템 아키텍처</h3>
<p>데스크톱급 GPU를 라즈베리 파이 5에 연결하는 것은 실험적이지만 기능적으로 가능한 영역이다. 이는 주로 거대 언어 모델(LLM)과 같이 내장 하드웨어나 AI 키트의 용량을 초과하는 모델을 실행하기 위해 시도된다.</p>
<ul>
<li>
<p><strong>필수 하드웨어:</strong></p>
</li>
<li>
<p>라즈베리 파이 5 (LLM을 위해 8GB 또는 16GB 모델 권장) 49</p>
</li>
<li>
<p>PCIe HAT/어댑터 (예: Pineboards HatDrive!, uPCIty Lite) 23</p>
</li>
<li>
<p>eGPU 도크/라이저 및 케이블 (예: JMT M.2 to PCIe 도크, OCuLink 케이블) 23</p>
</li>
<li>
<p>외부 ATX/SFX 파워 서플라이(PSU) (라즈베리 파이는 GPU에 필요한 전력을 공급할 수 없음) 23</p>
</li>
<li>
<p><strong>GPU 선택:</strong> 리눅스 커널의 오픈소스 <code>amdgpu</code> 드라이버 덕분에 AMD Polaris(RX 400/500) 및 최신 RDNA 카드(RX 6000/7000)가 가장 현실적인 선택지이다.23 Nvidia와 인텔 GPU는 비공개 소스 드라이버와 ARM64 아키텍처와의 비호환성 문제로 인해 지원이 매우 실험적이며 일반적으로 작동하지 않는다.52</p>
</li>
</ul>
<h3>4.2  소프트웨어 및 커널 엔지니어링: 심층 분석</h3>
<p>eGPU를 사용하기 위한 소프트웨어 설정은 매우 복잡하며 높은 수준의 기술을 요구한다.</p>
<ul>
<li>
<p><strong>커널 재컴파일:</strong> 라즈베리 파이 리눅스 커널을 소스 코드로부터 직접 재컴파일하는 것이 핵심 요구사항이다.23</p>
</li>
<li>
<p><strong><code>amdgpu</code> 패치 적용:</strong> ARM 아키텍처와의 비호환성을 해결하고 드라이버가 작동하도록 특정 패치를 커널 소스에 적용해야 한다.23</p>
</li>
<li>
<p><strong>드라이버 활성화:</strong> <code>make menuconfig</code>를 실행하여 최종 커널 이미지에 <code>amdgpu</code> 드라이버가 포함되도록 선택해야 한다.23</p>
</li>
<li>
<p><strong>Vulkan 지원:</strong> 패치를 적용한 커널 빌드가 성공하면 외부 GPU에서 안정적인 Vulkan 지원이 활성화되며, 이는 AI/ML 컴퓨팅 작업에 필수적이다.50</p>
</li>
</ul>
<h3>4.3  사용 사례 분석: 로컬 거대 언어 모델(LLM)</h3>
<p>eGPU의 주된 동기는 LLM 실행이다. Vulkan을 지원하는 <code>llama.cpp</code> 프레임워크를 사용하여 모델의 레이어를 eGPU로 오프로드할 수 있다.49</p>
<p><strong>표 4: eGPU LLM 추론 성능</strong></p>
<table><thead><tr><th>LLM</th><th>양자화</th><th>사용된 GPU</th><th>성능 (토큰/초)</th><th>비고</th></tr></thead><tbody>
<tr><td><strong>Llama-3.2 3B</strong></td><td>Q4_K_M</td><td>AMD WX 3100</td><td>16.90</td><td>VRAM에 완전히 적재 가능</td></tr>
<tr><td><strong>Llama-3.2 3B</strong></td><td>Q4_K_M</td><td>AMD RX 6700 XT</td><td>&gt; 20 (추정)</td><td>VRAM에 완전히 적재 가능</td></tr>
<tr><td><strong>Mistral 22B</strong></td><td>-</td><td>AMD RX 6700 XT</td><td>낮음</td><td>CPU/GPU 간 분할로 인한 성능 저하</td></tr>
</tbody></table>
<p>데이터 출처: 50</p>
<p>성능 분석 결과, PCIe 2.0 x1 레인이 압도적인 병목 지점임이 드러났다.51 GPU는 빠르게 계산할 수 있지만, 라즈베리 파이의 시스템 RAM과 GPU의 VRAM 간에 데이터를 전송하는 데 걸리는 시간이 전체 처리량을 심각하게 제한한다. 이는 특히 VRAM 용량을 초과하여 시스템 RAM을 함께 사용해야 하는 대규모 모델에서 두드러진다.50</p>
<p>결론적으로, 라즈베리 파이 5에서 eGPU를 사용하는 것은 플랫폼의 유연성과 오픈소스 커뮤니티의 역량을 보여주는 공학적 성과이지만, 비용 효율적이거나 성능 경쟁력이 있는 솔루션은 아니다. 총 구축 비용은 300~700달러에 달할 수 있으며 50, 이는 더 강력한 x86 미니 PC나 전용 AI 개발 보드(예: Jetson 시리즈)의 가격대에 해당한다.22 따라서 eGPU 구성은 한계를 탐구하는 연구 프로젝트에 더 가깝다고 볼 수 있다.</p>
<p>하지만 이 구성에는 예상치 못한 강력한 장점이 있다. 바로 유휴 상태에서의 탁월한 전력 효율성이다. 라즈베리 파이 5 자체는 유휴 시 2~3W만 소비하며 19, eGPU를 포함한 전체 시스템도 모델을 실행하지 않을 때는 10~12W의 낮은 전력만 사용한다.50 이는 간헐적으로 사용되는 ‘상시 가동형’ AI 에이전트(예: 홈 어시스턴트, 로컬 챗봇)에 매우 매력적인 특성이다. 운영 비용과 전력 소비가 중요한 홈랩 환경에서, 이 구성은 강력한 로컬 AI 모델을 배포하기 위한 독보적으로 에너지 효율적인 플랫폼을 제공한다.</p>
<h2>5.  라즈베리 파이 5의 실제 AI 애플리케이션</h2>
<h3>5.1  실시간 컴퓨터 비전</h3>
<ul>
<li>
<p><strong>객체 탐지:</strong> 파이 카메라(모듈 3 또는 AI 카메라)와 적절한 모델/프레임워크를 사용하여 객체 탐지 시스템을 구축할 수 있다.</p>
</li>
<li>
<p><strong>하드웨어:</strong> 라즈베리 파이 5, 카메라 모듈 3 55 또는 IMX500 센서가 탑재된 공식 AI 카메라.57</p>
</li>
<li>
<p><strong>소프트웨어:</strong> TensorFlow Lite나 OpenCV를 사용한 기본 탐지 30, 또는 AI 키트와 YOLOv8을 사용한 고성능 탐지.61</p>
</li>
<li>
<p><strong>프로젝트 예시:</strong> 스마트 보안 카메라, 야생 동물 모니터링, 산업 품질 관리(제조 부품의 이상 감지).30 <code>yokoyan-robotics/raspberry-pi5-imx500-yolo</code>와 같은 GitHub 저장소는 완전한 가이드를 제공한다.61</p>
</li>
</ul>
<h3>5.2  대화형 AI 및 음성 비서</h3>
<p>완전한 로컬, 저지연 음성 비서를 구축하는 것은 라즈베리 파이 5에서 여러 AI 모델을 동시에 실행하는 능력을 보여주는 강력한 사례이다.</p>
<ul>
<li>
<p><strong>하드웨어:</strong> 라즈베리 파이 5, 고품질 USB 마이크 또는 원거리 음성 인식을 위한 ReSpeaker와 같은 마이크 어레이.65</p>
</li>
<li>
<p><strong>소프트웨어 파이프라인:</strong></p>
</li>
</ul>
<ol>
<li>
<p><strong>호출어 감지(Wake Word Detection):</strong> Picovoice와 같은 경량 모델.69</p>
</li>
<li>
<p><strong>음성-텍스트 변환(STT):</strong> Vosk와 같은 로컬 STT 엔진.70</p>
</li>
<li>
<p><strong>LLM 추론:</strong> Ollama를 통해 CPU에서 실행되는 로컬 LLM (예: Gemma, Phi-3).70</p>
</li>
<li>
<p><strong>텍스트-음성 변환(TTS):</strong> Piper와 같은 로컬 TTS 엔진.70</p>
</li>
</ol>
<ul>
<li><strong>프로젝트 예시:</strong> GitHub의 <code>m15-ai/TrooperAI</code> 프로젝트는 이러한 모든 구성 요소를 MediaPipe를 이용한 제스처 제어와 함께 통합한 훌륭한 사례 연구이다.70</li>
</ul>
<h3>5.3  산업용 IoT: 예측 유지보수 및 이상 감지</h3>
<p>라즈베리 파이 5는 산업 환경에서 센서 데이터를 분석하는 데 사용될 수 있다.</p>
<ul>
<li>
<p><strong>개념:</strong> 진동, 온도, 전류 등 센서 데이터를 기계 학습으로 분석하여 장비 고장을 예측하거나 실시간으로 이상을 감지한다.72</p>
</li>
<li>
<p><strong>하드웨어:</strong> GPIO나 다른 인터페이스를 통해 센서에 연결된 라즈베리 파이 5 (예: 가속도계를 위한 Sense HAT).75 Prophesee GenX320과 같은 이벤트 기반 비전 센서는 고속 진동 모니터링에 사용될 수 있다.79</p>
</li>
<li>
<p><strong>방법론:</strong></p>
</li>
</ul>
<ol>
<li>
<p><strong>데이터 수집:</strong> 정상 및 고장 상태에서 장치의 센서 데이터를 수집하고 레이블을 지정한다.78</p>
</li>
<li>
<p><strong>모델 훈련:</strong> 더 강력한 머신에서 MATLAB, Scikit-learn, TensorFlow와 같은 프레임워크를 사용하여 분류 또는 회귀 모델(예: LSTM, Bagged Trees)을 훈련한다.72</p>
</li>
<li>
<p><strong>배포:</strong> 훈련되고 양자화된 모델을 라즈베리 파이 5에 배포하여 실시간 센서 데이터에 대한 추론을 수행한다.81</p>
</li>
</ol>
<ul>
<li><strong>프로젝트 예시:</strong> AWS는 라즈베리 파이 5에 적용할 수 있는 예측 유지보수 데모 아키텍처 샘플을 제공한다.72</li>
</ul>
<h2>6.  종합 및 전략적 권장 사항</h2>
<h3>6.1  의사결정 프레임워크: AI 경로 선택</h3>
<p>본 보고서의 분석 결과를 종합하여, 프로젝트 요구사항에 맞는 최적의 AI 구현 전략을 선택하기 위한 실용적인 의사결정 프레임워크를 제시한다.</p>
<p><strong>표 5: 라즈베리 파이 5 AI 구현 전략 의사결정 매트릭스</strong></p>
<table><thead><tr><th>전략</th><th>성능 (TOPS/FPS 등가)</th><th>전력 소비</th><th>총 비용 ($)</th><th>개발 복잡도 (1-5)</th><th>이상적인 사용 사례</th></tr></thead><tbody>
<tr><td><strong>CPU 단독</strong></td><td>낮음-중간 (~0.5 TOPS, ~12 FPS)</td><td>매우 낮음</td><td>낮음 (<span class="math math-inline">60-</span>80)</td><td>1 (가장 낮음)</td><td>저비용, 저전력 애플리케이션, 기본 분류/탐지, 학습용</td></tr>
<tr><td><strong>GPU 가속</strong></td><td>중간</td><td>매우 낮음</td><td>낮음 (<span class="math math-inline">60-</span>80)</td><td>4 (높음)</td><td>추가 하드웨어 없이 성능 향상을 원하는 전문가, GPGPU 실험</td></tr>
<tr><td><strong>NPU 가속 (AI Kit)</strong></td><td>높음 (13 TOPS, ~120 FPS)</td><td>낮음</td><td>중간 (<span class="math math-inline">140-</span>150)</td><td>2 (낮음)</td><td>고성능/저지연 컴퓨터 비전, 다중 스트림 분석, 실시간 객체 추적</td></tr>
<tr><td><strong>eGPU 가속</strong></td><td>매우 높음 (GPU에 따라 다름)</td><td>높음 (활성 시) / 낮음 (유휴 시)</td><td>높음 (<span class="math math-inline">300-</span>700+)</td><td>5 (매우 높음)</td><td>로컬 LLM 실행, 유휴 전력 소모가 중요한 상시 가동 AI 에이전트, 연구</td></tr>
</tbody></table>
<h3>6.2  온디바이스 AI의 미래와 라즈베리 파이의 역할</h3>
<p>지연 시간, 개인 정보 보호, 신뢰성에 대한 요구가 증가함에 따라 온디바이스 AI로의 전환은 가속화되고 있다.83 균형 잡힌 성능과 뛰어난 확장성을 갖춘 라즈베리 파이 5는 이러한 트렌드의 핵심 플랫폼으로 자리매김할 완벽한 위치에 있다. 단순한 취미용 도구를 넘어, 본격적인 AI 시스템 및 제품의 실행 가능한 구성 요소로 진화하고 있다.30</p>
<p>결론적으로, 라즈베리 파이 5의 진정한 강점은 단일 작업에서 가장 빠른 성능을 제공하는 것이 아니라, 광범위한 맞춤형 엣지 AI 솔루션을 설계하기 위한 가장 다재다능하고 비용 효율적이며 잘 지원되는 플랫폼이라는 점에 있다. 이는 개발자와 엔지니어에게 전례 없는 유연성을 제공하며, 엣지에서의 지능 구현 가능성을 한 단계 끌어올린다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>Raspberry Pi 5 Review - PCMag, https://www.pcmag.com/reviews/raspberry-pi-5</li>
<li>Raspberry Pi 5 vs. Pi 4 AI performance CPU Benchmark: How much leap forward? - Latest News from Seeed Studio, https://www.seeedstudio.com/blog/2023/09/28/raspberry-pi-5-vs-pi-4-ai-performance-cpu-benchmark-how-much-leap-forward/</li>
<li>Raspberry Pi 5 - The Pi Hut, https://thepihut.com/products/raspberry-pi-5</li>
<li>Raspberry Pi 5 (8 GB RAM) - Elektor, https://www.elektor.com/products/raspberry-pi-5-8-gb-ram</li>
<li>Raspberry Pi 5, https://datasheets.raspberrypi.com/rpi5/raspberry-pi-5-product-brief.pdf</li>
<li>Raspberry Pi 5 - 4GB - SparkFun Electronics, https://www.sparkfun.com/raspberry-pi-5-4gb.html</li>
<li>Raspberry Pi 5 - 16 GB RAM : ID 6125 - Adafruit, https://www.adafruit.com/product/6125</li>
<li>Processors - Raspberry Pi Documentation, https://www.raspberrypi.com/documentation/computers/processors.html</li>
<li>Raspberry Pi - Wikipedia, https://en.wikipedia.org/wiki/Raspberry_Pi</li>
<li>Quick Start Guide: Raspberry Pi with Ultralytics YOLO11, https://docs.ultralytics.com/guides/raspberry-pi/</li>
<li>Buy a Raspberry Pi 5, https://www.raspberrypi.com/products/raspberry-pi-5/</li>
<li>Raspberry Pi 5 - 8GB - SparkFun Electronics, https://www.sparkfun.com/raspberry-pi-5-8gb.html</li>
<li>Raspberry Pi 5 8GB - CanaKit, https://www.canakit.com/raspberry-pi-5-8gb.html</li>
<li>Benchmarking Raspberry Pi 5, https://www.raspberrypi.com/news/benchmarking-raspberry-pi-5/</li>
<li>Raspberry Pi 5 Graphics Continue With Open-Source Driver &amp; Crazy Fast Compared To RPi 4 - Phoronix, https://www.phoronix.com/review/raspberry-pi-5-graphics/2</li>
<li>Raspberry Pi5 Benchmarks Thread, https://forums.raspberrypi.com/viewtopic.php?t=357062</li>
<li>Raspberry Pi 5 16GB - SC1113 - PiShop US, https://www.pishop.us/product/raspberry-pi-5-16gb/</li>
<li>Who would pay $120 for a Raspberry Pi? - YouTube, https://www.youtube.com/watch?v=apWi16EROKc</li>
<li>16GB Raspberry Pi 5 on sale now at $120, https://www.raspberrypi.com/news/16gb-raspberry-pi-5-on-sale-now-at-120/</li>
<li>Raspberry Pi 5 16GB: A High-Performance Upgrade for AI and Hobbyists - Electromaker.io, https://www.electromaker.io/blog/article/raspberry-pi-5-16gb-a-high-performance-upgrade-for-ai-and-hobbyists</li>
<li>Raspberry Pi computer hardware - Raspberry Pi Documentation, https://www.raspberrypi.com/documentation/computers/raspberry-pi.html</li>
<li>The Raspberry Pi 5 is no match for a tini-mini-micro PC - Louwrentius, https://louwrentius.com/the-raspberry-pi-5-is-no-match-for-a-tini-mini-micro-pc.html</li>
<li>Use an External GPU on Raspberry Pi 5 for 4K Gaming | Jeff Geerling, https://www.jeffgeerling.com/blog/2024/use-external-gpu-on-raspberry-pi-5-4k-gaming</li>
<li>Buy a Raspberry Pi AI Kit, https://www.raspberrypi.com/products/ai-kit/</li>
<li>Benchmark on RPi5 and CM4 running yolov8s with rpi ai kit | Seeed Studio Wiki, https://wiki.seeedstudio.com/benchmark_on_rpi5_and_cm4_running_yolov8s_with_rpi_ai_kit/</li>
<li>Raspberry Pi 5 CPU Performance - Medium, https://medium.com/@davidly_33504/raspberry-pi-5-cpu-performance-2d019aa6c0df</li>
<li>Raspberry Pi 5 Benchmarks: Significantly Better Performance, Improved I/O Review - Phoronix, https://www.phoronix.com/review/raspberry-pi-5-benchmarks/5</li>
<li>Benchmarking TensorFlow and TensorFlow Lite on Raspberry Pi 5 - Hackster.io, https://www.hackster.io/news/benchmarking-tensorflow-and-tensorflow-lite-on-raspberry-pi-5-b9156d58a6a2</li>
<li>Benchmarking TensorFlow and TensorFlow Lite on Raspberry Pi 5 #piday #raspberrypi, https://blog.adafruit.com/2024/06/21/benchmarking-tensorflow-and-tensorflow-lite-on-raspberry-pi-5-piday-raspberrypi/</li>
<li>How to Set Up Raspberry Pi 5 for AI Projects &amp; Machine Learning - Elecrow, https://www.elecrow.com/blog/setup-raspberry-pi-5-for-ai-projects-and-machine-learning.html</li>
<li>How to Run TensorFlow Lite Models on Raspberry Pi - Paperspace Blog, https://blog.paperspace.com/tensorflow-lite-raspberry-pi/</li>
<li>PyTorch installation wheels for Raspberry Pi 64 OS - GitHub, https://github.com/Qengineering/PyTorch-Raspberry-Pi-64-OS</li>
<li>Install PyTorch on Raspberry Pi 5 - Q-engineering, <a href="https://qengineering.eu/install%20pytorch%20on%20raspberry%20pi%205.html">https://qengineering.eu/install%20pytorch%20on%20raspberry%20pi%205.html</a></li>
<li>A Step by Step guide to installing PyTorch in Raspberry Pi | by Suparna S Nair - Medium, https://medium.com/secure-and-private-ai-writing-challenge/a-step-by-step-guide-to-installing-pytorch-in-raspberry-pi-a1491bb80531</li>
<li>PyTorch on raspberry pi - Reddit, https://www.reddit.com/r/pytorch/comments/161zb2t/pytorch_on_raspberry_pi/</li>
<li>ONNX Runtime IoT Deployment on Raspberry Pi, https://onnxruntime.ai/docs/tutorials/iot-edge/rasp-pi-cv.html</li>
<li>GPU speed-up on Raspberry Pi 5 · Issue #226 · Mozilla-Ocho/llamafile - GitHub, https://github.com/Mozilla-Ocho/llamafile/issues/226</li>
<li>use GPU in raspberry pi 5, https://forums.raspberrypi.com/viewtopic.php?t=370359</li>
<li>Comparison of tensorflow and tensorflow lite for object detection on Raspberry Pi 4, https://www.researchgate.net/publication/370622055_Comparison_of_tensorflow_and_tensorflow_lite_for_object_detection_on_Raspberry_Pi_4</li>
<li>Deep learning with Raspberry Pi and alternatives in 2024 - Q-engineering, https://qengineering.eu/deep-learning-with-raspberry-pi-and-alternatives.html</li>
<li>AI Kit - Raspberry Pi Documentation, https://www.raspberrypi.com/documentation/accessories/ai-kit.html</li>
<li>Does the Raspberry Pi have an NPU? Raspberry Pi NPU Acceleration Recommendation - Latest News from Seeed Studio, https://www.seeedstudio.com/blog/2024/07/26/does-the-raspberry-pi-have-an-npu/</li>
<li>Exploring AI with SBCs: Raspberry Pi 5 AI Kit and Google Coral Dev Boa - PicoCluster, https://www.picocluster.com/collections/exploring-ai-with-sbcs-raspberry-pi-5-ai-kit-and-google-coral-dev-board/ai</li>
<li>Buy a Raspberry Pi AI HAT+, https://www.raspberrypi.com/products/ai-hat/</li>
<li>Testing Raspberry Pi’s AI Kit - 13 TOPS for $70 | Jeff Geerling, https://www.jeffgeerling.com/blog/2024/testing-raspberry-pis-ai-kit-13-tops-70</li>
<li>Raspberry Pi AI Kit Review: Brainiac | Tom’s Hardware, https://www.tomshardware.com/raspberry-pi/raspberry-pi-ai-kit-review</li>
<li>Seeed-Projects/Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L - GitHub, https://github.com/Seeed-Projects/Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L</li>
<li>Benchmark on RPi5 &amp; CM4 running yolov8s with Hailo 8L - Raspberry Pi Forums, https://forums.raspberrypi.com/viewtopic.php?t=373867</li>
<li>A GPU-powered Pi for more efficient AI? - YouTube, https://www.youtube.com/watch?v=AyR7iCS7gNI</li>
<li>LLMs accelerated with eGPU on a Raspberry Pi 5 | Jeff Geerling, https://www.jeffgeerling.com/blog/2024/llms-accelerated-egpu-on-raspberry-pi-5</li>
<li>Running Pi 5 with a PC GPU - Raspberry Pi Forums, https://forums.raspberrypi.com/viewtopic.php?t=357189</li>
<li>Run LLM on Pi5: Connecting an NVIDIA GPU to Raspberry Pi 5 via PCIe x4 - Alican Kiraz, https://alican-kiraz1.medium.com/run-llm-on-pi5-connecting-an-nvidia-gpu-to-raspberry-pi-5-via-pcie-x4-a6d52c3efd2a</li>
<li>Progress on Intel and Nvidia GPUs on Raspberry Pi - Jeff Geerling, https://www.jeffgeerling.com/blog/2025/progress-on-intel-and-nvidia-gpus-on-raspberry-pi</li>
<li>Real-Time AI Object Detection Testing (Pi5 AI Kit vs. NVIDIA Jetson) - YouTube, https://www.youtube.com/watch?v=BUvvKThcjFA</li>
<li>Raspberry Pi Camera Module 3 - Elektor, https://www.elektor.com/products/raspberry-pi-camera-module-3</li>
<li>Raspberry Pi Camera Module 3 Standard NoIR Wide NoIR Wide, https://datasheets.raspberrypi.com/camera/camera-module-3-product-brief.pdf</li>
<li>AI Camera - Raspberry Pi Documentation, https://www.raspberrypi.com/documentation/accessories/ai-camera.html</li>
<li>Buy a Raspberry Pi AI Camera, https://www.raspberrypi.com/products/ai-camera/</li>
<li>Object Detection on the Raspberry Pi 5 | by Jeff Gensler - Medium, https://jeffzzq.medium.com/object-detection-on-the-raspberry-pi-5-463ba0f11d1e</li>
<li>YOLO Object and Animal Recognition on the Raspberry Pi 5 | Beginner Python Guide, https://www.youtube.com/watch?v=XKIm_R_rIeQ</li>
<li>Raspberry Pi 5 + AI Camera running YOLOv8n - Real-time object detection is here! - Reddit, https://www.reddit.com/r/raspberry_pi/comments/1n10plc/raspberry_pi_5_ai_camera_running_yolov8n_realtime/</li>
<li>Tutorial of AI Kit with Raspberry Pi 5 about YOLOv8n object detection, https://forums.raspberrypi.com/viewtopic.php?t=376404</li>
<li>Real-Time Detection of Hole-Type Defects on Industrial Components Using Raspberry Pi 5, https://www.mdpi.com/2571-5577/8/4/89</li>
<li>Build Your Own Solder Defect Detection System with the Raspberry Pi AI Camera | Brain Builder Guide - YouTube, https://www.youtube.com/watch?v=rGDhbQJ6n9Q</li>
<li>Seeed ReSpeaker USB Mic Array V2.0 2-Mics Far-field Microphone Array Intelligent Speech Recognition Development Board Acoustics - AliExpress, https://www.aliexpress.com/item/32841978358.html</li>
<li>Raspberry Pi 4 B ReSpeaker Mic Array V2.0 /USB Mic Array Microphone Array AI Intelligent Voice Recognition Development Board, https://trexhouston.com/Raspberry-Pi-4-B-ReSpeaker-Mic-Array-V2-0-USB-Mic-Array-1026720</li>
<li>Good USB microphones - Raspberry Pi Forums, https://forums.raspberrypi.com/viewtopic.php?t=385131</li>
<li>Unlock AI Audio with the ReSpeaker 2-Mics for Raspberry Pi - Electromaker.io, https://www.electromaker.io/blog/article/empowering-your-raspberry-pi-unleashing-ai-with-the-respeaker-2-mics-pi-hat</li>
<li>Free-to-use Voice AI - Raspberry Pi Forums, https://forums.raspberrypi.com/viewtopic.php?t=338146</li>
<li>m15-ai/TrooperAI: Conversational AI, local, low-latency voice assistant for Raspberry Pi 5 with LED, gesture control, and streaming LLM replies. - GitHub, https://github.com/m15-ai/TrooperAI</li>
<li>How To Create an AI Voice Assistant with Raspberry Pi - Micro Center, https://www.microcenter.com/site/mc-news/article/ai-voice-assistant-rapsberry-pi.aspx</li>
<li>aws-samples/predictive-maintenance-demo - GitHub, https://github.com/aws-samples/predictive-maintenance-demo</li>
<li>predictive-maintenance · GitHub Topics, https://github.com/topics/predictive-maintenance</li>
<li>Investigating a Raspberry Pi Cluster for Detecting Anomalies in the Smart Grid - Suzanne J. Matthews, https://www.suzannejmatthews.com/docs/Candelario2017.pdf</li>
<li>Physical Computing with Python - Code Club Projects - Raspberry Pi Foundation, https://projects.raspberrypi.org/en/projects/physical-computing</li>
<li>Machine Learning in Python With Raspberry Pi &amp; Sensors (Level 2) - AI Code Academy, https://lessonbook.ai/courses/machine-learning-in-python-with-raspberry-pi-sensors-level-2</li>
<li>Sensor Tutorial with Python, Raspberry Pi, and Notecarrier Pi - Blues Developers, https://dev.blues.io/guides-and-tutorials/collecting-sensor-data/notecarrier-pi/raspberry-pi/python/</li>
<li>Perform Predictive Maintenance for Rotating Device Using Machine Learning Algorithm on Raspberry Pi - MATLAB &amp; Simulink Example - MathWorks, https://www.mathworks.com/help/simulink/supportpkg/raspberrypi_ref/perform-predictive-maintenance-for-rotating-device-using-machine-learning-algorithm-on-raspberry-pi.html</li>
<li>PROPHESEE Starter Kit GenX320 for Raspberry Pi 5, https://www.prophesee.ai/event-based-starter-kit-genx320-raspberry-pi-5/</li>
<li>Capturing Data from Sensors Sequentially Using Raspberry Pi 5 and NRF24, https://forums.raspberrypi.com/viewtopic.php?t=374055</li>
<li>Leveraging advanced RNN with LSTM for efficient, real-time anomaly detection in IoT networks, optimized for performance in resource-constrained environments. - GitHub, https://github.com/SHVleV9CYWkK/IoT-anomaly-detection</li>
<li>Real-Time Noise Detection on Raspberry Pi Using Deep Signal Anomaly Detector - MATLAB &amp; Simulink - MathWorks, https://www.mathworks.com/help/dsp/ug/real-time-noise-detection-on-a-raspberry-pi-using-deep-signal-anomaly-detector.html</li>
<li>The future of AI is on-device so the logical next step is agentic on-device AI : r/robotics, https://www.reddit.com/r/robotics/comments/1o1w0uc/the_future_of_ai_is_ondevice_so_the_logical_next/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>