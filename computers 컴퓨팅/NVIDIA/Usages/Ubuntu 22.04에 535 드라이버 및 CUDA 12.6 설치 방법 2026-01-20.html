<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:Ubuntu 22.04에 535 드라이버 및 CUDA 12.6 설치 방법</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>Ubuntu 22.04에 535 드라이버 및 CUDA 12.6 설치 방법</h1>
                    <nav class="breadcrumbs"><a href="../../../index.html">Home</a> / <a href="../../index.html">컴퓨터 (Computers)</a> / <a href="../index.html">NVIDIA 제품</a> / <a href="index.html">NVIDIA 제품 사용 방법</a> / <span>Ubuntu 22.04에 535 드라이버 및 CUDA 12.6 설치 방법</span></nav>
                </div>
            </header>
            <article>
                <h1>Ubuntu 22.04에 535 드라이버 및 CUDA 12.6 설치 방법</h1>
<p>2026-01-20, G30</p>
<p>본 문서는 Ubuntu 22.04 환경에서 딥러닝 개발을 수행하기 위해 <strong>NVIDIA Driver 535</strong>, <strong>CUDA Toolkit 12.6</strong>, <strong>cuDNN 9.3</strong>을 충돌 없이 설치하는 표준 절차를 기술한다.</p>
<p>모든 작업은 터미널에서 진행하며, 기존 패키지와의 충돌을 방지하기 위해 <strong>Runfile(로컬 인스톨러)</strong> 방식을 채택한다.</p>
<h2>1. 환경 사양</h2>
<ul>
<li><strong>OS:</strong> Ubuntu 22.04 LTS</li>
<li><strong>GPU:</strong> NVIDIA GeForce RTX 30 Series 이상 권장</li>
<li><strong>Target:</strong> Driver 535 / CUDA 12.6 / cuDNN 9.3</li>
</ul>
<h2>2.  사전 준비 및 기존 환경 정리</h2>
<p>새로운 드라이버와 툴킷 설치 전, 시스템을 업데이트하고 구버전 패키지를 완전히 제거한다.</p>
<h3>2.1  시스템 업데이트 및 필수 의존성 설치</h3>
<p>드라이버 빌드에 필요한 커널 헤더와 컴파일러를 설치한다.</p>
<pre><code class="language-Bash">sudo apt update &amp;&amp; sudo apt upgrade -y
sudo apt install build-essential linux-headers-$(uname -r) zlib1g -y
</code></pre>
<h3>2.2  기존 NVIDIA 패키지 제거 (Clean Install)</h3>
<p>충돌 방지를 위해 기존에 설치된 드라이버와 CUDA 툴킷을 모두 삭제한다.</p>
<pre><code class="language-Bash">sudo apt autoremove --purge nvidia* -y
sudo apt remove --purge cuda* -y
sudo rm -rf /usr/local/cuda*
</code></pre>
<h2>3.  NVIDIA Driver 535 설치</h2>
<p>Ubuntu 패키지 매니저(APT)를 사용하여 안정적인 535 버전 드라이버를 설치한다.</p>
<h3>3.1  드라이버 설치</h3>
<pre><code class="language-Bash"># 그래픽 드라이버 PPA 추가 (최신 안정화 버전 확보)
sudo add-apt-repository ppa:graphics-drivers/ppa
sudo apt update

# 535 드라이버 설치
sudo apt install nvidia-driver-535 -y
</code></pre>
<h3>3.2  시스템 재부팅 및 확인</h3>
<p>드라이버 로드를 위해 반드시 재부팅한다.</p>
<pre><code class="language-Bash">sudo reboot
</code></pre>
<p>재부팅 후 설치 상태를 확인한다.</p>
<pre><code class="language-Bash">nvidia-smi
</code></pre>
<ul>
<li><strong>확인 사항:</strong> <code>Driver Version: 535.xx.xx</code>가 출력되어야 한다.</li>
</ul>
<h2>4.  CUDA Toolkit 12.6 설치</h2>
<p>드라이버 버전을 강제로 변경하지 않도록 <strong>Runfile</strong> 방식을 사용한다.</p>
<h3>4.1  설치 파일 다운로드</h3>
<pre><code class="language-Bash">wget https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda_12.6.0_560.28.03_linux.run
</code></pre>
<h3>4.2  설치 실행</h3>
<pre><code class="language-Bash">sudo sh cuda_12.6.0_560.28.03_linux.run
</code></pre>
<h3>4.3  설치 옵션 구성 (★ 중요)</h3>
<p>설치 화면(TUI)에서 다음 절차를 엄수한다.</p>
<ol>
<li><strong>EULA:</strong> <code>accept</code> 입력.</li>
<li><strong>Selection Menu:</strong> <code>[X] Driver</code> 항목에서 **스페이스바를 눌러 체크를 해제([ ])**한다.</li>
</ol>
<ul>
<li><em>이유: 이미 535 드라이버가 설치되어 있으므로 덮어쓰기를 방지해야 한다.</em></li>
</ul>
<ol start="3">
<li><strong>Toolkit:</strong> <code>[X] CUDA Toolkit 12.6</code> 체크 상태 유지.</li>
<li><strong>Install:</strong> 선택 후 엔터.</li>
</ol>
<h3>4.4  환경 변수 등록 (<code>.bashrc</code>)</h3>
<p>시스템이 CUDA 명령어를 인식하도록 경로를 추가한다.</p>
<pre><code class="language-Bash"># .bashrc 파일 열기
nano ~/.bashrc

# 맨 아래줄에 다음 내용 추가
export PATH=/usr/local/cuda-12.6/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

# 저장 후 종료 (Ctrl+O -&gt; Enter -&gt; Ctrl+X)

# 변경 사항 적용
source ~/.bashrc
</code></pre>
<h3>4.5  설치 확인</h3>
<pre><code class="language-Bash">nvcc --version
</code></pre>
<ul>
<li><strong>확인 사항:</strong> <code>release 12.6</code> 문구가 포함되어야 한다.</li>
</ul>
<h2>5.  cuDNN 9.3 라이브러리 설치</h2>
<p>딥러닝 프레임워크 가속을 위한 cuDNN 라이브러리를 설치한다. CUDA 12.x 버전에 대응하는 9.3 버전을 설치한다.</p>
<h3>5.1  로컬 리포지토리 설치</h3>
<pre><code class="language-Bash"># 1. 설치 파일 다운로드
wget https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/cudnn-local-repo-ubuntu2204-9.3.0_1.0-1_amd64.deb

# 2. 패키지 설치
sudo dpkg -i cudnn-local-repo-ubuntu2204-9.3.0_1.0-1_amd64.deb

# 3. 인증 키링 복사
sudo cp /var/cudnn-local-repo-ubuntu2204-9.3.0/cudnn-*-keyring.gpg /usr/share/keyrings/

# 4. 패키지 목록 갱신
sudo apt-get update
</code></pre>
<h3>5.2  라이브러리 설치</h3>
<p>CUDA 12용 cuDNN 메타 패키지를 설치한다.</p>
<pre><code class="language-bash">sudo apt-get install -y cudnn-cuda-12
</code></pre>
<h2>6.  최종 검증</h2>
<p>모든 구성 요소가 정상적으로 설치되었는지 확인한다.</p>
<h3>6.1  버전 통합 확인 표</h3>
<table><thead><tr><th><strong>구분</strong></th><th><strong>명령어</strong></th><th><strong>정상 출력 예시</strong></th><th><strong>비고</strong></th></tr></thead><tbody>
<tr><td><strong>GPU Driver</strong></td><td><code>nvidia-smi</code></td><td><code>Driver Version: 535.xx</code></td><td><code>CUDA Version: 12.2</code> 표기는 무시함</td></tr>
<tr><td><strong>CUDA Toolkit</strong></td><td><code>nvcc --version</code></td><td><code>release 12.6</code></td><td>실제 컴파일러 버전</td></tr>
<tr><td><strong>cuDNN</strong></td><td>`dpkg -l</td><td>grep cudnn`</td><td><code>cudnn-cuda-12</code> 등 출력</td></tr>
</tbody></table>
<p>위 3가지 항목이 모두 정상 출력되면 설치 과정은 종료된다. 이제 PyTorch 또는 TensorFlow를 설치하여 개발을 시작할 수 있다.</p>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>