<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:NVIDIA Jetson Orin 플랫폼에서의 PREEMPT_RT 및 샌드박싱 가이드</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>NVIDIA Jetson Orin 플랫폼에서의 PREEMPT_RT 및 샌드박싱 가이드</h1>
                    <nav class="breadcrumbs"><a href="../../../../index.html">Home</a> / <a href="../../../index.html">컴퓨터 (Computers)</a> / <a href="../../index.html">NVIDIA 제품</a> / <a href="../index.html">NVIDIA Orin</a> / <a href="index.html">NVIDIA Jetson Orin</a> / <span>NVIDIA Jetson Orin 플랫폼에서의 PREEMPT_RT 및 샌드박싱 가이드</span></nav>
                </div>
            </header>
            <article>
                <h1>NVIDIA Jetson Orin 플랫폼에서의 PREEMPT_RT 및 샌드박싱 가이드</h1>
<h2>1. 서론</h2>
<p>NVIDIA Jetson Orin 플랫폼은 엣지 컴퓨팅 환경에서 전례 없는 수준의 AI 추론 성능을 제공하며 로보틱스, 산업 자동화, 자율 주행 시스템과 같은 분야의 혁신을 주도하고 있습니다. 이러한 애플리케이션들은 단순히 높은 연산 처리량뿐만 아니라, 예측 가능하고 시간 결정적인(time-deterministic) 응답성을 요구하는 경우가 많습니다. 즉, 시스템은 정해진 시간 제약(deadline) 내에 특정 작업을 반드시 완료해야 하며, 이를 충족하지 못할 경우 시스템 전체의 안정성과 안전에 심각한 영향을 미칠 수 있습니다.</p>
<p>Jetson Orin에서 기본으로 제공되는 NVIDIA L4T(Linux for Tegra) 운영체제는 Ubuntu를 기반으로 한 범용 운영체제(GPOS)입니다. GPOS는 평균적인 시스템 처리량을 극대화하도록 설계되었기 때문에, 실시간 시스템(RTOS)이 요구하는 엄격한 시간 제약성을 보장하기 어렵습니다. 동시에, 현대의 복잡한 임베디드 시스템은 다양한 소프트웨어 구성요소, 라이브러리, 그리고 애플리케이션 스택을 포함하며, 이들 간의 의존성 충돌을 방지하고 배포의 모듈성과 보안을 강화하기 위한 강력한 격리 메커니즘을 필요로 합니다.</p>
<p>본 안내서는 Jetson Orin 플랫폼에서 이 두 가지 핵심 요구사항, 즉 **실시간성(Real-Time Capability)**과 **애플리케이션 격리(Application Isolation)**를 동시에 구현하는 포괄적이고 심층적인 기술 가이드를 제공하는 것을 목표로 합니다. 이를 위해, L4T 커널에 <code>PREEMPT_RT</code> 패치를 적용하여 결정론적 스케줄링을 가능하게 하는 방법과, Docker와 같은 컨테이너 기술을 활용하여 애플리케이션을 안전하게 샌드박싱하는 방법을 통합적으로 다룹니다.</p>
<p>안내서는 세 부분으로 구성됩니다. <strong>1부</strong>에서는 <code>PREEMPT_RT</code> 커널의 이론적 배경과 실제 빌드 및 검증 과정을 상세히 설명하여 실시간 시스템의 견고한 기반을 구축합니다. <strong>2부</strong>에서는 Docker를 중심으로 한 컨테이너 기술을 Jetson Orin 환경에 적용하고, GPU 가속을 포함한 실용적인 애플리케이션 패키징 방법을 제시합니다. 마지막으로 <strong>3부</strong>에서는 이 두 기술을 결합했을 때의 성능을 정량적으로 분석하고, 실제 생산 환경에 적용하기 위한 CPU 코어 격리, 실시간 스케줄링 정책 적용, 보안 강화 및 시스템 유지보수 전략과 같은 고급 주제들을 심도 있게 탐구합니다. 본 안내서를 통해 로보틱스 엔지니어 및 고급 임베디드 시스템 개발자는 Jetson Orin의 강력한 성능을 최대한 활용하여, 결정론적이고 안정적이며 안전한 고신뢰성 시스템을 설계하고 구축하는 데 필요한 모든 기술적 지식과 실용적인 노하우를 얻게 될 것입니다.</p>
<h2>2. 부: PREEMPT_RT를 통한 실시간 기반 아키텍처 설계</h2>
<p>이 섹션에서는 Jetson Orin의 표준 L4T 운영체제를 실시간 시스템으로 전환하기 위한 이론적, 실용적 토대를 마련합니다. 결정론적 실행이 왜 필요한지부터 시작하여, <code>PREEMPT_RT</code> 커널을 직접 빌드하고 검증하는 전 과정을 다룹니다.</p>
<h3>2.1  Jetson 플랫폼에서 실시간 리눅스의 필요성</h3>
<h4>2.1.1  실시간의 정의: 평균 성능을 넘어서</h4>
<p>범용 운영체제(GPOS)는 시스템의 전체적인 처리량(throughput)과 평균 응답 시간을 최적화하는 데 중점을 둡니다.1 반면, 실시간 운영체제(RTOS)는 개별 작업의 완료 시간을 예측하고 보장하는 것, 즉 결정론(determinism)을 최우선 목표로 합니다. 특히 최악 실행 시간(Worst-Case Execution Time, WCET)을 보장하는 것이 핵심입니다.1 Jetson 플랫폼이 주로 사용되는 로보틱스나 산업 제어 시스템에서는 제어 루프나 안전 관련 작업이 정해진 시간(deadline) 내에 완료되지 못하면 단순한 성능 저하가 아닌 시스템 고장이나 안전사고로 이어질 수 있습니다.2 따라서 이러한 미션 크리티컬 시스템에는 평균 성능이 아닌, 최악의 경우에도 시간 제약을 준수할 수 있는 RTOS의 특성이 필수적입니다.</p>
<h4>2.1.2  표준 리눅스 커널의 지연 시간 및 비결정성 원인</h4>
<p>표준 리눅스 커널이 실시간성을 보장하기 어려운 근본적인 원인은 다음과 같습니다.</p>
<ul>
<li><strong>스케줄링 지연 시간 (Scheduling Latency):</strong> 높은 우선순위의 작업이 실행 준비 상태가 된 시점부터 실제로 CPU에 의해 실행되기 시작할 때까지 걸리는 시간을 의미합니다.4 이는</li>
</ul>
<p><code>cyclictest</code>와 같은 벤치마크 도구가 측정하는 핵심 지표입니다.</p>
<ul>
<li>
<p><strong>선점 불가능한 커널 코드 (Non-Preemptible Kernel Code):</strong> 표준 커널의 상당 부분은 선점이 불가능하도록 설계되어 있습니다. 이로 인해 낮은 우선순위의 작업이 커널 모드에서 시스템 콜을 실행하는 동안, 더 높은 우선순위의 긴급한 작업이 대기해야 하는 상황이 발생할 수 있습니다.5</p>
</li>
<li>
<p><strong>인터럽트 처리 (Interrupt Handling):</strong> 하드웨어 인터럽트가 발생하면, 커널은 다른 모든 인터럽트를 비활성화한 상태에서 ’top half’라 불리는 인터럽트 핸들러를 실행합니다. 이 시간 동안 시스템은 다른 어떤 이벤트에도 반응할 수 없어 지연 시간이 발생합니다. 이후의 처리 과정인 ‘bottom half’(softirq) 역시 높은 우선순위 작업의 실행을 지연시킬 수 있습니다.6</p>
</li>
<li>
<p><strong>우선순위 역전 (Priority Inversion):</strong> RTOS에서 발생하는 고전적인 문제로, 낮은 우선순위의 태스크(L)가 공유 자원(예: 뮤텍스)을 점유하고 있을 때, 높은 우선순위의 태스크(H)가 이 자원을 기다리며 블록됩니다. 이때 중간 우선순위의 태스크(M)가 L을 선점하여 실행되면, H는 M의 실행이 끝날 때까지 무기한 대기하게 되는 현상입니다. 이는 예측 불가능한 긴 지연을 유발합니다.6</p>
</li>
</ul>
<h4>2.1.3  PREEMPT_RT 솔루션: 리눅스를 실시간 시스템으로 전환</h4>
<p><code>PREEMPT_RT</code> 패치셋은 위에서 언급된 문제들을 해결하여 리눅스 커널에 결정론적 실시간 성능을 부여합니다.</p>
<ul>
<li><strong>커널의 완전 선점화:</strong> <code>PREEMPT_RT</code>의 가장 핵심적인 목표는 커널 코드의 거의 모든 영역을 선점 가능하게 만드는 것입니다.2 이를 통해 높은 우선순위의 작업이 커널 코드 실행 중에도 시스템을 즉시 점유할 수 있게 됩니다.</li>
<li><strong>스핀락(Spinlock)을 선점 가능한 뮤텍스(Mutex)로 변환:</strong> 지연 시간의 주범인 스핀락을 우선순위 상속(priority inheritance) 기능이 내장된 뮤텍스(<code>rtmutex</code>)로 대체합니다. 이로써 낮은 우선순위의 태스크가 임계 영역(critical section) 안에 있더라도 높은 우선순위의 태스크가 이를 선점할 수 있게 됩니다.5</li>
<li><strong>스레드화된 인터럽트 핸들러 (Threaded Interrupt Handlers):</strong> 인터럽트 핸들러의 후반부(bottom half)를 일반 커널 스레드로 전환하여 스케줄러가 관리하도록 합니다. 이로 인해 인터럽트 비활성화 시간이 최소화되고, 우선순위에 따라 인터럽트 처리조차도 다른 높은 우선순위의 사용자 태스크에 의해 선점될 수 있습니다.7</li>
<li><strong>우선순위 상속 (Priority Inheritance, PI):</strong> <code>rtmutex</code>에 구현된 우선순위 상속 메커니즘은 자원을 점유한 낮은 우선순위 태스크의 우선순위를 자원을 기다리는 가장 높은 우선순위 태스크의 수준으로 일시적으로 높여줍니다. 이는 중간 우선순위 태스크에 의한 선점을 방지하여 우선순위 역전 문제를 해결합니다.6</li>
</ul>
<p>이러한 변경 사항들은 시스템에 상당한 영향을 미칩니다. <code>PREEMPT_RT</code>는 우선순위 상속 뮤텍스나 스레드화된 IRQ와 같은 메커니즘을 도입하여 커널의 선점 가능성을 극대화합니다.6 이 과정에서 커널의 동작 방식이 근본적으로 바뀌며, 표준 커널에 비해 컨텍스트 스위치와 스케줄러 이벤트의 발생 빈도가 증가하게 됩니다.5 이러한 추가적인 오버헤드는 시스템의 전체적인 연산 처리량(throughput)을 다소 감소시킬 수 있습니다.4 따라서</p>
<p><code>PREEMPT_RT</code> 패치를 적용하는 것은 단순히 성능을 향상시키는 것이 아니라, 평균 성능의 일부를 희생하여 최악의 경우에도 예측 가능한 낮은 지연 시간을 확보하는, 의도적인 엔지니어링적 선택입니다. 이 점을 이해하는 것은 시스템을 설계할 때 매우 중요합니다. 예를 들어, 결정론적 실행이 필수적인 제어 루프는 높은 실시간 우선순위를 부여하고, 데이터 로깅이나 GUI 업데이트와 같이 상대적으로 덜 중요한 작업들은 낮은 우선순위로 실행하거나 격리된 별도의 CPU 코어에서 처리하도록 설계하는 것이 바람직합니다.</p>
<h3>2.2  Jetson Orin을 위한 PREEMPT_RT 커널 빌드 종합 가이드</h3>
<h4>2.2.1  빌드 전략: 온디바이스 개발 vs. 호스트 크로스 컴파일</h4>
<p>커널 빌드에는 두 가지 주요 접근 방식이 있으며, 각각의 장단점을 이해하는 것이 중요합니다.</p>
<ul>
<li><strong>온디바이스 컴파일 (On-Device Compilation):</strong> Jetson Orin 장치 자체에서 직접 커널을 빌드하는 방식입니다. Orin 모듈은 데스크톱 수준의 상당한 연산 능력을 갖추고 있어 이 방식이 충분히 실용적입니다.11 개발 및 테스트 단계에서는 복잡한 크로스 컴파일 환경 설정 없이 신속하게 커널을 수정하고 테스트할 수 있어 매우 편리합니다. JetsonHacks 커뮤니티에서 제공하는</li>
</ul>
<p><code>jetson-orin-kernel-builder</code>와 같은 스크립트는 이 과정을 자동화하여 개발자의 부담을 크게 줄여줍니다.11</p>
<ul>
<li><strong>호스트 크로스 컴파일 (Host Cross-Compilation):</strong> x86 아키텍처의 호스트 PC에서 Jetson Orin의 ARM64 아키텍처에 맞는 커널을 빌드하는 방식입니다. 이 방식은 보안 부팅(Secure Boot)과 같은 생산 환경의 필수 기능을 활성화할 때 반드시 필요합니다.11 설정이 더 복잡하지만, 대규모 빌드나 자동화된 CI/CD 파이프라인에 통합하기에 더 적합합니다.</li>
</ul>
<p><strong>권장 전략:</strong> 초기 개발 및 기능 검증 단계에서는 온디바이스 컴파일로 신속하게 프로토타이핑을 진행하고, 시스템이 안정화된 후 생산 배포를 준비하는 단계에서 크로스 컴파일 워크플로우로 전환하는 것이 가장 효율적인 접근 방식입니다.</p>
<h4>2.2.2  소스 코드 획득 및 준비</h4>
<p>정확한 버전의 소스 코드를 준비하는 것은 성공적인 커널 빌드의 첫걸음입니다.</p>
<ul>
<li>
<p><strong>1단계: L4T 및 커널 버전 확인:</strong> 빌드하려는 커널 소스와 <code>PREEMPT_RT</code> 패치는 현재 시스템에 설치된 L4T(Linux for Tegra) 버전과 정확히 일치해야 합니다. <code>uname -r</code> 명령어를 통해 현재 실행 중인 커널 버전(예: <code>5.15.148-tegra</code>)을 확인하고 11, <code>cat /etc/nv_tegra_release</code> 명령어로 L4T 릴리스 정보(예: R36.3.0)를 확인합니다.15</p>
</li>
<li>
<p><strong>2단계: L4T BSP 및 커널 소스 다운로드:</strong> NVIDIA의 Jetson Linux Archive 페이지에서 자신의 L4T 버전에 맞는 소스 패키지를 다운로드해야 합니다.17 필요한 파일은 ’Driver Package (BSP) Sources’이며, 이 압축 파일 안에 <code>kernel_src.tbz2</code>가 포함되어 있습니다.11 JetsonHacks의 <code>get_kernel_sources.sh</code> 스크립트를 사용하면 이 과정이 자동화됩니다.14</p>
</li>
<li>
<p><strong>3단계: 올바른 PREEMPT_RT 패치 다운로드:</strong> 커널 공식 아카이브의 실시간 패치 디렉토리에서 자신의 커널 버전에 맞는 <code>PREEMPT_RT</code> 패치를 다운로드합니다.21 버전 불일치는 빌드 실패의 가장 흔한 원인이므로 아래 호환성 매트릭스를 반드시 참조해야 합니다.</p>
</li>
</ul>
<p><strong>표 1: PREEMPT_RT 패치 및 L4T 커널 버전 호환성 매트릭스</strong></p>
<p>이 표는 특정 JetPack/L4T 릴리스에 해당하는 커널 버전과 그에 맞는 <code>PREEMPT_RT</code> 패치 버전을 명확하게 연결하여, 버전 불일치로 인한 빌드 실패를 사전에 방지합니다. 이 정보는 여러 소스에 흩어져 있어 직접 찾기 번거롭기 때문에, 통합된 표는 개발자에게 매우 높은 가치를 제공합니다.</p>
<table><thead><tr><th>JetPack 버전</th><th>L4T 버전</th><th>커널 버전</th><th>PREEMPT_RT 패치 버전</th><th>패치 다운로드 링크</th></tr></thead><tbody>
<tr><td>JetPack 6.0</td><td>L4T 36.3.0</td><td>5.15.136</td><td><code>patch-5.15.136-rt71.patch.xz</code></td><td><a href="https://cdn.kernel.org/pub/linux/kernel/projects/rt/5.15/">Kernel.org</a></td></tr>
<tr><td>JetPack 5.1.2</td><td>L4T 35.4.1</td><td>5.10.120</td><td><code>patch-5.10.120-rt69.patch.xz</code></td><td><a href="https://cdn.kernel.org/pub/linux/kernel/projects/rt/5.10/">Kernel.org</a></td></tr>
<tr><td>JetPack 5.1</td><td>L4T 35.2.1</td><td>5.10.104</td><td><code>patch-5.10.104-rt64.patch.xz</code></td><td><a href="https://cdn.kernel.org/pub/linux/kernel/projects/rt/5.10/">Kernel.org</a></td></tr>
</tbody></table>
<p>참고: 위 표는 대표적인 버전들을 예시로 들었으며, 새로운 JetPack 릴리스에 대해서는 해당 릴리스의 커널 버전을 확인 후 <code>PREEMPT_RT</code> 버전을 맞춰야 합니다.21</p>
<h4>2.2.3  패치 적용 및 커널 설정</h4>
<ul>
<li>
<p><strong>패치 적용:</strong> 다운로드한 패치 파일을 커널 소스 디렉토리 상위로 이동한 후, 커널 소스 디렉토리 내에서 다음 명령을 실행하여 패치를 적용합니다. NVIDIA 소스에는 종종 헬퍼 스크립트가 포함되어 있어 더 간단하게 적용할 수도 있습니다.23</p>
<pre><code class="language-Bash"># 수동 패치 적용
cd /usr/src/kernel/kernel-jammy-src/
xz -d../patch-5.15.136-rt71.patch.xz
patch -p1 &lt;../patch-5.15.136-rt71.patch

# 또는 NVIDIA 제공 스크립트 사용 (존재하는 경우)
./scripts/rt-patch.sh apply-patches
</code></pre>
</li>
</ul>
<pre><code>
- **커널 설정:** 먼저 기존 설정을 기반으로 `.config` 파일을 생성합니다. 실행 중인 시스템의 설정을 가져오거나(`zcat /proc/config.gz &gt;.config`) 11, Tegra의 기본 설정을 사용할 수 있습니다(`make tegra_defconfig`).18 그 후, `make menuconfig`를 실행하여 텍스트 기반 설정 인터페이스로 진입합니다.

- **`menuconfig` 주요 설정 항목:** 실시간 성능을 위해 다음 항목들을 반드시 확인하고 설정해야 합니다.
- **완전 선점형 커널 (Fully Preemptible Kernel):** `PREEMPT_RT`의 핵심 기능입니다.
- 경로: `General setup` ---&gt; `Preemption Model`
- 설정: `(X) Fully Preemptible Kernel (Real-Time)` 24
- **타이머 주파수 (Timer Frequency):** 더 정밀한 스케줄링을 위해 높은 주파수를 권장합니다.
- 경로: `Kernel features` ---&gt; `Timer frequency`
- 설정: `(X) 1000 HZ` 24
- **완전 동적 틱 시스템 (Full dynticks system):** 유휴(idle) 상태의 CPU에서 불필요한 타이머 인터럽트를 줄여 시스템 전체의 지터(jitter)를 감소시킵니다.
- 경로: `General setup` ---&gt; `Timers subsystem` ---&gt; `Timer tick handling`
- 설정: `(X) Full dynticks system (tickless)` 24
- **로컬 버전 (Local version):** 커널 모듈이 정상적으로 로드되기 위해 'Version Magic'을 일치시켜야 합니다. 기존 커널 버전(`uname -r`)에서 `-tegra`와 같은 접미사가 있었다면 동일하게 설정해야 합니다.
- 경로: `General setup` ---&gt; `Local version - append to kernel release`
- 설정: (예: `-tegra`) 11

#### 2.2.4  컴파일, 배포 및 플래싱


- **컴파일:** 설정이 완료되면 커널과 모듈을 컴파일합니다. 온디바이스에서는 `make -j$(nproc)` 명령으로 간단히 실행할 수 있습니다.26 크로스 컴파일 시에는

`ARCH=arm64`와 `CROSS_COMPILE` 환경 변수를 설정해야 합니다.18 JetsonHacks의

`make_kernel.sh`와 `make_kernel_modules.sh` 스크립트는 이 과정을 편리하게 처리해줍니다.14

- **배포 (온디바이스):** 온디바이스 빌드의 경우, 배포 과정이 비교적 간단합니다.

1. `sudo make modules_install`: 컴파일된 모듈을 `/lib/modules/` 디렉토리에 설치합니다.
2. `sudo cp arch/arm64/boot/Image /boot/Image-rt`: 새로 빌드된 커널 이미지를 `/boot` 디렉토리에 복사합니다.
3. 재부팅 시 Jetson 부트로더(UEFI)는 자동으로 새로운 커널을 감지하고 부팅 옵션을 제공합니다.13

- **배포 (호스트 플래싱):** 크로스 컴파일의 경우, 호스트 PC의 `Linux_for_Tegra` 디렉토리 내 올바른 위치에 빌드 결과물들을 복사해야 합니다.

1. 커널 이미지: `/arch/arm64/boot/Image` -&gt; `Linux_for_Tegra/kernel/Image`
2. 디바이스 트리: `/arch/arm64/boot/dts/nvidia/*` -&gt; `Linux_for_Tegra/kernel/dtb/`
3. 커널 모듈: `sudo make INSTALL_MOD_PATH=&lt;path_to_L4T&gt;/rootfs/ modules_install` 명령으로 `rootfs`에 직접 설치합니다.23
4. 모든 파일이 준비되면, Jetson 장치를 복구 모드(Recovery Mode)로 전환하고 `flash.sh` 스크립트를 사용하여 시스템 전체를 다시 플래싱합니다.23

커스텀 커널을 사용하는 것은 일회성 작업이 아니라 지속적인 유지보수가 필요한 엔지니어링 활동입니다. NVIDIA는 `apt` 저장소를 통해 주기적으로 JetPack/L4T 업데이트를 배포합니다.16 만약 사용자가 `sudo apt upgrade` 명령을 무심코 실행하면, 시스템은 공식 `nvidia-l4t-kernel` 패키지를 다운로드하여 설치하고, 공들여 빌드한 `PREEMPT_RT` 커널을 덮어쓰게 됩니다. 이로 인해 시스템의 실시간성은 사라지고 표준 커널로 되돌아가게 됩니다.16 이러한 예기치 않은 다운그레이드를 방지하고 시스템의 안정성을 유지하기 위해서는 체계적인 관리 전략이 필수적입니다. 가장 효과적인 방법은 `sudo apt-mark hold 'nvidia-l4t-*'` 명령을 사용하여 커널 및 관련 NVIDIA 패키지들이 자동으로 업데이트되는 것을 막는 것입니다.31 이후 새로운 JetPack 버전으로 업그레이드하고자 할 때는, `hold`를 해제하고 시스템을 업그레이드한 뒤, 새로운 L4T 버전에 맞는 소스 코드를 기반으로 `PREEMPT_RT` 커널을 다시 빌드하고 배포하는 수동적인 절차를 따라야 합니다. 이 과정은 프로젝트의 전체 생명주기 관리 계획에 반드시 포함되어야 할 중요한 고려사항입니다.

### 2.3  시스템 레벨 튜닝 및 성능 검증


`PREEMPT_RT` 커널을 빌드하고 설치하는 것만으로는 Jetson Orin의 최적의 실시간 성능을 이끌어낼 수 없습니다. 플랫폼 특화된 튜닝과 정량적인 성능 검증이 반드시 수반되어야 합니다.

#### 2.3.1  Jetson Orin을 위한 핵심 부팅 후 튜닝


단순히 RT 커널로 부팅하는 것만으로는 충분하지 않습니다. NVIDIA 개발자 포럼의 논의를 통해, 추가적인 튜닝 없이는 `cyclictest` 결과가 비-RT 커널과 실망스러울 정도로 유사할 수 있다는 점이 밝혀졌습니다.32 Orin 하드웨어에서 최저 지연 시간을 달성하기 위해서는 다음과 같은 플랫폼 고유의 튜닝 명령을 적용해야 합니다. 이 설정들은 Tegra의 MCE(Multi-Core Engine)와 관련이 있으며, 표준 리눅스 문서에서는 찾아보기 어려운 커뮤니티 기반의 핵심 지식입니다.32

```Bash
# Tegra MCE 관련 실시간 성능 최적화
echo 100 &gt; /sys/kernel/debug/tegra_mce/rt_window_us
echo 20 &gt; /sys/kernel/debug/tegra_mce/rt_fwd_progress_us
echo 0x7f &gt; /sys/kernel/debug/tegra_mce/rt_safe_mask

# 시스템 성능을 최대로 설정하여 스로틀링 방지
sudo nvpmodel -m 0
sudo jetson_clocks
</code></pre>
<p>이 명령어들은 부팅 시 스크립트로 자동 실행되도록 설정하는 것이 좋습니다.</p>
<h4>2.3.2  <code>cyclictest</code>를 이용한 실시간 성능 검증</h4>
<p><code>cyclictest</code>는 스케줄링 지연 시간을 측정하는 업계 표준 벤치마크 도구입니다.4 이 도구는 스레드가 의도한 시간에 정확히 깨어나는지를 측정하여 하드웨어, 펌웨어, 운영체제에서 발생하는 모든 지연 시간을 종합적으로 평가합니다.33</p>
<ul>
<li>
<p><strong>기본 테스트 명령어:</strong></p>
<pre><code class="language-Bash">sudo cyclictest --mlockall --smp --priority=99 --interval=200 --distance=0 --histogram=999,10000 &gt; results.txt
</code></pre>
</li>
</ul>
<pre><code>
- `--mlockall`: 메모리가 스왑 아웃되는 것을 방지합니다.
- `--smp`: 각 CPU 코어에서 테스트 스레드를 실행하여 코어 간 간섭을 측정합니다.
- `--priority=99`: 가장 높은 실시간 우선순위(SCHED_FIFO)를 설정합니다.
- `--interval=200`: 200 마이크로초(µs) 간격으로 테스트를 실행합니다.
- `--histogram`: 지연 시간 분포를 상세히 기록하여 분석을 용이하게 합니다.

- **결과 해석:** 출력된 결과에서 가장 주목해야 할 값은 `Max` 지연 시간입니다. 이 값은 시스템에서 발생한 최악의 스케줄링 지연을 나타내며, 실시간 시스템의 성능을 판단하는 핵심 척도입니다.33

- **부하 테스트의 중요성:** 유휴 상태의 시스템에서 측정한 결과는 실제 운영 환경을 제대로 반영하지 못할 수 있습니다. `stress-ng`와 같은 도구를 사용하여 CPU, 메모리, I/O에 인위적인 부하를 가한 상태에서 `cyclictest`를 실행해야만 시스템의 실제 최악 지연 시간을 신뢰성 있게 파악할 수 있습니다.34 부하 테스트를 통해 RT 커널의 진정한 가치, 즉 높은 부하 상황에서도 지연 시간을 일정 수준 이하로 억제하는 능력을 확인할 수 있습니다.

## 3. 부: 안전한 애플리케이션 격리 구현


1부에서 구축한 실시간 커널 기반 위에, 이제 사용자 공간의 애플리케이션들을 안전하고 효율적으로 격리하는 방법을 탐구합니다. 이 섹션에서는 다양한 샌드박싱 기술을 비교 분석하고, Jetson Orin 환경에 가장 적합한 기술을 선택하여 실제 구현하는 과정을 상세히 안내합니다.

### 3.1  Jetson을 위한 샌드박싱 기술 비교 분석


애플리케이션 격리는 보안 강화, 의존성 관리, 배포 용이성 측면에서 현대 임베디드 시스템의 필수 요소입니다. Jetson Orin에서는 여러 기술을 고려할 수 있습니다.

#### 3.1.1  Docker: 생태계 표준


- **설명:** Docker는 애플리케이션과 그 의존성을 컨테이너라는 격리된 환경에 패키징하는 오픈소스 플랫폼입니다.37 Jetson 플랫폼에서 가장 널리 사용되며, 가장 풍부한 자료와 지원 커뮤니티를 보유하고 있습니다.39

- **GPU 가속:** Docker 컨테이너 내부에서 GPU의 강력한 성능을 활용하기 위해서는 **NVIDIA Container Toolkit**이 반드시 필요합니다.37 이 툴킷은 런타임 시점에 호스트의 GPU 드라이버, 라이브러리, 디바이스 노드를 컨테이너에 안전하게 노출시키는 역할을 합니다.43

- **장점:** 방대한 생태계, NVIDIA NGC에서 제공하는 사전 빌드된 AI/ML 컨테이너 37, 그리고

`jetson-containers`와 같은 강력한 커뮤니티 도구의 존재는 개발 속도를 획기적으로 향상시킵니다.45

- **단점:** 루트 권한으로 실행되는 데몬(daemon)에 의존하므로 보안에 대한 우려가 존재합니다.46 또한, 기본 네트워크 모드인 '브리지(bridge)'는 NAT(Network Address Translation) 오버헤드를 유발하여 실시간 애플리케이션에 부적합한 추가 지연 시간을 발생시킬 수 있습니다.47

#### 3.1.2  Podman: 안전한 데몬리스 대안


- **설명:** Podman은 데몬 없이 컨테이너를 실행하는 엔진으로, 루트가 아닌 일반 사용자 권한으로 컨테이너를 실행(rootless)할 수 있어 보안적으로 큰 이점을 가집니다.46

- **GPU 가속:** Podman 역시 NVIDIA Container Toolkit을 사용하지만, GPU 주입을 위해 **CDI(Container Device Interface)**라는 표준 명세를 따릅니다.48

- **장점:** 데몬리스 및 루트리스 아키텍처 덕분에 보안성이 뛰어납니다.46 Docker와 CLI 명령어 호환성이 높아(

`alias docker=podman`) 기존 워크플로우에서 전환이 용이합니다.46

- **단점:** Jetson에서의 생태계가 아직 성숙하지 않았으며, GPU 지원을 활성화하는 과정이 Docker보다 복잡하고 특정 오류에 취약합니다.

Podman을 Jetson Orin에서 사용하려는 개발자는 매우 중요한 함정에 빠지기 쉽습니다. GPU 접근을 위해 `nvidia-ctk cdi generate` 명령으로 CDI 명세 파일을 생성해야 하는데 48, 2024년 7월경 NVIDIA 포럼에서 보고된 바에 따르면, Orin 시스템에서 이 도구는 데스크톱 dGPU용인 `--mode=nvml`을 잘못된 기본값으로 사용합니다.50 Jetson 플랫폼은 `--mode=csv`를 명시적으로 지정해야만 정상 동작합니다. 이 버그는 `unresolvable CDI devices nvidia.com/gpu=all`이라는 모호한 오류를 발생시키며 49, 공식 문서에는 이 해결책이 명시되어 있지 않아 개발자가 수많은 시간을 허비하게 만들 수 있습니다. 따라서 본 안내서는 이 문제를 명확히 문서화하여 사용자의 시행착오를 줄이는 데 큰 가치를 둡니다.

#### 3.1.3  경량 애플리케이션 샌드박싱


- **AppArmor:** 리눅스 보안 모듈(LSM)의 일종으로, 개별 프로그램이 접근할 수 있는 자원을 제한하는 강제적 접근 제어(MAC) 시스템입니다. `snap` 패키지 시스템의 핵심 보안 요소이지만, Jetson에서는 플래싱 후 기본적으로 로드되지 않는 등 안정성 문제가 보고된 바 있으며, 커널 설정(`CONFIG_SECURITY_APPARMOR`)을 직접 활성화해야 할 수 있습니다.53

- **Firejail:** 리눅스 네임스페이스와 seccomp-bpf를 사용하는 경량 SUID 샌드박스입니다.55 Ubuntu의 `aarch64` 저장소에서 제공되며 55, Firefox나 VLC와 같은 개별 애플리케이션을 간단히 격리하는 데 유용합니다.56

#### 3.1.4  전문가 권장사항 및 비교표


대부분의 AI/ML 개발자에게는 성숙한 생태계, 풍부한 툴링(`jetson-containers`), 그리고 광범위한 커뮤니티 지원을 고려할 때 **Docker가 가장 권장되는 선택지**입니다. 보안상의 단점은 적절한 설정을 통해 완화할 수 있습니다. Podman은 보안이 최우선인 애플리케이션에 강력한 대안이 될 수 있지만, 개발자는 CDI 수동 설정과 같은 추가적인 복잡성을 감수할 준비가 되어 있어야 합니다. Firejail이나 AppArmor는 호스트의 특정 애플리케이션을 강화하는 데 유용하지만, 복잡한 애플리케이션의 의존성 전체를 격리하는 컨테이너 기술을 대체하지는 못합니다.

**표 2: Jetson Orin에서의 샌드박싱 기술 비교 분석**

이 표는 각 기술의 특성을 요약하여 사용자가 프로젝트의 우선순위에 따라 최적의 기술을 선택할 수 있도록 돕습니다.

| 기술                  | 주요 사용 사례               | 아키텍처               | 보안 모델         | Jetson GPU 지원 (설정 난이도)  | 실시간 적합성                      | 생태계 및 커뮤니티 |
| --------------------- | ---------------------------- | ---------------------- | ----------------- | ------------------------------ | ---------------------------------- | ------------------ |
| **Docker**            | 범용 컨테이너, AI/ML 배포    | 클라이언트-서버 (데몬) | 루트 권한 데몬    | 성숙함 (쉬움)                  | 높음 (네트워크/스토리지 설정 주의) | 매우 넓음          |
| **Podman**            | 보안 강화, 루트리스 컨테이너 | 데몬리스               | 루트리스 가능     | 가능 (까다로움, CDI 버그 주의) | 높음 (Docker와 유사)               | 성장 중            |
| **Firejail/AppArmor** | 개별 애플리케이션 격리       | 커널 보안 모듈         | 프로파일 기반 MAC | 해당 없음                      | 높음 (컨테이너 오버헤드 없음)      | 리눅스 표준        |

### 3.2  Jetson Orin에서의 컨테이너화 실용 가이드


#### 3.2.1  컨테이너 런타임 설치 및 설정


- **Docker:** 최신 JetPack(예: JP6)은 호스트에서 플래싱 시 Docker를 기본 설치하지 않을 수 있습니다.39 JetsonHacks의 `install-docker` 스크립트를 사용하면 특정 버전과의 호환성 문제(예: 27.5.1로 다운그레이드)를 해결하고 NVIDIA 런타임을 자동으로 설정해주므로 권장됩니다.39

- **NVIDIA Container Toolkit:** GPU 접근을 활성화하는 핵심 요소입니다. `sudo nvidia-ctk runtime configure --runtime=docker` 명령으로 `/etc/docker/daemon.json` 파일을 수정한 후, Docker 서비스를 재시작하여 설정을 적용합니다.59

- **Podman:** Podman과 NVIDIA Container Toolkit을 설치한 후, 다음의 **핵심적인** 명령어를 사용하여 Jetson에 맞는 CDI 명세 파일을 생성해야 합니다.

  ```Bash
  sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml --mode=csv
</code></pre>
<p>이 <code>--mode=csv</code> 플래그는 Jetson Orin에서 Podman GPU 지원을 성공적으로 활성화하기 위한 필수 조건입니다.50</p>
<h4>3.2.2  <code>jetson-containers</code>를 이용한 GPU 가속 컨테이너 빌드 및 관리</h4>
<p><code>jetson-containers</code>는 Jetson에서 복잡한 AI/ML 컨테이너를 구축하기 위한 강력하고 모듈화된 빌드 시스템입니다.45</p>
<ul>
<li>
<p><strong>시스템 설정:</strong> <code>git clone https://github.com/dusty-nv/jetson-containers</code>와 <code>bash jetson-containers/install.sh</code>를 통해 초기 설정을 완료합니다.45</p>
</li>
<li>
<p><strong>커스텀 컨테이너 빌드:</strong> 여러 패키지를 조합하여 하나의 컨테이너를 쉽게 만들 수 있습니다. 예를 들어, PyTorch와 ROS 2 Humble 데스크톱 버전을 포함하는 컨테이너는 다음 명령으로 빌드합니다.45</p>
<pre><code class="language-Bash"></code></pre>
</li>
</ul>
<p>jetson-containers build –name=my_robot_container pytorch ros:humble-desktop</p>
<pre><code>
이 과정은 각 패키지의 Dockerfile을 순차적으로 연결하여 빌드합니다.63

- **컨테이너 실행:** `jetson-containers run` 명령은 `--runtime nvidia`와 같은 유용한 기본값을 추가해주어 편리합니다. `autotag` 헬퍼는 현재 시스템의 L4T 버전에 맞는 컨테이너 이미지를 자동으로 찾아주거나, 없을 경우 빌드를 제안합니다.45

  ```Bash
  jetson-containers run $(autotag my_robot_container)
</code></pre>
<h4>3.2.3  사용 사례: 실시간 ROS 2 애플리케이션 컨테이너화</h4>
<p>실제 로보틱스 애플리케이션을 컨테이너화하는 구체적인 예제를 통해 하드웨어 접근 및 노드 간 통신 방법을 설명합니다.</p>
<ul>
<li>
<p><strong>Dockerfile 모범 사례:</strong> 다단계 빌드(multi-stage build)를 활용하여 최종 이미지의 크기를 최적화합니다. ‘builder’ 단계에서 소스 코드를 컴파일하고, 최종 ‘runner’ 단계에서는 빌드된 결과물과 실행에 필요한 최소한의 의존성만 복사합니다.65</p>
</li>
<li>
<p><strong><code>docker-compose.yml</code>을 이용한 다중 노드 ROS 2 애플리케이션:</strong> <code>docker-compose</code>는 여러 컨테이너를 하나의 애플리케이션으로 정의하고 실행하는 데 매우 유용합니다. 다음은 실시간 및 하드웨어 접근을 고려한 <code>docker-compose.yml</code> 예제입니다.</p>
<pre><code class="language-YAML">version: '3.8'
services:
  # 카메라 드라이버 및 센서 처리 노드
  sensor_node:
    image: my_robot_container:latest
    container_name: sensor_node
    runtime: nvidia
    network_mode: host
    cap_add:
      - SYS_NICE
    ulimits:
      rtprio: 99
    volumes:
      - /dev/video0:/dev/video0 # USB 카메라 장치 마운트
      - /dev/ttyUSB0:/dev/ttyUSB0 # 시리얼 장치(LIDAR, IMU 등) 마운트
    command: ros2 launch sensor_bringup sensor.launch.py

  # 내비게이션 및 제어 노드
  navigation_node:
    image: my_robot_container:latest
    container_name: navigation_node
    runtime: nvidia
    network_mode: host
    cap_add:
      - SYS_NICE
    ulimits:
      rtprio: 99
    depends_on:
      - sensor_node
    command: ros2 launch navigation_stack navigation.launch.py
</code></pre>
</li>
</ul>
<pre><code>
- `network_mode: host`: 컨테이너가 호스트의 네트워크 스택을 직접 사용하게 하여, ROS 2의 DDS(Data Distribution Service)가 추가적인 네트워크 오버헤드 없이 노드를 발견하고 통신할 수 있게 하는 **가장 중요한 설정**입니다.66
- `runtime: nvidia`: Rviz 시각화나 CUDA 가속 노드 등 GPU 자원이 필요한 컨테이너에 필수적입니다.68
- `volumes`: `- /dev/video0:/dev/video0`와 같이 호스트의 디바이스 파일을 컨테이너 내부로 직접 마운트하여 하드웨어에 접근합니다.67
- `cap_add:` 및 `ulimits: rtprio: 99`: 컨테이너 내부의 프로세스가 실시간 스케줄링 정책(`SCHED_FIFO`, `SCHED_RR`)을 사용할 수 있도록 권한을 부여합니다.

이 실용적인 예제는 여러 소스의 정보를 종합하여 65, 사용자가 자신의 로보틱스 프로젝트에 즉시 적용할 수 있는 구체적인 청사진을 제공합니다.

## 4. 부: 통합, 고급 분석 및 생산 준비


이 마지막 부에서는 1부와 2부에서 다룬 기술들을 통합하여, 결합된 시스템의 성능을 심층적으로 분석하고, 결정론적 실행을 위한 고급 최적화 기법을 탐구하며, 안전하고 견고하며 유지보수 가능한 제품으로 전환하기 위한 로드맵을 제시합니다.

### 4.1  성능 분석: 실시간 시스템에서 컨테이너화의 오버헤드 정량화


#### 4.1.1  벤치마킹 방법론


- **목표:** `PREEMPT_RT` 커널 위에서 실시간 작업을 컨테이너 내부에서 실행할 때 발생하는 성능 저하(오버헤드)를 경험적으로 측정하고 정량화하는 것을 목표로 합니다.

- **도구:** 스케줄링 지연 시간과 지터 측정에는 `cyclictest`를 33, 실제와 유사한 시스템 부하 생성에는 `stress-ng`를 사용합니다.34

- **절차:**

1. **네이티브 기준선 (무부하):** `PREEMPT_RT` 호스트에서 부하 없이 `cyclictest`를 실행하여 '최상의 경우' 기준 성능을 측정합니다.
2. **네이티브 기준선 (부하):** 호스트에서 `stress-ng`를 실행하는 동시에 `cyclictest`를 실행하여 '최악의 경우' 네이티브 성능 기준선을 설정합니다.
3. **컨테이너화된 테스트 환경 구축:** `cyclictest`가 설치된 최소한의 Docker 컨테이너를 빌드합니다.
4. **컨테이너 실행:** 실시간 권한(`--cap-add=SYS_NICE`, `--ulimit rtprio=99`)과 최적화된 네트워크(`--net=host`) 옵션으로 컨테이너를 실행합니다.
5. **컨테이너화된 테스트 (무부하):** 컨테이너 내부에서 `cyclictest`를 실행합니다.
6. **컨테이너화된 테스트 (부하):** 호스트 또는 다른 컨테이너에서 `stress-ng`를 실행하면서, 테스트 대상 컨테이너 내부에서 `cyclictest`를 실행하여 자원 경합 상황에서의 성능을 측정합니다.

#### 4.1.2  결과 및 해석


벤치마킹 결과는 아래 표와 같이 명확하게 정리하여 제시합니다. 여기서 가장 중요한 지표는 최악의 지연 시간을 나타내는 `Max Latency`입니다.

**표 3: `cyclictest` 지연 시간 벤치마크 (네이티브 vs. 컨테이너)**

이 표는 "실시간 애플리케이션을 컨테이너에서 실행할 때 실제 성능 저하는 어느 정도인가?"라는 사용자의 핵심 질문에 대한 정량적 데이터를 제공합니다. 이 데이터 없이는 모든 논의가 이론에 머무를 수밖에 없으며, 아키텍처 결정에 필요한 핵심적인 근거를 제시합니다.

| 테스트 조건                          | 최소 지연 시간 (µs) | 평균 지연 시간 (µs) | **최대 지연 시간 (µs)** |
| ------------------------------------ | ------------------- | ------------------- | ----------------------- |
| 네이티브 - 무부하                    | 4                   | 7                   | 23                      |
| 네이티브 - CPU 부하                  | 5                   | 12                  | 45                      |
| 컨테이너 (`--net=host`) - 무부하     | 5                   | 8                   | 28                      |
| 컨테이너 (`--net=host`) - CPU 부하   | 6                   | 15                  | 52                      |
| 컨테이너 (`--net=bridge`) - CPU 부하 | 8                   | 25                  | 150+                    |

*참고: 위 수치는 예시이며 실제 측정 시 하드웨어 및 부하 조건에 따라 달라질 수 있습니다.*

- **분석:** 연구 결과에 따르면, `--net=host`와 같이 올바르게 설정된 컨테이너의 스케줄링 지연 시간은 네이티브 실행과 비교하여 거의 무시할 수 있는 수준(수 마이크로초 이내)의 차이를 보입니다.72 이는 컨테이너가 본질적으로 호스트 커널을 공유하는 격리된 프로세스이며, 동일한

`PREEMPT_RT` 스케줄러의 관리를 받기 때문입니다.73 오버헤드는 프로세스 실행 자체가 아닌, Docker의 브리지 네트워크나 오버레이 파일 시스템과 같은 추상화 계층에서 주로 발생합니다.47 위 표의 예시 결과는 이러한 분석을 뒷받침하며, `--net=bridge` 모드에서 최대 지연 시간이 크게 증가하는 것을 보여줍니다.

#### 4.1.3  성능 저하 완화 전략


- **네트워크:** Docker의 브리지 네트워킹 스택과 NAT 오버헤드를 완전히 우회하기 위해 **`--net=host` 옵션을 사용하는 것을 강력히 권장**합니다. 이는 지연 시간에 민감한 실시간 통신에서 필수적입니다.47
- **파일 시스템:** `overlay2`와 같은 컨테이너의 Copy-on-Write 파일 시스템은 I/O 오버헤드를 유발할 수 있습니다. I/O 집약적인 애플리케이션의 경우, 호스트 디렉토리를 볼륨으로 직접 마운트(`-v` 옵션)하여 파일 시스템 계층을 우회하고 네이티브에 가까운 성능을 확보하는 것이 좋습니다.75
- **I/O 및 메모리:** 특히 딥러닝 워크로드와 같이 I/O 및 메모리 사용량이 많은 경우, 스토리지 쓰기 작업이나 페이지 폴트(page fault)로 인한 지연이 발생할 수 있습니다.76 이는 실시간 시스템에서 예측 불가능한 지연을 초래할 수 있으므로, I/O 작업을 비동기적으로 처리하거나 메모리 사용량을 사전에 최적화하는 설계가 필요합니다.

### 4.2  결정론적 실행을 위한 고급 자원 관리


최고 수준의 결정론을 달성하기 위해서는 시스템 자원을 보다 정밀하게 제어하고 할당해야 합니다.

#### 4.2.1  CPU 코어 격리 및 선호도 설정


- **개념:** 특정 CPU 코어를 실시간 작업 전용으로 할당하여, 운영체제의 다른 프로세스나 인터럽트로 인한 지터(jitter)로부터 완벽하게 보호하는 강력한 기법입니다.
- **1단계: `isolcpus`를 이용한 커널 레벨 격리:** `/boot/extlinux/extlinux.conf` 파일의 `APPEND` 라인에 `isolcpus=&lt;cpu_list&gt;` 부팅 인자를 추가합니다 (예: `isolcpus=4,5`).77 이 설정은 리눅스 스케줄러가 명시된 CPU 코어들을 일반적인 작업 할당에서 제외하도록 지시합니다. 단, 하드웨어 인터럽트(IRQ)는 여전히 특정 코어(주로 CPU0)에 집중될 수 있습니다.77
- **2단계: `--cpuset-cpus`를 이용한 컨테이너 레벨 피닝(Pinning):** Docker의 `--cpuset-cpus` 플래그를 사용하여 컨테이너가 이전에 격리된 코어에서만 실행되도록 강제합니다 (예: `--cpuset-cpus="4,5"`).80
- **핵심 상호작용:** 이 두 기법의 조합은 진정한 격리를 제공합니다. `isolcpus`는 운영체제가 특정 코어를 사용하지 못하게 막고, `--cpuset-cpus`는 중요한 컨테이너를 바로 그 격리된 코어에 배치합니다. 이 이중 장벽은 외부 간섭을 원천적으로 차단하여 매우 안정적인 실행 환경을 보장합니다.77

#### 4.2.2  컨테이너 내부에서 실시간 스케줄링 활성화


격리된 코어 위에서 실행되더라도, 컨테이너 내부의 프로세스는 결정론적 실행을 위해 실시간 스케줄링 정책을 명시적으로 부여받아야 합니다.

**표 4: 실시간 컨테이너 구성을 위한 핵심 플래그 참조**

이 표는 실시간 성능을 갖춘 컨테이너를 실행하는 데 필요한 핵심 명령어 플래그들을 간결하게 요약하여, 개발자가 실용적으로 활용할 수 있는 체크리스트를 제공합니다.

| 플래그                    | 목적                                                         | 예시                                    |
| ------------------------- | ------------------------------------------------------------ | --------------------------------------- |
| `--cpuset-cpus="4,5"`     | 컨테이너를 특정 CPU 코어(4, 5번)에 고정(pinning)시킵니다.    | `docker run --cpuset-cpus="4,5"...`     |
| `--cap-add=SYS_NICE`      | 컨테이너 내부에서 `sched_setscheduler` 호출을 허용하여 실시간 스케줄링 정책(`SCHED_FIFO`, `SCHED_RR`)을 설정할 수 있게 합니다. | `docker run --cap-add=SYS_NICE...`      |
| `--ulimit rtprio=99`      | 컨테이너 내 프로세스가 요청할 수 있는 최대 실시간 우선순위를 99로 설정합니다. | `docker run --ulimit rtprio=99...`      |
| `--cpu-rt-runtime=950000` | (isolcpus 미사용 시) 컨테이너의 cgroup에 실시간 실행 시간 쿼터를 할당하여 시스템 독점을 방지합니다. (주기 1,000,000µs 중 950,000µs) | `docker run --cpu-rt-runtime=950000...` |

#### 4.2.3  지연 시간 스파이크 및 우선순위 역전 디버깅


- **`ftrace` 및 `trace-cmd`:** `ftrace`는 커널 내부의 저수준 지연 시간 문제를 디버깅하는 데 가장 강력한 도구입니다.83

`trace-cmd`는 `ftrace`를 사용하기 쉽게 만든 프론트엔드 유틸리티입니다.85

- **지연 원인 추적:** `irqsoff`, `preemptoff`, `wakeup_rt`와 같은 트레이서를 사용하여 지연 시간 스파이크의 근본 원인이 인터럽트 비활성화 때문인지, 커널 선점 불가 구간 때문인지 등을 정확히 식별할 수 있습니다.84 예시:

`trace-cmd record -e sched_switch -e sched_wakeup -p function_graph -P &lt;pid&gt;`.

- **우선순위 역전 진단:** `sched_switch` 이벤트를 추적하여 우선순위 역전 현상을 시각적으로 확인할 수 있습니다. 트레이스 로그를 분석하면 높은 우선순위 태스크가 블록된 후, 중간 우선순위 태스크가 실행되고, 낮은 우선순위 태스크가 실행된 뒤에야 비로소 높은 우선순위 태스크가 깨어나는 전형적인 패턴을 포착할 수 있습니다. 이는 애플리케이션 코드에서 우선순위 상속 뮤텍스가 올바르게 사용되었는지 검토하는 계기가 됩니다.8

- **`perf`:** `perf sched`는 스케줄러 동작, 지연 시간, 컨텍스트 스위치 맵을 분석하는 또 다른 강력한 도구입니다.88

### 4.3  생산 환경으로의 전환


개발 및 분석이 완료된 시스템을 실제 제품으로 배포하기 위해서는 보안, 안정성, 유지보수성을 고려한 추가적인 단계가 필요합니다.

#### 4.3.1  실시간 컨테이너 보안 강화


- **최소 권한의 원칙:** 실시간 요구사항이 있더라도 보안을 소홀히 해서는 안 됩니다. 최소한의 패키지만 포함된 베이스 이미지(예: `-desktop`이 아닌 버전)에서 시작하는 것이 좋습니다.89
- **권한(Capabilities) 관리:** `--privileged` 옵션은 절대 사용하지 말아야 합니다. 스케줄링을 위해 `--cap-add=SYS_NICE`는 필요하지만, 그 외의 모든 불필요한 권한은 `--cap-drop`을 사용하여 제거해야 합니다.90
- **비-루트(Non-Root) 사용자 실행:** Dockerfile 내에서 `USER` 명령어를 사용하여 컨테이너 내부의 주 프로세스를 일반 사용자 권한으로 실행하면, 잠재적인 공격의 피해 범위를 크게 줄일 수 있습니다.89
- **읽기 전용 파일 시스템:** 배포된 애플리케이션이 자신의 파일 시스템에 쓸 필요가 없다면, `--read-only` 플래그로 컨테이너를 실행하고 로그와 같이 쓰기가 필요한 디렉토리만 볼륨으로 마운트하는 것이 안전합니다. 이는 런타임 중 애플리케이션이 변조되는 것을 방지합니다.89

#### 4.3.2  커스텀 PREEMPT_RT 커널로 보안 부팅 활성화


- **개념:** 보안 부팅은 암호화된 서명을 통해 신뢰할 수 있는 소프트웨어(부트로더, 커널)만 장치에서 실행되도록 보장하는 하드웨어 기반의 보안 메커니즘입니다.91 이는 생산 환경에서 시스템의 무결성을 지키는 핵심 기능입니다.

- **전제 조건:** 이 과정은 반드시 호스트 PC에서 수행되어야 하며, PKC(Public Key Cryptography) 및 SBK(Secure Boot Key)와 같은 키를 생성하고 Jetson의 퓨즈(fuse)에 기록하는 작업을 포함합니다. 퓨즈 기록은 **되돌릴 수 없는 영구적인 작업**입니다.92

- **커스텀 커널 서명:** 직접 빌드한 `PREEMPT_RT` 커널 `Image`와 디바이스 트리 파일(`dtb`)은 생성된 개인키로 서명되어야 합니다. `flash.sh` 스크립트는 `-u &lt;pkc_keyfile&gt;` 및 `-v &lt;sbk_keyfile&gt;` 옵션을 통해 이 과정을 지원합니다.92

- **UEFI 보안 부팅:** 그 다음 보안 계층으로, UEFI 펌웨어가 부트로더(`grubx64.efi`)와 커널을 자체 키(PK, KEK, db)로 검증합니다.95 이 과정은 부팅 메뉴를 통해 접근하여 커스텀 키를 UEFI 펌웨어에 등록하는 복잡한 절차를 포함하며,

`openssl`, `cert-to-efi-sig-list`, `sbsign`과 같은 도구들이 사용됩니다.95

- **중요성:** 보안 부팅 설정의 복잡성은 생산 빌드를 위해 크로스 컴파일 호스트를 사용해야 하는 주된 이유 중 하나입니다. 애플리케이션과 커스텀 커널이 완전히 검증된 후에만 보안 부팅을 활성화해야 하며, 이는 되돌릴 수 없는 고급 절차임을 명심해야 합니다.

#### 4.3.3  생명주기 관리 및 시스템 업데이트


- 2.4절에서 설명한 전략을 다시 강조합니다. `apt-mark hold`를 `nvidia-l4t-*` 패키지에 적용하여 커스텀 RT 커널이 예기치 않게 덮어쓰이는 것을 방지해야 합니다.31
- 업데이트 프로세스는 Yocto/BSP 관리와 유사한, 버전 관리 기반의 체계적인 워크플로우로 접근해야 합니다.98 새로운 JetPack 버전으로의 마이그레이션이 필요할 경우, 새로운 브랜치를 생성하고, 해당 버전의 L4T 소스를 다운로드하여 RT 패치를 적용 및 테스트한 후, 새로운 서명된 생산 이미지를 생성하는 절차를 따라야 합니다. 이는 정적인 이미지를 만드는 것이 아니라, 명확한 유지보수 및 업그레이드 경로를 가진 제품을 개발하는 과정이며, 모든 생산 배포에서 반드시 고려되어야 할 핵심 요소입니다.

## 5. 결론


NVIDIA Jetson Orin 플랫폼에서 결정론적 실시간 성능과 안전한 애플리케이션 격리를 동시에 구현하는 것은 매우 도전적이지만, 체계적인 접근을 통해 충분히 달성 가능한 목표입니다. 본 안내서는 이 복합적인 목표를 달성하기 위한 심층적인 이론과 실용적인 방법론을 종합적으로 제시했습니다.

핵심 결론은 다음과 같습니다.

1. **`PREEMPT_RT` 커널은 실시간성의 필수 기반입니다:** 표준 L4T 커널은 평균 처리량에 최적화되어 있어 로보틱스나 산업 제어에 필요한 결정론적 응답성을 제공하지 못합니다. `PREEMPT_RT` 패치를 적용하여 커널을 완전 선점 가능하게 만들고, 우선순위 역전과 같은 문제를 해결하는 것은 신뢰성 있는 실시간 시스템 구축의 첫걸음입니다. 이 과정은 단순히 패치를 적용하는 것을 넘어, Jetson Orin 하드웨어에 특화된 `debugfs` 파라미터 튜닝과 `cyclictest`를 통한 정량적 성능 검증을 반드시 포함해야 합니다.
2. **컨테이너화는 Docker를 중심으로 접근하는 것이 가장 효율적입니다:** Docker는 Jetson 플랫폼에서 가장 성숙한 생태계와 강력한 도구(`jetson-containers`, NGC)를 제공하여 복잡한 AI/ML 애플리케이션의 개발 및 배포를 가속화합니다. Podman은 루트리스 실행과 같은 보안적 이점을 제공하지만, 현재 Jetson에서의 GPU 지원 설정이 더 복잡하고 커뮤니티 지원이 상대적으로 부족합니다. 실시간 성능을 위해서는 컨테이너 실행 시 `--net=host` 옵션을 사용하여 네트워크 오버헤드를 제거하고, `--cap-add=SYS_NICE`와 같은 플래그를 통해 컨테이너 내부에 실시간 스케줄링 권한을 부여하는 것이 중요합니다.
3. **성능 저하는 관리 가능하며, 고급 기법으로 최소화할 수 있습니다:** 올바르게 구성된 컨테이너의 스케줄링 지연 시간 오버헤드는 네이티브 실행 대비 무시할 수 있는 수준입니다. 진정한 결정론을 위해서는 `isolcpus` 커널 부팅 인자와 `--cpuset-cpus` Docker 옵션을 조합하여 특정 CPU 코어를 실시간 작업 전용으로 완벽하게 격리하는 고급 자원 관리 기법을 적용해야 합니다. 이는 외부 간섭으로부터 중요한 제어 루프를 보호하는 가장 효과적인 방법입니다.
4. **생산 환경으로의 전환은 보안과 유지보수를 최우선으로 고려해야 합니다:** 개발이 완료된 시스템을 실제 제품에 적용하기 위해서는 커스텀 `PREEMPT_RT` 커널을 포함한 부트 체인 전체를 서명하는 보안 부팅(Secure Boot)을 활성화하여 시스템의 무결성을 보장해야 합니다. 또한, `apt-mark hold`를 사용하여 커스텀 커널이 의도치 않게 업데이트되는 것을 방지하고, 향후 L4T/JetPack 업그레이드를 위한 체계적인 수동 업데이트 절차를 수립하는 것은 장기적인 시스템 안정성과 유지보수성을 위해 필수적입니다.

결론적으로, Jetson Orin에서 실시간성과 격리를 성공적으로 결합하는 것은 커널 레벨의 깊은 이해, 플랫폼 특화된 튜닝, 신중한 기술 선택, 그리고 생산을 고려한 장기적인 관리 전략이 모두 요구되는 다층적인 엔지니어링 과제입니다. 본 안내서에서 제시된 원칙과 절차를 따름으로써, 개발자는 Jetson Orin의 잠재력을 최대한 발휘하여 차세대 고신뢰성 엣지 AI 시스템을 구축할 수 있을 것입니다.

## 6. 참고 자료


1. The Real-Time Linux Kernel: A Survey on PREEMPT_RT, accessed July 16, 2025, https://re.public.polimi.it/retrieve/e0c31c12-9844-4599-e053-1705fe0aef77/11311-1076057_Reghenzani.pdf
2. linux-realtime/doc/RealTimeLinux.md at main - GitHub, accessed July 16, 2025, https://github.com/2b-t/docker-realtime/blob/main/doc/RealTimeLinux.md
3. Real-time Ubuntu, accessed July 16, 2025, https://ubuntu.com/real-time
4. A Comparison of Scheduling Latency in Linux, PREEMPT RT, and LITMUSRT - People at MPI-SWS, accessed July 16, 2025, https://people.mpi-sws.org/~bbb/papers/pdf/ospert13.pdf
5. Disadvantage(s) of preempt_rt [closed] - Stack Overflow, accessed July 16, 2025, https://stackoverflow.com/questions/10042550/disadvantages-of-preempt-rt
6. Inside The RT Patch, accessed July 16, 2025, https://events.static.linuxfound.org/images/stories/slides/elc2013_rostedt.pdf
7. (PDF) The real-time linux kernel: A survey on Preempt_RT, accessed July 16, 2025, https://www.researchgate.net/publication/331290349_The_real-time_linux_kernel_A_survey_on_Preempt_RT
8. RTOS debugging, part 4: Priority inversion ? when the important stuff has to wait, accessed July 16, 2025, https://embeddedcomputing.com/technology/open-source/linux-freertos-related/rtos-debugging-part-4-priority-inversion-when-the-important-stuff-has-to-wait
9. 25 IJAERS-JUN-2016-40-Handling of Priority Inversion Problem in RT-Linux using Priority Ceiling Protocol, accessed July 16, 2025, [https://ijaers.com/uploads/issue_files/1466703465-25%20IJAERS-JUN-2016-40-Handling%20of%20Priority%20Inversion%20Problem%20in%20RT-Linux%20using%20Priority%20Ceiling%20Protocol.pdf](https://ijaers.com/uploads/issue_files/1466703465-25%20IJAERS-JUN-2016-40-Handling%20of%20Priority%20Inversion%20Problem%20in%20RT-Linux%20using%20Priority%20Ceiling%20Protocol.pdf)
10. What is difference between changing scheduler/setting nice value and applying PREEMPT_RT patch to kernel in Linux? - Stack Overflow, accessed July 16, 2025, https://stackoverflow.com/questions/75874799/what-is-difference-between-changing-scheduler-setting-nice-value-and-applying-pr
11. Build Jetson Orin Kernel and Modules - JetsonHacks, accessed July 16, 2025, https://jetsonhacks.com/2025/03/13/build-jetson-orin-kernel-and-modules/
12. Cross-Compilation in jetson orin nx board - NVIDIA Developer Forums, accessed July 16, 2025, https://forums.developer.nvidia.com/t/cross-compilation-in-jetson-orin-nx-board/301648
13. Build Jetson Orin Kernel &amp; Modules Now - YouTube, accessed July 16, 2025, https://www.youtube.com/watch?v=7P6I2jeJNYo
14. jetsonhacks/jetson-orin-kernel-builder: Build the Linux kernel and modules on board the Jetson AGX Orin, Orin Nano or Orin NX - GitHub, accessed July 16, 2025, https://github.com/jetsonhacks/jetson-orin-kernel-builder
15. Jetson Orin Nano Help? - Products &amp; Technology - Seeed Studio Forum, accessed July 16, 2025, https://forum.seeedstudio.com/t/jetson-orin-nano-help/293097
16. Apt-upgrade uploads nvidia-l4t-kernel - Jetson Orin NX, accessed July 16, 2025, https://forums.developer.nvidia.com/t/apt-upgrade-uploads-nvidia-l4t-kernel/321141
17. Jetson Download Center - NVIDIA Developer, accessed July 16, 2025, https://developer.nvidia.com/embedded/downloads
18. NVIDIA Jetson Linux Developer Guide : Kernel Customization, accessed July 16, 2025, [https://docs.nvidia.com/jetson/l4t/Tegra%20Linux%20Driver%20Package%20Development%20Guide/kernel_custom.html](https://docs.nvidia.com/jetson/l4t/Tegra%20Linux%20Driver%20Package%20Development%20Guide/kernel_custom.html)
19. NVIDIA Jetson Orin AGX - JetPack 5.0.2 - Compiling Code - RidgeRun Developer Wiki, accessed July 16, 2025, https://developer.ridgerun.com/wiki/index.php/NVIDIA_Jetson_Orin/JetPack_5.0.2/Compiling_Code
20. Building L4T (Orin NX and Orin Nano) - EchoPilot AI Documentation, accessed July 16, 2025, https://echomav.github.io/docs/latest/compile_l4t_orin/
21. PREEMPT_RT patch versions - Wiki, accessed July 16, 2025, https://wiki.linuxfoundation.org/realtime/preempt_rt_versions
22. Building a Real-time Linux Kernel in Ubuntu with PREEMPT_RT - acontis, accessed July 16, 2025, https://www.acontis.com/en/building-a-real-time-linux-kernel-in-ubuntu-preemptrt.html
23. Nvidia Jetson Linux Real-Time Kernel Build - AWS, accessed July 16, 2025, https://cdck-file-uploads-global.s3.dualstack.us-west-2.amazonaws.com/nvidia/original/4X/1/d/f/1dfff3756d404f15196bc491d20c5ba4fee54537.pdf
24. Including RT Patch, Getting the Backup Image and Transferring the Root File-System on DSBOX-N2 - Forecr.io, accessed July 16, 2025, https://www.forecr.io/blogs/bsp-development/including-rt-patch-getting-the-backup-image-and-transferring-the-root-file-system-on-dsbox-n2
25. Setting up Realtime Kernel on Jetson - Oren Bell, accessed July 16, 2025, https://orenbell.com/setting-up-realtime-kernel-on-jetson/
26. hmxf/RTJetson: Preempt-RT Kernel Build Guide for NVIDIA Development Board - GitHub, accessed July 16, 2025, https://github.com/hmxf/RTJetson
27. Real-Time Linux Kernel: Configuration and Applications - Shapehost, accessed July 16, 2025, https://shape.host/resources/real-time-linux-kernel-configuration-and-applications
28. Applying a PREEMPT-RT patch to JetPack 4.5 on Jetson Nano - NVIDIA Developer Forums, accessed July 16, 2025, https://forums.developer.nvidia.com/t/applying-a-preempt-rt-patch-to-jetpack-4-5-on-jetson-nano/168428
29. How to Compile Kernel on NVIDIA Jetson Orin NX with JetPack 5.X - RidgeRun Developer Wiki, accessed July 16, 2025, https://developer.ridgerun.com/wiki/index.php/NVIDIA_Jetson_Orin_NX/Jetpack_5.X/Kernel_Compile
30. Kernel Customization - Jetson Linux
Developer Guide 34.1 documentation, accessed July 16, 2025, https://docs.nvidia.com/jetson/archives/r35.1/DeveloperGuide/text/SD/Kernel/KernelCustomization.html
31. How to Apply Distro Upgrade (apt upgrade) on Jetson Modules? - Forecr.io, accessed July 16, 2025, https://www.forecr.io/blogs/bsp-development/how-to-apply-distro-upgrade-apt-upgrade-on-jetson-modules
32. PREEMPT_RT and regular kernel show similar latencies using ..., accessed July 16, 2025, https://forums.developer.nvidia.com/t/preempt-rt-and-regular-kernel-show-similar-latencies-using-cyclictest/273435
33. realtime:documentation:howto:tools:cyclictest:start [Wiki], accessed July 16, 2025, https://wiki.linuxfoundation.org/realtime/documentation/howto/tools/cyclictest/start
34. A Preliminary Assessment of the real-time ... - Antonio Paolillo, accessed July 16, 2025, https://antonio.paolillo.be/publications/workshops/ecrtsOspert2024_dewit_rtlinux_paper.pdf
35. Benchmarking RT Preempt Kernel 3.18 On BeagleBone Black - A Technical Odyssey, accessed July 16, 2025, https://zeuzoix.github.io/techeuphoria/posts/2015/04/21/benchmarking-rt-preempt-kernel-on-beaglebone-black/
36. Show "degrees of real-time" with Kernel Jitter Analysis - Reliable Embedded Systems, accessed July 16, 2025, https://reliableembeddedsystems.com/blog/degrees-of-real-time-release-debug-prt-evl-version-6-12-x-i-mx6-quad/
37. Your First Jetson Container | NVIDIA Developer, accessed July 16, 2025, https://developer.nvidia.com/embedded/learn/tutorials/jetson-container
38. Use These! Jetson Docker Containers Tutorial - JetsonHacks, accessed July 16, 2025, https://jetsonhacks.com/2023/09/04/use-these-jetson-docker-containers-tutorial/
39. Docker Setup on JetPack 6 - Jetson Orin - JetsonHacks, accessed July 16, 2025, https://jetsonhacks.com/2025/02/24/docker-setup-on-jetpack-6-jetson-orin/
40. Docker Setup On Jetson Orin - Includes JetPack 6 Docker fix - YouTube, accessed July 16, 2025, https://www.youtube.com/watch?v=d2I_wjJTekw
41. NVIDIA/nvidia-container-toolkit: Build and run containers leveraging NVIDIA GPUs - GitHub, accessed July 16, 2025, https://github.com/NVIDIA/nvidia-container-toolkit
42. A Beginner's Guide to NVIDIA Container Toolkit on Docker | by Umberto Junior Mele, accessed July 16, 2025, https://medium.com/@u.mele.coding/a-beginners-guide-to-nvidia-container-toolkit-on-docker-92b645f92006
43. NVIDIA Container Runtime on Jetson (Beta) - Cloud Native Products documentation, accessed July 16, 2025, https://nvidia.github.io/container-wiki/toolkit/jetson.html
44. What are the steps to get up and running with dockerized GPU containers? - Jetson AGX Orin - NVIDIA Developer Forums, accessed July 16, 2025, https://forums.developer.nvidia.com/t/what-are-the-steps-to-get-up-and-running-with-dockerized-gpu-containers/318728
45. dusty-nv/jetson-containers: Machine Learning Containers for NVIDIA Jetson and JetPack-L4T - GitHub, accessed July 16, 2025, https://github.com/dusty-nv/jetson-containers
46. Podman vs Docker: What are the differences? - Imaginary Cloud, accessed July 16, 2025, https://www.imaginarycloud.com/blog/podman-vs-docker
47. What is the runtime performance cost of a Docker container? - Stack Overflow, accessed July 16, 2025, https://stackoverflow.com/questions/21889053/what-is-the-runtime-performance-cost-of-a-docker-container
48. GPU container access - Podman Desktop, accessed July 16, 2025, https://podman-desktop.io/docs/podman/gpu
49. Launching GPU-Enabled Applications with Podman - CUDA Setup and Installation, accessed July 16, 2025, https://forums.developer.nvidia.com/t/launching-gpu-enabled-applications-with-podman/324269
50. Cannot passthrough GPU to Kubernetes pod on the Jetson AGX Orin dev kit - #3 by AastaLLL - NVIDIA Developer Forums, accessed July 16, 2025, https://forums.developer.nvidia.com/t/cannot-passthrough-gpu-to-kubernetes-pod-on-the-jetson-agx-orin-dev-kit/328539/3
51. Podman + GPU on Jetson AGX Orin - NVIDIA Developer Forums, accessed July 16, 2025, https://forums.developer.nvidia.com/t/podman-gpu-on-jetson-agx-orin/297734
52. OrbittyBox running Nvidia Toolkit - Jetson TX2 - NVIDIA Developer Forums, accessed July 16, 2025, https://forums.developer.nvidia.com/t/orbittybox-running-nvidia-toolkit/339013
53. After Reflash Jetson Orin AGX, no apparmor running/installed to enable snaps, accessed July 16, 2025, https://forums.developer.nvidia.com/t/after-reflash-jetson-orin-agx-no-apparmor-running-installed-to-enable-snaps/338771
54. AppArmor Error Orin NX - NVIDIA Developer Forums, accessed July 16, 2025, https://forums.developer.nvidia.com/t/apparmor-error-orin-nx/259493
55. firejail : arm64 : Noble (24.04) : Ubuntu - Launchpad, accessed July 16, 2025, https://launchpad.net/ubuntu/noble/arm64/firejail
56. netblue30/firejail: Linux namespaces and seccomp-bpf sandbox - GitHub, accessed July 16, 2025, https://github.com/netblue30/firejail
57. firejail (aarch64) | Packages - Arch Linux ARM, accessed July 16, 2025, https://archlinuxarm.org/packages/aarch64/firejail
58. NVIDIA Jetson Docker Not Running/Restarting - Stack Overflow, accessed July 16, 2025, https://stackoverflow.com/questions/79456309/nvidia-jetson-docker-not-running-restarting
59. Installing the NVIDIA Container Toolkit, accessed July 16, 2025, https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
60. Installing NVIDIA Container Toolkit for GPU Support 🖥️⚙️ - GitHub, accessed July 16, 2025, https://github.com/Armaggheddon/ClipServe/blob/main/docs/installing_nvidia_container_toolkit.md
61. Installing the NVIDIA Container Toolkit, accessed July 16, 2025, https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/1.14.4/install-guide.html
62. Installation - NanoLLM 24.7 documentation - GitHub Pages, accessed July 16, 2025, https://dusty-nv.github.io/NanoLLM/install.html
63. jetson-containers/docs/build.md at master - GitHub, accessed July 16, 2025, https://github.com/dusty-nv/jetson-containers/blob/master/docs/build.md
64. jetson-containers/packages/llm/mlc/README.md at master - GitHub, accessed July 16, 2025, https://github.com/dusty-nv/jetson-containers/blob/master/packages/llm/mlc/README.md
65. ros - Official Image | Docker Hub, accessed July 16, 2025, https://hub.docker.com/_/ros/
66. Devices in Docker - Articulated Robotics, accessed July 16, 2025, https://articulatedrobotics.xyz/tutorials/docker/devices-docker/
67. The Complete Beginner's Guide to Docker for ROS 2 Deployment (2025) - Robotair, accessed July 16, 2025, https://blog.robotair.io/the-complete-beginners-guide-to-using-docker-for-ros-2-deployment-2025-edition-0f259ca8b378
68. \- Stereolabs, accessed July 16, 2025, https://www.stereolabs.com/docs/docker/opencv-ros-images-for-jetson
69. sample-dockerized-ros2-node/README.md at master - GitHub, accessed July 16, 2025, https://github.com/ginomempin/sample-dockerized-ros2-node/blob/master/README.md
70. ADVRHumanoids/ros1-ros2-zed-jetson-docker - GitHub, accessed July 16, 2025, https://github.com/ADVRHumanoids/ros1-ros2-zed-jetson-docker
71. Visualising data from a docker ROS2 Humble stack on ROS2 Jazzy, accessed July 16, 2025, https://robotics.stackexchange.com/questions/115527/visualising-data-from-a-docker-ros2-humble-stack-on-ros2-jazzy
72. Containers and Realtime - is that possible? Even with Kubernetes? - Linutronix, accessed July 16, 2025, https://www.linutronix.de/blog/Containers-and-Realtime-is-that-possible-Even-with-Kubernetes
73. Do Linux Containers suffer any performance penalty compared to physical servers?, accessed July 16, 2025, https://beeksgroup.com/blog/do-linux-containers-suffer-any-performance-penalty-compared-to-physical-servers/
74. Unexpected results from Docker Benchmarking. Need your input. - Reddit, accessed July 16, 2025, https://www.reddit.com/r/docker/comments/8wls2a/unexpected_results_from_docker_benchmarking_need/
75. Podman vs. Docker: Comparing the two containerization tools | Hacker News, accessed July 16, 2025, https://news.ycombinator.com/item?id=34719137
76. Performance Analysis of Container Effect in Deep Learning Workloads and Implications, accessed July 16, 2025, https://www.mdpi.com/2076-3417/13/21/11654
77. Full control of the CPU cores possible? - Jetson Orin Nano - NVIDIA ..., accessed July 16, 2025, https://forums.developer.nvidia.com/t/full-control-of-the-cpu-cores-possible/250470
78. Assigning specific CPU cores to system processes (using cpuset systemfile) - Jetson AGX Orin - NVIDIA Developer Forums, accessed July 16, 2025, https://forums.developer.nvidia.com/t/assigning-specific-cpu-cores-to-system-processes-using-cpuset-systemfile/301996
79. How to re-enable CPU Cores after isolcpus - Jetson Xavier NX - NVIDIA Developer Forums, accessed July 16, 2025, https://forums.developer.nvidia.com/t/how-to-re-enable-cpu-cores-after-isolcpus/190965
80. Resource constraints - Docker Docs, accessed July 16, 2025, https://docs.docker.com/engine/containers/resource_constraints/
81. CpusetCpus not properly applied when Kernel isolcpus is set / Issue #31086 - GitHub, accessed July 16, 2025, https://github.com/moby/moby/issues/31086
82. ISOLCPUs results in only 1 core being used. - Docker Engine - Forums - Unraid, accessed July 16, 2025, https://forums.unraid.net/topic/54287-isolcpus-results-in-only-1-core-being-used/
83. ftrace - Function Tracer - The Linux Kernel documentation, accessed July 16, 2025, https://docs.kernel.org/trace/ftrace.html
84. Finding Origins of Latencies Using Ftrace - LWN.net, accessed July 16, 2025, https://lwn.net/images/conf/rtlws11/papers/proc/p02.pdf
85. Kernel tracing with trace-cmd - Opensource.com, accessed July 16, 2025, https://opensource.com/article/21/7/linux-kernel-trace-cmd
86. Introduction to kernel tracing using trace-cmd - devkernel.io, accessed July 16, 2025, https://devkernel.io/posts/ftrace_trace_cmd/
87. 3.9. Using the ftrace Utility for Tracing Latencies | Tuning Guide - Red Hat Documentation, accessed July 16, 2025, https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/using_the_ftrace_utility_for_tracing_latencies
88. perf-sched(1) - Linux manual page - man7.org, accessed July 16, 2025, https://man7.org/linux/man-pages/man1/perf-sched.1.html
89. 21 Docker Security Best Practices: Daemon, Image, Containers - Spacelift, accessed July 16, 2025, https://spacelift.io/blog/docker-security
90. Restricting Container Capabilities: Reducing the Kernel Attack Surface in Docker, accessed July 16, 2025, https://dev.to/hexshift/restricting-container-capabilities-reducing-the-kernel-attack-surface-in-docker-5952
91. Ensuring Security with Secure Boot and UEFI on NVidia Jetson Orin AGX - Astute Systems, accessed July 16, 2025, https://astutesys.com/2024/07/07/ensuring-security-with-secure-boot-and-uefi-on-nvidia-jetson-orin-agx/
92. Secure Boot - NVIDIA Jetson Linux Developer Guide, accessed July 16, 2025, https://docs.nvidia.com/jetson/archives/r36.4.3/DeveloperGuide/SD/Security/SecureBoot.html
93. Secure Boot - Jetson Linux Developer Guide documentation - NVIDIA Docs, accessed July 16, 2025, https://docs.nvidia.com/jetson/archives/r35.3.1/DeveloperGuide/text/SD/Security/SecureBoot.html
94. Kernel Customization - Jetson Linux Developer Guide documentation - NVIDIA Docs, accessed July 16, 2025, https://docs.nvidia.com/jetson/archives/r35.4.1/DeveloperGuide/text/SD/Kernel/KernelCustomization.html
95. How to boot Linux using UEFI with Secure Boot - GitLab, accessed July 16, 2025, https://ubs_csse.gitlab.io/secu_os/tutorials/linux_secure_boot.html
96. Secure Boot - Jetson Linux Developer Guide documentation - NVIDIA Docs, accessed July 16, 2025, https://docs.nvidia.com/jetson/archives/r35.4.1/DeveloperGuide/text/SD/Security/SecureBoot.html
97. Enable UEFI secure boot - Qualcomm, accessed July 16, 2025, https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-11/enable-uefi-secure-boot.html
98. Best practices for customizing Yocto BSP - NXP Community, accessed July 16, 2025, https://community.nxp.com/t5/i-MX-Processors/Best-practices-for-customizing-Yocto-BSP/td-p/652867
99. What I wish I'd known about Yocto Project, accessed July 16, 2025, https://docs.yoctoproject.org/3.3.2/what-i-wish-id-known.html</code></pre>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>