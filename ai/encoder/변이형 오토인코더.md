# 변이형 오토인코더
[인코더](./index.md)



생성 모델(Generative Model)은 기계 학습의 한 분야로서, 훈련 데이터의 기저에 있는 패턴과 확률 분포를 학습하여 기존 데이터와 유사하지만 완전히 새로운 데이터를 생성하는 것을 목표로 하는 모델을 총칭한다.1 이는 입력 데이터가 주어졌을 때 특정 레이블이나 값을 예측하는 판별 모델(Discriminative Model)과는 근본적으로 다른 접근 방식을 취한다.3

판별 모델은 주어진 입력 $X$에 대한 레이블 $Y$의 조건부 확률 $p(Y|X)$를 모델링하는 데 집중한다.5 예를 들어, 이미지 분류기는 고양이 사진($X$)이 주어졌을 때 '고양이'라는 레이블($Y$)이 나올 확률을 최대화하도록 학습된다. 반면, 생성 모델은 입력 데이터 $X$와 레이블 $Y$의 결합 확률 분포 $p(X, Y)$를 학습하거나, 레이블이 없는 비지도 학습 환경에서는 데이터 자체의 분포 $p(X)$를 직접 학습한다.3 이 능력 덕분에 생성 모델은 단순히 데이터를 분류하는 것을 넘어, 데이터가 '어떻게' 생성되었는지 그 과정을 이해하고, 이 이해를 바탕으로 해당 분포로부터 새로운 샘플을 '생성(generate)'할 수 있다.2

생성 모델의 핵심 목표는 훈련 데이터셋의 복잡하고 고차원적인 확률 분포를 근사하는 것이다. 일단 이 분포를 성공적으로 학습하면, 모델은 마치 훈련 데이터의 스타일과 특징을 모두 이해한 예술가처럼, 세상에 존재하지 않았던 새로운 이미지, 텍스트, 음악 등을 창조해낼 수 있다.2 이러한 능력은 데이터가 부족한 분야에서 데이터를 증강(data augmentation)하거나, 예술 및 콘텐츠 창작, 신약 개발과 같은 혁신적인 분야에서 무한한 가능성을 열어주고 있다.2


표준 오토인코더(Autoencoder, AE)는 인코더(encoder)와 디코더(decoder)라는 두 개의 신경망으로 구성된 비지도 학습 모델이다.8 인코더는 고차원의 입력 데이터를 저차원의 잠재 공간(latent space)으로 압축하고, 디코더는 이 압축된 잠재 표현(latent representation)으로부터 원본 데이터를 다시 복원하는 역할을 한다.10 AE의 주된 목적은 재구성 오차(reconstruction error)를 최소화하는 과정에서 데이터의 중요한 특징을 추출하는 것으로, 주로 데이터 압축, 노이즈 제거, 차원 축소 등에 활용된다.9

그러나 AE는 진정한 의미의 생성 모델로 기능하기에는 결정적인 한계를 지닌다. 그 한계는 바로 잠재 공간의 불규칙성(irregularity)과 비연속성에 있다. AE의 학습 목표는 오직 '재구성'에만 초점이 맞춰져 있어, 잠재 공간의 구조에 대해서는 어떠한 제약도 가하지 않는다.8 그 결과, 인코더는 각 입력 데이터를 잠재 공간 상의 특정 '점(point)' 또는 '좌표(coordinate)'로 매핑하도록 학습될 뿐, 이 점들이 잠재 공간 내에서 의미 있는 분포나 구조를 형성하도록 강제되지 않는다.10

이러한 불규칙한 잠재 공간은 생성 능력에 치명적인 약점으로 작용한다. 훈련된 AE의 잠재 공간에서, 학습된 데이터 포인트들 사이에 존재하는 '빈 공간(empty space)'에서 임의의 벡터를 샘플링하여 디코더에 입력하면, 디코더는 이전에 본 적 없는 생소한 입력을 받았기 때문에 의미 있는 출력을 만들어내지 못한다.11 대부분의 경우, 결과물은 알아볼 수 없는 노이즈나 왜곡된 형태일 뿐, 새롭고 그럴듯한 데이터라고 보기 어렵다.11 따라서 AE는 뛰어난 '재구성' 모델일 수는 있으나, 잠재 공간으로부터 새로운 데이터를 창조하는 '생성' 모델로서는 부적합하다.13


표준 오토인코더의 근본적인 한계를 극복하기 위해, 2013년 Diederik P. Kingma와 Max Welling은 변이형 오토인코더(Variational Autoencoder, VAE)를 제안하였다.15 VAE는 AE의 기본 구조를 차용하면서도, 생성 모델로서 기능하기 위해 베이즈 추론(Bayesian inference)의 원리를 접목한 심층 생성 모델이다.17

VAE의 가장 핵심적인 혁신은 잠재 공간을 다루는 방식에 있다. AE가 입력을 잠재 공간의 결정론적인(deterministic) 단일 벡터로 인코딩하는 것과 달리, VAE는 입력을 연속적인 확률 분포(probabilistic distribution)로 인코딩한다.9 구체적으로, VAE의 인코더는 입력 데이터 $x$가 주어졌을 때, 잠재 공간 상의 특정 점 $z$를 직접 출력하는 것이 아니라, 해당 점이 따를 확률 분포(일반적으로 정규분포)의 파라미터, 즉 평균($\mu$)과 분산($\sigma^2$)을 출력한다.11

이러한 확률적 인코딩 방식은 잠재 공간의 구조에 근본적인 변화를 가져온다. VAE는 손실 함수를 통해 모든 데이터 포인트의 잠재 분포가 특정 사전 분포(prior distribution, 보통 표준 정규분포)에 가깝도록 강제한다. 이 규제(regularization) 효과 덕분에 VAE의 잠재 공간은 불규칙하고 비어있는 공간 없이, 부드럽고(smooth) 연속적인(continuous) 구조를 갖게 된다.20 결과적으로 잠재 공간 내의 어떤 지점에서 샘플링을 하더라도 디코더가 이를 의미 있는 데이터로 해석하여 생성할 수 있게 된다. 이는 VAE가 AE의 데이터 압축 및 재구성 기능을 수행하면서도, 동시에 강력한 생성 능력을 갖추게 되는 근본적인 이유이다.9

이러한 전환은 단순한 구조적 개선을 넘어선 패러다임의 변화를 의미한다. AE의 목표가 '재구성 오차의 최소화'라는 비교적 단순한 문제였다면, VAE는 '데이터의 로그 가능도 최대화'라는 훨씬 더 근본적이고 어려운 문제를 풀고자 한다.12 VAE는 이 문제를 해결하기 위한 도구로 변분 추론이라는 통계적 기법을 사용하며, 오토인코더와 유사한 구조는 이 기법을 신경망으로 구현하는 과정에서 자연스럽게 나타난 형태일 뿐이다. 실제로 VAE의 수학적 기반은 희소 오토인코더나 노이즈 제거 오토인코더와 같은 고전적인 오토인코더와는 거의 관련이 없으며, 변분 베이즈 방법론에 깊이 뿌리내리고 있다.15 따라서 VAE는 '생성을 위해 개선된 AE'가 아니라, 'AE의 구조를 활용하여 확률적 생성 모델링 문제를 푸는 새로운 종류의 모델'로 이해하는 것이 더 정확하다. 이 확률적 기반 덕분에 VAE는 단순 생성을 넘어 불확실성에 대한 추론이 중요한 이상 탐지나 준지도 학습과 같은 고차원적인 문제에도 성공적으로 적용될 수 있다.



변이형 오토인코더의 인코더는 종종 '추론 네트워크(inference network)' 또는 '인식 모델(recognition model)'로 불린다.12 그 주된 역할은 관찰된 데이터 $x$로부터 눈에 보이지 않는 잠재 변수 $z$의 분포를 추론하는 것이다. 통계학적 용어로 이는 데이터 $x$가 주어졌을 때의 잠재 변수 $z$의 사후 확률(posterior probability), 즉 $p(z|x)$를 근사하는 과정에 해당한다.25 VAE는 이 실제 사후 확률을 직접 계산하기 어렵기 때문에, 이를 신경망으로 구현된 함수 $q_\phi(z|x)$를 통해 근사한다. 여기서 $\phi$는 인코더 신경망의 가중치와 편향 같은 학습 가능한 파라미터를 의미한다.26

표준 오토인코더의 인코더가 입력 $x$에 대해 잠재 공간의 단일 벡터 $z$를 출력하는 결정론적(deterministic) 함수인 것과 대조적으로, VAE의 인코더는 확률적(probabilistic)이다. 즉, 인코더는 $q_\phi(z|x)$가 특정 확률 분포를 따르도록 해당 분포의 파라미터를 출력한다. 일반적으로 이 분포는 다변량 정규분포(multivariate Gaussian distribution) $\mathcal{N}(\mu(x), \Sigma(x))$로 가정된다.24 따라서 인코더의 최종 출력은 잠재 벡터 자체가 아니라, 이 정규분포를 정의하는 평균 벡터 $\mu(x)$와 공분산 행렬 $\Sigma(x)$이다.11

실제 구현에서는 계산의 복잡성을 줄이고 효율성을 높이기 위해 몇 가지 가정이 추가된다. 가장 일반적인 가정은 잠재 변수의 각 차원이 서로 독립적이라고 보는 것이다. 이 경우 공분산 행렬 $\Sigma(x)$은 대각 성분 외에는 모두 0인 대각 행렬(diagonal matrix)이 된다. 결과적으로 인코더는 각 잠재 차원 $i$에 대한 평균 $\mu_i$와 분산 $\sigma_i^2$만을 계산하면 되므로, 최종적으로 두 개의 벡터, 즉 평균 벡터 $\mu$와 분산 벡터 $\sigma^2$을 출력하게 된다.21 더 나아가, 분산 값은 항상 양수여야 한다는 제약을 만족시키기 위해, 네트워크가 직접 분산을 출력하는 대신 분산의 로그 값($\log \sigma^2$)을 출력하도록 설계하는 것이 일반적이다. 이 로그-분산 값에 지수 함수를 취하면 항상 양수인 분산 값을 얻을 수 있기 때문이다.11


VAE의 가장 핵심적인 특징이자 표준 AE와의 근본적인 차이점은 바로 잠재 공간의 구조에 있다. 표준 AE의 잠재 공간은 학습 데이터 포인트들이 흩어져 있는 불규칙한 공간으로, 데이터가 존재하지 않는 '구멍'이 많아 생성 모델로 활용하기 어렵다.12 반면, VAE는 잠재 공간이 매우 잘 조직된, 즉 연속적이고(continuous), 부드러우며(smooth), 밀집된(dense) 구조를 갖도록 학습 과정에서 명시적으로 강제한다.20

이러한 구조화는 VAE의 손실 함수에 포함된 규제 항, 즉 쿨백-라이블러 발산(Kullback-Leibler Divergence, KL Divergence)에 의해 달성된다. KL 발산은 두 확률 분포 사이의 차이를 측정하는 지표로, VAE에서는 인코더가 출력하는 각 데이터 포인트의 잠재 분포 $q_\phi(z|x)$와 우리가 사전에 정의한 간단한 사전 분포(prior distribution) $p(z)$ 사이의 거리를 측정한다.8 이 사전 분포 $p(z)$는 보통 평균이 0이고 공분산이 단위 행렬인 표준 정규분포 $\mathcal{N}(0, I)$로 설정된다.20

훈련 과정에서 VAE는 이 KL 발산 값을 최소화하도록 학습된다. 이는 인코더가 생성하는 모든 잠재 분포 $q_\phi(z|x)$를 원점 중심의 표준 정규분포 $p(z)$에 가깝게 만들도록 강제하는 강력한 규제로 작용한다. 이 규제 덕분에 두 가지 중요한 효과가 발생한다. 첫째, 비슷한 입력 데이터들은 잠재 공간에서 서로 가까운 위치에 있는 유사한 분포로 인코딩된다. 둘째, 잠재 공간 전체가 데이터 포인트들의 분포로 조밀하게 채워져 '빈 공간'이 거의 사라진다.

이렇게 잘 구조화된 잠재 공간은 '보간(interpolation)'을 의미 있게 만든다. 예를 들어, 잠재 공간에서 숫자 '1'에 해당하는 점과 숫자 '7'에 해당하는 점을 찾은 뒤, 두 점을 잇는 직선 상의 중간 지점들을 샘플링하여 디코더에 넣으면, '1'이 점차 '7'로 변해가는 자연스러운 중간 형태의 이미지들을 생성할 수 있다. 더 나아가, 안경을 쓴 사람의 이미지에서 추출한 잠재 벡터에서 '안경'이라는 속성에 해당하는 잠재 벡터를 빼면, 안경을 벗은 얼굴 이미지를 생성하는 것과 같은 의미론적 벡터 연산(semantic arithmetic)도 가능해진다.28 이는 VAE가 데이터의 단순한 픽셀 패턴을 넘어, 데이터의 기저에 있는 추상적인 생성 요인들을 학습하고 있음을 시사한다.


VAE의 디코더는 '생성 네트워크(generative network)'로 불리며, 인코더와는 반대의 역할을 수행한다.12 즉, 저차원의 잠재 공간에 있는 한 점 $z$를 입력으로 받아, 이를 고차원의 원본 데이터 공간으로 다시 매핑하는 것이다. 구체적으로 디코더는 잠재 변수 $z$가 주어졌을 때의 데이터 $x$의 조건부 확률 분포 $p_\theta(x|z)$를 모델링한다. 여기서 $\theta$는 디코더 신경망의 학습 가능한 파라미터를 나타낸다.25

훈련 단계에서 VAE의 전체 과정은 다음과 같다. 먼저 입력 데이터 $x$가 인코더를 통과하여 잠재 분포 $q_\phi(z|x)$의 파라미터($\mu, \sigma^2$)를 얻는다. 그 다음, 이 분포로부터 잠재 벡터 $z$를 샘플링한다. 마지막으로, 이 샘플링된 $z$가 디코더에 입력되어 원본 입력 $x$와 최대한 유사한 출력 $\hat{x}$를 생성하도록 학습된다.22 이 과정에서 디코더는 잠재 공간의 각 점들이 어떤 데이터에 해당하는지를 학습하게 된다.

VAE가 완전히 훈련되고 나면, 우리는 새로운 데이터를 생성하기 위해 디코더만을 독립적으로 사용할 수 있다. 이 때 인코더는 더 이상 필요하지 않다.9 생성 과정은 매우 간단하다. 먼저 잠재 공간의 사전 분포 $p(z)$(즉, $\mathcal{N}(0, I)$)에서 임의의 벡터 $z_{new}$를 샘플링한다. 그리고 이 $z_{new}$를 훈련된 디코더에 입력한다. 그러면 디코더는 이 잠재 벡터를 해석하여, 훈련 데이터에서는 본 적이 없지만 통계적 특성이 유사한 새롭고 그럴듯한 데이터 $\hat{x}_{new}$를 생성해낸다.14 이 과정이 VAE를 강력한 생성 모델로 만드는 핵심 원리이다.

다음 표는 표준 오토인코더와 변이형 오토인코더의 핵심적인 차이점을 요약하여 보여준다. 이 비교를 통해 두 모델의 구조적 유사성에도 불구하고 그 철학과 목적이 근본적으로 어떻게 다른지 명확히 이해할 수 있다.

**Table 1: 표준 오토인코더(AE)와 변이형 오토인코더(VAE) 비교**

| 특징 (Feature)       | 표준 오토인코더 (Standard Autoencoder, AE)                   | 변이형 오토인코더 (Variational Autoencoder, VAE)             |
| -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **주요 목적**        | 데이터 압축, 특징 추출, 노이즈 제거 8                        | 새로운 데이터 생성, 데이터 분포 학습 8                       |
| **인코더 출력**      | 잠재 공간의 단일 벡터 (결정론적) 9                           | 잠재 분포의 파라미터 (평균 $\mu$, 분산 $\sigma^2$) (확률적) 20 |
| **잠재 공간**        | 불규칙하고 비연속적일 수 있음. 구조에 대한 제약 없음 8       | 연속적이고 부드러운 분포를 따르도록 규제됨 (보통 정규분포) 20 |
| **손실 함수**        | 재구성 손실 (Reconstruction Loss) (e.g., MSE) 10             | 재구성 손실 + KL 발산 (ELBO 최대화) 8                        |
| **데이터 생성 능력** | 약함. 잠재 공간의 임의 샘플링이 의미 있는 출력을 보장하지 않음 11 | 강함. 잠재 공간의 사전 분포에서 샘플링하여 새로운 데이터 생성 가능 9 |
| **이론적 기반**      | 표현 학습, 차원 축소 13                                      | 변분 추론, 확률적 그래픽 모델 15                             |



모든 확률적 생성 모델의 근본적인 목표는 훈련 데이터가 나타날 확률, 즉 데이터의 증거(evidence) 또는 가능도(likelihood) $p(x)$를 최대화하는 것이다. 잠재 변수 $z$를 사용하는 모델에서 이 가능도는 잠재 변수에 대한 주변화(marginalization)를 통해 계산된다.24
$$
p(x) = \int p(x, z) dz = \int p(x|z)p(z)dz
$$
여기서 $p(z)$는 잠재 변수의 사전 분포(prior distribution)이고, $p(x|z)$는 잠재 변수 $z$가 주어졌을 때 데이터 $x$가 생성될 조건부 확률, 즉 디코더에 해당한다. 이 적분은 잠재 공간 전체에 대해 수행되어야 한다. 잠재 변수 $z$의 차원이 조금만 높아져도 이 적분은 해석적으로 풀 수 없으며, 수치적으로 계산하는 것 또한 거의 불가능하다. 이러한 문제를 '다루기 힘들다(intractable)'고 표현한다.17

이 문제와 직결된 또 다른 난관은 잠재 변수의 사후 확률(posterior probability) $p(z|x)$를 계산하는 것이다. 베이즈 정리(Bayes' rule)에 따르면 사후 확률은 다음과 같이 표현된다.17
$$
p(z|x) = \frac{p(x|z)p(z)}{p(x)}
$$
분모에 intractable한 $p(x)$가 포함되어 있기 때문에, 사후 확률 $p(z|x)$ 역시 직접 계산하는 것이 불가능하다. 사후 확률은 주어진 데이터 $x$를 가장 잘 설명하는 잠재 변수 $z$가 무엇인지에 대한 정보를 담고 있으므로, 이를 계산할 수 없다는 것은 모델 학습에 있어 심각한 장애물이다. VAE는 이 두 가지 intractability 문제를 해결하기 위해 변분 추론이라는 강력한 근사 기법을 도입한다.


변분 추론(Variational Inference)은 다루기 힘든 실제 사후 확률 분포 $p(z|x)$를, 다루기 쉬운 간단한 확률 분포 $q_\phi(z|x)$(예: 정규분포)로 근사하는 방법론이다.15 여기서 $q_\phi(z|x)$는 인코더 네트워크에 해당하며, $\phi$는 인코더의 파라미터이다. 변분 추론의 목표는 근사 분포 $q_\phi(z|x)$를 실제 사후 분포 $p(z|x)$와 최대한 유사하게 만드는 것이다. 두 분포 사이의 유사성은 쿨백-라이블러 발산(Kullback-Leibler Divergence)으로 측정하며, 따라서 우리의 목표는 이 KL 발산을 최소화하는 것이다.30
$$
\min_\phi D_{KL}(q_\phi(z|x) \parallel p(z|x))
$$
KL 발산의 정의($D_{KL}(q \parallel p) = \mathbb{E}_{z \sim q}[\log q(z) - \log p(z)]$)를 이용하여 위 식을 전개하면, 데이터의 로그 가능도 $\log p(x)$에 대한 매우 중요한 관계식을 유도할 수 있다.24
$$
\begin{align*}
D_{KL}(q_\phi(z|x) \parallel p(z|x)) &= \mathbb{E}_{z \sim q_\phi(z|x)}[\log q_\phi(z|x) - \log p(z|x)] \\
&= \mathbb{E}_{z \sim q_\phi(z|x)}[\log q_\phi(z|x) - \log \frac{p(x|z)p(z)}{p(x)}] \\
&= \mathbb{E}_{z \sim q_\phi(z|x)}[\log q_\phi(z|x) - \log p(x|z) - \log p(z) + \log p(x)] \\
&= \mathbb{E}_{z \sim q_\phi(z|x)}[\log q_\phi(z|x) - \log p(z)] - \mathbb{E}_{z \sim q_\phi(z|x)}[\log p(x|z)] + \log p(x) \\
&= D_{KL}(q_\phi(z|x) \parallel p(z)) - \mathbb{E}_{z \sim q_\phi(z|x)}[\log p(x|z)] + \log p(x)
\end{align*}
$$
이 식을 $\log p(x)$에 대해 정리하면 다음과 같다.
$$
\log p(x) = D_{KL}(q_\phi(z|x) \parallel p(z|x)) - D_{KL}(q_\phi(z|x) \parallel p(z)) + \mathbb{E}_{z \sim q_\phi(z|x)}[\log p_\theta(x|z)]
$$
여기서 마지막 두 항을 묶어 $\mathcal{L}(\phi, \theta; x)$라고 정의하면,
$$
\log p(x) = D_{KL}(q_\phi(z|x) \parallel p(z|x)) + \mathcal{L}(\phi, \theta; x)
$$
이때 $\mathcal{L}(\phi, \theta; x)$를 **증거 하한(Evidence Lower Bound, ELBO)** 이라고 부른다. KL 발산 값은 항상 0보다 크거나 같으므로($D_{KL} \ge 0$), $\log p(x) \ge \mathcal{L}(\phi, \theta; x)$ 라는 부등식이 항상 성립한다.30 즉, ELBO는 우리가 최대화하고자 하는 로그 가능도 $\log p(x)$의 하한선(lower bound)이 된다. 위 식에서 $\log p(x)$는 주어진 데이터에 대해 상수이므로, ELBO($\mathcal{L}$)를 최대화하는 것은 다루기 힘든 KL 발산 $D_{KL}(q_\phi(z|x) \parallel p(z|x))$을 최소화하는 것과 동일한 효과를 가진다. 따라서 VAE는 직접 최적화하기 어려운 $\log p(x)$를 최대화하는 대신, 다루기 쉬운 대리 목표(surrogate objective)인 ELBO를 최대화하는 방향으로 학습을 진행한다.26

ELBO는 다음과 같이 두 가지 의미 있는 항으로 분해될 수 있다.8
$$
\mathcal{L}(\phi, \theta; x) = \underbrace{\mathbb{E}_{z \sim q_\phi(z|x)}[\log p_\theta(x|z)]}_{\text{Reconstruction Term}} - \underbrace{D_{KL}(q_\phi(z|x) \parallel p(z))}_{\text{Regularization Term}}
$$

1. **재구성 항 (Reconstruction Term):** 첫 번째 항 $\mathbb{E}_{z \sim q_\phi(z|x)}[\log p_\theta(x|z)]$는 인코더가 만든 잠재 분포 $q_\phi(z|x)$에서 샘플링한 잠재 변수 $z$를 디코더 $p_\theta(x|z)$에 입력했을 때, 원본 데이터 $x$가 나타날 로그 확률의 기댓값이다. 이는 디코더가 원본 입력을 얼마나 잘 복원하는지를 측정하는 항으로, 이 값을 최대화하는 것은 재구성 오차를 최소화하는 것과 같다. 이 때문에 '재구성 손실(reconstruction loss)'의 음수 값으로 해석되기도 한다.20
2. **규제 항 (Regularization Term):** 두 번째 항 $- D_{KL}(q_\phi(z|x) \parallel p(z))$는 인코더가 만든 근사 사후 분포 $q_\phi(z|x)$가 사전 분포 $p(z)$(보통 표준 정규분포 $\mathcal{N}(0, I)$)와 얼마나 다른지를 측정하는 KL 발산에 음수를 취한 것이다. ELBO를 최대화하려면 이 KL 발산 값을 최소화해야 한다. 이는 인코더가 출력하는 잠재 분포가 사전 분포의 형태를 따르도록 강제하는 규제 역할을 하여, 잠재 공간이 부드럽고 잘 구조화되도록 만든다.20

결국 VAE의 학습은 이 두 항 사이의 균형을 찾는 과정이다. 재구성 항은 모델이 데이터의 세부 사항을 잘 포착하도록(data fidelity) 유도하고, 규제 항은 모델이 과적합되는 것을 방지하고 잠재 공간의 일반화 성능을 높이도록(model regularity) 유도한다. 이 두 가지 상충하는 목표 사이의 절묘한 균형이 VAE의 강력한 생성 능력의 원천이 된다.


VAE의 목적 함수인 ELBO를 경사 하강법으로 최적화하기 위해서는 목적 함수를 모델 파라미터($\phi, \theta$)에 대해 미분할 수 있어야 한다. 그러나 ELBO의 재구성 항 $\mathbb{E}_{z \sim q_\phi(z|x)}[\log p_\theta(x|z)]$에는 심각한 문제가 있다. 바로 기댓값을 계산하기 위한 샘플링 과정 $z \sim q_\phi(z|x)$ 때문이다. 샘플링은 본질적으로 확률적인 연산으로, 특정 지점에서 미분 계수를 정의할 수 없는 미분 불가능(non-differentiable)한 과정이다.33 이로 인해 디코더에서 계산된 손실의 그래디언트가 샘플링 노드를 거슬러 올라가 인코더의 파라미터 

$\phi$까지 전달될 수 없다. 즉, 역전파(backpropagation)가 불가능하다.24

이 문제를 해결하기 위해 VAE는 **재매개변수화 기법(reparameterization trick)** 이라는 독창적인 방법을 사용한다.33 이 기법의 핵심 아이디어는 확률 변수 $z$의 샘플링 과정을 두 부분으로 분리하는 것이다: (1) 모델 파라미터와 무관한 고정된 분포에서 노이즈를 샘플링하는 확률적 부분과, (2) 이 노이즈를 모델 파라미터를 이용해 변환하는 결정론적 부분.35

예를 들어, 우리가 $z$를 평균이 $\mu$이고 표준편차가 $\sigma$인 정규분포 $\mathcal{N}(\mu, \sigma^2)$에서 샘플링하고자 할 때, 재매개변수화 기법은 다음과 같이 $z$를 계산한다.

1. 먼저, 파라미터와 무관한 표준 정규분포에서 노이즈 변수 $\epsilon$을 샘플링한다: $\epsilon \sim \mathcal{N}(0, I)$.
2. 그 다음, 이 $\epsilon$을 인코더가 출력한 $\mu$와 $\sigma$를 이용해 결정론적인 함수로 변환한다: $z = \mu + \sigma \cdot \epsilon$.11

이 두 과정은 수학적으로 $z \sim \mathcal{N}(\mu, \sigma^2)$에서 직접 샘플링하는 것과 동일한 결과를 낳는다. 하지만 결정적인 차이가 있다. 이제 확률적인 샘플링 과정은 모델의 계산 그래프 외부에서 입력으로 주어지는 $\epsilon$으로 분리되었고, 잠재 변수 $z$는 파라미터 $\mu$와 $\sigma$에 대해 미분 가능한 결정론적 함수가 되었다. 따라서 디코더에서 계산된 손실의 그래디언트는 이제 $z$를 거쳐 $\mu$와 $\sigma$로, 그리고 최종적으로 인코더의 파라미터 $\phi$까지 아무런 문제 없이 역전파될 수 있다.24

이처럼 재매개변수화 기법은 VAE의 이론적 토대인 변분 추론을 현대 딥러닝의 강력한 최적화 도구인 경사 하강법 및 역전파와 결합시켜주는 결정적인 다리 역할을 한다. 이 기법이 없었다면 VAE를 종단간(end-to-end) 방식으로 효율적으로 훈련하는 것은 불가능했을 것이다. VAE의 성공은 변분 추론이라는 우아한 이론적 프레임워크와 재매개변수화 기법이라는 실용적인 공학적 해결책의 완벽한 결합에 기인한다고 할 수 있다.



변이형 오토인코더는 강력한 생성 모델이지만, 특히 생성적 적대 신경망(GAN)과 비교했을 때 생성된 이미지가 종종 흐릿하거나(blurry) 뭉개져 보이는(smudged) 경향이 있다는 한계점을 지닌다.28 이러한 현상은 단일 원인이 아닌, VAE의 구조와 학습 방식에 내재된 여러 요인이 복합적으로 작용한 결과이다.

첫 번째 주요 원인은 **픽셀 단위 손실 함수(pixel-wise loss function)**의 사용이다. VAE의 재구성 항은 일반적으로 각 픽셀의 차이를 측정하는 평균 제곱 오차(Mean Squared Error, MSE)나 이진 교차 엔트로피(Binary Cross-Entropy, BCE)를 손실 함수로 사용한다.10 이러한 손실 함수는 이미지의 전체적인 구조, 텍스처, 또는 인간의 시각적 인식과 관련된 지각적 품질(perceptual quality)을 고려하지 않는다. 대신, 픽셀 값의 평균적인 차이를 최소화하는 데에만 집중한다. 예를 들어, 실제 이미지가 여러 가능한 형태(mode)를 가질 때(가령, 약간씩 다르게 쓰인 손글씨 숫자 '7'), MSE를 최소화하는 가장 쉬운 방법은 이 모든 형태들의 '평균'에 해당하는 이미지를 생성하는 것이다. 이미지 공간에서 평균을 취하는 연산은 일반적으로 날카로운 경계나 세밀한 디테일을 뭉개는 효과를 낳기 때문에, 결과적으로 흐릿한 이미지가 생성된다.38

두 번째 원인은 **잠재 공간의 연속성과 정규분포 가정**에 있다. VAE는 KL 발산 규제를 통해 잠재 공간이 연속적인 정규분포를 따르도록 강제한다. 이는 데이터 생성의 다양성과 안정성을 확보하는 데에는 유리하지만, 디코더가 이 연속적인 공간의 평균적인 특성을 학습하게 만든다.40 즉, 디코더는 잠재 공간의 특정 지점 하나하나에 대해 매우 날카로운 이미지를 생성하기보다는, 넓은 영역에 걸쳐 전반적으로 그럴듯한(plausible) 이미지를 생성하는 '안전한' 전략을 택하게 된다. 이는 모델이 데이터 분포 전체를 부드럽게 덮으려는 시도가 오히려 개별 샘플의 선명도를 희생시키는 결과로 이어진다.41

세 번째 원인은 **정보 병목 현상(information bottleneck)**이다. VAE의 인코더는 고차원의 원본 이미지 데이터를 저차원의 잠재 공간으로 압축한다. 이 과정에서 필연적으로 정보의 손실이 발생한다. 특히, 이미지의 미세한 텍스처나 작은 글씨와 같은 고주파(high-frequency) 성분의 정보는 압축 과정에서 쉽게 사라지는 경향이 있다.41 디코더는 이 정보가 부족한 잠재 벡터로부터 이미지를 복원해야 하므로, 저주파(low-frequency) 성분의 전반적인 구조 위주로 복원하게 되고, 이는 결과적으로 흐릿한 이미지로 나타난다.37 잠재 공간의 차원을 늘리면 재구성 품질이 향상될 수는 있지만, 이는 모델의 복잡도를 높이고 과적합의 위험을 증가시킬 수 있다.10


후방 붕괴(Posterior Collapse)는 VAE, 특히 텍스트나 시계열 데이터와 같이 순차적인 정보를 다루는 모델에서 자주 발생하는 심각한 학습 실패 현상이다.43 이 현상은 인코더가 출력하는 근사 사후 분포 $q_\phi(z|x)$가 입력 데이터 $x$와 무관하게 사전 분포 $p(z)$와 거의 동일해져 버리는 것을 의미한다.45

후방 붕괴가 발생하면, VAE의 손실 함수 중 KL 발산 항 $D_{KL}(q_\phi(z|x) \parallel p(z))$은 0에 가깝게 수렴하여 최적화된 것처럼 보이지만, 실제로는 모델이 잠재 변수를 전혀 활용하지 못하는 상태에 빠진 것이다.47 잠재 변수 $z$가 입력 $x$에 대한 어떤 정보도 담지 못하기 때문에, 디코더는 $z$를 완전히 무시하고 오직 이전에 생성된 출력에만 의존하여 다음 출력을 예측하게 된다. 결과적으로 모델은 잠재 공간의 의미 있는 표현을 학습하지 못하고, 단순한 언어 모델처럼 작동하게 된다.43

이 문제의 주된 원인은 **강력한 자기회귀(autoregressive) 디코더**의 사용에 있다. LSTM이나 Transformer와 같은 자기회귀 모델은 이전 타임스텝의 출력을 다음 타임스텝의 입력으로 사용하여 순차적인 데이터를 매우 효과적으로 모델링할 수 있다. 만약 디코더의 성능이 너무 강력하여 잠재 변수 $z$의 도움 없이도 훈련 데이터를 거의 완벽하게 재구성할 수 있다면, 모델은 굳이 $x$에 대한 정보를 $z$에 인코딩하려는 노력을 할 필요가 없어진다. 대신, 최적화 과정에서 더 다루기 쉬운 KL 발산 항을 0으로 만드는, 즉 $q_\phi(z|x)$를 $p(z)$로 수렴시키는 '쉬운 길'을 택하게 된다.44

후방 붕괴 문제를 완화하기 위해 여러 가지 기법들이 제안되었다. 대표적인 방법으로는 **KL 비용 어닐링(KL cost annealing)**이 있다. 이 방법은 훈련 초반에는 KL 발산 항의 가중치를 0에 가깝게 두어 모델이 재구성에 집중하게 하고, 훈련이 진행됨에 따라 가중치를 점진적으로 1까지 증가시켜 잠재 변수를 활용하도록 유도하는 기법이다.49 또 다른 방법으로는 **단어 드롭아웃(word dropout)**이 있다. 이는 자기회귀 디코더의 입력으로 들어가는 이전 타임스텝의 정답 단어를 일정 확률로 제거하여, 디코더가 부족한 정보를 채우기 위해 잠재 변수 $z$에 더 의존하도록 강제하는 방식이다.49 이 외에도 디코더의 구조를 약화시키거나, 손실 함수를 변형하는 등의 다양한 연구가 진행되고 있다.


VAE와 함께 현대 생성 모델의 양대 산맥을 이루는 생성적 적대 신경망(Generative Adversarial Network, GAN)과의 비교는 VAE의 특징과 한계를 더욱 명확하게 이해하는 데 도움을 준다.50 두 모델은 새로운 데이터를 생성한다는 공통된 목표를 가지지만, 그 철학과 접근 방식은 극명하게 대조된다.

VAE가 확률 분포를 명시적으로 모델링하고 최대 가능도 추정(maximum likelihood estimation)을 통해 학습하는 추론 기반(inference-based) 모델이라면, GAN은 생성자(generator)와 판별자(discriminator)라는 두 네트워크가 서로 경쟁하는 게임 이론 기반(game-theoretic)의 모델이다.51 생성자는 실제 데이터와 유사한 가짜 데이터를 만들고, 판별자는 주어진 데이터가 실제인지 가짜인지를 구별하도록 학습한다. 이 둘의 적대적 경쟁을 통해 생성자는 점차 실제와 구분하기 어려운 고품질의 데이터를 생성하게 된다.51

이러한 근본적인 차이는 두 모델의 장단점으로 이어진다. VAE는 학습 과정이 안정적이고, 데이터의 전체적인 분포를 학습하므로 생성된 샘플의 다양성이 높다. 또한, 잘 구조화된 잠재 공간을 가지고 있어 의미론적 보간이나 특징 조작이 용이하다.28 하지만 앞서 언급했듯이 생성된 이미지가 흐릿하다는 단점이 있다. 반면, GAN은 판별자라는 '심판'이 지각적 현실성(perceptual realism)을 기준으로 생성자를 훈련시키기 때문에 매우 선명하고 사실적인 이미지를 생성할 수 있다.36 그러나 생성자와 판별자 사이의 균형을 맞추기가 매우 어려워 훈련이 불안정하며, 생성자가 판별자를 속이기 쉬운 몇 가지 데이터 형태만 반복적으로 생성하는 '모드 붕괴(mode collapse)' 현상이 발생하기 쉽다.40

이러한 특성은 두 모델이 서로 다른 방식으로 '어려움 보존의 법칙'을 따르고 있음을 시사한다. 즉, 생성 모델링이라는 근본적으로 어려운 문제를 푸는 데 있어 쉬운 길은 없다는 것이다. VAE는 명시적인 확률 모델링을 통해 학습의 안정성과 다양성을 얻는 대신, 픽셀 단위 손실 함수의 한계로 인해 생성물의 선명도를 희생한다. GAN은 적대적 학습을 통해 선명도를 얻는 대신, 학습의 안정성과 생성물의 다양성을 희생한다. 이처럼 두 모델의 장단점은 독립적인 버그가 아니라, 각자의 기본 철학에서 비롯된 필연적인 결과이다. 이 본질적인 트레이드오프 관계를 이해하는 것은 두 모델을 적재적소에 활용하고, 나아가 두 모델의 장점을 결합하려는 VAE-GAN 28이나 확산 모델(Diffusion Models) 40과 같은 차세대 생성 모델의 등장 배경을 이해하는 데 매우 중요하다.

**Table 2: 변이형 오토인코더(VAE)와 생성적 적대 신경망(GAN) 비교**

| 특징 (Feature)       | 변이형 오토인코더 (Variational Autoencoder, VAE) | 생성적 적대 신경망 (Generative Adversarial Network, GAN)     |
| -------------------- | ------------------------------------------------ | ------------------------------------------------------------ |
| **아키텍처**         | 인코더(Encoder)와 디코더(Decoder) 51             | 생성자(Generator)와 판별자(Discriminator) 51                 |
| **학습 목표**        | 증거 하한(ELBO) 최대화 (확률적 재구성) 51        | Minimax 게임: 생성자는 판별자를 속이고, 판별자는 진짜와 가짜를 구별 (적대적 학습) 51 |
| **손실 함수**        | 재구성 손실 + KL 발산 52                         | 생성자 손실 + 판별자 손실 (보통 Binary Cross-Entropy) 52     |
| **생성 이미지 품질** | 흐릿하지만 다양성이 높음 (Blurry but diverse) 36 | 선명하지만 다양성이 낮을 수 있음 (Sharp but prone to mode collapse) 36 |
| **학습 안정성**      | 상대적으로 안정적이고 수렴이 쉬움 52             | 불안정하고, 훈련이 어려움. 모드 붕괴(Mode Collapse) 문제 발생 가능 40 |
| **잠재 공간**        | 잘 구조화되어 보간, 특징 조작에 용이함 28        | 명시적인 인코더가 없어 구조화되어 있지 않음. 잠재 공간 탐색이 어려움 39 |
| **평가**             | 로그 가능도(Log-likelihood)로 평가 가능          | 평가가 어려움. 주로 시각적 품질이나 FID 같은 간접적 지표 사용 53 |


VAE의 기본 프레임워크는 그 유연성과 이론적 명확성 덕분에 다양한 방향으로 확장되어 왔다. 이러한 확장 모델들은 VAE의 고유한 한계를 극복하거나 특정 목적에 맞게 기능을 강화하는 것을 목표로 한다. VAE의 진화는 VAE 프레임워크의 각 구성 요소(입력, 손실 함수, 잠재 공간 구조)를 체계적으로 수정하여 이루어졌다. 이는 VAE가 모듈식 설계를 가지고 있어 특정 문제를 해결하기 위한 '외과적 수술'과 같은 정밀한 개선이 가능함을 보여준다.


기본적인 VAE는 비조건부(unconditional) 생성 모델로, 어떤 데이터가 생성될지 사용자가 제어할 수 없다. **조건부 VAE(Conditional VAE, CVAE)**는 이러한 한계를 극복하기 위해 제안된 모델이다.54 CVAE는 생성 과정에 조건(condition) 변수 $c$를 추가하여 사용자가 원하는 특성을 가진 데이터를 생성할 수 있도록 한다. 이 조건 변수는 클래스 레이블, 텍스트 설명, 또는 다른 이미지 등 다양한 형태의 정보가 될 수 있다.54

CVAE의 구조는 기본 VAE와 유사하지만, 조건 변수 $c$가 인코더와 디코더 양쪽에 추가적인 입력으로 제공된다는 점이 다르다. 인코더는 입력 데이터 $x$와 조건 $c$를 함께 받아 조건부 잠재 분포 $q_\phi(z|x, c)$를 학습하고, 디코더는 잠재 변수 $z$와 조건 $c$를 함께 받아 조건부 데이터 분포 $p_\theta(x|z, c)$를 학습한다.56

이러한 구조 덕분에 CVAE는 목표 지향적인(targeted) 생성이 가능해진다. 예를 들어, MNIST 손글씨 데이터셋을 학습할 때 각 숫자의 레이블을 조건으로 부여하면, 사용자는 '숫자 7을 생성하라'는 명령을 통해 명확하게 숫자 7 이미지만을 생성할 수 있다.58 또한, 이미지 캡션을 조건으로 주어 특정 설명에 부합하는 이미지를 생성하거나, 스케치 이미지를 조건으로 주어 사실적인 채색 이미지로 변환하는 등의 복잡한 이미지 대 이미지 변환(image-to-image translation) 작업도 수행할 수 있다.55 이처럼 CVAE는 VAE의 생성 능력에 '제어'라는 중요한 차원을 더한 모델이다.


VAE의 잠재 공간은 연속적이고 부드럽지만, 각 잠재 차원이 데이터의 어떤 의미론적 특징(semantic feature)에 해당하는지는 명확하지 않다. 예를 들어, 얼굴 이미지를 학습했을 때 잠재 변수의 첫 번째 차원이 '미소의 정도'를, 두 번째 차원이 '머리카락의 길이'를 나타내도록 학습된다는 보장이 없다. 이러한 표현을 '얽힌(entangled)' 표현이라고 한다.

**β-VAE**는 잠재 공간에서 데이터의 생성 요인(generative factors)을 서로 독립적인 차원으로 분리하여 학습하는, 즉 **분리된 표현(disentangled representation)** 학습을 목표로 하는 모델이다.60 이를 위해 β-VAE는 VAE의 ELBO 목적 함수를 다음과 같이 수정한다.61
$$
\mathcal{L} = \mathbb{E}_{z \sim q_\phi(z|x)}[\log p_\theta(x|z)] - \beta D_{KL}(q_\phi(z|x) \parallel p(z))
$$
기존 VAE의 목적 함수에서 KL 발산 항에 하이퍼파라미터 $\beta$가 곱해진 형태이다. 여기서 $\beta=1$이면 원래의 VAE와 동일하다. 만약 $\beta > 1$로 설정하면, 모델은 KL 발산 항을 최소화하는 데 더 큰 가중치를 두게 된다. 이는 인코더가 출력하는 잠재 분포 $q_\phi(z|x)$를 사전 분포 $p(z)$(독립적인 다변량 정규분포)에 더욱 강력하게 맞추도록 강제하는 효과를 낳는다. 이 강력한 규제가 잠재 변수들이 서로 통계적으로 독립적인 방향으로 학습되도록 유도하여, 각 차원이 데이터의 독립적인 생성 요인(예: 색상, 크기, 회전 등)을 포착하게 만든다.60

그러나 이러한 분리된 표현 학습에는 대가가 따른다. $\beta$ 값을 높여 잠재 공간에 대한 규제를 강화할수록, 잠재 변수가 담을 수 있는 정보의 양은 줄어든다(정보 병목 현상 심화). 이로 인해 디코더가 원본 이미지를 재구성하는 데 필요한 세부 정보를 잃게 되어, 재구성 품질이 저하되는 트레이드오프(trade-off) 관계가 존재한다.62 따라서 실제 적용 시에는 분리 성능과 재구성 품질 사이의 적절한 균형점을 찾는 것이 중요하다.


VAE의 고질적인 문제인 흐릿한 이미지 생성을 해결하기 위한 혁신적인 접근법 중 하나가 **벡터 양자화 VAE(Vector Quantized VAE, VQ-VAE)**이다.63 VQ-VAE의 핵심 아이디어는 VAE의 연속적인(continuous) 잠재 공간을 이산적인(discrete) 잠재 공간으로 대체하는 것이다.64

VQ-VAE의 인코더는 일반적인 CNN 구조를 통해 입력 이미지 $x$로부터 연속적인 특징 맵 $z_e(x)$를 출력한다. 그 다음, VQ-VAE의 핵심인 **벡터 양자화(Vector Quantization)** 단계가 수행된다. 이 단계에서는 미리 정의된 학습 가능한 임베딩 벡터 집합, 즉 **코드북(codebook)** $E = \{e_1, e_2,..., e_K\}$을 사용한다. 인코더 출력 $z_e(x)$의 각 벡터는 코드북에 있는 모든 임베딩 벡터 $e_k$와의 거리를 계산하여, 가장 가까운 임베딩 벡터로 대체(양자화)된다.65 이 양자화된 벡터들의 집합 $z_q(x)$가 최종적으로 디코더의 입력으로 사용된다.67

이 과정에는 '가장 가까운 벡터 찾기'라는 미분 불가능한 연산(argmin)이 포함되어 있어, 일반적인 역전파 방식으로는 인코더를 학습시킬 수 없다. VQ-VAE는 이 문제를 해결하기 위해 **Straight-Through Estimator**라는 기법을 사용한다. 이는 순전파 시에는 양자화를 수행하지만, 역전파 시에는 양자화 과정을 건너뛰고 디코더로부터 온 그래디언트를 양자화된 벡터 $z_q(x)$에서 인코더의 출력 $z_e(x)$로 그대로 복사하는 방식이다.67

VQ-VAE의 손실 함수는 세 가지 항으로 구성된다.64

1. **재구성 손실(Reconstruction Loss):** 디코더가 양자화된 잠재 벡터로부터 원본 이미지를 얼마나 잘 복원하는지를 측정한다.
2. **코드북 손실(Codebook Loss):** 코드북의 임베딩 벡터 $e_k$들이 인코더의 출력 $z_e(x)$에 가까워지도록 업데이트한다. 이는 코드북이 데이터의 유용한 특징들을 학습하도록 한다.
3. **전념 손실(Commitment Loss):** 인코더의 출력 $z_e(x)$가 선택된 코드북 벡터에 '전념(commit)'하도록, 즉 너무 멀리 벗어나지 않도록 규제한다. 이는 인코더와 코드북의 학습 속도를 조절하고 안정성을 높인다.

이산적인 잠재 표현을 사용함으로써 VQ-VAE는 연속적인 공간에서 발생하는 평균화 효과를 근본적으로 방지하고, GAN에 필적할 만큼 선명하고 고품질의 이미지를 생성할 수 있다.28 또한, KL 발산 항이 없어 후방 붕괴 문제로부터 비교적 자유롭다는 장점도 있다.63


VAE의 독특한 확률적 잠재 공간 모델링 능력은 단순한 이미지 생성을 넘어 다양한 분야에서 실용적인 응용을 가능하게 한다.

- **이상 탐지 (Anomaly Detection):** VAE는 정상 데이터의 복잡한 분포를 학습하는 데 매우 효과적이다. 정상 데이터만으로 VAE를 훈련시킨 후, 새로운 데이터를 입력했을 때 발생하는 재구성 오차를 측정한다. 만약 입력 데이터가 훈련 시 보았던 정상 데이터의 분포에서 크게 벗어나는 비정상(anomalous) 데이터라면, 모델은 이를 제대로 재구성하지 못하고 큰 재구성 오차를 발생시킨다. 이 원리를 이용하여 특정 임계값을 넘는 재구성 오차를 가진 데이터를 이상치로 탐지할 수 있다.70 이 방법은 금융 거래에서의 사기 탐지, 산업 설비의 고장 예측, 의료 영상에서의 종양 발견 등 레이블이 없는 데이터에서 희귀한 이벤트를 찾아내는 데 널리 사용된다.70
- **데이터 증강 및 압축 (Data Augmentation & Compression):** 머신러닝 모델의 성능은 훈련 데이터의 양과 질에 크게 좌우된다. 데이터가 부족한 경우, 잘 훈련된 VAE는 학습된 잠재 공간에서 새로운 샘플들을 생성하여 훈련 데이터셋을 인위적으로 늘리는 데이터 증강(data augmentation)에 활용될 수 있다.2 한편, VAE의 인코더는 고차원 데이터를 저차원의 의미 있는 잠재 벡터로 압축하는 효율적인 비선형 압축기로 기능할 수 있다. 이는 정보이론의 손실 압축(lossy compression)과도 깊은 이론적 연관성을 가지며, 실제로 VAE 아키텍처는 최신 이미지 및 비디오 압축 기술 개발에 영감을 주고 있다.16
- **준지도 학습 (Semi-Supervised Learning):** 많은 실제 문제에서는 소수의 레이블된 데이터와 대량의 레이블되지 않은 데이터가 함께 존재한다. 준지도 학습은 이 두 종류의 데이터를 모두 활용하여 모델 성능을 높이는 것을 목표로 한다. VAE는 이러한 시나리오에 매우 적합하다. 먼저 대량의 레이블되지 않은 데이터를 사용하여 VAE를 훈련시켜 데이터의 기저 구조를 반영하는 강력한 잠재 공간을 학습한다. 그 다음, 이 VAE의 인코더를 특징 추출기로 사용하여 모든 데이터를 저차원의 잠재 벡터로 변환하고, 이 잠재 벡터를 입력으로 하여 소수의 레이블된 데이터만으로 분류기를 학습시킨다.22 레이블되지 않은 데이터를 통해 학습된 풍부한 잠재 표현이 분류 작업에 매우 유용한 정보를 제공하기 때문에, 적은 레이블만으로도 높은 성능의 모델을 구축할 수 있다.77



변이형 오토인코더(VAE)는 딥러닝 시대에 베이즈 변분 추론이라는 통계적 원리를 성공적으로 접목시킨 선구적인 생성 모델이다. VAE의 등장은 생성 모델링 분야에 중요한 패러다임 전환을 가져왔다. 이전의 모델들이 단순히 데이터의 표면적인 형태를 모방하는 데 그쳤다면, VAE는 데이터의 기저에 있는 확률 분포를 명시적으로 모델링하고 학습할 수 있는 길을 열었다.

가장 큰 기여는 '확률적 잠재 공간'이라는 개념을 도입하고 이를 실용적으로 구현했다는 점이다. 결정론적 매핑에 의존했던 표준 오토인코더의 한계를 극복하고, 연속적이고 잘 구조화된 잠재 공간을 통해 의미 있는 데이터 생성과 조작을 가능하게 했다. 이는 VAE가 단순한 재구성 도구를 넘어 진정한 생성 모델로서 기능하게 된 근본적인 이유이다. 또한, ELBO라는 명확한 목적 함수와 재매개변수화 기법이라는 독창적인 최적화 해법을 제시함으로써, 복잡한 확률 모델을 표준적인 딥러닝 프레임워크 내에서 효율적으로 학습시킬 수 있음을 증명했다. 이러한 이론적 우아함과 실용적 유연성 덕분에 VAE는 이상 탐지, 데이터 증강, 준지도 학습 등 다양한 응용 분야의 발전을 촉진하는 핵심 기술로 자리매김했다.


VAE는 많은 기여에도 불구하고 여전히 해결해야 할 도전 과제들을 안고 있다. 생성된 이미지의 '흐릿함'과 강력한 디코더 사용 시 발생하는 '후방 붕괴'는 VAE의 성능을 제약하는 고전적인 문제이다.36 이러한 문제들을 해결하기 위한 연구는 VAE의 진화를 이끄는 주요 동력으로 작용하고 있다. VQ-VAE는 이산적 잠재 공간을 도입하여 흐릿함 문제를 효과적으로 해결했으며 63, VAE-GAN과 같이 VAE와 GAN을 결합하여 각 모델의 장점을 취하려는 하이브리드 모델 연구도 활발히 진행되었다.28 최근에는 VAE를 확산 모델(Diffusion Models)과 결합하여 생성 품질과 샘플링 효율을 동시에 높이려는 시도들이 주목받고 있다.40

또 다른 중요한 연구 방향은 잠재 공간의 '해석 가능성(interpretability)'과 '분리(disentanglement)'를 향상시키는 것이다. β-VAE와 같은 모델들이 이 분야의 초기 연구를 이끌었지만, 여전히 감독 없이(unsupervised) 의미 있는 분리된 표현을 학습하는 것은 어려운 문제로 남아있다.60 AI가 데이터를 인간처럼 이해하고, 특정 속성만을 선택적으로 제어하기 위해서는 잠재 공간의 각 차원이 어떤 의미를 갖는지 명확히 파악하는 기술이 필수적이며, 이는 앞으로도 중요한 연구 주제가 될 것이다. 이와 더불어, 대규모 데이터셋과 거대 모델(예: Stable Diffusion에 사용되는 VAE) 환경에서 VAE의 학습 효율성과 성능을 최적화하는 연구 또한 지속적으로 이루어지고 있다.7


미래의 생성 AI 생태계에서 VAE는 단독 생성 모델로서의 역할뿐만 아니라, 더 크고 복잡한 시스템의 핵심 '구성 요소(component)'로서 그 중요성이 더욱 커질 것으로 전망된다. 이러한 경향은 Stable Diffusion과 같은 최신 텍스트-이미지 생성 모델에서 이미 뚜렷하게 나타나고 있다.

Stable Diffusion은 직접적으로 고차원의 픽셀 공간에서 이미지를 생성하는 대신, VAE를 사용하여 이미지를 다루기 쉬운 저차원의 잠재 공간으로 압축한다.42 실제 이미지 생성 과정인 확산 프로세스는 바로 이 압축된 잠재 공간에서 수행되며, 마지막 단계에서 VAE의 디코더를 통해 잠재 표현을 다시 고해상도 이미지로 복원한다.7 여기서 VAE는 단순한 생성기가 아니라, 픽셀의 세계와 의미의 세계를 잇는 '효율적인 번역기'이자 '의미론적 압축기'로서 기능한다. 이 접근법은 계산 비용을 획기적으로 줄이면서도 고품질의 이미지를 생성할 수 있게 하여, 거대 생성 모델의 대중화를 이끈 핵심 요인 중 하나가 되었다.

이처럼 VAE의 강력한 표현 학습 능력과 차원 축소 능력은 다른 생성 패러다임과 결합될 때 엄청난 시너지를 발휘한다. 앞으로 VAE는 GAN, 확산 모델, 트랜스포머 등 다양한 모델 아키텍처와 결합하여, 생성 모델의 효율성, 품질, 제어 가능성을 높이는 데 필수적인 기반 기술로 계속해서 활용될 것이다. VAE는 생성 AI라는 거대한 건축물을 지탱하는 견고한 주춧돌 중 하나로서, 그 진화를 계속해 나갈 것으로 기대된다.


1. What is a Generative Model? | IBM, 8월 9, 2025에 액세스, https://www.ibm.com/think/topics/generative-model
2. What is a Generative Model? - DataCamp, 8월 9, 2025에 액세스, https://www.datacamp.com/blog/what-is-a-generative-model
3. Generative model - Wikipedia, 8월 9, 2025에 액세스, https://en.wikipedia.org/wiki/Generative_model
4. Generative AI Models Explained - AltexSoft, 8월 9, 2025에 액세스, https://www.altexsoft.com/blog/generative-ai/
5. Background: What is a Generative Model? | Machine Learning - Google for Developers, 8월 9, 2025에 액세스, https://developers.google.com/machine-learning/gan/generative
6. VAEs for Image Generation - Number Analytics, 8월 9, 2025에 액세스, https://www.numberanalytics.com/blog/vaes-for-image-generation
7. What Is VAE in Stable Diffusion? - Built In, 8월 9, 2025에 액세스, https://builtin.com/artificial-intelligence/stable-diffusion-vae
8. Understanding the Differences Between AutoEncoder (AE) and Variational AutoEncoder (VAE) | by Etorezone | Medium, 8월 9, 2025에 액세스, https://medium.com/@etorezone/understanding-the-differences-between-autoencoder-ae-and-variational-autoencoder-vae-1ccb52ebf76c
9. What is a Variational Autoencoder? - IBM, 8월 9, 2025에 액세스, https://www.ibm.com/think/topics/variational-autoencoder
10. [Hands-On] 오토인코더의 이해와 구현 - Medium, 8월 9, 2025에 액세스, [https://medium.com/@hugmanskj/hands-on-%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94%EC%9D%98-%EC%9D%B4%ED%95%B4%EC%99%80-%EA%B5%AC%ED%98%84-f0d9e3b31819](https://medium.com/@hugmanskj/hands-on-오토인코더의-이해와-구현-f0d9e3b31819)
11. [만들면서 배우는 생성 AI] 3장 - 변이형 오토인코더(VAE) - velog, 8월 9, 2025에 액세스, [https://velog.io/@running_learning/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%83%9D%EC%84%B1-AI-2%EC%9E%A5-%EB%94%A5%EB%9F%AC%EB%8B%9D](https://velog.io/@running_learning/만들면서-배우는-생성-AI-2장-딥러닝)
12. Variational Autoencoders - Deep Learning, CMU, 8월 9, 2025에 액세스, https://deeplearning.cs.cmu.edu/S20/document/recitation/recitation12.pdf
13. Autoencoder or Variational Auto Encoder? : r/learnmachinelearning - Reddit, 8월 9, 2025에 액세스, https://www.reddit.com/r/learnmachinelearning/comments/1aiohuu/autoencoder_or_variational_auto_encoder/
14. Image Generation Series - Variational Autoencoders | by Mani - Medium, 8월 9, 2025에 액세스, https://medium.com/@manikantan.srinivasan2001/image-generation-series-variational-autoencoders-f8da3e6e0559
15. Variational autoencoder - Wikipedia, 8월 9, 2025에 액세스, https://en.wikipedia.org/wiki/Variational_autoencoder
16. Variational Autoencoders - Dremio, 8월 9, 2025에 액세스, https://www.dremio.com/wiki/variational-autoencoders/
17. Tutorial: VAE as an inference paradigm for neuroimaging - arXiv, 8월 9, 2025에 액세스, https://arxiv.org/pdf/2501.08009
18. Tutorial: VAE as an inference paradigm for neuroimaging - arXiv, 8월 9, 2025에 액세스, https://arxiv.org/html/2501.08009v1
19. [생성AI] 생성AI 기초(6) : 변이 오토인코더 - 글래스 비드 게임, 8월 9, 2025에 액세스, [https://futures-studies.tistory.com/entry/%EC%83%9D%EC%84%B1AI-%EC%83%9D%EC%84%B1AI-%EA%B8%B0%EC%B4%886-%EB%B3%80%EC%9D%B4-%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94](https://futures-studies.tistory.com/entry/생성AI-생성AI-기초6-변이-오토인코더)
20. What is Variational Autoencoders ? - Analytics Vidhya, 8월 9, 2025에 액세스, https://www.analyticsvidhya.com/blog/2023/07/an-overview-of-variational-autoencoders/
21. Variational AutoEncoders - GeeksforGeeks, 8월 9, 2025에 액세스, https://www.geeksforgeeks.org/machine-learning/variational-autoencoders/
22. Variational Autoencoders: How They Work and Why They Matter | DataCamp, 8월 9, 2025에 액세스, https://www.datacamp.com/tutorial/variational-autoencoders
23. www.ibm.com, 8월 9, 2025에 액세스, [https://www.ibm.com/kr-ko/think/topics/autoencoder#:~:text=4-,%EB%B3%80%EC%9D%B4%ED%98%95%20%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94,%EC%83%9D%EC%84%B1%ED%95%98%EB%8A%94%20%EB%8D%B0%20%EC%82%AC%EC%9A%A9%EB%90%A9%EB%8B%88%EB%8B%A4.](https://www.ibm.com/kr-ko/think/topics/autoencoder#:~:text=4-,변이형 오토인코더,생성하는 데 사용됩니다.)
24. Tutorial on Variational Autoencoders, 8월 9, 2025에 액세스, https://arxiv.org/abs/1606.05908
25. Tutorial - What is a variational autoencoder? – Jaan Lı 李, 8월 9, 2025에 액세스, https://jaan.io/what-is-variational-autoencoder-vae-tutorial/
26. Variational Inference & Derivation of the Variational Autoencoder (VAE) Loss Function: A True Story | by Dr Stephen Odaibo | The Blog of RETINA-AI Health, Inc. | Medium, 8월 9, 2025에 액세스, https://medium.com/retina-ai-health-inc/variational-inference-derivation-of-the-variational-autoencoder-vae-loss-function-a-true-story-3543a3dc67ee
27. Variational autoencoders simply explained - AI Accelerator Institute, 8월 9, 2025에 액세스, https://www.aiacceleratorinstitute.com/variational-autoencoders-simply-explained/
28. A Crash Course on VAEs, VQ-VAEs, and VAE-GANs - Medium, 8월 9, 2025에 액세스, https://medium.com/mlearning-ai/a-crash-course-on-vaes-vq-vaes-and-vae-gans-3fdcc40b059e
29. [D] The popular theoretical explanation for VAE is inconsistent. Please change my mind., 8월 9, 2025에 액세스, https://www.reddit.com/r/MachineLearning/comments/1h5f6co/d_the_popular_theoretical_explanation_for_vae_is/
30. Evidence lower bound - Wikipedia, 8월 9, 2025에 액세스, https://en.wikipedia.org/wiki/Evidence_lower_bound
31. ELBO (Evidence of Lower BOund) - Lifetime behind every seconds, 8월 9, 2025에 액세스, https://yonghyuc.wordpress.com/2019/09/26/elbo-evidence-of-lower-bound/
32. Derivation of ELBO in VAE. I read a blog on how to build VAE using ..., 8월 9, 2025에 액세스, https://fangdahan.medium.com/derivation-of-elbo-in-vae-25ad7991fdf7
33. The Reparameterization Trick - Gregory Gundersen, 8월 9, 2025에 액세스, https://gregorygundersen.com/blog/2018/04/29/reparameterization/
34. 7.3.2 재매개변수화 트릭 - 밑바닥부터 시작하는 딥러닝 5 [Book], 8월 9, 2025에 액세스, https://www.oreilly.com/library/view/mitbadagbuteo-sijaghaneun-dibreoning/9791169212960/chapter-95.html
35. 재매개변수화 트릭은 무엇이며 VAE(Variational Autoencoders) 교육에 중요한 이유는 무엇입니까?, 8월 9, 2025에 액세스, [https://ko.eitca.org/%EC%9D%B8%EA%B3%B5-%EC%A7%80%EB%8A%A5/eitc-ai-adl-%EA%B3%A0%EA%B8%89-%EB%94%A5-%EB%9F%AC%EB%8B%9D/%EA%B3%A0%EA%B8%89-%EC%83%9D%EC%84%B1-%EB%AA%A8%EB%8D%B8/%ED%98%84%EB%8C%80%EC%9D%98-%EC%9E%A0%EC%9E%AC-%EB%B3%80%EC%88%98-%EB%AA%A8%EB%8D%B8/%EC%8B%9C%ED%97%98-%EA%B2%80%ED%86%A0-%ED%98%84%EB%8C%80-%EC%9E%A0%EC%9E%AC-%EB%B3%80%EC%88%98-%EB%AA%A8%EB%8D%B8/%EC%9E%AC%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98%ED%99%94-%ED%8A%B8%EB%A6%AD%EC%9D%80-%EB%AC%B4%EC%97%87%EC%9D%B4%EB%A9%B0-%EC%9D%B4%EA%B2%83%EC%9D%B4-%EB%B3%80%ED%98%95-%EC%9E%90%EB%8F%99-%EC%9D%B8%EC%BD%94%EB%8D%94%EC%9D%98-%ED%9B%88%EB%A0%A8%EC%97%90-%EC%A4%91%EC%9A%94%ED%95%9C-%EC%9D%B4%EC%9C%A0%EB%8A%94-%EB%AC%B4%EC%97%87%EC%9E%85%EB%8B%88%EA%B9%8C%3F/](https://ko.eitca.org/인공-지능/eitc-ai-adl-고급-딥-러닝/고급-생성-모델/현대의-잠재-변수-모델/시험-검토-현대-잠재-변수-모델/재매개변수화-트릭은-무엇이며-이것이-변형-자동-인코더의-훈련에-중요한-이유는-무엇입니까%3F/)
36. 변형 오토인코더란 무엇인가요? - IBM, 8월 9, 2025에 액세스, https://www.ibm.com/kr-ko/think/topics/variational-autoencoder
37. Why is the variational auto-encoder's output blurred, while GANs output is crisp and has sharp edges? - Artificial Intelligence Stack Exchange, 8월 9, 2025에 액세스, https://ai.stackexchange.com/questions/8885/why-is-the-variational-auto-encoders-output-blurred-while-gans-output-is-crisp
38. [D]Why are images created by GAN sharper than images by VAE? : r ..., 8월 9, 2025에 액세스, https://www.reddit.com/r/MachineLearning/comments/9t712f/dwhy_are_images_created_by_gan_sharper_than/
39. [D] Quality of generated image from VAE vs GAN : r/MachineLearning, 8월 9, 2025에 액세스, https://www.reddit.com/r/MachineLearning/comments/gum5iq/d_quality_of_generated_image_from_vae_vs_gan/
40. Comparing Diffusion, GAN, and VAE Techniques - Generative AI Lab, 8월 9, 2025에 액세스, https://generativeailab.org/l/generative-ai/a-tale-of-three-generative-models-comparing-diffusion-gan-and-vae-techniques/569/
41. Explicitly Minimizing the Blur Error of Variational Autoencoders, 8월 9, 2025에 액세스, https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/594280/1/Explicitly_Minimizing_the_Blur_Error_of_Variational_Autoencoders.pdf
42. VAE. The Latent Bottleneck: Why Image Generation Processes Lose Fine Details - Medium, 8월 9, 2025에 액세스, https://medium.com/@efrat_37973/vae-the-latent-bottleneck-why-image-generation-processes-lose-fine-details-a056dcd6015e
43. Detecting Posterior Collapse in Conditional and Hierarchical Variational Autoencoders - arXiv, 8월 9, 2025에 액세스, https://arxiv.org/html/2306.05023v3
44. Scale-VAE: Preventing Posterior Collapse in Variational Autoencoder - ACL Anthology, 8월 9, 2025에 액세스, https://aclanthology.org/2024.lrec-main.1250.pdf
45. Controlling Posterior Collapse by an Inverse Lipschitz Constraint on the Decoder Network, 8월 9, 2025에 액세스, https://arxiv.org/html/2304.12770v2
46. Posterior collapse - Just Do It - 티스토리, 8월 9, 2025에 액세스, https://xogns7652.tistory.com/entry/Posterior-collapse
47. [D] Variational Autoencoders are not autoencoders : r/MachineLearning - Reddit, 8월 9, 2025에 액세스, https://www.reddit.com/r/MachineLearning/comments/al0lvl/d_variational_autoencoders_are_not_autoencoders/
48. How does variational autoencoders actually work in comparison to GAN?, 8월 9, 2025에 액세스, https://datascience.stackexchange.com/questions/121467/how-does-variational-autoencoders-actually-work-in-comparison-to-gan
49. Preventing Posterior Collapse with DVAE for Text Modeling - MDPI, 8월 9, 2025에 액세스, https://www.mdpi.com/1099-4300/27/4/423
50. www.geeksforgeeks.org, 8월 9, 2025에 액세스, [https://www.geeksforgeeks.org/deep-learning/generative-models-in-ai-a-comprehensive-comparison-of-gans-and-vaes/#:~:text=Neural%20Network%2DBased%3A%20Both%20GANs,outputs%20from%20this%20latent%20space.](https://www.geeksforgeeks.org/deep-learning/generative-models-in-ai-a-comprehensive-comparison-of-gans-and-vaes/#:~:text=Neural Network-Based%3A Both GANs,outputs from this latent space.)
51. Generative Models in AI: A Comprehensive Comparison of GANs ..., 8월 9, 2025에 액세스, https://www.geeksforgeeks.org/deep-learning/generative-models-in-ai-a-comprehensive-comparison-of-gans-and-vaes/
52. VAE Vs. GAN For Image Generation | Baeldung on Computer Science, 8월 9, 2025에 액세스, https://www.baeldung.com/cs/vae-vs-gan-image-generation
53. VAE v/s GAN - A case study. Deep learning is a field that focuses ..., 8월 9, 2025에 액세스, https://medium.com/@parakatta/vae-v-s-gan-a-case-study-b09c7169ac02
54. Learn Conditional VAE | Introduction to Generative Networks - Codefinity, 8월 9, 2025에 액세스, https://codefinity.com/courses/v2/0cb5bd44-cf54-4200-9e26-ac4232a374bb/3a629837-6e9d-43f9-b4d9-a66ddd8fb15b/59514068-ee4e-46a4-9caf-8ced6af5af25
55. Exploring Advanced Generative AI | Conditional VAEs - Analytics Vidhya, 8월 9, 2025에 액세스, https://www.analyticsvidhya.com/blog/2023/09/generative-ai-conditional-vaes/
56. Conditional Variational Auto-encoder - Pyro Tutorials 1.9.1 documentation, 8월 9, 2025에 액세스, https://pyro.ai/examples/cvae.html
57. CVAE 설명 - 치킨고양이짱아 공부일지, 8월 9, 2025에 액세스, https://chickencat-jjanga.tistory.com/4
58. Hands-on with Conditional Variational Autoencoders (CVAE) - YouTube, 8월 9, 2025에 액세스, https://www.youtube.com/watch?v=e4izCK7l4Kc&pp=0gcJCfwAo7VqN5tD
59. [논문 리뷰] CRepair: CVAE-based Automatic Vulnerability Repair Technology - Moonlight, 8월 9, 2025에 액세스, https://www.themoonlight.io/ko/review/crepair-cvae-based-automatic-vulnerability-repair-technology
60. Disentangling Variational Autoencoders | beta_vae – Weights & Biases - Wandb, 8월 9, 2025에 액세스, https://wandb.ai/arpastrana/beta_vae/reports/Disentangling-Variational-Autoencoders--VmlldzozNDQ3MDk
61. A Closer Look at Disentangling in β-VAE - arXiv, 8월 9, 2025에 액세스, https://arxiv.org/pdf/1912.05127
62. Denoising Multi-Beta VAE: Representation Learning for ... - arXiv, 8월 9, 2025에 액세스, https://arxiv.org/pdf/2507.06613
63. [1711.00937] Neural Discrete Representation Learning - arXiv, 8월 9, 2025에 액세스, https://arxiv.org/abs/1711.00937
64. Understanding Vector Quantized Variational Autoencoders (VQ-VAE ..., 8월 9, 2025에 액세스, https://shashank7-iitd.medium.com/understanding-vector-quantized-variational-autoencoders-vq-vae-323d710a888a
65. VQ-VAE EXPLAINER: Learn Vector-Quantized Variational Autoencoders with Interactive Visualization, 8월 9, 2025에 액세스, https://xnought.github.io/files/vq_vae_explainer.pdf
66. VQ-VAE(Neural Discrete Representation Learning) - velog, 8월 9, 2025에 액세스, https://velog.io/@trwy25/VQ-VAENeural-Discrete-Representation-Learning
67. Understanding Vector Quantization in VQ-VAE - Hugging Face, 8월 9, 2025에 액세스, https://huggingface.co/blog/ariG23498/understand-vq
68. Variational Autoencoders: VAE to VQ-VAE / dVAE - Rohit Bandaru, 8월 9, 2025에 액세스, https://rohitbandaru.github.io/blog/VAEs/
69. Generating Diverse High-Fidelity Images with VQ-VAE2 - DeepStudy - 티스토리, 8월 9, 2025에 액세스, https://deepseow.tistory.com/42
70. Variational Autoencoder Based Anomaly Detection in Large-Scale ..., 8월 9, 2025에 액세스, https://www.mdpi.com/1996-1073/18/11/2770
71. Training a Variational Autoencoder for Anomaly Detection Using TensorFlow, 8월 9, 2025에 액세스, https://www.analyticsvidhya.com/blog/2023/09/variational-autoencode-for-anomaly-detection-using-tensorflow/
72. Data Augmentation & Anomaly Detection with Variational ... - Ksolves, 8월 9, 2025에 액세스, https://www.ksolves.com/blog/artificial-intelligence/a-multifaceted-approach-exploring-advanced-vaes-for-data-augmentation-and-anomaly-detection
73. Multi-Channel Multi-Scale Convolution Attention Variational Autoencoder (MCA-VAE): An Interpretable Anomaly Detection Algorithm Based on Variational Autoencoder - MDPI, 8월 9, 2025에 액세스, https://www.mdpi.com/1424-8220/24/16/5316
74. 오토인코더와 변이형 오토인코더를 활용한 공유 킥보드 사용자 인증 시스템 강화 - Korea Science, 8월 9, 2025에 액세스, https://koreascience.kr/article/CFKO202133648814920.pdf
75. CBN-VAE: A Data Compression Model with Efficient Convolutional Structure for Wireless Sensor Networks - PMC, 8월 9, 2025에 액세스, https://pmc.ncbi.nlm.nih.gov/articles/PMC6721250/
76. Lossy Image Compression With Quantized Hierarchical VAEs - CVF Open Access, 8월 9, 2025에 액세스, https://openaccess.thecvf.com/content/WACV2023/papers/Duan_Lossy_Image_Compression_With_Quantized_Hierarchical_VAEs_WACV_2023_paper.pdf
77. Exploring Semi-supervised Variational Autoencoders for Biomedical ..., 8월 9, 2025에 액세스, https://pmc.ncbi.nlm.nih.gov/articles/PMC6708455/
78. Semi-supervised Learning with Variational Autoencoders | Bounded Rationality, 8월 9, 2025에 액세스, https://bjlkeng.io/posts/semi-supervised-learning-with-variational-autoencoders/
79. The Semi-Supervised VAE - Pyro Tutorials 1.9.1 documentation, 8월 9, 2025에 액세스, https://pyro.ai/examples/ss-vae.html
80. Infinite Variational Autoencoder for Semi-Supervised Learning - CVF Open Access, 8월 9, 2025에 액세스, https://openaccess.thecvf.com/content_cvpr_2017/papers/Abbasnejad_Infinite_Variational_Autoencoder_CVPR_2017_paper.pdf
81. [2402.02346] Closed-Loop Unsupervised Representation Disentanglement with $β$-VAE Distillation and Diffusion Probabilistic Feedback - arXiv, 8월 9, 2025에 액세스, https://arxiv.org/abs/2402.02346

