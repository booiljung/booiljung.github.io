# 대규모 언어 모델
[대규모 언어 모델](./index.md)


이 파트에서는 대규모 언어 모델(LLM)의 기본 개념을 정립하고 그 발전 과정을 추적한다. 언어 모델의 역사는 인간 언어에 내재된 복잡하고 순차적이며 장거리 의존성 문제를 표현하고 처리하는 한계를 극복하기 위한 지속적인 탐구의 과정이었음을 논증한다.



대규모 언어 모델(Large Language Model, LLM)은 방대한 양의 데이터에 대해 사전훈련된 매우 큰 딥러닝 모델로 정의된다.1 이는 자연어 처리(Natural Language Processing, NLP) 분야의 중대한 발전을 대표하며, 머신러닝 및 딥러닝 원칙에 기반을 두고 있다.2 그 핵심 기술은 인간의 뇌에서 영감을 받은 신경망 아키텍처로, 정보를 처리하는 계층화된 노드로 구성된다.2 이 모델들은 수십억에서 수조 개에 이르는 매개변수(파라미터)를 포함할 수 있으며, 이 매개변수들은 모델이 훈련 과정에서 학습하는 가중치와 편향이다.4


가장 기본적인 수준에서 LLM은 정교한 '다음 토큰 예측기'이다.6 모델은 방대한 훈련 데이터에서 학습한 패턴을 기반으로 확률을 사용하여 시퀀스에서 다음 단어 또는 토큰이 무엇일지 예측한다.3 이 단순해 보이는 기능이 거대한 규모로 수행될 때, 텍스트 생성, 요약, 번역, 질의응답과 같은 '창발적 능력(emergent abilities)'이 나타난다.1 즉, 모델은 단순히 예측하는 것을 넘어, 일관성 있고 문맥적으로 적절한 콘텐츠를 생성하게 된다.


- **규모(Scale):** '대규모(Large)'라는 용어는 방대한 훈련 데이터셋의 크기(수조 개의 단어)와 모델의 매개변수 수(수십억에서 수조 개) 모두를 지칭한다.2 이 규모는 모델의 능력과 직접적으로 관련이 있다.8
- **다재다능성(Multi-task Learning):** 단일 사전훈련된 LLM은 특정 과제에 대한 별도의 훈련 없이도 매우 다양한 작업을 수행할 수 있으며, 이는 이전 모델들과의 핵심적인 차별점이다.1 간단한 지시사항이나 '프롬프트'만으로 질문에 답하고, 문서를 요약하며, 언어를 번역하고, 코드를 작성할 수 있다.1
- **문맥 인식(Contextual Awareness):** 현대 LLM은 긴 텍스트 구절에 걸쳐 문맥을 이해하는 데 탁월하며, 이를 통해 일관성 있고 관련성 높은 응답을 생성할 수 있다.4 이는 LLM의 기반 아키텍처인 트랜스포머(Transformer)의 직접적인 결과물이다.1



초기 언어 모델은 순전히 통계적인 방식이었으며, **n-gram 모델**이 대표적인 예이다.9 N-gram은 `n-1`개의 이전 단어를 기반으로 특정 단어가 나타날 확률을 계산한다.10 이 접근법은 지역적 문맥을 포착하는 데 효과적이었지만 근본적인 한계가 있었다. N-gram은 '차원의 저주'와 데이터 희소성 문제에 시달렸으며, 문장 내에서 멀리 떨어진 단어 간의 관계인 장거리 의존성을 처리할 수 없었고 단어 간의 의미적 유사성을 파악하지 못했다.1


2000년대 초 요슈아 벤지오(Yoshua Bengio)와 같은 연구자들이 언어 모델링에 신경망을 도입하면서 중대한 돌파구가 마련되었다.11 이는 가장 유명하게는 **Word2Vec**(2013)과 같은 **단어 임베딩** 기술의 발전으로 이어졌다.11 단어 임베딩은 단어를 이산적인 단위로 취급하는 대신, 연속적인 공간의 밀집 벡터로 표현했다.11 이 벡터 표현은 의미적 관계를 포착했다. 예를 들어, '왕'과 '여왕' 벡터의 관계는 '남자'와 '여자' 벡터의 관계와 유사하게 나타났다.11 이는 통계 모델의 핵심적인 한계를 극복한 것이다.


**순환 신경망(Recurrent Neural Networks, RNNs)**은 이전 입력에 대한 '은닉 상태' 또는 기억을 유지함으로써 순차적 데이터를 처리하도록 설계되었다.13

**장단기 메모리(Long Short-Term Memory, LSTM)** 네트워크와 **게이트 순환 유닛(Gated Recurrent Units, GRU)**은 '게이팅' 메커니즘을 도입하여 **기울기 소실 문제**를 더 잘 처리하도록 설계된 RNN의 발전된 형태로, 단순한 RNN보다 더 긴 범위의 의존성을 학습할 수 있게 했다.11

하지만 이 시기에도 한계는 명확했다. 기계 번역과 같은 작업에서 최첨단 기술이었던 시퀀스-투-시퀀스(Seq2Seq) 모델은 전체 입력 시퀀스를 단일한 고정 길이의 '문맥 벡터'로 압축했는데, 이는 특히 긴 문장에서 정보 병목 현상을 일으켰다.13 시퀀스 시작 부분의 정보는 종종 손실되었다. 더 근본적인 제약은 RNN/LSTM의 순차적 특성이었다. 이들은 텍스트를 토큰 단위로 순서대로 처리해야만 했고, 이로 인해 병렬화가 불가능하여 대규모 데이터셋에서의 훈련이 극도로 느리고 계산 비용이 많이 들었다.1 이것이 바로 극복해야 할 결정적인 장벽이었다.

언어 모델링의 전체 역사는 두 가지 근본적이고 상호 연결된 제약, 즉 (1) 문맥의 표현과 (2) 계산의 효율성을 극복하기 위한 일련의 혁신 과정으로 볼 수 있다. N-gram은 지역적 문맥 표현에 그쳤고, 단어 임베딩은 의미 표현 문제는 해결했지만 순차적 문맥 문제는 해결하지 못했다. RNN/LSTM은 기억을 도입하여 순차적 문맥을 직접 다루었지만, 순차적 처리라는 계산적 병목과 고정 길이 문맥 벡터라는 표현적 병목을 새로 만들었다. 2014년 바다나우(Bahdanau)의 어텐션 메커니즘은 RNN의 표현적 병목을 해결하기 위해 발명되었고, 디코더가 전체 입력을 다시 참조할 수 있게 했다.16 그리고 마침내 트랜스포머는 RNN의 결함을 수정하기 위해 만들어진 어텐션 메커니즘이 순환 구조 자체를 완전히 대체할 만큼 강력하다는 급진적인 도약을 이루었다.7 이는 병렬화를 통해 계산적 병목을, 모든 토큰 간의 비교를 허용함으로써 표현적 병목을 동시에 해결했다. 이 인과적 사슬은 트랜스포머가 고립된 발명품이 아니라, 이 두 가지 핵심 제약과의 수십 년에 걸친 싸움의 논리적 귀결이었음을 보여준다.

| 시대                 | 주요 모델/기술    | 핵심 개념          | 해결된 주요 한계                    | 새롭게 등장한 한계 / 다음 과제     |
| -------------------- | ----------------- | ------------------ | ----------------------------------- | ---------------------------------- |
| **통계 시대**        | N-gram            | 단어 시퀀스의 확률 | -                                   | 데이터 희소성, 장거리 문맥 부재 10 |
| **초기 신경망 시대** | Word2Vec          | 의미적 벡터 표현   | 의미론적 이해 부족 11               | 순차적 정보 처리 능력 부재         |
| **순환 시대**        | LSTM              | 순차적 기억        | 장거리 의존성 처리 미흡 13          | 순차적 처리 병목, 정보 압축 손실 1 |
| **트랜스포머 시대**  | 트랜스포머/어텐션 | 병렬적 문맥 처리   | 순차적 병목 및 장거리 의존성 문제 7 | 막대한 계산 비용, 블랙박스 특성 18 |


이 파트에서는 사실상 모든 현대 LLM의 기반이 되는 트랜스포머 아키텍처를 상세히 해부한다. 이 아키텍처의 새로운 설계가 어떻게 이전 모델들의 한계를 직접적으로 해결하고 전례 없는 규모의 가능성을 열었는지 강조한다.



2017년 구글 연구원들이 발표한 논문 "Attention Is All You Need"는 트랜스포머 아키텍처를 소개했다.4 이 논문의 가장 혁명적인 기여는 당시 시퀀스 처리의 지배적인 방법이었던 순환 및 컨볼루션 계층을 완전히 제거한 것이다.7 오직 어텐션 메커니즘에만 의존함으로써, 트랜스포머는 입력 시퀀스의 모든 토큰을 동시에(병렬로) 처리할 수 있게 되었고, 이는 훈련 시간을 극적으로 단축시키고 훨씬 더 큰 데이터셋의 사용을 가능하게 했다.1 이러한 병렬화 가능성은 현대 LLM에서 트랜스포머가 지배적인 위치를 차지하게 된 핵심적인 이유이다.18


최초의 트랜스포머는 기계 번역을 위해 설계되었으며 **인코더-디코더** 아키텍처를 특징으로 한다.1

- **인코더 스택:** 동일한 계층 여러 개(원본 논문에서는 N=6)가 쌓인 구조로 구성된다. 각 계층은 두 개의 주요 하위 계층, 즉 멀티-헤드 셀프-어텐션 메커니즘과 위치별 완전 연결 피드-포워드 네트워크를 가진다. 인코더의 역할은 입력 시퀀스(예: 독일어 문장)를 처리하여 풍부하고 문맥화된 수치적 표현을 구축하는 것이다.7
- **디코더 스택:** 역시 N=6개의 동일한 계층으로 구성된다. 디코더는 인코더에 있는 두 개의 하위 계층 외에, 인코더의 출력에 대해 멀티-헤드 어텐션을 수행하는 세 번째 하위 계층을 추가로 삽입한다 (크로스-어텐션). 디코더의 역할은 인코더의 표현을 받아 출력 시퀀스(예: 번역된 영어 문장)를 자기회귀적(autoregressive) 방식으로 토큰 단위로 생성하는 것이다.7
- **잔차 연결 및 계층 정규화:** 인코더와 디코더의 각 하위 계층은 잔차 연결(residual connection)과 계층 정규화(layer normalization)로 감싸여 있다. 이는 기울기가 소실되거나 폭주하는 것을 방지하여 매우 깊은 네트워크의 훈련을 가능하게 하는 핵심적인 기법이다.7


- **입력 임베딩:** 프로세스는 입력 토큰(단어 또는 하위 단어)을 고차원 벡터로 변환하는 것으로 시작된다. 이 임베딩 계층은 각 토큰의 의미론적 의미를 포착한다.2 이 벡터의 차원은 종종 $d_{model}$ (원본 논문에서는 512)로 지칭된다.15

- **위치 인코딩:** 모델은 순환이나 컨볼루션 구조가 없기 때문에 단어 순서에 대한 내재적 감각이 없다. 이 문제를 해결하기 위해 "위치 인코딩"이 입력 임베딩에 더해진다. 이는 시퀀스 내 각 토큰의 위치에 대한 정보를 모델에 제공하는 벡터이다. 원본 논문에서는 이를 위해 서로 다른 주파수의 사인 및 코사인 함수를 사용했다.15 이를 통해 "남자가 개를 문다"와 "개가 남자를 문다"가 다르게 처리될 수 있다.



어텐션은 **쿼리(Query, Q)**와 한 세트의 **키-값(Key-Value, K-V)** 쌍을 출력에 매핑하는 함수로 설명된다.7 데이터베이스 검색 시스템에 비유할 수 있다. 

**쿼리**는 찾고 있는 것이고, **키**는 데이터베이스 항목의 인덱스나 레이블이며, **값**은 항목의 실제 내용이다. 이 메커니즘은 쿼리와 각 키 사이의 점수(닷-프로덕트 사용)를 계산하여 작동한다. 이 점수는 각 해당 값에 얼마나 많은 "주의"를 기울일지 결정한다. 점수는 키 차원의 제곱근($sqrt(d_k)$)으로 **스케일링**되어 닷-프로덕트 값이 너무 커지는 것을 방지하고 훈련 중 기울기를 안정시킨다.15 스케일링된 점수에 

**소프트맥스** 함수를 적용하여 합이 1이 되는 가중치로 변환한다. 이 가중치들은 값들의 가중 합을 계산하는 데 사용되어 최종 출력 벡터를 생성한다.15


트랜스포머의 인코더와 디코더에서는 **셀프-어텐션**이라는 특별한 형태의 어텐션이 사용된다. 여기서는 쿼리, 키, 값이 모두 동일한 소스, 즉 이전 계층의 출력에서 나온다.7 이를 통해 시퀀스의 각 위치가 시퀀스의 다른 모든 위치에 주의를 기울일 수 있다. 예를 들어, "동물은 너무 피곤했기 때문에 길을 건너지 않았다"라는 문장에서 셀프-어텐션은 대명사 '그것'이 '길'이 아닌 '동물'에 높은 주의를 기울여야 함을 계산하여 대명사의 지시 대상을 해결할 수 있다.4


단일 어텐션 계산을 수행하는 대신, 트랜스포머는 **멀티-헤드 어텐션**을 사용한다. Q, K, V 벡터는 여러 개의 저차원 하위 공간으로 선형 투영되며, 어텐션 메커니즘은 이러한 각 "헤드"에서 병렬로 실행된다.7 이는 마치 전문가 팀(헤드들)이 문장을 살펴보는 것과 같다. 한 전문가는 구문 관계에, 다른 전문가는 의미 관계에, 세 번째 전문가는 장거리 의존성에 집중할 수 있다.24 모든 헤드의 출력을 연결하고 다시 선형 변환하여 최종 출력을 생성한다. 이를 통해 모델은 서로 다른 위치에서 다른 표현 하위 공간의 정보에 공동으로 주의를 기울일 수 있어 그 능력을 크게 향상시킨다.18


- **마스크드 셀프-어텐션:** 디코더는 출력 시퀀스의 미래 위치가 "마스킹"되는 수정된 셀프-어텐션 메커니즘을 사용한다.15 이는 훈련 및 생성 중에 모델이 이미 생성한 토큰에만 주의를 기울일 수 있도록 하기 때문에 매우 중요하다. 이는 모델이 자기회귀적 속성(즉, 이전 토큰을 기반으로 한 번에 하나의 토큰을 생성)을 유지하도록 보장한다.15
- **크로스-어텐션 (인코더-디코더 어텐션):** 이는 디코더의 세 번째 하위 계층에 있는 메커니즘이다. 여기서는 **쿼리**가 디코더의 마스크드 셀프-어텐션 계층에서 오고, **키와 값**은 **인코더**의 최종 출력에서 온다. 이를 통해 디코더는 각 출력 토큰을 생성할 때 *입력* 시퀀스의 가장 관련성 높은 부분에 다시 집중할 수 있다.22

트랜스포머 아키텍처의 성공은 단순히 어텐션 때문이 아니라, 병렬화 가능한 셀프-어텐션과 잔차 연결에 의해 가능해진 깊은 계층 구조 사이의 **시너지 효과** 때문이다. RNN은 시간적으로는 깊었지만(긴 시퀀스를 처리) 계층적으로는 얕았는데, 많은 RNN 계층을 쌓는 것은 훈련하기 어려웠기 때문이다. "Attention Is All You Need" 논문은 어텐션뿐만 아니라 N=6개의 동일한 계층으로 구성된 **스택**을 제안했다.7 이 깊은 수직적 스태킹을 통해 모델은 언어에 대한 점점 더 추상적인 표현을 학습한다.

셀프-어텐션은 단일 계층 내에서 정보 혼합을 위한 원시 메커니즘을 제공하지만, 단일 어텐션 계층만으로는 강력하지 않다. 이러한 계층을 깊게 쌓을 수 있게 하는 핵심 요소는 **잔차 연결과 계층 정규화**이다.7 이것들이 없었다면 불안정한 기울기 때문에 6개 계층(현대 GPT 모델의 96개 계층은 말할 것도 없고)의 트랜스포머를 훈련하는 것은 불가능했을 것이다. 따라서 진정한 혁신은 (a) 병렬 정보 혼합을 위한 **셀프-어텐션**, (b) 계층적 특징 추출을 위한 **깊은 스태킹**, (c) 깊은 스태킹을 훈련 가능하게 만드는 **잔차/정규화**라는 세 부분으로 구성된 시스템이다.

또한, 어텐션 유형(셀프-어텐션, 마스크드 셀프-어텐션, 크로스-어텐션)의 분리는 복잡한 시퀀스-투-시퀀스 작업을 위해 필수적인 정교한 역할 분담을 반영한다. 인코더의 임무는 입력을 이해하는 것이며, 모든 입력 단어가 다른 모든 입력 단어에 의해 문맥화될 수 있도록 하는 **셀프-어텐션**은 이 목적에 완벽하다.22 디코더는 일관된 출력을 생성하고 그 출력이 입력과 일치하도록 보장하는 두 가지 임무를 가진다. 

**마스크드 셀프-어텐션**은 생성된 출력이 언어적으로 유효하도록(예: 문법적으로 정확하도록) 보장하는 첫 번째 임무를 수행한다.15

**크로스-어텐션**은 출력을 입력과 정렬하는 두 번째 임무를 수행하며, 디코더가 생성의 각 단계에서 인코더에게 "지금 생성하려는 단어와 가장 관련 있는 원본 입력 부분은 어디인가?"라고 물을 수 있는 다리 역할을 한다.22 이 세 가지 어텐션 시스템은 단일 통합 아키텍처 내에서 입력 이해, 출력 일관성, 입력-출력 정렬이라는 별개의 하위 문제들을 우아하게 해결한다.


이 파트에서는 LLM이 원시적인 "기반 모델"에서 고도로 유능하고 정렬된 보조자로 만들어지는 다단계 과정을 상세히 설명한다. 일반적인 지식을 습득하는 것과 특정 행동을 형성하는 것 사이의 중요한 차이점을 강조한다.



사전훈련(Pre-training)은 모델이 범용 지식을 학습하는 초기 단계이자 계산적으로 가장 집약적인 단계이다.25 이 단계에서 모델은 위키피디아, 깃허브, 그리고 광범위한 인터넷에서 수집한 방대한 양의 레이블 없는 텍스트 데이터셋(종종 수조 개의 단어 또는 토큰으로 구성됨)으로 훈련된다.2 이 과정은 데이터 자체가 레이블을 제공하기 때문에 **비지도 학습** 또는 더 정확하게는 **자기-지도 학습(self-supervised learning)**으로 설명된다. 이 단계에서는 인간의 주석 작업이 필요 없다.1 모델은 텍스트의 한 부분을 다른 부분으로부터 예측하려고 시도하면서 학습한다. 이 단계는 계산 비용이 극도로 높아 수백만 달러의 비용이 들 수 있으며, 일반적으로 대기업이나 자금이 풍부한 연구소에서만 수행된다.26


주요 훈련 목표는 **다음 토큰 예측**(인과적 언어 모델링이라고도 함)이다. 모델에 텍스트 시퀀스가 주어지면 바로 다음 토큰을 예측하도록 훈련된다.4 이는 GPT 시리즈와 같은 모델의 핵심 목표이다. 또 다른 일반적인 목표는 BERT와 같은 모델에서 사용되는 **마스크드 언어 모델링(Masked Language Modeling, MLM)**이다. MLM에서는 입력 시퀀스의 일부 토큰이 무작위로 마스킹되고(예: `` 토큰으로 대체), 모델은 원래의 마스킹된 토큰을 예측하도록 훈련된다.25 이러한 단순한 목표를 거대한 규모로 수행함으로써 모델은 데이터에 내재된 문법, 구문, 의미, 사실적 지식 및 추론 패턴을 학습한다.1


사전훈련 단계의 결과물은 **기반 모델(base model)**이다.1 이 모델은 훈련 데이터와 통계적으로 유사한 방식으로 텍스트를 완성하는 데 뛰어난 강력한 "인터넷 문서 시뮬레이터"이다.6 그러나 기반 모델은 유용한 보조자가 아니다. 지시를 따르거나, 대화 형식으로 질문에 답하거나, 안전 지침을 준수하도록 훈련되지 않았다.12 질문에 대해 더 많은 질문을 하거나, 웹 문서와 문체적으로 유사한 관련 없는 텍스트를 생성할 수 있다.



기반 모델을 유용하게 만들려면 특정 작업이나 행동에 맞게 조정해야 한다. 이는 다양한 형태의 미세조정(fine-tuning)을 통해 달성된다.2 미세조정은 사전훈련된 모델을 가져와 더 작고, 더 구체적이며, 종종 레이블이 지정된 데이터셋에서 추가로 훈련하는 과정이다.25


이것은 일반적으로 사전훈련 후 첫 번째 단계이다. 모델은 고품질의 지시-응답 쌍 데이터셋(예: `{instruction: "이 기사를 요약해줘", input: "<기사 텍스트>", output: "<요약문>"}`)으로 훈련된다.12 이를 통해 모델은 **지시를 따르고** 유용한 형식으로 응답하는 방법을 학습한다.2 InstructGPT와 ChatGPT의 초기 버전이 이런 방식으로 만들어졌다.


- **인간 피드백을 통한 강화 학습(RLHF):** 이는 유용성, 정직성, 무해성과 같은 복잡한 인간의 가치에 모델을 정렬(align)하기 위한 중요한 단계이다.8
  1. **비교 데이터 수집:** 인간 평가자에게 단일 프롬프트에 대한 모델의 여러 응답을 보여주고 최고부터 최악까지 순위를 매기도록 요청한다.
  2. **보상 모델 훈련:** 이 비교 데이터를 사용하여 인간이 어떤 응답을 선호할지 예측하는 별도의 "보상 모델"을 훈련시킨다.
  3. **RL을 통한 미세조정:** 원래 LLM은 강화 학습(예: PPO 알고리즘)을 사용하여 미세조정되며, 이때 보상 모델이 LLM의 정책을 인간이 높게 평가할 만한 출력을 생성하는 방향으로 유도하는 신호를 제공한다.
- **직접 선호도 최적화(DPO):** RLHF에 대한 더 최신의, 종종 더 안정적인 대안으로, 별도의 보상 모델을 훈련할 필요 없이 선호도 데이터에 대해 언어 모델을 직접 최적화하여 유사한 목표를 달성한다.28


**지식 주입**(모델에 새로운 사실을 가르치는 것)을 위한 미세조정과 **정렬**(모델의 스타일, 톤, 형식을 변경하는 것)을 위한 미세조정 사이에는 중요한 구분이 존재한다.28 LIMA("Less Is More for Alignment") 논문은 모델의 핵심 지식과 능력은 거의 전적으로 사전훈련 중에 학습된다는 것을 보여주었다. 정렬은 놀라울 정도로 작고, 고품질이며, 다양한 예제 데이터셋으로 달성될 수 있다.28 이 통찰은 Alpaca나 Vicuna와 같은 강력한 오픈 소스 모델의 탄생으로 이어졌다. 이들은 Llama 기반 모델을 GPT-4와 같은 더 강력한 모델이 생성한 작은 대화 데이터셋으로 미세조정하여 만들어졌다.28 그들은 완전한 RLHF 파이프라인 없이도 유용한 보조자의 *스타일*을 효과적으로 학습했다.


새로운 지식을 주입하기 위해 미세조정하는 것은 비용이 많이 들고 "파국적 망각"을 초래할 수 있다. **검색 증강 생성(Retrieval-Augmented Generation, RAG)**은 추론 시점에 외부의 최신 지식으로 LLM을 강화하는 대안적인 접근법이다.12

**작동 방식:** 사용자가 쿼리를 하면 RAG 시스템은 먼저 벡터 데이터베이스와 같은 외부 지식 기반에서 관련 문서를 검색한다. 이 문서들은 컨텍스트로 사용자의 프롬프트에 추가된다. 그런 다음 LLM은 원래 쿼리와 검색된 정보를 모두 기반으로 답변을 생성한다.12 RAG는 LLM을 새로운 지식 기반에 특화시키는 데 매우 효과적이며, 모델의 응답을 사실적 문서에 기반하게 함으로써 환각(hallucination)을 줄일 수 있다.28

LLM의 생애 주기는 근본적인 관심사의 분리를 드러낸다: 사전훈련은 **일반화**(세상을 배우는 것)를 위한 것이고, 미세조정과 정렬은 **특화**(역할을 배우는 것)를 위한 것이다. 이 분리는 안전하고 유용한 AI를 만드는 열쇠이다. 사전훈련에서 나온 기반 모델은 순수한 지식 엔진이다.6 그것은 사물에 대해 

*알지만* 어떻게 *행동해야* 하는지는 모른다. SFT/지시 튜닝은 첫 번째 특화 단계로, 모델에게 지시를 따르는 에이전트의 "역할"을 가르친다.28 RLHF/DPO는 더 깊은 특화 단계로, 공손함, 신중함, 훈계하지 않음과 같이 명시되지 않은 미묘한 인간의 선호를 가르친다.28 이 다단계 과정은 의도적인 공학적 선택이다. 지식 습득과 행동 훈련을 분리함으로써, 개발자들은 강력하지만 예측 불가능한 기반 모델을 가져와 그 행동을 유용하고 안전하도록 신중하게 제약할 수 있다.

RAG의 부상과 "정렬에는 더 적은 것이 더 낫다"는 발견은 더 효율적이고 모듈화된 AI 시스템을 향한 중대한 패러다임 전환을 의미한다. "처음부터 모든 것을 훈련시키는" 단일체 모델은 "핵심 모델 + 외부 구성 요소"라는 더 민첩한 아키텍처로 대체되고 있다. LIMA 논문의 발견은 행동 정렬이 놀라울 정도로 저렴하다는 것을 보여주어, 이를 사전훈련의 막대한 비용과 분리시켰다.28 이는 오픈 소스 커뮤니티가 매우 경쟁력 있는 모델을 만들 수 있게 했다.28 동시에 RAG는 사실적 지식이 외부화될 수 있음을 보여주었다.12 모델이 전체 인터넷을 암기할 필요 없이, 최신 외부 지식 기반에 

*접근*하는 강력한 추론기가 될 수 있다. 이 두 가지 추세의 결합은 새로운 아키텍처 패러다임으로 이어진다: 고도로 유능한 사전훈련된 **추론 코어**(LLM)가 특정 상호작용 스타일에 맞게 저렴하게 **정렬**되고, RAG를 통해 외부 지식으로 동적으로 **증강**되는 것이다. 이는 단일체 모델을 계속해서 재훈련하는 것보다 훨씬 더 확장 가능하고, 유지보수 가능하며, 적응력이 뛰어나다.


이 파트에서는 선도적인 LLM 제품군을 비교하여 현재의 최첨단 기술을 살펴보고, 이들이 가능하게 하는 광범위한 응용 분야를 탐색한다. 주요 AI 연구소 간의 아키텍처, 기능 및 출시 철학의 전략적 차이점을 강조한다.



- **모델:** GPT-4 및 그 후속 모델 (예: o3-pro).32
- **아키텍처:** 대규모 트랜스포머 기반 모델. 정확한 크기와 아키텍처는 공개되지 않았지만, 멀티모달 모델로 알려져 있다.33
- **주요 특징:**
  - **멀티모달리티 (GPT-4V):** 이미지와 텍스트 입력을 모두 받아들여 텍스트 출력을 생성할 수 있다.33 이미지의 내용, 문맥, 심지어 유머까지 이해할 수 있다.34
  - **인간 수준의 성능:** 모의 변호사 시험에서 상위 10%의 점수로 합격하는 등 다양한 전문 및 학술 벤치마크에서 인간 수준의 성능을 보인다.33
  - **안전 및 정렬:** 프로젝트의 주요 초점은 사후 훈련 정렬(RLHF 및 기타 방법 사용)과 안전에 있었으며, 광범위한 적대적 테스트와 위험을 개괄하는 상세한 "시스템 카드"를 포함한다.33
- **철학:** 엄격한 내부 프로세스를 통해 일반 지능의 경계를 넓히고 안전을 보장하는 데 초점을 맞춘, 철저히 통제된 비공개 소스(closed-source) 출시.


- **모델:** Gemini 1.5 Pro, Gemini 2.5 Pro, Gemini 2.5 Flash.38
- **아키텍처:** **희소 전문가 혼합(Sparse Mixture-of-Experts, MoE)** 트랜스포머 아키텍처를 사용하여 매우 큰 모델 크기를 허용하면서도 주어진 입력에 대해 "전문가"의 일부만 활성화하여 계산 효율성을 향상시킨다.40
- **주요 특징:**
  - **네이티브 멀티모달리티:** 처음부터 멀티모달로 구축되어 텍스트, 이미지, 오디오, 비디오를 원활하게 처리한다.38 오디오 녹음에서 새로운 언어의 음성 패턴을 문맥 내에서 학습하는 등의 작업을 수행할 수 있다.43
  - **방대한 문맥 창:** 최대 1백만 토큰(테스트는 최대 1천만 토큰)의 문맥 창을 특징으로 하여, 책 전체, 코드베이스 또는 몇 시간 분량의 비디오를 단일 프롬프트로 처리할 수 있다.38 이는 거의 완벽한 "건초더미에서 바늘 찾기" 재현율로 입증되었다.43
  - **고급 추론:** 최신 2.5 모델은 명시적인 "사고(thinking)" 단계를 특징으로 하며, 모델이 답변을 내놓기 전에 복잡한 문제를 추론하기 위해 추론 시 추가 계산을 사용하여 수학 및 코딩 벤치마크 성능을 향상시킨다.38
- **철학:** 구글의 방대한 인프라와 데이터 자산을 활용하여 네이티브 멀티모달리티, 극단적인 규모의 문맥 창, 검증 가능한 추론에 중점을 둔다.


- **모델:** Llama 2, Llama 3 (8B, 70B, 405B), Llama 3.2 (멀티모달).44
- **아키텍처:** 트랜스포머 기반이며, 핵심적인 효율성 중심의 혁신을 포함한다.
- **주요 특징:**
  - **오픈 소스 리더십:** Llama 모델은 공개적으로 출시되어 연구자와 개발자가 광범위하게 접근할 수 있으며, 이는 커뮤니티에서 대규모 혁신의 촉매제가 되었다.44
  - **토크나이저 효율성:** Llama 3는 128K 토큰의 더 큰 토크나이저 어휘를 사용하여 언어를 더 효율적으로 인코딩하고 모델 성능을 향상시킨다.45
  - **그룹화된 쿼리 어텐션(GQA):** Llama 3에 채택되어 추론 효율성을 개선하고, 표준 멀티-헤드 어텐션에 비해 모델을 더 빠르고 저렴하게 실행할 수 있게 한다.45
  - **시스템 수준의 책임감 있는 AI:** 메타는 Llama Guard 2 및 CyberSec Eval 2와 같은 오픈 소스 안전 도구 모음을 제공하여 개발자가 모델을 책임감 있게 구축할 수 있도록 지원한다.45
- **철학:** 오픈 소스 출시를 통해 발전을 주도하며, 전 세계 커뮤니티가 널리 채택하고 구축할 수 있는 고성능이면서도 효율적인 모델을 만드는 데 중점을 둔다.

주요 AI 연구소들의 전략적 선택은 고전적인 기술 생태계 경쟁을 반영한다: 긴밀하게 통합된 고성능의 "벽으로 둘러싸인 정원"(애플/OpenAI) 대 개방적이고 사용자 정의 가능하며 널리 채택된 플랫폼(안드로이드/메타). 구글의 전략은 독특한 데이터 및 인프라 이점을 활용하는 하이브리드 방식이다. OpenAI의 GPT-4는 최고의 성능을 제공하지만 블랙박스이다.33 이는 OpenAI가 성능 우위를 유지하고 안전을 통제할 수 있게 하지만, 광범위한 커뮤니티의 맞춤화와 연구를 제한한다. 메타의 Llama 3는 명시적으로 오픈 소스이다.45 이는 거대한 개발자 생태계를 조성하고 전 세계적으로 혁신을 가속화하며 비용을 절감한다. 구글의 Gemini는 OpenAI처럼 비공개 소스이지만, 1백만 토큰 이상의 문맥 창과 네이티브 멀티모달리티와 같은 핵심 차별점은 구글 규모의 인프라와 독점 데이터셋(예: 유튜브) 없이는 복제하기 매우 어려운 것들이다.40 이러한 전략의 분기는 단순한 기술적 선호의 문제가 아니라, 전체 AI 산업의 미래를 형성할 근본적인 비즈니스 및 철학적 경쟁이다.

| 모델 제품군          | 개발사 | 출시 철학             | 주요 아키텍처 특징       | 독보적 역량                     | 문맥 창                 | 멀티모달리티                               |
| -------------------- | ------ | --------------------- | ------------------------ | ------------------------------- | ----------------------- | ------------------------------------------ |
| **GPT-4 / o-시리즈** | OpenAI | 비공개 소스, API 접근 | 대규모 트랜스포머        | 범용 전문/학술 성능             | 예: 128k                | 텍스트, 이미지 -->> 텍스트 33                 |
| **Gemini 2.5**       | Google | 비공개 소스, API 접근 | 희소 전문가 혼합(MoE)    | 네이티브 멀티모달리티 및 장문맥 | 최대 1M 42              | 텍스트, 이미지, 오디오, 비디오 -->> 텍스트 42 |
| **Llama 3**          | Meta   | 오픈 소스             | GQA 및 효율적 토크나이저 | 와트당 성능 및 개방적 접근성    | 예: 8k, 향후 더 긴 버전 | 텍스트 전용, 멀티모달 버전 개발 중 45      |



- **텍스트 생성 및 카피라이팅:** 마케팅 문구, 제품 설명서부터 단편 소설에 이르기까지 독창적인 콘텐츠 작성.1
- **요약:** 긴 문서, 기사 또는 회의록을 간결한 요약문으로 압축.1
- **번역:** 수십 개의 언어 간 텍스트를 향상된 유창성과 정확도로 번역.1


- **코드 생성:** 자연어 프롬프트로부터 다양한 언어(Python, JavaScript, SQL 등)로 코드 작성.1 Amazon CodeWhisperer와 GitHub Copilot이 대표적인 예이다.1
- **디버깅 및 문서화:** 오류 식별, 수정 제안, 프로젝트 문서 자동 생성을 통해 개발자 지원.5


- **지식 기반 질의응답 (KI-NLP):** 대규모 디지털 아카이브나 제공된 문서에서 정보를 추출하여 특정 질문에 답변.1
- **텍스트 분류 및 감성 분석:** 고객 감성 측정, 주제별 텍스트 분류, 텍스트 간 관계 파악.1


- **대화형 AI:** 일정 관리, 고객 지원, 정보 검색과 같은 작업을 위한 자연스럽고 매력적인 대화가 가능한 고급 챗봇 및 가상 비서 구동.2


이 마지막 파트에서는 LLM이 직면한 중대한 장애물을 다루고 이를 극복하기 위한 최첨단 연구를 탐색한다. 한계, 윤리적 우려, 미래 방향을 종합하여 이 분야가 나아갈 방향에 대한 일관된 비전을 제시한다.



- **정의:** LLM은 유창하고, 그럴듯하며, 문법적으로는 정확하지만 사실적으로는 부정확하거나, 말이 안 되거나, 제공된 소스 컨텍스트에 부합하지 않는 응답을 생성할 수 있다.12
- **원인:** 이는 모델이 사실의 데이터베이스가 아니라 확률적 패턴 매칭기이기 때문에 발생한다. 모델은 통계적으로 가능성이 높은 텍스트를 생성하며, 이것이 현실과 일치하지 않을 수 있다.6
- **완화 방안:** RAG(외부 사실에 근거), 개선된 미세조정, 자기 수정을 유도하는 프롬프트 등이 활발한 연구 분야이다.30 GPT-4는 GPT-3.5에 비해 환각이 크게 감소했지만 문제는 여전히 존재한다.34


- **정의:** LLM은 방대하고 선별되지 않은 훈련 데이터에 존재하는 사회적 편견을 답습하고 증폭시킬 수 있다.12
- **사례:**
  - **고정관념:** 성별, 인종, 직업과 관련된 해로운 고정관념을 강화(예: 의사는 남성, 간호사는 여성과 연관 짓기).31
  - **정치적 및 문화적 편향:** 영어 및 서구 중심 데이터의 과대 표현은 다른 관점을 경시하거나 왜곡하는 모델로 이어질 수 있다.31 메타는 Meta AI에서 이 문제를 해결하기 위해 적극적으로 노력하고 있다.47


- **프롬프트 주입 및 탈옥:** 사용자는 모델의 안전 필터를 우회하기 위해 악의적인 프롬프트를 만들어 유해하거나 비윤리적이거나 금지된 콘텐츠를 생성하도록 속일 수 있다.31
- **허위 정보 및 조작 정보:** LLM은 설득력 있지만 거짓인 콘텐츠를 대량으로 생성하는 데 사용될 수 있어 정보 생태계에 위협이 된다.31
- **슬리퍼 에이전트:** 특정 입력에 의해 트리거될 때까지 잠복 상태로 있는 숨겨진 악의적 행동을 모델이 보이는 이론적이지만 심각한 위험.31
- **과잉 의존:** 사용자가 비판적 검증 없이 LLM의 출력을 과도하게 신뢰하는 것이 중요한 위험이며, 이는 고위험 분야에서 특히 위험하다.33



- **도전 과제:** LLM은 패턴 매칭과 정보 검색에는 뛰어나지만, 구조화되고 논리적인 사고를 요구하는 복잡한 다단계 추론에는 어려움을 겪는다.30

- **새로운 기술:**

  - **프롬프트 전략:** **사고의 연쇄(Chain-of-Thought, CoT)** 프롬프팅(모델이 "작업 과정"을 보여주게 함), 자기-일관성(Self-Consistency), **사고의 트리(Tree-of-Thought)**는 더 강력한 추론 과정을 이끌어내는 방법들이다.30

  - **아키텍처 혁신:** **검색 증강 생성(RAG)**은 추론을 외부 사실에 근거하게 한다.30

    **신경-기호 하이브리드**는 신경망의 패턴 매칭 강점과 기호 추론 시스템의 엄격한 논리를 결합하고자 한다.30

  - **구글의 "사고" 모델:** Gemini 2.5의 명시적 추론 단계는 이러한 연구 동향의 상업적 구현이다.38


- **동향:** 이 분야는 텍스트 전용 모델을 넘어 텍스트, 이미지, 오디오, 비디오를 원활하게 처리하고 추론할 수 있는 **멀티모달 대규모 언어 모델(Multimodal Large Language Models, MLLMs)**로 빠르게 이동하고 있다.12
- **아키텍처:** MLLM은 일반적으로 모달리티별 인코더(예: CLIP과 같은 비전 인코더), 서로 다른 데이터 표현을 정렬하는 "커넥터" 모듈, 그리고 추론을 위한 "뇌" 역할을 하는 핵심 LLM으로 구성된다.53
- **응용:** 이는 비디오 설명, 차트에 대한 질문 답변 56, 이미지를 기반으로 한 이야기 생성과 같은 새로운 능력을 가능하게 한다.53


- **도전 과제:** LLM의 훈련 및 배포에 드는 막대한 계산 및 에너지 비용은 발전과 접근성의 주요 장벽이다.57

- **새로운 기술:**

  - **모델 압축:** **양자화**(모델 가중치의 수치 정밀도를 낮춤, 예: 8비트, 4비트, 심지어 1비트)와 **가지치기**(중복 가중치 제거)는 모델 크기를 줄이는 핵심 방법이다.57

  - **효율적인 아키텍처:** **전문가 혼합(MoE)** 모델(Gemini, Mixtral 등)은 낮은 추론 비용으로 더 큰 모델을 가능하게 한다.57

    **상태 공간 모델(State Space Models, SSMs)**(Mamba 등)은 매우 긴 시퀀스에 대해 더 나은 확장성을 가진 트랜스포머의 잠재적 대안으로 부상하고 있다.57

  - **엣지 컴퓨팅:** 이러한 효율성 향상은 스마트폰과 같은 로컬 장치에 강력한 모델을 배포하는 데 매우 중요하며, 이는 개인 정보 보호 및 지연 시간에 중대한 영향을 미친다.50


- **다음 패러다임:** 고급 추론, 도구 사용, 메모리의 융합은 **LLM 기반 에이전트**의 개발로 이어지고 있다.8
- **정의:** 에이전트는 LLM을 핵심 추론 엔진으로 사용하여 환경(예: 웹사이트 또는 소프트웨어 터미널)을 인식하고, 결정을 내리고, 다단계 계획을 수립하며, 외부 도구(예: API 호출, 코드 실행)를 사용하여 행동을 취하는 자율 시스템이다.8
- **미래 방향:** 이는 LLM이 수동적인 텍스트 생성기에서 디지털 환경의 능동적인 참여자로 전환됨을 의미하며, 최소한의 인간 개입으로 복잡하고 장기적인 목표를 달성할 수 있는 능력을 갖추게 된다. 이러한 자율 에이전트의 안전성을 평가하고 보장하는 것은 중요한 미해결 연구 과제이다.60

주요 연구 분야들-추론, 멀티모달리티, 효율성, 에이전트-는 독립적인 영역이 아니라 깊이 시너지 효과를 내며 새로운 종류의 AI를 창조하기 위해 수렴하고 있다. 한 분야의 발전은 다른 분야의 발전을 직접적으로 가능하게 하거나 필요하게 만든다. 예를 들어, 더 유능한 **에이전트**를 구축하려면 복잡한 계획을 가능하게 하는 더 강력한 **추론** 능력이 필요하다.30 에이전트가 현실 세계에서 작동하려면, 세상이 텍스트뿐만이 아니므로 **멀티모달**이어야 한다.53 그리고 이러한 더 복잡하고 멀티모달 추론 에이전트가 실용적이고 널리 배포되려면, 특히 개인 장치에서는 극도로 

**효율적**이어야 한다.57 따라서 에이전트 AI를 향한 추진력은 다른 모든 분야의 연구를 이끄는 주요 동인이다. 모델 양자화(효율성)의 돌파구는 강력한 추론 모델(추론)을 휴대폰에서 실행할 수 있을 만큼 작게 만들어, 카메라 입력(멀티모달리티)을 처리하여 개인 비서(에이전트) 역할을 할 수 있게 할 것이다. 이는 모든 주요 연구 방향 간의 명확한 인과적 및 시너지 관계를 보여준다. 최종 목표는 더 나은 챗봇이 아니라, 유능하고 효율적이며 상호작용적인 인공 에이전트이다.


대규모 언어 모델(LLM)은 단순한 통계적 패턴 매칭에서 시작하여, 인간 언어의 복잡성을 포착하기 위한 수십 년간의 여정을 거쳐 현재의 정교한 생성형 AI로 진화했다. N-gram의 지역적 문맥 한계에서 RNN의 순차적 처리 병목에 이르기까지, 각 시대의 기술은 이전의 제약을 극복하려는 시도였다. 2017년 트랜스포머 아키텍처의 등장은 병렬 처리와 셀프-어텐션을 통해 이러한 제약들을 동시에 해결하며 패러다임의 전환을 가져왔고, 이는 전례 없는 규모의 모델 훈련을 가능하게 했다.

오늘날 LLM의 생애 주기는 지식 습득을 위한 막대한 비용의 사전훈련과, 특정 역할과 안전성을 부여하기 위한 정교한 미세조정 및 정렬 과정으로 명확히 구분된다. OpenAI, 구글, 메타와 같은 선도 기업들은 각각 비공개 고성능 모델, 네이티브 멀티모달 및 장문맥 모델, 그리고 개방형 생태계 주도라는 뚜렷한 전략적 방향을 통해 이 분야의 발전을 이끌고 있다.

그러나 환각, 편향, 안전성과 같은 근본적인 도전 과제는 여전히 남아있다. 미래의 연구는 이러한 한계를 극복하는 동시에, 더 발전된 추론, 진정한 멀티모달리티, 그리고 극대화된 효율성을 추구하는 방향으로 나아가고 있다. 궁극적으로 이러한 연구 흐름들은 서로 융합하여, 단순히 텍스트를 생성하는 도구를 넘어, 디지털 및 물리적 세계와 상호작용하며 복잡한 작업을 자율적으로 수행하는 AI 에이전트의 시대를 열고 있다. 따라서 LLM의 여정은 기술적 진보를 넘어, 지능의 본질을 탐구하고 책임감 있는 AI의 미래를 설계하는 과정 그 자체라 할 수 있다.


1. What is LLM? - Large Language Models Explained - AWS, accessed July 3, 2025, https://aws.amazon.com/what-is/large-language-model/
2. What are Large Language Models? | A Comprehensive LLMs Guide ..., accessed July 3, 2025, https://www.elastic.co/what-is/large-language-models
3. What is an LLM (large language model)? - Cloudflare, accessed July 3, 2025, https://www.cloudflare.com/learning/ai/what-is-large-language-model/
4. Introduction to Large Language Models (LLMs) and Their Principles, accessed July 3, 2025, [https://stephen-smj.tech/2024/07/09/LLM%20Introduction/index.html](https://stephen-smj.tech/2024/07/09/LLM Introduction/index.html)
5. What is a Large Language Model (LLM) - GeeksforGeeks, accessed July 3, 2025, https://www.geeksforgeeks.org/large-language-model-llm/
6. A Comprehensive Guide to Pre-training LLMs - Analytics Vidhya, accessed July 3, 2025, https://www.analyticsvidhya.com/blog/2025/02/llm-pre-training/
7. Attention is All you Need - NIPS, accessed July 3, 2025, https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf
8. Large Language Models: A Survey - arXiv, accessed July 3, 2025, https://arxiv.org/html/2402.06196v3
9. Language model - Wikipedia, accessed July 3, 2025, https://en.wikipedia.org/wiki/Language_model
10. Evolution of Language Models: From Rules-Based Models to LLMs, accessed July 3, 2025, https://www.appypieagents.ai/blog/evolution-of-language-models
11. A Brief History of Large Large Language Models (LLMs) - Idiot Developer, accessed July 3, 2025, https://idiotdeveloper.com/a-brief-history-of-large-large-language-models-llms/
12. Large language model - Wikipedia, accessed July 3, 2025, https://en.wikipedia.org/wiki/Large_language_model
13. What is an attention mechanism? | IBM, accessed July 3, 2025, https://www.ibm.com/think/topics/attention-mechanism
14. 3. Understanding Transformers: Part 1 - The Evolution from RNNs ..., accessed July 3, 2025, https://m.youtube.com/watch?v=_BTK3G4kJzY
15. Transformer (deep learning architecture) - Wikipedia, accessed July 3, 2025, https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)
16. 11. Attention Mechanisms and Transformers - Dive into Deep Learning, accessed July 3, 2025, http://www.d2l.ai/chapter_attention-mechanisms-and-transformers/index.html
17. Attention Is All You Need (Vaswani et al., ArXiv 2017) | Jonathan K. Kummerfeld, accessed July 3, 2025, https://jkk.name/reading-notes/old-blog/2017-10-20_onlyattention/
18. Attention Is All You Need - Wikipedia, accessed July 3, 2025, https://en.wikipedia.org/wiki/Attention_Is_All_You_Need
19. On the Biology of a Large Language Model - Transformer Circuits Thread, accessed July 3, 2025, https://transformer-circuits.pub/2025/attribution-graphs/biology.html
20. Attention is All you Need - NIPS, accessed July 3, 2025, https://papers.nips.cc/paper/7181-attention-is-all-you-need
21. Attention Is All You Need | Request PDF - ResearchGate, accessed July 3, 2025, https://www.researchgate.net/publication/317558625_Attention_Is_All_You_Need
22. Transformer Attention Mechanism in NLP - GeeksforGeeks, accessed July 3, 2025, https://www.geeksforgeeks.org/transformer-attention-mechanism-in-nlp/
23. How Transformers Work: A Detailed Exploration of Transformer Architecture - DataCamp, accessed July 3, 2025, https://www.datacamp.com/tutorial/how-transformers-work
24. Introduction to Transformers and Attention Mechanisms | by Rakshit Kalra - Medium, accessed July 3, 2025, https://medium.com/@kalra.rakshit/introduction-to-transformers-and-attention-mechanisms-c29d252ea2c5
25. Fine-Tuning vs. Pre-Training: Key Differences for Language Models - Sapien, accessed July 3, 2025, https://www.sapien.io/blog/fine-tuning-vs-pre-training-key-differences-for-language-models
26. What is the difference between pre-training, fine-tuning, and instruct-tuning exactly? - Reddit, accessed July 3, 2025, https://www.reddit.com/r/learnmachinelearning/comments/19f04y3/what_is_the_difference_between_pretraining/
27. Fine-Tuning LLMs: A Guide With Examples - DataCamp, accessed July 3, 2025, https://www.datacamp.com/tutorial/fine-tuning-large-language-models
28. A brief summary of language model finetuning - Stack Overflow, accessed July 3, 2025, https://stackoverflow.blog/2024/10/31/a-brief-summary-of-language-model-finetuning/
29. Fine tuning Vs Pre-training. The objective of my articles is to... | by Eduardo Ordax | Medium, accessed July 3, 2025, https://medium.com/@eordaxd/fine-tuning-vs-pre-training-651d05186faf
30. Advancing Reasoning in Large Language Models: Promising Methods and Approaches, accessed July 3, 2025, https://arxiv.org/html/2502.03671v1
31. Large language model - Wikipedia, accessed July 3, 2025, https://en.wikipedia.org/wiki/Large_language_model#Limitations_and_risks
32. LLM Leaderboard - Comparison of over 100 AI models from OpenAI, Google, DeepSeek & others, accessed July 3, 2025, https://artificialanalysis.ai/leaderboards/models
33. GPT-4 Technical Report - OpenAI, accessed July 3, 2025, https://cdn.openai.com/papers/gpt-4.pdf
34. GPT-4 Technical Report Highlights - Reflections, accessed July 3, 2025, https://annjose.com/post/gpt-4-tech-report-highlights/
35. GPT-4 Technical Report - arXiv, accessed July 3, 2025, http://arxiv.org/pdf/2303.08774
36. GPT-4V(ision) technical work and authors - OpenAI, accessed July 3, 2025, https://openai.com/contributions/gpt-4v/
37. GPT-4 - OpenAI, accessed July 3, 2025, https://openai.com/index/gpt-4-research/
38. Gemini 2.5 Pro - Google DeepMind, accessed July 3, 2025, https://deepmind.google/models/gemini/pro/
39. We're expanding our Gemini 2.5 family of models, accessed July 3, 2025, https://blog.google/products/gemini/gemini-2-5-model-family-expands/
40. Gemini 1.5 Technical Report: Key Reveals and Insights - Gradient Flow, accessed July 3, 2025, https://gradientflow.com/gemini-1-5-technical-report/
41. Gemini - Google DeepMind, accessed July 3, 2025, https://deepmind.google/models/gemini/
42. Gemini 2.5: Pushing the Frontier with Advanced ... - Googleapis.com, accessed July 3, 2025, https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf
43. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context - Googleapis.com, accessed July 3, 2025, https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf
44. The future of AI: Built with Llama - AI at Meta, accessed July 3, 2025, https://ai.meta.com/blog/future-of-ai-built-with-llama/
45. Introducing Meta Llama 3: The most capable openly available LLM ..., accessed July 3, 2025, https://ai.meta.com/blog/meta-llama-3/
46. [ACL 2024] Emerging Trends and Key Insights in LLM Research - LG AI Research BLOG, accessed July 3, 2025, https://www.lgresearch.ai/blog/view?seq=474
47. Our responsible approach to Meta AI and Meta Llama 3, accessed July 3, 2025, https://ai.meta.com/blog/meta-llama-3-meta-ai-responsibility/
48. arXiv:2503.18971v1 [cs.AI] 22 Mar 2025, accessed July 3, 2025, [https://arxiv.org/pdf/2503.18971?](https://arxiv.org/pdf/2503.18971)
49. zchuz/CoT-Reasoning-Survey: [ACL 2024] A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future - GitHub, accessed July 3, 2025, https://github.com/zchuz/CoT-Reasoning-Survey
50. [2405.10739] Efficient Multimodal Large Language Models: A Survey - arXiv, accessed July 3, 2025, https://arxiv.org/abs/2405.10739
51. [2408.08632] A Survey on Benchmarks of Multimodal Large Language Models - arXiv, accessed July 3, 2025, https://arxiv.org/abs/2408.08632
52. A Survey of Multimodal Large Language Model from A Data-centric Perspective - arXiv, accessed July 3, 2025, https://arxiv.org/abs/2405.16640
53. survey on multimodal large language models | National Science Review - Oxford Academic, accessed July 3, 2025, https://academic.oup.com/nsr/article/11/12/nwae403/7896414
54. A Comprehensive Survey of Multimodal Large Language Models: Concept, Application and Safety - ResearchGate, accessed July 3, 2025, https://www.researchgate.net/publication/385012837_A_Comprehensive_Survey_of_Multimodal_Large_Language_Models_Concept_Application_and_Safety
55. A Survey on Multimodal Large Language Models - OpenReview, accessed July 3, 2025, https://openreview.net/pdf?id=2iwozOs6YB
56. [ACL 2024] A New Approach to Chart Understanding and Reasoning - LG AI Research BLOG, accessed July 3, 2025, https://www.lgresearch.ai/blog/view?seq=476
57. Efficient Large Language Models: A Survey | OpenReview, accessed July 3, 2025, https://openreview.net/forum?id=bsCCJHbO8A
58. Efficient-ML/Awesome-Model-Quantization - GitHub, accessed July 3, 2025, https://github.com/Efficient-ML/Awesome-Model-Quantization
59. Advances in LLM Prompting and Model Capabilities: A 2024-2025 Review - Reddit, accessed July 3, 2025, https://www.reddit.com/r/PromptEngineering/comments/1ki9qwb/advances_in_llm_prompting_and_model_capabilities/
60. arXiv:2503.16416v1 [cs.AI] 20 Mar 2025, accessed July 3, 2025, https://arxiv.org/pdf/2503.16416