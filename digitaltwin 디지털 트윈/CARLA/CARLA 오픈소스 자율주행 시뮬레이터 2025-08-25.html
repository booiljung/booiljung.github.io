<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:CARLA 오픈소스 자율주행 시뮬레이터</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>CARLA 오픈소스 자율주행 시뮬레이터</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">디지털트윈 (Digital Twins)</a> / <a href="index.html">CARLA 오픈소스 자율주행 시뮬레이터</a> / <span>CARLA 오픈소스 자율주행 시뮬레이터</span></nav>
                </div>
            </header>
            <article>
                <h1>CARLA 오픈소스 자율주행 시뮬레이터</h1>
<p>2025-08-25, G25DR</p>
<h2>1.  자율주행 시뮬레이션의 패러다임과 CARLA의 등장</h2>
<h3>1.1 자율주행 기술 개발에서 시뮬레이션의 필수불가결성</h3>
<p>자율주행 기술의 개발은 천문학적인 시간과 비용, 그리고 무엇보다도 안전에 대한 막대한 책임을 수반한다. 실제 차량을 개조하여 도로 주행 테스트를 수행하는 전통적인 방식은 그 자체로 수많은 한계에 직면한다. 예측 불가능한 교통 상황, 기상 변화, 그리고 잠재적인 사고 위험은 데이터 수집의 효율성을 저해하고 개발 주기를 지연시키는 주된 요인이다. 특히, 시스템의 안전성을 검증하기 위해 반드시 필요한 위험한 ‘엣지 케이스(Edge Case)’ 시나리오, 예를 들어 갑작스러운 보행자 출현이나 전방 차량의 급제동과 같은 상황을 실제 도로에서 의도적으로 재현하는 것은 거의 불가능에 가깝다.</p>
<p>이러한 물리적 테스트의 근본적인 한계를 극복하기 위한 대안으로 가상 환경 시뮬레이션이 부상하였다. 시뮬레이터는 비용 효율적이고 안전하며, 통제된 환경에서 수많은 시나리오를 무한히 반복 테스트할 수 있는 독보적인 장점을 제공한다. 이는 단순히 기존의 테스트를 보조하는 수단을 넘어, 자율주행 알고리즘, 특히 인공지능(AI) 모델의 개발 패러다임 자체를 바꾸는 핵심 동력으로 작용한다. 강화학습이나 모방학습과 같은 데이터 기반 AI 모델은 방대한 양의 주행 데이터를 필요로 하는데, 시뮬레이터는 이러한 대규모 데이터셋을 단기간에 자동으로 생성하는 강력한 도구로서의 역할을 수행한다.1</p>
<p>이러한 시대적 요구 속에서, CARLA(Car Learning to Act)는 자율주행 연구의 새로운 지평을 연 핵심적인 오픈소스 프로젝트로 등장하였다.</p>
<h3>1.2 CARLA의 개발 배경과 철학</h3>
<p>CARLA는 자율주행 시스템의 개발, 훈련, 그리고 검증을 총체적으로 지원하기 위한 목적으로 처음부터 설계된 오픈소스 시뮬레이터이다.3 Intel, Toyota, GM과 같은 세계적인 기업들의 공동 개발 참여는 프로젝트의 초기 비전과 기술적 깊이를 방증한다.1</p>
<p>CARLA의 가장 중요한 철학은 ’연구의 민주화(Democratization of R&amp;D)’에 있다.4 과거 고성능 시뮬레이션 환경은 일부 거대 기업이나 연구소의 전유물이었으며, 이는 기술 개발의 진입 장벽으로 작용했다. CARLA는 이러한 장벽을 허물기 위해 소스 코드는 물론, 도시 레이아웃, 건물, 차량, 보행자와 같은 고품질 디지털 에셋을 누구나 자유롭게 사용할 수 있도록 공개하였다. 이 개방성 철학 덕분에, 대규모 자본이나 물리적 인프라를 갖추지 못한 전 세계의 소규모 연구팀이나 대학에서도 최첨단 자율주행 연구에 동등하게 참여할 수 있는 기회가 열렸다. 이는 특정 플랫폼에 종속된 상용 시뮬레이터들과 CARLA를 구분 짓는 가장 근본적인 차별점이다.</p>
<p>이러한 배경은 CARLA의 등장이 단순한 도구의 출현을 넘어 자율주행 연구의 ’방법론적 전환’을 촉발했음을 시사한다. 과거 연구가 고가의 실제 차량을 개조하고 제한된 도로 환경에서 데이터를 수집하는 하드웨어 중심의 접근법에 의존했다면 , CARLA는 사실적인 가상 환경과 센서 데이터를 무료로 제공함으로써 연구의 중심축을 물리적 세계에서 가상 세계로 이동시키는 촉매가 되었다. 연구자들은 이제 코드 몇 줄로 위험한 충돌 시나리오나 극한의 악천후 조건을 생성하고 2, 수만 개의 정제된 데이터를 단시간에 확보할 수 있게 되었다.1 결과적으로 CARLA는 아이디어의 검증 주기를 획기적으로 단축시키고, 데이터 기반 AI 모델 개발이라는 새로운 연구 패러다임을 가속하는 핵심 <strong>연구 플랫폼</strong>으로 확고히 자리매김하였다.</p>
<h3>1.3 안내서의 구조와 분석 범위 제시</h3>
<p>본 안내서는 오픈소스 자율주행 시뮬레이터 CARLA를 다각적이고 심층적으로 고찰하는 것을 목표로 한다. 이를 위해 먼저 CARLA의 근간을 이루는 서버-클라이언트 아키텍처와 언리얼 엔진의 역할을 분석한다. 이어서 카메라, LiDAR 등 핵심 기능과 기술적 제원을 상세히 살펴보고, 알고리즘 검증부터 데이터셋 생성에 이르는 구체적인 활용 사례를 연구한다. 또한, ROS 연동을 포함한 CARLA의 확장적 생태계를 조망하고, LGSVL, AirSim 등 주요 경쟁 시뮬레이터와의 비교를 통해 그 위상을 평가한다. 마지막으로, 물리 엔진의 한계와 Sim-to-Real 문제 등 기술적 한계점을 비판적으로 분석하고, 최신 개발 동향을 바탕으로 미래 발전 방향을 전망하며 결론을 맺는다.</p>
<h2>2.  CARLA 아키텍처 심층 분석</h2>
<h3>2.1 서버-클라이언트 모델: 유연성과 확장성의 근간</h3>
<p>CARLA의 아키텍처는 그 핵심에 서버-클라이언트 모델을 두고 있다. 이는 시뮬레이션의 연산 부하를 분리하고 시스템의 유연성과 확장성을 극대화하기 위한 설계적 선택이다.</p>
<ul>
<li><strong>서버(Server):</strong> 가상 세계의 구현을 책임진다. 언리얼 엔진(Unreal Engine)을 기반으로 3D 환경 렌더링, 물리 법칙 연산, 액터(차량, 보행자 등)의 상태 업데이트 등 모든 시뮬레이션의 핵심 로직을 수행한다. 서버는 지정된 TCP 포트(기본값: 2000, 2001)를 통해 클라이언트의 접속을 대기한다.</li>
<li><strong>클라이언트(Client):</strong> 시뮬레이션을 제어하고 데이터를 수신하는 역할을 한다. 사용자는 Python 또는 C++ API를 통해 클라이언트를 구현하며, 서버에 제어 명령(예: 차량 생성, 속도 변경, 센서 부착)을 전송하고 서버로부터 센서 데이터나 시뮬레이션 상태 정보를 받아온다.</li>
</ul>
<p>이 분산 구조는 하나의 서버에 여러 클라이언트가 동시에 접속하여 각기 다른 액터를 제어하는 것을 가능하게 한다.5 예를 들어, 한 클라이언트는 자율주행 차량(Ego Vehicle)을 제어하고, 다른 클라이언트들은 주변 차량이나 보행자의 행동을 제어하는 복잡한 다중 에이전트(Multi-agent) 상호작용 시나리오를 손쉽게 구현할 수 있다. 이는 대규모 교통 환경 시뮬레이션을 위한 확장성의 근간이 된다. 클라이언트는 <code>carla.Client('localhost', 2000)</code>와 같은 간단한 코드를 통해 서버에 접속하며, 이 통신은 TCP/IP 프로토콜을 기반으로 이루어진다.6 고성능이 요구되는 작업을 위해 C++로 직접 클라이언트를 개발할 수도 있는데, 이는 Python API가 내부적으로 C++로 작성된 <code>libCarla</code> 라이브러리를 바인딩(binding)한 구조이기 때문이다.</p>
<h3>2.2 언리얼 엔진(Unreal Engine)의 역할: 사실성과 물리 시뮬레이션</h3>
<p>CARLA가 높은 수준의 시각적 사실성을 달성할 수 있었던 배경에는 에픽게임즈의 언리얼 엔진이 있다. CARLA가 언리얼 엔진을 렌더링 및 물리 엔진으로 채택한 이유는 크게 세 가지로 요약할 수 있다. 첫째, 업계 최고 수준의 사실적인 그래픽 렌더링 능력. 둘째, 엔진을 무료로 사용할 수 있고 소스 코드에 직접 접근할 수 있는 개방적인 라이선스 정책. 셋째, 방대한 개발자 커뮤니티와 문서이다.7</p>
<p>초기 버전은 OpenGL 렌더링 백엔드를 사용했으나, 최신 버전에서는 더 높은 성능을 제공하는 Vulkan을 기본으로 지원한다.5 또한, 공식 로드맵에 따라 차세대 렌더링 기술이 집약된 언리얼 엔진 5로의 메이저 업데이트가 진행 중이어서 , 향후 그래픽 품질과 시뮬레이션 성능은 더욱 향상될 것으로 기대된다.</p>
<p>물리 연산은 언리얼 엔진에 내장된 PhysX 엔진을 기반으로 수행된다.5 이는 차량 간의 충돌, 중력, 마찰 등 기본적인 물리 현상을 모사하는 데 사용된다. 하지만 PhysX는 범용 물리 엔진으로서, 실제 차량의 복잡하고 정밀한 동역학을 완벽하게 시뮬레이션하는 데에는 명백한 한계를 가진다. 이 점은 CARLA의 주요 기술적 한계 중 하나로, VII절에서 더 상세히 논한다.</p>
<h3>2.3 Python API: 시뮬레이션 제어를 위한 핵심 인터페이스</h3>
<p>CARLA의 가장 강력한 특징 중 하나는 직관적이고 유연한 Python API를 제공한다는 점이다. 이 API는 사용자가 스크립트 언어를 통해 시뮬레이션의 거의 모든 측면을 정밀하게 제어할 수 있는 핵심 인터페이스 역할을 한다.</p>
<p>Python API를 통해 수행할 수 있는 주요 작업은 다음과 같다.</p>
<ul>
<li><strong>월드(World) 제어:</strong> 맵 변경(<code>client.load_world</code>), 날씨 설정, 시뮬레이션 시간 제어 등 전역 환경을 관리한다.6</li>
<li><strong>액터(Actor) 관리:</strong> 차량, 보행자, 센서 등 시뮬레이션 내의 모든 동적 객체(액터)를 생성(<code>world.try_spawn_actor</code>), 소멸, 제어한다.9</li>
<li><strong>상태 조회 및 제어:</strong> 특정 액터의 위치, 속도, 가속도 등 물리적 상태를 실시간으로 조회하고, 조향각이나 스로틀 같은 제어 입력을 직접 가할 수 있다.</li>
<li><strong>센서 데이터 수신:</strong> 차량에 부착된 센서로부터 생성되는 데이터를 비동기적(asynchronous)으로 수신(<code>sensor.listen</code>)하여 처리한다.9</li>
</ul>
<p>이러한 유연성 덕분에 <code>pygame</code>, <code>numpy</code>와 같은 파이썬 생태계의 풍부한 라이브러리들과 손쉽게 통합하여 사용자 인터페이스를 구축하거나 데이터를 분석할 수 있다. 더 나아가 <code>TensorFlow</code>, <code>Keras</code>, <code>PyTorch</code>와 같은 주요 머신러닝 프레임워크와 직접 연동하여, 시뮬레이션 환경 내에서 AI 모델을 실시간으로 훈련하고 평가하는 파이프라인을 구축하는 것이 가능하다.10</p>
<h3>2.4 차량 동역학 모델: 키네마틱 모델과 물리적 제약</h3>
<p>CARLA에서 차량의 움직임을 제어하는 기본 모델은 주로 **자전거 모델(Bicycle Model)**에 기반한 키네마틱 모델(kinematic model)이다.11 이 모델은 4개의 바퀴를 가진 복잡한 차량 시스템을 전륜과 후륜, 단 두 개의 바퀴로 구성된 시스템으로 단순화한다. 차량의 거동은 주로 앞바퀴의 조향각(<span class="math math-inline">\delta</span>)과 속도(<span class="math math-inline">v</span>)에 의해 결정되는 비선형(non-linear) 시스템으로 표현된다.</p>
<p>이러한 모델링 방식은 모델 예측 제어(MPC, Model Predictive Control)와 같은 고급 제어 알고리즘을 적용하기에 적합하다.11 MPC는 현재 상태를 기반으로 미래의 일정 시간 동안 차량의 거동을 예측하고, 동시에 조향각 제한이나 가속도 제한과 같은 물리적 제약 조건을 만족시키면서 목표 경로와의 오차를 최소화하는 최적의 제어 입력(조향각, 가속도)을 계산하는 기법이다.</p>
<p>사용자는 <code>VehiclePhysicsControl</code> API를 통해 각 바퀴의 최대 조향각(<code>max_steer_angle</code>)이나 타이어 마찰 계수 등 일부 물리 파라미터를 조정하여 차량의 거동을 어느 정도 변경할 수 있다.12 하지만 이는 실제 차량의 복잡한 타이어-노면 상호작용, 서스펜션의 움직임, 하중 이동에 따른 동특성 변화 등을 정밀하게 모사하기에는 역부족이다.</p>
<p>결론적으로 CARLA의 아키텍처는 ’개방성’과 ‘실용성’ 사이의 정교한 타협의 산물이라 할 수 있다. 최고 수준의 그래픽 사실성을 위해 상용 게임 엔진인 언리얼 엔진을 채택하는 ‘실용적’ 선택을 했고, 동시에 모든 제어권을 사용자에게 개방하기 위해 유연한 서버-클라이언트 구조와 Python API라는 ‘개방적’ 인터페이스를 설계했다. 물리 엔진의 경우, 극도로 정밀하지만 무거운 전문 동역학 시뮬레이터 대신, 언리얼 엔진의 내장 PhysX와 키네마틱 모델을 사용하는 ‘실용적’ 절충안을 택했다. 만약 극사실적인 물리 엔진을 기본으로 채택했다면, 시뮬레이션 속도가 저하되어 대규모 AI 학습 데이터 생성이라는 핵심 목표 달성이 어려웠을 것이다. 이처럼 CARLA의 아키텍처는 학술 연구와 AI 개발이라는 명확한 목표를 달성하기 위해, 그래픽 사실성은 극대화하고 제어 유연성은 완전히 개방하며, 물리 시뮬레이션은 성능을 위해 일정 수준 타협한 결과물이다. 이 절묘한 균형점이 바로 CARLA를 성공으로 이끈 핵심 요인이라 분석된다.</p>
<h2>3.  핵심 기능 및 기술적 제원</h2>
<h3>3.1 센서 스위트: 현실 세계의 눈과 귀</h3>
<p>CARLA는 실제 자율주행 차량에 탑재되는 다양한 센서들을 정교하게 모델링하여 제공한다. 이는 인지 알고리즘의 개발과 검증에 필수적인 요소다.</p>
<ul>
<li><strong>RGB 카메라 (<code>sensor.camera.rgb</code>):</strong> 가장 기본적인 센서로, 사람의 눈과 유사한 컬러 이미지를 생성한다. 화각(FOV), 이미지 해상도, 감마, 노출 등 실제 카메라의 다양한 파라미터를 설정할 수 있으며, 렌즈 왜곡(lens distortion) 효과를 추가하여 현실감을 높일 수 있다.5</li>
<li><strong>LiDAR (<code>sensor.lidar.ray_cast</code>):</strong> 레이저 광선을 발사하여 주변 환경과의 거리를 측정하고 3D 포인트 클라우드(Point Cloud) 데이터를 생성한다. 광선 추적(Ray Tracing) 방식을 기반으로 하며, 채널 수, 수평 해상도, 초당 회전 수(RPM), 최대 탐지 거리(range) 등을 세밀하게 설정할 수 있다. 또한, 레이저 빔의 강도(intensity) 감쇠, 노이즈, 드롭아웃(drop-off)과 같은 물리적 현상을 일부 모델링하여 현실성을 더했다.</li>
<li><strong>RADAR (<code>sensor.other.radar</code>):</strong> 전파를 이용하여 객체의 거리뿐만 아니라 상대 속도까지 직접 측정할 수 있는 센서다. 악천후 상황에서도 비교적 강건한 특성을 가지며, 원거리 객체 탐지에 유용하다.</li>
<li><strong>IMU (<code>sensor.other.imu</code>):</strong> 관성 측정 장치(Inertial Measurement Unit)로, 3축 가속도와 3축 각속도를 측정한다. 이를 통해 차량의 자세(roll, pitch, yaw) 변화를 추정할 수 있으며, 자율주행 차량의 위치 추정(Localization) 알고리즘에 핵심적인 정보를 제공한다.5</li>
<li><strong>GNSS (<code>sensor.other.gnss</code>):</strong> 위성 항법 시스템(Global Navigation Satellite System) 센서로, 흔히 GPS로 알려져 있다. 차량의 전역 좌표(위도, 경도, 고도)를 제공한다.5 IMU 데이터와 융합(Sensor Fusion)하여 더 정확한 위치를 추정하는 데 사용된다.13</li>
<li><strong>특수 센서 (Ground-Truth Sensors):</strong> CARLA의 강력함은 AI 모델 학습에 이상적인 ‘정답’ 데이터를 직접 생성하는 특수 센서에서 드러난다. **깊이 카메라(Depth Camera)**는 각 픽셀까지의 거리를, **의미 분할 카메라(Semantic Segmentation Camera)**는 각 픽셀이 어떤 클래스(도로, 차량, 보행자 등)에 속하는지를 완벽하게 알려준다. 이는 현실 세계에서는 얻기 불가능한 고품질의 레이블링된 데이터를 무한정 생성할 수 있게 해준다.</li>
</ul>
<p>이처럼 CARLA는 단순한 테스트베드를 넘어 ’AI 교사’로서의 역할을 수행한다. 일반적인 시뮬레이터가 현실 세계의 센서 출력을 ’모방’하는 데 그친다면, CARLA는 현실에서는 얻을 수 없는 완벽한 정보, 즉 ‘Ground-Truth’ 데이터를 제공한다. 예를 들어, 모든 객체의 3D 바운딩 박스 정보를 오차 없이 제공하며 , 이는 객체 탐지 모델을 훈련시키는 데 이상적인 정답지로 활용된다. 이 능력은 AI 모델이 불완전하고 노이즈가 많은 실제 데이터로 학습할 때보다 훨씬 효율적으로 성능을 향상시킬 수 있는 환경을 제공하며, CARLA가 자율주행 AI 연구에서 대체 불가능한 위치를 차지하게 만든 결정적 요인이다.</p>
<h3>3.2 동적 액터(Actor) 및 환경 제어</h3>
<p>정적인 도로 환경뿐만 아니라, 그 안에서 상호작용하는 동적인 액터들을 제어하는 기능은 시뮬레이션의 현실성을 좌우한다.</p>
<ul>
<li><strong>보행자(Pedestrian):</strong> CARLA의 보행자는 단순한 장애물이 아니다. 그들은 신호를 지키고, 횡단보도를 건너며, 때로는 예측 불가능한 행동을 보이는 동적 액터로 시뮬레이션된다. 특히 버전 0.9 업데이트를 통해 보행자 모델이 대대적으로 개선되어 어린이 캐릭터가 추가되고, 스켈레톤의 모든 뼈대를 제어할 수 있는 인터페이스가 도입되었다.7 이를 통해 보행자의 미세한 몸짓(body language)이나 복잡한 행동을 연출할 수 있게 되었으며, 이는 “저 보행자가 과연 길을 건널 것인가?“와 같은 보행자 행동 예측(prediction) 알고리즘 연구에 매우 중요한 기반을 제공한다.7</li>
<li><strong>차량 및 교통류(Traffic Manager):</strong></li>
<li><strong>Autopilot:</strong> 개별 차량에 내장된 간단한 주행 로직을 활성화하는 기능이다. <code>vehicle.set_autopilot(True)</code> 명령어로 실행하며, 차선을 따라 주행하고 기본적인 장애물을 회피한다.1</li>
<li><strong>Traffic Manager:</strong> 도시 전체의 교통 흐름을 보다 지능적이고 현실적으로 제어하기 위해 도입된 고급 모듈이다. Traffic Manager는 다수의 NPC(Non-Player Character) 차량들을 통제하여 안전거리 유지, 신호등 준수, 자연스러운 차선 변경 등 현실적인 군집 주행 패턴을 만들어낸다. 사용자는 특정 차량의 주행 스타일을 ’공격적’으로 설정하거나, 제한 속도를 무시하도록 하는 등 다양한 변수를 부여하여 테스트 시나리오의 복잡성을 높일 수 있다. 또한, 동일한 시나리오를 오차 없이 반복 실행할 수 있는 **결정론적 모드(Deterministic mode)**를 지원하여 알고리즘 성능 비교의 신뢰도를 높여준다.5</li>
<li><strong>날씨 시스템:</strong> 자율주행 인지 시스템의 강건성(Robustness)을 테스트하기 위해 날씨는 매우 중요한 변수다. CARLA는 맑은 날, 구름 낀 날, 비 오는 날, 안개 낀 날 등 다양한 날씨 프리셋을 제공하며, 태양의 고도, 강수량, 안개 농도 등의 파라미터를 동적으로 제어할 수 있다. 특히 0.9.5 버전부터는 야간 모드, 빗방울 효과, 바람이 식생에 미치는 영향 등이 추가되어 환경의 현실성이 크게 향상되었다.5</li>
</ul>
<h3>3.3 맵과 월드: 시뮬레이션의 무대</h3>
<p>CARLA의 시뮬레이션이 펼쳐지는 공간인 ‘맵’ 또는 ’월드’는 3D 모델과 도로망 정보의 결합으로 이루어진다.</p>
<ul>
<li>
<p><strong>맵 구성과 OpenDRIVE:</strong> 모든 맵은 시각적 요소를 담은 3D 모델과, 도로의 기하학적 구조를 정의하는 <strong>OpenDRIVE</strong> 파일(.xodr)로 구성된다.15 OpenDRIVE는 차선, 교차로, 신호등, 표지판 등의 정보를 표준화된 XML 형식으로 기술하는 ASAM(Association for Standardization of Automation and Measuring Systems)의 표준 규격이다. CARLA는 이 표준을 준수함으로써 다른 전문 도구와의 호환성을 확보했다.</p>
</li>
<li>
<p><strong>기본 제공 맵:</strong> 설치 시 Town01부터 Town07까지의 기본 맵이 제공되며, 추가 맵 팩을 통해 Town10, 그리고 100km²에 달하는 방대한 크기를 자랑하는 Town12, Town13과 같은 대규모 맵(Large Map)을 사용할 수 있다. 이 대규모 맵들은 고속도로, 도심, 주거 지역, 시골길 등 다양한 환경을 포함하고 있어 장거리 주행 및 다양한 시나리오 테스트에 적합하다.</p>
</li>
<li>
<p><strong>커스텀 맵 생성:</strong> CARLA의 가장 큰 장점 중 하나는 사용자가 직접 맵을 제작할 수 있다는 것이다. MathWorks사의 <strong>RoadRunner</strong>는 CARLA가 공식적으로 지원하는 맵 제작 도구다. 일반적인 제작 과정은 다음과 같다.</p>
</li>
</ul>
<ol>
<li>
<p>OpenStreetMap(OSM)과 같은 실제 지도 데이터에서 원하는 지역의 데이터를 추출한다.16</p>
</li>
<li>
<p>JOSM과 같은 편집기를 사용하여 도로망 데이터를 수정 및 보완한다.</p>
</li>
<li>
<p>RoadRunner로 이 데이터를 불러와 3D 도로망을 생성하고, 차선 종류, 도로 폭, 표지판 등을 상세하게 설정한다.</p>
</li>
<li>
<p>최종적으로 CARLA에서 사용할 수 있는 포맷(.fbx, .xodr)으로 내보낸다.</p>
</li>
</ol>
<p>이러한 과정을 통해 국내 도로 환경과 같이 특정 지역의 특성을 반영한 맞춤형 테스트 환경을 구축할 수 있다.17</p>
<p>다음 표는 CARLA가 제공하는 주요 센서 모델의 명세와 그 강점 및 한계를 요약한 것이다. 이는 연구자가 시뮬레이션 데이터를 활용할 때 그 내재적 한계를 명확히 인지하고, 알고리즘 설계 시 이를 보완하는 방향을 고려하는 데 필수적인 정보를 제공한다.</p>
<table><thead><tr><th>센서 유형</th><th>블루프린트 ID</th><th>주요 설정 파라미터</th><th>출력 데이터 형식</th><th>노이즈 모델</th><th>강점</th><th>한계점</th></tr></thead><tbody>
<tr><td>RGB 카메라</td><td><code>sensor.camera.rgb</code></td><td><code>image_size_x</code>, <code>fov</code>, <code>lens_distortion</code></td><td><code>carla.Image</code></td><td>지원 (제한적)</td><td>높은 사실성, 다양한 카메라 효과</td><td>실제와 같은 광학적 왜곡, 노출 변화 완벽 재현 불가</td></tr>
<tr><td>LiDAR</td><td><code>sensor.lidar.ray_cast</code></td><td><code>channels</code>, <code>range</code>, <code>points_per_second</code></td><td><code>carla.LidarMeasurement</code></td><td>지원 (Drop-off 등)</td><td>포인트 클라우드 강도(intensity) 값 제공</td><td>악천후(비, 안개)에 의한 산란 효과 미흡, 빔 발산 모델 단순</td></tr>
<tr><td>RADAR</td><td><code>sensor.other.radar</code></td><td><code>horizontal_fov</code>, <code>range</code>, <code>points_per_second</code></td><td><code>carla.RadarMeasurement</code></td><td>지원</td><td>속도 정보 직접 측정</td><td>클러터(Clutter), 다중 반사 등 복잡한 전파 현상 모델링 미흡</td></tr>
<tr><td>IMU</td><td><code>sensor.other.imu</code></td><td><code>noise_accel_stddev_x</code>, <code>noise_gyro_bias_y</code></td><td><code>carla.IMUMeasurement</code></td><td>지원 (가우시안 노이즈)</td><td>가속도, 각속도, 방위각 제공</td><td>온도 변화에 따른 바이어스 드리프트 등 미지원</td></tr>
<tr><td>GNSS</td><td><code>sensor.other.gnss</code></td><td><code>noise_lat_stddev</code>, <code>noise_lon_stddev</code></td><td><code>carla.GnssMeasurement</code></td><td>지원 (가우시안 노이즈)</td><td>전역 위치 정보 제공</td><td>다중 경로 오차(Multipath error), 위성 가시성 변화 미반영</td></tr>
</tbody></table>
<h2>4.  활용 사례 연구: 알고리즘 검증에서 데이터 생성까지</h2>
<p>CARLA의 풍부한 기능과 유연한 API는 자율주행 연구의 다양한 단계에서 폭넓게 활용된다. 단순한 알고리즘 검증을 넘어, AI 모델 학습을 위한 데이터 생성, 특정 위험 상황에 대한 스트레스 테스트 등 그 활용 범위는 매우 넓다.</p>
<h3>4.1 End-to-End 자율주행 모델 학습 및 검증</h3>
<p>End-to-End 자율주행은 센서 입력(예: 카메라 영상)으로부터 조향, 가속/감속과 같은 차량 제어 출력을 직접 학습하는 방식으로, CARLA는 이러한 모델의 연구 및 개발에 이상적인 환경을 제공한다.10</p>
<p>대표적인 학습 방식은 모방학습(Imitation Learning)이다. 연구자는 CARLA의 <code>Autopilot</code> 모드를 이용해 전문가(expert)의 주행 데이터를 손쉽게 수집할 수 있다.1 이 과정에서 시뮬레이터는 주행 영상, 차량의 위치 및 속도, 그리고 해당 시점의 운전 조작량(조향각, 스로틀 값)을 한 쌍으로 묶어 기록한다. 이렇게 수집된 수만 개의 데이터 쌍은 AI 모델, 특히 심층 신경망(Deep Neural Network)을 훈련시키는 데 사용된다.1</p>
<p>하지만 이러한 방식은 명백한 한계를 가진다. 학습 데이터에 포함되지 않은 예외적인 상황, 예를 들어 갑자기 도로로 뛰어드는 보행자나 정차된 장애물을 마주했을 때, 모델이 올바르게 대처하지 못하고 충돌하는 문제가 발생할 수 있다.18 이를 해결하기 위해, 카메라 영상뿐만 아니라 LiDAR나 RADAR와 같은 추가 센서 정보를 입력으로 함께 사용하여 모델의 상황 인지 능력을 높이거나, 정상 주행 데이터의 분포에서 벗어나는 이상 상황을 탐지(Anomaly Detection)하는 별도의 모듈을 결합하는 등의 연구가 활발히 진행되고 있다.18</p>
<h3>4.2 모듈형 아키텍처(인지-판단-제어) 테스트: CARLA Leaderboard 챌린지 사례</h3>
<p>현실의 자율주행 시스템은 대부분 인지(Perception), 판단(Planning), 제어(Control)의 여러 모듈이 결합된 복잡한 아키텍처를 가진다. CARLA는 이러한 모듈형 시스템의 각 구성 요소를 개별적으로 테스트하고, 전체 시스템을 통합하여 종합적으로 검증하는 강력한 테스트베드 역할을 수행한다.</p>
<p>그 대표적인 예가 <strong>CARLA Leaderboard 챌린지</strong>이다. 이는 전 세계 연구팀들이 자신들의 자율주행 스택을 CARLA가 제공하는 표준 시나리오 환경에서 경쟁적으로 평가받는 플랫폼이다. 2023년 Leaderboard 2.0 챌린지에서 우승한 Kyber-E2E 팀의 사례는 CARLA의 활용 가능성을 잘 보여준다.20</p>
<ul>
<li><strong>센싱(Sensing):</strong> RGB 카메라, 360도 LiDAR, Radar, GNSS, IMU 등 다양한 센서로부터 데이터를 융합하여 사용하였다.</li>
<li><strong>인지(Perception):</strong> 특히 교통 표지판 인식 성능을 높이기 위해, 단순한 CNN 모델을 넘어 OWL-ViT(Vision Transformer)나 ViLT(Vision-and-Language Transformer)와 같은 최첨단 비전-언어 모델을 활용하여 이미지 내의 텍스트와 기호를 해석했다.</li>
<li><strong>판단/계획(Planning):</strong> 전문가의 주행 데이터로부터 최적의 주행 정책을 학습하는 역강화학습(Inverse Reinforcement Learning, IRL) 기법을 모션 플래너에 적용하여, 복잡한 교통 상황에서 보다 인간과 유사하고 안전한 경로를 생성하도록 했다.</li>
</ul>
<p>이 사례는 CARLA가 단순히 개별 알고리즘의 성능을 측정하는 것을 넘어, 최신 AI 기술들이 총망라된 복잡한 자율주행 스택 전체의 실효성을 종합적으로 평가하고 검증하는 표준 플랫폼으로서 기능하고 있음을 명확히 보여준다.</p>
<h3>4.3 특수 환경 데이터셋 생성: 악천후, 센서 차단 시나리오</h3>
<p>자율주행 시스템의 안전성을 확보하기 위해서는 맑은 날의 이상적인 조건뿐만 아니라, 폭우, 안개, 야간 등 인지 시스템의 성능이 저하될 수 있는 악천후(adverse weather) 환경에서의 강건성을 검증해야 한다. 그러나 실제 세계에서 이러한 특정 조건의 데이터를 일관성 있게, 그리고 대량으로 수집하는 것은 매우 어렵고 위험하다.2</p>
<p>CARLA는 이러한 문제를 해결하는 데 매우 효과적인 솔루션을 제공한다. <strong>CARAIN 데이터셋 생성 사례</strong>는 그 대표적인 예다.21</p>
<ol>
<li><strong>원본 데이터 획득:</strong> 먼저 CARLA 시뮬레이터 내에서 맑은 날씨의 고속도로 주행 장면 이미지를 대량으로 획득한다.</li>
<li><strong>악천후 효과 합성:</strong> 획득한 원본 이미지에 강우량(<span class="math math-inline">mm/h</span>)에 따라 계산된 빗줄기 효과를 디지털 방식으로 합성하여, 다양한 강도의 폭우 상황 이미지를 생성한다.</li>
<li><strong>데이터 라벨링:</strong> 생성된 합성 이미지에 대해 차선 정보를 수동 또는 반자동으로 주석(Annotation) 처리하여, AI 모델 학습을 위한 정답 데이터를 만든다.</li>
<li><strong>성능 평가:</strong> 이렇게 구축된 ’가상 악천후 데이터셋’을 사용하여, 기존의 DNN 기반 차선 인식 알고리즘들의 성능이 강우량 증가에 따라 얼마나 급격히 저하되는지를 정량적으로 측정하고 분석한다.</li>
</ol>
<p>이 연구는 시뮬레이터가 단순히 존재하는 시나리오를 테스트하는 것을 넘어, 현실에서 얻기 힘든 ’가상의 데이터셋’을 창조하고, 이를 통해 특정 환경 요인이 시스템의 특정 모듈에 미치는 영향을 체계적으로 분석할 수 있음을 입증한 중요한 사례다.</p>
<h3>4.4 시나리오 기반 테스트: ScenarioRunner와 OpenSCENARIO</h3>
<p>자율주행 시스템의 안전성을 평가하기 위해서는 무작위적인 교통 흐름 속에서의 주행 능력뿐만 아니라, 사전에 정의된 특정 위험 시나리오에 대한 대응 능력을 검증하는 것이 필수적이다.</p>
<p><strong>ScenarioRunner</strong>는 이를 위해 CARLA가 공식적으로 제공하는 시나리오 실행 엔진이다. 사용자는 Python 스크립트나 표준화된 파일 형식을 통해 ‘전방 차량이 50m 앞에서 급정거하는 시나리오’, ‘사각지대에서 보행자가 무단횡단하는 시나리오’ 등 구체적인 테스트 케이스를 기술하고, 이를 CARLA 환경에서 자동으로 실행 및 평가할 수 있다.</p>
<p>특히 ScenarioRunner는 ASAM의 표준 시나리오 기술 언어인 <strong>OpenSCENARIO</strong>를 지원한다. 이는 시나리오의 재사용성과 이식성을 크게 높여, RoadRunner와 같은 외부 도구에서 생성한 시나리오를 CARLA에서 실행하거나 22, CARLA에서 검증된 시나리오를 다른 시뮬레이터 환경에서도 활용할 수 있는 기반을 제공한다.</p>
<p>더 나아가, <strong>ISS-Scenario 프레임워크</strong>와 같이 ScenarioRunner를 기반으로 시스템의 가장 취약한 지점을 능동적으로 찾아내는 연구도 활발하다.23 이 프레임워크는 시나리오의 매개변수(예: 상대 차량의 속도, 출현 타이밍)를 유전 알고리즘(Genetic Algorithm)과 같은 최적화 기법을 통해 변화시키면서, 시스템이 충돌하거나 오작동하는 ’실패 지점(failure case)’을 자동으로 탐색한다. 이는 수동적인 테스트 케이스 실행을 넘어, 시스템의 안전성을 보다 체계적이고 효율적으로 검증하는 진일보한 접근법이다.</p>
<p>이러한 활용 사례들은 CARLA가 ’재현성(Reproducibility)’과 ’확장성(Scalability)’이라는 과학적 연구의 핵심 가치를 자율주행 분야에 구현하고 있음을 보여준다. 전통적인 도로 테스트는 날씨, 주변 차량의 미세한 움직임 등 통제 불가능한 변수 때문에 동일한 조건을 완벽하게 재현하는 것이 불가능하다. 반면, CARLA는 Traffic Manager의 결정론적 모드 5와 ScenarioRunner를 통해 모든 조건을 완벽하게 통제하고 수천 번 반복 실행할 수 있는 ’재현성’을 보장한다. 또한 클라우드 플랫폼과 연계하여 수천 개의 시뮬레이션을 병렬로 실행하는 ’확장성’을 제공한다.24 이를 통해 CARLA는 자율주행 알고리즘 평가를 ’일회성 주행’에서 ’대규모 통계적 검증’으로 전환시켰으며, 이는 기술의 안전성을 객관적으로 입증하는 데 필수적인 패러다임의 변화라 할 수 있다.</p>
<h2>5.  CARLA 생태계: 확장과 통합</h2>
<p>CARLA의 진정한 힘은 단일 소프트웨어로서의 기능적 우수성을 넘어, 다양한 외부 도구 및 플랫폼과 유기적으로 결합하여 더 큰 가치를 창출하는 개방형 ’생태계’에 있다. CARLA는 모든 것을 스스로 해결하려 하기보다, 다른 전문 분야의 강력한 도구들과 쉽게 연결될 수 있는 ’인터페이스’를 제공하는 데 집중함으로써 자율주행 개발의 허브(Hub)로 자리매김했다.</p>
<h3>5.1 ROS 및 Autoware 연동: 로보틱스 세계와의 연결</h3>
<p>ROS(Robot Operating System)는 로봇 공학 분야의 사실상 표준 플랫폼으로, 수많은 알고리즘, 드라이버, 개발 도구로 구성된 방대한 생태계를 자랑한다. CARLA는 **<code>carla-ros-bridge</code>**라는 공식 브릿지를 통해 이 거대한 로보틱스 세계와 완벽하게 통합된다.</p>
<p><code>carla-ros-bridge</code>는 CARLA 시뮬레이터와 ROS 간의 양방향 통신을 중계한다.25</p>
<ul>
<li><strong>CARLA to ROS:</strong> CARLA의 가상 센서들(카메라, LiDAR, IMU 등)이 생성하는 데이터는 <code>carla-ros-bridge</code>를 통해 표준 ROS 메시지 형태로 변환되어, 각각의 ROS 토픽(Topic)으로 발행(Publish)된다. 예를 들어, 카메라 이미지는 <code>/carla/ego_vehicle/rgb_front/image_color</code>와 같은 토픽으로, LiDAR 포인트 클라우드는 <code>/carla/ego_vehicle/lidar</code> 토픽으로 실시간 스트리밍된다.</li>
<li><strong>ROS to CARLA:</strong> ROS 환경에서 동작하는 자율주행 알고리즘 노드(Node)가 계산한 제어 명령(조향각, 속도 등)은 특정 토픽(예: <code>/carla/ego_vehicle/vehicle_control_cmd</code>)으로 발행되고, 브릿지는 이 메시지를 구독(Subscribe)하여 CARLA 내의 차량 액터를 직접 제어한다.</li>
</ul>
<p>이러한 연동을 통해, 연구자들은 실제 로봇 하드웨어 없이도 ROS 기반으로 개발된 전체 자율주행 소프트웨어 스택을 CARLA의 사실적인 가상 환경에서 직접 테스트하고 디버깅할 수 있다. 특히, 대표적인 오픈소스 자율주행 스택인 <strong>Autoware</strong>와의 통합이 용이하여 , Autoware의 인지, 판단, 제어 모듈이 CARLA 환경에서 어떻게 작동하는지 검증하는 것이 가능하다. 또한, Rviz와 같은 ROS의 강력한 시각화 도구를 사용하여 시뮬레이션 중인 센서 데이터와 알고리즘의 중간 결과물을 실시간으로 모니터링할 수 있어 개발 및 디버깅 효율을 크게 향상시킨다.26</p>
<h3>5.2 타 시뮬레이션 도구와의 연동: 기능의 확장</h3>
<p>CARLA는 자신의 약점을 보완하고 기능을 확장하기 위해 다른 전문 시뮬레이션 도구와의 연동, 즉 **Co-simulation(협력 시뮬레이션)**을 적극적으로 지원한다.</p>
<ul>
<li><strong>CarSim 연동:</strong> CARLA의 가장 큰 약점 중 하나인 단순한 차량 물리 엔진을 보완하기 위한 가장 대표적인 사례다. 이 연동 환경에서 CARLA는 사실적인 3D 도로 환경과 가상 센서 데이터 제공에 집중하고, 차량 동역학 시뮬레이션 전문 소프트웨어인 CarSim은 전달받은 제어 입력과 도로 정보를 바탕으로 매우 정밀한 차량의 물리적 거동을 계산한다. CarSim이 계산한 차량의 새로운 위치와 자세 정보는 다시 CARLA로 전송되어 시각적으로 렌더링된다. 이 방식을 통해, CARLA의 기본 모델로는 구현하기 어려운 과속방지턱 통과 시의 정밀한 상하 움직임(vertical dynamics)이나 타이어의 슬립 현상 등을 시뮬레이션에 반영할 수 있어, Sim-to-Real 간극을 줄이는 데 크게 기여한다.27</li>
<li><strong>SUMO, VISSIM 연동:</strong> 거시적인 교통 흐름 시뮬레이션에 특화된 도구인 SUMO(Simulation of Urban MObility), PTV-Vissim과의 연동도 지원한다. CARLA의 Traffic Manager가 주변 차량의 미시적인 상호작용을 제어하는 데 강점이 있다면, SUMO나 VISSIM은 도시 전체의 교통 신호 최적화, 도로 용량 분석 등 거시적인 교통 공학 시뮬레이션에 강점이 있다. 이 둘을 연동함으로써, 자율주행차가 도시 전체의 교통 흐름에 미치는 영향을 분석하는 등 더욱 복잡하고 넓은 범위의 연구가 가능해진다.</li>
</ul>
<h3>5.3 CI/V&amp;V 플랫폼과의 연계: 개발 프로세스의 자동화</h3>
<p>자율주행 소프트웨어는 수백만 줄의 코드로 이루어진 복잡한 시스템으로, 새로운 기능을 추가하거나 버그를 수정할 때마다 기존 기능이 의도치 않게 손상되는 <strong>회귀(Regression)</strong> 문제가 발생할 위험이 크다. 이를 방지하기 위해, 코드 변경이 있을 때마다 수천 개의 테스트 시나리오를 자동으로 실행하여 시스템의 안전성과 성능을 지속적으로 검증하는 CI/V&amp;V(Continuous Integration / Verification &amp; Validation) 프로세스가 필수적이다.</p>
<p>Applied Intuition과 같은 상용 CI/V&amp;V 플랫폼들은 CARLA를 핵심 시뮬레이션 엔진 중 하나로 활용하여 이러한 개발 프로세스를 자동화한다.24 개발자가 새로운 코드를 버전 관리 시스템에 제출하면, 클라우드 기반의 CI 파이프라인이 자동으로 트리거된다. 이 파이프라인은 CARLA 시뮬레이터 상에서 수백, 수천 개의 정의된 테스트 시나리오를 병렬로 실행하고, 그 결과를 분석하여 시스템이 사전에 정의된 안전 요구사항(예: 충돌 없음, 차선 이탈 없음)을 모두 만족하는지 자동으로 리포트한다. 이처럼 CARLA를 CI/V&amp;V 파이프라인에 통합함으로써, 개발 주기를 획기적으로 단축하고 자율주행 소프트웨어의 신뢰성을 체계적으로 관리할 수 있다.</p>
<p>결론적으로, CARLA의 성공은 단일 소프트웨어의 우수성을 넘어 ‘개방형 생태계’ 전략의 승리라고 평가할 수 있다. CARLA는 그 자체로 완벽한 도구가 아니다. 물리 엔진은 부정확하고, 교통류 모델은 전문 도구보다 단순하며, 시나리오 관리 기능도 제한적이다. 하지만 CARLA 개발팀은 이 모든 것을 직접 개발하는 대신, <code>carla-ros-bridge</code>, Co-simulation 인터페이스 등 다른 전문 도구와 쉽게 ’연결’될 수 있는 표준화된 인터페이스를 제공하는 데 집중했다. 그 결과, CARLA는 자율주행 개발이라는 거대한 퍼즐의 ’중심 조각’이 되었다. 사용자들은 ROS 생태계의 방대한 알고리즘 라이브러리를 가져와 CARLA에 연결하고, CarSim의 정밀한 물리 엔진을 빌려오며, Applied Intuition의 관리 도구를 얹어 자신에게 필요한 최적의 개발 환경을 ’조립’할 수 있게 되었다. 이러한 플랫폼이자 허브로서의 역할이야말로 CARLA의 지속 가능성과 확장성을 담보하는 가장 중요한 자산이다.</p>
<h2>6.  비교 분석: 주요 자율주행 시뮬레이터와의 고찰</h2>
<p>자율주행 시뮬레이터 시장에는 CARLA 외에도 여러 대안이 존재해왔다. 이들과의 비교 분석을 통해 CARLA의 기술적 위상과 경쟁력을 객관적으로 평가할 수 있다. 특히 LGSVL(현 SVL)과 AirSim은 CARLA와 함께 오픈소스 진영을 대표했던 주요 시뮬레이터다.</p>
<h3>6.1 CARLA vs. LGSVL (현 SVL)</h3>
<ul>
<li><strong>공통점:</strong> LGSVL(LG Silicon Valley Lab) Simulator는 CARLA와 마찬가지로 자율주행 시스템 개발 및 테스트를 위한 오픈소스 시뮬레이터다. 특히 ROS/Autoware와의 높은 통합성을 목표로 설계되어, 시스템 통합 테스트에 강점을 보였다.</li>
<li><strong>차이점:</strong></li>
<li><strong>그래픽 엔진:</strong> 가장 큰 기술적 차이는 기반 엔진에 있다. CARLA는 언리얼 엔진을 사용하여 사실적인 그래픽 렌더링에 강점을 보이는 반면, LGSVL은 유니티(Unity) 엔진을 기반으로 개발되었다.</li>
<li><strong>개발 주체 및 현황:</strong> LGSVL은 LG전자에서 주도하여 개발했으나, 현재는 오픈소스 프로젝트로서의 개발 동력이 크게 약화된 상태다. 반면, CARLA는 활발한 오픈소스 커뮤니티의 기여와 함께 지속적인 버전 업데이트가 이루어지고 있어 프로젝트의 생명력 측면에서 큰 차이를 보인다.</li>
<li><strong>주요 초점:</strong> LGSVL은 Autoware 스택을 시뮬레이션 환경에서 구동하고 검증하는 데 특화된 경향이 있었다. 이에 비해 CARLA는 AI 모델 학습을 위한 데이터 생성, 유연한 시나리오 기반 테스트, 다양한 외부 도구와의 연동 등 더 넓은 범위의 연구 및 개발 생태계를 구축하는 데 성공했다.</li>
</ul>
<h3>6.2 CARLA vs. AirSim</h3>
<ul>
<li><strong>공통점:</strong> AirSim(Aerial Informatics and Robotics Simulation)은 Microsoft Research에서 개발한 오픈소스 시뮬레이터로, CARLA와 동일하게 언리얼 엔진을 사용하여 높은 수준의 그래픽 품질과 물리 기반 시뮬레이션을 제공한다.</li>
<li><strong>차이점:</strong></li>
<li><strong>지원 대상:</strong> AirSim의 가장 독보적인 특징은 지상의 차량뿐만 아니라 드론(UAV, Unmanned Aerial Vehicle)과 같은 공중 이동체 시뮬레이션을 포괄적으로 지원한다는 점이다. 이는 AirSim을 항공 로보틱스 연구에 매우 적합한 도구로 만들었다.</li>
<li><strong>환경 및 물리:</strong> AirSim은 고충실도(High-fidelity) 물리 시뮬레이션에 더 큰 중점을 두었으며, 대규모 환경 맵을 상대적으로 쉽게 추가할 수 있는 구조적 장점이 있었다.</li>
<li><strong>생태계 및 기능:</strong> 반면, CARLA는 자율주행 ’차량’에 특화된 기능들, 예를 들어 다양한 행동 패턴을 가진 보행자, 도시 교통 흐름을 제어하는 Traffic Manager, 시나리오 실행기(ScenarioRunner), 경쟁을 통한 성능 검증 플랫폼(Leaderboard) 등 도시 주행 환경의 동적인 요소를 시뮬레이션하고 평가하는 데 필요한 생태계가 훨씬 더 풍부하다.</li>
<li><strong>개발 현황:</strong> 가장 결정적인 차이는 프로젝트의 지속성이다. Microsoft는 2022년, 상용 클라우드 기반 플랫폼인 ’Project AirSim’에 집중하기 위해 오픈소스 AirSim 프로젝트의 공식적인 개발 및 지원을 중단했다. 소스 코드는 여전히 공개되어 있지만, 더 이상의 기능 추가나 공식적인 유지보수는 이루어지지 않고 있다.</li>
</ul>
<p>이러한 비교 분석은 현재 자율주행 시뮬레이터 시장이 단순한 ‘기술’ 경쟁을 넘어 ‘생태계의 지속성’ 경쟁으로 전환되었음을 명확히 보여준다. 과거에는 LGSVL, AirSim, CARLA가 각각 Autoware 통합, 드론 지원, 그래픽 품질 등 고유의 기술적 장점을 내세우며 경쟁했다. 그러나 LGSVL과 AirSim은 개발 주체 기업의 전략 변화로 인해 오픈소스 프로젝트로서의 성장 동력을 상실했다. 이는 아무리 뛰어난 기술이라도 지속적인 유지보수와 커뮤니티의 지원 없이는 결국 도태될 수 있음을 보여주는 사례다.</p>
<p>반면, CARLA는 특정 기업의 단기적 이익을 넘어 학계와 산업계가 함께 참여하는 강력하고 활발한 오픈소스 커뮤니티를 구축하는 데 성공했다. GitHub에서의 활발한 논의, 꾸준한 버전 릴리즈 5, Leaderboard와 같은 경쟁 플랫폼 운영 20 등이 이를 증명한다. 결과적으로, 연구자와 개발자가 시뮬레이터를 선택하는 기준은 더 이상 ’현재의 기능’에만 머무르지 않는다. ‘미래의 발전 가능성’, ‘문제 발생 시 도움을 받을 수 있는 커뮤니티의 존재’, ’지속적인 업데이트’와 같은 <strong>생태계의 건강성과 지속성</strong>이 훨씬 더 중요한 판단 기준이 되었다. 이러한 관점에서 CARLA는 경쟁자들을 압도하며 자율주행 연구 분야의 사실상 표준(De facto standard) 시뮬레이터로 자리 잡았다.</p>
<p>다음 표는 주요 오픈소스 자율주행 시뮬레이터의 핵심적인 특징을 비교 분석한 것이다.</p>
<table><thead><tr><th>구분</th><th>CARLA</th><th>LGSVL (SVL)</th><th>AirSim</th></tr></thead><tbody>
<tr><td><strong>개발 엔진</strong></td><td>Unreal Engine</td><td>Unity</td><td>Unreal Engine</td></tr>
<tr><td><strong>라이선스</strong></td><td>MIT (코드), CC-BY (에셋)</td><td>Apache 2.0</td><td>MIT</td></tr>
<tr><td><strong>개발 현황</strong></td><td><strong>활발 (Active Development)</strong></td><td><strong>비활발/중단 (Inactive)</strong></td><td><strong>개발 중단 (Discontinued)</strong></td></tr>
<tr><td><strong>주요 특징</strong></td><td>고품질 그래픽, 풍부한 센서, 동적 액터(보행자), Traffic Manager, 시나리오 실행기</td><td>Autoware 통합, 다중 로봇 시뮬레이션</td><td>차량 및 드론(UAV) 지원, 고충실도 물리 모델</td></tr>
<tr><td><strong>생태계</strong></td><td><strong>매우 풍부 (ROS Bridge, Leaderboard, ScenarioRunner, 다수 연동 사례)</strong></td><td>Autoware 중심</td><td>제한적</td></tr>
<tr><td><strong>적합 분야</strong></td><td>AI 모델 학습/검증, 데이터셋 생성, 복잡한 도시 시나리오 테스트</td><td>Autoware 기반 시스템 통합 테스트</td><td>드론 및 항공 로보틱스 연구, 물리 기반 제어 알고리즘</td></tr>
<tr><td><strong>장점</strong></td><td>활발한 커뮤니티, 지속적 업데이트, 풍부한 문서, 높은 유연성</td><td>간편한 Autoware 연동</td><td>드론 지원, HIL/SIL 지원</td></tr>
<tr><td><strong>단점</strong></td><td>단순한 차량 동역학 모델, 높은 시스템 요구사양</td><td>개발 불확실성, 제한된 기능 확장</td><td>개발 중단, 도시 동적 요소 부족</td></tr>
</tbody></table>
<h2>7.  한계점 및 도전 과제 분석</h2>
<p>CARLA는 자율주행 연구에 지대한 공헌을 했지만, 완벽한 도구는 아니며 몇 가지 명백한 한계점과 기술적 도전 과제를 안고 있다. 이러한 한계를 명확히 인지하는 것은 시뮬레이션 결과를 올바르게 해석하고, Sim-to-Real 문제를 해결하기 위한 첫걸음이다.</p>
<h3>7.1 물리 엔진의 한계: 저자유도 모델의 동특성 문제</h3>
<p>CARLA의 가장 빈번하게 지적되는 약점은 차량 동역학 모델의 정밀성이 부족하다는 점이다.27 앞서 언급했듯, CARLA의 기본 차량 모델은 언리얼 엔진의 범용 물리 엔진인 PhysX와 키네마틱 모델에 기반한다. 이 모델은 일반적인 주행 상황을 근사적으로 모사할 수는 있지만, 실제 차량의 복잡한 동적 특성(dynamic characteristics)을 정밀하게 반영하지 못한다.</p>
<p>예를 들어, 급격한 조향 시 발생하는 타이어의 측면 슬립(side slip), 노면 상태에 따른 접지력 변화, 제동 시 무게 중심 이동으로 인한 노즈 다이브(nose-dive) 현상, 서스펜션의 정교한 움직임 등은 CARLA의 저자유도(low-fidelity) 모델로는 정확한 시뮬레이션이 어렵다.27 이로 인해, CARLA 시뮬레이션 환경에서 완벽하게 안정적으로 작동하던 제어 알고리즘이 실제 차량에 탑재되었을 때에는 예상치 못한 진동이나 불안정한 거동을 보이는 심각한 **‘Sim-to-Real Gap’**을 유발할 수 있다.</p>
<p>이 문제를 극복하기 위한 가장 현실적인 방안은 CarSim, VI-Grade, IPG CarMaker와 같은 고정밀 차량 동역학 전문 시뮬레이터와의 연동(Co-simulation)이다.27 이러한 하이브리드 접근법을 통해, CARLA는 자신의 강점인 사실적인 환경 및 센서 모델링에 집중하고, 차량의 정밀한 물리 거동 계산은 전문 도구에 위임함으로써 시뮬레이션의 전체적인 신뢰도를 높일 수 있다.</p>
<h3>7.2 성능 문제: 대규모 시뮬레이션의 병목 현상</h3>
<p>언리얼 엔진 기반의 고품질 그래픽 렌더링은 CARLA의 큰 장점이지만, 동시에 높은 컴퓨팅 자원을 요구하는 원인이 되기도 한다. CARLA를 원활하게 구동하기 위해서는 최소 6GB, 권장 8GB 이상의 VRAM을 갖춘 고성능 GPU가 필수적이다.</p>
<p>특히 대규모 맵에서 수십, 수백 대의 차량과 다수의 고해상도 센서(카메라, LiDAR 등)를 동시에 시뮬레이션할 경우, 초당 프레임 수(FPS)가 급격히 저하되는 성능 병목 현상이 발생할 수 있다. 이는 실시간 상호작용이 중요한 테스트나, 빠른 반복 학습이 필수적인 강화학습 환경에서 큰 제약이 된다.</p>
<p>CARLA는 이러한 성능 문제를 완화하기 위한 몇 가지 옵션을 제공한다.</p>
<ul>
<li><strong>No-Rendering Mode:</strong> 그래픽 렌더링 과정을 완전히 비활성화하여, 오직 물리 연산과 API 통신만 수행하는 모드다. 시각적 확인이 필요 없는 대규모 데이터 수집이나 제어/계획 알고리즘의 빠른 로직 검증에 매우 유용하다.</li>
<li><strong>품질 수준 조정:</strong> 시뮬레이터 실행 시 <code>-quality-level=Low</code> 옵션을 부여하여 렌더링 품질을 낮춤으로써 시스템 부하를 줄이고 성능을 확보할 수 있다.</li>
</ul>
<h3>7.3 현실과의 간극(Sim-to-Real Gap): 완벽한 모사는 불가능하다</h3>
<p>모든 시뮬레이터는 현실 세계의 복잡성을 어느 정도 추상화하고 단순화할 수밖에 없으며, 이로 인해 발생하는 ’현실과의 간극’은 CARLA 역시 피할 수 없는 근본적인 도전 과제다.</p>
<ul>
<li><strong>센서 노이즈 모델링의 한계:</strong> CARLA는 가우시안 노이즈 등 기본적인 센서 노이즈 모델을 제공하지만 , 현실 세계의 복잡하고 비정형적인 노이즈를 완벽하게 재현하지는 못한다. 예를 들어, 카메라 센서의 경우 렌즈에 묻은 빗방울이나 흙먼지로 인한 왜곡, 역광 상황에서의 플레어(flare) 현상 등을 모델링하기 어렵다. LiDAR 센서 역시 비나 안개, 먼지와 같은 대기 중 입자에 의한 레이저 빔의 산란(scattering) 및 흡수 효과를 정밀하게 시뮬레이션하는 데 한계가 있다.21</li>
<li><strong>복잡한 상호작용의 부재:</strong> CARLA의 Traffic Manager와 보행자 AI는 상당한 수준의 현실성을 보여주지만, 도시 환경의 무한한 복잡성을 모두 포착하지는 못한다. 다른 운전자와의 비언어적 소통(눈 맞춤, 손짓), 예측 불가능한 돌발 행동, 복잡한 교차로에서의 암묵적인 양보 규칙 등은 현재의 기술로 모델링하기 매우 어려운 영역이다.</li>
<li><strong>도메인 차이(Domain Gap):</strong> 시뮬레이션으로 생성된 이미지는 아무리 사실적이라도 실제 카메라로 촬영한 이미지와는 픽셀 레벨에서 미세한 차이(텍스처, 조명, 색감 등)를 가진다. 이러한 ’도메인 차이’로 인해, 시뮬레이션 데이터로만 학습된 딥러닝 인지 모델은 실제 환경 데이터에 적용했을 때 성능이 크게 저하되는 경향이 있다. 이 간극을 줄이기 위해, 렌더링 파라미터를 무작위로 변경하여 모델의 일반화 성능을 높이는 **도메인 무작위화(Domain Randomization)**나, 두 도메인의 데이터 분포를 유사하게 만드는 **도메인 적응(Domain Adaptation)**과 같은 추가적인 기법이 요구된다.</li>
</ul>
<h3>7.4 사용상의 문제점 및 알려진 버그</h3>
<p>오픈소스 프로젝트로서 CARLA는 지속적으로 개선되고 있지만, 사용 과정에서 몇 가지 불편함이나 버그가 보고되기도 한다. 예를 들어, 특정 버전에서는 카메라 센서의 데이터 전송이 갑자기 중단되거나, IMU 센서의 중력 측정값에 오류가 발생하는 등의 버그가 존재했으며, 이는 후속 버전에서 수정되었다. 또한, Python API를 코드 편집기에서 사용할 때 자동 완성(auto-completion) 기능이 원활하게 작동하지 않아 개발 편의성이 떨어지는 문제가 지적되기도 한다.28 시뮬레이터를 비정상적으로 종료할 경우 프로세스가 완전히 정리되지 않아 시스템이 멈추는 현상도 빈번하게 발생한다.28 Autoware와 연동하여 신호등 인식 기능을 테스트할 때, 시뮬레이션을 재시작하면 신호등의 내부 ID가 변경되어 매번 수동으로 매핑을 다시 해주어야 하는 번거로움도 보고된 바 있다.29</p>
<p>이러한 CARLA의 한계점들은 그 자체의 결함이라기보다, 시뮬레이션 기술 본연의 내재적 딜레마인 **‘정밀도(Fidelity) vs. 확장성(Scalability)’**의 문제를 드러낸다. CARLA는 물리 엔진의 정밀도를 일부 희생하는 대신, 수백 대의 차량을 동시에 시뮬레이션할 수 있는 확장성을 얻었다. 센서 모델의 완벽한 현실성을 추구하기보다, 실시간 성능을 유지하는 범위 내에서의 근사를 택했다. 이 딜레마는 CARLA만의 문제가 아니라 모든 시뮬레이터가 직면한 근본적인 트레이드오프다. 따라서 CARLA를 평가할 때는 ’왜 모든 것이 현실과 똑같지 않은가?’라는 질문 대신, ’주어진 목표(AI 학습, 대규모 시나리오 테스트)를 달성하기 위해 정밀도와 확장성 사이에서 어떤 현명한 선택을 했는가?’라는 관점으로 접근해야 한다. CARLA의 진정한 가치는 이 딜레마에 대한 성공적인 해답을 제시하고, 사용자가 Co-simulation 등을 통해 스스로 그 균형점을 조절할 수 있는 유연성을 제공했다는 데 있다.</p>
<h2>8.  결론: CARLA의 현재 위상과 미래 발전 방향</h2>
<h3>8.1 연구 및 산업계에 미친 영향 요약</h3>
<p>CARLA는 지난 몇 년간 자율주행 기술 생태계에 지대한 영향을 미치며, 단순한 시뮬레이션 도구를 넘어 연구와 개발의 패러다임을 전환하는 핵심 플랫폼으로 자리 잡았다. 그 영향을 요약하면 다음과 같다.</p>
<p>첫째, <strong>연구의 민주화</strong>를 실현했다. 고품질의 시뮬레이션 환경과 디지털 에셋을 오픈소스로 제공함으로써, 막대한 자본 투자 없이도 누구나 최첨단 자율주행 연구에 참여할 수 있는 길을 열었다.</p>
<p>둘째, <strong>데이터 기반 AI 개발 방법론을 확산</strong>시켰다. 현실에서 수집하기 어려운 위험 시나리오나 악천후 조건의 데이터를 대량으로 생성할 수 있게 함으로써, 모방학습 및 강화학습과 같은 AI 모델의 발전을 가속화했다.</p>
<p>셋째, <strong>알고리즘 성능 평가의 표준을 제시</strong>했다. CARLA Leaderboard와 같은 플랫폼을 통해, 전 세계 연구팀들이 공정하고 재현 가능한 환경에서 자신들의 자율주행 스택을 객관적으로 평가하고 경쟁할 수 있는 기준을 마련했다.</p>
<p>넷째, <strong>강력한 개방형 생태계를 구축</strong>했다. ROS, Autoware, CarSim 등 외부 전문 도구와의 유연한 연동을 지원함으로써, CARLA를 중심으로 한 확장 가능한 개발 환경을 조성하고 기술 공유의 선순환 구조를 만들었다.</p>
<h3>8.2 최신 기술 동향 및 개발 로드맵</h3>
<p>CARLA는 현재의 성공에 안주하지 않고, 활발한 커뮤니티와 개발팀을 중심으로 지속적인 발전을 거듭하고 있다. 공식 로드맵과 최근 릴리즈 노트를 통해 다음과 같은 미래 발전 방향을 엿볼 수 있다.</p>
<ul>
<li><strong>언리얼 엔진 5로의 전환:</strong> 가장 주목할 만한 변화는 차세대 게임 엔진인 언리얼 엔진 5.5로의 메이저 업데이트다. 이는 가상 메시 시스템인 ’나나이트(Nanite)’와 실시간 글로벌 일루미네이션 기술인 ‘루멘(Lumen)’ 등을 활용하여, 시뮬레이션의 시각적 사실성을 이전과는 비교할 수 없는 수준으로 끌어올릴 잠재력을 가지고 있다. 이는 Sim-to-Real 간극을 줄이는 데 크게 기여할 것으로 기대된다.</li>
<li><strong>지속적인 기능 및 에셋 확장:</strong> 최근 0.9.15 버전 릴리즈에서는 100km² 규모의 새로운 대규모 맵(Town13)과 유럽형 대형 트럭(HGV) 모델이 추가되었으며, OSM 데이터로부터 맵을 절차적으로 생성하는 실험적인 도구가 도입되었다. 이처럼 Traffic Manager의 지능 향상, 새로운 센서 모델 추가, 물리 엔진 개선, 버그 수정 등 내실을 다지는 작업이 꾸준히 이루어지고 있다.5</li>
<li><strong>외부 플랫폼과의 연계 강화:</strong> NVIDIA Omniverse와 같은 3D 협업 및 시뮬레이션 플랫폼과의 통합을 모색하는 움직임은  CARLA 생태계가 단순히 자율주행 분야를 넘어, 더 넓은 디지털 트윈 및 가상 세계 구축 기술과 융합하려는 방향성을 보여준다.</li>
</ul>
<h3>8.3 자율주행 시뮬레이션 기술의 미래 전망</h3>
<p>CARLA의 발전을 통해 본 자율주행 시뮬레이션 기술은 앞으로 다음과 같은 방향으로 진화할 것으로 전망된다.</p>
<ul>
<li><strong>초현실주의(Hyper-realism) 추구:</strong> 렌더링 기술과 물리 엔진의 발전은 시뮬레이션과 현실의 경계를 점차 허물 것이다. 실시간 레이 트레이싱, AI 기반 텍스처 생성 기술 등은 시각적 사실성을 극대화할 것이다.</li>
<li><strong>하이브리드 시뮬레이션의 보편화:</strong> CARLA와 같은 환경/센서 시뮬레이터, CarSim과 같은 고정밀 동역학 시뮬레이터, SUMO와 같은 거시 교통류 시뮬레이터를 유기적으로 결합하는 하이브리드 방식이 표준 개발 환경으로 자리 잡을 것이다.</li>
<li><strong>AI 기반 시나리오 생성:</strong> 사전에 정의된 시나리오를 수동으로 실행하는 단계를 넘어, AI가 자율주행 시스템의 취약점을 스스로 찾아내기 위해 가장 위험하고 도전적인 시나리오를 자동으로 생성하고 최적화하는 기술(Adversarial Scenario Generation)이 안전성 검증의 핵심으로 부상할 것이다.</li>
<li><strong>디지털 트윈(Digital Twin)으로의 확장:</strong> 실제 도시나 특정 테스트베드를 정밀하게 가상 공간에 복제한 디지털 트윈 환경에서의 시뮬레이션이 더욱 중요해질 것이다. 이를 통해 실제 도로에서 테스트하기 전, 가상 복제 공간에서 수백만 km의 주행 테스트를 수행하여 안전성을 사전에 확보할 수 있다.</li>
</ul>
<h3>8.4 최종 고찰</h3>
<p>CARLA는 자율주행 기술 개발의 패러다임을 바꾼 혁신적인 도구임이 분명하다. 개방성과 유연성을 무기로 연구의 진입 장벽을 낮추고, 전 세계 수많은 연구자들의 집단 지성을 통해 발전하는 성공적인 오픈소스 생태계의 모델을 제시했다.</p>
<p>그러나 우리는 시뮬레이션이 현실을 ’대체’하는 마법의 도구가 아니라, 현실 세계의 테스트를 ’보완’하고 ’가속화’하는 도구임을 항상 명심해야 한다. CARLA의 강점인 데이터 생성 능력과 시나리오 테스트 유연성을 극대화하는 동시에, 그 내재적 한계인 Sim-to-Real 간극을 명확히 인지해야 한다. 시뮬레이션 결과를 비판적으로 분석하고, 도메인 적응 기법을 적용하며, 최종적으로는 실제 도로에서의 검증을 통해 그 간극을 메우려는 노력을 병행할 때, 우리는 CARLA라는 강력한 도구를 발판 삼아 더 안전하고 신뢰할 수 있는 자율주행 기술의 미래에 한 걸음 더 다가갈 수 있을 것이다.</p>
<h2>9. 참고 자료</h2>
<ol>
<li>[논문 리뷰] ISS-Scenario: Scenario-based Testing in CARLA - Moonlight, accessed August 20, 2025, https://www.themoonlight.io/ko/review/iss-scenario-scenario-based-testing-in-carla</li>
<li>한국자동차공학회, accessed August 20, 2025, <a href="https://www.ksae.org/journal_list/search_index.php?mode=view&amp;sid=53066&amp;gubun=2&amp;year=2023&amp;month=11&amp;issue=0&amp;number=0&amp;page=45&amp;page_pre&amp;kwon_title=JUVDJUI2JTk0JUVBJUIzJTg0JUVEJTk1JTk5JUVDJTg4JUEwJUVCJThDJTgwJUVEJTlBJThD">https://www.ksae.org/journal_list/search_index.php?mode=view&amp;sid=53066&amp;gubun=2&amp;year=2023&amp;month=11&amp;issue=0&amp;number=0&amp;page=45&amp;page_pre=&amp;kwon_title=JUVDJUI2JTk0JUVBJUIzJTg0JUVEJTk1JTk5JUVDJTg4JUEwJUVCJThDJTgwJUVEJTlBJThD</a></li>
<li>Maps - CARLA Simulator, accessed August 20, 2025, https://carla.readthedocs.io/en/latest/core_map/</li>
<li>CARLA Simulator, accessed August 20, 2025, https://carla.org/</li>
<li>경로 추종 시뮬레이티드 운전 차량의 영상 기반 행동 학습을 위한 심층신경망 모델 - AURIC, accessed August 20, 2025, http://journal.auric.kr/kiee/XmlViewer/f396690</li>
<li>(CARLA) 1. PythonAPI를 이용해서 CARLA 사용하기 - 자동차 설계하기.., accessed August 20, 2025, https://kimbrain.tistory.com/515</li>
<li>Development of High-Fidelity Automotive LiDAR Sensor Model with Standardized Interfaces, accessed August 20, 2025, https://www.mdpi.com/1424-8220/22/19/7556</li>
<li>A Comparative Analysis of CARLA and AirSim Simulators: Investigating Implementation Challenges in Autonomous Driving - Longdom Publishing, accessed August 20, 2025, https://www.longdom.org/open-access/a-comparative-analysis-of-carla-and-airsim-simulators-investigating-implementation-challenges-in-autonomous-driving-1101912.html</li>
<li>CARLA 시뮬레이터 기반 합성 평가 데이터셋을 활용한 극한 폭우 상황에서의 심층 신경망을 - Korea Science, accessed August 20, 2025, https://koreascience.kr/article/JAKO202405136180753.pdf</li>
<li>다중 신경망 기반 Carla simulator 자율주행 성능개선, accessed August 20, 2025, https://lib.kau.ac.kr/mir.liberty.file/libertyfile/contents/0000000002/20220106035239503NZ9I6HQOIG.pdf</li>
<li>carla 0.9.12 - 캔버슬릭의 블로그 It is all doable - 티스토리, accessed August 20, 2025, https://rinpoche.tistory.com/3</li>
<li>A Survey on Simulators for Testing Self-Driving Cars - ResearchGate, accessed August 20, 2025, https://www.researchgate.net/publication/353695427_A_Survey_on_Simulators_for_Testing_Self-Driving_Cars</li>
<li>CARLA+: An Evolution of the CARLA Simulator for Complex Environment Using a Probabilistic Graphical Model - MDPI, accessed August 20, 2025, https://www.mdpi.com/2504-446X/7/2/111</li>
<li>CARLA [0.9.X] 실행 방법 - GitHub, accessed August 20, 2025, https://github.com/BenMSK/Carla_log</li>
<li>Carla Scenario and Casezoo Evaluation — DI-drive 0.3.4 documentation - GitHub Pages, accessed August 20, 2025, https://opendilab.github.io/DI-drive/features/casezoo.html</li>
<li>Carla 연동 자율주행 시나리오 편집기 개발 - 한국자동차공학회, accessed August 20, 2025, <a href="https://www.ksae.org/func/download_journal.php?path=L2hvbWUvdmlydHVhbC9rc2FlL2h0ZG9jcy91cGxvYWQvam91cm5hbC8yMDIwMDgyMjE2MDYxNC4yMzAuNS4yLnBkZg%3D%3D&amp;filename=MjBTS1NBRV9EMDIwLnBkZg%3D%3D&amp;bsid=47153">https://www.ksae.org/func/download_journal.php?path=L2hvbWUvdmlydHVhbC9rc2FlL2h0ZG9jcy91cGxvYWQvam91cm5hbC8yMDIwMDgyMjE2MDYxNC4yMzAuNS4yLnBkZg==&amp;filename=MjBTS1NBRV9EMDIwLnBkZg==&amp;bsid=47153</a></li>
<li>[Lab Meeting] MPC 기반 차량 경로 추종 제어기Carla Simulator 구현 - YouTube, accessed August 20, 2025, https://www.youtube.com/watch?v=pNXzbjuuVS0</li>
<li>시뮬레이터와 차량 모델 통합 및 검증 CARLA … - 한국자동차공학회, accessed August 20, 2025, <a href="https://ksae.org/func/download_journal.php?path=L2hvbWUvdmlydHVhbC9rc2FlL2h0ZG9jcy91cGxvYWQvam91cm5hbC8yMDI1MDMxNDEzNDQxNy42MDkzLjkuMy5wZGY%3D&amp;filename=MjRBS1NBRV9KMDE1LnBkZg%3D%3D&amp;bsid=55386">https://ksae.org/func/download_journal.php?path=L2hvbWUvdmlydHVhbC9rc2FlL2h0ZG9jcy91cGxvYWQvam91cm5hbC8yMDI1MDMxNDEzNDQxNy42MDkzLjkuMy5wZGY=&amp;filename=MjRBS1NBRV9KMDE1LnBkZg==&amp;bsid=55386</a></li>
<li>자율주행차 연구개발의 민주화를 위한 CARLA - CoPlay, accessed August 20, 2025, https://www.coplay.kr/en/community/posts/259</li>
<li>[Carla Project] Localization-1: Kalman Filter based IMU GPS Fusion Localization - gyeongtiger 님의 블로그 - 티스토리, accessed August 20, 2025, https://gyeongtiger.tistory.com/24</li>
<li>carla-simulator/carla: Open-source simulator for autonomous driving research. - GitHub, accessed August 20, 2025, https://github.com/carla-simulator/carla</li>
<li>
<ol start="2">
<li>CARLA튜토리얼 - CVAD - 티스토리, accessed August 20, 2025, https://cvad.tistory.com/7</li>
</ol>
</li>
<li>자율 주행 시스템을 위한 테스트 시나리오 개발 - MATLAB &amp; Simulink - MathWorks, accessed August 20, 2025, https://www.mathworks.com/videos/design-and-simulate-scenarios-for-automated-driving-application-1655370916390.html</li>
<li>There is also… AirSim from Microsoft - https://github.com/microsoft/airsim Gaz… | Hacker News, accessed August 20, 2025, https://news.ycombinator.com/item?id=15721311</li>
<li>C++ Carla client - velog, accessed August 20, 2025, <a href="https://velog.io/@nabi4622/libCarla-%EB%B9%8C%EB%93%9C%EA%B3%BC%EC%A0%95">https://velog.io/@nabi4622/libCarla-%EB%B9%8C%EB%93%9C%EA%B3%BC%EC%A0%95</a></li>
<li>CARLA Version Releases 번역 - 이승민의 개발 블로그, accessed August 20, 2025, https://minsdevblog.tistory.com/12</li>
<li>[ROS 시뮬레이터] Autonomous Car Simulator : Carla 환경 구성 및 설치 / 기본 예제 살펴보기 (trouble shooting failed), accessed August 20, 2025, https://saint-swithins-day.tistory.com/54</li>
<li>[자율주행 시뮬레이터] CARLA 서버·클라이언트 생성하기 | 정리하여 …, accessed August 20, 2025, https://hchoi256.github.io/cv/carla-lt1/</li>
<li>[현대제어강의]자율주행 시뮬레이터 Carla Simulator 소개 - YouTube, accessed August 20, 2025, https://www.youtube.com/watch?v=z_oulQggw68</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>