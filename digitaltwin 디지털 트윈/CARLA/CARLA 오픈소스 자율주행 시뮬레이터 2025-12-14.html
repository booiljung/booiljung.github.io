<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:CARLA 오픈소스 자율주행 시뮬레이터</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>CARLA 오픈소스 자율주행 시뮬레이터</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">디지털트윈 (Digital Twins)</a> / <a href="index.html">CARLA 오픈소스 자율주행 시뮬레이터</a> / <span>CARLA 오픈소스 자율주행 시뮬레이터</span></nav>
                </div>
            </header>
            <article>
                <h1>CARLA 오픈소스 자율주행 시뮬레이터</h1>
<p>2025-12-14, G30DR</p>
<h2>1.  서론</h2>
<p>자율주행 자동차(Autonomous Vehicle, AV) 기술은 현대 교통 시스템의 패러다임을 전환할 핵심 기술로 부상하고 있다. 인공지능, 특히 딥러닝 기반의 인지, 판단, 제어 알고리즘의 비약적인 발전은 완전 자율주행의 실현 가능성을 높이고 있다. 그러나 이러한 시스템을 실제 도로 환경에서 개발하고 검증하는 과정은 막대한 비용과 시간, 그리고 무엇보다 안전상의 위험을 수반한다. 실제 주행 데이터 수집은 물리적 한계로 인해 다양한 날씨 조건, 조명 변화, 그리고 희귀하게 발생하는 사고 상황(Corner Cases/Edge Cases)을 충분히 커버하기 어렵다는 근본적인 문제를 안고 있다.</p>
<p>이러한 배경에서 고정밀 가상 시뮬레이터는 자율주행 연구 개발 파이프라인의 필수 불가결한 요소로 자리 잡았다. 시뮬레이터를 통해 연구자들은 물리적 제약 없이 다양한 시나리오를 반복적으로 테스트하고, 알고리즘의 안전성을 검증하며, 대규모 데이터를 생성하여 인공지능 모델을 학습시킬 수 있다.</p>
<p>본 보고서에서 심층적으로 다루게 될 <strong>CARLA(Car Learning to Act)</strong> 시뮬레이터는 이러한 요구에 부응하기 위해 개발된 오픈 소스 플랫폼이다. 인텔 랩스(Intel Labs), 컴퓨터 비전 센터(CVC), 도요타 연구소(TRI) 등의 지원 하에 개발된 CARLA는 언리얼 엔진(Unreal Engine)을 기반으로 구축되어 시각적으로 매우 사실적인 환경을 제공하며, 유연한 Python API를 통해 시뮬레이션의 모든 측면을 정밀하게 제어할 수 있는 기능을 제공한다.1</p>
<p>본 연구 보고서는 CARLA 시뮬레이터의 아키텍처, 핵심 기능, 물리 엔진, 센서 모델링, 그리고 ROS(Robot Operating System) 및 Autoware와 같은 외부 시스템과의 통합 방법론을 망라한다. 또한, 자율주행 알고리즘의 정량적 평가를 위한 시나리오 러너(ScenarioRunner)와 리더보드(Leaderboard) 시스템의 평가 지표를 심층 분석하여, 연구자와 개발자가 CARLA를 활용하여 자율주행 시스템의 신뢰성을 확보하는 데 필요한 실질적이고 구체적인 지식을 제공하는 것을 목적으로 한다.</p>
<h2>2.  시스템 아키텍처 및 핵심 디자인</h2>
<p>CARLA의 설계 철학은 확장성(Scalability), 유연성(Flexibility), 그리고 사실성(Realism)에 기반한다. 이를 구현하기 위해 CARLA는 고도로 모듈화된 <strong>서버-클라이언트(Server-Client)</strong> 아키텍처를 채택하고 있다. 이 구조는 시뮬레이션의 물리 연산 및 렌더링 부하를 분산시키고, 사용자가 다양한 환경에서 시뮬레이터에 접근하여 제어할 수 있는 유연성을 보장한다.2</p>
<h3>2.1  서버-클라이언트 통신 모델</h3>
<p>CARLA 시스템의 핵심은 월드(World)를 관장하는 서버와, 이 월드에 개입하는 클라이언트 간의 상호작용이다.</p>
<ul>
<li><strong>서버(The Server):</strong> 서버는 시뮬레이션의 물리적 세계를 구현하는 주체이다. 언리얼 엔진(Unreal Engine 4 또는 5) 위에서 구동되며, 3D 장면의 렌더링, 강체 역학(Rigid Body Dynamics) 및 충돌 처리, 센서 데이터 생성(Ray-casting 등)을 전담한다. 서버는 클라이언트로부터 전달받은 제어 명령을 다음 시간 단계(Time Step)에 반영하고, 그 결과로 변화된 월드의 상태(차량 위치, 센서 이미지 등)를 클라이언트에게 전송한다.4</li>
<li><strong>클라이언트(The Client):</strong> 클라이언트는 사용자가 작성한 스크립트(주로 Python)로 구동된다. 클라이언트는 서버에 TCP/IP 프로토콜을 통해 연결되며, 월드에 새로운 차량이나 보행자를 생성(Spawn)하거나, 날씨를 변경하고, 특정 차량에 제어 명령(조향, 가속, 제동)을 내리는 역할을 수행한다. CARLA는 <strong>멀티 클라이언트(Multi-Client)</strong> 구조를 지원하여, 하나의 서버에 여러 개의 클라이언트가 동시에 접속하여 서로 다른 차량을 제어하거나 트래픽을 관리할 수 있다.2</li>
</ul>
<h4>2.1.1 통신 프로토콜 및 포트 구성</h4>
<p>CARLA는 기본적으로 두 개의 TCP 포트를 사용하여 통신을 수행한다.</p>
<ol>
<li><strong>명령 제어 포트 (기본값 2000):</strong> 클라이언트가 서버에 접속하여 월드 설정을 변경하거나 액터를 제어하는 RPC(Remote Procedure Call) 명령을 전송하는 데 사용된다.</li>
<li><strong>데이터 스트리밍 포트 (기본값 2001):</strong> 카메라 이미지, LiDAR 포인트 클라우드 등 대용량의 센서 데이터를 서버에서 클라이언트로 고속 전송하는 데 사용된다. 이 포트는 2000번 포트에 오프셋(+1)을 적용하여 자동으로 설정된다.4</li>
</ol>
<p>이러한 이원화된 포트 구조는 제어 신호의 지연(Latency)을 최소화하면서도 대역폭을 많이 차지하는 센서 데이터를 안정적으로 전송하기 위한 설계적 선택이다.</p>
<h3>2.2  동기화 모델: 동기 모드와 비동기 모드</h3>
<p>시뮬레이션의 시간 흐름과 실제 시간의 관계, 그리고 서버와 클라이언트 간의 데이터 교환 타이밍을 결정하는 동기화 모델은 CARLA 활용에 있어 가장 중요한 개념 중 하나이다.4</p>
<h4>2.2.1 비동기 모드 (Asynchronous Mode)</h4>
<p>비동기 모드는 CARLA의 기본 실행 설정이다. 이 모드에서 서버는 클라이언트의 명령 수신 여부와 관계없이 자신의 연산 속도에 맞춰 최대한 빠르게 시뮬레이션 시간을 진행시킨다.</p>
<ul>
<li><strong>특징:</strong> 서버는 클라이언트가 연산을 마칠 때까지 기다리지 않는다. 따라서 클라이언트의 처리 속도가 느리거나 네트워크 지연이 발생할 경우, 클라이언트는 일부 프레임을 놓칠 수 있다.</li>
<li><strong>용도:</strong> 시뮬레이션 월드를 자유롭게 탐색하거나, 엄격한 시간 동기화가 필요 없는 실험, 혹은 사람이 직접 주행 연습을 할 때 적합하다.</li>
<li><strong>한계:</strong> 센서 데이터 수집과 제어 명령 간의 시간 차이가 일정하지 않아(Non-deterministic), 동일한 코드를 실행해도 매번 다른 결과가 나올 수 있어 자율주행 알고리즘의 검증용으로는 부적합할 수 있다.</li>
</ul>
<h4>2.2.2 동기 모드 (Synchronous Mode)</h4>
<p>동기 모드는 자율주행 시스템의 학습 및 검증에 필수적인 모드이다. 이 모드에서 서버는 클라이언트로부터 <strong>‘Tick’</strong> 신호(다음 프레임으로 진행하라는 명령)를 받을 때까지 대기 상태를 유지한다.</p>
<ul>
<li><strong>메커니즘:</strong> 클라이언트는 서버에 시뮬레이션 설정을 변경하여 동기 모드를 활성화한다. 이후 클라이언트 코드 내에서 <code>world.tick()</code> 함수를 호출해야만 시뮬레이션 시간이 <code>fixed_delta_seconds</code>만큼 전진한다.</li>
<li><strong>장점:</strong> 서버와 클라이언트 간의 완벽한 동기화를 보장한다. 클라이언트가 딥러닝 모델 추론 등 무거운 연산을 수행하더라도, 서버는 그 연산이 끝날 때까지 멈춰 있으므로 데이터 손실이 발생하지 않는다.</li>
<li><strong>결정론적 실행(Determinism):</strong> 물리 엔진의 연산 주기를 고정함으로써, 동일한 초기 조건과 제어 입력을 주었을 때 항상 동일한 시뮬레이션 결과를 얻을 수 있다. 이는 알고리즘 디버깅과 회귀 테스트(Regression Test)에 매우 중요하다.7</li>
</ul>
<h3>2.3  언리얼 엔진 기반의 물리 및 렌더링</h3>
<p>CARLA는 에픽 게임즈(Epic Games)의 언리얼 엔진(Unreal Engine)을 기반으로 구축되었다. 현재 안정화 버전은 UE4(4.26)를 사용하며, 최신 개발 브랜치는 UE5(5.5)로의 전환을 진행 중이다.1</p>
<ul>
<li><strong>렌더링 파이프라인:</strong> 언리얼 엔진의 PBR(Physically Based Rendering) 시스템을 활용하여 재질의 질감, 빛의 반사, 그림자 등을 사실적으로 묘사한다. 이는 카메라 기반의 인지 알고리즘이 실제 도로 환경과 유사한 시각적 특징을 학습하는 데 결정적인 기여를 한다. 특히 UE5 버전에서는 <strong>루멘(Lumen)</strong> 글로벌 일루미네이션과 <strong>나나이트(Nanite)</strong> 가상화 지오메트리 기술이 도입되어, 더욱 정교한 빛의 처리와 무한에 가까운 폴리곤 처리가 가능해져 시뮬레이션의 시각적 충실도를 획기적으로 높이고 있다.</li>
<li><strong>물리 엔진:</strong> 차량의 동역학, 충돌 감지, 중력 및 마찰력 계산을 위해 언리얼 엔진의 물리 엔진(PhysX 또는 Chaos)을 사용한다. CARLA는 이를 바탕으로 차량의 서스펜션, 타이어 마찰 모델, 엔진 토크 곡선 등을 세밀하게 튜닝할 수 있는 인터페이스를 제공하여 실제 차량과 유사한 주행 질감을 구현한다.3</li>
</ul>
<h2>3.  시뮬레이션 월드 구성 요소</h2>
<p>CARLA의 가상 세계는 단순한 3D 모델의 집합이 아니라, 자율주행차의 주행을 위한 논리적 정보와 물리적 자산이 결합된 복합적인 환경이다.</p>
<h3>3.1  맵과 OpenDRIVE 표준</h3>
<p>CARLA의 도로 네트워크는 <strong>ASAM OpenDRIVE</strong> 표준 포맷(주로 1.4 버전)을 따른다.3 OpenDRIVE 파일(.xodr)은 도로의 기하학적 구조, 차선의 속성(타입, 폭, 제한 속도), 교차로의 연결 정보, 표지판 및 신호등의 위치 정보를 XML 형식으로 정의한다.</p>
<ul>
<li><strong>도로 네트워크 생성:</strong> 사용자는 RoadRunner와 같은 전문 저작 도구를 사용하여 OpenDRIVE 맵을 생성하고, 이를 CARLA로 임포트할 수 있다.2 CARLA는 OpenDRIVE 파일을 파싱하여 시뮬레이션 내의 차량이 주행 가능한 경로를 인식하게 하고, AI 차량들이 교통 법규를 준수하며 주행할 수 있는 내비게이션 경로(Waypoint)를 생성한다.</li>
<li><strong>맵 자산:</strong> CARLA는 기본적으로 ’Town01’부터 ’Town15’에 이르는 다양한 환경의 맵을 제공한다. 여기에는 단순한 시골 도로, 복잡한 도심 교차로, 고속도로, 터널, 로터리 등 자율주행 테스트에 필요한 다양한 도로 형태가 포함된다.</li>
<li><strong>대규모 맵(Large Maps):</strong> 최신 버전(0.9.15 등)에서는 타일 스트리밍(Tile Streaming) 기술을 도입하여 단일 메모리에 로드하기 어려운 거대한 맵(예: 20km x 20km)을 지원한다. 이는 에고 차량의 위치를 중심으로 필요한 맵 타일만을 동적으로 로딩하고, 멀어지면 언로딩하는 방식으로 메모리 효율성을 극대화한다.8</li>
</ul>
<h3>3.2  날씨 및 환경 제어 시스템</h3>
<p>자율주행 시스템의 강건성(Robustness)을 검증하기 위해서는 다양한 날씨와 조명 조건에서의 테스트가 필수적이다. CARLA는 <code>carla.WeatherParameters</code> 클래스를 통해 환경 변수를 실시간으로 매우 세밀하게 제어할 수 있는 기능을 제공한다.2</p>
<table><thead><tr><th><strong>환경 변수</strong></th><th><strong>제어 범위 및 효과</strong></th><th><strong>관련 영향</strong></th></tr></thead><tbody>
<tr><td><strong>Cloudiness</strong></td><td>0.0(맑음) ~ 100.0(흐림)</td><td>조도 변화, 그림자 강도</td></tr>
<tr><td><strong>Precipitation</strong></td><td>0.0(없음) ~ 100.0(폭우)</td><td>노면 마찰력 감소, 카메라 시야 방해, 센서 노이즈</td></tr>
<tr><td><strong>PrecipitationDeposits</strong></td><td>0.0 ~ 100.0</td><td>도로 웅덩이 생성 (빛 반사 및 하이드로플레이닝 효과)</td></tr>
<tr><td><strong>WindIntensity</strong></td><td>0.0 ~ 100.0</td><td>식생(나무, 풀)의 움직임, 빗방울의 궤적 변화, 차량 물리 영향</td></tr>
<tr><td><strong>SunAltitudeAngle</strong></td><td>-90.0 ~ 90.0</td><td>시간대 변경(낮/밤), 그림자 길이, 역광 상황 연출</td></tr>
<tr><td><strong>FogDensity</strong></td><td>0.0 ~ 100.0</td><td>가시거리 감소, LiDAR/카메라 인식률 저하</td></tr>
<tr><td><strong>FogDistance</strong></td><td>0.0 ~ 무한대</td><td>안개가 시작되는 거리 설정</td></tr>
<tr><td><strong>Wetness</strong></td><td>0.0 ~ 100.0</td><td>도로 표면의 젖은 정도 (반사율 증가)</td></tr>
</tbody></table>
<p>이러한 파라미터들은 개별적으로 조절하거나, ‘ClearNoon’, ’HardRainSunset’과 같이 미리 정의된 프리셋(Preset)을 통해 손쉽게 적용할 수 있다. 특히 비가 오거나 젖은 노면에서는 차량의 물리적 마찰 계수가 자동으로 조정되어 제동 거리가 늘어나는 등의 물리적 변화도 함께 시뮬레이션된다.</p>
<h3>3.3  액터(Actor) 라이브러리: 차량 및 보행자</h3>
<p>시뮬레이션 내의 모든 동적, 정적 개체는 **액터(Actor)**라는 추상화된 객체로 관리된다. 사용자는 <code>BlueprintLibrary</code>를 통해 원하는 액터의 설계도(Blueprint)를 검색하고, 속성을 설정하여 월드에 생성(Spawn)한다.4</p>
<h4>3.3.1 차량 (Vehicles)</h4>
<p>CARLA는 수십 종의 차량 모델을 제공한다. 경차, 세단, SUV, 트럭, 밴, 오토바이, 자전거 등 다양한 차종이 포함된다.</p>
<ul>
<li><strong>물리 속성 커스터마이징:</strong> 차량의 질량, 무게 중심, 휠의 회전 반경, 엔진 토크 커브, 공기 저항 계수 등 물리적 거동을 결정하는 세부 파라미터를 사용자가 직접 수정할 수 있다. 이를 통해 특정 실제 차량의 거동을 모사하거나, 극한의 주행 상황을 연출할 수 있다.</li>
<li><strong>조명 시스템:</strong> 전조등, 브레이크등, 방향 지시등, 후진등, 안개등 등 차량의 모든 조명 장치를 개별적으로 제어할 수 있으며, 이는 야간 주행이나 신호 전달 시나리오 테스트에 활용된다.</li>
</ul>
<h4>3.3.2 보행자 (Walkers)</h4>
<p>보행자는 자율주행차의 안전성을 검증하는 데 있어 가장 중요한 동적 장애물이다. CARLA의 보행자는 단순한 강체가 아니라, 뼈대(Bone) 구조를 가진 스켈레탈 메쉬(Skeletal Mesh)로 구현되어 있어 걷기, 뛰기, 대기 등의 자연스러운 애니메이션을 수행한다.9</p>
<ul>
<li><strong>제어기 (Controller):</strong> 보행자는 <code>WalkerAIController</code>에 의해 제어된다. 사용자는 보행자에게 목표 지점으로 이동하거나, 무작위로 배회하도록 명령할 수 있다.</li>
<li><strong>내비게이션:</strong> 보행자는 Recast &amp; Detour 라이브러리 기반의 내비게이션 메쉬를 사용하여 장애물을 회피하고 최적의 경로를 찾아 이동한다.</li>
<li><strong>다양성:</strong> 성별, 나이, 복장, 체형이 다른 다양한 보행자 모델을 제공하여 인식 알고리즘의 편향을 방지하고 일반화 성능을 높일 수 있도록 지원한다.</li>
</ul>
<h2>4.  센서 시뮬레이션 기술</h2>
<p>CARLA의 가장 강력한 기능 중 하나는 자율주행차가 세상을 인지하는 데 사용하는 다양한 센서를 물리적으로 모델링하여 제공한다는 점이다. 센서는 차량의 어느 위치에나 부착할 수 있으며(상대 좌표 사용), 멀티 센서 퓨전(Sensor Fusion) 연구를 위한 완벽한 시간 동기화 데이터를 제공한다.11</p>
<h3>4.1  카메라 센서군 (Camera Sensors)</h3>
<ul>
<li><strong>RGB 카메라:</strong> 실제 카메라와 유사한 컬러 이미지를 생성한다. FOV(시야각), 셔터 속도, ISO, f-stop, 감마 보정, 렌즈 왜곡(Lens Distortion), 모션 블러(Motion Blur) 등 광학적 특성을 상세하게 설정할 수 있다.</li>
<li><strong>Depth 카메라:</strong> 각 픽셀의 값으로 해당 지점까지의 거리(Depth) 정보를 출력한다. 출력 이미지는 0~1 사이로 정규화되거나, 실제 미터 단위 거리로 변환 가능한 로그 스케일 데이터를 제공한다. 이는 거리 추정 알고리즘의 Ground Truth(정답지)로 활용된다.</li>
<li><strong>Semantic Segmentation 카메라:</strong> 렌더링된 이미지의 각 픽셀에 대해 해당 객체의 클래스 ID(예: 도로=1, 보행자=4, 차량=10)를 색상으로 인코딩하여 출력한다. 이는 딥러닝 기반의 세멘틱 세그멘테이션 모델을 학습시키거나 평가하는 데 필수적인 레이블 데이터를 별도의 수작업 없이 무제한으로 생성할 수 있게 해준다.11</li>
<li><strong>Instance Segmentation 카메라:</strong> Semantic Segmentation과 유사하지만, 동일한 클래스 내에서도 개별 객체(예: 차량 A와 차량 B)를 구분할 수 있는 고유 ID를 부여한다.</li>
<li><strong>DVS (Dynamic Vision Sensor) 카메라:</strong> 픽셀의 밝기 변화(Intensity Change)가 발생할 때만 이벤트를 생성하는 뉴로모픽(Neuromorphic) 센서를 모델링한다. 고속으로 움직이는 물체 인식이나 HDR(High Dynamic Range) 환경에서의 인식 연구에 활용된다.</li>
<li><strong>Optical Flow 카메라:</strong> 이전 프레임과 현재 프레임 사이의 픽셀 이동 벡터를 출력하여, 객체의 움직임 속도와 방향을 추정하는 연구에 사용된다.</li>
</ul>
<h3>4.2  능동형 센서군 (Active Sensors)</h3>
<ul>
<li><strong>LiDAR (Light Detection and Ranging):</strong> 레이저 펄스를 발사하고 반사되어 돌아오는 시간을 측정하여 3D 점군(Point Cloud) 데이터를 생성한다.</li>
<li><strong>파라미터:</strong> 채널 수(16~128채널 등), 회전 속도(RPM), 최대 거리, 상/하 수직 시야각(FOV), 포인트당 노이즈 표준편차, 드롭오프(Drop-off) 비율 등을 설정하여 Velodyne이나 Ouster 등 실제 상용 LiDAR 제품의 특성을 모사할 수 있다.12</li>
<li><strong>Semantic LiDAR:</strong> 일반 LiDAR 데이터에 각 포인트가 부딪힌 물체의 클래스 정보(Semantic Tag)를 포함하여 출력한다. 3D 포인트 클라우드 세그멘테이션 연구에 매우 유용하다.</li>
<li><strong>Radar:</strong> 밀리미터파를 사용하여 전방 객체의 거리, 속도(도플러 효과), 방위각 정보를 제공한다. LiDAR에 비해 날씨의 영향을 덜 받으며, 장거리 객체 탐지에 유리한 특성을 모델링한다.</li>
</ul>
<h3>4.3  기타 센서 및 가상 센서</h3>
<ul>
<li><strong>GNSS (GPS):</strong> 위성 항법 시스템을 모사하여 차량의 위도, 경도, 고도 정보를 제공한다. 실제 환경과 유사한 위치 오차(Noise)를 주입할 수 있다.</li>
<li><strong>IMU (Inertial Measurement Unit):</strong> 3축 가속도계(Accelerometer), 3축 자이로스코프(Gyroscope), 나침반(Compass) 데이터를 제공한다. 차량의 자세 추정(Pose Estimation) 및 관성 항법 시스템 개발에 사용된다.11</li>
<li><strong>가상 센서 (Pseudo Sensors):</strong> 물리적인 센서는 아니지만 시뮬레이션 내부 정보를 활용하여 특정 이벤트를 감지하는 센서들이다.</li>
<li><strong>Collision Detector:</strong> 차량이 다른 물체와 충돌하는 순간 충돌 강도와 대상 정보를 보고한다.</li>
<li><strong>Lane Invasion Detector:</strong> 차량 바퀴가 차선을 넘을 때(중앙선 침범, 갓길 이탈 등) 이벤트를 발생시킨다.</li>
<li><strong>Obstacle Detector:</strong> 차량 전방의 특정 영역 내에 있는 장애물을 감지한다.</li>
</ul>
<p>이러한 다양한 센서 데이터는 <code>sensor_tick</code> 파라미터를 통해 데이터 생성 주기를 조절할 수 있으며, 동기 모드 사용 시 모든 센서 데이터가 동일한 시뮬레이션 타임스탬프를 갖도록 보장되어 완벽한 센서 퓨전이 가능하다.7</p>
<h2>5.  자율주행 시스템 통합 및 확장성</h2>
<p>CARLA는 독립적인 시뮬레이션 도구로도 훌륭하지만, ROS, Autoware, SUMO 등 외부 생태계와의 강력한 통합 기능을 통해 그 가치가 배가된다.</p>
<h3>5.1  ROS 및 ROS 2 브릿지 (ROS Bridge)</h3>
<p>로봇 운영 체제(ROS, Robot Operating System)는 자율주행 연구의 사실상 표준 미들웨어이다. CARLA는 <code>ros-bridge</code> 패키지를 통해 시뮬레이터 내부의 데이터와 ROS 네트워크 간의 양방향 통신을 지원한다.7</p>
<ul>
<li><strong>데이터 발행 (Publishing):</strong> CARLA의 센서 데이터를 ROS 표준 메시지 형식(예: <code>sensor_msgs/Image</code>, <code>sensor_msgs/PointCloud2</code>, <code>sensor_msgs/NavSatFix</code>)으로 변환하여 ROS 토픽으로 발행한다. 이를 통해 개발자는 시뮬레이터를 실제 하드웨어인 것처럼 간주하고 ROS 기반의 알고리즘을 테스트할 수 있다.</li>
<li><strong>제어 구독 (Subscribing):</strong> ROS 노드(예: 경로 계획기, 제어기)에서 발행하는 차량 제어 명령(<code>ackermann_msgs/AckermannDrive</code> 등)을 수신하여 CARLA 차량에 적용한다.</li>
<li><strong>TF 트리 관리:</strong> 차량의 위치와 부착된 센서들 간의 좌표 변환 관계를 담은 TF(Transform) 트리를 실시간으로 방송(Broadcast)하여, SLAM이나 센서 퓨전 알고리즘이 올바른 좌표계를 사용할 수 있도록 돕는다.</li>
<li><strong>시간 동기화:</strong> ROS의 <code>/clock</code> 토픽을 통해 시뮬레이션 시간(Sim Time)을 발행하여, ROS 노드들이 실제 시간이 아닌 시뮬레이션 시간에 맞춰 동작하도록 동기화한다. 이는 고속 시뮬레이션이나 느린 연산 상황에서도 알고리즘의 시간적 일관성을 유지하는 데 필수적이다.</li>
</ul>
<h3>5.2  Autoware 통합 (CARLA-Autoware Bridge)</h3>
<p>Autoware는 세계적으로 가장 널리 사용되는 오픈 소스 자율주행 소프트웨어 스택이다. CARLA는 Autoware와의 심리스한 연동을 위해 전용 브릿지 솔루션을 제공한다.13</p>
<ul>
<li><strong>아키텍처:</strong> CARLA-Autoware 브릿지는 ’CARLA 서버 &lt;-&gt; ROS Bridge &lt;-&gt; Autoware Bridge &lt;-&gt; Autoware’의 구조로 통신한다.</li>
<li><strong>좌표계 변환:</strong> CARLA는 언리얼 엔진 기반으로 왼손 좌표계(Left-handed system)를 사용하고, Autoware(ROS 기반)는 오른손 좌표계(Right-handed system)를 사용한다. 브릿지는 포인트 클라우드, 차량 위치, 방향 벡터 등의 데이터를 실시간으로 변환하여 좌표계 불일치 문제를 해결한다.14</li>
<li><strong>데이터 포맷 변환:</strong> Autoware Universe 등 최신 버전은 Lanelet2 형식의 벡터 맵을 요구한다. CARLA는 OpenDRIVE 맵을 Lanelet2 포맷으로 변환하거나, Autoware가 요구하는 특정 센서 구성(LiDAR 위치 등)을 맞추기 위한 유틸리티를 제공한다.</li>
<li><strong>제어 명령 변환:</strong> Autoware가 출력하는 목표 속도, 가속도, 조향각 명령을 CARLA 차량의 입력인 스로틀(0~1), 브레이크(0~1), 스티어링(-1~1) 값으로 변환하기 위해 내장된 PID 제어기를 사용한다. 이를 통해 Autoware의 계획(Planning) 모듈이 시뮬레이션 차량을 정교하게 제어할 수 있다.14</li>
</ul>
<h3>5.3  SUMO 공동 시뮬레이션 (Co-Simulation)</h3>
<p>SUMO(Simulation of Urban MObility)는 미시적 교통 흐름 시뮬레이션에 특화된 도구이다. CARLA는 차량의 동역학 및 센서 시뮬레이션에 강점이 있는 반면, 대규모 교통 흐름 생성에는 연산 비용이 많이 든다. 공동 시뮬레이션은 이 두 시뮬레이터의 장점을 결합한다.16</p>
<ul>
<li><strong>역할 분담:</strong> SUMO는 도시 전체의 수많은 차량들의 이동 경로, 신호등 주기, 교통 체증 상황을 관리한다. CARLA는 이 중 자율주행차(Ego Vehicle) 주변의 차량들만을 고해상도로 렌더링하고 물리 연산을 수행한다.</li>
<li><strong>동기화 메커니즘:</strong> TraCI(Traffic Control Interface)를 통해 두 시뮬레이터가 연결된다. 매 시간 단계마다 SUMO는 차량들의 위치 업데이트 정보를 CARLA에 전송하고, CARLA는 자율주행차의 위치 정보를 SUMO에 전송하여 서로 충돌하지 않고 상호작용하도록 한다. 이를 통해 현실적인 교통 패턴(러시아워 등) 내에서 자율주행차를 테스트할 수 있다.</li>
</ul>
<h2>6.  시나리오 검증 및 평가: ScenarioRunner와 Leaderboard</h2>
<p>단순 주행 테스트를 넘어, 특정하고 위험한 상황에서의 대처 능력을 평가하기 위해 CARLA는 체계적인 검증 도구를 제공한다.</p>
<h3>6.1  ScenarioRunner와 OpenSCENARIO</h3>
<p>ScenarioRunner는 CARLA용 시나리오 실행 엔진이다. 사용자는 파이썬 스크립트 또는 <strong>ASAM OpenSCENARIO</strong> 표준 포맷을 사용하여 시나리오를 정의하고 실행할 수 있다.18</p>
<ul>
<li><strong>시나리오의 구성:</strong> 시나리오는 자율주행차(Ego), 배경 차량(NPC), 그리고 트리거(Trigger) 조건으로 구성된다.</li>
<li><strong>예시:</strong> “자율주행차가 교차로에 진입(Trigger)하면, 오른쪽에서 오던 차량이 신호를 무시하고 직진(Behavior)한다.”</li>
<li><strong>원자적 행동(Atomic Behaviors):</strong> ScenarioRunner는 시나리오를 구성하는 기본 블록(차선 변경, 급정거, 따라가기 등)을 제공하여, 사용자가 이를 조합해 복잡한 시나리오를 쉽게 저작할 수 있도록 돕는다.20</li>
<li><strong>평가 기준(Criteria):</strong> 시나리오 성공 여부를 판단하는 조건을 정의한다. 충돌 발생, 차선 이탈, 제한 속도 위반, 목적지 도달 실패 등을 자동으로 감지하여 Pass/Fail 결과를 도출한다.</li>
</ul>
<h3>6.2  CARLA 자율주행 리더보드 (Leaderboard)</h3>
<p>리더보드는 전 세계 연구팀들이 개발한 자율주행 에이전트의 성능을 동일한 조건에서 공정하게 평가하고 순위를 매기는 오픈 플랫폼이다. 리더보드 2.0 및 최신 버전은 매우 도전적인 경로와 복합적인 교통 상황을 포함한다.8</p>
<h4>6.2.1 평가 지표 (Metrics) 상세 분석</h4>
<p>리더보드의 순위는 단순한 주행 완료 여부가 아닌, 안전성과 효율성을 종합적으로 고려한 수식에 의해 결정된다.8</p>
<ol>
<li>주행 점수 (Driving Score):</li>
</ol>
<p>최종 순위를 결정하는 메인 지표이다.</p>
<p><span class="math math-display">\text{Driving Score} = R_i \times P_i</span></p>
<p>여기서 <span class="math math-inline">R_i</span>는 경로 완료율(Route Completion, %), <span class="math math-inline">P_i</span>는 위반 페널티(Infraction Penalty) 점수이다.</p>
<ol start="2">
<li>경로 완료율 (Route Completion, <span class="math math-inline">R_i</span>):</li>
</ol>
<p>에이전트가 지정된 전체 경로 거리 중 몇 퍼센트를 주행했는지를 나타낸다. 완주 시 100점이다.</p>
<ol start="3">
<li>위반 페널티 (Infraction Penalty, <span class="math math-inline">P_i</span>):</li>
</ol>
<p>에이전트가 주행 중 범한 실수들에 대해 점수를 차감하는 방식이 아니라, 전체 점수에 0~1 사이의 계수를 곱해 나가는 방식(Geometric Series)을 취한다. 이는 단 한 번의 중대한 실수가 점수를 크게 깎아먹도록 설계된 것이다.</p>
<p><span class="math math-display">P_i = \prod_{j} (p_j)^{\#\text{infractions}_j}</span></p>
<p>또는 최신 버전에서는 다음과 같은 공식을 사용하기도 한다:</p>
<p><span class="math math-display">P_i = \frac{1}{1 + \sum_j (c_j \times \#\text{infractions}_j)}</span></p>
<p>(문맥에 따라 리더보드 버전에 따른 계산식 차이가 있을 수 있으나, 위반이 많을수록 점수가 0에 수렴한다는 원칙은 동일하다.)</p>
<p>주요 위반 항목 및 가중치(Coefficient/Penalty Multiplier):</p>
<p>다음 표는 리더보드에서 정의하는 주요 위반 사항과 그 심각도를 나타낸다.8 수치가 1.0보다 작을수록(또는 가중치가 클수록) 점수에 치명적이다.</p>
<table><thead><tr><th><strong>위반 항목 (Infraction Type)</strong></th><th><strong>설명</strong></th><th><strong>심각도 영향</strong></th></tr></thead><tbody>
<tr><td><strong>Collisions with pedestrians</strong></td><td>보행자와의 충돌</td><td>가장 치명적 (점수 대폭 하락)</td></tr>
<tr><td><strong>Collisions with vehicles</strong></td><td>다른 차량과의 충돌</td><td>매우 치명적</td></tr>
<tr><td><strong>Collisions with static layout</strong></td><td>가로수, 벽, 가로등 등과의 충돌</td><td>치명적</td></tr>
<tr><td><strong>Running a red light</strong></td><td>적색 신호 무시 및 통과</td><td>중대한 위반</td></tr>
<tr><td><strong>Running a stop sign</strong></td><td>정지 표지판 미준수</td><td>중대한 위반</td></tr>
<tr><td><strong>Off-road driving</strong></td><td>도로(차도) 영역을 벗어나 주행</td><td>지속 시간에 비례하여 감점</td></tr>
<tr><td><strong>Route deviation</strong></td><td>지정된 경로에서 크게 벗어남</td><td>시뮬레이션 중단 사유가 될 수 있음</td></tr>
<tr><td><strong>Agent blocked</strong></td><td>일정 시간 이상 움직이지 않음</td><td>교통 흐름 방해로 간주, 타임아웃 처리</td></tr>
</tbody></table>
<p>이러한 정량적이고 가혹한 평가 시스템은 연구자들이 단순히 ‘가는’ 자율주행차가 아니라, ‘안전하고 규칙을 준수하는’ 자율주행차를 개발하도록 유도한다.</p>
<h2>7. 설치 가이드 및 시스템 최적화</h2>
<p>CARLA는 고성능 시뮬레이터이므로 적절한 설치 및 환경 설정이 중요하다.</p>
<h3>7.1 하드웨어 요구사항 및 최적화</h3>
<ul>
<li><strong>GPU:</strong> CARLA 0.9.14 이상 버전 및 UE5 버전을 원활히 구동하기 위해서는 최소 NVIDIA RTX 2070 (8GB VRAM) 이상의 그래픽 카드가 권장된다. 특히 다수의 카메라 센서를 부착하거나 고해상도 렌더링을 수행할 경우 VRAM 용량이 성능의 병목이 될 수 있다.6</li>
<li><strong>CPU:</strong> 물리 연산과 트래픽 매니저(Traffic Manager)의 AI 처리를 위해 멀티코어 성능이 중요하다.</li>
<li><strong>RAM:</strong> 대규모 맵 로딩과 컴파일을 위해 최소 32GB 이상의 시스템 메모리가 권장된다.23</li>
<li><strong>Disk:</strong> 소스 빌드를 위해서는 약 165GB 이상의 공간이 필요하며, 로딩 속도 향상을 위해 NVMe SSD 사용이 필수적이다.</li>
</ul>
<h3>7.2 설치 방법 및 트러블슈팅</h3>
<ol>
<li><strong>패키지 버전 (Pre-compiled):</strong> 일반적인 사용자는 GitHub 릴리즈에서 압축 파일을 다운로드하여 실행한다.
<ul>
<li><em>주의:</em> Python API 버전(예: 3.7, 3.8)이 시스템의 Python 버전과 정확히 일치해야 한다. <code>.egg</code> 파일을 <code>PYTHONPATH</code>에 추가하거나 <code>pip install carla</code> 명령으로 클라이언트 라이브러리를 설치해야 한다.6</li>
</ul>
</li>
<li><strong>소스 빌드 (Source Build):</strong> 엔진 수정이나 플러그인 개발이 필요한 경우 사용한다.
<ul>
<li><em>절차:</em> GitHub 계정을 에픽 게임즈 계정과 연동하여 언리얼 엔진 소스 접근 권한을 얻어야 한다. 이후 <code>make PythonAPI</code>, <code>make launch</code> 등의 명령어로 빌드한다.</li>
<li><em>난점:</em> CMake 버전, 컴파일러 버전(Visual Studio 등), Python 의존성 문제 등이 발생할 수 있으므로 공식 문서의 요구사항을 엄격히 준수해야 한다.24</li>
</ul>
</li>
<li><strong>Docker 실행:</strong>
<ul>
<li>헤드리스 모드(디스플레이 없음)로 서버 운영 시 매우 유용하다. <code>nvidia-docker</code> 또는 <code>nvidia-container-toolkit</code>이 필수이다.</li>
<li>명령어 예시: <code>docker run --runtime=nvidia --net=host carlasim/carla:latest /bin/bash CarlaUE4.sh -RenderOffScreen</code>.26</li>
</ul>
</li>
</ol>
<h2>8. 결론</h2>
<p>CARLA 시뮬레이터는 자율주행 기술의 연구, 개발, 검증을 위한 가장 포괄적이고 강력한 오픈 소스 플랫폼이다. 서버-클라이언트 아키텍처를 통한 유연성, 언리얼 엔진 기반의 사실적인 시각화, 정밀한 센서 모델링, 그리고 ROS 및 Autoware와의 긴밀한 통합은 CARLA를 학계와 산업계의 표준 도구로 자리 잡게 하였다.</p>
<p>특히 ScenarioRunner와 Leaderboard를 통한 정량적 평가 체계는 자율주행 알고리즘의 안전성을 객관적으로 증명할 수 있는 수단을 제공함으로써 기술의 상용화를 앞당기는 데 기여하고 있다. 향후 언리얼 엔진 5로의 완전한 전환과 대규모 디지털 트윈 기술의 접목은 CARLA의 활용 범위를 개별 차량의 제어를 넘어 스마트 시티 관제 및 V2X(Vehicle-to-Everything) 통신 검증 영역까지 확장시킬 것으로 전망된다. 연구자와 개발자에게 있어 CARLA에 대한 깊은 이해와 활용 능력은 차세대 모빌리티 혁신을 주도하기 위한 필수적인 역량이 될 것이다.</p>
<h4><strong>참고 자료</strong></h4>
<ol>
<li>carla-simulator/carla: Open-source simulator for autonomous driving research. - GitHub, 12월 14, 2025에 액세스, https://github.com/carla-simulator/carla</li>
<li>CARLA Simulator, 12월 14, 2025에 액세스, https://carla.org/</li>
<li>Introduction - CARLA Simulator, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/start_introduction/</li>
<li>Foundations - CARLA Simulator UE5, 12월 14, 2025에 액세스, https://carla-ue5.readthedocs.io/en/latest/foundations/</li>
<li>Run Carla Server on Linux and Client on Windows #5655 - GitHub, 12월 14, 2025에 액세스, https://github.com/carla-simulator/carla/discussions/5655</li>
<li>Quick start package installation - CARLA Simulator, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/start_quickstart/</li>
<li>3rd Party Integrations - CARLA Simulator, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/3rd_party_integrations/</li>
<li>Get started with Leaderboard 2.0, 12월 14, 2025에 액세스, https://leaderboard.carla.org/get_started_v2_0/</li>
<li>Python API reference - CARLA documentation, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/python_api/</li>
<li>Actors - CARLA Simulator - Read the Docs, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/core_actors/</li>
<li>Sensors reference - CARLA Simulator - Read the Docs, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/ref_sensors/</li>
<li>Sensors reference - CARLA Simulator, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/0.9.11/ref_sensors/</li>
<li>Autoware - CAR Lab, 12월 14, 2025에 액세스, https://www.thecarlab.org/projects/autoware</li>
<li>[Literature Review] CARLA-Autoware-Bridge: Facilitating Autonomous Driving Research with a Unified Framework for Simulation and Module Development - Moonlight, 12월 14, 2025에 액세스, https://www.themoonlight.io/en/review/carla-autoware-bridge-facilitating-autonomous-driving-research-with-a-unified-framework-for-simulation-and-module-development</li>
<li>CARLA-Autoware-Bridge: Facilitating Autonomous Driving Research with a Unified Framework for Simulation and Module Development - arXiv, 12월 14, 2025에 액세스, https://arxiv.org/html/2402.11239v1</li>
<li>SUMO co-simulation - CARLA documentation, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/adv_sumo/</li>
<li>Construction of a Joint Simulation Platform Using SUMO, CARLA, and Autoware and Its Application in Multi-Vehicle Interactions at - IEEE Xplore, 12월 14, 2025에 액세스, https://ieeexplore.ieee.org/iel8/11040155/11041694/11042155.pdf</li>
<li>CARLA ScenarioRunner, 12월 14, 2025에 액세스, http://scenario-runner.readthedocs.io/</li>
<li>carla-simulator/scenario_runner: Traffic scenario definition and execution engine - GitHub, 12월 14, 2025에 액세스, https://github.com/carla-simulator/scenario_runner</li>
<li>Traffic Simulation Overview - CARLA documentation, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/0.9.13/ts_traffic_simulation_overview/</li>
<li>CARLA Autonomous Driving Leaderboard, 12월 14, 2025에 액세스, https://leaderboard.carla.org/</li>
<li>Evaluation Criteria for the Leaderboard 2.0, 12월 14, 2025에 액세스, https://leaderboard.carla.org/evaluation_v2_0/</li>
<li>What is the system requirements for CARLA simulator? : r/SelfDrivingCars - Reddit, 12월 14, 2025에 액세스, https://www.reddit.com/r/SelfDrivingCars/comments/pbuhtz/what_is_the_system_requirements_for_carla/</li>
<li>F.A.Q. - CARLA Simulator, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/build_faq</li>
<li>Windows build - CARLA Simulator - Read the Docs, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/build_windows</li>
<li>CARLA in Docker - CARLA Simulator - CARLA documentation, 12월 14, 2025에 액세스, https://carla.readthedocs.io/en/latest/build_docker/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>