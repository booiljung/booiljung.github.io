<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:NVIDIA Edify</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>NVIDIA Edify</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">디지털트윈 (Digital Twins)</a> / <a href="index.html">NVidia Omniverse</a> / <span>NVIDIA Edify</span></nav>
                </div>
            </header>
            <article>
                <h1>NVIDIA Edify</h1>
<h2>1. 서론</h2>
<p>NVIDIA Edify는 단일 생성형 AI 모델을 지칭하는 용어가 아니다. 이는 이미지, 비디오, 3D 에셋, 360도 고명암 대비(HDRi), 물리 기반 렌더링(PBR) 재질 등 광범위한 시각적 콘텐츠 생성을 목표로 설계된 포괄적인 <strong>멀티모달(multimodal) AI 아키텍처</strong>로 정의해야 한다.1 이러한 정의는 NVIDIA가 특정 애플리케이션 개발을 넘어, 시각 생성 AI 기술의 근간을 이루는 핵심 기술 스택을 구축하고자 했음을 명확히 보여준다. Edify는 라플라시안 확산(Laplacian diffusion)이나 다중 시점(multi-view) 3D 생성과 같은 기술적 혁신을 선보였을 뿐만 아니라, ’상업적 안전성(commercially safe)’이라는 명확한 가치 제안을 통해 기업 시장을 정밀하게 공략한 선구적 시도였다.3 생성형 AI 시장 초기에 저작권 문제가 첨예한 법적, 윤리적 쟁점으로 부상했을 때, 이는 Edify를 경쟁 모델과 차별화하는 핵심 요소로 작용했다.</p>
<p>본 안내서는 Edify의 기술적 근간을 심층적으로 해부하고(제1부), NVIDIA의 거대한 AI 생태계 내에서 Edify가 수행했던 전략적 역할을 분석하며(제2부), 치열한 경쟁 환경 속에서 Edify가 차지했던 독자적인 위치를 조명한다(제3부). 마지막으로, Edify NIM(NVIDIA Inference Microservice) 프리뷰 서비스의 중단이 가지는 의미를 다각도로 해석하고, 이를 통해 NVIDIA의 거시적인 생성형 AI 전략이 어떻게 진화하고 있는지를 추적함으로써 Edify가 남긴 기술적, 전략적 유산을 종합적으로 평가하고자 한다(제4부).</p>
<h2>2.  Edify의 기술적 기반과 아키텍처</h2>
<h3>2.1  Edify Image: 픽셀 공간에서의 라플라시안 확산 모델</h3>
<p>Edify 아키텍처의 2D 이미지 생성 부문을 담당하는 Edify Image는 기존 확산 모델의 패러다임에서 벗어난 독자적인 접근법을 채택했다. Stable Diffusion과 같은 주류 모델들이 VAE(Variational Autoencoder)를 이용해 고차원의 이미지 데이터를 저차원의 잠재 공간(latent space)으로 압축하여 처리하는 방식을 사용하는 것과 대조적으로, Edify Image는 원본 이미지의 픽셀 공간(pixel space)에서 직접 작동하는 방식을 선택했다.5 이러한 선택은 모델의 기술적 정체성과 직결된다.</p>
<h4>2.1.1 라플라시안 확산 모델(Laplacian Diffusion Model)의 원리</h4>
<p>Edify Image의 핵심 혁신은 ’라플라시안 확산 모델’이라는 새로운 개념에 있다. 이 모델의 근본적인 아이디어는 이미지 신호를 주파수 대역별로 분해하고, 각 대역에 서로 다른 감쇠율(attenuation rate)을 적용하여 노이즈를 추가하는 새로운 확산 프로세스를 제안하는 것이다.5 이는 이미지의 거시적 구조를 담고 있는 저주파 정보와 섬세한 디테일을 담고 있는 고주파 정보를 시간 축에 따라 다르게 처리함으로써, 생성 과정 전반에 걸쳐 세부 묘사의 정밀도를 극대화하려는 시도이다.</p>
<p>수학적으로 이 과정은 다음과 같이 공식화할 수 있다. 원본 이미지 <span class="math math-inline">\mathbf{x}_0</span>를 라플라시안 피라미드(Laplacian pyramid) 기법을 통해 여러 주파수 대역 <span class="math math-inline">\mathbf{x}_0^{(i)}</span>로 분해한다. 이후 특정 시간 <span class="math math-inline">t</span>에서의 노이즈가 추가된 이미지 <span class="math math-inline">\mathbf{x}_t</span>는 각 주파수 대역에 서로 다른 감쇠 계수 <span class="math math-inline">\alpha_t^{(i)}</span>를 적용한 신호의 합으로 정의된다.6<br />
<span class="math math-display">
\mu(\mathbf{x}_0, t) = \sum_{i} \alpha_t^{(i)} \mathbf{x}_0^{(i)}
</span></p>
<p><span class="math math-display">
\mathbf{x}_t = \mu(\mathbf{x}_0, t) + \sigma_t \epsilon
</span></p>
<p>여기서 핵심은 고주파 대역에 해당하는 감쇠 계수 <span class="math math-inline">\alpha_t^{(i)}</span>가 저주파 대역의 계수보다 더 빠르게 0에 수렴하도록 설계하는 것이다. 이로 인해 확산 과정의 초기 단계(시간 <span class="math math-inline">t</span>가 작을 때)에서는 고주파 정보가 빠르게 소멸되고 저주파 구조 정보가 상대적으로 오래 보존된다. 역으로, 이미지 생성(denoising) 과정에서는 초기 단계에서 전체적인 구조를 먼저 복원하고, 후반부로 갈수록 점차 고주파 디테일을 정교하게 복원하는 계층적 생성이 가능해진다.</p>
<h4>2.1.2 계단식(Cascaded) 아키텍처와 시너지</h4>
<p>Edify Image는 저해상도 이미지를 생성하는 기본 모델과, 이를 입력받아 점진적으로 해상도를 높이는 여러 후속 모델들로 구성된 계단식(cascaded) 아키텍처를 사용한다.6 라플라시안 확산 모델은 이러한 구조에서 발생하기 쉬운 아티팩트 누적 문제를 효과적으로 완화한다. 일반적인 계단식 모델에서 업샘플링 단계는 단순히 픽셀 수를 늘리는 데 초점을 맞추는 경우가 많지만, Edify Image의 후속 모델들은 이전 단계에서 감쇠되었던 특정 고주파 대역의 정보를 복원하는 명확한 목표를 가지고 훈련되기 때문이다.</p>
<p>이러한 기술적 선택은 단순한 학술적 시도를 넘어 명확한 전략적 목표를 가진다. 잠재 공간 모델은 VAE 인코더와 디코더 과정에서 미세한 정보 손실이나 아티팩트가 발생할 위험이 있다. 특히 이미지 내 텍스트 렌더링이나 복잡한 질감 표현에서 이러한 한계가 드러나곤 한다. 반면, 픽셀 공간에서 직접 작동하고 다중 스케일 처리를 통해 정밀도를 높인 Edify Image는 ’픽셀 수준의 정확성(pixel-perfect accuracy)’을 달성할 수 있으며, 이는 결과물의 품질과 신뢰성이 무엇보다 중요한 상업용 및 기업용 애플리케이션 시장의 요구에 정확히 부합하는 아키텍처 선택이라 할 수 있다.5</p>
<h3>2.2  Edify 3D: 다중 시점 합성에서 3D 재구성까지</h3>
<p>Edify 3D는 3D 에셋 생성 분야에서 고질적인 문제로 지적되어 온 고품질 3D 학습 데이터의 부족 문제를 해결하기 위해, 2D 이미지 생성 기술을 중간 단계로 활용하는 독창적인 2단계 파이프라인을 채택했다.10</p>
<h4>2.2.1 단계 생성 파이프라인</h4>
<ol>
<li><strong>1단계 - 다중 시점 확산 모델 (Multi-View Diffusion Model):</strong> 텍스트 프롬프트가 입력되면, 모델은 해당 객체를 여러 가상 카메라 시점에서 바라본 RGB 이미지들과 표면의 기하학적 정보를 담고 있는 법선 맵(surface normal map) 이미지를 <em>일관성 있게</em> 동시에 생성한다.10 이러한 다중 시점 간의 일관성은 기존 단일 이미지 생성 모델의 self-attention 레이어를 확장하여, 각 뷰(view)의 특징(feature)들이 서로 정보를 교환하도록 설계된 메커니즘을 통해 달성된다. 이는 마치 비디오의 각 프레임이 시간적 일관성을 유지하는 것과 유사한 원리로 작동한다.10</li>
<li><strong>2단계 - 재구성 모델 (Reconstruction Model):</strong> 1단계에서 생성된 여러 장의 2D 이미지들(RGB 및 법선 맵)을 입력으로 받아, 이를 종합하여 최종적인 3D 에셋을 재구성한다. 이 과정에서 객체의 복잡한 기하학적 구조(geometry), 최대 4K 해상도의 고품질 텍스처, PBR(물리 기반 렌더링) 재질, 그리고 후반 작업을 용이하게 하는 정리된 UV 맵이 함께 생성된다.10</li>
</ol>
<h4>2.2.2 ‘생산 준비(Production-Ready)’ 에셋의 지향</h4>
<p>Edify 3D의 핵심 목표는 단순히 3D 형태를 만드는 것을 넘어, 전문 아티스트들이 후반 작업에서 즉시 활용할 수 있는 ‘생산 준비된(production-ready)’ 에셋을 제공하는 것이었다. 이를 위해 모델은 ’깨끗한 사변형 기반 토폴로지(clean quads-based topology)’와 자동화된 UV 매핑 기능을 제공하도록 설계되었다.3 이는 많은 초기 3D 생성 도구들이 불규칙한 삼각형 메시(tri-mesh)나 소위 ’녹아내린 치즈’처럼 보이는 비정형적 형태를 출력하여 후속 작업에 어려움을 주었던 것과 명확히 대조되는 지점이다.12</p>
<p>Edify 3D의 이러한 설계 철학은 NVIDIA의 더 큰 비전, 즉 산업 메타버스 플랫폼인 ‘Omniverse’ 및 ‘디지털 트윈’ 전략과 깊은 연관성을 가진다. 생성된 에셋이 PBR 재질과 깨끗한 기하 구조를 갖춘다는 것은, 이 에셋들이 Omniverse와 같은 시뮬레이션 환경 내에서 물리적으로 정확하게 상호작용할 수 있는 ‘SimReady’ 에셋으로 기능할 수 있음을 의미한다.13 이는 Edify 3D가 단순한 콘텐츠 제작 도구를 넘어, NVIDIA의 산업 메타버스 생태계를 풍부하게 채우기 위한 핵심적인 에셋 생성 파이프라인으로 기획되었음을 시사한다. 즉, Edify 3D는 NVIDIA의 하드웨어(GPU), 플랫폼(Omniverse), 그리고 콘텐츠(생성형 AI)로 이어지는 거대한 수직 통합 전략에서 핵심적인 연결고리 역할을 수행하도록 설계된 것이다.</p>
<h2>3.  NVIDIA 생태계 내 Edify의 전략적 활용</h2>
<h3>3.1  AI 파운드리와 피카소 서비스: 맞춤형 AI 모델링의 구현</h3>
<p>NVIDIA는 Edify를 통해 완성된 AI 모델을 판매하는 것을 넘어, ‘AI 모델 생성’ 자체를 서비스화(Model-as-a-Service)하려는 야심 찬 전략을 펼쳤다. 그 중심에는 ’NVIDIA AI Foundry’라는 개념이 있다. 이는 마치 반도체 파운드리 기업 TSMC가 팹리스 기업들의 설계를 받아 칩을 제조해주듯, NVIDIA가 기업들의 고유 데이터를 활용하여 맞춤형 AI 모델을 개발하고 운영할 수 있도록 지원하는 플랫폼 및 서비스를 의미한다.14</p>
<p>이 파운드리 생태계에서 Edify는 기업들이 활용할 수 있는 핵심적인 <strong>파운데이션 아키텍처</strong>로 기능했다.2 기업들은 잘 훈련된 일반 Edify 모델을 기반으로 시작하여, 자사의 독점적인 데이터셋을 이용해 미세조정(fine-tuning)을 거침으로써 자사의 브랜드 스타일과 고유한 지적 재산(IP)이 반영된 맞춤형 생성 모델을 구축할 수 있었다. 초기에는 이 서비스가 ’NVIDIA Picasso’라는 이름의 클라우드 서비스로 발표되었으며, Edify는 그 안에 포함된 핵심 모델 아키텍처였다.2 시간이 지나면서 ’Picasso’라는 브랜드는 점차 더 넓은 개념인 ‘Edify’ 또는 ’AI Foundry’로 통합 및 대체된 것으로 보인다.15</p>
<p>이러한 접근법은 AI 시장의 주도권을 모델 개발사가 아닌, 모델 개발을 가능하게 하는 ’인프라 및 플랫폼 제공자’인 NVIDIA가 확보하려는 정교한 전략적 포석이다. 모든 기업이 처음부터 파운데이션 모델을 훈련하는 것은 막대한 비용과 전문성을 요구한다. NVIDIA는 이미 최적화된 파운데이션 아키텍처(Edify)와 세계 최고 수준의 훈련 인프라(DGX Cloud)를 보유하고 있으므로 2, 기업은 자신들의 핵심 자산인 ’데이터’만 제공하면 된다. NVIDIA AI Foundry는 이 둘을 결합하여 맞춤형 모델을 ’생산’해주는 공장 역할을 수행하며, 이를 통해 NVIDIA는 단순한 GPU 판매자를 넘어 모든 기업의 AI 전환 과정에 깊숙이 관여하는 핵심 파트너로 자리매김하게 된다.</p>
<h3>3.2  핵심 파트너십 분석: Shutterstock, Getty Images, Adobe</h3>
<p>Edify의 전략에서 파트너십은 단순한 기술 협력을 넘어, 그 자체로 핵심적인 가치 제안이었다. 이는 생성형 AI 시장의 ’데이터 전쟁’에서 NVIDIA가 선택한 독특한 경로를 보여준다.</p>
<ul>
<li><strong>Shutterstock &amp; Getty Images - ’상업적 안전성’의 근원:</strong> Edify 모델은 Shutterstock과 Getty Images가 보유한 방대한 양의 <strong>라이선스된(fully licensed)</strong> 콘텐츠를 기반으로 훈련되었다.2 이는 생성된 결과물의 저작권 문제를 우려하는 기업 고객들에게 법적 위험이 없는 ‘상업적으로 안전한(commercially safe)’ 솔루션임을 보증하는 강력한 장치가 되었다. 더 나아가, 원작자에게 수익이 공정하게 분배되는 윤리적 모델임을 강조함으로써 기업의 사회적 책임(CSR) 요구에도 부응했다.2 특히 Shutterstock은 Edify 3D 아키텍처를 기반으로 한 Text-to-3D API 서비스를 출시하여, 기업들이 자사 애플리케이션에 3D 생성 기능을 손쉽게 통합할 수 있는 통로를 제공했다.2</li>
<li><strong>Getty Images - 미세조정(Fine-tuning) 및 제어 기능 강화:</strong> Getty Images는 기업 고객이 자체 데이터셋을 업로드하여 Edify 모델을 미세조정하고, 자사의 엄격한 브랜드 가이드라인에 부합하는 이미지를 생성할 수 있는 서비스를 제공했다.2 이는 생성형 AI의 고질적인 문제인 ’통제 불가능성’에 대한 기업의 우려를 해소하고, AI를 예측 가능하고 신뢰할 수 있는 마케팅 도구로 활용할 수 있게 만들었다.</li>
<li><strong>Adobe - 크리에이티브 워크플로우로의 확장:</strong> NVIDIA는 Adobe와의 협력을 통해 Edify의 강력한 3D 생성 기술을 Adobe Firefly 및 Creative Cloud 제품군에 통합할 계획을 발표했다.2 이는 Edify를 통해 생성된 에셋이 전문가들의 기존 워크플로우에 단절 없이 통합될 수 있음을 의미하며, Edify 기술의 파급력을 주류 크리에이티브 시장으로 확장할 수 있는 중요한 전략적 협력이었다.</li>
</ul>
<p>이러한 파트너십들은 웹 스크래핑에 기반한 ’양’의 경쟁(예: Stable Diffusion) 대신, 라이선스 계약을 통한 ’질’과 ’법적 안정성’의 경쟁을 선택한 NVIDIA의 전략을 명확히 보여준다. 이는 기술력만으로는 쉽게 모방할 수 없는 강력한 해자를 구축하며, 특히 법적 리스크에 민감한 대기업 시장을 효과적으로 공략하는 데 결정적인 역할을 했다. 즉, 이 파트너십들은 Edify의 기술을 상용화하는 통로이자, Edify의 핵심 가치인 ’신뢰’를 보증하는 증표로서 기능했다.</p>
<h3>3.3  고급 기능과 창의적 제어</h3>
<p>Edify는 단순한 텍스트 프롬프트를 넘어, 사용자가 생성 과정을 보다 정밀하고 의도적으로 제어할 수 있는 다양한 고급 기능을 제공하고자 했다.2</p>
<ul>
<li><strong>정밀한 이미지 제어:</strong></li>
<li><strong>Sketch:</strong> 사용자가 제공한 스케치의 윤곽과 형태를 따라 이미지를 생성한다.</li>
<li><strong>Depth:</strong> 참조 이미지의 깊이 맵(depth map)을 추출하여, 새로운 이미지에 동일한 공간적 구도를 적용한다.</li>
<li><strong>Segmentation:</strong> 이미지의 특정 객체나 영역을 분할(segment)하여 해당 부분만 선택적으로 수정, 추가, 또는 제거한다.</li>
<li><strong>다양한 콘텐츠 유형 생성:</strong></li>
<li><strong>360 HDRi:</strong> 텍스트나 이미지 프롬프트로부터 최대 16K 해상도의 고품질 HDRi 환경 맵을 생성하여, 3D 장면에 사실적인 조명과 반사, 배경을 손쉽게 제공한다.3</li>
<li><strong>PBR Materials:</strong> 물리 기반 렌더링(Physically Based Rendering) 재질을 생성하여, 3D 에셋의 표면이 빛과 상호작용하는 방식을 현실과 가깝게 시뮬레이션할 수 있도록 지원한다.3</li>
</ul>
<p>이러한 제어 기능들은 생성형 AI를 ’우연의 산물’을 만드는 도구에서 ’창작자의 의도를 정확히 구현’하는 전문적인 도구로 격상시키려는 시도였다. 이는 AI를 창작 과정의 단순한 대체재가 아닌, 창의성을 증폭시키는 보조자(co-pilot)로 활용하려는 전문가들의 요구에 부응하는 것이며, AI 기술이 기존의 전문 창작 워크플로우에 자연스럽게 통합되기 위한 필수적인 진화 방향을 제시했다.</p>
<h2>4.  경쟁 환경 및 시장 분석</h2>
<h3>4.1  주요 시각 생성형 AI 플랫폼 비교 분석</h3>
<p>Edify의 전략적 포지셔닝을 명확히 이해하기 위해서는, 동시대의 주요 경쟁 플랫폼인 Adobe Firefly, Midjourney, Stable Diffusion과의 다각적인 비교 분석이 필수적이다. 아래 표는 각 플랫폼의 핵심 기술, 주요 기능, 학습 데이터 소스, 상업적 안전성, 라이선스 모델, 그리고 주요 타겟 고객을 기준으로 비교 분석한 결과이다.</p>
<p>이 비교 분석표는 복잡한 생성형 AI 시장의 지형도를 한눈에 보여준다. 각 플랫폼은 서로 다른 기술적, 사업적 선택을 통해 자신만의 독자적인 시장 영역을 구축하려 했다. Edify와 Adobe Firefly는 ’상업적 안전성’과 ’기업 시장’이라는 공통분모를 가지지만, Edify는 3D 생성과 파운드리 서비스라는 차별점을, Firefly는 자사의 강력한 크리에이티브 소프트웨어 생태계와의 깊은 통합을 강점으로 내세웠다. 반면 Midjourney는 타의 추종을 불허하는 예술적 품질과 독창적인 스타일로 개인 창작자 시장을 장악했고, Stable Diffusion은 완전한 개방성과 무한한 확장성을 무기로 개발자와 AI 커뮤니티의 지지를 받았다. 이 표는 Edify의 전략이 왜 ’기업용 고품질, 고신뢰성, 멀티모달 생성 솔루션’이라는 특정 니치 시장을 목표로 했는지를 명확하게 입증하는 핵심 자료이다.</p>
<table><thead><tr><th>기능 (Feature)</th><th>NVIDIA Edify</th><th>Adobe Firefly</th><th>Midjourney</th><th>Stable Diffusion</th></tr></thead><tbody>
<tr><td><strong>핵심 기술 (Core Tech)</strong></td><td>라플라시안/다중 시점 확산 5</td><td>독자적 확산 모델 24</td><td>독자적 확산 모델 25</td><td>잠재 공간 확산 (Latent Diffusion) 8</td></tr>
<tr><td><strong>주요 기능 (Key Features)</strong></td><td>2D, 3D, 360 HDRi, PBR, 미세조정 2</td><td>2D, 벡터, 비디오, 미세조정, 스타일 키트 24</td><td>2D 이미지, 스타일/캐릭터 참조, Pan/Zoom 27</td><td>2D 이미지, In/Outpainting, ControlNet, LoRA 8</td></tr>
<tr><td><strong>데이터 소스 (Data Source)</strong></td><td>라이선스 계약 (Shutterstock, Getty) 3</td><td>Adobe Stock, 공개 도메인, 텍스트 효과는 Adobe Fonts 29</td><td>웹 데이터 기반 (추정) 28</td><td>LAION 등 대규모 웹 데이터셋 8</td></tr>
<tr><td><strong>상업적 안전성</strong></td><td>매우 높음 (파트너사를 통한 IP 면책) 4</td><td>높음 (기업용 플랜에 IP 면책 제공) 29</td><td>사용자 책임 원칙 30</td><td>라이선스 및 모델에 따라 다름 32</td></tr>
<tr><td><strong>라이선스 모델</strong></td><td>파운드리 서비스 (B2B) 2</td><td>구독 기반 (생성 크레딧 시스템) 26</td><td>구독 기반 (GPU 시간 기반) 27</td><td>오픈소스 / 커뮤니티 / 상업용 라이선스 혼재 32</td></tr>
<tr><td><strong>주요 대상</strong></td><td>대기업, 콘텐츠 제공업체, 개발자 2</td><td>크리에이터, 마케터, 기업 29</td><td>아티스트, 디자이너, 개인 사용자 28</td><td>개발자, 연구자, AI 커뮤니티, 스타트업 8</td></tr>
</tbody></table>
<h2>5.  전략적 전환과 Edify의 유산</h2>
<h3>5.1  Edify NIM 프리뷰 중단에 대한 분석</h3>
<p>2025년 6월 6일을 기점으로, Edify가 더 이상 NVIDIA NIM(NVIDIA Inference Microservice) 프리뷰 형태로 제공되지 않는다는 공지가 다수의 NVIDIA 공식 블로그와 문서를 통해 반복적으로 확인되었다.1 대신 사용자들은 <code>build.nvidia.com</code>에서 제공되는 다양한 시각 AI 모델들을 탐색하도록 안내받고 있다.</p>
<p>이러한 변화를 Edify 프로젝트의 ’실패’나 ’폐기’로 해석하는 것은 사안의 본질을 놓치는 피상적인 분석이다. Edify 아키텍처는 여전히 Shutterstock과 같은 핵심 파트너사들의 상용 서비스에 깊숙이 통합되어 있으며 18, NVIDIA Omniverse의 차세대 Blueprint 워크플로우에서도 중요한 구성 요소로 활용되고 있다.39</p>
<p>Edify NIM 프리뷰의 중단은 특정 브랜드 모델을 전면에 내세우는 ’제품 중심 전략’에서, NVIDIA와 서드파티의 모든 AI 모델을 손쉽게 배포하고 실행할 수 있도록 지원하는 ’플랫폼 중심 전략’으로의 거시적인 전환을 의미한다. NVIDIA의 핵심 비즈니스는 GPU 하드웨어 판매이며, 이를 극대화하기 위해서는 가능한 한 많은 소프트웨어와 AI 모델이 자사 하드웨어 상에서 가장 효율적으로 실행되도록 만들어야 한다. 시장 초기에는 Edify라는 플래그십 모델을 통해 NVIDIA의 기술적 비전과 ’상업적 안전성’이라는 가치를 시장에 각인시킬 필요가 있었다. 그러나 시장이 성숙함에 따라 Stable Diffusion, Llama, FLUX.1 등 수많은 강력한 오픈소스 및 상용 모델들이 등장했다.41 이 모든 모델과 개별적으로 경쟁하는 것은 비효율적이다.</p>
<p>대신, 이 모든 모델들을 표준화된 컨테이너 형태로 최적화하여 배포할 수 있는 <strong>NIM</strong>이라는 ’운송 수단’을 제공하는 것이 훨씬 더 강력하고 확장성 있는 전략이다.43 이제 시장에서 어떤 모델이 최종 승자가 되든, 그 모델이 NIM을 통해 NVIDIA GPU 위에서 실행된다면 NVIDIA는 결국 승리하게 된다. 이는 PC 시장에서 Microsoft가 특정 하드웨어 제조사와 경쟁하는 대신 Windows라는 운영체제 플랫폼을 제공하여 시장 전체를 장악했던 전략과 유사하다. 따라서 Edify NIM의 중단은 Edify의 가치가 소멸했기 때문이 아니라, Edify라는 개별 ’승객’을 내세우기보다 모든 승객을 태울 수 있는 ‘NIM이라는 기차 시스템’ 자체를 전면에 내세우는 것이 더 큰 전략적 이점을 가지게 되었기 때문으로 해석해야 한다.</p>
<h3>5.2  NVIDIA의 차세대 시각 생성 AI 전략</h3>
<p>Edify NIM 중단 이후 NVIDIA가 제시하는 방향성은 명확하다. 이는 개방성, 통합, 그리고 지속적인 연구 개발이라는 세 가지 축으로 요약할 수 있다.</p>
<ul>
<li><strong><code>build.nvidia.com</code> - 새로운 AI 모델 허브:</strong> 이 포털은 NVIDIA의 새로운 플랫폼 전략을 상징하는 공간이다. 개발자들은 이곳에서 NVIDIA가 직접 개발한 모델뿐만 아니라 Stability AI, Black Forest Labs 등 다양한 파트너사들이 제공하는 최신 모델들을 NIM 형태로 자유롭게 탐색하고 배포할 수 있다.41 이는 선택의 폭을 넓혀 개발자 생태계를 NVIDIA 플랫폼으로 유인하고, 특정 모델에 대한 종속성을 줄이는 역할을 한다.</li>
<li><strong>Omniverse Blueprints - 워크플로우 통합:</strong> NVIDIA는 생성형 AI 모델들을 NIM 형태로 Omniverse의 3D 워크플로우에 통합하는 레퍼런스 아키텍처인 ’Omniverse Blueprints’를 제공한다.13 이는 AI를 단순한 콘텐츠 생성 도구를 넘어, 산업 디지털 트윈, 물리 기반 시뮬레이션, 물리 AI 훈련 등 고부가가치 산업 영역으로 확장하려는 명확한 의도를 보여준다.</li>
<li><strong>지속적인 연구 개발:</strong> Edify 3D 이후에도 NVIDIA Research는 LATTE3D와 같이 더 빠르고 효율적인 Text-to-3D 모델 연구를 지속적으로 발표하고 있다.46 이는 특정 제품 브랜드의 존속 여부와는 무관하게, 핵심 기술에 대한 R&amp;D는 계속해서 진행되고 있으며, 그 성과물은 미래의 NIM이나 AI Foundry 서비스를 통해 생태계에 지속적으로 공급될 것임을 시사한다.</li>
</ul>
<h3>5.3  Edify가 남긴 유산과 미래 전망</h3>
<p>Edify는 비록 전면에 나서는 브랜드는 아니게 되었지만, NVIDIA의 AI 전략에 지울 수 없는 유산을 남겼다.</p>
<ul>
<li><strong>시장 개척의 유산:</strong> Edify는 ’기업용 생성형 AI’라는 시장을 사실상 정의했으며, ’상업적 안전성’과 ’창의적 제어’라는 기업의 핵심 요구사항을 시장의 표준으로 제시했다. 이는 Adobe Firefly와 같은 후발 주자들의 전략 수립에도 상당한 영향을 미쳤다.</li>
<li><strong>기술적 유산:</strong> Edify Image의 라플라시안 확산 모델과 Edify 3D의 다중 시점 합성 파이프라인과 같은 혁신적인 기술적 아이디어들은, 비록 Edify라는 이름으로 포장되지 않더라도 NVIDIA 내부의 후속 연구 및 제품 개발에 지속적으로 영향을 미칠 중요한 자산으로 남을 것이다.</li>
<li><strong>전략적 초석:</strong> 무엇보다 Edify는 NVIDIA AI Foundry와 NIM이라는 더 큰 플랫폼 전략의 성공 가능성을 시험하고, Shutterstock, Getty Images와 같은 핵심 데이터 파트너를 확보하는 결정적인 초석 역할을 수행했다. Edify가 없었다면, NVIDIA가 현재와 같이 강력한 플랫폼 중심의 생태계 전략을 이토록 신속하고 효과적으로 펼치기는 어려웠을 것이다.</li>
</ul>
<h2>6. 결론</h2>
<p>NVIDIA Edify의 여정은 특정 AI 모델의 흥망성쇠를 넘어, 생성형 AI 시장의 동적인 변화에 대응하는 한 기술 거인의 정교한 전략적 진화를 보여주는 사례이다. Edify는 특정 모델의 이름이기보다, NVIDIA가 생성형 AI 애플리케이션 시장에 진입하기 위해 내세웠던 기술적 비전과 전략적 접근법의 총체였다. 이 아키텍처는 선도적인 기술력을 과시하고, ’상업적 안전성’이라는 새로운 시장을 개척했으며, 핵심 파트너십을 구축하는 데 성공적으로 기여했다.</p>
<p>Edify NIM 프리뷰의 중단은 프로젝트의 종결이 아닌, 성공적인 파일럿 프로젝트 완료 후 더 큰 규모의 본 프로젝트, 즉 NIM 플랫폼 생태계 구축으로 확장하는 자연스러운 전략적 진화 과정으로 해석하는 것이 타당하다. NVIDIA는 ’최고의 AI 모델’을 직접 만드는 경쟁에 매몰되기보다, ’모든 AI 모델을 위한 최고의 플랫폼’을 제공함으로써 게임의 규칙 자체를 바꾸고 있다.</p>
<p>향후 NVIDIA는 특정 모델 브랜드를 전면에 내세우기보다는, <code>build.nvidia.com</code>과 NIM을 통해 개방형 모델 생태계를 적극적으로 지원하고, Omniverse와 같은 자사 플랫폼과의 심층적인 통합을 통해 고부가가치 산업 애플리케이션 시장에서의 지배력을 강화하려 할 것이다. 이 과정에서 Edify가 개척했던 ’신뢰할 수 있는 AI’라는 가치는 NVIDIA의 모든 생성형 AI 전략의 기저에 흐르는 핵심 원칙으로 계속해서 중요한 역할을 수행할 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>NVIDIA Edify, a Cloud-Based Generative AI Service for Creating Images, Videos, and 3D Applications D52672 | GTC Digital Spring 2023 | NVIDIA On-Demand, https://www.nvidia.com/en-us/on-demand/session/gtcspring23-d52672/</li>
<li>NVIDIA Edify Unlocks 3D Generative AI, New Image Controls for Visual Content Providers, https://blogs.nvidia.com/blog/edify-3d-generative-ai-custom-fine-tuning/</li>
<li>Decoding NVIDIA Edify — The Technology That Helps Developers Create Custom Models Trained on Their Data, https://blogs.nvidia.com/blog/ai-decoded-edify/</li>
<li>Shutterstock Launches First Ethical Generative 3D API, https://investor.shutterstock.com/news-releases/news-release-details/shutterstock-launches-first-ethical-generative-3d-api</li>
<li>Edify Image: High-Quality Image Generation with Pixel Space Laplacian Diffusion Models, https://huggingface.co/papers/2411.07126</li>
<li>High-Quality Image Generation with Pixel Space Laplacian Diffusion Models - arXiv, https://arxiv.org/html/2411.07126v1</li>
<li>[2112.10752] High-Resolution Image Synthesis with Latent Diffusion Models - arXiv, https://arxiv.org/abs/2112.10752</li>
<li>Stable Diffusion - Wikipedia, https://en.wikipedia.org/wiki/Stable_Diffusion</li>
<li>High-Quality Image Generation with Pixel Space Laplacian Diffusion …, https://simg.baai.ac.cn/paperfile/9a832fdd-f899-4016-bb13-8ac1a7824b59.pdf</li>
<li>Edify 3D: Scalable High-Quality 3D Asset Generation - arXiv, https://arxiv.org/html/2411.07135v1</li>
<li>Edify 3D: Scalable High-Quality 3D Asset Generation | OpenReview, <a href="https://openreview.net/forum?id=KJ8MUtjWj0&amp;referrer=%5Bthe+profile+of+Donglai+Xiang%5D(/profile?id%3D~Donglai_Xiang1)">https://openreview.net/forum?id=KJ8MUtjWj0&amp;referrer=%5Bthe%20profile%20of%20Donglai%20Xiang%5D(%2Fprofile%3Fid%3D~Donglai_Xiang1)</a></li>
<li>NVIDIA’s Edify 3D model quickly generates high-quality 3D assets from text or image prompts in under 2 minutes, using multi-view diffusion and transformers. With 4K textures, realistic materials and optimized mesh structures, it’s a powerful scalable tool for simulation : r/singularity - Reddit, https://www.reddit.com/r/singularity/comments/1gredul/nvidias_edify_3d_model_quickly_generates/</li>
<li>NVIDIA Expands Omniverse With Generative Physical AI, https://nvidianews.nvidia.com/news/nvidia-expands-omniverse-with-generative-physical-ai</li>
<li>Custom Models for Generative AI | NVIDIA AI Foundry, https://www.nvidia.com/en-us/ai/foundry/</li>
<li>How Gen AI Helps Create and Edit Photorealistic Materials - NVIDIA Blog, https://blogs.nvidia.com/blog/siggraph-research-generative-ai-materials-3d-scenes/</li>
<li>NVIDIA Announces Generative AI Services for Language, Visual Content, and Biology Applications, https://developer.nvidia.com/blog/nvidia-announces-generative-ai-services-for-language-visual-content-and-biology-applications/</li>
<li>NVIDIAS NEW Insane PICASSO SHOCKS The Entire Industry! (NEW SOFTWARE ANNOUNCED!) - YouTube, https://www.youtube.com/watch?v=dHY5LWfkYLk</li>
<li>Shutterstock Releases Generative 3D, Getty Images Upgrades Service Powered by NVIDIA, https://blogs.nvidia.com/blog/edify-shutterstock-getty-images/</li>
<li>The Ultimate Generative 3D API Toolkit - Shutterstock, https://www.shutterstock.com/es/discover/generative-ai-3d</li>
<li>NVIDIA Edify Powers 3D Generative AI &amp; Fine-Tuning AI Image Creation - AI Secrets, https://aisecrets.com/news/nvidia-edify-3d-model-generation/</li>
<li>Exploring NVIDIA Edify’s AI &amp; Image Tools for Creators : r/ArtificialInteligence - Reddit, https://www.reddit.com/r/ArtificialInteligence/comments/1bjl7ga/exploring_nvidia_edifys_ai_image_tools_for/</li>
<li>Getty Images Introduces Updated AI Model with Increased Speed, Quality, and Accuracy, https://investors.gettyimages.com/news-releases/news-release-details/getty-images-introduces-updated-ai-model-increased-speed-quality/</li>
<li>NVIDIA Researchers Harness Real-Time Gen AI to Build Immersive Desert World, https://blogs.nvidia.com/blog/real-time-3d-generative-ai-research-siggraph-2024/</li>
<li>Adobe Firefly FAQ, https://helpx.adobe.com/firefly/get-set-up/learn-the-basics/adobe-firefly-faq.html</li>
<li>What Is Midjourney? Here’s What You Need to Know About the AI Image Generator - CNET, https://www.cnet.com/tech/services-and-software/what-is-midjourney-heres-what-you-need-to-know-about-the-ai-image-generator/</li>
<li>Adobe Firefly - Free Generative AI for creatives, https://www.adobe.com/products/firefly.html</li>
<li>Comparing Midjourney Plans, https://docs.midjourney.com/hc/en-us/articles/27870484040333-Comparing-Midjourney-Plans</li>
<li>How to use Midjourney | Zapier, https://zapier.com/blog/how-to-use-midjourney/</li>
<li>Adobe Firefly | Comprehensive &amp; Commercially Safe AI Content Creation for Businesses, https://business.adobe.com/products/firefly-business/firefly-ai-approach.html</li>
<li>Terms of Service - MidJourney Docs, https://docs.midjourney.com/hc/en-us/articles/32083055291277-Terms-of-Service</li>
<li>4.2 – Midjourney Copyright And Licensing Lesson - Futurepedia, https://www.futurepedia.io/courses/midjourney-mastery/lessons/midjourney-copyright-and-licensing</li>
<li>Stability AI License, https://stability.ai/license</li>
<li>SD3 Usage License Is Insane and Absurd! - Medium, https://medium.com/@codingdudecom/sd3-license-9377f5dcfe57</li>
<li>Generative credits FAQ - Adobe Help Center, https://helpx.adobe.com/firefly/get-set-up/learn-the-basics/generative-credits-faq.html</li>
<li>LICENSE.md · stabilityai/stable-diffusion-3.5-large at main - Hugging Face, https://huggingface.co/stabilityai/stable-diffusion-3.5-large/blob/main/LICENSE.md</li>
<li>Research Galore From 2024: Recapping AI Advancements in 3D Simulation, Climate Science and Audio Engineering - NVIDIA Blog, https://blogs.nvidia.com/blog/ai-research-2024/</li>
<li>NVIDIA Edify Unlocks 3D Generative AI, New Image Controls for Visual Content Providers, https://resources.nvidia.com/en-us-nim/nvidia-edify-unlocks-3d-generative-ai</li>
<li>NVIDIA Media2 Transforms Content Creation, Streaming and Audience Experiences With AI, https://blogs.nvidia.com/blog/media2/</li>
<li>Into the Omniverse: How Generative AI Fuels Personalized, Brand-Accurate Visuals With OpenUSD - NVIDIA Blog, https://blogs.nvidia.com/blog/generative-ai-openusd-fuels-3d-product-configurators/</li>
<li>Building a Generative AI OpenUSD App for Brand-Accurate Marketing Visuals, https://developer.nvidia.com/blog/building-a-generative-ai-openusd-app-for-brand-accurate-marketing-visuals/</li>
<li>Explore Visual Design Models | Try NVIDIA NIM APIs, https://build.nvidia.com/explore/visual-design</li>
<li>NVIDIA NIM Revolutionizes Model Deployment, Now Available to Transform World’s Millions of Developers Into Generative AI Developers, https://nvidianews.nvidia.com/news/nvidia-nim-model-deployment-generative-ai-developers</li>
<li>NVIDIA NIM Offers Optimized Inference Microservices for Deploying AI Models at Scale, https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/</li>
<li>NVIDIA NIM for Developers, https://developer.nvidia.com/nim</li>
<li>NVIDIA Omniverse Blueprints - GitHub, https://github.com/NVIDIA-Omniverse-blueprints</li>
<li>Check out LATTE3D, NVIDIA’s peppy new text-to-3D AI model | CG Channel, https://www.cgchannel.com/2024/03/check-out-latte3d-nvidias-peppy-new-text-to-3d-ai-model/</li>
<li>Instant Latte: NVIDIA Gen AI Research Brews 3D Shapes in Under a Second, https://blogs.nvidia.com/blog/latte-3d-generative-ai-research/</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>