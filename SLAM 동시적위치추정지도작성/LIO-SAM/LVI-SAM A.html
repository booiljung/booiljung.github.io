<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:LVI-SAM</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>LVI-SAM</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">SLAM (Simultaneous Localization and Mapping)</a> / <a href="index.html">LIO-SAM</a> / <span>LVI-SAM</span></nav>
                </div>
            </header>
            <article>
                <h1>LVI-SAM</h1>
<h2>1.  LVI-SAM 패러다임: LiDAR, 비전, 관성 센서의 통합</h2>
<h3>1.1  LVI-SAM의 정의: 스무딩 및 매핑 기반의 강결합 주행 거리계</h3>
<p>LVI-SAM(Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping)은 3D LiDAR, 카메라, 관성 측정 장치(IMU)의 데이터를 강결합(Tightly-coupled)하여 실시간으로 고정밀 상태 추정 및 지도 작성을 달성하는 최첨단 SLAM(Simultaneous Localization and Mapping) 프레임워크이다.1 그 명칭은 시스템의 핵심 철학을 명확히 드러낸다. “스무딩 및 매핑(Smoothing and Mapping)“이라는 구절은 이 시스템이 필터 기반 방식과 달리, 과거의 모든 상태를 포함하는 궤적 전체를 최적화하는 스무딩 기법을 사용함을 의미한다.3 구체적으로, LVI-SAM은 모든 센서 측정값 간의 관계를 팩터 그래프(Factor Graph)로 모델링하고, 이 그래프의 확률을 최대화하는 방식으로 가장 가능성 있는 전역 상태를 추정한다. 동시에 주변 환경의 3차원 지도를 생성하는 “매핑” 작업을 수행하여, 자율 이동 로봇이 자신의 위치를 인식하고 경로를 계획하는 데 필수적인 정보를 제공한다.</p>
<p>이 시스템은 LiDAR, 비전, IMU라는 세 가지 이종 센서의 장점을 극대화하도록 설계되었다. LiDAR는 조명 변화에 강인하고 정밀한 3차원 기하 구조 정보를 제공하며, 카메라는 풍부한 텍스처 정보를 통해 장소 인식(Place Recognition)에 탁월한 성능을 보인다. IMU는 높은 주파수로 로봇의 동적 움직임을 측정하여 빠른 기동 상황에 대응하고 다른 저주파 센서 데이터의 왜곡을 보정하는 역할을 한다.4 LVI-SAM은 이 세 센서의 정보를 팩터 그래프라는 단일 최적화 프레임워크 내에서 긴밀하게 융합함으로써, 각 센서가 개별적으로 작동할 때보다 훨씬 더 높은 정확도와 강건성을 달성한다.1</p>
<h3>1.2  다중 센서 융합의 당위성: 단일 센서의 퇴화(Degeneracy) 문제 극복</h3>
<p>LVI-SAM과 같은 다중 센서 융합 시스템의 등장은 단일 센서 기반 SLAM 시스템이 직면하는 근본적인 한계, 즉 ‘퇴화(Degeneracy)’ 문제에서 비롯된다.5 퇴화란 특정 환경 조건에서 센서 데이터로부터 로봇의 움직임을 유일하게 결정할 수 없는 상황을 의미하며, 이는 위치 추정 오차의 급격한 증가 또는 시스템 실패로 이어진다.</p>
<p>비전 기반 SLAM(Visual SLAM) 또는 시각-관성 주행 거리계(Visual-Inertial Odometry, VIO)는 텍스처가 부족한 벽이나 복도, 조명이 급격하게 변하는 환경, 또는 빠른 회전으로 인한 모션 블러(motion blur)가 발생하는 상황에서 특징점 추적에 실패하여 성능이 급격히 저하된다.7 반면, LiDAR 기반 SLAM 또는 LiDAR-관성 주행 거리계(Lidar-Inertial Odometry, LIO)는 기하학적 구조가 뚜렷하지 않은 넓은 개활지나 긴 복도와 같은 환경에서 특징점을 충분히 추출하지 못해 퇴화 문제에 직면한다.8 예를 들어, 긴 복도를 따라 직진하는 경우, 전진 방향과 복도 축 방향의 회전에 대한 구속 조건이 약해져 드리프트(drift)가 누적되기 쉽다.</p>
<p>LVI-SAM의 핵심 철학은 이러한 센서들의 상보적인 특성을 활용하여 퇴화 문제를 극복하는 것이다. 비전 센서가 텍스처 부족으로 어려움을 겪는 환경(예: 흰 벽)은 종종 LiDAR에게는 명확한 평면이나 모서리와 같은 기하학적 특징을 제공한다. 반대로, LiDAR가 기하학적 특징 부족으로 실패하는 개활지(예: 평평한 들판)는 비전 센서에게 원거리의 나무나 건물과 같은 풍부한 시각적 특징점을 제공할 수 있다. IMU는 두 센서가 모두 어려움을 겪는 빠른 움직임 상황에서 단기적인 모션 추정치를 제공하여 시스템의 연속성을 보장한다. 이처럼 LVI-SAM은 각 센서가 가장 잘 작동하는 영역의 정보를 선택적으로 활용하고, 한 센서가 약점을 보이는 상황에서는 다른 센서의 정보로 보완함으로써 전체 시스템의 강건성을 극대화한다.</p>
<h3>1.3  핵심 기여: 강건한 위치 인식을 위한 새로운 기준 정립</h3>
<p>LVI-SAM이 SLAM 연구 커뮤니티에 기여한 핵심적인 내용은 다음과 같이 요약할 수 있다.</p>
<p>첫째, 팩터 그래프를 기반으로 LiDAR, 비전, IMU 센서 데이터를 강결합하여 다중 센서 융합과 장소 인식을 통한 전역 최적화를 동시에 달성하는 새로운 LVIO(Lidar-Visual-Inertial Odometry) 프레임워크를 제안했다는 점이다.1 이는 단순히 세 가지 센서를 사용하는 것을 넘어, 각 센서에서 파생된 제약 조건(constraint)들을 단일 최적화 문제로 통합하여 전역적으로 일관된 해를 구하는 체계적인 방법을 제시했다는 데 의의가 있다.</p>
<p>둘째, 시스템의 강건성을 획기적으로 향상시킨 독창적인 아키텍처를 구현했다는 점이다. LVI-SAM의 가장 큰 혁신은 센서 퇴화에 대응하는 방식에 있다. 이 시스템은 시각-관성 시스템(VIS)과 LiDAR-관성 시스템(LIS)이라는 두 개의 하위 시스템으로 구성되는데, 한쪽 하위 시스템이 실패할 경우 이를 감지하고 다른 쪽 시스템만으로 작동을 지속할 수 있도록 설계되었다.1 이는 단순히 센서를 추가하여 정확도를 높이는 것을 넘어, 실제 예측 불가능한 환경에서 발생할 수 있는 센서 실패 상황에서도 시스템 전체가 멈추지 않고 임무를 지속할 수 있도록 하는 ’아키텍처 수준의 회복탄력성(resilience)’을 구현한 것이다. 이러한 설계는 LVI-SAM을 텍스처가 부족한 환경과 기하학적 특징이 부족한 환경 모두에서 강건하게 만드는 핵심 요소이다.</p>
<p>셋째, 다양한 플랫폼, 규모, 환경에서 수집된 데이터셋을 통해 시스템의 성능을 광범위하게 검증함으로써, 후속 LVIO 연구를 위한 견고한 기준선(baseline)을 제시했다는 점이다.1 LVI-SAM의 등장은 이후 수많은 연구들이 자신들의 알고리즘 성능을 LVI-SAM과 비교하여 개선점을 입증하는 기준으로 삼게 만들었다.6 이는 LVI-SAM이 LVIO 분야에서 하나의 ’표준’으로 자리 잡았음을 방증한다.</p>
<p>결론적으로, LVI-SAM의 기여는 단순히 센서를 하나 더 추가한 것이 아니라, 시스템 아키텍처 자체를 통해 강건성을 확보하는 새로운 패러다임을 제시했다는 데 있다. 이는 센서 융합의 목표가 단순히 모든 상황에서 최대의 정확도를 추구하는 것이 아니라, 어떤 상황에서도 시스템이 안정적으로 작동하도록 보장하는 것임을 보여주는 중요한 철학적 전환이다.</p>
<h2>2.  시스템 아키텍처 및 데이터 흐름</h2>
<h3>2.1  이중 하위 시스템 프레임워크: LIS와 VIS</h3>
<p>LVI-SAM의 아키텍처는 시각-관성 시스템(Visual-Inertial System, VIS)과 LiDAR-관성 시스템(Lidar-Inertial System, LIS)이라는 두 개의 주요 하위 시스템으로 구성된다.1 이 두 시스템은 독립적으로 작동할 수도 있고, 상호 정보를 교환하며 협력할 수도 있다. 이러한 모듈식 구조는 LVI-SAM의 강건성과 유연성의 핵심이다.</p>
<p>이 아키텍처의 독창성은 두 하위 시스템이 각각 해당 분야에서 이미 성능이 검증된 최첨단 오픈소스 알고리즘을 기반으로 한다는 점에서 비롯된다. VIS는 대표적인 단안 VIO 알고리즘인 <strong>VINS-Mono</strong>를, LIS는 강력한 LIO 알고리즘인 <strong>LIO-SAM</strong>을 기반으로 개조 및 통합되었다.15 이는 LVI-SAM이 완전히 새로운 VIO나 LIO를 개발하는 대신, 기존의 강력한 모듈들을 효과적으로 ’통합’하고 그들 사이의 ’인터페이스’를 설계하는 시스템 엔지니어링 관점의 혁신을 추구했음을 보여준다.12 이러한 접근 방식은 개발을 가속화했을 뿐만 아니라, 각 하위 시스템의 구조와 데이터 처리 방식을 결정하는 중요한 요인이 되었다.</p>
<h3>2.2  LiDAR-관성 하위 시스템 (LIS): LIO-SAM의 계승</h3>
<h4>2.2.1  특징 추출 및 지역적 스케일의 스캔 매칭</h4>
<p>LIS는 LIO-SAM의 핵심 방법론을 계승한다. 먼저, 3D LiDAR 포인트 클라우드에서 곡률이 높은 점들을 ‘엣지(edge)’ 특징점으로, 곡률이 낮은 점들을 ‘평면(planar)’ 특징점으로 추출한다.1 LVI-SAM의 실시간 성능을 보장하는 핵심적인 설계 결정 중 하나는 이 특징점들을 전역 지도(global map)가 아닌 ’지역 지도(local map)’에 정합(scan-matching)한다는 것이다. 이 지역 지도는 고정된 크기의 최근 키프레임(keyframe)들로 구성된 슬라이딩 윈도우 방식으로 유지된다.3 전역 지도 대신 지역 지도를 사용함으로써 계산 부하와 메모리 사용량을 획기적으로 줄여 실시간 처리가 가능해진다.3</p>
<h4>2.2.2  IMU 사전 통합과 슬라이딩 윈도우 지도의 역할</h4>
<p>LIS에서 IMU 데이터는 두 가지 중요한 역할을 수행한다. 첫째, LiDAR 센서가 스캔하는 동안 발생하는 로봇의 움직임으로 인한 포인트 클라우드의 왜곡(skew)을 보정(de-skewing)한다. 둘째, IMU 측정값을 사전 통합(pre-integration)하여 얻은 모션 추정치는 LiDAR 주행 거리계 최적화를 위한 초기값(initial guess)으로 사용되어, 최적화 과정의 수렴 속도와 안정성을 높인다.1 LIS는 이 과정을 통해 생성된 키프레임과 특징점들을 슬라이딩 윈도우 내의 지역 지도에 지속적으로 추가하고, 오래된 정보는 한계화(marginalization)하여 계산 복잡도를 일정하게 유지한다.1</p>
<h3>2.3  시각-관성 하위 시스템 (VIS): VINS-Mono의 적용</h3>
<h4>2.3.1  특징점 추적 및 IMU 사전 통합</h4>
<p>VIS는 VINS-Mono의 파이프라인을 기반으로 작동한다.1 먼저, 단안 카메라 이미지에서 KLT(Kanade-Lucas-Tomasi) 알고리즘과 같은 희소 특징점 추적 기법을 사용하여 시각적 특징점들을 추출하고 프레임 간에 추적한다.1 그 후, 이 시각적 측정값과 키프레임 사이의 IMU 사전 통합 측정값을 강결합하여 로봇의 상태(위치, 자세, 속도, IMU 바이어스)를 추정한다.15 IMU 데이터는 시각 정보만으로는 알 수 없는 실제 스케일(scale)을 결정하고, 빠른 움직임에 대한 강건성을 제공하는 데 필수적이다.</p>
<h4>2.3.2  시각 주행 거리계를 위한 슬라이딩 윈도우 최적화</h4>
<p>VIS 역시 LIS와 마찬가지로 슬라이딩 윈도우 최적화 기법을 사용한다.15 최근의 시간 윈도우 내에 포함된 키프레임들의 상태 변수와 3D 특징점들의 위치를 최적화 변수로 설정한다. 최적화의 목표는 윈도우 내에서 시각적 재투영 오차(visual reprojection error)와 IMU 측정 오차의 합을 최소화하는 것이다. 이 과정을 통해 VIS는 실시간으로 카메라의 궤적과 3D 특징점 지도, 그리고 IMU의 속도 및 바이어스를 추정한다.18</p>
<h3>2.4  강결합의 연결점: LIS와 VIS의 협력 방식</h3>
<p>LVI-SAM에서 “강결합“이라는 용어는 시스템의 아키텍처를 이해하는 데 있어 미묘한 해석을 필요로 한다. 프론트엔드에서는 두 하위 시스템이 독립적으로 특징을 처리하고 주행 거리계를 계산한 뒤, 그 <em>결과물</em>을 서로 교환하는 방식으로 상호작용한다. 이는 약결합(loosely-coupled) 방식의 특징을 일부 포함한다. 그러나 백엔드에서는 두 시스템에서 생성된 모든 제약 조건들이 하나의 팩터 그래프 내에서 <em>공동으로 최적화</em>되어 단일의 전역적으로 일관된 상태 추정치를 산출한다. 이것이 LVI-SAM을 강결합 시스템으로 정의하는 핵심적인 이유이다.1 이러한 하이브리드 아키텍처는 각 서브시스템의 모듈성과 강건성을 유지하면서도 전역 최적화의 정확성을 확보하기 위한 실용적인 설계의 결과물이다. 두 시스템의 구체적인 협력 방식은 다음과 같다.</p>
<h4>2.4.1  상호 초기값 제공 및 데이터 교환</h4>
<p>두 하위 시스템은 서로의 추정 결과를 활용하여 성능을 향상시킨다. VIS는 시스템 시작 시 초기화 과정이 복잡할 수 있는데, 이때 LIS의 안정적인 초기 추정치를 활용하여 더 빠르고 정확하게 초기화를 수행할 수 있다.1 반대로, LIS의 LiDAR 스캔 매칭 과정에서는 VIS가 추정한 주행 거리계(visual odometry) 결과가 매우 효과적인 초기값으로 사용된다. 이는 스캔 매칭의 탐색 공간을 줄여 계산 효율성을 높이고, 잘못된 지역 최솟값에 빠질 위험을 감소시킨다.1</p>
<h4>2.4.2  시각 특징점을 위한 LiDAR 기반 깊이 정보 강화</h4>
<p>이는 두 시스템 간의 가장 중요한 강결합 메커니즘 중 하나이다. VIS는 기본적으로 단안 카메라를 사용하므로, 시각적 특징점의 깊이(depth) 정보를 직접적으로 알 수 없어 스케일 모호성(scale ambiguity) 문제가 발생한다. LVI-SAM은 LiDAR 포인트 클라우드를 카메라 이미지에 투영하여 시각적 특징점에 해당하는 3D 좌표, 즉 깊이 정보를 추출한다.1 이 과정을 통해 VIS는 일부 특징점들에 대해 마치 스테레오 카메라처럼 작동하는 ‘유사 스테레오(pseudo-stereo)’ 시스템이 되어, 스케일 정확도를 크게 향상시키고 3D 맵 포인트를 더 안정적으로 삼각측량(triangulation)할 수 있게 된다.10</p>
<h4>2.4.3  비전 기반 루프 폐쇄 및 LiDAR 정밀화</h4>
<p>루프 폐쇄(Loop closure)는 누적된 오차를 보정하는 데 필수적인 과정이다. LVI-SAM은 이 과정에서 두 센서의 장점을 영리하게 결합한다. 먼저, VIS가 BoW(Bag-of-Words)와 같은 효율적인 시각적 장소 인식 기술을 사용하여 과거에 방문했던 장소와의 루프 폐쇄 후보를 신속하게 감지한다.1 그 후, LIS가 해당 후보 프레임 간의 정밀한 LiDAR 스캔 매칭을 수행하여 기하학적으로 일치하는지 검증하고, 미세 조정을 통해 매우 정확한 상대 변환(relative transformation)을 계산한다. 이 2단계 접근 방식은 계산적으로 비싼 LiDAR 기반 루프 폐쇄 탐색을 전체 맵에 대해 수행할 필요 없이, 비전이 제시한 유망한 후보에 대해서만 정밀 검사를 수행하므로 효율성과 정확성을 모두 달성한다.</p>
<h2>3.  최적화의 핵심: 팩터 그래프 스무딩 및 매핑</h2>
<h3>3.1  상태 추정을 최대 사후 확률(MAP) 문제로 공식화</h3>
<p>LVI-SAM의 수학적 기반은 상태 추정 문제를 확률론적 관점에서 접근하는 데 있다. 시스템은 모든 센서 측정값이 주어졌을 때, 로봇의 전체 궤적(과거부터 현재까지의 모든 상태)이 나타날 가장 높은 확률을 찾는 것을 목표로 한다. 이를 최대 사후 확률(Maximum a Posteriori, MAP) 추정 문제라고 한다.3 MAP 추정 문제는 베이즈 정리를 기반으로 하며, 다음과 같이 표현될 수 있다:</p>
<p><span class="math math-display"> \hat{\mathbf{X}} = \underset{\mathbf{X}}{\arg\max} , P(\mathbf{X} | \mathbf{Z}) \propto \underset{\mathbf{X}}{\arg\max} , P(\mathbf{Z} | \mathbf{X}) P(\mathbf{X}) </span></p>
<p>여기서 <span class="math math-inline">\mathbf{X}</span>는 추정하고자 하는 모든 상태 변수(로봇의 위치, 자세, 속도, 바이어스 등)의 집합이고, <span class="math math-inline">\mathbf{Z}</span>는 모든 센서 측정값(IMU, LiDAR, 카메라)의 집합이다. <span class="math math-inline">P(\mathbf{Z} | \mathbf{X})</span>는 상태가 주어졌을 때 측정값이 나타날 확률을 나타내는 우도(likelihood)이며, <span class="math math-inline">P(\mathbf{X})</span>는 상태에 대한 사전 확률(prior)이다.</p>
<p>LVI-SAM은 이 MAP 문제를 모델링하고 해결하기 위한 도구로 팩터 그래프(Factor Graph)를 사용한다.3 팩터 그래프는 변수 노드(variable nodes)와 팩터 노드(factor nodes)로 구성된 이분 그래프(bipartite graph)로, 전체 확률 분포를 여러 개의 팩터(인자)의 곱으로 분해하여 표현한다. 센서 측정값의 노이즈가 가우시안 분포를 따른다고 가정하면, MAP 추정 문제는 비선형 최소제곱(non-linear least squares) 문제를 푸는 것과 등가가 된다. 즉, 모든 센서 측정 모델에서 발생하는 오차(잔차, residual)의 제곱 합을 최소화하는 상태 변수 <span class="math math-inline">\mathbf{X}</span>를 찾는 것이다. 이 최적화 기반 접근 방식은 루프 폐쇄와 같이 시간 순서에 맞지 않는 정보를 자연스럽게 통합할 수 있어 필터링 기반 방식보다 일반적으로 더 높은 전역 일관성과 정확도를 제공한다.9</p>
<h3>3.2. LVI-SAM 팩터 그래프의 해부학</h3>
<p>LVI-SAM의 팩터 그래프는 시스템이 추정해야 할 변수들을 나타내는 ’노드’와, 센서 측정으로부터 얻어지는 제약 조건을 나타내는 ’팩터’로 구성된다.3</p>
<h4>3.2.1. 상태 변수 (노드)</h4>
<p>팩터 그래프의 노드는 최적화를 통해 구하고자 하는 미지의 변수들이다. LVI-SAM의 상태 벡터 <span class="math math-inline">\mathbf{x}</span>는 특정 시점에서의 로봇 상태를 나타내며, 일반적으로 다음과 같이 구성된다 1:</p>
<p>x=</p>
<ul>
<li>R∈SO(3): 월드 좌표계에 대한 IMU 좌표계의 회전 행렬 (자세)</li>
<li>p∈R3: 월드 좌표계에서의 IMU 좌표계의 위치 벡터</li>
<li>v∈R3: 월드 좌표계에서의 속도 벡터</li>
<li>b=[ba,bg]: IMU 가속도계 및 자이로스코프 바이어스</li>
</ul>
<p>팩터 그래프는 각 키프레임 시점의 이러한 상태 노드들과 함께, VIS에 의해 추적되는 3D 랜드마크(특징점)의 위치를 나타내는 랜드마크 노드들을 포함한다.18</p>
<h4>3.2.2. 측정 모델 (팩터)</h4>
<p>팩터는 하나 이상의 노드에 연결되어 해당 노드들 간의 확률적 제약 조건을 나타낸다. 각 팩터는 특정 센서 측정 모델에 기반한 오차 함수(비용 함수)와 연관된다. LVI-SAM의 주요 팩터는 다음과 같다.</p>
<ul>
<li><strong>IMU 사전 통합 팩터 (IMU Pre-integration Factor):</strong> 두 연속적인 키프레임의 상태 노드(xi,xj)를 연결한다. 두 키프레임 사이에서 수집된 고주파 IMU 측정값을 사전 통합하여 생성된 상대적인 움직임 제약 조건을 나타낸다. 이 팩터는 두 상태 간의 상대적인 위치, 속도, 자세 변화를 구속한다.1</li>
<li><strong>LiDAR 주행 거리계 팩터 (Lidar Odometry Factor):</strong> LIS의 스캔 매칭 결과로부터 생성되며, 두 키프레임 간의 상대적인 변환을 제약한다. 이 팩터는 엣지 및 평면 특징점과 지도 간의 점-선, 점-평면 거리를 최소화하는 데서 파생된다.1</li>
<li><strong>시각 재투영 팩터 (Visual Reprojection Factor):</strong> 상태 노드(xi)와 3D 랜드마크 노드(lk)를 연결한다. 3D 랜드마크 lk를 i번째 키프레임의 카메라 자세로 투영했을 때의 예상 픽셀 좌표와, 실제 이미지에서 관측된 픽셀 좌표 간의 차이(재투영 오차)를 나타낸다.1 LVI-SAM은 LiDAR로부터 깊이 정보가 제공된 시각 특징점과 그렇지 않은 특징점을 구분하여 서로 다른 신뢰도를 가진 재투영 팩터를 사용한다.12</li>
<li><strong>루프 폐쇄 팩터 (Loop Closure Factor):</strong> 현재 키프레임의 상태 노드(xk)와 시간적으로 멀리 떨어진 과거의 키프레임 상태 노드(xi)를 연결한다. VIS와 LIS의 협력을 통해 루프가 감지되면, 두 키프레임 간의 상대 변환이 팩터로 추가된다. 이 팩터는 장시간 운행 시 누적된 드리프트를 전역적으로 보정하는 데 결정적인 역할을 한다.1</li>
</ul>
<h3>3.3. 최적화 과정: 잔차의 공동 최소화</h3>
<p>LVI-SAM은 위에서 설명한 모든 종류의 팩터들을 단일 팩터 그래프에 통합하고, 전체 오차의 합을 공동으로 최소화한다.1 이는 특정 센서에 편중되지 않고 모든 센서 정보를 종합적으로 고려하여 가장 일관성 있는 해를 찾는 과정이다.</p>
<p>최적화는 일반적으로 Levenberg-Marquardt(LM)와 같은 반복적인 비선형 최소제곱 솔버를 통해 수행된다. 이러한 솔버는 팩터 그래프 최적화를 위해 널리 사용되는 라이브러리인 GTSAM(Georgia Tech Smoothing and Mapping)에 구현되어 있다.17 전체 그래프를 매번 다시 최적화하는 것은 계산적으로 비효율적이므로, LVI-SAM은 iSAM2(incremental Smoothing and Mapping 2)와 같은 증분 스무딩 알고리즘을 활용한다. iSAM2는 새로운 노드와 팩터가 추가될 때마다 전체 그래프를 재계산하는 대신, 변화의 영향을 받는 부분만 효율적으로 업데이트하여 실시간 성능을 보장한다.</p>
<p>이러한 팩터 그래프 기반의 최적화 프레임워크는 LVI-SAM의 모듈성과 확장성의 핵심적인 기반이 된다. 팩터 그래프는 본질적으로 모듈식 구조를 가지고 있어, 각 센서 측정 유형이 독립적인 ’팩터’로 캡슐화된다.3 이는 새로운 종류의 센서를 시스템에 통합하는 과정을 매우 용이하게 만든다. 예를 들어, GPS, 지자계 센서, 또는 광학 흐름 센서를 추가하고 싶다면, 해당 센서의 측정 모델을 정의하는 새로운 팩터 유형을 만들고 이를 관련 상태 노드에 연결하기만 하면 된다. LIO-SAM이 선택적으로 GPS 팩터를 포함할 수 있었던 것 3과, LVI-SAM의 후속 연구인 LPVIMO-SAM이 지자계 및 광학 흐름 팩터를 동일한 그래프 구조에 추가한 것 10은 이러한 확장성을 명확히 보여준다. 따라서 LVI-SAM은 단일 알고리즘을 넘어, 다양한 센서를 융합할 수 있는 강력한 청사진으로서의 가치를 지닌다. “-SAM” 접미사가 하나의 패러다임으로 자리 잡은 것은 바로 이러한 팩터 그래프의 유연성과 강력함 때문이다.</p>
<h2>4. 성능 분석 및 벤치마킹</h2>
<h3>4.1. 표준 평가 지표</h3>
<p>SLAM 시스템의 성능을 정량적으로 평가하기 위해 표준화된 지표가 사용된다. 가장 널리 사용되는 지표는 **절대 궤적 오차(Absolute Trajectory Error, ATE)**이다. ATE는 알고리즘이 추정한 궤도와 실제 참값(ground truth) 궤도 간의 전역적인 일관성을 평가한다. 두 궤도를 먼저 정렬한 후, 각 시간 스탬프에서의 위치 차이를 계산하여 이들의 제곱평균제곱근(Root Mean Squared Error, RMSE) 값으로 나타내는 것이 일반적이다.13 낮은 ATE RMSE 값은 높은 전역 정확도를 의미한다. 이 외에도, 연속된 두 포즈 간의 상대적인 오차를 측정하는 **상대 포즈 오차(Relative Pose Error, RPE)**가 드리프트의 정도를 평가하는 데 사용되기도 한다.</p>
<h3>4.2. 표준화된 데이터셋에서의 성능 (KITTI, M2DGR, EuRoC)</h3>
<p>알고리즘 간의 공정한 비교를 위해서는 표준화된 공개 데이터셋을 사용한 평가가 필수적이다. SLAM 연구에서 널리 사용되는 데이터셋으로는 자율주행 시나리오를 담은 KITTI 21, 실내 드론 비행 데이터를 포함하는 EuRoC 23, 그리고 지상 로봇을 위한 다중 센서 데이터셋인 M2DGR 24 등이 있다.</p>
<p>특히 LVI-SAM을 평가할 때 유의할 점은, KITTI 데이터셋의 경우 IMU 데이터 주파수가 낮은 ‘Odometry’ 버전 대신, 고주파 IMU 데이터가 포함된 ‘Raw’ 버전을 사용해야 한다는 것이다.27 M2DGR 데이터셋은 실내, 실외, 완전한 어둠, 엘리베이터 이동 등 다양한 도전적인 시나리오와 풍부한 센서 구성을 포함하고 있어, LVI-SAM과 같은 다중 센서 융합 시스템의 강건성을 평가하는 데 매우 적합한 벤치마크로 활용된다.24</p>
<h3>4.3. 비교 분석: LVI-SAM 대 LIO-SAM, VINS-Mono 및 기타 최신 시스템</h3>
<p>LVI-SAM의 성능은 단독으로 평가되기보다는, 그 이전의 시스템 및 이후의 경쟁 시스템들과의 비교를 통해 그 가치가 명확해진다.</p>
<ul>
<li><strong>LIO-SAM 대비 성능 향상:</strong> 한 연구에 따르면, LIO-SAM과 비교했을 때 LVI-SAM은 시각 정보를 추가함으로써 RMSE를 약 81%까지 감소시키는 놀라운 성능 향상을 보였다.10 이는 시각 정보가 LiDAR 단독으로는 해결하기 어려운 퇴화 상황을 보완하고, 특히 루프 폐쇄를 통해 전역 드리프트를 효과적으로 줄여주기 때문이다.</li>
<li><strong>LVI-SAM 기반 개선 연구:</strong> LVI-SAM이 공개된 이후, 수많은 연구들이 이를 기반으로 특정 부분을 개선하여 성능을 더욱 향상시키는 방향으로 진행되었다. 예를 들어, 한 연구는 복잡한 야외 환경에서 LiDAR 프론트엔드를 개선하여 LVI-SAM 대비 이동 오차를 약 4.7% 감소시켰다.11 또 다른 연구는 기존의 특징점 검출기 대신 SuperPoint와 같은 최신 딥러닝 기반 검출기를 사용하여 VIS의 성능을 높임으로써, KITTI 데이터셋 05 시퀀스에서 12%, M2DGR 데이터셋 Street07 시퀀스에서 11%의 RMSE를 각각 감소시켰다.6</li>
</ul>
<p>이러한 연구 동향은 LVI-SAM이 연구 커뮤니티 내에서 차지하는 위상의 변화를 시사한다. 초기에는 최첨단(cutting-edge) 알고리즘으로 제시되었지만, 현재는 새로운 알고리즘의 성능을 검증하기 위한 ’황금 표준 기준선(gold-standard baseline)’으로 자리매김했다. 즉, LVI-SAM을 능가하는 것이 새로운 LVI-SLAM 알고리즘의 우수성을 입증하는 하나의 관문이 된 것이다. 이는 LVI-SAM의 성능이 그만큼 신뢰받고 널리 인정받고 있음을 의미하며, 그 자체의 절대적인 성능 수치를 넘어 LVI-SLAM 분야의 혁신을 촉진하는 중요한 기준점 역할을 하고 있다는 점에서 그 의의를 찾을 수 있다.</p>
<p>아래 표는 여러 연구에서 보고된 LVI-SAM 및 그 후속 알고리즘들의 성능을 요약한 것이다.</p>
<table><thead><tr><th>알고리즘</th><th>데이터셋 시퀀스</th><th>ATE (RMSE, m)</th><th>LVI-SAM 대비 성능 향상 (%)</th><th>출처</th></tr></thead><tbody>
<tr><td>LVI-SAM</td><td>-</td><td>기준</td><td>-</td><td>1</td></tr>
<tr><td>개선된 LVI-SAM (SuperPoint)</td><td>KITTI 05</td><td>-</td><td>12% RMSE 감소</td><td>6</td></tr>
<tr><td>개선된 LVI-SAM (SuperPoint)</td><td>M2DGR Street07</td><td>-</td><td>11% RMSE 감소</td><td>6</td></tr>
<tr><td>개선된 LVI-SAM (Field Env.)</td><td>복잡한 야외 환경</td><td>-</td><td>~4.7% 이동 오차 감소</td><td>11</td></tr>
<tr><td>LPVIMO-SAM</td><td>자체 수집 데이터셋</td><td>-</td><td>43.40% RMSE 감소</td><td>14</td></tr>
<tr><td>SOTA LIVO System</td><td>M2DGR</td><td>0.478</td><td>(직접 비교 없음)</td><td>25</td></tr>
</tbody></table>
<h3>4.4. 인지적으로 어려운 시나리오에서의 강건성</h3>
<p>LVI-SAM의 가장 큰 장점 중 하나는 인지적으로 어려운(perceptually-challenged) 환경에서의 강건성이다. 앞서 언급했듯이, 이 시스템은 VIS와 LIS라는 두 개의 하위 시스템으로 구성되어 있으며, 한쪽의 성능이 저하될 경우 다른 쪽이 시스템 전체의 작동을 유지한다.1</p>
<ul>
<li><strong>텍스처가 부족한(Texture-less) 환경:</strong> 복도, 창고, 터널 등 시각적 특징이 거의 없는 환경에서는 VIS의 성능이 급격히 저하된다. 이러한 상황에서 LVI-SAM은 LIS에 더 크게 의존하여 벽, 바닥, 모서리 등 기하학적 구조 정보를 바탕으로 안정적인 위치 추정을 계속한다.</li>
<li><strong>특징이 부족한(Feature-less) 환경:</strong> 넓은 들판이나 안개 낀 날씨와 같이 LiDAR가 뚜렷한 기하학적 특징을 찾기 어려운 환경에서는 LIS가 퇴화 문제에 직면할 수 있다. 이때 LVI-SAM은 VIS를 통해 원거리의 물체나 지면의 텍스처 등 시각적 정보를 활용하여 위치를 추정함으로써 시스템의 강건성을 유지한다.10</li>
</ul>
<p>이러한 고유한 이중화 및 상호 보완 설계 덕분에 LVI-SAM은 단일 센서 시스템이나 단순 융합 시스템보다 훨씬 넓은 범위의 실제 환경에서 안정적으로 작동할 수 있다.</p>
<h2>5. 실제 구현: 과제 및 고려사항</h2>
<h3>5.1. 계산 부하: CPU 및 메모리 사용량 분석</h3>
<p>LVI-SAM과 같이 복잡한 다중 센서 융합 SLAM 시스템을 실시간으로 운영하는 것은 상당한 계산 자원을 요구한다. 이는 특히 전력 소모와 탑재 중량에 제약이 있는 소형 모바일 로봇이나 드론에 시스템을 탑재할 때 중요한 고려사항이 된다.29 LVI-SAM은 VIS와 LIS라는 두 개의 하위 시스템을 동시에 실행하고, 여기에 더해 이들로부터 생성된 제약 조건들을 통합하여 전역 팩터 그래프를 최적화해야 하므로, CPU와 RAM 사용량이 높을 수밖에 없다.</p>
<p>시스템 설계자들은 이러한 계산 부하를 관리하기 위해 여러 전략을 사용했다. LIS에서 전역 지도 대신 슬라이딩 윈도우 기반의 지역 지도를 사용하는 것과 VIS에서 슬라이딩 윈도우 최적화를 수행하는 것이 대표적인 예이다.3 이러한 기법들은 계산 복잡도가 시간에 따라 무한정 증가하는 것을 막고 실시간성을 보장하는 데 필수적이다. 그럼에도 불구하고, 대규모 환경을 장시간 탐사하는 경우 지역 지도조차도 메모리에 부담을 줄 수 있다.30</p>
<p>이러한 한계는 LVI-SAM 이후에 등장한 최신 LIVO 시스템들이 계산 및 메모리 효율성을 주요 개선 목표로 삼는다는 점에서 명확히 드러난다. 예를 들어, 메모리 효율적인 하이브리드 지도 구조를 제안하거나, LiDAR 제약 조건이 충분할 때 시각적 업데이트를 적응적으로 줄이는 등의 기법들이 연구되고 있다.31 이는 LVI-SAM과 같은 초기 강결합 시스템들이 성능과 강건성을 확보하는 데 집중했다면, 다음 세대의 연구는 이를 어떻게 더 적은 자원으로 구현할 것인가에 초점을 맞추고 있음을 보여준다.</p>
<h3>5.2. 센서 외부 파라미터 교정의 중요성</h3>
<p>다중 센서 융합 시스템의 성능은 각 센서 간의 상대적인 위치와 방향, 즉 외부 파라미터(extrinsic parameters)가 얼마나 정확하게 교정(calibration)되었는지에 절대적으로 의존한다.33 부정확한 외부 파라미터는 센서 노이즈나 상태 추정 알고리즘의 퇴화 문제와 더불어 전체 시스템 오차의 주요 원인 중 하나이다.35</p>
<p>전통적인 외부 파라미터 교정은 체커보드와 같은 정교한 보정 타겟을 사용하여 사전에 수행되는데, 이는 시간이 많이 소요되고 번거로운 작업이다.33 더 큰 문제는 로봇이 운용되는 동안 발생하는 기계적 진동이나 충격으로 인해 사전에 교정된 파라미터 값이 틀어질 수 있다는 점이다.33</p>
<p>이러한 문제를 해결하기 위해, 시스템이 작동하는 동안 실시간으로 외부 파라미터를 추정하는 온라인 교정(online calibration) 기법들이 연구되고 있다. 이 방법들은 외부 파라미터를 상태 벡터의 일부로 포함시켜 다른 상태 변수들과 함께 최적화한다.33 하지만 이러한 온라인 교정 기법은 계산 비용을 추가로 발생시키는 단점이 있다.36 LVI-SAM의 기본 구현은 외부 파라미터가 사전에 정확하게 측정되었다고 가정하므로, 실제 시스템에 적용하기 위해서는 정밀한 사전 교정 작업이 반드시 선행되어야 한다.</p>
<h3>5.3. 동적 환경 탐색: 움직이는 객체의 영향</h3>
<p>대부분의 SLAM 알고리즘은 주변 환경이 정적(static)이라는 가정을 기반으로 한다. 그러나 자율주행이나 도심 로봇 서비스와 같은 실제 환경에는 자동차, 보행자 등 움직이는 객체들이 무수히 존재한다. 이러한 동적 객체들은 정적 세계 가정을 위배하여, 특징점 매칭이나 스캔 매칭 과정에 잘못된 정보를 제공하고 결과적으로 주행 거리계 추정에 심각한 오차를 유발할 수 있다.9</p>
<p>LVI-SAM의 기본 알고리즘에는 동적 객체를 명시적으로 처리하는 기능이 포함되어 있지 않다. 공식 GitHub 저장소의 이슈 트래커에 이와 관련된 질문이 제기된 것은 사용자들이 실제 환경에서 이 문제에 직면하고 있음을 보여준다.37 이 문제를 해결하기 위해 LVI-SAM을 기반으로 한 후속 연구들, 예를 들어 LVI-fusion과 같은 시스템에서는 딥러닝 기반의 이미지 분할(image segmentation) 기술을 사용하여 동적 객체를 먼저 식별하고 제거한 후, 정적인 배경에 대해서만 특징점을 추출하는 모듈을 추가하기도 했다.9 이는 실제 동적 환경에서 강건한 성능을 확보하기 위해서는 동적 객체 처리 기능이 필수적인 확장 요소임을 시사한다.</p>
<p>결론적으로, LVI-SAM이 학술적인 벤치마크에서 보여주는 강건성은 ’센서 퇴화’에 대한 것이며, 실제 현장에서의 강건성은 또 다른 차원의 문제이다. 정확한 센서 교정, 대부분 정적인 환경, 그리고 충분한 계산 자원이라는 ’숨겨진 전제 조건’들이 충족되지 않으면 알고리즘의 이론적 성능이 실제 성능으로 이어지기 어렵다. 따라서 LVI-SAM을 실제 로봇에 성공적으로 배포하기 위해서는 이러한 실용적인 문제들을 반드시 해결해야 한다.</p>
<h3>5.4. 구현 및 의존성: ROS, GTSAM, 그리고 커뮤니티의 통찰</h3>
<p>LVI-SAM의 공식 구현체는 로봇 운영체제(Robot Operating System, ROS)를 기반으로 하며, 팩터 그래프 최적화를 위해 GTSAM 라이브러리에 의존한다.17 오픈소스로 코드가 공개되어 있어 많은 연구자와 개발자들이 이를 활용하고 있으며, 이 과정에서 축적된 커뮤니티의 경험과 논의는 알고리즘의 실제적인 측면을 이해하는 데 귀중한 정보를 제공한다.</p>
<p>공식 GitHub 저장소의 이슈(Issues) 페이지를 분석해 보면 다음과 같은 실제적인 통찰을 얻을 수 있다 19:</p>
<ul>
<li><strong>결합 방식에 대한 의문:</strong> 일부 사용자들은 VIS의 결과가 LIS의 초기값으로만 사용되는 점을 지적하며, 이것이 진정한 의미의 강결합인지에 대해 의문을 제기한다. 이는 2.4절에서 논의된 하이브리드 결합 구조에 대한 실제 사용자들의 반응을 보여준다.19</li>
<li><strong>특정 환경에서의 불안정성:</strong> 한 사용자는 작은 실내 공간에서 빠르게 회전할 때 주행 거리계가 불안정해지고 드리프트가 발생하는 문제를 보고했다.38 이는 알고리즘이 특정 조건(예: 특징점이 적고 급격한 움직임이 많은 환경)에서는 여전히 한계를 가질 수 있음을 시사한다.</li>
<li><strong>하드웨어 및 소프트웨어 호환성 문제:</strong> 반복 스캔 패턴이 없는 최신 LiDAR에 대한 지원 여부나 ROS2 환경으로의 이식 문제 등, 특정 하드웨어 및 소프트웨어 환경에 대한 호환성 문제가 논의되고 있다.37</li>
<li><strong>커뮤니티 기반 개선 프로젝트:</strong> LVI-SAM-Easyused와 같은 커뮤니티 프로젝트는 공식 코드의 불명확한 외부 파라미터 설정 문제를 해결하여 사용 편의성을 높이는 것을 목표로 한다.27 이는 공식 구현체가 실제 다양한 장비에 적용되기에는 일부 실용적인 장벽이 존재하며, 커뮤니티가 이를 보완하는 역할을 하고 있음을 보여준다.</li>
</ul>
<p>이러한 커뮤니티의 피드백은 논문만으로는 알 수 없는 알고리즘의 실제적인 장단점과 한계를 파악하는 데 매우 중요하다.</p>
<h2>6. 유산과 미래 전망</h2>
<h3>6.1. 현대 SLAM 연구의 기초 기준선으로서의 LVI-SAM</h3>
<p>LVI-SAM은 등장 이후 LVI-SLAM 분야에서 가장 중요한 기준선(baseline) 중 하나로 확고히 자리 잡았다. 다수의 최신 SLAM 리뷰 논문과 연구 논문에서 LVI-SAM은 현존하는 최첨단 시스템으로 지속적으로 인용되고 있다.4 LIO-SAM과 VINS-Mono라는 두 강력한 시스템을 시스템 수준에서 성공적으로 결합한 17 이 프레임워크는, 강력하면서도 접근성 높은 플랫폼을 제공함으로써 LVI-SLAM 하위 분야의 발전을 이끌었다. 특히, 코드가 오픈소스로 공개된 점은 이러한 영향력을 가속화하는 결정적인 촉매제가 되었다.17 LVI-SAM의 성공은 단순히 하나의 뛰어난 알고리즘을 넘어서, 후속 연구들이 나아갈 방향과 비교 대상을 제시했다는 점에서 그 학술적 유산이 크다고 할 수 있다.</p>
<h3>6.2. LVI-SAM 기반 개선 및 후속 연구 동향</h3>
<p>LVI-SAM이 제시한 견고한 기반 위에서 수많은 후속 연구들이 파생되었다. 이들은 LVI-SAM의 특정 부분을 개선하거나 새로운 기능을 추가하는 방식으로 발전해왔으며, 하나의 ’알고리즘 계보’를 형성하고 있다.</p>
<ul>
<li><strong>프론트엔드 개선:</strong> 일부 연구는 LVI-SAM의 프론트엔드 성능을 향상시키는 데 집중했다. 예를 들어, VIS의 특징점 검출기를 SuperPoint와 같은 딥러닝 기반의 고성능 검출기로 교체하여 텍스처가 부족하거나 조명 변화가 심한 환경에서의 강건성을 높였다.6 또한, 울퉁불퉁하고 비구조적인 야외 환경에서의 주행을 위해 LIS의 LiDAR 프론트엔드를 개선하여 지면 특징을 더 잘 활용하거나 노이즈에 강인하게 만든 연구도 있다.11</li>
<li><strong>센서 융합 확장:</strong> LVI-SAM의 “-SAM” 아키텍처, 즉 스무딩 및 매핑 기반 팩터 그래프의 가장 큰 장점은 확장성이다. LPVIMO-SAM과 같은 연구는 이 아키텍처를 기반으로 편광 카메라(Polarization Vision), 지자계 센서(Magnetometer), 광학 흐름(Optical Flow) 센서를 추가로 통합했다.10 이는 팩터 그래프 프레임워크가 새로운 종류의 센서 제약 조건을 ‘팩터’ 형태로 손쉽게 추가할 수 있음을 보여주는 대표적인 사례이다.</li>
<li><strong>특정 과제 해결:</strong> 또 다른 연구 흐름은 LVI-SAM이 기본적으로 다루지 않는 특정 문제들을 해결하는 데 초점을 맞춘다. 예를 들어, LVI-fusion은 동적 객체가 많은 도심 환경에서의 성능 저하 문제를 해결하기 위해 이미지 분할 모듈을 추가하여 움직이는 객체를 사전에 제거하는 기능을 구현했다.9</li>
</ul>
<p>이러한 연구들은 LVI-SAM이 단지 완성된 시스템이 아니라, 다양한 방향으로 확장되고 발전할 수 있는 강력한 플랫폼임을 입증한다.</p>
<h3>6.3. 미해결 과제 및 LVI-SLAM의 미래 연구 방향</h3>
<p>LVI-SAM과 그 후속 연구들의 눈부신 발전에도 불구하고, LVI-SLAM 분야에는 여전히 해결해야 할 중요한 과제들이 남아있다.</p>
<ul>
<li><strong>계산 효율성:</strong> 앞서 논의했듯이, 복잡한 융합 시스템의 높은 계산 및 메모리 요구사항은 자원이 제한된 플랫폼으로의 배포를 어렵게 만든다. 따라서 알고리즘의 정확도와 강건성을 유지하면서 계산 비용을 줄이는 것은 여전히 중요한 연구 주제이다.30</li>
<li><strong>극한 환경에 대한 강건성:</strong> LVI-SAM은 센서 퇴화에 대해 높은 강건성을 보이지만, 매우 빠른 속도로 울퉁불퉁한 지형을 주행하거나 11, 센서 데이터의 대부분이 손실되는 극단적인 상황에서는 여전히 실패할 수 있다. 이러한 극한 조건에서의 안정성을 보장하기 위한 연구가 계속 필요하다.</li>
<li><strong>생애주기 매핑 및 확장성(Lifelong Mapping and Scalability):</strong> 로봇이 장기간에 걸쳐 매우 넓은 영역을 탐사할 때, 계산 비용이나 메모리 사용량이 무한정 증가하지 않으면서 지도를 지속적으로 유지하고 활용하는 ’생애주기 SLAM’은 아직 완전히 해결되지 않은 문제이다.30</li>
<li><strong>의미론적 이해(Semantic Understanding):</strong> 현재의 SLAM은 주로 기하학적인 지도 작성에 머물러 있다. 미래의 SLAM은 지도를 구성하는 객체가 무엇인지(예: 자동차, 보행자, 도로)를 이해하는 의미론적(semantic) 정보를 통합하는 방향으로 나아갈 것이다. 이를 통해 로봇은 단순히 ’장애물이 있다’는 것을 넘어 ‘저것은 자동차이므로 움직일 수 있다’ 또는 ’이곳은 주행 가능한 도로이다’와 같이 더 높은 수준의 추론을 통해 지능적인 항법을 수행할 수 있게 될 것이다. BEV(Bird’s-Eye-View) 기반 경로 계획 연구 40 등은 이러한 방향으로의 초기 단계로 볼 수 있다.</li>
</ul>
<p>결론적으로, LIO-SAM과 LVI-SAM을 통해 대중화된 ‘스무딩 및 매핑(-SAM)’ 아키텍처는 현대 로보틱스 분야에서 다중 센서 융합을 위한 지배적인 설계 패턴으로 자리 잡았다. LIO-SAM이 IMU 사전 통합, 특징 추출, 지역 스캔 매칭, 그리고 팩터 그래프 기반 백엔드 최적화라는 효과적인 패턴을 확립했고 3, LVI-SAM은 전체 VIO 하위 시스템을 이 팩터 그래프에 제약 조건을 제공하는 또 다른 ’가상 센서’로 취급함으로써 이 패턴을 성공적으로 확장했다.1 LPVIMO-SAM과 같은 후속 연구들이 새로운 센서를 동일한 패턴에 따라 ’팩터’로 추가하는 방식을 따르는 것은 14 이 아키텍처의 강력함과 유연성을 증명한다. 따라서 LVI-SAM을 이해하는 것은 단순히 하나의 알고리즘을 배우는 것을 넘어, 현대 로보틱스 센서 융합의 근간을 이루는 핵심적인 설계 사상을 파악하는 것이라 할 수 있다.</p>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>