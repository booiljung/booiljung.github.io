<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:Voxblox++</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>Voxblox++</h1>
                    <nav class="breadcrumbs"><a href="../../index.html">Home</a> / <a href="../index.html">SLAM (Simultaneous Localization and Mapping)</a> / <a href="index.html">Blox</a> / <span>Voxblox++</span></nav>
                </div>
            </header>
            <article>
                <h1>Voxblox++</h1>
<h2>1. 서론</h2>
<p>로보틱스 분야에서 로봇이 주변 환경을 인식하고 이해하는 방식은 지난 수십 년간 근본적인 패러다임 전환을 겪어왔다. 초기 로봇 시스템의 주된 관심사가 장애물의 위치를 파악하여 충돌 없이 이동하는 것이었다면, 현대의 지능형 로봇에게는 훨씬 더 높은 수준의 환경 이해 능력이 요구된다. 이는 단순히 ’갈 수 있는 공간’과 ’갈 수 없는 공간’을 구분하는 기하학적 맵(Geometric Map)을 넘어, 환경을 구성하는 각 요소가 ’무엇’이며(시맨틱, semantic), ‘어떻게’ 개별적으로 존재하는지(인스턴스, instance)를 파악하는 시맨틱 맵(Semantic Map)의 구축을 의미한다.1 이러한 고차원적 정보는 로봇이 특정 물건을 집어 옮기거나(manipulation), 문을 여는 등 복잡하고 의미 있는 상호작용을 수행하기 위한 필수 전제조건이다.3</p>
<p>이러한 기술적 요구 속에서, 특히 마이크로 비행체(Micro Aerial Vehicle, MAV)와 같이 계산 자원과 탑재량이 극히 제한된 플랫폼에서의 실시간 3D 매핑은 중요한 도전 과제로 남아있었다.5 이 문제에 대한 효과적인 해법 중 하나로 <code>Voxblox</code>가 등장했다. <code>Voxblox</code>는 CPU 기반 환경에서도 실시간으로 주변 환경의 3D 기하학적 구조를 효율적으로 표현하고, 특히 경로 계획에 필수적인 장애물 거리 정보를 증분적으로(incrementally) 계산하는 강력한 프레임워크를 제공하며 학계와 산업계의 큰 주목을 받았다.6 그러나 <code>Voxblox</code>는 순수한 기하학적 정보만을 다루었기에, 로봇의 지능을 한 단계 끌어올리기 위한 시맨틱 정보의 통합이라는 과제가 남았다.</p>
<p><code>Voxblox++</code>는 바로 이 지점에서 출발한다.1</p>
<p><code>Voxblox++</code>는 견고한 기하학적 매핑 프레임워크인 <code>Voxblox</code>의 기반 위에, 객체 수준의 시맨틱 정보와 인스턴스 정보를 통합하려는 선구적인 시도였다.9 이는 3D 맵을 단순한 공간 표현에서 지식 베이스(knowledge base)로 변모시키려는 중요한 발걸음이었다.</p>
<p>본 안내서는 <code>Voxblox++</code>를 기술적, 역사적 맥락 속에서 심층적으로 고찰하는 것을 목표로 한다. 이를 위해, 먼저 <code>Voxblox++</code>의 기술적 토대가 된 <code>Voxblox</code>의 핵심 원리와 아키텍처를 상세히 분석한다. 그다음, <code>Voxblox++</code>가 시맨틱 정보를 통합하기 위해 도입한 핵심 파이프라인과 알고리즘을 해부하고, 이 과정에서 드러나는 명백한 기술적 한계와 구조적 취약점을 비판적으로 조명한다. 마지막으로, <code>Voxblox++</code>의 한계를 극복하기 위해 등장한 다양한 후속 연구들과 대안적 프레임워크들을 조망함으로써, 3D 시맨틱 매핑 기술의 발전 계보 속에서 <code>Voxblox++</code>가 차지하는 기술사적 의의와 유산을 종합적으로 평가하고자 한다.</p>
<h2>2.  <code>Voxblox</code>의 기초: 기하학적 매핑의 토대</h2>
<p><code>Voxblox++</code>를 이해하기 위해서는 그 근간을 이루는 <code>Voxblox</code>에 대한 깊이 있는 이해가 선행되어야 한다. <code>Voxblox</code>는 단순한 3D 재구성 라이브러리가 아니라, 특정 목적, 즉 자원이 제한된 로봇 플랫폼에서의 실시간 경로 계획을 위해 고도로 최적화된 시스템이다. 이 장에서는 <code>Voxblox</code>의 핵심 목표와 이를 달성하기 위한 기술적 구성 요소들을 상세히 분석한다.</p>
<h3>2.1  핵심 목표: 실시간 경로 계획을 위한 맵 표현</h3>
<p><code>Voxblox</code>의 탄생 배경에는 MAV와 같이 작고 빠른 로봇이 미지의 환경을 탐사하며 실시간으로 경로를 수정해야 하는 절박한 필요성이 자리 잡고 있다.5 이러한 로봇은 제한된 페이로드와 전력으로 인해 고성능 GPU와 같은 계산 자원을 활용하기 어렵다.5 따라서 경량화된 알고리즘이 필수적이다.</p>
<p>특히, CHOMP (Covariant Hamiltonian Optimization for Motion Planning)나 TrajOpt와 같은 궤적 최적화(Trajectory Optimization) 기반의 경로 계획 알고리즘은 로봇의 작업 공간 내 모든 지점에서 가장 가까운 장애물까지의 거리와 그 거리의 그래디언트(gradient) 정보를 요구한다.5 이 정보는 로봇이 충돌을 회피하면서도 부드럽고 효율적인 경로를 생성하는 데 결정적인 역할을 한다.</p>
<p><code>Voxblox</code>는 바로 이 ’장애물 거리 정보’를 CPU 기반 환경에서 실시간으로, 그리고 증분적으로 제공하는 것을 핵심 설계 목표로 삼았다.5</p>
<h3>2.2  Truncated Signed Distance Fields (TSDF)의 원리</h3>
<p><code>Voxblox</code>의 기본 데이터 구조는 Truncated Signed Distance Field (TSDF)이다. TSDF는 3D 공간을 복셀(Voxel)이라는 작은 정육면체 격자로 나누고, 각 복셀에 정보를 저장하는 체적 표현 방식(volumetric representation)이다.</p>
<h4>2.2.1  정의와 특징</h4>
<p>TSDF에서 각 복셀은 가장 가까운 물리적 표면(surface)까지의 부호화된 거리(signed distance)를 저장한다.5 이 거리는 다음과 같은 특징을 가진다.</p>
<ul>
<li><strong>부호(Sign):</strong> 복셀이 표면 바깥(자유 공간)에 있으면 양수(+), 표면 안쪽(점유 공간)에 있으면 음수(-) 값을 가진다. 표면 자체는 거리 0으로 표현된다.</li>
<li><strong>투영 거리(Projective Distance):</strong> <code>Voxblox</code>의 TSDF는 깊이 센서의 광선(sensor ray) 방향을 따라 측정된 투영 거리를 사용한다. 이는 계산이 빠르다는 장점이 있지만, 표면에서 멀어질수록 실제 유클리드 거리와 오차가 커지는 단점이 있다.5</li>
<li><strong>절단(Truncation):</strong> 모든 공간의 거리 값을 저장하는 것은 비효율적이므로, 표면 주변의 좁은 영역(절단 반경, truncation radius) 내에서만 거리 값을 계산하고 저장한다. 이 반경을 벗어나는 영역은 최대 절단 거리 값으로 고정된다.10</li>
</ul>
<p>이러한 특징 덕분에 TSDF는 센서 노이즈에 강건하고, 연속적인 표면 정보를 암시적으로 표현하여 고품질의 메시(mesh)를 생성하는 데 유리하다.5</p>
<h4>2.2.2  가중 평균 업데이트</h4>
<p>로봇이 움직이며 새로운 깊이 정보를 얻을 때마다, TSDF 맵은 증분적으로 업데이트된다. 새로운 측정치와 기존 복셀 값을 통합하기 위해 가중 평균(weighted average) 방식이 사용된다. 특정 복셀 <span class="math math-inline">\mathbf{p}</span>에 대해, <span class="math math-inline">k</span>번째 관측이 들어왔을 때의 업데이트 과정은 다음과 같은 수식으로 표현될 수 있다.10<br />
<span class="math math-display">
D_{k}(\mathbf{p}) = \frac{W_{k-1}(\mathbf{p})D_{k-1}(\mathbf{p}) + w_k(\mathbf{p})d_k(\mathbf{p})}{W_{k-1}(\mathbf{p}) + w_k(\mathbf{p})}
</span></p>
<p><span class="math math-display">
W_{k}(\mathbf{p}) = W_{k-1}(\mathbf{p}) + w_k(\mathbf{p})
</span></p>
<p>여기서 각 변수는 다음을 의미한다.</p>
<ul>
<li><span class="math math-inline">D_{k-1}(\mathbf{p})</span>, <span class="math math-inline">W_{k-1}(\mathbf{p})</span>: 업데이트 전 복셀 <span class="math math-inline">\mathbf{p}</span>에 저장되어 있던 기존의 Signed Distance 값과 누적 가중치.</li>
<li><span class="math math-inline">d_k(\mathbf{p})</span>, <span class="math math-inline">w_k(\mathbf{p})</span>: <span class="math math-inline">k</span>번째 관측에서 복셀 <span class="math math-inline">\mathbf{p}</span>에 대해 계산된 새로운 Signed Distance 값과 그에 해당하는 가중치.</li>
<li><span class="math math-inline">D_k(\mathbf{p})</span>, <span class="math math-inline">W_k(\mathbf{p})</span>: 업데이트 후 복셀 <span class="math math-inline">\mathbf{p}</span>에 저장될 새로운 Signed Distance 값과 누적 가중치.</li>
</ul>
<p>가중치 <span class="math math-inline">w_k(\mathbf{p})</span>는 일반적으로 센서 모델에 따라 결정되며, 거리가 멀어질수록 신뢰도가 낮아지는 것을 반영한다. <code>Voxblox</code>는 특히 큰 복셀 크기를 사용할 때 발생하는 표면 왜곡을 줄이기 위해, 센서 측정치에 일정한 가중치를 부여하는 대신 거리에 따라 선형적으로 감쇠하는 가중치 전략(linear drop-off weighting)을 제안하여 정확도를 높였다.10 이 가중 평균 방식은 여러 프레임에 걸친 관측을 자연스럽게 융합하여 센서 노이즈를 효과적으로 평활화(smoothing)하는 역할을 한다.6</p>
<h3>2.3  증분적 Euclidean Signed Distance Fields (ESDF) 생성 알고리즘</h3>
<p>앞서 언급했듯이, 경로 계획 알고리즘은 투영 거리가 아닌 실제 유클리드 거리(Euclidean distance)를 필요로 한다. ESDF는 맵의 모든 복셀이 가장 가까운 점유 공간(장애물)까지의 실제 유클리드 거리를 저장하는 맵이다.6</p>
<p><code>Voxblox</code>의 핵심 기여 중 하나는 TSDF로부터 이 ESDF를 효율적으로, 그리고 증분적으로 생성하는 방법을 제시한 것이다.5</p>
<p>기존 방식들은 전체 맵이 완성된 후 일괄(batch)적으로 ESDF를 계산했는데, 이는 실시간 로봇 애플리케이션에 부적합했다.5</p>
<p><code>Voxblox</code>는 Lau 등이 제안한 점유 격자(occupancy map) 기반의 증분적 ESDF 생성 알고리즘을 TSDF 환경에 맞게 확장하고 개선했다.5</p>
<p>알고리즘의 핵심은 <strong>Wavefront Propagation</strong> (파면 전파) 방식이다.10</p>
<ol>
<li><strong>Site Voxel 식별:</strong> TSDF가 업데이트될 때, 새로 관측되어 점유 상태로 확인된 복셀(정확히는 0-crossing, 즉 부호가 바뀌는 경계에 있는 복셀)들을 ’사이트(site)’로 지정한다. 이 사이트들은 거리 계산의 기준점이 된다.</li>
<li><strong>우선순위 큐 활용:</strong> 알고리즘은 두 개의 우선순위 큐, 즉 ‘raise’ 큐와 ‘lower’ 큐를 사용한다.10</li>
</ol>
<ul>
<li><strong>Lower Queue:</strong> 새로운 사이트 복셀이 추가되거나 기존 복셀의 거리 값이 더 짧은 경로의 발견으로 인해 감소해야 할 때, 해당 복셀들이 이 큐에 추가된다. 큐에서 복셀을 하나씩 꺼내어 그 주변 26개의 이웃 복셀(26-connected neighbors)들의 거리 값을 갱신하고, 만약 이웃의 거리 값이 더 짧아졌다면 그 이웃도 큐에 추가한다. 이 과정은 마치 물에 돌을 던졌을 때 파동이 퍼져나가는 것처럼 거리 정보가 전파되는 것과 같다.</li>
<li><strong>Raise Queue:</strong> 장애물이 제거되거나 이동하여 기존 사이트 복셀이 더 이상 유효하지 않게 되면, 해당 사이트를 부모로 삼던 복셀들의 거리 정보는 무효화되어야 한다. 이 복셀들은 raise 큐에 추가되어, 주변으로 “거리가 무한대가 되었음“을 전파시켜 관련 영역의 ESDF를 재계산하도록 유도한다.12</li>
</ul>
<ol start="3">
<li><strong>증분적 업데이트:</strong> 이 방식은 맵 전체가 아닌, 변화가 발생한 지역 주변으로만 계산을 한정시킨다. 로봇은 매 순간 환경의 극히 일부만을 관측하므로, 이러한 증분적 접근은 계산량을 획기적으로 줄여 실시간 처리를 가능하게 한다.5</li>
</ol>
<h3>2.4  Voxel Hashing: 동적 맵 관리를 위한 핵심 구조</h3>
<p>로봇이 미지의 환경을 탐사할 때, 맵의 최종 크기를 미리 알 수 없다. 고정된 크기의 배열로 맵을 표현하면 메모리 낭비가 심하거나, 로봇이 예상 범위를 벗어났을 때 대처할 수 없다. <code>Voxblox</code>는 이 문제를 해결하기 위해 Niessner 등이 제안한 <strong>Voxel Hashing</strong> 기법을 채택했다.5</p>
<p>Voxel Hashing의 원리는 다음과 같다.</p>
<ul>
<li><strong>블록 단위 관리:</strong> 전체 맵 공간을 일정한 크기(예: <span class="math math-inline">16 \times 16 \times 16</span> 복셀)의 블록(Voxel Block)으로 나눈다.</li>
<li><strong>해시 테이블 매핑:</strong> 각 블록의 공간적 위치(인덱스)를 키(key)로, 해당 블록 데이터가 저장된 메모리 주소를 값(value)으로 하는 해시 테이블을 유지한다.</li>
<li><strong>동적 할당:</strong> 로봇이 새로운 공간을 관측하여 해당 위치에 복셀 블록이 필요해지면, 그때서야 메모리를 할당하고 해시 테이블에 새로운 항목을 추가한다.</li>
</ul>
<p>이 구조는 <code>Octomap</code>에서 사용하는 옥트리(octree) 구조와 비교하여 다음과 같은 장점을 가진다.5</p>
<ul>
<li><strong>빠른 접근 속도:</strong> 특정 위치의 복셀에 접근할 때, 해시 테이블을 통해 <span class="math math-inline">O(1)</span>의 상수 시간 복잡도로 해당 블록을 찾을 수 있다. 반면, 옥트리는 트리의 깊이에 비례하는 <span class="math math-inline">O(\log n)</span>의 시간이 소요된다.</li>
<li><strong>유연한 확장성:</strong> 맵의 어느 부분이든 필요에 따라 블록을 추가할 수 있어, 맵이 동적으로 성장하는 탐사 시나리오에 매우 적합하다.</li>
</ul>
<p><code>Voxblox</code>는 TSDF와 ESDF를 각각 독립적인 ’레이어(layer)’로 관리하며, 각 레이어는 자신만의 Voxel Hashing 구조를 가진다. 이를 통해 기하학 정보와 경로 계획용 거리 정보를 효율적으로 분리하여 관리할 수 있다.5</p>
<h3>2.5  성능 및 비교: <code>Voxblox</code> vs. <code>Octomap</code></h3>
<p><code>Voxblox</code>의 설계 철학은 ’읽기 쉽고 확장하기 쉬운 코드’를 우선시하면서도, 경로 계획이라는 명확한 목적을 달성하기 위한 성능 최적화를 포함한다.13 특히 주목할 만한 것은 데이터 통합기(integrator)의 성능이다.</p>
<ul>
<li><strong>Integrator 비교:</strong></li>
<li><strong><code>Simple Integrator</code>:</strong> <code>Octomap</code>과 유사하게, 센서에서 측정된 모든 3D 포인트를 개별적인 광선으로 간주하여 처리한다. 이는 정확하지만 계산량이 많다.13</li>
<li><strong><code>Fast Integrator</code>:</strong> <code>Voxblox</code>의 핵심 최적화 중 하나로, 동일한 복셀에 투영되는 여러 3D 포인트들을 하나의 그룹으로 묶어 평균 위치를 계산한 뒤, 이 평균 위치에 대해 한 번만 광선 투사(ray casting)를 수행한다. 이 ‘bundling’ 기법은 데이터 통합 속도를 크게 향상시킨다.10</li>
</ul>
<p>이러한 최적화 덕분에 <code>Voxblox</code>는 대표적인 3D 매핑 라이브러리인 <code>Octomap</code>과 비교하여 상당한 성능 우위를 보인다. KITTI 데이터셋을 이용한 벤치마크 결과는 이를 명확히 뒷받침한다.13</p>
<p><strong>표 1: <code>Voxblox</code>와 <code>Octomap</code> 성능 비교 (KITTI 데이터셋 기반)</strong></p>
<table><thead><tr><th>복셀 크기 (Voxel Size)</th><th><code>Voxblox</code> (fast integrator)</th><th><code>Voxblox</code> (simple integrator)</th><th><code>Octomap</code></th><th></th></tr></thead><tbody>
<tr><td>5 cm</td><td>13.9 ms/scan</td><td>110.1 ms/scan</td><td>215.1 ms/scan</td><td></td></tr>
<tr><td>10 cm</td><td>11.7 ms/scan</td><td>94.2 ms/scan</td><td>175.7 ms/scan</td><td></td></tr>
<tr><td>20 cm</td><td>10.3 ms/scan</td><td>81.3 ms/scan</td><td>142.1 ms/scan</td><td></td></tr>
</tbody></table>
<p>출처:.13 Intel i7-4810MQ CPU @ 2.8 GHz 환경에서 측정된 평균 통합 시간(ms/scan). 값이 낮을수록 성능이 우수함.</p>
<p>이 표에서 볼 수 있듯이, <code>Voxblox</code>의 fast integrator는 모든 복셀 크기에서 <code>Octomap</code>보다 월등히 빠른 처리 속도를 보여준다. 20cm 복셀 크기에서는 10배 이상 빠른 성능을 기록하며, 이는 <code>Voxblox</code>가 실시간 애플리케이션에 얼마나 적합한지를 정량적으로 증명한다.</p>
<p>이러한 <code>Voxblox</code>의 성공은 <strong>목적 지향적 설계의 승리</strong>로 해석될 수 있다. <code>Voxblox</code>는 3D 재구성의 시각적 품질이나 모든 시나리오에 대응하는 범용성 대신, ’자원이 제한된 MAV에서의 실시간 경로 계획’이라는 매우 구체적인 문제에 집중했다.5 이 명확한 목표는 시스템의 모든 설계 결정에 영향을 미쳤다. 예를 들어, GPU가 아닌 CPU 코어 하나에서도 실시간 동작이 가능하도록 설계한 점 6, Voxel Hashing을 통한 효율적인 메모리 관리, TSDF에서 ESDF로의 증분적 변환, 그리고 Fast Integrator를 통한 빠른 데이터 통합은 모두 이 목표를 달성하기 위한 필연적인 선택이었다. 그 결과,</p>
<p><code>Voxblox</code>는 <code>Octomap</code>과 같은 범용 라이브러리가 제공할 수 없는 특정 작업(궤적 최적화를 위한 ESDF 생성)에서의 압도적인 성능을 확보할 수 있었다.14 이는 로보틱스 시스템 설계에서 ‘모든 것을 적당히 잘하는’ 시스템보다 ‘필요한 한 가지를 매우 잘하는’ 시스템이 갖는 가치를 명확히 보여주는 사례라 할 수 있다.</p>
<h2>3.  <code>Voxblox++</code>의 핵심: 객체 중심 시맨틱 매핑으로의 확장</h2>
<p><code>Voxblox</code>가 3D 공간의 기하학적 구조를 효율적으로 표현하는 데 성공했다면, <code>Voxblox++</code>는 그 위에 의미론적(semantic) 레이어를 추가하여 로봇의 환경 ‘이해’ 능력을 한 차원 높이려는 시도이다. 이 장에서는 <code>Voxblox++</code>가 어떻게 <code>Voxblox</code>의 기반 위에 객체 중심의 시맨틱 맵을 구축하는지, 그 핵심 목표와 파이프라인을 상세히 분석한다.</p>
<h3>3.1  프레임워크의 목표: 단순 기하학을 넘어선 ‘이해’</h3>
<p><code>Voxblox++</code>의 근본적인 목표는 로봇이 주변 환경을 단순한 장애물의 집합이 아닌, 개별적인 의미를 가진 객체들의 집합으로 인식하게 하는 것이다.1 이는 로봇이 “저기 있는 의자를 피해가라“는 수준을 넘어 “저기 있는 컵을 집어라“와 같은 고수준의 임무를 수행하기 위한 필수적인 단계이다.</p>
<p>이를 위해 <code>Voxblox++</code>는 기존의 기하학적 맵에 다음 두 가지 핵심 정보를 추가하고자 한다.2</p>
<ol>
<li><strong>시맨틱 클래스 (Semantic Class):</strong> 각 객체가 무엇인지(예: 의자, 테이블, 사람)를 식별한다.</li>
<li><strong>인스턴스 ID (Instance ID):</strong> 같은 클래스에 속하더라도 개별 객체를 구분한다(예: 첫 번째 의자와 두 번째 의자).</li>
</ol>
<p><code>Voxblox++</code>의 중요한 특징 중 하나는 사전에 정의된 클래스의 객체들뿐만 아니라, 이전에 한 번도 본 적 없는 새로운 객체(unseen object-like instances)까지도 발견하고 3D 모델로 구축할 수 있는 능력을 목표로 한다는 점이다.1 이는 로봇이 완전히 새로운 환경에 처했을 때에도 강건하게 대처할 수 있는 일반화 능력을 부여하려는 시도이다. 결과적으로, <code>Voxblox++</code>가 생성하는 맵은 로봇의 안전한 항해(navigation)와 경로 계획뿐만 아니라, 잡기(grasping)나 조작(manipulation)과 같은 정교한 상호작용 계획에 직접적으로 사용될 수 있는 풍부한 정보를 담게 된다.1</p>
<h3>3.2  핵심 파이프라인: Geometric-Semantic 융합</h3>
<p><code>Voxblox++</code>는 RGB-D 카메라로부터 들어오는 연속적인 이미지 스트림과, 외부 SLAM 시스템(예: VINS-Mono, ROVIO)으로부터 추정된 카메라의 6-DoF 포즈를 입력으로 받아 동작한다.1 전체 파이프라인은 크게 세 단계로 구성된다.</p>
<h4>3.2.1  1단계: 프레임 단위 분할 (Per-frame Segmentation)</h4>
<p>각각의 새로운 RGB-D 프레임이 들어올 때마다, <code>Voxblox++</code>는 두 종류의 분할 작업을 병렬적으로 수행하여 3D 공간에 대한 초기 추정을 생성한다.1</p>
<ul>
<li><strong>기하학적 분할 (Geometric Segmentation):</strong> 이 단계에서는 깊이 영상(depth image)만을 사용한다. 깊이 정보를 3D 포인트 클라우드로 변환한 뒤, 비지도 학습(unsupervised) 방식의 알고리즘을 이용해 표면의 기하학적 특징(예: 볼록성, 평탄성)에 기반하여 장면을 여러 개의 3D 세그먼트(segment)로 분할한다.1 이 세그먼트들은 객체의 일부 또는 전체에 해당할 수 있는 후보 영역들이다.</li>
<li><strong>시맨틱/인스턴스 분할 (Semantic/Instance Segmentation):</strong> 동시에 RGB 영상은 딥러닝 기반의 인스턴스 분할 네트워크(예: Mask R-CNN)의 입력으로 사용된다. 네트워크는 이미지의 각 픽셀에 대해 시맨틱 클래스(예: ‘의자’)와 인스턴스 ID(예: ‘의자_1’)를 예측하는 파놉틱 분할(panoptic segmentation) 마스크를 출력한다.1 이 결과는 장면에 ‘어떤’ 객체들이 ‘몇 개’ 있는지를 알려준다.</li>
</ul>
<p>이 두 분할 결과는 서로 교차(intersection)되어, 기하학적으로 의미 있으면서 동시에 시맨틱 정보가 부여된 ’표면 마스크(surface mask)’를 생성하는 데 사용된다.16</p>
<h4>3.2.2  2단계: 데이터 연관 (Data Association)</h4>
<p>프레임 단위로 생성된 수많은 3D 세그먼트들은 시간적으로 일관된 객체로 통합되어야 한다. 데이터 연관 단계는 바로 이 문제를 해결한다. 즉, 현재 프레임에서 관찰된 인스턴스 세그먼트들을 이전 프레임들로부터 구축된 전역 맵(global map) 상의 객체 인스턴스들과 연결(matching)하는 과정이다.1</p>
<p>이 과정은 현재 프레임의 3D 세그먼트와 전역 맵에 이미 존재하는 객체들 간의 유사도를 측정하여 최적의 쌍을 찾는 방식으로 이루어진다. 유사도는 기하학적 형태, 크기, 위치, 그리고 시맨틱 클래스 정보 등을 종합적으로 고려하여 계산될 수 있다. 이 데이터 연관 전략을 통해 로봇은 객체를 여러 프레임에 걸쳐 지속적으로 추적하고, 그 형태를 점진적으로 정밀하게 재구성할 수 있게 된다.1</p>
<h4>3.2.3  3단계: 전역 맵 통합 (Global Map Integration)</h4>
<p>데이터 연관이 완료되면, 각 프레임에서 얻어진 관측 정보(표면 형상, 시맨틱 클래스, 인스턴스 ID)는 최종적으로 전역 맵에 통합된다.1</p>
<p><code>Voxblox++</code>는 이 전역 맵의 기반으로 <code>Voxblox</code>의 TSDF 볼륨을 사용한다.</p>
<p>이를 위해 기존 <code>Voxblox</code>의 복셀 구조가 확장된다. 원래의 <code>Voxblox</code> 복셀은 TSDF 거리 값과 가중치 정보만을 저장했지만, <code>Voxblox++</code>의 복셀은 여기에 추가적으로 <strong>시맨틱 클래스 ID</strong>와 <strong>객체 인스턴스 ID</strong>를 저장할 수 있는 필드를 가진다.2 새로운 관측이 들어오면,</p>
<p><code>Voxblox</code>의 가중 평균 업데이트 방식과 유사하게, 각 복셀의 시맨틱 및 인스턴스 정보도 증분적으로 융합된다. 예를 들어, 특정 복셀에 대해 ’의자’라는 관측이 여러 번 들어오면 해당 복셀이 ’의자’일 신뢰도가 높아지는 방식이다.</p>
<p>이러한 통합 과정을 통해, <code>Voxblox++</code>는 기하학적으로 정확하면서도 각 복셀이 어떤 객체 인스턴스에 속하는지를 명확히 아는 풍부한 3D 시맨틱 맵을 점진적으로 구축하게 된다.</p>
<h3>3.3  기술적 구현: <code>Voxblox</code>의 확장</h3>
<p><code>Voxblox++</code>는 완전히 새로운 시스템이 아니라, 기존의 <code>Voxblox</code> 라이브러리를 확장하여 구현되었다.2 이는</p>
<p><code>Voxblox</code>가 제공하는 효율적인 복셀 해싱, TSDF/ESDF 관리, ROS 통합 등의 장점을 그대로 계승하면서, 그 위에 시맨틱 레이어를 추가하는 현명한 전략이다.</p>
<p>소스코드는 주로 C++로 작성되었으며, ETH Zurich의 ASL(Autonomous Systems Lab)에서 개발하여 GitHub를 통해 오픈소스로 공개하였다.8 이 덕분에 많은 연구자들이</p>
<p><code>Voxblox++</code>를 기반으로 다양한 연구를 수행할 수 있었다. 예를 들어, <code>voxblox-plus-pro</code>와 같은 파생 프로젝트는 <code>Voxblox++</code>의 2D 인식 부분을 최신 딥러닝 모델인 YOLOACT로 교체하여 성능을 개선하려는 시도를 보여준다.17</p>
<p><code>Voxblox++</code>의 아키텍처는 <strong>2D 지능의 3D 세계로의 취약한 투영(The Brittle Projection of 2D Intelligence into a 3D World)</strong> 이라는 관점에서 해석될 수 있다. <code>Voxblox++</code>가 개발되던 시점에는 3D 포인트 클라우드를 직접 처리하는 3D 인식 기술보다, 이미지 기반의 2D 딥러닝 인식 기술이 훨씬 더 발전하고 성숙해 있었다. 따라서 <code>Voxblox++</code>의 설계자들은 이 강력한 2D 인식 능력을 최대한 활용하는 합리적인 선택을 했다. 즉, 2D 분할 결과를 깊이 정보와 결합하여 3D 공간으로 ’리프팅(lifting)’하고, 이를 <code>Voxblox</code>의 정교한 기하학적 맵에 ’덧칠’하는 방식을 채택한 것이다.1</p>
<p>하지만 이러한 설계는 구조적인 취약점을 내포하고 있다. 이 아키텍처는 2D 인식기가 만들어내는 모든 종류의 오류, 노이즈, 불확실성을 아무런 여과 없이 3D 맵으로 그대로 전파시키는 통로 역할을 한다. 2D 이미지 상에서의 작은 오분할(over/under-segmentation)이나 경계의 불확실성이 3D 공간으로 투영될 때는 기하학적 왜곡과 결합하여 훨씬 더 큰 오류로 증폭될 수 있다.15</p>
<p><code>Voxblox++</code>는 3D 공간의 기하학적 일관성이나 객체의 물리적 제약 조건을 활용하여 2D 인식 단계의 오류를 수정하는 피드백 루프(feedback loop)가 부재하다. 결국, 전체 시스템의 성능 상한선이 전적으로 입력으로 사용되는 2D 인식기의 성능에 의해 결정되는 한계를 갖게 된다. 이 본질적인 문제는 다음 장에서 다룰 <code>Voxblox++</code>의 구체적인 한계점들의 근본적인 원인이 된다.</p>
<h2>4.  <code>Voxblox++</code>의 비판적 분석 및 기술적 한계</h2>
<p><code>Voxblox++</code>는 시맨틱 매핑 분야에서 중요한 진일보를 이뤘지만, 동시에 후속 연구들이 해결해야 할 명확한 기술적 한계들을 드러냈다. 이 장에서는 <code>Voxblox++</code>의 핵심적인 약점들을 심층적으로 분석하고, 이러한 한계가 발생하는 근본적인 원인을 탐구한다.</p>
<h3>4.1  시맨틱 일관성의 부재: 잘못된 병합</h3>
<p><code>Voxblox++</code>가 직면한 가장 심각한 문제 중 하나는 <strong>시맨틱 일관성(semantic consistency)의 부재</strong>이다. 시스템은 초기 2D-3D 투영 과정에서 발생하는 기하학적 과분할(geometric over-segmentation), 즉 하나의 객체가 여러 개의 작은 조각으로 나뉘는 문제를 해결하기 위해, 기하학적으로 인접한 3D 세그먼트들을 반복적으로 병합하는 전략을 사용한다.15</p>
<p>그러나 이 병합 과정에는 치명적인 결함이 있다. <code>Voxblox++</code>는 두 세그먼트를 병합할지 여부를 결정할 때, 그들의 시맨틱 레이블이 동일한지를 확인하는 강력한 메커니즘을 갖추고 있지 않다.16 그 결과, 단순히 공간상에서 가깝다는 이유만으로 의미론적으로는 전혀 다른 두 객체가 하나의 인스턴스로 잘못 합쳐지는 오류가 빈번하게 발생한다. 예를 들어, 벽에 붙어 있는 침대를 매핑하는 경우, 2D 분할의 작은 오류로 인해 벽의 일부가 침대의 일부로 잘못 인식될 수 있다.</p>
<p><code>Voxblox++</code>는 이 잘못 인식된 벽 조각과 실제 침대 조각이 기하학적으로 가깝기 때문에, 두 세그먼트가 같은 객체라고 판단하고 병합해버린다.16 최종적으로 생성된 맵에는 벽을 침범한 기괴한 형태의 ‘침대’ 객체가 남게 된다. 이는 로봇이 객체의 정확한 형태와 경계를 알아야 하는 조작(manipulation)과 같은 작업에서 심각한 문제를 야기할 수 있다.</p>
<h3>4.2  2D 인식 노이즈의 증폭: 과분할 및 미분할 문제</h3>
<p><code>Voxblox++</code>의 아키텍처는 2D 파놉틱 분할(panoptic segmentation) 결과에 전적으로 의존하기 때문에, 2D 인식 단계에서 발생하는 노이즈에 매우 취약하다.15 2D 분할 마스크의 작은 부정확성이 3D 공간으로 투영되면서 증폭되어, 최종 3D 맵의 품질을 크게 저하시킨다.</p>
<p>실제 실험 결과들은 <code>Voxblox++</code>가 특정 종류의 객체에 대해 체계적으로 오류를 범하는 경향을 보여준다. 예를 들어, 책장과 같이 복잡한 내부 구조를 가진 객체는 종종 여러 개의 분리된 객체로 잘못 인식되거나(과분할, over-segmentation), 일부가 누락되어 불완전하게 분할(미분할, under-segmentation)된다.16 반대로, 테이블이나 바닥과 같이 크고 평평한 객체는 표면의 작은 노이즈나 조명 변화로 인해 여러 조각으로 나뉘어 인식되는 경향이 있다.16 이러한 오류들은 근본적으로 2D 분할 마스크의 경계가 3D 객체의 실제 경계와 완벽하게 일치하지 않기 때문에 발생하며, <code>Voxblox++</code>는 이러한 불일치를 보정하거나 완화할 효과적인 메커니즘을 갖추고 있지 않다.</p>
<h3>4.3  프레임 카운팅 기반 레이블링의 취약성</h3>
<p>여러 프레임에 걸쳐 관찰된 3D 객체(또는 객체 조각)의 최종 시맨틱 레이블과 인스턴스 ID를 결정하는 과정에서도 <code>Voxblox++</code>는 단순하고 취약한 방식을 사용한다. <code>Voxblox++</code>는 ’프레임 카운팅(frame counting)’이라는 기법을 사용하는데, 이는 특정 3D 세그먼트에 대해 여러 프레임에서 관찰된 레이블들 중 가장 빈번하게 나타난 레이블을 최종 레이블로 선택하는 방식이다.16</p>
<p>이 방식은 직관적이지만 다음과 같은 심각한 문제점들을 내포하고 있다.16</p>
<ol>
<li><strong>관점 차이 무시:</strong> 로봇의 시점이 바뀜에 따라 2D 분할의 정확도와 노이즈 수준은 크게 달라질 수 있다. 특정 각도에서는 매우 부정확한 예측이 나올 수 있는데, 프레임 카운팅 방식은 이러한 예측의 신뢰도 차이를 전혀 고려하지 않고 오직 빈도수만을 계산한다.</li>
<li><strong>상관관계 무시:</strong> 각 3D 세그먼트의 레이블을 완전히 독립적으로 결정한다. 예를 들어, ’테이블’로 레이블링된 세그먼트 바로 위에 있는 세그먼트는 ’컵’일 확률이 높다는 식의 공간적, 의미론적 상관관계를 전혀 활용하지 않는다.</li>
<li><strong>오류 전파 및 고착화:</strong> 만약 노이즈가 심한 2D 예측이 우연히 여러 프레임에 걸쳐 반복적으로 관찰된다면, 이 잘못된 예측이 다수결 원칙에 따라 최종 레이블로 확정되어 버린다. 한번 잘못된 레이블이 부여되면 이를 바로잡기가 매우 어렵다.</li>
</ol>
<p>결과적으로, 프레임 카운팅 방식은 시시각각 변하는 관측의 질과 객체 간의 맥락 정보를 무시함으로써, 노이즈에 강건하지 못하고 종종 부정확한 시맨틱 맵을 생성하는 원인이 된다.</p>
<h3>4.4  정량적 성능의 한계</h3>
<p><code>Voxblox++</code>의 이러한 질적 한계는 정량적 평가에서도 명확하게 드러난다. <code>Voxblox++</code>의 단점들을 개선하기 위해 제안된 후속 연구들과의 비교 평가는 <code>Voxblox++</code>의 성능적 한계를 객관적으로 보여준다. 시맨틱 분할 및 인스턴스 분할의 정확도를 측정하는 주요 지표들, 예를 들어 mAP(mean Average Precision)나 PQ(Panoptic Quality) 등에서 <code>Voxblox++</code>는 최신 기법들에 비해 현저히 낮은 점수를 기록한다.16</p>
<p>특히 주목할 점은, 이러한 성능 격차가 <strong>실제 로봇 환경을 더 잘 모사하는 조건에서 더욱 커진다</strong>는 것이다. 연구실 환경에서 얻을 수 있는 완벽한 Ground Truth 궤적을 사용했을 때보다, 실제 SLAM 시스템이 추정하여 약간의 오차를 포함하는 궤적을 사용했을 때 <code>Voxblox++</code>의 성능 저하가 훨씬 더 심각하게 나타난다.15 SceneNN 데이터셋을 이용한 한 연구에서는 SLAM 추정 포즈를 사용했을 때, 제안된 방법이 <code>Voxblox++</code>보다 mAP50 기준으로 41.4 대 25.7이라는 압도적인 성능 차이를 보였다.16 이는</p>
<p><code>Voxblox++</code>가 이상적인 조건에서는 어느 정도 작동하지만, 실제 로봇이 마주하는 불확실성과 노이즈가 존재하는 현실 세계에서는 그 성능이 급격히 저하됨을 시사한다.</p>
<p>이러한 <code>Voxblox++</code>의 한계들은 단일 알고리즘의 정교함 부족 문제를 넘어, 시스템 아키텍처 수준의 근본적인 문제에서 기인한다. 이는 <strong>피드백 없는 파이프라인의 필연적 실패(The Inevitable Failure of a Feed-forward Pipeline)</strong> 로 요약될 수 있다. <code>Voxblox++</code>의 전체 정보 흐름은 <code>2D 인식 --&gt;&gt; 3D 투영 --&gt;&gt; 데이터 연관 --&gt;&gt; 맵 통합</code>이라는 엄격한 단방향(feed-forward) 파이프라인을 따른다. 파이프라인의 후반부, 즉 3D 맵 레벨에서 생성된 고차원적인 정보(예: “이 객체는 기하학적으로 완결된 형태를 가져야 한다” 또는 “벽과 침대는 서로 다른 객체이므로 병합될 수 없다”)가 파이프라인의 전반부(2D 인식 또는 데이터 연관)로 다시 전달되어 초기 추정을 수정하거나 정제하는 <strong>피드백 루프(feedback loop)</strong> 가 존재하지 않는다.</p>
<p>예를 들어, 2D 인식기가 벽의 일부를 침대로 잘못 인식하는 오류가 발생했다고 가정해보자. 이 오류는 아무런 제지 없이 3D 공간으로 투영된다. 데이터 연관 및 통합 단계에서 <code>Voxblox++</code>는 이 잘못된 세그먼트가 기하학적으로 침대와 가깝다는 이유만으로 병합을 시도할 뿐, “벽과 침대는 시맨틱적으로 다르다“는 제약 조건을 활용하여 이 병합을 거부할 수 없다.16 3D 레벨에서 명백히 비상식적인 결과를 발견하더라도, 이를 초기 2D 인식 단계에 알려 “이 영역을 다시 확인하라“고 요청할 메커니즘이 부재한 것이다.</p>
<p>이러한 아키텍처적 한계는 왜 후속 연구들이 3D 공간상에서 객체들 간의 관계를 그래프(graph)로 모델링하고, 그래프 최적화(graph optimization)와 같은 기법을 통해 전역적인 일관성(global consistency)을 강제하는 방향으로 발전했는지를 명확하게 설명해준다.15</p>
<p><code>Voxblox++</code>의 접근법이 “일단 3D로 올리고 보자“라면, 성공적인 후속 연구들은 “3D 공간의 맥락을 고려하여 의미가 맞는지 확인하며 통합하자“는, 보다 정교하고 양방향적인 접근법으로 전환한 것이다.</p>
<h2>5.  <code>Voxblox</code> 계열의 진화와 대안적 접근법</h2>
<p><code>Voxblox</code>와 <code>Voxblox++</code>가 제시한 프레임워크와 그 명확한 한계는 역설적으로 3D 매핑 연구 커뮤니티에 풍부한 연구 주제를 제공하는 기폭제가 되었다. 이 장에서는 <code>Voxblox</code> 계열의 기술이 어떻게 다양한 방향으로 진화했는지, 그리고 <code>Voxblox++</code>의 단점을 극복하기 위해 어떤 대안적 접근법들이 등장했는지를 살펴본다. <code>Voxblox</code>에서 시작된 기술적 흐름이 속도, 정확도, 전역 일관성, 시맨틱 일관성 등 다양한 문제를 해결하기 위해 어떻게 분화하고 발전했는지를 한눈에 파악하기 위해 다음 표를 먼저 제시한다.</p>
<p><strong>표 2: <code>Voxblox</code> 계열 프레임워크 비교</strong></p>
<table><thead><tr><th>프레임워크</th><th>주요 목표</th><th>핵심 기술</th><th>처리 장치</th><th>주요 공헌</th></tr></thead><tbody>
<tr><td><strong><code>Voxblox</code></strong></td><td>실시간 경로 계획을 위한 기하학적 맵</td><td>TSDF, 증분적 ESDF, Voxel Hashing</td><td>CPU</td><td>MAV를 위한 효율적인 CPU 기반 실시간 ESDF 맵 생성 5</td></tr>
<tr><td><strong><code>Voxblox++</code></strong></td><td>객체 중심 시맨틱 매핑</td><td>기하학적-시맨틱 분할 융합, 데이터 연관</td><td>CPU</td><td><code>Voxblox</code>에 인스턴스 인지 시맨틱 레이어 추가 1</td></tr>
<tr><td><strong><code>Voxfield</code></strong></td><td>ESDF 정확도 및 생성 속도 개선</td><td>비투영(Non-projective) TSDF, 완전 유클리드 거리</td><td>CPU</td><td><code>Voxblox</code>의 투영 거리 오차를 제거하여 ESDF 정확도 향상 12</td></tr>
<tr><td><strong><code>nvblox</code></strong></td><td>고해상도 매핑을 위한 GPU 가속</td><td>GPU 기반 병렬 TSDF/ESDF 통합</td><td>GPU</td><td><code>Voxblox</code>의 연산을 GPU로 가속하여 처리 속도를 수십 배 향상 12</td></tr>
<tr><td><strong><code>Voxgraph</code></strong></td><td>전역적 일관성을 갖춘 대규모 매핑</td><td>서브맵 기반 포즈 그래프 최적화 (PGO)</td><td>CPU</td><td><code>Voxblox</code> 서브맵들을 이용해 전역적으로 일관된 대규모 맵 구축 19</td></tr>
</tbody></table>
<h3>5.1  기하학적 정확도 및 연산 속도 개선</h3>
<p><code>Voxblox</code>의 기하학적 표현 자체의 한계와 CPU 기반 처리의 성능 한계를 극복하려는 연구들이 활발히 진행되었다.</p>
<ul>
<li><strong><code>Voxfield</code>:</strong> 이 프레임워크는 <code>Voxblox</code>의 ESDF가 갖는 근본적인 부정확성 문제에 집중했다.18</li>
</ul>
<p><code>Voxblox</code>는 계산 효율성을 위해 센서 광선을 따른 투영 거리(projective distance)를 사용하고, ESDF 전파 과정에서 유사 유클리드(quasi-Euclidean) 거리 근사를 사용한다. 이는 특히 표면에서 멀어지거나 복잡한 구조에서 실제 유클리드 거리와 상당한 오차를 유발할 수 있다.12</p>
<p><code>Voxfield</code>는 이를 해결하기 위해 <strong>비투영(non-projective) TSDF</strong>라는 새로운 공식을 도입하고, ESDF 계산 시 완전한 유클리드 거리를 사용하도록 알고리즘을 개선했다. 그 결과, <code>Voxfield</code>는 <code>Voxblox</code> 대비 더 정확하고 완결성 높은 기하학적 맵을 생성하며, ESDF 생성 시간 또한 최대 42%까지 단축하는 성과를 보였다.12</p>
<ul>
<li><strong><code>nvblox</code>:</strong> <code>Voxblox</code>가 CPU 기반으로 설계되어 맵의 해상도나 규모가 커질수록 성능이 저하되는 한계를 극복하기 위해 등장했다.12</li>
</ul>
<p><code>nvblox</code>는 <code>Voxblox</code>의 핵심 알고리즘들(TSDF 통합, ESDF 생성 등)을 GPU에서 병렬로 처리되도록 재설계한 라이브러리다. 이를 통해 기존 CPU 기반 시스템의 계산 병목 현상을 해결하고, 성능을 극적으로 향상시켰다. 벤치마크 결과에 따르면, <code>nvblox</code>는 표면 재구성에서 최대 177배, ESDF 계산에서 최대 31배의 속도 향상을 달성했다.12 이 덕분에 Jetson과 같은 임베디드 GPU 플랫폼에서도 고해상도의 3D 맵을 실시간으로 생성하고 업데이트하는 것이 가능해졌다.</p>
<h3>5.2  전역 일관성 확보를 위한 확장</h3>
<p><code>Voxblox</code>와 <code>Voxblox++</code>는 기본적으로 지역 맵(local map)을 생성하는 데 초점을 맞추고 있어, 로봇이 넓은 영역을 장시간 탐사할 때 발생하는 누적 오차(drift) 문제에 취약하다. 이 문제를 해결하기 위해 <code>Voxblox</code> 생태계는 전역 일관성(global consistency)을 확보하는 방향으로 확장되었다.</p>
<ul>
<li><strong><code>Voxgraph</code>:</strong> <code>Voxgraph</code>는 전역적으로 일관된 체적 맵을 구축하기 위한 프레임워크이다.19 이 시스템은 전체 환경을 하나의 거대한 맵으로 관리하는 대신, 여러 개의 작은</li>
</ul>
<p><strong>서브맵(submap)</strong> 의 집합으로 표현한다. 각 서브맵은 <code>Voxblox</code>를 이용해 생성된 지역 TSDF 맵이다. <code>Voxgraph</code>는 이 서브맵들을 노드(node)로 하는 포즈 그래프(pose graph)를 구축한다. 로봇이 이동하며 새로운 서브맵을 생성하면, 이전에 생성된 서브맵과 겹치는 영역에서 정합(registration) 제약 조건을 계산하여 그래프에 엣지(edge)로 추가한다. 또한, 루프 폐쇄(loop closure)가 감지되면(예: 로봇이 이전에 방문했던 장소로 돌아왔을 때) 그래프에 해당 제약 조건을 추가한다. 마지막으로, 포즈 그래프 최적화를 수행하여 모든 서브맵의 위치와 방향을 전역적으로 가장 일관된 상태로 조정한다. <code>Voxgraph</code>의 독창적인 점은 서브맵 간의 정합 제약 조건을 계산할 때, <code>Voxblox</code>의 SDF 표현을 직접 활용하여 계산 비용을 크게 줄였다는 것이다. 이 덕분에 CPU만으로도 수백 개의 서브맵을 포함하는 대규모 맵을 수 초 내에 최적화할 수 있게 되었다.19</p>
<h3>5.3  시맨틱 일관성 강화를 위한 후속 연구</h3>
<p><code>Voxblox++</code>가 드러낸 가장 큰 약점인 시맨틱 일관성 부재 문제를 해결하기 위한 연구들이 다수 등장했다. 이 연구들의 공통적인 접근 방식은 3D 공간에서의 전역적인 맥락 정보를 활용하여 지역적인(per-frame) 인식 오류를 바로잡는 것이다.</p>
<p>한 주요 연구 흐름은 <code>Voxblox++</code>가 독립적으로 다루었던 3D 세그먼트(논문에서는 ’슈퍼포인트(super-point)’로 지칭)들을 노드로 하는 <strong>그래프를 구축</strong>하고, 이 그래프 상에서 최적화를 수행하는 것이다.15 이 그래프의 엣지는 슈퍼포인트들 간의 공간적 인접성이나 의미론적 유사성과 같은 관계를 나타낸다. 예를 들어, “인접한 두 슈퍼포인트는 같은 인스턴스에 속할 가능성이 높다” 또는 “의자(chair) 슈퍼포인트는 테이블(table) 슈퍼포인트 근처에 나타날 가능성이 높다“와 같은 사전 지식을 제약 조건으로 모델링할 수 있다. 그 후, 그래프 최적화 알고리즘을 통해 모든 제약 조건을 가장 잘 만족시키는 방향으로 각 슈퍼포인트의 시맨틱 레이블과 인스턴스 ID를 전역적으로 조율하고 정제(refine)한다. 이 접근법은 <code>Voxblox++</code>의 단순한 프레임 카운팅 방식과 달리, 객체 간의 맥락 정보를 적극적으로 활용함으로써 잘못된 병합 및 분할 문제를 크게 개선하고, 훨씬 더 일관되고 정확한 시맨틱 맵을 생성할 수 있다.15</p>
<h3>5.4  불확실성 정량화를 통한 신뢰성 향상</h3>
<p><code>Voxblox++</code>와 같은 초기 시맨틱 매핑 시스템들은 대부분 결정론적(deterministic)으로 작동한다. 즉, 2D 인식 결과가 주어지면 이를 ’사실’로 받아들이고 맵에 통합하며, 그 예측이 얼마나 신뢰할 수 있는지에 대한 정보는 폐기된다. 이러한 한계를 극복하기 위해 매핑 과정의 불확실성을 명시적으로 모델링하고 정량화하려는 연구들이 등장했다.</p>
<ul>
<li><strong><code>Voxeland</code>:</strong> <code>Voxeland</code>는 증거 이론(Theory of Evidence, 또는 Dempster-Shafer Theory)에 기반한 새로운 확률적 시맨틱 매핑 프레임워크를 제안한다.23 이 프레임워크는 2D 신경망의 예측을 절대적인 진리가 아닌, 특정 가설에 대한 ’주관적 의견(subjective opinion)’으로 취급한다. 예를 들어, 어떤 영역에 대해 신경망이 “80% 확률로 의자, 10% 확률로 테이블, 10% 확률로 불확실“이라고 예측했다면, 이 정보를 그대로 보존한다. 시간이 지남에 따라 여러 프레임에서 들어오는 이러한 ’의견’들을 증거 이론의 규칙에 따라 통합하여 각 복셀과 객체에 대한 ’증거(evidence)’를 누적시킨다. 이 접근법의 가장 큰 장점은</li>
</ul>
<p><strong>불확실성 맵(uncertainty map)</strong> 을 생성할 수 있다는 것이다. <code>Voxeland</code>는 기하학적 레벨(이 복셀이 어떤 객체 인스턴스에 속하는지에 대한 불확실성)과 시맨틱 레벨(이 객체의 클래스가 무엇인지에 대한 불확실성) 모두에서 불확실성을 정량화할 수 있다. 이 맵은 로봇에게 “맵의 이 부분은 아직 정보가 부족하고 신뢰할 수 없으니, 다시 한번 관찰하거나 다른 각도에서 봐야 한다“와 같은 능동적인 의사결정의 근거를 제공하여, 보다 강건하고 신뢰성 있는 매핑을 가능하게 한다.23</p>
<p>이러한 진화 과정을 종합해 볼 때, <code>Voxblox</code>와 <code>Voxblox++</code>는 <strong>문제 정의로서의 프레임워크(Framework as a Problem Definition)</strong> 라는 중요한 유산을 남겼다고 평가할 수 있다. 이들 프레임워크는 그 자체로 완벽하고 최종적인 솔루션이라기보다는, 로보틱스 매핑 커뮤니티가 앞으로 해결해야 할 명확한 문제들을 정의하고, 이를 검증할 수 있는 견고한 플랫폼 또는 벤치마크의 역할을 수행했다. <code>Voxblox</code>가 제시한 기하학적 매핑의 한계점들은 각각 <code>Voxfield</code>(ESDF 정확도 부족), <code>nvblox</code>(CPU 성능 한계), <code>voxgraph</code>(전역 일관성 부재)와 같은 후속 연구들의 탄생을 직접적으로 이끌었다.12 마찬가지로,</p>
<p><code>Voxblox++</code>가 드러낸 시맨틱 매핑의 한계점들, 즉 시맨틱 일관성 부재와 불확실성 미고려 문제는 그래프 최적화 기반의 매핑 시스템과 <code>Voxeland</code>와 같은 확률적 매핑 시스템의 등장을 촉발했다.15 결국 성공적인 연구 프레임워크의 진정한 가치는 그것이 모든 문제를 해결하는 데 있는 것이 아니라, 커뮤니티가 다음 단계에 집중해야 할 도전 과제들을 명확하게 수면 위로 드러내고, 이를 해결하기 위한 연구의 로드맵을 제시하는 데 있음을 <code>Voxblox</code> 계열의 발전사는 명확히 보여준다.</p>
<h2>6. 결론</h2>
<p>본 안내서는 <code>Voxblox++</code>를 중심으로, 그 기술적 뿌리가 된 <code>Voxblox</code>부터 시작하여 시맨틱 매핑으로의 확장 과정, 그리고 그 과정에서 드러난 명백한 한계와 이를 극복하기 위한 후속 연구들의 발전 계보를 심층적으로 추적하고 분석했다.</p>
<p><code>Voxblox++</code>의 기술사적 의의는, 실시간 기하학적 매핑의 대표 주자였던 <code>Voxblox</code>의 견고한 기반 위에 3D 공간에 객체 수준의 시맨틱 정보를 통합하려는 선구적인 시도였다는 점에서 찾을 수 있다. 이는 로봇 지능의 패러다임이 단순히 ’어디로 갈 수 있는가(navigability)’의 문제를 넘어, 환경과 ’무엇을 할 수 있는가(interactability)’의 문제로 나아가는 중요한 전환점에서 교량 역할을 수행했음을 의미한다. <code>Voxblox++</code>는 기하학과 시맨틱을 결합하는 통합 프레임워크를 구체적으로 제시하고 이를 오픈소스로 공개함으로써, 이후 수많은 후속 연구들이 등장할 수 있는 귀중한 발판을 마련했다는 점에서 큰 학술적, 실용적 공헌을 했다.2</p>
<p>그러나 <code>Voxblox++</code>는 동시에 명확한 한계를 통해 2D-to-3D 시맨틱 리프팅(lifting) 방식이 가진 근본적인 도전 과제들을 수면 위로 드러냈다. 3D 공간의 맥락을 고려하지 않는 세그먼트 병합으로 인한 <strong>시맨틱 일관성 부재</strong>, 2D 인식기의 오류를 그대로 증폭시키는 <strong>노이즈 취약성</strong>, 그리고 관측의 질과 객체 간의 상관관계를 무시하는 <strong>단순한 프레임 카운팅 기반 레이블링 방식</strong>은 <code>Voxblox++</code>가 강건하고 신뢰성 있는 시맨틱 맵을 생성하는 데 있어 넘어야 할 높은 장벽이었다.15 이러한 한계는 특정 알고리즘의 미흡함을 넘어, 3D 레벨의 정보가 2D 인식 단계로 피드백되지 않는 단방향 파이프라인이라는 아키텍처 수준의 문제에서 기인했다.</p>
<p>역설적이게도, <code>Voxblox++</code>가 명확하게 보여준 이러한 한계점들은 로보틱스 매핑 커뮤니티에 해결해야 할 다음 문제들을 제시하는 역할을 했다. <code>Voxblox</code>의 기하학적 부정확성과 성능 한계가 <code>Voxfield</code>와 <code>nvblox</code>의 탄생을 이끌었듯이, <code>Voxblox++</code>의 시맨틱 일관성 부재는 3D 공간의 전역적 관계를 모델링하는 그래프 기반 최적화 기법의 발전을 촉진했다. 또한, <code>Voxblox++</code>의 결정론적 접근법의 한계는 <code>Voxeland</code>와 같이 불확실성을 정량적으로 다루는 확률적 매핑 프레임워크의 필요성을 부각시켰다. 이처럼 <code>Voxblox</code>와 <code>Voxblox++</code>는 정답이 아닌, 더 나은 질문을 던진 프레임워크로서 그 유산을 남겼다.</p>
<p>미래의 3D 시맨틱 매핑 기술은 <code>Voxblox++</code>가 제시했던 방향성을 계승하되, 그 한계를 극복하는 방향으로 진화할 것이 자명하다. 이는 단순히 시맨틱 레이블을 맵에 추가하는 것을 넘어, 전역적 기하학 및 시맨틱 일관성 확보, 사람이나 다른 로봇과 같은 동적 객체에 대한 강건한 대응 능력, 센서 노이즈와 인식 오류를 포함하는 불확실성의 명시적 처리, 그리고 객체 간의 기능적, 물리적 관계를 이해하는 더 깊은 수준의 장면 이해(scene understanding)를 통합하는 방향으로 나아갈 것으로 전망된다.3</p>
<p><code>Voxblox++</code>는 그 여정의 중요한 시작점 중 하나로 기억될 것이다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>(PDF) Volumetric Instance-Aware Semantic Mapping and 3D Object Discovery, https://www.researchgate.net/publication/331485448_Volumetric_Instance-Aware_Semantic_Mapping_and_3D_Object_Discovery</li>
<li>Volumetric Instance-Aware Semantic Mapping and 3D Object Discovery - GitHub Pages, https://jenjenchung.github.io/anthropomorphic/Papers/Grinvald2019volumetric.pdf</li>
<li>Semantic Mapping for Mobile Robots in Indoor Scenes: A Survey - MDPI, https://www.mdpi.com/2078-2489/12/2/92</li>
<li>Autonomous Exploration and Semantic Updating of Large-Scale Indoor Environments with Mobile Robots - arXiv, https://arxiv.org/html/2409.15493v2</li>
<li>Voxblox: Incremental 3D Euclidean Signed Distance Fields for On-Board MAV Planning - Helen Oleynikova, https://helenol.github.io/publications/iros_2017_voxblox.pdf</li>
<li>[1611.03631] Voxblox: Incremental 3D Euclidean Signed Distance Fields for On-Board MAV Planning - arXiv, https://arxiv.org/abs/1611.03631</li>
<li>ethz-asl/voxblox: A library for flexible voxel-based mapping, mainly focusing on truncated and Euclidean signed distance fields. - GitHub, https://github.com/ethz-asl/voxblox</li>
<li>ethz-asl/voxblox-plusplus: A volumetric object-level semantic mapping framework. - GitHub, https://github.com/ethz-asl/voxblox-plusplus</li>
<li>Volumetric Instance-Aware Semantic Mapping and 3D Object Discovery - arXiv, https://arxiv.org/abs/1903.00268</li>
<li>Voxblox: Incremental 3D Euclidean Signed Distance Fields for On-Board MAV Planning, https://huggingface.co/papers/1611.03631</li>
<li>Voxblox: Building 3D Signed Distance Fields for Planning - Research Collection - ETH Zürich, https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/128028/eth-50485-01.pdf</li>
<li>nvblox: GPU-Accelerated Incremental Signed Distance Field Mapping - arXiv, https://arxiv.org/html/2311.00626v2</li>
<li>Performance - voxblox documentation - Read the Docs, https://voxblox.readthedocs.io/en/latest/pages/Performance.html</li>
<li>VDBFusion: Flexible and Efficient TSDF Integration of Range Sensor Data - MDPI, https://www.mdpi.com/1424-8220/22/3/1296</li>
<li>Volumetric Semantically Consistent 3D Panoptic Mapping - arXiv, https://arxiv.org/html/2309.14737v2</li>
<li>Volumetric Semantically Consistent 3D Panoptic Mapping, https://arxiv.org/pdf/2309.14737</li>
<li>DeepDuke/voxblox-plus-pro - GitHub, https://github.com/DeepDuke/voxblox-plus-pro</li>
<li>Voxfield: Non-Projective Signed Distance Fields for Online Planning and 3D Reconstruction, https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/pan2022iros.pdf</li>
<li>ethz-asl/voxgraph: Voxblox-based Pose graph optimization - GitHub, https://github.com/ethz-asl/voxgraph</li>
<li>Voxfield: Non-Projective Signed Distance Fields for Online Planning and 3D Reconstruction - SciSpace, https://scispace.com/pdf/voxfield-non-projective-signed-distance-fields-for-online-18jrivw0.pdf</li>
<li>Voxfield: Non-Projective Signed Distance Fields for Online Planning and 3D Reconstruction, https://www.researchgate.net/publication/366610904_Voxfield_Non-Projective_Signed_Distance_Fields_for_Online_Planning_and_3D_Reconstruction</li>
<li>Mapping for online path planning and 3D reconstruction, https://ethz.ch/content/dam/ethz/special-interest/baug/igp/photogrammetry-remote-sensing-dam/documents/pdf/Student_Theses/MA_YuePan.pdf</li>
<li>Voxeland: Probabilistic Instance-Aware Semantic Mapping with Evidence-based Uncertainty Quantification* - arXiv, https://arxiv.org/html/2411.08727v1</li>
<li>Semantic Mapping in Indoor Embodied AI – A Comprehensive Survey and Future Directions, https://arxiv.org/html/2501.05750v1</li>
<li>Object-Level Semantic Map Construction for Dynamic Scenes - MDPI, https://www.mdpi.com/2076-3417/11/2/645</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>