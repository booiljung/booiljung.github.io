<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIJUNG:SLAM 기술 역사</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117607984-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-117607984-2');
    </script>

    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        startup: {
          ready: () => {
            // pulldown-cmark 출력을 MathJax 형식으로 변환
            document.querySelectorAll('.math-inline').forEach(node => {
              node.outerHTML = '$' + node.innerText + '$';
            });
            document.querySelectorAll('.math-display').forEach(node => {
              node.outerHTML = '$$' + node.innerText + '$$';
            });
            MathJax.startup.defaultReady();
          }
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.esm.mjs';
        let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'default';
        mermaid.initialize({ startOnLoad: false, theme: theme });
        
        document.addEventListener("DOMContentLoaded", function() {
            var mermaidBlocks = document.querySelectorAll("pre > code.language-mermaid");
            mermaidBlocks.forEach(function(block) {
                var pre = block.parentElement;
                var div = document.createElement("div");
                div.className = "mermaid";
                div.textContent = block.textContent.trim();
                pre.replaceWith(div);
            });
            mermaid.run({
                querySelector: '.mermaid'
            });
        });
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            var toggler = document.getElementsByClassName("caret");
            for (var i = 0; i < toggler.length; i++) {
                toggler[i].addEventListener("click", function() {
                    this.parentElement.querySelector(".nested").classList.toggle("active");
                    this.classList.toggle("caret-down");
                });
            }
            
            // 활성 경로 자동 확장
            var activeLink = document.querySelector(".sidebar .active");
            if (activeLink) {
                var parents = [];
                var el = activeLink;
                while (el) {
                    if (el.classList && el.classList.contains("nested")) {
                        el.classList.add("active");
                        // 이 중첩된 목록의 캐럿 찾기
                        // 중첩된 목록은 캐럿이 있는 li 안에 있습니다
                        var li = el.parentElement;
                        if (li) {
                            var caret = li.querySelector(".caret");
                            if (caret) {
                                caret.classList.add("caret-down");
                            }
                        }
                    }
                    el = el.parentElement;
                    if (el && el.classList.contains("sidebar")) break;
                }
            }


        });
    </script>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="container">
        <main class="content">
            <header>
                <div class="header-content">
                    <h1>SLAM 기술 역사</h1>
                    <nav class="breadcrumbs"><a href="../index.html">Home</a> / <a href="index.html">SLAM (Simultaneous Localization and Mapping)</a> / <span>SLAM 기술 역사</span></nav>
                </div>
            </header>
            <article>
                <h1>SLAM 기술 역사</h1>
<p>2025-08-25, G25DR</p>
<h2>1.  SLAM 문제의 정의와 기술적 발전 과정</h2>
<h3>1.1  SLAM의 본질: 동시적 위치 추정 및 지도 작성</h3>
<p>SLAM(Simultaneous Localization and Mapping)은 로봇 공학 및 컴퓨터 비전 분야의 근본적인 문제 중 하나로, 미지의 환경에서 외부 위치 정보 시스템(예: GPS)의 도움 없이 로봇 스스로 자신의 위치를 추정함과 동시에 주변 환경의 지도를 작성하는 기술을 의미한다.1 이 문제의 핵심적인 어려움은 위치 추정(Localization)과 지도 작성(Mapping)이라는 두 과업이 서로 강하게 상호 의존적이라는 점에 있다. 정확한 지도가 있다면 로봇은 센서 데이터를 지도와 대조하여 자신의 위치를 쉽게 파악할 수 있다. 반대로, 로봇이 자신의 정확한 위치를 알고 있다면, 센서 관측을 통해 일관성 있는 지도를 구축할 수 있다. 이처럼 어느 한쪽을 해결하기 위해 다른 한쪽이 먼저 해결되어야 하는 순환적 딜레마 때문에 SLAM은 종종 ’닭과 달걀 문제(chicken or egg problem)’에 비유된다.3 SLAM 알고리즘은 이 딜레마를 해결하기 위해 위치와 지도를 동시에, 점진적으로 추정해 나가는 확률적 프레임워크를 제공한다.</p>
<h3>1.2  SLAM 기술의 시대적 구분</h3>
<p>SLAM 기술의 발전 과정은 알고리즘의 성숙도, 활용 가능한 센서 기술, 그리고 컴퓨팅 성능의 발전에 따라 크게 세 시대로 구분할 수 있다. 이는 단순히 연대기적 구분을 넘어, 각 시대가 해결하고자 했던 핵심 문제와 기술적 패러다임의 변화를 반영한다.</p>
<h4>1.2.1  이론 시대 (Theoretical Era, 1986–2010)</h4>
<p>1986년 Smith, Self, Cheeseman에 의해 SLAM 문제가 로봇의 위치와 랜드마크의 위치 간의 상관관계를 고려해야 하는 확률적 상태 추정 문제로 처음 정립되면서 이론 시대가 시작되었다.7 이 시기에는 확장 칼만 필터(EKF), 파티클 필터(Particle Filter), 최대 우도 추정(Maximum Likelihood Estimation) 등 SLAM 문제를 해결하기 위한 핵심적인 수학적, 이론적 토대가 마련되었다. 연구자들은 SLAM 알고리즘을 크게 필터링 기반 접근법과 최적화 기반 접근법의 두 갈래로 나누어 발전시켰다. 2010년 Strasdat이 필터링과 최적화 방법론을 포괄적으로 비교 분석한 연구는 이 시대의 이론적 논의를 집대성하고, 이후 단일 센서 및 다중 센서 SLAM 기술 발전의 이론적 기틀을 마련한 중요한 이정표로 평가된다.7</p>
<h4>1.2.2  단일 센서 시대 (Single-Sensor Era, 1990–2015)</h4>
<p>이론 시대에 제안된 알고리즘들이 실제 로봇 시스템에 적용되기 시작하며 SLAM 기술이 본격적으로 실용화된 시기이다. 1990년 Moutarlier가 EKF를 레이저 스캐너와 주행기록계(odometry)를 장착한 로봇에 처음 적용한 것을 시작으로, 다양한 단일 센서 기반 SLAM 알고리즘이 폭발적으로 등장했다.7 2D 레이저 SLAM 분야에서는 Gmapping, Karto SLAM과 같은 고전적인 알고리즘들이 개발되었으며, 1990년대 후반부터는 카메라를 이용한 Visual SLAM(VSLAM) 연구가 활발해져 MonoSLAM, PTAM, ORB-SLAM과 같은 기념비적인 알고리즘들이 탄생했다.7 이 시기에 연구자들은 SLAM 문제의 최적화 과정에서 나타나는 정보 행렬(H-matrix)의 희소성(sparsity)과 같은 핵심적인 구조적 특성을 이해하게 되었고, 이는 SLAM의 계산 효율성을 높이는 데 결정적인 역할을 했다. 2015년경에 이르러 다수의 고전적인 단일 센서 SLAM 알고리즘들이 높은 완성도에 도달하면서 이 시대는 막을 내렸다.7</p>
<h4>1.2.3  융합 시대 (Fusion Era, 2015-현재)</h4>
<p>단일 센서 SLAM 기술이 성숙기에 접어들면서, 연구의 초점은 여러 종류의 센서 데이터를 융합하여 단일 센서의 한계를 극복하고 강인성과 정확도를 극대화하는 방향으로 이동했다. 특히 저렴하고 소형화된 관성 측정 장치(IMU)의 보급은 카메라와 IMU를 결합한 Visual-Inertial SLAM(VIO) 또는 Visual-Inertial Odometry(VIO)의 발전을 촉진했다.8 VIO는 카메라가 특징점을 추적하기 어려운 빠른 움직임이나 텍스처가 부족한 환경에서도 IMU의 관성 정보를 이용해 안정적인 위치 추정을 가능하게 한다. 이처럼 융합 시대는 각 센서의 장점을 취하고 단점을 상호 보완하여, 더욱 복잡하고 동적인 실제 환경에서 신뢰성 있게 동작하는 SLAM 시스템을 구축하는 것을 목표로 한다.</p>
<h3>1.3  안내서의 구성 및 분석 대상 기술 소개</h3>
<p>본 안내서는 SLAM 기술의 발전사를 관통하는 핵심 알고리즘들을 심층적으로 비교 고찰하는 것을 목표로 한다. 이를 위해 필터링 기반의 고전적 접근법을 대표하는 EKF-SLAM과 FastSLAM, 그리고 현대 SLAM 기술의 주류를 이루는 최적화 기반 접근법의 대표주자인 PTAM, ORB-SLAM, LSD-SLAM, Google Cartographer를 분석 대상으로 선정했다. 각 기술의 핵심 원리, 수학적 모델, 장단점을 체계적으로 분석하고, 최종적으로 이들 기술을 종합적으로 비교하여 SLAM 기술의 발전 동향과 핵심적인 트레이드오프 관계를 조명하고자 한다. 이를 통해 독자들이 SLAM 기술의 계보를 이해하고, 각 기술의 본질적인 특성을 파악하며, 미래 기술의 방향성을 조망할 수 있도록 돕는 것이 본 안내서의 목적이다.</p>
<h2>2.  SLAM 기술 계보도 및 핵심 분류 체계</h2>
<h3>2.1  SLAM 기술 계보도</h3>
<p>아래의 계보도는 본 안내서에서 다루는 주요 SLAM 기술들의 발표 연도와 상호 영향을 시각적으로 표현한 것이다. 이는 SLAM 기술이 어떻게 필터링 기반 접근법에서 최적화 기반 접근법으로 발전해왔으며, 특히 Visual SLAM 내에서 아이디어들이 어떻게 계승되고 융합되었는지를 보여준다.</p>
<pre><code class="language-mermaid">graph TD
    subgraph "이론적 기반"
        ProbabilisticSLAM
    end

    subgraph " "
        A["필터링 기반 (Filtering-Based)"]
        B(FastSLAM&lt;br&gt;Montemerlo et al., 2002)
        ProbabilisticSLAM --&gt; A
        A --&gt; B
    end

    subgraph " "
        C["최적화 기반 (Optimization-Based)"]
        D(PTAM&lt;br&gt;Klein &amp; Murray, 2007)
        G(LSD-SLAM&lt;br&gt;Engel et al., 2014)
        E(ORB-SLAM&lt;br&gt;Mur-Artal et al., 2015)
        H(Google Cartographer&lt;br&gt;Hess et al., 2016)
        ProbabilisticSLAM --&gt; C
        C --&gt; D
        C -- "Pose Graph" --&gt; H
        D -- "Parallel Tracking &amp; Mapping" --&gt; E
        D -- "Keyframe-based BA" --&gt; E
        G -- "Direct Method" --&gt; E
    end
</code></pre>
<h3>2.2  핵심 분류 기준</h3>
<p>SLAM 알고리즘은 다양한 기준으로 분류할 수 있지만, 가장 핵심적인 분류 기준은 후면부(Back-end)의 최적화 방식과 전면부(Front-end)의 데이터 처리 방식이다. 이 두 가지 기준은 알고리즘의 성능, 정확도, 계산 복잡도, 그리고 강인성을 결정하는 근본적인 설계 철학의 차이를 반영한다.</p>
<h4>2.2.1  후면부(Back-end) 방식에 따른 분류: 필터링 vs. 최적화</h4>
<p>후면부는 전면부에서 처리된 데이터를 바탕으로 로봇의 전체 궤적과 지도의 일관성을 유지하고 최적화하는 역할을 담당한다.</p>
<ul>
<li><strong>필터링 기반 (Filtering-Based)</strong>: 이 접근법은 마르코프 가정(Markov assumption)에 기반하여, 직전 시간 스텝의 상태 추정치와 현재 시간 스텝의 관측 데이터만을 사용하여 현재 상태를 재귀적으로 추정한다.9 과거의 모든 관측 데이터를 저장하고 처리할 필요가 없어 메모리 사용량이 적고 계산이 빠르다는 장점이 있다. EKF-SLAM과 FastSLAM이 이 범주에 속한다. 하지만 이 방식은 한번 추정 과정에서 오류가 발생하면 이를 되돌리거나 수정하기가 매우 어렵다. 과거의 상태를 다시 고려하지 않기 때문에, 시간이 지남에 따라 오차가 누적되어 전역적인 지도 일관성을 유지하기 어렵다는 근본적인 한계를 가진다.</li>
<li><strong>최적화 기반 (Optimization-Based)</strong>: 이 접근법은 ‘전체 SLAM(Full SLAM)’ 문제로도 불리며, 일정 기간 동안 수집된 모든 관측 데이터(또는 이정표가 되는 키프레임) 간의 제약 조건(constraints)을 하나의 거대한 비선형 최적화 문제로 구성한다.7 로봇의 궤적과 맵 랜드마크의 위치를 변수로 놓고, 관측 모델에 기반한 오차(예: 재투영 오차)를 최소화하는 해를 찾는다. 이 방식은 모든 데이터를 고려하기 때문에 계산 비용이 높지만, 루프 클로저(loop closure) 등을 통해 과거의 오류를 수정하고 전역적으로 일관된(globally consistent) 지도와 궤적을 얻을 수 있다는 강력한 장점이 있다. Graph-SLAM과 번들 조정(Bundle Adjustment)이 대표적인 최적화 기법이며, PTAM의 성공 이후 현대 SLAM 시스템의 주류 패러다임으로 자리 잡았다.</li>
</ul>
<h4>2.2.2  전면부(Front-end) 방식에 따른 분류: 특징점 기반 vs. 직접 방식 (Visual SLAM)</h4>
<p>전면부는 원시 센서 데이터(raw sensor data)를 입력받아 후면부가 처리하기 용이한 형태로 가공하는 역할을 한다. 특히 Visual SLAM에서 이 구분은 매우 중요하다. 이는 원시 데이터인 이미지를 어떻게 추상화하여 기하학적 제약 조건을 만들 것인가에 대한 근본적인 철학의 차이를 보여준다.</p>
<ul>
<li><strong>특징점 기반 (Indirect Method)</strong>: 이 방식은 먼저 이미지에서 SIFT, SURF, ORB와 같이 조명이나 시점 변화에 불변하는 소수의 salient한 특징점(keypoint)들을 추출한다.11 그 후, 연속된 프레임 간에 이 특징점들을 매칭하고, 이들 간의 기하학적 관계(예: 재투영 오차)를 최소화하는 방식으로 카메라의 움직임을 추정한다. PTAM과 ORB-SLAM이 이 방식을 사용한다. 특징점이라는 높은 수준의 추상화를 거치기 때문에 조명 변화나 큰 시점 변화에 강인하며, 후면부에서 다루어야 할 데이터의 양이 적어 계산적으로 효율적이다. 그러나 특징점 추출이 어려운 텍스처가 부족한 환경(예: 흰 벽)에서는 성능이 급격히 저하되며, 추출된 특징점 이외의 풍부한 이미지 정보를 버린다는 단점이 있다.13</li>
<li><strong>직접 방식 (Direct Method)</strong>: 이 방식은 특징점 추출이라는 중간 단계를 생략하고, 픽셀의 밝기 값(intensity) 자체를 직접 사용하여 카메라의 움직임을 추정한다.14 참조 프레임과 현재 프레임 간의 광도 오차(photometric error), 즉 같은 3D 지점을 투영했을 때 나타나는 픽셀 값의 차이를 최소화하는 카메라 포즈를 찾는다. LSD-SLAM이 대표적인 예이다. 이 방식은 이미지의 모든 픽셀 정보(또는 그래디언트가 높은 픽셀 정보)를 활용하므로 텍스처가 부족한 환경에서도 엣지 등의 정보를 이용해 동작할 수 있으며, 준밀도(semi-dense) 또는 밀도(dense) 높은 맵을 생성할 수 있다. 반면, 픽셀 밝기 값에 직접 의존하기 때문에 조명 변화나 카메라의 자동 노출 기능 등에 매우 민감하고, 빠른 움직임으로 인한 모션 블러에 취약하다는 한계를 가진다.17</li>
</ul>
<p>이러한 분류 체계를 통해 각 SLAM 기술이 어떤 설계적 트레이드오프 위에서 개발되었는지 이해할 수 있다. 예를 들어, ORB-SLAM은 최적화 기반 후면부와 특징점 기반 전면부를 결합하여 정확성과 강인성을 극대화한 반면, LSD-SLAM은 동일한 최적화 기반 후면부를 사용하면서도 직접 방식 전면부를 채택하여 맵의 밀도를 높이는 데 집중했다.</p>
<h2>3.  필터링 기반 SLAM 기법 심층 분석</h2>
<p>필터링 기반 SLAM은 확률적 로봇 공학의 초기 발전을 이끈 고전적인 접근법이다. 이 방법론의 핵심은 로봇의 상태와 환경 지도를 하나의 확률 분포로 표현하고, 새로운 움직임과 관측이 들어올 때마다 이 분포를 재귀적으로 갱신하는 것이다. 이는 과거의 모든 정보를 요약한 현재의 ’믿음(belief)’을 바탕으로 미래를 예측하고 현재를 수정해나가는 과정에 비유할 수 있다.</p>
<h3>3.1  EKF-SLAM</h3>
<p>EKF-SLAM은 SLAM 문제를 해결하기 위해 확장 칼만 필터(Extended Kalman Filter)를 적용한 최초의 확률적 접근법이다. 이 방법론의 근본적인 아이디어는 로봇의 포즈(위치와 방향)와 모든 랜드마크의 위치를 하나의 거대한 상태 벡터(state vector)로 결합하고, 이 벡터의 평균과 불확실성(공분산 행렬)을 추정하는 것이다.7</p>
<h4>3.1.1  핵심 원리 및 수학적 모델</h4>
<p>EKF-SLAM은 두 단계, 즉 예측(Prediction)과 갱신(Update) 단계를 반복적으로 수행한다.</p>
<ul>
<li>
<p>상태 벡터 정의: 시간 k에서의 상태 벡터 <span class="math math-inline">x_k</span>는 로봇의 상태 <span class="math math-inline">x_v</span>와 N개 랜드마크의 위치 <span class="math math-inline">m_1,..., m_N</span>을 모두 포함한다.</p>
<p><span class="math math-display">
x_k = 
\begin{bmatrix}
x_v^T &amp; m_1^T &amp; \cdots &amp; m_N^T
\end{bmatrix}
</span></p>
</li>
<li>
<p><strong>예측 단계 (Prediction)</strong>: 로봇의 움직임 제어 입력 <span class="math math-inline">u_k</span>가 주어지면, 움직임 모델 <code>f</code>를 사용하여 로봇의 다음 상태와 그 불확실성을 예측한다. 랜드마크의 위치는 변하지 않는다고 가정한다.</p>
</li>
<li>
<p>상태 예측:</p>
<p><span class="math math-display">
  \hat{x}_{k|k-1} = f(\hat{x}_{k-1|k-1}, u_k)
</span></p>
</li>
</ul>
<p>공분산 예측:</p>
<pre><code>$$
P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k
</code></pre>
<p>$$</p>
<p>여기서 <span class="math math-inline">P</span>는 상태 공분산 행렬, <span class="math math-inline">F_k</span>는 비선형 움직임 모델 <code>f</code>를 현재 상태에서 선형화한 자코비안 행렬, <span class="math math-inline">Q_k</span>는 움직임의 불확실성을 나타내는 프로세스 노이즈 공분산이다.</p>
<ul>
<li>
<p><strong>갱신 단계 (Update)</strong>: 로봇이 센서를 통해 랜드마크를 관측(<span class="math math-inline">z_k</span>)하면, 이 정보를 사용하여 예측된 상태를 보정한다.</p>
</li>
<li>
<p>칼만 이득(Kalman Gain) 계산:</p>
<p><span class="math math-display">
  K_k = P_{k|k-1} H_k^T (H_k P_{k|k-1} H_k^T + R_k)^{-1}
</span></p>
</li>
</ul>
<p>상태 갱신:</p>
<pre><code>$$
\hat{x}_{k|k} = \hat{x}_{k|k-1} + K_k (z_k - h(\hat{x}_{k|k-1}))
</code></pre>
<p>$$</p>
<p>공분산 갱신:</p>
<pre><code>$$
P_{k|k} = (I - K_k H_k) P_{k|k-1}
</code></pre>
<p>$$</p>
<p>여기서 <span class="math math-inline">H_k</span>는 비선형 관측 모델 <code>h</code>를 선형화한 자코비안 행렬, <span class="math math-inline">R_k</span>는 센서 측정의 불확실성을 나타내는 관측 노이즈 공분산이다. 칼만 이득 <span class="math math-inline">K_k</span>는 예측의 불확실성과 관측의 불확실성을 가중하여 최적의 보정량을 결정하는 역할을 한다.</p>
<h4>3.1.2  장단점 및 한계</h4>
<p>EKF-SLAM은 SLAM 문제에 대한 최초의 체계적인 확률적 해법을 제시했다는 점에서 역사적 의의가 크다.</p>
<ul>
<li><strong>장점</strong>: 소규모 환경에서는 실시간으로 동작할 만큼 계산적으로 효율적이며, 로봇과 맵의 불확실성을 공분산 행렬이라는 형태로 명시적으로 표현하고 관리하는 강력한 이론적 프레임워크를 제공한다.10</li>
<li><strong>단점</strong>: 그러나 EKF-SLAM은 세 가지 치명적인 한계로 인해 대규모 환경에 적용하기 어렵다.</li>
</ul>
<ol>
<li><strong>계산 복잡도</strong>: 상태 벡터의 크기는 랜드마크의 수 <code>N</code>에 비례하여 커진다 (<code>3+2N</code> 차원 for 2D). 공분산 행렬의 크기는 <code>(3+2N)x(3+2N)</code>이 되며, 이를 갱신하는 데 필요한 계산량은 랜드마크 수의 제곱에 비례(<span class="math math-inline">O(N^2)</span>)한다.19 이로 인해 랜드마크가 수백 개만 넘어가도 실시간 처리가 불가능해진다.</li>
<li><strong>선형화 오차</strong>: 로봇의 움직임과 센서 관측 모델은 본질적으로 비선형적이다. EKF는 이를 1차 테일러 급수 전개를 통해 강제로 선형 근사(자코비안 계산)한다. 비선형성이 강한 경우 이 근사 오차가 누적되어 결국 추정치가 실제 값에서 멀어지는 발산(divergence) 현상을 초래할 수 있다.10</li>
<li><strong>데이터 연관 실패</strong>: 데이터 연관(Data Association)은 현재 관측된 특징이 이전에 관측된 랜드마크 중 어느 것인지를 결정하는 과정이다. 만약 이 결정이 잘못되면(예: 두 개의 다른 랜드마크를 같은 것으로 착각), 잘못된 정보로 공분산 행렬이 갱신된다. EKF-SLAM은 단일 가설(unimodal Gaussian)만을 유지하기 때문에, 한번 발생한 데이터 연관 오류는 시스템 전체에 치명적인 영향을 미치며 회복이 거의 불가능하다.19</li>
</ol>
<h3>3.2  FastSLAM</h3>
<p>FastSLAM은 EKF-SLAM의 근본적인 한계, 특히 계산 복잡도와 비선형성 문제를 해결하기 위해 등장했다. 이 알고리즘의 핵심 아이디어는 라오-블랙웰화 입자 필터(Rao-Blackwellized Particle Filter, RBPF)라는 정교한 통계적 기법을 사용하여, 거대하고 복잡한 SLAM 문제를 다수의 작고 간단한 문제로 분해(factorization)하는 것이다.22</p>
<h4>3.2.1  핵심 원리 및 수학적 모델</h4>
<p>FastSLAM은 ’로봇의 경로를 알면 각 랜드마크의 위치 추정은 서로 독립이 된다’는 통계적 사실에 기반한다. 이를 통해 SLAM 후방 확률분포를 다음과 같이 인수분해한다.25</p>
<ul>
<li>
<p><strong>인수분해 (Factorization)</strong>:</p>
<p><span class="math math-display">
p(s^t, \Theta | z^t, u^t) = p(s^t | z^t, u^t) \prod_{k=1}^{N} p(\theta_k | s^t, z^t, u^t)
</span></p>
</li>
</ul>
<p>여기서 <span class="math math-inline">s^t</span>는 시간 <code>t</code>까지의 로봇 경로(<span class="math math-inline">s_1,..., s_t</span>), <span class="math math-inline">\Theta</span>는 모든 랜드마크의 집합, <span class="math math-inline">z^t</span>는 관측, <span class="math math-inline">u^t</span>는 제어 입력이다. 이 식은 전체 SLAM 문제를 (1) 로봇의 경로에 대한 후방 확률 <span class="math math-inline">p(s^t |...)</span>을 추정하는 문제와 (2) 추정된 경로가 주어졌을 때 각 랜드마크 <span class="math math-inline">\theta_k</span>의 위치를 독립적으로 추정하는 <code>N</code>개의 문제로 나눌 수 있음을 의미한다.</p>
<ul>
<li><strong>알고리즘 구조</strong>: FastSLAM은 이 인수분해된 구조를 RBPF를 통해 효율적으로 구현한다.</li>
</ul>
<ol>
<li><strong>입자 필터 (Particle Filter)</strong>: <span class="math math-inline">M</span>개의 입자(particle)를 사용하여 복잡한 형태를 가질 수 있는 로봇 경로의 확률분포 <span class="math math-inline">p(s^t |...)</span>를 근사한다. 각 입자는 로봇이 지나왔을 가능성이 있는 하나의 가설 경로(hypothesized path)를 나타낸다.</li>
<li><strong>독립적인 EKF</strong>: 각 입자는 자신만의 맵을 가지고 있으며, 이 맵은 <span class="math math-inline">N</span>개의 독립적인 저차원(2x2 또는 3x3) EKF로 구성된다. 각 EKF는 해당 입자의 경로 가설 하에서 단 하나의 랜드마크 위치만을 추정한다.19</li>
</ol>
<p>이러한 구조는 EKF-SLAM이 하나의 거대한 고차원 EKF를 유지하는 것과 대조적이다. FastSLAM은 수많은 작고 독립적인 EKF들을 다루기 때문에 계산적으로 훨씬 효율적이다.</p>
<h4>3.2.2  장단점 및 한계</h4>
<p>FastSLAM은 EKF-SLAM의 한계를 극복하며 SLAM 연구에 중요한 진전을 이루었다.</p>
<ul>
<li><strong>장점</strong>:</li>
</ul>
<ol>
<li><strong>향상된 확장성</strong>: 랜드마크 수 <code>N</code>에 대해 계산 복잡도가 <span class="math math-inline">O(M \log N)</span> (M은 입자 수)으로, EKF-SLAM의 <span class="math math-inline">O(N^2)</span>에 비해 월등히 뛰어나 대규모 환경에 적용이 가능하다.19</li>
<li><strong>비선형성 처리 능력</strong>: 입자 필터는 샘플 기반의 비모수적 방법이므로, 로봇의 움직임 모델이 강한 비선형성을 가지거나 확률분포가 비-가우시안(non-Gaussian) 형태를 띠더라도 효과적으로 표현할 수 있다.26</li>
<li><strong>강인한 데이터 연관</strong>: 각 입자는 독립적인 데이터 연관 가설을 가질 수 있다. 이는 자연스럽게 다중 가설 추적(multi-hypothesis tracking)을 구현하는 것과 같다. 만약 일부 입자가 잘못된 데이터 연관을 하더라도, 이 입자들은 관측 데이터와 불일치하여 중요도 가중치(importance weight)가 낮아지고, 리샘플링(resampling) 과정에서 자연스럽게 도태된다. 이 덕분에 데이터 연관 오류에 매우 강인하다.2</li>
</ol>
<ul>
<li><strong>단점</strong>:</li>
</ul>
<ol>
<li><strong>입자 고갈 (Particle Depletion)</strong>: 리샘플링 과정이 반복되면서 유전적 다양성이 소실되어, 결국 소수의 우세한 입자들만 살아남고 나머지 입자들은 사라지는 현상이다. 이는 추정치가 실제 분포의 일부 모드에만 집중하게 만들어, 장기적으로는 추정치의 정확도를 떨어뜨리고 불확실성을 과소평가하게 만든다.24</li>
<li><strong>계산 비용</strong>: 알고리즘의 성능은 입자의 수 <span class="math math-inline">M</span>에 크게 의존한다. 상태 공간이 복잡할수록 더 많은 입자가 필요하며, 이는 계산 비용 증가로 이어진다.28</li>
<li><strong>제안 분포의 한계</strong>: 입자 필터의 효율성은 새로운 입자를 샘플링하는 제안 분포(proposal distribution)가 얼마나 실제 후방 확률분포와 유사한지에 달려있다. FastSLAM 1.0은 간단한 움직임 모델을 제안 분포로 사용하는데, 이는 관측 정보를 활용하지 않아 비효율적이다. 이 문제를 해결하기 위해 관측 정보를 반영하여 더 나은 제안 분포를 사용하는 FastSLAM 2.0이 제안되었다.5</li>
</ol>
<p>결론적으로, EKF-SLAM에서 FastSLAM으로의 전환은 SLAM 문제에서 불확실성을 다루는 방식의 근본적인 패러다임 변화를 의미한다. 단일의 복잡한 가우시안 근사 모델에서 벗어나, 다수의 가설을 동시에 탐색하는 비모수적, 샘플 기반 표현으로 이동한 것이다. 이 변화는 SLAM을 소규모 실험실 환경에서 대규모 실제 환경으로 확장하는 데 결정적인 역할을 했다.</p>
<h2>4.  최적화 기반 SLAM 기법 심층 분석</h2>
<p>2000년대 후반부터 SLAM 연구의 패러다임은 필터링 기반 접근법에서 최적화 기반 접근법으로 점차 이동했다. 이 변화의 핵심 동기는 필터링 방식의 근본적인 한계, 즉 과거의 오류를 수정할 수 없다는 점을 극복하고, 수집된 모든 정보를 활용하여 전역적으로 가장 일관성 있는 해를 찾고자 하는 요구였다. 최적화 기반 SLAM은 일정 시간 동안의 로봇 궤적과 맵을 하나의 거대한 그래프로 모델링하고, 모든 제약 조건을 동시에 만족시키는 최적의 해를 찾는 방식으로 동작한다.</p>
<h3>4.1  PTAM (Parallel Tracking and Mapping)</h3>
<p>PTAM은 2007년 Klein과 Murray에 의해 발표된 Visual SLAM 시스템으로, 현대 VSLAM의 구조에 지대한 영향을 미쳤다. PTAM의 가장 혁신적인 기여는 SLAM 문제를 실시간 처리가 중요한 ’트래킹(Tracking)’과 계산 비용이 높은 ’맵핑(Mapping)’의 두 가지 작업으로 분리하고, 이를 별도의 스레드에서 병렬적으로 처리하는 구조를 제안한 것이다.29</p>
<h4>4.1.1  핵심 원리 및 주요 기법</h4>
<ul>
<li><strong>병렬 처리 구조</strong>:</li>
<li><strong>트래킹 스레드 (Tracking Thread)</strong>: 이 스레드는 카메라로부터 들어오는 모든 프레임에 대해 동작한다. 이미 생성된 맵을 바탕으로, 현재 프레임의 특징점과 맵 포인트 간의 재투영 오차를 최소화하여 카메라의 포즈를 매우 빠르고 가볍게 추정하는 데 집중한다. 이 과정은 프레임 속도(frame-rate)로 동작해야 하므로, 맵을 수정하는 등의 무거운 작업은 수행하지 않는다.29</li>
<li><strong>맵핑 스레드 (Mapping Thread)</strong>: 이 스레드는 트래킹 스레드와 독립적으로, 더 낮은 빈도로 동작한다. 트래킹 과정에서 ’키프레임(Keyframe)’으로 선정된 중요한 프레임들만을 사용하여 맵을 생성하고 정교화한다. 핵심 작업은 계산 비용이 매우 높은 번들 조정(Bundle Adjustment, BA)을 수행하여 맵 포인트의 3D 위치와 키프레임들의 포즈를 전역적으로 최적화하는 것이다.30</li>
<li><strong>키프레임 기반 접근법 (Keyframe-based Approach)</strong>: PTAM은 비디오 스트림의 모든 프레임을 처리하는 대신, 새로운 정보를 충분히 담고 있다고 판단되는 소수의 프레임만을 ’키프레임’으로 선택한다. 이 키프레임들이 맵을 구성하는 기본 단위가 된다. 이 전략은 데이터의 중복성을 제거하고, 후면부 최적화(BA)의 계산량을 실시간 시스템에서 감당할 수 있는 수준으로 줄이는 핵심적인 역할을 한다.32</li>
<li><strong>번들 조정 (Bundle Adjustment, BA)</strong>: 맵핑 스레드의 핵심 기술로, 모든 키프레임의 포즈와 모든 3D 맵 포인트의 위치를 동시에 최적화하여, 모든 관측된 특징점의 재투영 오차(reprojection error)의 총합을 최소화하는 비선형 최적화 기법이다. 이는 맵의 기하학적 구조가 전역적으로 가장 일관성을 갖도록 보장하며, 필터링 기반 방식보다 훨씬 높은 정확도를 제공한다.30</li>
</ul>
<h4>4.1.2  장단점</h4>
<ul>
<li><strong>장점</strong>: PTAM은 병렬 처리 아키텍처를 통해 증강 현실(AR)과 같은 애플리케이션에서 실시간으로 정확한 카메라 트래킹을 최초로 성공시켰다.29 키프레임 기반의 BA를 도입함으로써 필터링 방식의 누적 오차 문제를 해결하고 월등히 높은 정확도를 달성했다. 이 구조는 이후 대부분의 현대 VSLAM 시스템(예: ORB-SLAM)의 표준이 되었다.32</li>
<li><strong>단점</strong>: 원본 PTAM은 작은 규모의 AR 작업 공간에 최적화되어 설계되었다. 따라서 대규모 환경에서 발생하는 누적 오차를 보정하기 위한 루프 클로저 기능이 없으며, 트래킹을 잃어버렸을 때 위치를 다시 찾는 재인식(relocalization) 기능이 상대적으로 취약하다.13</li>
</ul>
<h3>4.2  ORB-SLAM</h3>
<p>ORB-SLAM은 2015년 Mur-Artal 등에 의해 발표되었으며, PTAM의 혁신적인 병렬 구조를 계승하고 여기에 여러 핵심 기술들을 융합하여 완성도를 극대화한 시스템이다. ORB-SLAM은 높은 정확도, 강인한 루프 클로저, 실시간 재인식 기능을 모두 갖추어 소규모 실내 환경부터 대규모 실외 환경까지 아우르는 다목적(versatile) VSLAM 시스템으로 평가받는다.32</p>
<h4>4.2.1  시스템 구성 (3-Thread Architecture)</h4>
<p>ORB-SLAM은 PTAM의 2-스레드 구조를 3-스레드로 확장하여 각 기능의 전문성과 효율성을 높였다.</p>
<ul>
<li><strong>트래킹 (Tracking)</strong>: 매 프레임마다 ORB 특징점을 추출하고, 이전 프레임의 포즈를 초기값으로 하여 현재 카메라 포즈를 추정한다. 이 때, 전체 맵이 아닌 ’공시성 그래프(Covisibility Graph)’를 통해 연결된 지역 맵(local map)만을 참조하여 계산 효율성을 높인다. 또한 현재 프레임을 새로운 키프레임으로 삽입할지 여부를 결정한다.</li>
<li><strong>지역 맵핑 (Local Mapping)</strong>: 새로운 키프레임이 삽입되면 이 스레드가 활성화된다. 새로운 맵 포인트를 삼각측량(triangulation)을 통해 생성하고, 불필요한 맵 포인트를 제거한다. 가장 중요한 작업은, 현재 키프레임과 공시성 그래프 상에서 강하게 연결된 이웃 키프레임들 및 그들이 관측하는 맵 포인트들을 대상으로 지역 번들 조정(Local BA)을 수행하여 지역 맵의 일관성을 최적화하는 것이다.</li>
<li><strong>루프 클로징 (Loop Closing)</strong>: 이 스레드는 대규모 환경에서의 누적 오차를 해결하는 핵심적인 역할을 한다. 새로운 키프레임이 생성될 때마다, Bag-of-Words(BoW) 기법을 사용하여 이전에 방문했던 장소와 유사한지 빠르게 검사한다(장소 인식). 만약 루프가 탐지되면, 먼저 유사 변환(Sim(3))을 계산하여 스케일 드리프트를 포함한 오차를 추정한다. 그 후, 루프를 구성하는 키프레임들을 대상으로 자세 그래프 최적화(Pose Graph Optimization)를 수행하여 누적된 오차를 전역적으로 분배하고 보정한다. 마지막으로, 전역 번들 조정(Full BA)을 통해 전체 맵의 일관성을 다시 최적화한다.13</li>
</ul>
<h4>4.2.2  수학적 모델 (Bundle Adjustment Cost Function)</h4>
<p>ORB-SLAM의 정확도는 번들 조정(BA)에 크게 의존한다. BA는 아래와 같은 비용 함수(cost function)를 최소화하는 맵 포인트의 3D 위치 <span class="math math-inline">\{X_{w,j}\}</span>와 키프레임의 포즈 <span class="math math-inline">\{T_{iw}\}</span>를 찾는 문제이다.13<br />
<span class="math math-display">
C = \sum_{i,j} \rho_h (e_{i,j}^T \Omega_{i,j}^{-1} e_{i,j})
</span><br />
각 항의 의미는 다음과 같다.</p>
<ul>
<li><span class="math math-inline">e_{i,j} = x_{i,j} - \pi_i(T_{iw}, X_{w,j})</span>: 키프레임 <code>i</code>에서 관측된 3D 맵 포인트 <code>j</code>의 실제 2D 이미지 좌표 <span class="math math-inline">x_{i,j}</span>와, 3D 위치 <span class="math math-inline">X_{w,j}</span>를 카메라 포즈 <span class="math math-inline">T_{iw}</span>로 투영한 예상 2D 좌표 <span class="math math-inline">\pi_i(...)</span> 간의 차이, 즉 <strong>재투영 오차</strong>이다.</li>
<li><span class="math math-inline">\rho_h</span>: <strong>Huber 로버스트 비용 함수</strong>로, 잘못된 특징점 매칭과 같은 이상치(outlier)가 전체 최적화에 미치는 영향을 줄여준다.</li>
<li><span class="math math-inline">\Omega_{i,j}^{-1}</span>: <strong>정보 행렬</strong>로, 특징점이 검출된 이미지 스케일에 따른 공분산 행렬의 역행렬이다. 이는 더 확실하게 관측된(즉, 더 큰 스케일에서 검출된) 특징점에 더 작은 가중치를 부여하여 관측의 불확실성을 반영한다.</li>
</ul>
<h4>4.2.3  장단점</h4>
<ul>
<li><strong>장점</strong>: ORB-SLAM은 정확도, 강인성, 다목적성 면에서 매우 뛰어난 성능을 보인다. 실시간 루프 클로저와 재인식 기능 덕분에 장시간, 대규모 환경에서도 안정적으로 동작한다.13 단안, 스테레오, RGB-D 등 다양한 카메라를 지원하며, 소스 코드가 공개되어 VSLAM 연구 및 개발의 표준 벤치마크로 널리 활용된다.6</li>
<li><strong>단점</strong>: 특징점 기반 방식의 고유한 한계로 인해 텍스처가 부족하거나 반복적인 패턴이 많은 환경에서는 특징점 추출 및 매칭에 실패하여 트래킹이 불안정해질 수 있다.6 또한, 3개의 스레드에서 BA, 그래프 최적화 등 복잡한 연산을 수행하므로 계산 요구량이 높아 저사양 임베디드 시스템에 적용하기에는 부담이 될 수 있다. 순수한 회전 운동 시에는 깊이 추정이 어려워 성능이 저하될 수 있다.37</li>
</ul>
<h3>4.3  LSD-SLAM (Large-Scale Direct Monocular SLAM)</h3>
<p>LSD-SLAM은 2014년 Engel 등에 의해 제안되었으며, 특징점 기반 방식의 한계를 극복하고자 등장한 직접 방식(Direct Method)의 대표주자이다. 이 시스템은 이미지에서 인위적인 특징점을 추출하는 대신, 픽셀의 밝기 값 자체를 정보로 사용하여 카메라 포즈와 맵을 동시에 추정한다.14</p>
<h4>4.3.1  핵심 원리 및 수학적 모델</h4>
<p>LSD-SLAM의 핵심은 두 이미지 간의 **광도 오차(photometric error)**를 최소화하는 것이다. 이는 동일한 3D 지점이 서로 다른 시점에서 촬영되었을 때, 두 이미지 상의 픽셀 밝기 값은 유사해야 한다는 가정에 기반한다.</p>
<ul>
<li>
<p><strong>광도 오차 최소화 (Photometric Error Minimization)</strong>: 참조 키프레임 <span class="math math-inline">I_{ref}</span>와 현재 프레임 <span class="math math-inline">I</span> 간의 상대적인 변환 <span class="math math-inline">\xi</span>를 찾기 위해, 다음의 비용 함수 <span class="math math-inline">E(\xi)</span>를 최소화한다.16</p>
<p><span class="math math-display">
E(\xi) = \sum_i (I_{ref}(p_i) - I(\omega(p_i, D_{ref}(p_i), \xi)))^2
</span></p>
</li>
</ul>
<p>여기서 <span class="math math-inline">p_i</span>는 참조 프레임의 픽셀, <span class="math math-inline">D_{ref}(p_i)</span>는 해당 픽셀의 역깊이(inverse depth, 1/depth), <span class="math math-inline">\omega(...)</span>는 픽셀 <span class="math math-inline">p_i</span>를 3D 공간으로 역투영한 후 변환 <span class="math math-inline">\xi</span>를 적용하고 다시 현재 프레임으로 투영하는 워프 함수(warp function)이다. 이 비선형 최소제곱 문제는 가우스-뉴턴(Gauss-Newton)과 같은 반복적인 최적화 기법으로 해결된다.</p>
<h4>4.3.2  주요 특징</h4>
<ul>
<li><strong>준밀도 맵 (Semi-dense Map)</strong>: LSD-SLAM은 이미지의 모든 픽셀을 사용하는 밀도(dense) 방식과 소수의 특징점만 사용하는 희소(sparse) 방식의 절충안으로, 이미지에서 그래디언트(밝기 변화)가 충분히 큰 영역의 픽셀들만을 선택하여 깊이를 추정한다. 이를 통해 희소 맵보다 훨씬 풍부한 기하학적 정보를 담고 있으면서도 실시간 처리가 가능한 준밀도 맵을 생성한다.8</li>
<li><strong>Sim(3) 기반 스케일 드리프트 보정</strong>: 단안 카메라는 깊이를 직접 측정할 수 없어 움직이면서 깊이를 추정하는데, 이 과정에서 스케일(scale)이 점진적으로 변하는 스케일 드리프트 문제가 발생한다. LSD-SLAM은 키프레임 간의 변환을 단순한 6-DOF 강체 변환(SE(3))이 아닌, 스케일 변화까지 포함하는 7-DOF 유사 변환(Sim(3))으로 모델링한다. 이를 통해 루프 클로저 시 누적된 스케일 드리프트를 명시적으로 추정하고 전역적으로 보정할 수 있다.16</li>
</ul>
<h4>4.3.3  장단점</h4>
<ul>
<li><strong>장점</strong>: 특징점 추출 과정이 없어 계산적으로 효율적이며, 코너가 없는 평면이나 엣지 등 특징점 기반 방식이 활용하기 어려운 이미지 정보를 적극적으로 사용하므로 텍스처가 부족한 인공적인 환경에서 강점을 보인다.17 생성되는 준밀도 맵은 장애물 회피나 AR 오클루전(occlusion) 등에 활용될 수 있는 풍부한 정보를 제공한다.</li>
<li><strong>단점</strong>: 픽셀의 절대적인 밝기 값에 직접 의존하기 때문에, 조명의 급격한 변화나 카메라의 자동 노출/화이트 밸런스 기능에 매우 민감하다는 치명적인 약점이 있다.6 또한, 빠른 카메라 움직임으로 인한 모션 블러(motion blur)가 발생하면 이미지의 그래디언트 정보가 손상되어 트래킹 성능이 급격히 저하된다.</li>
</ul>
<h3>4.4  Google Cartographer</h3>
<p>Google Cartographer는 2016년에 공개된 SLAM 라이브러리로, 특히 LiDAR 센서를 활용한 2D 및 3D 매핑에 강점을 보인다. 이 시스템의 핵심 철학은 SLAM 문제를 두 단계로 나누어, 지역적으로는 빠르고 일관된 맵을 생성하고(Local SLAM), 전역적으로는 이 지역 맵들을 연결하여 누적 오차를 보정하는(Global SLAM) 것이다.39</p>
<h4>4.4.1  핵심 원리 및 주요 기법</h4>
<ul>
<li><strong>서브맵 기반 지역 SLAM (Submap-based Local SLAM)</strong>: Cartographer는 연속적인 LiDAR 스캔들을 실시간으로 정합(scan matching)하여 하나의 작은 지역 맵, 즉 ’서브맵(Submap)’을 점진적으로 구축한다. 새로운 스캔은 전체 맵이 아닌, 현재 구축 중인 이 서브맵에 대해서만 정합되므로 계산 부하가 매우 낮다. 일정 수의 스캔이 누적되어 서브맵이 완성되면, 이 서브맵은 더 이상 수정되지 않는 불변의 단위가 된다.41</li>
<li><strong>자세 그래프 최적화 기반 전역 SLAM (Pose Graph Optimization-based Global SLAM)</strong>: 전역 SLAM은 후면부에서 비동기적으로 실행된다. 시스템이 지금까지 생성한 모든 스캔 포즈와 완성된 서브맵 포즈들을 노드(node)로, 그리고 이들 간의 상대적인 변환 관계(예: 스캔과 서브맵 간의 정합 결과)를 엣지(edge)로 하는 자세 그래프(Pose Graph)를 구성한다.</li>
<li><strong>실시간 루프 클로저</strong>: Cartographer의 핵심 경쟁력은 효율적인 루프 클로저 메커니즘에 있다. 백그라운드 스레드에서 현재 스캔과 과거에 생성된 모든 서브맵 간의 정합을 지속적으로 시도한다. 대규모 맵에서 이 과정을 실시간으로 수행하기 위해, 최적의 매칭 위치를 효율적으로 찾기 위한 분기 한정법(Branch-and-Bound) 기반의 스캔 매처를 사용한다.41 루프가 성공적으로 탐지되면, 이는 자세 그래프에 새로운 엣지(제약 조건)로 추가된다. 그 후, Ceres Solver와 같은 비선형 최적화 라이브러리를 사용하여 전체 그래프를 최적화함으로써, 루프를 통해 발견된 불일치(누적 오차)를 그래프 전체에 전파하여 전역적으로 일관된 맵을 생성한다.41</li>
</ul>
<h4>4.4.2  수학적 모델 (Graph Optimization Problem)</h4>
<p>Cartographer의 전역 최적화는 모든 서브맵 포즈 <span class="math math-inline">\Xi^m = \{\xi_{m_i}\}</span>와 스캔 포즈 <span class="math math-inline">\Xi^s = \{\xi_{s_j}\}</span>를 변수로 하여, 이들 간의 상대 포즈 제약 조건으로부터 계산된 잔차의 총합을 최소화하는 비선형 최소제곱 문제로 공식화된다.41</p>
<p><span class="math math-display">
\underset{\Xi^m, \Xi^s}{\text{argmin}} \frac{1}{2} \sum_{ij} \rho(E^2(\xi_{m_i}, \xi_{s_j}; \Sigma_{ij}, \xi_{ij}))
</span></p>
<p>여기서 <span class="math math-inline">E</span>는 서브맵 <span class="math math-inline">i</span>의 좌표계에서 본 스캔 <span class="math math-inline">j</span>의 포즈와, 제약 조건으로 주어진 상대 포즈 <span class="math math-inline">\xi_{ij}</span> 간의 오차를 나타낸다. <span class="math math-inline">\Sigma_{ij}</span>는 해당 제약 조건의 불확실성을 나타내는 공분산 행렬이며, <span class="math math-inline">\rho</span>는 잘못된 루프 클로저와 같은 이상치의 영향을 줄이기 위한 로버스트 손실 함수(예: Huber loss)이다.</p>
<h4>4.4.3  장단점</h4>
<ul>
<li><strong>장점</strong>: LiDAR와 IMU를 주력 센서로 사용하여 매우 정밀하고 신뢰성 높은 2D/3D 그리드 맵을 생성할 수 있다. 서브맵 기반 접근법과 고도로 최적화된 루프 클로저 덕분에 매우 넓은 공간에서도 실시간으로 안정적인 성능을 제공한다.39 Google에 의해 개발되고 유지보수되어 산업 현장에서의 신뢰성과 완성도가 높다.</li>
<li><strong>단점</strong>: 주로 LiDAR와 IMU 데이터에 의존하도록 설계되어, 카메라의 풍부한 시각 정보를 적극적으로 활용하지는 않는다.42 따라서 외형 기반의 장소 인식이나 시각적 텍스처가 중요한 애플리케이션에는 한계가 있다. 또한, 다양한 센서 구성에 대한 설정이 다소 복잡하고 하드웨어 의존성이 높은 편이다.</li>
</ul>
<p>최적화 기반 SLAM 기술들의 발전은 ’선택과 집중’이라는 전략으로 요약될 수 있다. PTAM의 키프레임과 Cartographer의 서브맵은 모두 방대한 센서 데이터 스트림에서 가장 정보 가치가 높은 부분만을 선택하여 처리함으로써, 이론적으로는 매우 비싼 전역 최적화를 실시간 시스템의 제약 하에서 실현 가능하게 만든 핵심적인 아이디어이다.</p>
<h2>5.  주요 SLAM 기술 종합 비교 고찰</h2>
<p>지금까지 분석한 6가지 핵심 SLAM 기술들은 각각 다른 시대적 배경과 기술적 목표 하에 개발되었으며, 고유한 장단점과 트레이드오프 관계를 가진다. 이 섹션에서는 이들 기술을 핵심적인 기준에 따라 종합적으로 비교하여 각 기술의 위치와 특성을 명확히 하고자 한다. 아래 표는 각 기술의 핵심적인 특징을 요약한 것이다.</p>
<table><thead><tr><th>기술 (Technology)</th><th>발표 연도 (Year)</th><th>핵심 접근법 (Core Approach)</th><th>주요 센서 (Sensor)</th><th>맵 밀도 (Map Density)</th><th>계산 복잡도 (Complexity)</th><th>장점 (Pros)</th><th>단점 (Cons)</th></tr></thead><tbody>
<tr><td><strong>EKF-SLAM</strong></td><td>1986</td><td>필터링 (EKF)</td><td>LiDAR, Camera</td><td>희소 (Sparse)</td><td><span class="math math-inline">O(N^2)</span></td><td>실시간(소규모), 명확한 확률적 기반</td><td>확장성 부재, 선형화 오차, 취약한 데이터 연관</td></tr>
<tr><td><strong>FastSLAM</strong></td><td>2002</td><td>필터링 (RBPF)</td><td>LiDAR, Camera</td><td>희소 (Sparse)</td><td><span class="math math-inline">O(M \log N)</span></td><td>비선형/비가우시안 처리, 강인한 데이터 연관</td><td>입자 고갈, 제안 분포 의존성, 맵 일관성 저하 가능</td></tr>
<tr><td><strong>PTAM</strong></td><td>2007</td><td>최적화 (BA, Indirect)</td><td>Monocular Camera</td><td>희소 (Sparse)</td><td>높음 (BA)</td><td>실시간 트래킹, 높은 정확도(BA), 병렬처리 선구자</td><td>소규모 환경 제한, 루프 클로저/재인식 부재</td></tr>
<tr><td><strong>LSD-SLAM</strong></td><td>2014</td><td>최적화 (Direct)</td><td>Monocular Camera</td><td>준밀도 (Semi-dense)</td><td>높음</td><td>텍스처 부족 환경 강점, 특징점 불필요, 준밀도 맵</td><td>조명 변화/빠른 모션에 민감, 스케일 추정 어려움</td></tr>
<tr><td><strong>ORB-SLAM</strong></td><td>2015</td><td>최적화 (BA, Indirect)</td><td>Monocular, Stereo, RGB-D</td><td>희소 (Sparse)</td><td>매우 높음</td><td>높은 정확도, 강인한 루프 클로저, 다목적성, 강건함</td><td>텍스처 부족 환경 취약, 높은 계산 요구량</td></tr>
<tr><td><strong>Cartographer</strong></td><td>2016</td><td>최적화 (Graph)</td><td>LiDAR, IMU</td><td>2D/3D 그리드</td><td>높음 (Graph Opt.)</td><td>LiDAR 기반 고정밀, 실시간 대규모 루프 클로저</td><td>시각 정보 활용 제한, 하드웨어 의존성 높음</td></tr>
</tbody></table>
<h3>5.1  심층 해설</h3>
<h4>5.1.1  정확도 vs. 강인성 vs. 계산량의 트레이드오프</h4>
<p>SLAM 시스템의 성능은 종종 정확도, 강인성, 계산량이라는 세 가지 축 사이의 균형점으로 평가된다.</p>
<ul>
<li><strong>ORB-SLAM</strong>은 이 세 가지 측면에서 가장 균형 잡힌 고성능을 목표로 설계되었다. 정교한 번들 조정과 그래프 최적화를 통해 최고의 정확도를 추구하며, Bag-of-Words 기반의 장소 인식과 공시성 그래프를 통해 다양한 환경에서의 강인성을 확보했다. 그러나 이러한 성능을 위해 3개의 병렬 스레드에서 복잡한 연산을 수행하므로 가장 높은 계산량을 요구한다.36</li>
<li><strong>LSD-SLAM</strong>은 특징점 기반 방식이 실패하는 텍스처 부족 환경에서의 ’강인성’을 확보하기 위해 직접 방식을 채택했다. 이는 코너가 없는 환경에서도 엣지 정보를 활용할 수 있게 해주지만, 픽셀 밝기 값에 직접 의존하기 때문에 조명 변화에 대한 ’강인성’은 희생해야 했다.17</li>
<li><strong>Cartographer</strong>는 LiDAR라는 고정밀 센서를 사용하여 기하학적 ’정확도’와 ’강인성’을 확보하는 데 중점을 둔다. LiDAR는 조명 변화에 영향을 받지 않으며, 직접적인 거리 측정을 통해 신뢰도 높은 맵을 생성한다. 하지만 이는 시각적 특징이 없는 환경에서는 장소 인식이 어렵다는 한계를 가지며, 고가의 센서와 높은 계산 자원을 필요로 한다.6</li>
<li>초기의 <strong>EKF-SLAM</strong>과 <strong>FastSLAM</strong>은 당시의 계산 자원 제약 하에서 실시간 ’계산량’을 만족시키는 데 초점을 맞추었다. EKF-SLAM은 수학적 우아함에도 불구하고 <span class="math math-inline">O(N^2)</span>의 복잡도로 인해 확장성에 실패했고, FastSLAM은 이를 <span class="math math-inline">O(M \log N)</span>으로 개선했지만 입자 고갈 문제로 인해 장기적인 ’정확도’와 일관성에서 한계를 보였다.22</li>
</ul>
<h4>5.1.2  맵의 밀도와 활용성</h4>
<p>생성되는 맵의 종류는 SLAM 시스템의 활용 범위를 결정하는 중요한 요소이다.</p>
<ul>
<li><strong>희소 맵 (Sparse Map)</strong>: EKF-SLAM, FastSLAM, PTAM, ORB-SLAM은 모두 소수의 랜드마크(특징점)로 구성된 희소 맵을 생성한다. 이 맵은 로봇의 위치를 추정하는 데에는 매우 효율적이고 충분하지만, 맵 자체에 담긴 정보가 적어 장애물 회피나 경로 계획과 같은 고수준 작업을 수행하는 데에는 한계가 있다.12</li>
<li><strong>준밀도 및 그리드 맵 (Semi-dense &amp; Grid Map)</strong>: LSD-SLAM이 생성하는 준밀도 맵과 Cartographer가 생성하는 2D/3D 그리드 맵은 환경의 기하학적 구조에 대한 훨씬 풍부한 정보를 담고 있다. LSD-SLAM의 맵은 텍스처가 있는 표면의 형태를 보여주며, Cartographer의 그리드 맵은 공간을 점유(occupied), 비어있음(free), 알 수 없음(unknown)으로 명확히 구분한다. 이러한 맵들은 로봇의 위치 추정뿐만 아니라, 자율 주행을 위한 경로 계획, 장애물 회피, 증강 현실(AR) 객체와의 상호작용 등 훨씬 다양한 응용 분야에 직접적으로 활용될 수 있다.43 따라서 어떤 애플리케이션을 목표로 하느냐에 따라 필요한 맵의 밀도가 달라지며, 이는 SLAM 알고리즘 선택의 중요한 기준이 된다.</li>
</ul>
<h4>5.1.3  기술적 패러다임의 전환</h4>
<p>이 기술들의 발전사를 관통해 보면 몇 가지 중요한 패러다임의 전환을 발견할 수 있다.</p>
<ul>
<li><strong>단일 가설에서 다중 가설로</strong>: EKF-SLAM은 전체 상태를 단일 가우시안 분포로 가정하는 ‘단일 가설’ 접근법이다. 이는 데이터 연관 실패 시 치명적인 결과를 낳았다. 반면, FastSLAM은 입자 필터를 통해 수많은 가설 경로를 동시에 탐색하는 ‘다중 가설’ 접근법을 도입하여 강인성을 획기적으로 높였다.</li>
<li><strong>점진적 추정에서 전역적 일관성으로</strong>: 필터링 기반 방식(EKF, FastSLAM)은 과거의 데이터를 요약하여 현재 상태만을 점진적으로 추정한다. 이는 계산적으로 효율적이지만 누적 오차를 피할 수 없다. PTAM 이후의 최적화 기반 방식은 키프레임이나 서브맵을 통해 과거의 정보를 유지하고, 루프 클로저와 같은 메커니즘을 통해 과거의 오류를 수정하며 ’전역적 일관성’을 확보하는 방향으로 전환되었다. 이는 SLAM 커뮤니티가 단순한 실시간 추정을 넘어, 정확하고 신뢰할 수 있는 대규모 맵을 구축하는 것을 더 중요한 목표로 삼게 되었음을 시사한다.</li>
</ul>
<p>결론적으로, ‘최고의’ SLAM 알고리즘은 존재하지 않는다. 각 기술은 특정 애플리케이션의 요구사항(예: 센서 종류, 환경 특성, 맵의 활용 목적, 가용 컴퓨팅 자원)에 맞춰 최적화된 설계의 결과물이다. 따라서 사용자는 이러한 핵심적인 트레이드오프 관계를 깊이 이해하고 자신의 목적에 가장 부합하는 기술을 선택해야 한다.</p>
<h2>6.  결론: SLAM 기술의 현재와 미래 전망</h2>
<h3>6.1  주요 SLAM 기술의 핵심 트레이드오프 요약</h3>
<p>본 안내서는 SLAM 기술의 발전사를 대표하는 여섯 가지 핵심 알고리즘을 심층적으로 분석하고 비교했다. EKF-SLAM에서 시작된 확률적 추정의 개념은 FastSLAM을 거쳐 계산적 확장성과 비선형성에 대한 해법을 모색했다. 이후 PTAM이 제시한 병렬 처리와 최적화 기반의 패러다임은 ORB-SLAM, LSD-SLAM, Google Cartographer와 같은 현대 SLAM 시스템의 기틀이 되었다. 이들의 발전 과정은 몇 가지 핵심적인 상충 관계(trade-off)를 중심으로 이루어져 왔다.</p>
<ul>
<li><strong>정확도 vs. 계산 복잡도</strong>: 번들 조정이나 전역 그래프 최적화와 같은 기법은 높은 정확도를 보장하지만 상당한 계산 자원을 요구한다. 반면, 필터링 기반 방식은 계산적으로 가볍지만 누적 오차와 선형화 문제로 인해 정확도에 한계가 있다.</li>
<li><strong>강인성 vs. 환경 가정</strong>: 특징점 기반 방식(ORB-SLAM)은 조명과 시점 변화에 강인하지만 텍스처가 풍부한 환경을 가정한다. 직접 방식(LSD-SLAM)은 텍스처가 부족한 환경에서도 동작하지만 조명에 민감하다. LiDAR 기반 방식(Cartographer)은 기하학적으로 명확한 환경에서 최고의 강인성을 보이지만, 특징 없는 넓은 공간에서는 어려움을 겪을 수 있다.</li>
<li><strong>맵의 밀도 vs. 활용성</strong>: 희소한 특징점 맵은 위치 추정에 효율적이지만 활용 범위가 제한적이다. 반면, 준밀도 또는 그리드 맵은 경로 계획, 장애물 회피 등 다양한 응용을 가능하게 하지만 더 많은 저장 공간과 처리 능력을 필요로 한다.</li>
</ul>
<p>이러한 트레이드오프는 SLAM 기술이 특정 응용 분야의 요구에 맞춰 분화하고 발전해왔음을 보여준다.</p>
<h3>6.2  현재 연구 동향 및 미래 전망</h3>
<p>SLAM 기술은 여전히 활발하게 연구가 진행 중인 분야이며, 특히 인공지능 기술의 발전과 맞물려 새로운 패러다임으로의 도약을 준비하고 있다.</p>
<ul>
<li><strong>딥러닝과의 융합</strong>: 전통적인 SLAM은 수작업으로 설계된 기하학적 모델에 크게 의존한다. 최근에는 딥러닝을 SLAM 파이프라인의 다양한 부분에 접목하려는 연구가 활발하다.10 예를 들어, 컨볼루션 신경망(CNN)을 사용하여 더 강인한 특징점을 추출하거나, 조명 변화에 불변하는 특징 기술자를 학습하고, 더 나아가 이미지 한 장으로부터 직접 카메라 포즈나 깊이를 추정하는 연구들이 진행되고 있다. 이는 전통적인 기하학 기반 SLAM이 어려움을 겪는 동적 객체 처리나 까다로운 환경에서의 강인성을 높일 잠재력을 가지고 있다.</li>
<li><strong>시맨틱 SLAM (Semantic SLAM)</strong>: 미래의 SLAM은 단순히 ’어디에 있는가’라는 기하학적 질문을 넘어 ’무엇이 있는가’라는 의미론적(semantic) 질문에 답하는 방향으로 발전할 것이다. 시맨틱 SLAM은 맵 상의 객체들에 ‘문’, ‘의자’, ’사람’과 같은 의미론적 레이블을 부여하는 것을 목표로 한다.44 이는 딥러닝 기반의 객체 탐지 및 분할 기술과 SLAM을 결합함으로써 가능해진다. 시맨틱 맵이 구축되면, 로봇은 “부엌으로 가서 컵을 가져와“와 같은 고수준의 인간 명령을 이해하고 수행할 수 있게 되어, 진정한 의미의 지능형 자율 로봇을 구현하는 핵심 기술이 될 것이다.</li>
<li><strong>강인성과 평생 SLAM (Robustness and Lifelong SLAM)</strong>: 실제 세계는 조명, 날씨, 계절의 변화가 극심하고, 예측 불가능한 동적 객체들로 가득 차 있다. 이러한 가혹하고 비정형적인 환경에서도 실패하지 않고 안정적으로 동작하는 강인한 SLAM 기술은 여전히 중요한 연구 목표이다.9 더 나아가, 한번 구축한 맵을 폐기하지 않고, 시간이 지남에 따라 변화하는 환경을 지속적으로 반영하여 맵을 갱신하고 재사용하는 ’평생 SLAM(Lifelong SLAM)’이 궁극적인 지향점이다. 이는 로봇이 장기간에 걸쳐 특정 공간에서 활동하며 경험을 축적하고 학습하는 능력을 갖추게 함을 의미한다.13</li>
<li><strong>다중 센서 융합의 심화</strong>: 융합 시대의 흐름은 앞으로 더욱 가속화될 것이다. 카메라, LiDAR, IMU뿐만 아니라, 레이더, 이벤트 카메라, 열화상 카메라 등 다양한 특성을 가진 센서들을 효과적으로 융합하여 각 센서의 단점을 상호 보완하고, 어떠한 악조건에서도 시스템의 성능을 보장하려는 연구가 주류를 이룰 것이다.10</li>
</ul>
<p>결론적으로, SLAM 기술은 순수한 기하학적 문제 해결을 넘어, 딥러닝과 의미론적 이해를 통합하여 로봇이 주변 세계를 종합적으로 ’인식(perception)’하는 시스템으로 진화하고 있다. 이러한 발전은 자율 주행차, 서비스 로봇, 증강 현실 등 미래 기술의 핵심 기반이 되어 우리 삶의 방식을 근본적으로 변화시킬 잠재력을 지니고 있다.</p>
<h2>7. 참고 자료</h2>
<ol>
<li>How SLAM Technology Can Support New-build Projects | GIM International, https://www.gim-international.com/content/article/how-slam-technology-can-support-new-build-projects</li>
<li>Simultaneous Localization and Mapping with Unknown Data Association Using FastSLAM - Sebastian Thrun, http://robots.stanford.edu/papers/montemerlo.fastslam-dataassoc03.pdf</li>
<li>The definitive guide to SLAM &amp; mobile mapping - NavVis, https://www.navvis.com/technology/slam</li>
<li>Simultaneous localization and mapping - Wikipedia, https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping</li>
<li>FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem With Unknown Data Association - CiteSeerX, https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=b4c3e8a4636a977c07ffcdb14aa089227e585157</li>
<li>The Complete Guide to SLAM: Origin, Applications, and Comparison of 5 systems - dtLabs, https://dt-labs.ai/blog/the-complete-guide-to-slam/</li>
<li>Overview of Multi-Robot Collaborative SLAM from the Perspective of Data Fusion - MDPI, https://www.mdpi.com/2075-1702/11/6/653</li>
<li>A Comprehensive Survey of Visual SLAM Algorithms - MDPI, https://www.mdpi.com/2218-6581/11/1/24</li>
<li>Are there any SLAM algorithms adopted or more popular than EKF SLAM and FastSLAM? | ResearchGate, https://www.researchgate.net/post/Are-there-any-SLAM-algorithms-adopted-or-more-popular-than-EKF-SLAM-and-FastSLAM</li>
<li>Unlocking the Power of SLAM in Autonomous Robotics - Number Analytics, https://www.numberanalytics.com/blog/unlocking-power-slam-autonomous-robotics</li>
<li>Timeline representing the most representative visual-only SLAM algorithms. - ResearchGate, https://www.researchgate.net/figure/Diagram-representing-the-MonoSLAM-algorithm_fig3_358523574</li>
<li>Visual SLAM: Possibilities, Challenges and the Future - Ignitarium, https://ignitarium.com/visual-slam-possibilities-challenges-and-the-future/</li>
<li>ORB-SLAM: A Versatile and Accurate Monocular SLAM System - Washington, https://courses.cs.washington.edu/courses/csep576/21au/resources/ORB-SLAM_A_Versatile_and_Accurate_Monocular_SLAM_System.pdf</li>
<li>LNCS 8690 - LSD-SLAM: Large-Scale Direct Monocular SLAM, http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/ECCV_2014/papers/8690/86900834.pdf</li>
<li>LSD-SLAM: large-scale direct monocular SLAM | Request PDF - ResearchGate, https://www.researchgate.net/publication/319770169_LSD-SLAM_large-scale_direct_monocular_SLAM</li>
<li>LSD-SLAM: Large-Scale Direct Monocular SLAM - Jakob Engel, https://jakobengel.github.io/pdf/engel14eccv.pdf</li>
<li>Visual SLAM: What Are the Current Trends and What to Expect? - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC9735432/</li>
<li>EKF-SLAM A Very Quick Guide - IRI-UPC, <a href="https://www.iri.upc.edu/people/jsola/JoanSola/objectes/curs_SLAM/SLAM2D/SLAM%20course.pdf">https://www.iri.upc.edu/people/jsola/JoanSola/objectes/curs_SLAM/SLAM2D/SLAM%20course.pdf</a></li>
<li>EKF SLAM vs. FastSLAM – A Comparison - Infoscience, https://infoscience.epfl.ch/bitstreams/d5871034-a345-4220-9e46-293f9e66e02a/download</li>
<li>The SLAM problem: a survey - EIA, http://eia.udg.es/~qsalvi/papers/2008-CCIAa.pdf</li>
<li>Divide and Conquer: EKF SLAM in O(n) - Universidad de Zaragoza, http://webdiis.unizar.es/GRPTR/pubs/2008_Paz_IEEETRO1.pdf</li>
<li>FastSLAM 2.0: An Improved Particle Filtering Algorithm for Simultaneous Localization and Mapping that Provably Converges - IJCAI, https://www.ijcai.org/Proceedings/03/Papers/165.pdf</li>
<li>FastsLAM: Real Time Implementation in Outdoor Environments - Australian Robotics and Automation Association, https://www.araa.asn.au/acra/acra2002/Papers/Nieto-Guivant-Nebot.pdf</li>
<li>FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem | Request PDF - ResearchGate, https://www.researchgate.net/publication/224773156_FastSLAM_A_Factored_Solution_to_the_Simultaneous_Localization_and_Mapping_Problem</li>
<li>FastSLAM: A Factored Solution to the Simultaneous Localization …, https://cdn.aaai.org/AAAI/2002/AAAI02-089.pdf</li>
<li>FastSLAM: An Efficient Solution to the Simultaneous Localization And Mapping Problem with Unknown Data Association - Sebastian Thrun, http://robots.stanford.edu/papers/Thrun03g.pdf</li>
<li>Consistency of the FastSLAM Algorithm - CiteSeerX, https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=998802f52b95b0f697805371ba4178dd90f84181</li>
<li>Context-Adaptable Deployment of FastSLAM 2.0 on Graphic Processing Unit with Unknown Data Association - MDPI, https://www.mdpi.com/2076-3417/14/23/11466</li>
<li>Parallel Tracking and Mapping for Small AR Workspaces - ResearchGate, https://www.researchgate.net/publication/4334429_Parallel_Tracking_and_Mapping_for_Small_AR_Workspaces</li>
<li>PTAM: Parallel Tracking and … - Perception and Learning in Machines, http://ahumaninmachinesworld.blogspot.com/2015/06/ptam-parallel-tracking-and-mapping.html</li>
<li>Stereo Parallel Tracking and Mapping for robot localization, https://webdiis.unizar.es/~jcivera/papers/pire_etal_iros15.pdf</li>
<li>[1502.00956] ORB-SLAM: a Versatile and Accurate Monocular SLAM System - ar5iv - arXiv, https://ar5iv.labs.arxiv.org/html/1502.00956</li>
<li>Vision Algorithms for Mobile Robotics Lecture 01 Introduction, https://rpg.ifi.uzh.ch/docs/teaching/2020/10_multiple_view_geometry_4.pdf</li>
<li>Monocular SLAM for Real-Time Applications on Mobile Platforms - Stanford University, https://web.stanford.edu/class/cs231m/projects/final-report-shridhar-neo.pdf</li>
<li>(PDF) ORB-SLAM: a versatile and accurate monocular SLAM system - ResearchGate, https://www.researchgate.net/publication/271823237_ORB-SLAM_a_versatile_and_accurate_monocular_SLAM_system</li>
<li>What is the ORB-SLAM algorithm? - Educative.io, https://www.educative.io/answers/what-is-the-orb-slam-algorithm</li>
<li>Comparison of Various SLAM Systems for Mobile Robot in an Indoor Environment - arXiv, https://arxiv.org/html/2501.09490v1</li>
<li>Visual SLAM - LSD-SLAM: Large-Scale Direct Monocular SLAM - Computer Vision Group, https://cvg.cit.tum.de/research/vslam/lsdslam</li>
<li>Cartographer SLAM Method for Optimization with an Adaptive Multi-Distance Scan Scheduler - MDPI, https://www.mdpi.com/2076-3417/10/1/347</li>
<li>(PDF) IMPROVING GOOGLE’S CARTOGRAPHER 3D MAPPING BY CONTINUOUS-TIME SLAM - ResearchGate, https://www.researchgate.net/publication/313945676_IMPROVING_GOOGLE’S_CARTOGRAPHER_3D_MAPPING_BY_CONTINUOUS-TIME_SLAM</li>
<li>Real-Time Loop Closure in 2D LIDAR SLAM - Google Research, https://research.google.com/pubs/archive/45466.pdf</li>
<li>Improving Sensor Adaptability and Functionality in Cartographer Simultaneous Localization and Mapping - PMC - PubMed Central, https://pmc.ncbi.nlm.nih.gov/articles/PMC11946133/</li>
<li>Introduction to SLAM (Simultaneous Localization and Mapping) | Ouster, https://ouster.com/insights/blog/introduction-to-slam-simultaneous-localization-and-mapping</li>
<li>An Overview on Visual SLAM: From Tradition to Semantic - MDPI, https://www.mdpi.com/2072-4292/14/13/3010</li>
<li>A compare result of the original PTAM and the improved PTAM algorithm - ResearchGate, https://www.researchgate.net/figure/A-compare-result-of-the-original-PTAM-and-the-improved-PTAM-algorithm-a-is-the_fig15_303780259</li>
</ol>

            </article>
            <footer>
                <p>Generated by Rust Site Gen</p>
            </footer>
        </main>
    </div>
</body>
</html>